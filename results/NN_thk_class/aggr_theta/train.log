Before oversampling: Counter({2.0: 2509, 1.0: 2329, 3.0: 1982, 5.0: 1790, 4.0: 1359})
After oversampling: Counter({1.0: 2509, 2.0: 2509, 3.0: 2509, 4.0: 2509, 5.0: 2509})
Classes: [1. 2. 3. 4. 5.]
*************************** Fold #: 1 ***************************
Model: "sequential_60"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_240 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_241 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_242 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_243 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6096 - accuracy: 0.1979 - val_loss: 1.6049 - val_accuracy: 0.2000

Epoch 00001: val_loss improved from inf to 1.60491, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 2/10000
12/12 - 0s - loss: 1.6029 - accuracy: 0.1993 - val_loss: 1.6005 - val_accuracy: 0.2008

Epoch 00002: val_loss improved from 1.60491 to 1.60053, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 3/10000
12/12 - 0s - loss: 1.5982 - accuracy: 0.2012 - val_loss: 1.5955 - val_accuracy: 0.1992

Epoch 00003: val_loss improved from 1.60053 to 1.59554, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 4/10000
12/12 - 0s - loss: 1.5922 - accuracy: 0.2120 - val_loss: 1.5880 - val_accuracy: 0.2351

Epoch 00004: val_loss improved from 1.59554 to 1.58804, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 5/10000
12/12 - 0s - loss: 1.5840 - accuracy: 0.2535 - val_loss: 1.5785 - val_accuracy: 0.2733

Epoch 00005: val_loss improved from 1.58804 to 1.57852, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 6/10000
12/12 - 0s - loss: 1.5728 - accuracy: 0.3182 - val_loss: 1.5648 - val_accuracy: 0.3060

Epoch 00006: val_loss improved from 1.57852 to 1.56482, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 7/10000
12/12 - 0s - loss: 1.5586 - accuracy: 0.3194 - val_loss: 1.5494 - val_accuracy: 0.3163

Epoch 00007: val_loss improved from 1.56482 to 1.54942, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 8/10000
12/12 - 0s - loss: 1.5381 - accuracy: 0.3561 - val_loss: 1.5248 - val_accuracy: 0.3522

Epoch 00008: val_loss improved from 1.54942 to 1.52484, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 9/10000
12/12 - 0s - loss: 1.5105 - accuracy: 0.3522 - val_loss: 1.4938 - val_accuracy: 0.3402

Epoch 00009: val_loss improved from 1.52484 to 1.49383, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 10/10000
12/12 - 0s - loss: 1.4760 - accuracy: 0.3566 - val_loss: 1.4577 - val_accuracy: 0.3315

Epoch 00010: val_loss improved from 1.49383 to 1.45765, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 11/10000
12/12 - 0s - loss: 1.4399 - accuracy: 0.3486 - val_loss: 1.4212 - val_accuracy: 0.3458

Epoch 00011: val_loss improved from 1.45765 to 1.42123, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 12/10000
12/12 - 0s - loss: 1.4048 - accuracy: 0.3629 - val_loss: 1.3930 - val_accuracy: 0.3578

Epoch 00012: val_loss improved from 1.42123 to 1.39305, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 13/10000
12/12 - 0s - loss: 1.3830 - accuracy: 0.3689 - val_loss: 1.3712 - val_accuracy: 0.3936

Epoch 00013: val_loss improved from 1.39305 to 1.37118, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 14/10000
12/12 - 0s - loss: 1.3670 - accuracy: 0.3785 - val_loss: 1.3576 - val_accuracy: 0.3801

Epoch 00014: val_loss improved from 1.37118 to 1.35758, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 15/10000
12/12 - 0s - loss: 1.3553 - accuracy: 0.3758 - val_loss: 1.3484 - val_accuracy: 0.4000

Epoch 00015: val_loss improved from 1.35758 to 1.34835, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 16/10000
12/12 - 0s - loss: 1.3491 - accuracy: 0.3916 - val_loss: 1.3444 - val_accuracy: 0.3857

Epoch 00016: val_loss improved from 1.34835 to 1.34443, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 17/10000
12/12 - 0s - loss: 1.3462 - accuracy: 0.3897 - val_loss: 1.3435 - val_accuracy: 0.3928

Epoch 00017: val_loss improved from 1.34443 to 1.34353, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 18/10000
12/12 - 0s - loss: 1.3463 - accuracy: 0.3869 - val_loss: 1.3382 - val_accuracy: 0.3928

Epoch 00018: val_loss improved from 1.34353 to 1.33822, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 19/10000
12/12 - 0s - loss: 1.3447 - accuracy: 0.3931 - val_loss: 1.3363 - val_accuracy: 0.3960

Epoch 00019: val_loss improved from 1.33822 to 1.33625, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 20/10000
12/12 - 0s - loss: 1.3421 - accuracy: 0.3914 - val_loss: 1.3363 - val_accuracy: 0.3920

Epoch 00020: val_loss improved from 1.33625 to 1.33625, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 21/10000
12/12 - 0s - loss: 1.3416 - accuracy: 0.3785 - val_loss: 1.3358 - val_accuracy: 0.3952

Epoch 00021: val_loss improved from 1.33625 to 1.33576, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 22/10000
12/12 - 0s - loss: 1.3417 - accuracy: 0.3881 - val_loss: 1.3356 - val_accuracy: 0.3936

Epoch 00022: val_loss improved from 1.33576 to 1.33557, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 23/10000
12/12 - 0s - loss: 1.3398 - accuracy: 0.3823 - val_loss: 1.3346 - val_accuracy: 0.3960

Epoch 00023: val_loss improved from 1.33557 to 1.33464, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 24/10000
12/12 - 0s - loss: 1.3411 - accuracy: 0.3821 - val_loss: 1.3348 - val_accuracy: 0.3873

Epoch 00024: val_loss did not improve from 1.33464
Epoch 25/10000
12/12 - 0s - loss: 1.3384 - accuracy: 0.3868 - val_loss: 1.3334 - val_accuracy: 0.3904

Epoch 00025: val_loss improved from 1.33464 to 1.33341, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 26/10000
12/12 - 0s - loss: 1.3394 - accuracy: 0.3928 - val_loss: 1.3316 - val_accuracy: 0.3936

Epoch 00026: val_loss improved from 1.33341 to 1.33161, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 27/10000
12/12 - 0s - loss: 1.3373 - accuracy: 0.3960 - val_loss: 1.3318 - val_accuracy: 0.3968

Epoch 00027: val_loss did not improve from 1.33161
Epoch 28/10000
12/12 - 0s - loss: 1.3382 - accuracy: 0.3978 - val_loss: 1.3310 - val_accuracy: 0.4016

Epoch 00028: val_loss improved from 1.33161 to 1.33105, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 29/10000
12/12 - 0s - loss: 1.3375 - accuracy: 0.3906 - val_loss: 1.3304 - val_accuracy: 0.4024

Epoch 00029: val_loss improved from 1.33105 to 1.33038, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 30/10000
12/12 - 0s - loss: 1.3389 - accuracy: 0.3899 - val_loss: 1.3324 - val_accuracy: 0.3849

Epoch 00030: val_loss did not improve from 1.33038
Epoch 31/10000
12/12 - 0s - loss: 1.3371 - accuracy: 0.3917 - val_loss: 1.3305 - val_accuracy: 0.4008

Epoch 00031: val_loss did not improve from 1.33038
Epoch 32/10000
12/12 - 0s - loss: 1.3374 - accuracy: 0.3960 - val_loss: 1.3326 - val_accuracy: 0.3880

Epoch 00032: val_loss did not improve from 1.33038
Epoch 33/10000
12/12 - 0s - loss: 1.3372 - accuracy: 0.3964 - val_loss: 1.3286 - val_accuracy: 0.3944

Epoch 00033: val_loss improved from 1.33038 to 1.32859, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 34/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3861 - val_loss: 1.3283 - val_accuracy: 0.3928

Epoch 00034: val_loss improved from 1.32859 to 1.32825, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 35/10000
12/12 - 0s - loss: 1.3358 - accuracy: 0.3983 - val_loss: 1.3325 - val_accuracy: 0.3857

Epoch 00035: val_loss did not improve from 1.32825
Epoch 36/10000
12/12 - 0s - loss: 1.3351 - accuracy: 0.3904 - val_loss: 1.3288 - val_accuracy: 0.3944

Epoch 00036: val_loss did not improve from 1.32825
Epoch 37/10000
12/12 - 0s - loss: 1.3359 - accuracy: 0.3841 - val_loss: 1.3285 - val_accuracy: 0.3928

Epoch 00037: val_loss did not improve from 1.32825
Epoch 38/10000
12/12 - 0s - loss: 1.3338 - accuracy: 0.3917 - val_loss: 1.3268 - val_accuracy: 0.3904

Epoch 00038: val_loss improved from 1.32825 to 1.32680, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 39/10000
12/12 - 0s - loss: 1.3338 - accuracy: 0.3833 - val_loss: 1.3274 - val_accuracy: 0.3825

Epoch 00039: val_loss did not improve from 1.32680
Epoch 40/10000
12/12 - 0s - loss: 1.3342 - accuracy: 0.3873 - val_loss: 1.3269 - val_accuracy: 0.3968

Epoch 00040: val_loss did not improve from 1.32680
Epoch 41/10000
12/12 - 0s - loss: 1.3335 - accuracy: 0.3913 - val_loss: 1.3258 - val_accuracy: 0.4000

Epoch 00041: val_loss improved from 1.32680 to 1.32582, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 42/10000
12/12 - 0s - loss: 1.3334 - accuracy: 0.3841 - val_loss: 1.3252 - val_accuracy: 0.3896

Epoch 00042: val_loss improved from 1.32582 to 1.32517, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 43/10000
12/12 - 0s - loss: 1.3328 - accuracy: 0.3955 - val_loss: 1.3257 - val_accuracy: 0.3857

Epoch 00043: val_loss did not improve from 1.32517
Epoch 44/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3969 - val_loss: 1.3253 - val_accuracy: 0.3865

Epoch 00044: val_loss did not improve from 1.32517
Epoch 45/10000
12/12 - 0s - loss: 1.3333 - accuracy: 0.3946 - val_loss: 1.3277 - val_accuracy: 0.3873

Epoch 00045: val_loss did not improve from 1.32517
Epoch 46/10000
12/12 - 0s - loss: 1.3339 - accuracy: 0.3860 - val_loss: 1.3286 - val_accuracy: 0.3888

Epoch 00046: val_loss did not improve from 1.32517
Epoch 47/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3863 - val_loss: 1.3279 - val_accuracy: 0.3825

Epoch 00047: val_loss did not improve from 1.32517
Epoch 48/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3927 - val_loss: 1.3253 - val_accuracy: 0.3920

Epoch 00048: val_loss did not improve from 1.32517
Epoch 49/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3952 - val_loss: 1.3292 - val_accuracy: 0.3849

Epoch 00049: val_loss did not improve from 1.32517
Epoch 50/10000
12/12 - 0s - loss: 1.3394 - accuracy: 0.3823 - val_loss: 1.3382 - val_accuracy: 0.3928

Epoch 00050: val_loss did not improve from 1.32517
Epoch 51/10000
12/12 - 0s - loss: 1.3376 - accuracy: 0.3880 - val_loss: 1.3295 - val_accuracy: 0.3753

Epoch 00051: val_loss did not improve from 1.32517
Epoch 52/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3882 - val_loss: 1.3250 - val_accuracy: 0.3841

Epoch 00052: val_loss improved from 1.32517 to 1.32498, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 53/10000
12/12 - 0s - loss: 1.3350 - accuracy: 0.3934 - val_loss: 1.3265 - val_accuracy: 0.3952

Epoch 00053: val_loss did not improve from 1.32498
Epoch 54/10000
12/12 - 0s - loss: 1.3321 - accuracy: 0.3917 - val_loss: 1.3246 - val_accuracy: 0.3825

Epoch 00054: val_loss improved from 1.32498 to 1.32460, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 55/10000
12/12 - 0s - loss: 1.3328 - accuracy: 0.3957 - val_loss: 1.3272 - val_accuracy: 0.3825

Epoch 00055: val_loss did not improve from 1.32460
Epoch 56/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3833 - val_loss: 1.3225 - val_accuracy: 0.3944

Epoch 00056: val_loss improved from 1.32460 to 1.32249, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 57/10000
12/12 - 0s - loss: 1.3332 - accuracy: 0.3919 - val_loss: 1.3272 - val_accuracy: 0.3888

Epoch 00057: val_loss did not improve from 1.32249
Epoch 58/10000
12/12 - 0s - loss: 1.3341 - accuracy: 0.3949 - val_loss: 1.3250 - val_accuracy: 0.3825

Epoch 00058: val_loss did not improve from 1.32249
Epoch 59/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3947 - val_loss: 1.3227 - val_accuracy: 0.3928

Epoch 00059: val_loss did not improve from 1.32249
Epoch 60/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3850 - val_loss: 1.3231 - val_accuracy: 0.3833

Epoch 00060: val_loss did not improve from 1.32249
Epoch 61/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3896 - val_loss: 1.3244 - val_accuracy: 0.3777

Epoch 00061: val_loss did not improve from 1.32249
Epoch 62/10000
12/12 - 0s - loss: 1.3304 - accuracy: 0.3923 - val_loss: 1.3233 - val_accuracy: 0.3849

Epoch 00062: val_loss did not improve from 1.32249
Epoch 63/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3960 - val_loss: 1.3220 - val_accuracy: 0.3865

Epoch 00063: val_loss improved from 1.32249 to 1.32197, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 64/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3947 - val_loss: 1.3217 - val_accuracy: 0.3944

Epoch 00064: val_loss improved from 1.32197 to 1.32173, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 65/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3889 - val_loss: 1.3224 - val_accuracy: 0.3976

Epoch 00065: val_loss did not improve from 1.32173
Epoch 66/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3962 - val_loss: 1.3255 - val_accuracy: 0.3793

Epoch 00066: val_loss did not improve from 1.32173
Epoch 67/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3937 - val_loss: 1.3239 - val_accuracy: 0.3888

Epoch 00067: val_loss did not improve from 1.32173
Epoch 68/10000
12/12 - 0s - loss: 1.3304 - accuracy: 0.3957 - val_loss: 1.3220 - val_accuracy: 0.3857

Epoch 00068: val_loss did not improve from 1.32173
Epoch 69/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3972 - val_loss: 1.3231 - val_accuracy: 0.3777

Epoch 00069: val_loss did not improve from 1.32173
Epoch 70/10000
12/12 - 0s - loss: 1.3273 - accuracy: 0.3953 - val_loss: 1.3216 - val_accuracy: 0.3968

Epoch 00070: val_loss improved from 1.32173 to 1.32157, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 71/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3967 - val_loss: 1.3212 - val_accuracy: 0.3896

Epoch 00071: val_loss improved from 1.32157 to 1.32115, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 72/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3971 - val_loss: 1.3207 - val_accuracy: 0.3841

Epoch 00072: val_loss improved from 1.32115 to 1.32072, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 73/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3951 - val_loss: 1.3217 - val_accuracy: 0.3841

Epoch 00073: val_loss did not improve from 1.32072
Epoch 74/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3965 - val_loss: 1.3207 - val_accuracy: 0.3912

Epoch 00074: val_loss improved from 1.32072 to 1.32067, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 75/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3909 - val_loss: 1.3211 - val_accuracy: 0.3849

Epoch 00075: val_loss did not improve from 1.32067
Epoch 76/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3994 - val_loss: 1.3207 - val_accuracy: 0.3809

Epoch 00076: val_loss did not improve from 1.32067
Epoch 77/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3897 - val_loss: 1.3212 - val_accuracy: 0.3873

Epoch 00077: val_loss did not improve from 1.32067
Epoch 78/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3903 - val_loss: 1.3245 - val_accuracy: 0.4000

Epoch 00078: val_loss did not improve from 1.32067
Epoch 79/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.4022 - val_loss: 1.3220 - val_accuracy: 0.3888

Epoch 00079: val_loss did not improve from 1.32067
Epoch 80/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3965 - val_loss: 1.3213 - val_accuracy: 0.3841

Epoch 00080: val_loss did not improve from 1.32067
Epoch 81/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3965 - val_loss: 1.3210 - val_accuracy: 0.3968

Epoch 00081: val_loss did not improve from 1.32067
Epoch 82/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3943 - val_loss: 1.3207 - val_accuracy: 0.3825

Epoch 00082: val_loss improved from 1.32067 to 1.32065, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 83/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3995 - val_loss: 1.3199 - val_accuracy: 0.3857

Epoch 00083: val_loss improved from 1.32065 to 1.31990, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 84/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3879 - val_loss: 1.3201 - val_accuracy: 0.3952

Epoch 00084: val_loss did not improve from 1.31990
Epoch 85/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3970 - val_loss: 1.3211 - val_accuracy: 0.3841

Epoch 00085: val_loss did not improve from 1.31990
Epoch 86/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3878 - val_loss: 1.3198 - val_accuracy: 0.3849

Epoch 00086: val_loss improved from 1.31990 to 1.31978, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 87/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3880 - val_loss: 1.3193 - val_accuracy: 0.3817

Epoch 00087: val_loss improved from 1.31978 to 1.31928, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 88/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3978 - val_loss: 1.3209 - val_accuracy: 0.3785

Epoch 00088: val_loss did not improve from 1.31928
Epoch 89/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3986 - val_loss: 1.3229 - val_accuracy: 0.4024

Epoch 00089: val_loss did not improve from 1.31928
Epoch 90/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3978 - val_loss: 1.3241 - val_accuracy: 0.3721

Epoch 00090: val_loss did not improve from 1.31928
Epoch 91/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3999 - val_loss: 1.3196 - val_accuracy: 0.3833

Epoch 00091: val_loss did not improve from 1.31928
Epoch 92/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3889 - val_loss: 1.3211 - val_accuracy: 0.3873

Epoch 00092: val_loss did not improve from 1.31928
Epoch 93/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3985 - val_loss: 1.3200 - val_accuracy: 0.3817

Epoch 00093: val_loss did not improve from 1.31928
Epoch 94/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3972 - val_loss: 1.3188 - val_accuracy: 0.3809

Epoch 00094: val_loss improved from 1.31928 to 1.31876, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 95/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3946 - val_loss: 1.3199 - val_accuracy: 0.3928

Epoch 00095: val_loss did not improve from 1.31876
Epoch 96/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3991 - val_loss: 1.3195 - val_accuracy: 0.3809

Epoch 00096: val_loss did not improve from 1.31876
Epoch 97/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3981 - val_loss: 1.3200 - val_accuracy: 0.3825

Epoch 00097: val_loss did not improve from 1.31876
Epoch 98/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3958 - val_loss: 1.3205 - val_accuracy: 0.3793

Epoch 00098: val_loss did not improve from 1.31876
Epoch 99/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3964 - val_loss: 1.3195 - val_accuracy: 0.3952

Epoch 00099: val_loss did not improve from 1.31876
Epoch 100/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3999 - val_loss: 1.3187 - val_accuracy: 0.3825

Epoch 00100: val_loss improved from 1.31876 to 1.31872, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 101/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3928 - val_loss: 1.3188 - val_accuracy: 0.3769

Epoch 00101: val_loss did not improve from 1.31872
Epoch 102/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3933 - val_loss: 1.3200 - val_accuracy: 0.3777

Epoch 00102: val_loss did not improve from 1.31872
Epoch 103/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3981 - val_loss: 1.3193 - val_accuracy: 0.3825

Epoch 00103: val_loss did not improve from 1.31872
Epoch 104/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3981 - val_loss: 1.3184 - val_accuracy: 0.3817

Epoch 00104: val_loss improved from 1.31872 to 1.31845, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 105/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3999 - val_loss: 1.3184 - val_accuracy: 0.3777

Epoch 00105: val_loss improved from 1.31845 to 1.31843, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 106/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3982 - val_loss: 1.3179 - val_accuracy: 0.3769

Epoch 00106: val_loss improved from 1.31843 to 1.31788, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 107/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3990 - val_loss: 1.3183 - val_accuracy: 0.3777

Epoch 00107: val_loss did not improve from 1.31788
Epoch 108/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3973 - val_loss: 1.3184 - val_accuracy: 0.3793

Epoch 00108: val_loss did not improve from 1.31788
Epoch 109/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3995 - val_loss: 1.3179 - val_accuracy: 0.3833

Epoch 00109: val_loss did not improve from 1.31788
Epoch 110/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3973 - val_loss: 1.3173 - val_accuracy: 0.3857

Epoch 00110: val_loss improved from 1.31788 to 1.31731, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 111/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3943 - val_loss: 1.3179 - val_accuracy: 0.3841

Epoch 00111: val_loss did not improve from 1.31731
Epoch 112/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3994 - val_loss: 1.3186 - val_accuracy: 0.3809

Epoch 00112: val_loss did not improve from 1.31731
Epoch 113/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3976 - val_loss: 1.3178 - val_accuracy: 0.3801

Epoch 00113: val_loss did not improve from 1.31731
Epoch 114/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3993 - val_loss: 1.3171 - val_accuracy: 0.3833

Epoch 00114: val_loss improved from 1.31731 to 1.31714, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 115/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3981 - val_loss: 1.3170 - val_accuracy: 0.3761

Epoch 00115: val_loss improved from 1.31714 to 1.31702, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 116/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3981 - val_loss: 1.3199 - val_accuracy: 0.3729

Epoch 00116: val_loss did not improve from 1.31702
Epoch 117/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.4009 - val_loss: 1.3172 - val_accuracy: 0.3769

Epoch 00117: val_loss did not improve from 1.31702
Epoch 118/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3993 - val_loss: 1.3190 - val_accuracy: 0.3920

Epoch 00118: val_loss did not improve from 1.31702
Epoch 119/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3981 - val_loss: 1.3183 - val_accuracy: 0.3713

Epoch 00119: val_loss did not improve from 1.31702
Epoch 120/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3970 - val_loss: 1.3179 - val_accuracy: 0.3865

Epoch 00120: val_loss did not improve from 1.31702
Epoch 121/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3902 - val_loss: 1.3171 - val_accuracy: 0.3825

Epoch 00121: val_loss did not improve from 1.31702
Epoch 122/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3977 - val_loss: 1.3183 - val_accuracy: 0.3849

Epoch 00122: val_loss did not improve from 1.31702
Epoch 123/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3980 - val_loss: 1.3196 - val_accuracy: 0.3729

Epoch 00123: val_loss did not improve from 1.31702
Epoch 124/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3992 - val_loss: 1.3184 - val_accuracy: 0.3825

Epoch 00124: val_loss did not improve from 1.31702
Epoch 125/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3998 - val_loss: 1.3179 - val_accuracy: 0.3849

Epoch 00125: val_loss did not improve from 1.31702
Epoch 126/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3965 - val_loss: 1.3214 - val_accuracy: 0.3785

Epoch 00126: val_loss did not improve from 1.31702
Epoch 127/10000
12/12 - 0s - loss: 1.3257 - accuracy: 0.3959 - val_loss: 1.3189 - val_accuracy: 0.3865

Epoch 00127: val_loss did not improve from 1.31702
Epoch 128/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3991 - val_loss: 1.3178 - val_accuracy: 0.3841

Epoch 00128: val_loss did not improve from 1.31702
Epoch 129/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3983 - val_loss: 1.3190 - val_accuracy: 0.3737

Epoch 00129: val_loss did not improve from 1.31702
Epoch 130/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3982 - val_loss: 1.3187 - val_accuracy: 0.3904

Epoch 00130: val_loss did not improve from 1.31702
Epoch 131/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.4014 - val_loss: 1.3184 - val_accuracy: 0.3729

Epoch 00131: val_loss did not improve from 1.31702
Epoch 132/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3911 - val_loss: 1.3165 - val_accuracy: 0.3809

Epoch 00132: val_loss improved from 1.31702 to 1.31647, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 133/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3992 - val_loss: 1.3171 - val_accuracy: 0.3793

Epoch 00133: val_loss did not improve from 1.31647
Epoch 134/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3944 - val_loss: 1.3181 - val_accuracy: 0.3857

Epoch 00134: val_loss did not improve from 1.31647
Epoch 135/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3972 - val_loss: 1.3178 - val_accuracy: 0.3785

Epoch 00135: val_loss did not improve from 1.31647
Epoch 136/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.4003 - val_loss: 1.3168 - val_accuracy: 0.3737

Epoch 00136: val_loss did not improve from 1.31647
Epoch 137/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3960 - val_loss: 1.3169 - val_accuracy: 0.3753

Epoch 00137: val_loss did not improve from 1.31647
Epoch 138/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3942 - val_loss: 1.3176 - val_accuracy: 0.3880

Epoch 00138: val_loss did not improve from 1.31647
Epoch 139/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3989 - val_loss: 1.3186 - val_accuracy: 0.3841

Epoch 00139: val_loss did not improve from 1.31647
Epoch 140/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3985 - val_loss: 1.3181 - val_accuracy: 0.3777

Epoch 00140: val_loss did not improve from 1.31647
Epoch 141/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3970 - val_loss: 1.3179 - val_accuracy: 0.3857

Epoch 00141: val_loss did not improve from 1.31647
Epoch 142/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3961 - val_loss: 1.3225 - val_accuracy: 0.3753

Epoch 00142: val_loss did not improve from 1.31647
Epoch 143/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3917 - val_loss: 1.3177 - val_accuracy: 0.3849

Epoch 00143: val_loss did not improve from 1.31647
Epoch 144/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3969 - val_loss: 1.3182 - val_accuracy: 0.3880

Epoch 00144: val_loss did not improve from 1.31647
Epoch 145/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3919 - val_loss: 1.3204 - val_accuracy: 0.3841

Epoch 00145: val_loss did not improve from 1.31647
Epoch 146/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3986 - val_loss: 1.3175 - val_accuracy: 0.3745

Epoch 00146: val_loss did not improve from 1.31647
Epoch 147/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3983 - val_loss: 1.3172 - val_accuracy: 0.3880

Epoch 00147: val_loss did not improve from 1.31647
Epoch 148/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3978 - val_loss: 1.3181 - val_accuracy: 0.3801

Epoch 00148: val_loss did not improve from 1.31647
Epoch 149/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3981 - val_loss: 1.3179 - val_accuracy: 0.3721

Epoch 00149: val_loss did not improve from 1.31647
Epoch 150/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3962 - val_loss: 1.3172 - val_accuracy: 0.3825

Epoch 00150: val_loss did not improve from 1.31647
Epoch 151/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3973 - val_loss: 1.3165 - val_accuracy: 0.3785

Epoch 00151: val_loss did not improve from 1.31647
Epoch 152/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3976 - val_loss: 1.3174 - val_accuracy: 0.3865

Epoch 00152: val_loss did not improve from 1.31647
Epoch 153/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3970 - val_loss: 1.3170 - val_accuracy: 0.3873

Epoch 00153: val_loss did not improve from 1.31647
Epoch 154/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3999 - val_loss: 1.3155 - val_accuracy: 0.3785

Epoch 00154: val_loss improved from 1.31647 to 1.31553, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 155/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3981 - val_loss: 1.3164 - val_accuracy: 0.3713

Epoch 00155: val_loss did not improve from 1.31553
Epoch 156/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3960 - val_loss: 1.3186 - val_accuracy: 0.3753

Epoch 00156: val_loss did not improve from 1.31553
Epoch 157/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3984 - val_loss: 1.3195 - val_accuracy: 0.3761

Epoch 00157: val_loss did not improve from 1.31553
Epoch 158/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3847 - val_loss: 1.3254 - val_accuracy: 0.3992

Epoch 00158: val_loss did not improve from 1.31553
Epoch 159/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3943 - val_loss: 1.3180 - val_accuracy: 0.3729

Epoch 00159: val_loss did not improve from 1.31553
Epoch 160/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3935 - val_loss: 1.3184 - val_accuracy: 0.3793

Epoch 00160: val_loss did not improve from 1.31553
Epoch 161/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3929 - val_loss: 1.3197 - val_accuracy: 0.3944

Epoch 00161: val_loss did not improve from 1.31553
Epoch 162/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3998 - val_loss: 1.3206 - val_accuracy: 0.3721

Epoch 00162: val_loss did not improve from 1.31553
Epoch 163/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3984 - val_loss: 1.3168 - val_accuracy: 0.3785

Epoch 00163: val_loss did not improve from 1.31553
Epoch 164/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3986 - val_loss: 1.3184 - val_accuracy: 0.3801

Epoch 00164: val_loss did not improve from 1.31553
Epoch 165/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3972 - val_loss: 1.3199 - val_accuracy: 0.3833

Epoch 00165: val_loss did not improve from 1.31553
Epoch 166/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.4018 - val_loss: 1.3187 - val_accuracy: 0.3777

Epoch 00166: val_loss did not improve from 1.31553
Epoch 167/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3978 - val_loss: 1.3162 - val_accuracy: 0.3729

Epoch 00167: val_loss did not improve from 1.31553
Epoch 168/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3957 - val_loss: 1.3162 - val_accuracy: 0.3721

Epoch 00168: val_loss did not improve from 1.31553
Epoch 169/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.4005 - val_loss: 1.3214 - val_accuracy: 0.3817

Epoch 00169: val_loss did not improve from 1.31553
Epoch 170/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3973 - val_loss: 1.3190 - val_accuracy: 0.3888

Epoch 00170: val_loss did not improve from 1.31553
Epoch 171/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3935 - val_loss: 1.3182 - val_accuracy: 0.3785

Epoch 00171: val_loss did not improve from 1.31553
Epoch 172/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3943 - val_loss: 1.3170 - val_accuracy: 0.3745

Epoch 00172: val_loss did not improve from 1.31553
Epoch 173/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3973 - val_loss: 1.3189 - val_accuracy: 0.3888

Epoch 00173: val_loss did not improve from 1.31553
Epoch 174/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3969 - val_loss: 1.3193 - val_accuracy: 0.3713

Epoch 00174: val_loss did not improve from 1.31553
Epoch 175/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3976 - val_loss: 1.3182 - val_accuracy: 0.3737

Epoch 00175: val_loss did not improve from 1.31553
Epoch 176/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3981 - val_loss: 1.3191 - val_accuracy: 0.3769

Epoch 00176: val_loss did not improve from 1.31553
Epoch 177/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3968 - val_loss: 1.3163 - val_accuracy: 0.3809

Epoch 00177: val_loss did not improve from 1.31553
Epoch 178/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3911 - val_loss: 1.3170 - val_accuracy: 0.3880

Epoch 00178: val_loss did not improve from 1.31553
Epoch 179/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3991 - val_loss: 1.3172 - val_accuracy: 0.3896

Epoch 00179: val_loss did not improve from 1.31553
Epoch 180/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.4004 - val_loss: 1.3187 - val_accuracy: 0.3896

Epoch 00180: val_loss did not improve from 1.31553
Epoch 181/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.4004 - val_loss: 1.3215 - val_accuracy: 0.3769

Epoch 00181: val_loss did not improve from 1.31553
Epoch 182/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3962 - val_loss: 1.3183 - val_accuracy: 0.3849

Epoch 00182: val_loss did not improve from 1.31553
Epoch 183/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.4002 - val_loss: 1.3168 - val_accuracy: 0.3793

Epoch 00183: val_loss did not improve from 1.31553
Epoch 184/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3983 - val_loss: 1.3232 - val_accuracy: 0.3769

Epoch 00184: val_loss did not improve from 1.31553
Epoch 185/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3954 - val_loss: 1.3180 - val_accuracy: 0.3912

Epoch 00185: val_loss did not improve from 1.31553
Epoch 186/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3989 - val_loss: 1.3169 - val_accuracy: 0.3745

Epoch 00186: val_loss did not improve from 1.31553
Epoch 187/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.4012 - val_loss: 1.3160 - val_accuracy: 0.3785

Epoch 00187: val_loss did not improve from 1.31553
Epoch 188/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3990 - val_loss: 1.3163 - val_accuracy: 0.3817

Epoch 00188: val_loss did not improve from 1.31553
Epoch 189/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3893 - val_loss: 1.3164 - val_accuracy: 0.3928

Epoch 00189: val_loss did not improve from 1.31553
Epoch 190/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3984 - val_loss: 1.3170 - val_accuracy: 0.3833

Epoch 00190: val_loss did not improve from 1.31553
Epoch 191/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3996 - val_loss: 1.3184 - val_accuracy: 0.3705

Epoch 00191: val_loss did not improve from 1.31553
Epoch 192/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3981 - val_loss: 1.3162 - val_accuracy: 0.3777

Epoch 00192: val_loss did not improve from 1.31553
Epoch 193/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3978 - val_loss: 1.3180 - val_accuracy: 0.3833

Epoch 00193: val_loss did not improve from 1.31553
Epoch 194/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.4030 - val_loss: 1.3173 - val_accuracy: 0.3888

Epoch 00194: val_loss did not improve from 1.31553
Epoch 195/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.4000 - val_loss: 1.3162 - val_accuracy: 0.3785

Epoch 00195: val_loss did not improve from 1.31553
Epoch 196/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3965 - val_loss: 1.3158 - val_accuracy: 0.3849

Epoch 00196: val_loss did not improve from 1.31553
Epoch 197/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.4004 - val_loss: 1.3156 - val_accuracy: 0.3857

Epoch 00197: val_loss did not improve from 1.31553
Epoch 198/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3979 - val_loss: 1.3195 - val_accuracy: 0.3777

Epoch 00198: val_loss did not improve from 1.31553
Epoch 199/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3993 - val_loss: 1.3158 - val_accuracy: 0.3920

Epoch 00199: val_loss did not improve from 1.31553
Epoch 200/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3930 - val_loss: 1.3154 - val_accuracy: 0.3880

Epoch 00200: val_loss improved from 1.31553 to 1.31537, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 201/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3926 - val_loss: 1.3159 - val_accuracy: 0.3952

Epoch 00201: val_loss did not improve from 1.31537
Epoch 202/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.4004 - val_loss: 1.3197 - val_accuracy: 0.3785

Epoch 00202: val_loss did not improve from 1.31537
Epoch 203/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3975 - val_loss: 1.3152 - val_accuracy: 0.3849

Epoch 00203: val_loss improved from 1.31537 to 1.31525, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 204/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3950 - val_loss: 1.3167 - val_accuracy: 0.3968

Epoch 00204: val_loss did not improve from 1.31525
Epoch 205/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.4022 - val_loss: 1.3202 - val_accuracy: 0.3817

Epoch 00205: val_loss did not improve from 1.31525
Epoch 206/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3989 - val_loss: 1.3144 - val_accuracy: 0.3865

Epoch 00206: val_loss improved from 1.31525 to 1.31441, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 207/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3981 - val_loss: 1.3137 - val_accuracy: 0.3865

Epoch 00207: val_loss improved from 1.31441 to 1.31369, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 208/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3964 - val_loss: 1.3156 - val_accuracy: 0.3880

Epoch 00208: val_loss did not improve from 1.31369
Epoch 209/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.4002 - val_loss: 1.3159 - val_accuracy: 0.4000

Epoch 00209: val_loss did not improve from 1.31369
Epoch 210/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3996 - val_loss: 1.3167 - val_accuracy: 0.3753

Epoch 00210: val_loss did not improve from 1.31369
Epoch 211/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3979 - val_loss: 1.3175 - val_accuracy: 0.3817

Epoch 00211: val_loss did not improve from 1.31369
Epoch 212/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.4011 - val_loss: 1.3150 - val_accuracy: 0.3928

Epoch 00212: val_loss did not improve from 1.31369
Epoch 213/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3984 - val_loss: 1.3160 - val_accuracy: 0.3825

Epoch 00213: val_loss did not improve from 1.31369
Epoch 214/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.4008 - val_loss: 1.3139 - val_accuracy: 0.3944

Epoch 00214: val_loss did not improve from 1.31369
Epoch 215/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3981 - val_loss: 1.3138 - val_accuracy: 0.3873

Epoch 00215: val_loss did not improve from 1.31369
Epoch 216/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3961 - val_loss: 1.3133 - val_accuracy: 0.3873

Epoch 00216: val_loss improved from 1.31369 to 1.31333, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 217/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.4000 - val_loss: 1.3139 - val_accuracy: 0.3777

Epoch 00217: val_loss did not improve from 1.31333
Epoch 218/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3945 - val_loss: 1.3148 - val_accuracy: 0.3825

Epoch 00218: val_loss did not improve from 1.31333
Epoch 219/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.4022 - val_loss: 1.3191 - val_accuracy: 0.3817

Epoch 00219: val_loss did not improve from 1.31333
Epoch 220/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3988 - val_loss: 1.3156 - val_accuracy: 0.3976

Epoch 00220: val_loss did not improve from 1.31333
Epoch 221/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3986 - val_loss: 1.3148 - val_accuracy: 0.3713

Epoch 00221: val_loss did not improve from 1.31333
Epoch 222/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.4004 - val_loss: 1.3140 - val_accuracy: 0.3801

Epoch 00222: val_loss did not improve from 1.31333
Epoch 223/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3961 - val_loss: 1.3139 - val_accuracy: 0.3817

Epoch 00223: val_loss did not improve from 1.31333
Epoch 224/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3996 - val_loss: 1.3148 - val_accuracy: 0.3817

Epoch 00224: val_loss did not improve from 1.31333
Epoch 225/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4005 - val_loss: 1.3136 - val_accuracy: 0.3960

Epoch 00225: val_loss did not improve from 1.31333
Epoch 226/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.4014 - val_loss: 1.3145 - val_accuracy: 0.3817

Epoch 00226: val_loss did not improve from 1.31333
Epoch 227/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.4005 - val_loss: 1.3144 - val_accuracy: 0.3952

Epoch 00227: val_loss did not improve from 1.31333
Epoch 228/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3954 - val_loss: 1.3124 - val_accuracy: 0.3912

Epoch 00228: val_loss improved from 1.31333 to 1.31236, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 229/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3990 - val_loss: 1.3122 - val_accuracy: 0.3880

Epoch 00229: val_loss improved from 1.31236 to 1.31220, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 230/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3985 - val_loss: 1.3125 - val_accuracy: 0.3912

Epoch 00230: val_loss did not improve from 1.31220
Epoch 231/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.4028 - val_loss: 1.3118 - val_accuracy: 0.4000

Epoch 00231: val_loss improved from 1.31220 to 1.31180, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 232/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3979 - val_loss: 1.3125 - val_accuracy: 0.3753

Epoch 00232: val_loss did not improve from 1.31180
Epoch 233/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3985 - val_loss: 1.3117 - val_accuracy: 0.3817

Epoch 00233: val_loss improved from 1.31180 to 1.31169, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 234/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3972 - val_loss: 1.3116 - val_accuracy: 0.3769

Epoch 00234: val_loss improved from 1.31169 to 1.31160, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 235/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3972 - val_loss: 1.3114 - val_accuracy: 0.3817

Epoch 00235: val_loss improved from 1.31160 to 1.31145, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 236/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3992 - val_loss: 1.3147 - val_accuracy: 0.3721

Epoch 00236: val_loss did not improve from 1.31145
Epoch 237/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3993 - val_loss: 1.3138 - val_accuracy: 0.3960

Epoch 00237: val_loss did not improve from 1.31145
Epoch 238/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3977 - val_loss: 1.3130 - val_accuracy: 0.3857

Epoch 00238: val_loss did not improve from 1.31145
Epoch 239/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.4002 - val_loss: 1.3156 - val_accuracy: 0.3785

Epoch 00239: val_loss did not improve from 1.31145
Epoch 240/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3990 - val_loss: 1.3134 - val_accuracy: 0.4040

Epoch 00240: val_loss did not improve from 1.31145
Epoch 241/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3944 - val_loss: 1.3128 - val_accuracy: 0.3888

Epoch 00241: val_loss did not improve from 1.31145
Epoch 242/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3981 - val_loss: 1.3119 - val_accuracy: 0.3817

Epoch 00242: val_loss did not improve from 1.31145
Epoch 243/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3981 - val_loss: 1.3125 - val_accuracy: 0.3928

Epoch 00243: val_loss did not improve from 1.31145
Epoch 244/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3990 - val_loss: 1.3125 - val_accuracy: 0.3793

Epoch 00244: val_loss did not improve from 1.31145
Epoch 245/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3994 - val_loss: 1.3126 - val_accuracy: 0.3912

Epoch 00245: val_loss did not improve from 1.31145
Epoch 246/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3997 - val_loss: 1.3130 - val_accuracy: 0.3777

Epoch 00246: val_loss did not improve from 1.31145
Epoch 247/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3963 - val_loss: 1.3125 - val_accuracy: 0.3873

Epoch 00247: val_loss did not improve from 1.31145
Epoch 248/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4003 - val_loss: 1.3118 - val_accuracy: 0.3984

Epoch 00248: val_loss did not improve from 1.31145
Epoch 249/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4012 - val_loss: 1.3116 - val_accuracy: 0.3880

Epoch 00249: val_loss did not improve from 1.31145
Epoch 250/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3995 - val_loss: 1.3130 - val_accuracy: 0.4056

Epoch 00250: val_loss did not improve from 1.31145
Epoch 251/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4034 - val_loss: 1.3143 - val_accuracy: 0.3753

Epoch 00251: val_loss did not improve from 1.31145
Epoch 252/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3970 - val_loss: 1.3102 - val_accuracy: 0.3833

Epoch 00252: val_loss improved from 1.31145 to 1.31017, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 253/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3977 - val_loss: 1.3119 - val_accuracy: 0.3825

Epoch 00253: val_loss did not improve from 1.31017
Epoch 254/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3999 - val_loss: 1.3108 - val_accuracy: 0.4000

Epoch 00254: val_loss did not improve from 1.31017
Epoch 255/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4034 - val_loss: 1.3163 - val_accuracy: 0.3793

Epoch 00255: val_loss did not improve from 1.31017
Epoch 256/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3966 - val_loss: 1.3173 - val_accuracy: 0.4032

Epoch 00256: val_loss did not improve from 1.31017
Epoch 257/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.4012 - val_loss: 1.3121 - val_accuracy: 0.3833

Epoch 00257: val_loss did not improve from 1.31017
Epoch 258/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3998 - val_loss: 1.3129 - val_accuracy: 0.3849

Epoch 00258: val_loss did not improve from 1.31017
Epoch 259/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3965 - val_loss: 1.3108 - val_accuracy: 0.3873

Epoch 00259: val_loss did not improve from 1.31017
Epoch 260/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3951 - val_loss: 1.3103 - val_accuracy: 0.3865

Epoch 00260: val_loss did not improve from 1.31017
Epoch 261/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3969 - val_loss: 1.3108 - val_accuracy: 0.3857

Epoch 00261: val_loss did not improve from 1.31017
Epoch 262/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3981 - val_loss: 1.3116 - val_accuracy: 0.3793

Epoch 00262: val_loss did not improve from 1.31017
Epoch 263/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3988 - val_loss: 1.3105 - val_accuracy: 0.3841

Epoch 00263: val_loss did not improve from 1.31017
Epoch 264/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3950 - val_loss: 1.3127 - val_accuracy: 0.4032

Epoch 00264: val_loss did not improve from 1.31017
Epoch 265/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.4043 - val_loss: 1.3107 - val_accuracy: 0.3880

Epoch 00265: val_loss did not improve from 1.31017
Epoch 266/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4021 - val_loss: 1.3115 - val_accuracy: 0.3888

Epoch 00266: val_loss did not improve from 1.31017
Epoch 267/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4006 - val_loss: 1.3114 - val_accuracy: 0.3833

Epoch 00267: val_loss did not improve from 1.31017
Epoch 268/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4012 - val_loss: 1.3130 - val_accuracy: 0.4040

Epoch 00268: val_loss did not improve from 1.31017
Epoch 269/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.4018 - val_loss: 1.3138 - val_accuracy: 0.3857

Epoch 00269: val_loss did not improve from 1.31017
Epoch 270/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3973 - val_loss: 1.3102 - val_accuracy: 0.3960

Epoch 00270: val_loss improved from 1.31017 to 1.31015, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 271/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4011 - val_loss: 1.3106 - val_accuracy: 0.3833

Epoch 00271: val_loss did not improve from 1.31015
Epoch 272/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3973 - val_loss: 1.3095 - val_accuracy: 0.3857

Epoch 00272: val_loss improved from 1.31015 to 1.30951, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 273/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3981 - val_loss: 1.3096 - val_accuracy: 0.3849

Epoch 00273: val_loss did not improve from 1.30951
Epoch 274/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3950 - val_loss: 1.3112 - val_accuracy: 0.4000

Epoch 00274: val_loss did not improve from 1.30951
Epoch 275/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.4019 - val_loss: 1.3124 - val_accuracy: 0.3873

Epoch 00275: val_loss did not improve from 1.30951
Epoch 276/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4038 - val_loss: 1.3108 - val_accuracy: 0.3873

Epoch 00276: val_loss did not improve from 1.30951
Epoch 277/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4009 - val_loss: 1.3099 - val_accuracy: 0.3841

Epoch 00277: val_loss did not improve from 1.30951
Epoch 278/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3998 - val_loss: 1.3097 - val_accuracy: 0.3880

Epoch 00278: val_loss did not improve from 1.30951
Epoch 279/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3981 - val_loss: 1.3104 - val_accuracy: 0.3833

Epoch 00279: val_loss did not improve from 1.30951
Epoch 280/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3986 - val_loss: 1.3101 - val_accuracy: 0.3849

Epoch 00280: val_loss did not improve from 1.30951
Epoch 281/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4004 - val_loss: 1.3096 - val_accuracy: 0.3960

Epoch 00281: val_loss did not improve from 1.30951
Epoch 282/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4019 - val_loss: 1.3093 - val_accuracy: 0.3896

Epoch 00282: val_loss improved from 1.30951 to 1.30926, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 283/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4044 - val_loss: 1.3102 - val_accuracy: 0.3928

Epoch 00283: val_loss did not improve from 1.30926
Epoch 284/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4021 - val_loss: 1.3104 - val_accuracy: 0.3880

Epoch 00284: val_loss did not improve from 1.30926
Epoch 285/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4027 - val_loss: 1.3095 - val_accuracy: 0.3976

Epoch 00285: val_loss did not improve from 1.30926
Epoch 286/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4010 - val_loss: 1.3126 - val_accuracy: 0.3777

Epoch 00286: val_loss did not improve from 1.30926
Epoch 287/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4029 - val_loss: 1.3146 - val_accuracy: 0.4088

Epoch 00287: val_loss did not improve from 1.30926
Epoch 288/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3993 - val_loss: 1.3116 - val_accuracy: 0.3809

Epoch 00288: val_loss did not improve from 1.30926
Epoch 289/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4015 - val_loss: 1.3105 - val_accuracy: 0.4040

Epoch 00289: val_loss did not improve from 1.30926
Epoch 290/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4030 - val_loss: 1.3129 - val_accuracy: 0.3713

Epoch 00290: val_loss did not improve from 1.30926
Epoch 291/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3957 - val_loss: 1.3102 - val_accuracy: 0.4080

Epoch 00291: val_loss did not improve from 1.30926
Epoch 292/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4064 - val_loss: 1.3095 - val_accuracy: 0.3984

Epoch 00292: val_loss did not improve from 1.30926
Epoch 293/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4004 - val_loss: 1.3130 - val_accuracy: 0.3873

Epoch 00293: val_loss did not improve from 1.30926
Epoch 294/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.4025 - val_loss: 1.3096 - val_accuracy: 0.4000

Epoch 00294: val_loss did not improve from 1.30926
Epoch 295/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4002 - val_loss: 1.3101 - val_accuracy: 0.3785

Epoch 00295: val_loss did not improve from 1.30926
Epoch 296/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3958 - val_loss: 1.3099 - val_accuracy: 0.3904

Epoch 00296: val_loss did not improve from 1.30926
Epoch 297/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.4012 - val_loss: 1.3129 - val_accuracy: 0.4080

Epoch 00297: val_loss did not improve from 1.30926
Epoch 298/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4010 - val_loss: 1.3108 - val_accuracy: 0.3904

Epoch 00298: val_loss did not improve from 1.30926
Epoch 299/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4034 - val_loss: 1.3092 - val_accuracy: 0.3920

Epoch 00299: val_loss improved from 1.30926 to 1.30921, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 300/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3993 - val_loss: 1.3096 - val_accuracy: 0.3928

Epoch 00300: val_loss did not improve from 1.30921
Epoch 301/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.4013 - val_loss: 1.3123 - val_accuracy: 0.3904

Epoch 00301: val_loss did not improve from 1.30921
Epoch 302/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.4043 - val_loss: 1.3104 - val_accuracy: 0.4048

Epoch 00302: val_loss did not improve from 1.30921
Epoch 303/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3993 - val_loss: 1.3094 - val_accuracy: 0.3857

Epoch 00303: val_loss did not improve from 1.30921
Epoch 304/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4013 - val_loss: 1.3097 - val_accuracy: 0.3944

Epoch 00304: val_loss did not improve from 1.30921
Epoch 305/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4023 - val_loss: 1.3088 - val_accuracy: 0.3936

Epoch 00305: val_loss improved from 1.30921 to 1.30882, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 306/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3985 - val_loss: 1.3093 - val_accuracy: 0.4008

Epoch 00306: val_loss did not improve from 1.30882
Epoch 307/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.4005 - val_loss: 1.3116 - val_accuracy: 0.3904

Epoch 00307: val_loss did not improve from 1.30882
Epoch 308/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4026 - val_loss: 1.3089 - val_accuracy: 0.3865

Epoch 00308: val_loss did not improve from 1.30882
Epoch 309/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4023 - val_loss: 1.3097 - val_accuracy: 0.3936

Epoch 00309: val_loss did not improve from 1.30882
Epoch 310/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4019 - val_loss: 1.3100 - val_accuracy: 0.3809

Epoch 00310: val_loss did not improve from 1.30882
Epoch 311/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3988 - val_loss: 1.3090 - val_accuracy: 0.4024

Epoch 00311: val_loss did not improve from 1.30882
Epoch 312/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4030 - val_loss: 1.3104 - val_accuracy: 0.3960

Epoch 00312: val_loss did not improve from 1.30882
Epoch 313/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4037 - val_loss: 1.3104 - val_accuracy: 0.4008

Epoch 00313: val_loss did not improve from 1.30882
Epoch 314/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4035 - val_loss: 1.3111 - val_accuracy: 0.3849

Epoch 00314: val_loss did not improve from 1.30882
Epoch 315/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4024 - val_loss: 1.3101 - val_accuracy: 0.4016

Epoch 00315: val_loss did not improve from 1.30882
Epoch 316/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3988 - val_loss: 1.3129 - val_accuracy: 0.3793

Epoch 00316: val_loss did not improve from 1.30882
Epoch 317/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.4012 - val_loss: 1.3112 - val_accuracy: 0.4008

Epoch 00317: val_loss did not improve from 1.30882
Epoch 318/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4004 - val_loss: 1.3101 - val_accuracy: 0.4024

Epoch 00318: val_loss did not improve from 1.30882
Epoch 319/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3997 - val_loss: 1.3091 - val_accuracy: 0.3833

Epoch 00319: val_loss did not improve from 1.30882
Epoch 320/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3992 - val_loss: 1.3102 - val_accuracy: 0.3896

Epoch 00320: val_loss did not improve from 1.30882
Epoch 321/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3976 - val_loss: 1.3097 - val_accuracy: 0.4048

Epoch 00321: val_loss did not improve from 1.30882
Epoch 322/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.4013 - val_loss: 1.3099 - val_accuracy: 0.3928

Epoch 00322: val_loss did not improve from 1.30882
Epoch 323/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4066 - val_loss: 1.3094 - val_accuracy: 0.3968

Epoch 00323: val_loss did not improve from 1.30882
Epoch 324/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3997 - val_loss: 1.3098 - val_accuracy: 0.3801

Epoch 00324: val_loss did not improve from 1.30882
Epoch 325/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4018 - val_loss: 1.3082 - val_accuracy: 0.3960

Epoch 00325: val_loss improved from 1.30882 to 1.30823, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 326/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3989 - val_loss: 1.3088 - val_accuracy: 0.3817

Epoch 00326: val_loss did not improve from 1.30823
Epoch 327/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3986 - val_loss: 1.3081 - val_accuracy: 0.3865

Epoch 00327: val_loss improved from 1.30823 to 1.30811, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 328/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4018 - val_loss: 1.3093 - val_accuracy: 0.3833

Epoch 00328: val_loss did not improve from 1.30811
Epoch 329/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4000 - val_loss: 1.3081 - val_accuracy: 0.3992

Epoch 00329: val_loss did not improve from 1.30811
Epoch 330/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4036 - val_loss: 1.3084 - val_accuracy: 0.4008

Epoch 00330: val_loss did not improve from 1.30811
Epoch 331/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4069 - val_loss: 1.3104 - val_accuracy: 0.3912

Epoch 00331: val_loss did not improve from 1.30811
Epoch 332/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3969 - val_loss: 1.3077 - val_accuracy: 0.4016

Epoch 00332: val_loss improved from 1.30811 to 1.30773, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 333/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4056 - val_loss: 1.3099 - val_accuracy: 0.3960

Epoch 00333: val_loss did not improve from 1.30773
Epoch 334/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4014 - val_loss: 1.3090 - val_accuracy: 0.3857

Epoch 00334: val_loss did not improve from 1.30773
Epoch 335/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4009 - val_loss: 1.3085 - val_accuracy: 0.3833

Epoch 00335: val_loss did not improve from 1.30773
Epoch 336/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4001 - val_loss: 1.3096 - val_accuracy: 0.3928

Epoch 00336: val_loss did not improve from 1.30773
Epoch 337/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4023 - val_loss: 1.3074 - val_accuracy: 0.3928

Epoch 00337: val_loss improved from 1.30773 to 1.30740, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 338/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4014 - val_loss: 1.3074 - val_accuracy: 0.3912

Epoch 00338: val_loss did not improve from 1.30740
Epoch 339/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4056 - val_loss: 1.3085 - val_accuracy: 0.3968

Epoch 00339: val_loss did not improve from 1.30740
Epoch 340/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3965 - val_loss: 1.3114 - val_accuracy: 0.4024

Epoch 00340: val_loss did not improve from 1.30740
Epoch 341/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4058 - val_loss: 1.3093 - val_accuracy: 0.3952

Epoch 00341: val_loss did not improve from 1.30740
Epoch 342/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4034 - val_loss: 1.3076 - val_accuracy: 0.3888

Epoch 00342: val_loss did not improve from 1.30740
Epoch 343/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4026 - val_loss: 1.3074 - val_accuracy: 0.3896

Epoch 00343: val_loss did not improve from 1.30740
Epoch 344/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4021 - val_loss: 1.3084 - val_accuracy: 0.3865

Epoch 00344: val_loss did not improve from 1.30740
Epoch 345/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4019 - val_loss: 1.3090 - val_accuracy: 0.3793

Epoch 00345: val_loss did not improve from 1.30740
Epoch 346/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3992 - val_loss: 1.3076 - val_accuracy: 0.4016

Epoch 00346: val_loss did not improve from 1.30740
Epoch 347/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3971 - val_loss: 1.3082 - val_accuracy: 0.3865

Epoch 00347: val_loss did not improve from 1.30740
Epoch 348/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3998 - val_loss: 1.3102 - val_accuracy: 0.3825

Epoch 00348: val_loss did not improve from 1.30740
Epoch 349/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3987 - val_loss: 1.3098 - val_accuracy: 0.4040

Epoch 00349: val_loss did not improve from 1.30740
Epoch 350/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4022 - val_loss: 1.3094 - val_accuracy: 0.3841

Epoch 00350: val_loss did not improve from 1.30740
Epoch 351/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4028 - val_loss: 1.3066 - val_accuracy: 0.3904

Epoch 00351: val_loss improved from 1.30740 to 1.30663, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 352/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4004 - val_loss: 1.3103 - val_accuracy: 0.4088

Epoch 00352: val_loss did not improve from 1.30663
Epoch 353/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4054 - val_loss: 1.3200 - val_accuracy: 0.3745

Epoch 00353: val_loss did not improve from 1.30663
Epoch 354/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3895 - val_loss: 1.3173 - val_accuracy: 0.4088

Epoch 00354: val_loss did not improve from 1.30663
Epoch 355/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4025 - val_loss: 1.3137 - val_accuracy: 0.3785

Epoch 00355: val_loss did not improve from 1.30663
Epoch 356/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3945 - val_loss: 1.3084 - val_accuracy: 0.4048

Epoch 00356: val_loss did not improve from 1.30663
Epoch 357/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4036 - val_loss: 1.3078 - val_accuracy: 0.3904

Epoch 00357: val_loss did not improve from 1.30663
Epoch 358/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3988 - val_loss: 1.3073 - val_accuracy: 0.3968

Epoch 00358: val_loss did not improve from 1.30663
Epoch 359/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4028 - val_loss: 1.3069 - val_accuracy: 0.3968

Epoch 00359: val_loss did not improve from 1.30663
Epoch 360/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4036 - val_loss: 1.3069 - val_accuracy: 0.4032

Epoch 00360: val_loss did not improve from 1.30663
Epoch 361/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4050 - val_loss: 1.3096 - val_accuracy: 0.3825

Epoch 00361: val_loss did not improve from 1.30663
Epoch 362/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3993 - val_loss: 1.3087 - val_accuracy: 0.4048

Epoch 00362: val_loss did not improve from 1.30663
Epoch 363/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4050 - val_loss: 1.3075 - val_accuracy: 0.3928

Epoch 00363: val_loss did not improve from 1.30663
Epoch 364/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4036 - val_loss: 1.3072 - val_accuracy: 0.3976

Epoch 00364: val_loss did not improve from 1.30663
Epoch 365/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4053 - val_loss: 1.3089 - val_accuracy: 0.4064

Epoch 00365: val_loss did not improve from 1.30663
Epoch 366/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4017 - val_loss: 1.3074 - val_accuracy: 0.3849

Epoch 00366: val_loss did not improve from 1.30663
Epoch 367/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4010 - val_loss: 1.3079 - val_accuracy: 0.3896

Epoch 00367: val_loss did not improve from 1.30663
Epoch 368/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4023 - val_loss: 1.3071 - val_accuracy: 0.3880

Epoch 00368: val_loss did not improve from 1.30663
Epoch 369/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4010 - val_loss: 1.3078 - val_accuracy: 0.4096

Epoch 00369: val_loss did not improve from 1.30663
Epoch 370/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4018 - val_loss: 1.3060 - val_accuracy: 0.3888

Epoch 00370: val_loss improved from 1.30663 to 1.30599, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 371/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4042 - val_loss: 1.3098 - val_accuracy: 0.3928

Epoch 00371: val_loss did not improve from 1.30599
Epoch 372/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4031 - val_loss: 1.3075 - val_accuracy: 0.4000

Epoch 00372: val_loss did not improve from 1.30599
Epoch 373/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3965 - val_loss: 1.3065 - val_accuracy: 0.3944

Epoch 00373: val_loss did not improve from 1.30599
Epoch 374/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4027 - val_loss: 1.3073 - val_accuracy: 0.3920

Epoch 00374: val_loss did not improve from 1.30599
Epoch 375/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4052 - val_loss: 1.3081 - val_accuracy: 0.3920

Epoch 00375: val_loss did not improve from 1.30599
Epoch 376/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4043 - val_loss: 1.3073 - val_accuracy: 0.3880

Epoch 00376: val_loss did not improve from 1.30599
Epoch 377/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4019 - val_loss: 1.3092 - val_accuracy: 0.4016

Epoch 00377: val_loss did not improve from 1.30599
Epoch 378/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4035 - val_loss: 1.3085 - val_accuracy: 0.3801

Epoch 00378: val_loss did not improve from 1.30599
Epoch 379/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3988 - val_loss: 1.3072 - val_accuracy: 0.3912

Epoch 00379: val_loss did not improve from 1.30599
Epoch 380/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4019 - val_loss: 1.3104 - val_accuracy: 0.4080

Epoch 00380: val_loss did not improve from 1.30599
Epoch 381/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4051 - val_loss: 1.3113 - val_accuracy: 0.3849

Epoch 00381: val_loss did not improve from 1.30599
Epoch 382/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4036 - val_loss: 1.3075 - val_accuracy: 0.3888

Epoch 00382: val_loss did not improve from 1.30599
Epoch 383/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4012 - val_loss: 1.3088 - val_accuracy: 0.4064

Epoch 00383: val_loss did not improve from 1.30599
Epoch 384/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4060 - val_loss: 1.3065 - val_accuracy: 0.3904

Epoch 00384: val_loss did not improve from 1.30599
Epoch 385/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4025 - val_loss: 1.3110 - val_accuracy: 0.3841

Epoch 00385: val_loss did not improve from 1.30599
Epoch 386/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4025 - val_loss: 1.3065 - val_accuracy: 0.4072

Epoch 00386: val_loss did not improve from 1.30599
Epoch 387/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.3981 - val_loss: 1.3070 - val_accuracy: 0.4016

Epoch 00387: val_loss did not improve from 1.30599
Epoch 388/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4021 - val_loss: 1.3119 - val_accuracy: 0.3769

Epoch 00388: val_loss did not improve from 1.30599
Epoch 389/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4008 - val_loss: 1.3072 - val_accuracy: 0.4048

Epoch 00389: val_loss did not improve from 1.30599
Epoch 390/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4066 - val_loss: 1.3110 - val_accuracy: 0.4064

Epoch 00390: val_loss did not improve from 1.30599
Epoch 391/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.4043 - val_loss: 1.3196 - val_accuracy: 0.3817

Epoch 00391: val_loss did not improve from 1.30599
Epoch 392/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3958 - val_loss: 1.3109 - val_accuracy: 0.4072

Epoch 00392: val_loss did not improve from 1.30599
Epoch 393/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4035 - val_loss: 1.3082 - val_accuracy: 0.3952

Epoch 00393: val_loss did not improve from 1.30599
Epoch 394/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4043 - val_loss: 1.3066 - val_accuracy: 0.4080

Epoch 00394: val_loss did not improve from 1.30599
Epoch 395/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4019 - val_loss: 1.3067 - val_accuracy: 0.4064

Epoch 00395: val_loss did not improve from 1.30599
Epoch 396/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4067 - val_loss: 1.3062 - val_accuracy: 0.3896

Epoch 00396: val_loss did not improve from 1.30599
Epoch 397/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4028 - val_loss: 1.3054 - val_accuracy: 0.3944

Epoch 00397: val_loss improved from 1.30599 to 1.30536, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 398/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4016 - val_loss: 1.3053 - val_accuracy: 0.3912

Epoch 00398: val_loss improved from 1.30536 to 1.30528, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 399/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4023 - val_loss: 1.3055 - val_accuracy: 0.3873

Epoch 00399: val_loss did not improve from 1.30528
Epoch 400/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4012 - val_loss: 1.3091 - val_accuracy: 0.4008

Epoch 00400: val_loss did not improve from 1.30528
Epoch 401/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4018 - val_loss: 1.3087 - val_accuracy: 0.3904

Epoch 00401: val_loss did not improve from 1.30528
Epoch 402/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4027 - val_loss: 1.3067 - val_accuracy: 0.3960

Epoch 00402: val_loss did not improve from 1.30528
Epoch 403/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4027 - val_loss: 1.3060 - val_accuracy: 0.3984

Epoch 00403: val_loss did not improve from 1.30528
Epoch 404/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4057 - val_loss: 1.3060 - val_accuracy: 0.3873

Epoch 00404: val_loss did not improve from 1.30528
Epoch 405/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4023 - val_loss: 1.3060 - val_accuracy: 0.3968

Epoch 00405: val_loss did not improve from 1.30528
Epoch 406/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4040 - val_loss: 1.3058 - val_accuracy: 0.4008

Epoch 00406: val_loss did not improve from 1.30528
Epoch 407/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4052 - val_loss: 1.3080 - val_accuracy: 0.3857

Epoch 00407: val_loss did not improve from 1.30528
Epoch 408/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3996 - val_loss: 1.3055 - val_accuracy: 0.4064

Epoch 00408: val_loss did not improve from 1.30528
Epoch 409/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4012 - val_loss: 1.3047 - val_accuracy: 0.3920

Epoch 00409: val_loss improved from 1.30528 to 1.30474, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 410/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4050 - val_loss: 1.3043 - val_accuracy: 0.3857

Epoch 00410: val_loss improved from 1.30474 to 1.30429, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 411/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4030 - val_loss: 1.3068 - val_accuracy: 0.4040

Epoch 00411: val_loss did not improve from 1.30429
Epoch 412/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4018 - val_loss: 1.3070 - val_accuracy: 0.3904

Epoch 00412: val_loss did not improve from 1.30429
Epoch 413/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4064 - val_loss: 1.3038 - val_accuracy: 0.3976

Epoch 00413: val_loss improved from 1.30429 to 1.30377, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 414/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4030 - val_loss: 1.3042 - val_accuracy: 0.4048

Epoch 00414: val_loss did not improve from 1.30377
Epoch 415/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4037 - val_loss: 1.3059 - val_accuracy: 0.3880

Epoch 00415: val_loss did not improve from 1.30377
Epoch 416/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4027 - val_loss: 1.3073 - val_accuracy: 0.3992

Epoch 00416: val_loss did not improve from 1.30377
Epoch 417/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4069 - val_loss: 1.3048 - val_accuracy: 0.3944

Epoch 00417: val_loss did not improve from 1.30377
Epoch 418/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4038 - val_loss: 1.3073 - val_accuracy: 0.3896

Epoch 00418: val_loss did not improve from 1.30377
Epoch 419/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4050 - val_loss: 1.3064 - val_accuracy: 0.4040

Epoch 00419: val_loss did not improve from 1.30377
Epoch 420/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4065 - val_loss: 1.3055 - val_accuracy: 0.3880

Epoch 00420: val_loss did not improve from 1.30377
Epoch 421/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4066 - val_loss: 1.3041 - val_accuracy: 0.4032

Epoch 00421: val_loss did not improve from 1.30377
Epoch 422/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4043 - val_loss: 1.3048 - val_accuracy: 0.4000

Epoch 00422: val_loss did not improve from 1.30377
Epoch 423/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4040 - val_loss: 1.3047 - val_accuracy: 0.3920

Epoch 00423: val_loss did not improve from 1.30377
Epoch 424/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4082 - val_loss: 1.3054 - val_accuracy: 0.3960

Epoch 00424: val_loss did not improve from 1.30377
Epoch 425/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4094 - val_loss: 1.3062 - val_accuracy: 0.3928

Epoch 00425: val_loss did not improve from 1.30377
Epoch 426/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4044 - val_loss: 1.3047 - val_accuracy: 0.3976

Epoch 00426: val_loss did not improve from 1.30377
Epoch 427/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4023 - val_loss: 1.3038 - val_accuracy: 0.3849

Epoch 00427: val_loss did not improve from 1.30377
Epoch 428/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4041 - val_loss: 1.3036 - val_accuracy: 0.3992

Epoch 00428: val_loss improved from 1.30377 to 1.30365, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 429/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4053 - val_loss: 1.3044 - val_accuracy: 0.3968

Epoch 00429: val_loss did not improve from 1.30365
Epoch 430/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4059 - val_loss: 1.3038 - val_accuracy: 0.3920

Epoch 00430: val_loss did not improve from 1.30365
Epoch 431/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4014 - val_loss: 1.3040 - val_accuracy: 0.4008

Epoch 00431: val_loss did not improve from 1.30365
Epoch 432/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4069 - val_loss: 1.3042 - val_accuracy: 0.4000

Epoch 00432: val_loss did not improve from 1.30365
Epoch 433/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4079 - val_loss: 1.3032 - val_accuracy: 0.3960

Epoch 00433: val_loss improved from 1.30365 to 1.30315, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 434/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4078 - val_loss: 1.3021 - val_accuracy: 0.4008

Epoch 00434: val_loss improved from 1.30315 to 1.30213, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 435/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4005 - val_loss: 1.3026 - val_accuracy: 0.3976

Epoch 00435: val_loss did not improve from 1.30213
Epoch 436/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4076 - val_loss: 1.3031 - val_accuracy: 0.3944

Epoch 00436: val_loss did not improve from 1.30213
Epoch 437/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4079 - val_loss: 1.3021 - val_accuracy: 0.3920

Epoch 00437: val_loss improved from 1.30213 to 1.30205, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 438/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4062 - val_loss: 1.3035 - val_accuracy: 0.3912

Epoch 00438: val_loss did not improve from 1.30205
Epoch 439/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4033 - val_loss: 1.3038 - val_accuracy: 0.3888

Epoch 00439: val_loss did not improve from 1.30205
Epoch 440/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4040 - val_loss: 1.3052 - val_accuracy: 0.3960

Epoch 00440: val_loss did not improve from 1.30205
Epoch 441/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4113 - val_loss: 1.3049 - val_accuracy: 0.4080

Epoch 00441: val_loss did not improve from 1.30205
Epoch 442/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4036 - val_loss: 1.3042 - val_accuracy: 0.3952

Epoch 00442: val_loss did not improve from 1.30205
Epoch 443/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4066 - val_loss: 1.3034 - val_accuracy: 0.3976

Epoch 00443: val_loss did not improve from 1.30205
Epoch 444/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4077 - val_loss: 1.3060 - val_accuracy: 0.3785

Epoch 00444: val_loss did not improve from 1.30205
Epoch 445/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4032 - val_loss: 1.3020 - val_accuracy: 0.4048

Epoch 00445: val_loss improved from 1.30205 to 1.30204, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 446/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4097 - val_loss: 1.3035 - val_accuracy: 0.3880

Epoch 00446: val_loss did not improve from 1.30204
Epoch 447/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4019 - val_loss: 1.3028 - val_accuracy: 0.4096

Epoch 00447: val_loss did not improve from 1.30204
Epoch 448/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4064 - val_loss: 1.3029 - val_accuracy: 0.3992

Epoch 00448: val_loss did not improve from 1.30204
Epoch 449/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4035 - val_loss: 1.3037 - val_accuracy: 0.3793

Epoch 00449: val_loss did not improve from 1.30204
Epoch 450/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4030 - val_loss: 1.3066 - val_accuracy: 0.4064

Epoch 00450: val_loss did not improve from 1.30204
Epoch 451/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4100 - val_loss: 1.3028 - val_accuracy: 0.3952

Epoch 00451: val_loss did not improve from 1.30204
Epoch 452/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4079 - val_loss: 1.3021 - val_accuracy: 0.3984

Epoch 00452: val_loss did not improve from 1.30204
Epoch 453/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4089 - val_loss: 1.3024 - val_accuracy: 0.3968

Epoch 00453: val_loss did not improve from 1.30204
Epoch 454/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4076 - val_loss: 1.3012 - val_accuracy: 0.4008

Epoch 00454: val_loss improved from 1.30204 to 1.30123, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 455/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4097 - val_loss: 1.3010 - val_accuracy: 0.3976

Epoch 00455: val_loss improved from 1.30123 to 1.30096, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 456/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4047 - val_loss: 1.3038 - val_accuracy: 0.3968

Epoch 00456: val_loss did not improve from 1.30096
Epoch 457/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4043 - val_loss: 1.3033 - val_accuracy: 0.3928

Epoch 00457: val_loss did not improve from 1.30096
Epoch 458/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4020 - val_loss: 1.3036 - val_accuracy: 0.4096

Epoch 00458: val_loss did not improve from 1.30096
Epoch 459/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4087 - val_loss: 1.3031 - val_accuracy: 0.3960

Epoch 00459: val_loss did not improve from 1.30096
Epoch 460/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4072 - val_loss: 1.3017 - val_accuracy: 0.4048

Epoch 00460: val_loss did not improve from 1.30096
Epoch 461/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4089 - val_loss: 1.3026 - val_accuracy: 0.3952

Epoch 00461: val_loss did not improve from 1.30096
Epoch 462/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4105 - val_loss: 1.3010 - val_accuracy: 0.3952

Epoch 00462: val_loss did not improve from 1.30096
Epoch 463/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4083 - val_loss: 1.3023 - val_accuracy: 0.3928

Epoch 00463: val_loss did not improve from 1.30096
Epoch 464/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4011 - val_loss: 1.3099 - val_accuracy: 0.4024

Epoch 00464: val_loss did not improve from 1.30096
Epoch 465/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4045 - val_loss: 1.3126 - val_accuracy: 0.3769

Epoch 00465: val_loss did not improve from 1.30096
Epoch 466/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3989 - val_loss: 1.3028 - val_accuracy: 0.4056

Epoch 00466: val_loss did not improve from 1.30096
Epoch 467/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4027 - val_loss: 1.3016 - val_accuracy: 0.3976

Epoch 00467: val_loss did not improve from 1.30096
Epoch 468/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4092 - val_loss: 1.3013 - val_accuracy: 0.4088

Epoch 00468: val_loss did not improve from 1.30096
Epoch 469/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4088 - val_loss: 1.3014 - val_accuracy: 0.3873

Epoch 00469: val_loss did not improve from 1.30096
Epoch 470/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4100 - val_loss: 1.3022 - val_accuracy: 0.3944

Epoch 00470: val_loss did not improve from 1.30096
Epoch 471/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4061 - val_loss: 1.3022 - val_accuracy: 0.4008

Epoch 00471: val_loss did not improve from 1.30096
Epoch 472/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4053 - val_loss: 1.3026 - val_accuracy: 0.3904

Epoch 00472: val_loss did not improve from 1.30096
Epoch 473/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4074 - val_loss: 1.3022 - val_accuracy: 0.4008

Epoch 00473: val_loss did not improve from 1.30096
Epoch 474/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4041 - val_loss: 1.3026 - val_accuracy: 0.3857

Epoch 00474: val_loss did not improve from 1.30096
Epoch 475/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4063 - val_loss: 1.3021 - val_accuracy: 0.3960

Epoch 00475: val_loss did not improve from 1.30096
Epoch 476/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4072 - val_loss: 1.3009 - val_accuracy: 0.4032

Epoch 00476: val_loss improved from 1.30096 to 1.30093, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 477/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4061 - val_loss: 1.3058 - val_accuracy: 0.3896

Epoch 00477: val_loss did not improve from 1.30093
Epoch 478/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4058 - val_loss: 1.3046 - val_accuracy: 0.4040

Epoch 00478: val_loss did not improve from 1.30093
Epoch 479/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4074 - val_loss: 1.3021 - val_accuracy: 0.3865

Epoch 00479: val_loss did not improve from 1.30093
Epoch 480/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4063 - val_loss: 1.3011 - val_accuracy: 0.4032

Epoch 00480: val_loss did not improve from 1.30093
Epoch 481/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4048 - val_loss: 1.3010 - val_accuracy: 0.4000

Epoch 00481: val_loss did not improve from 1.30093
Epoch 482/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4084 - val_loss: 1.3027 - val_accuracy: 0.4008

Epoch 00482: val_loss did not improve from 1.30093
Epoch 483/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4061 - val_loss: 1.3031 - val_accuracy: 0.3912

Epoch 00483: val_loss did not improve from 1.30093
Epoch 484/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4082 - val_loss: 1.3033 - val_accuracy: 0.3841

Epoch 00484: val_loss did not improve from 1.30093
Epoch 485/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3988 - val_loss: 1.3053 - val_accuracy: 0.4048

Epoch 00485: val_loss did not improve from 1.30093
Epoch 486/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4048 - val_loss: 1.3016 - val_accuracy: 0.3873

Epoch 00486: val_loss did not improve from 1.30093
Epoch 487/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4078 - val_loss: 1.3014 - val_accuracy: 0.3936

Epoch 00487: val_loss did not improve from 1.30093
Epoch 488/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4082 - val_loss: 1.3012 - val_accuracy: 0.3968

Epoch 00488: val_loss did not improve from 1.30093
Epoch 489/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4041 - val_loss: 1.3036 - val_accuracy: 0.3928

Epoch 00489: val_loss did not improve from 1.30093
Epoch 490/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4077 - val_loss: 1.3028 - val_accuracy: 0.3952

Epoch 00490: val_loss did not improve from 1.30093
Epoch 491/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4064 - val_loss: 1.3010 - val_accuracy: 0.3904

Epoch 00491: val_loss did not improve from 1.30093
Epoch 492/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4071 - val_loss: 1.3007 - val_accuracy: 0.3936

Epoch 00492: val_loss improved from 1.30093 to 1.30070, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 493/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4064 - val_loss: 1.3008 - val_accuracy: 0.4064

Epoch 00493: val_loss did not improve from 1.30070
Epoch 494/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4105 - val_loss: 1.3008 - val_accuracy: 0.4024

Epoch 00494: val_loss did not improve from 1.30070
Epoch 495/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4097 - val_loss: 1.3031 - val_accuracy: 0.3944

Epoch 00495: val_loss did not improve from 1.30070
Epoch 496/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4027 - val_loss: 1.3024 - val_accuracy: 0.4040

Epoch 00496: val_loss did not improve from 1.30070
Epoch 497/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4119 - val_loss: 1.3020 - val_accuracy: 0.3888

Epoch 00497: val_loss did not improve from 1.30070
Epoch 498/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4042 - val_loss: 1.3021 - val_accuracy: 0.4088

Epoch 00498: val_loss did not improve from 1.30070
Epoch 499/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4101 - val_loss: 1.2998 - val_accuracy: 0.3928

Epoch 00499: val_loss improved from 1.30070 to 1.29982, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 500/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4067 - val_loss: 1.3014 - val_accuracy: 0.3984

Epoch 00500: val_loss did not improve from 1.29982
Epoch 501/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4081 - val_loss: 1.3023 - val_accuracy: 0.3920

Epoch 00501: val_loss did not improve from 1.29982
Epoch 502/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4058 - val_loss: 1.3016 - val_accuracy: 0.4016

Epoch 00502: val_loss did not improve from 1.29982
Epoch 503/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4070 - val_loss: 1.3033 - val_accuracy: 0.3873

Epoch 00503: val_loss did not improve from 1.29982
Epoch 504/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4053 - val_loss: 1.3033 - val_accuracy: 0.4008

Epoch 00504: val_loss did not improve from 1.29982
Epoch 505/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4074 - val_loss: 1.3034 - val_accuracy: 0.3888

Epoch 00505: val_loss did not improve from 1.29982
Epoch 506/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4072 - val_loss: 1.3008 - val_accuracy: 0.3984

Epoch 00506: val_loss did not improve from 1.29982
Epoch 507/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4062 - val_loss: 1.3030 - val_accuracy: 0.4040

Epoch 00507: val_loss did not improve from 1.29982
Epoch 508/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4045 - val_loss: 1.3022 - val_accuracy: 0.3896

Epoch 00508: val_loss did not improve from 1.29982
Epoch 509/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4095 - val_loss: 1.2996 - val_accuracy: 0.4000

Epoch 00509: val_loss improved from 1.29982 to 1.29961, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 510/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4116 - val_loss: 1.3028 - val_accuracy: 0.3912

Epoch 00510: val_loss did not improve from 1.29961
Epoch 511/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4002 - val_loss: 1.3018 - val_accuracy: 0.4040

Epoch 00511: val_loss did not improve from 1.29961
Epoch 512/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4089 - val_loss: 1.3000 - val_accuracy: 0.3968

Epoch 00512: val_loss did not improve from 1.29961
Epoch 513/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4083 - val_loss: 1.3053 - val_accuracy: 0.3833

Epoch 00513: val_loss did not improve from 1.29961
Epoch 514/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4074 - val_loss: 1.3013 - val_accuracy: 0.4064

Epoch 00514: val_loss did not improve from 1.29961
Epoch 515/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4058 - val_loss: 1.2986 - val_accuracy: 0.3936

Epoch 00515: val_loss improved from 1.29961 to 1.29860, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 516/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4120 - val_loss: 1.2993 - val_accuracy: 0.3936

Epoch 00516: val_loss did not improve from 1.29860
Epoch 517/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4047 - val_loss: 1.3035 - val_accuracy: 0.4127

Epoch 00517: val_loss did not improve from 1.29860
Epoch 518/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4035 - val_loss: 1.3005 - val_accuracy: 0.3936

Epoch 00518: val_loss did not improve from 1.29860
Epoch 519/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4110 - val_loss: 1.3005 - val_accuracy: 0.3984

Epoch 00519: val_loss did not improve from 1.29860
Epoch 520/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4074 - val_loss: 1.3011 - val_accuracy: 0.4080

Epoch 00520: val_loss did not improve from 1.29860
Epoch 521/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4076 - val_loss: 1.2992 - val_accuracy: 0.3984

Epoch 00521: val_loss did not improve from 1.29860
Epoch 522/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4115 - val_loss: 1.2985 - val_accuracy: 0.3936

Epoch 00522: val_loss improved from 1.29860 to 1.29849, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 523/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4099 - val_loss: 1.2991 - val_accuracy: 0.3952

Epoch 00523: val_loss did not improve from 1.29849
Epoch 524/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4103 - val_loss: 1.2987 - val_accuracy: 0.4024

Epoch 00524: val_loss did not improve from 1.29849
Epoch 525/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4085 - val_loss: 1.3007 - val_accuracy: 0.4080

Epoch 00525: val_loss did not improve from 1.29849
Epoch 526/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4098 - val_loss: 1.3014 - val_accuracy: 0.3944

Epoch 00526: val_loss did not improve from 1.29849
Epoch 527/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4114 - val_loss: 1.3002 - val_accuracy: 0.3896

Epoch 00527: val_loss did not improve from 1.29849
Epoch 528/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.3965 - val_loss: 1.2996 - val_accuracy: 0.4000

Epoch 00528: val_loss did not improve from 1.29849
Epoch 529/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4105 - val_loss: 1.3011 - val_accuracy: 0.4072

Epoch 00529: val_loss did not improve from 1.29849
Epoch 530/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4095 - val_loss: 1.3007 - val_accuracy: 0.4040

Epoch 00530: val_loss did not improve from 1.29849
Epoch 531/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4110 - val_loss: 1.2982 - val_accuracy: 0.4016

Epoch 00531: val_loss improved from 1.29849 to 1.29822, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 532/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4085 - val_loss: 1.2983 - val_accuracy: 0.4008

Epoch 00532: val_loss did not improve from 1.29822
Epoch 533/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4042 - val_loss: 1.2994 - val_accuracy: 0.4104

Epoch 00533: val_loss did not improve from 1.29822
Epoch 534/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4076 - val_loss: 1.2986 - val_accuracy: 0.4080

Epoch 00534: val_loss did not improve from 1.29822
Epoch 535/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4097 - val_loss: 1.2999 - val_accuracy: 0.3984

Epoch 00535: val_loss did not improve from 1.29822
Epoch 536/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4131 - val_loss: 1.2991 - val_accuracy: 0.4032

Epoch 00536: val_loss did not improve from 1.29822
Epoch 537/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4090 - val_loss: 1.3002 - val_accuracy: 0.3992

Epoch 00537: val_loss did not improve from 1.29822
Epoch 538/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4104 - val_loss: 1.2995 - val_accuracy: 0.3944

Epoch 00538: val_loss did not improve from 1.29822
Epoch 539/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4106 - val_loss: 1.2984 - val_accuracy: 0.3968

Epoch 00539: val_loss did not improve from 1.29822
Epoch 540/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4068 - val_loss: 1.3010 - val_accuracy: 0.4056

Epoch 00540: val_loss did not improve from 1.29822
Epoch 541/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4110 - val_loss: 1.2982 - val_accuracy: 0.3944

Epoch 00541: val_loss improved from 1.29822 to 1.29820, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 542/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4107 - val_loss: 1.2995 - val_accuracy: 0.3928

Epoch 00542: val_loss did not improve from 1.29820
Epoch 543/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4112 - val_loss: 1.2987 - val_accuracy: 0.3960

Epoch 00543: val_loss did not improve from 1.29820
Epoch 544/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4078 - val_loss: 1.2981 - val_accuracy: 0.4072

Epoch 00544: val_loss improved from 1.29820 to 1.29807, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 545/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4061 - val_loss: 1.2976 - val_accuracy: 0.4080

Epoch 00545: val_loss improved from 1.29807 to 1.29760, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 546/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4149 - val_loss: 1.2980 - val_accuracy: 0.3992

Epoch 00546: val_loss did not improve from 1.29760
Epoch 547/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4110 - val_loss: 1.2987 - val_accuracy: 0.4072

Epoch 00547: val_loss did not improve from 1.29760
Epoch 548/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4092 - val_loss: 1.2976 - val_accuracy: 0.4008

Epoch 00548: val_loss improved from 1.29760 to 1.29755, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 549/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4112 - val_loss: 1.2983 - val_accuracy: 0.4000

Epoch 00549: val_loss did not improve from 1.29755
Epoch 550/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4151 - val_loss: 1.2975 - val_accuracy: 0.4016

Epoch 00550: val_loss improved from 1.29755 to 1.29749, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 551/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4084 - val_loss: 1.2971 - val_accuracy: 0.4040

Epoch 00551: val_loss improved from 1.29749 to 1.29706, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 552/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4114 - val_loss: 1.2985 - val_accuracy: 0.4151

Epoch 00552: val_loss did not improve from 1.29706
Epoch 553/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4092 - val_loss: 1.2991 - val_accuracy: 0.4000

Epoch 00553: val_loss did not improve from 1.29706
Epoch 554/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4089 - val_loss: 1.2981 - val_accuracy: 0.3976

Epoch 00554: val_loss did not improve from 1.29706
Epoch 555/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4110 - val_loss: 1.2983 - val_accuracy: 0.4040

Epoch 00555: val_loss did not improve from 1.29706
Epoch 556/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4090 - val_loss: 1.2993 - val_accuracy: 0.4127

Epoch 00556: val_loss did not improve from 1.29706
Epoch 557/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4097 - val_loss: 1.3005 - val_accuracy: 0.4008

Epoch 00557: val_loss did not improve from 1.29706
Epoch 558/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4027 - val_loss: 1.2989 - val_accuracy: 0.4120

Epoch 00558: val_loss did not improve from 1.29706
Epoch 559/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4107 - val_loss: 1.2967 - val_accuracy: 0.4040

Epoch 00559: val_loss improved from 1.29706 to 1.29673, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 560/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4105 - val_loss: 1.2991 - val_accuracy: 0.3888

Epoch 00560: val_loss did not improve from 1.29673
Epoch 561/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4118 - val_loss: 1.2999 - val_accuracy: 0.3968

Epoch 00561: val_loss did not improve from 1.29673
Epoch 562/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4112 - val_loss: 1.2972 - val_accuracy: 0.3960

Epoch 00562: val_loss did not improve from 1.29673
Epoch 563/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4094 - val_loss: 1.2953 - val_accuracy: 0.4016

Epoch 00563: val_loss improved from 1.29673 to 1.29530, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 564/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4091 - val_loss: 1.2972 - val_accuracy: 0.4024

Epoch 00564: val_loss did not improve from 1.29530
Epoch 565/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4092 - val_loss: 1.2973 - val_accuracy: 0.3960

Epoch 00565: val_loss did not improve from 1.29530
Epoch 566/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4098 - val_loss: 1.3017 - val_accuracy: 0.4024

Epoch 00566: val_loss did not improve from 1.29530
Epoch 567/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4081 - val_loss: 1.2996 - val_accuracy: 0.3928

Epoch 00567: val_loss did not improve from 1.29530
Epoch 568/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4110 - val_loss: 1.2963 - val_accuracy: 0.3984

Epoch 00568: val_loss did not improve from 1.29530
Epoch 569/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4093 - val_loss: 1.2981 - val_accuracy: 0.4120

Epoch 00569: val_loss did not improve from 1.29530
Epoch 570/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4121 - val_loss: 1.2964 - val_accuracy: 0.4032

Epoch 00570: val_loss did not improve from 1.29530
Epoch 571/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4106 - val_loss: 1.2984 - val_accuracy: 0.3984

Epoch 00571: val_loss did not improve from 1.29530
Epoch 572/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4114 - val_loss: 1.2990 - val_accuracy: 0.4104

Epoch 00572: val_loss did not improve from 1.29530
Epoch 573/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4061 - val_loss: 1.2975 - val_accuracy: 0.3928

Epoch 00573: val_loss did not improve from 1.29530
Epoch 574/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4112 - val_loss: 1.2978 - val_accuracy: 0.3952

Epoch 00574: val_loss did not improve from 1.29530
Epoch 575/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4055 - val_loss: 1.2977 - val_accuracy: 0.4056

Epoch 00575: val_loss did not improve from 1.29530
Epoch 576/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4108 - val_loss: 1.2967 - val_accuracy: 0.4112

Epoch 00576: val_loss did not improve from 1.29530
Epoch 577/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4130 - val_loss: 1.2945 - val_accuracy: 0.4064

Epoch 00577: val_loss improved from 1.29530 to 1.29452, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 578/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4112 - val_loss: 1.2963 - val_accuracy: 0.3984

Epoch 00578: val_loss did not improve from 1.29452
Epoch 579/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4072 - val_loss: 1.2957 - val_accuracy: 0.4104

Epoch 00579: val_loss did not improve from 1.29452
Epoch 580/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4032 - val_loss: 1.2961 - val_accuracy: 0.4056

Epoch 00580: val_loss did not improve from 1.29452
Epoch 581/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4148 - val_loss: 1.2951 - val_accuracy: 0.4016

Epoch 00581: val_loss did not improve from 1.29452
Epoch 582/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4092 - val_loss: 1.2948 - val_accuracy: 0.4096

Epoch 00582: val_loss did not improve from 1.29452
Epoch 583/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4135 - val_loss: 1.2959 - val_accuracy: 0.3992

Epoch 00583: val_loss did not improve from 1.29452
Epoch 584/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4109 - val_loss: 1.2957 - val_accuracy: 0.3992

Epoch 00584: val_loss did not improve from 1.29452
Epoch 585/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4092 - val_loss: 1.2978 - val_accuracy: 0.4127

Epoch 00585: val_loss did not improve from 1.29452
Epoch 586/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4139 - val_loss: 1.2976 - val_accuracy: 0.4024

Epoch 00586: val_loss did not improve from 1.29452
Epoch 587/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4042 - val_loss: 1.3016 - val_accuracy: 0.4072

Epoch 00587: val_loss did not improve from 1.29452
Epoch 588/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4119 - val_loss: 1.2954 - val_accuracy: 0.3984

Epoch 00588: val_loss did not improve from 1.29452
Epoch 589/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4129 - val_loss: 1.2975 - val_accuracy: 0.3952

Epoch 00589: val_loss did not improve from 1.29452
Epoch 590/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4100 - val_loss: 1.2967 - val_accuracy: 0.4104

Epoch 00590: val_loss did not improve from 1.29452
Epoch 591/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4140 - val_loss: 1.2950 - val_accuracy: 0.4080

Epoch 00591: val_loss did not improve from 1.29452
Epoch 592/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4136 - val_loss: 1.2951 - val_accuracy: 0.4024

Epoch 00592: val_loss did not improve from 1.29452
Epoch 593/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4147 - val_loss: 1.2950 - val_accuracy: 0.4032

Epoch 00593: val_loss did not improve from 1.29452
Epoch 594/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4135 - val_loss: 1.2963 - val_accuracy: 0.4223

Epoch 00594: val_loss did not improve from 1.29452
Epoch 595/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4159 - val_loss: 1.2954 - val_accuracy: 0.4056

Epoch 00595: val_loss did not improve from 1.29452
Epoch 596/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4083 - val_loss: 1.2985 - val_accuracy: 0.4104

Epoch 00596: val_loss did not improve from 1.29452
Epoch 597/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4101 - val_loss: 1.2958 - val_accuracy: 0.3976

Epoch 00597: val_loss did not improve from 1.29452
Epoch 598/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4033 - val_loss: 1.2938 - val_accuracy: 0.4127

Epoch 00598: val_loss improved from 1.29452 to 1.29376, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 599/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4142 - val_loss: 1.2984 - val_accuracy: 0.4064

Epoch 00599: val_loss did not improve from 1.29376
Epoch 600/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4136 - val_loss: 1.2950 - val_accuracy: 0.4072

Epoch 00600: val_loss did not improve from 1.29376
Epoch 601/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4142 - val_loss: 1.2935 - val_accuracy: 0.4143

Epoch 00601: val_loss improved from 1.29376 to 1.29346, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 602/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4140 - val_loss: 1.2959 - val_accuracy: 0.4080

Epoch 00602: val_loss did not improve from 1.29346
Epoch 603/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4128 - val_loss: 1.2944 - val_accuracy: 0.4120

Epoch 00603: val_loss did not improve from 1.29346
Epoch 604/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4136 - val_loss: 1.2930 - val_accuracy: 0.3992

Epoch 00604: val_loss improved from 1.29346 to 1.29305, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 605/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4116 - val_loss: 1.2947 - val_accuracy: 0.4048

Epoch 00605: val_loss did not improve from 1.29305
Epoch 606/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4066 - val_loss: 1.2948 - val_accuracy: 0.4135

Epoch 00606: val_loss did not improve from 1.29305
Epoch 607/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4124 - val_loss: 1.2944 - val_accuracy: 0.4135

Epoch 00607: val_loss did not improve from 1.29305
Epoch 608/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4167 - val_loss: 1.2956 - val_accuracy: 0.4032

Epoch 00608: val_loss did not improve from 1.29305
Epoch 609/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4128 - val_loss: 1.2951 - val_accuracy: 0.4112

Epoch 00609: val_loss did not improve from 1.29305
Epoch 610/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4088 - val_loss: 1.2944 - val_accuracy: 0.4096

Epoch 00610: val_loss did not improve from 1.29305
Epoch 611/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4115 - val_loss: 1.2946 - val_accuracy: 0.4120

Epoch 00611: val_loss did not improve from 1.29305
Epoch 612/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4093 - val_loss: 1.2991 - val_accuracy: 0.4120

Epoch 00612: val_loss did not improve from 1.29305
Epoch 613/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4123 - val_loss: 1.2941 - val_accuracy: 0.4040

Epoch 00613: val_loss did not improve from 1.29305
Epoch 614/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4127 - val_loss: 1.2936 - val_accuracy: 0.4048

Epoch 00614: val_loss did not improve from 1.29305
Epoch 615/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4137 - val_loss: 1.3010 - val_accuracy: 0.3984

Epoch 00615: val_loss did not improve from 1.29305
Epoch 616/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.3975 - val_loss: 1.3015 - val_accuracy: 0.4151

Epoch 00616: val_loss did not improve from 1.29305
Epoch 617/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4107 - val_loss: 1.2927 - val_accuracy: 0.4167

Epoch 00617: val_loss improved from 1.29305 to 1.29268, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 618/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4142 - val_loss: 1.2932 - val_accuracy: 0.4135

Epoch 00618: val_loss did not improve from 1.29268
Epoch 619/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4136 - val_loss: 1.2929 - val_accuracy: 0.4175

Epoch 00619: val_loss did not improve from 1.29268
Epoch 620/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4135 - val_loss: 1.2946 - val_accuracy: 0.4120

Epoch 00620: val_loss did not improve from 1.29268
Epoch 621/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4112 - val_loss: 1.2956 - val_accuracy: 0.4048

Epoch 00621: val_loss did not improve from 1.29268
Epoch 622/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4140 - val_loss: 1.2950 - val_accuracy: 0.4159

Epoch 00622: val_loss did not improve from 1.29268
Epoch 623/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4134 - val_loss: 1.2929 - val_accuracy: 0.4112

Epoch 00623: val_loss did not improve from 1.29268
Epoch 624/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4146 - val_loss: 1.2918 - val_accuracy: 0.4040

Epoch 00624: val_loss improved from 1.29268 to 1.29184, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 625/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4114 - val_loss: 1.2934 - val_accuracy: 0.4064

Epoch 00625: val_loss did not improve from 1.29184
Epoch 626/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4181 - val_loss: 1.2966 - val_accuracy: 0.3976

Epoch 00626: val_loss did not improve from 1.29184
Epoch 627/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4089 - val_loss: 1.2947 - val_accuracy: 0.4183

Epoch 00627: val_loss did not improve from 1.29184
Epoch 628/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4160 - val_loss: 1.2921 - val_accuracy: 0.4120

Epoch 00628: val_loss did not improve from 1.29184
Epoch 629/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4151 - val_loss: 1.2925 - val_accuracy: 0.4151

Epoch 00629: val_loss did not improve from 1.29184
Epoch 630/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4136 - val_loss: 1.2941 - val_accuracy: 0.4056

Epoch 00630: val_loss did not improve from 1.29184
Epoch 631/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4138 - val_loss: 1.2924 - val_accuracy: 0.4191

Epoch 00631: val_loss did not improve from 1.29184
Epoch 632/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4100 - val_loss: 1.2940 - val_accuracy: 0.4159

Epoch 00632: val_loss did not improve from 1.29184
Epoch 633/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4151 - val_loss: 1.2937 - val_accuracy: 0.4056

Epoch 00633: val_loss did not improve from 1.29184
Epoch 634/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4120 - val_loss: 1.2934 - val_accuracy: 0.4080

Epoch 00634: val_loss did not improve from 1.29184
Epoch 635/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4135 - val_loss: 1.2947 - val_accuracy: 0.4175

Epoch 00635: val_loss did not improve from 1.29184
Epoch 636/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4116 - val_loss: 1.2942 - val_accuracy: 0.4120

Epoch 00636: val_loss did not improve from 1.29184
Epoch 637/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4166 - val_loss: 1.2959 - val_accuracy: 0.4032

Epoch 00637: val_loss did not improve from 1.29184
Epoch 638/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4173 - val_loss: 1.2959 - val_accuracy: 0.4127

Epoch 00638: val_loss did not improve from 1.29184
Epoch 639/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4139 - val_loss: 1.2932 - val_accuracy: 0.4088

Epoch 00639: val_loss did not improve from 1.29184
Epoch 640/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4105 - val_loss: 1.2919 - val_accuracy: 0.4120

Epoch 00640: val_loss did not improve from 1.29184
Epoch 641/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4166 - val_loss: 1.2949 - val_accuracy: 0.4143

Epoch 00641: val_loss did not improve from 1.29184
Epoch 642/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4186 - val_loss: 1.2932 - val_accuracy: 0.4072

Epoch 00642: val_loss did not improve from 1.29184
Epoch 643/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4125 - val_loss: 1.2948 - val_accuracy: 0.4048

Epoch 00643: val_loss did not improve from 1.29184
Epoch 644/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4112 - val_loss: 1.2956 - val_accuracy: 0.4096

Epoch 00644: val_loss did not improve from 1.29184
Epoch 645/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4099 - val_loss: 1.2933 - val_accuracy: 0.4104

Epoch 00645: val_loss did not improve from 1.29184
Epoch 646/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4163 - val_loss: 1.2946 - val_accuracy: 0.4135

Epoch 00646: val_loss did not improve from 1.29184
Epoch 647/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4136 - val_loss: 1.2942 - val_accuracy: 0.4207

Epoch 00647: val_loss did not improve from 1.29184
Epoch 648/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4133 - val_loss: 1.2930 - val_accuracy: 0.4207

Epoch 00648: val_loss did not improve from 1.29184
Epoch 649/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4183 - val_loss: 1.2937 - val_accuracy: 0.4120

Epoch 00649: val_loss did not improve from 1.29184
Epoch 650/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4143 - val_loss: 1.2964 - val_accuracy: 0.4000

Epoch 00650: val_loss did not improve from 1.29184
Epoch 651/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4081 - val_loss: 1.2951 - val_accuracy: 0.4048

Epoch 00651: val_loss did not improve from 1.29184
Epoch 652/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4143 - val_loss: 1.2935 - val_accuracy: 0.4064

Epoch 00652: val_loss did not improve from 1.29184
Epoch 653/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4115 - val_loss: 1.2925 - val_accuracy: 0.4191

Epoch 00653: val_loss did not improve from 1.29184
Epoch 654/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4121 - val_loss: 1.2916 - val_accuracy: 0.4096

Epoch 00654: val_loss improved from 1.29184 to 1.29155, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 655/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4147 - val_loss: 1.2934 - val_accuracy: 0.4032

Epoch 00655: val_loss did not improve from 1.29155
Epoch 656/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4136 - val_loss: 1.2928 - val_accuracy: 0.4127

Epoch 00656: val_loss did not improve from 1.29155
Epoch 657/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4163 - val_loss: 1.2921 - val_accuracy: 0.4143

Epoch 00657: val_loss did not improve from 1.29155
Epoch 658/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4151 - val_loss: 1.2906 - val_accuracy: 0.4159

Epoch 00658: val_loss improved from 1.29155 to 1.29060, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 659/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4117 - val_loss: 1.2941 - val_accuracy: 0.4120

Epoch 00659: val_loss did not improve from 1.29060
Epoch 660/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4149 - val_loss: 1.2939 - val_accuracy: 0.4040

Epoch 00660: val_loss did not improve from 1.29060
Epoch 661/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4092 - val_loss: 1.2948 - val_accuracy: 0.4127

Epoch 00661: val_loss did not improve from 1.29060
Epoch 662/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4118 - val_loss: 1.2919 - val_accuracy: 0.4096

Epoch 00662: val_loss did not improve from 1.29060
Epoch 663/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4149 - val_loss: 1.2932 - val_accuracy: 0.4016

Epoch 00663: val_loss did not improve from 1.29060
Epoch 664/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4170 - val_loss: 1.2924 - val_accuracy: 0.4112

Epoch 00664: val_loss did not improve from 1.29060
Epoch 665/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4168 - val_loss: 1.2894 - val_accuracy: 0.4167

Epoch 00665: val_loss improved from 1.29060 to 1.28936, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 666/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4148 - val_loss: 1.2896 - val_accuracy: 0.4231

Epoch 00666: val_loss did not improve from 1.28936
Epoch 667/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4152 - val_loss: 1.2969 - val_accuracy: 0.4000

Epoch 00667: val_loss did not improve from 1.28936
Epoch 668/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4087 - val_loss: 1.2960 - val_accuracy: 0.4112

Epoch 00668: val_loss did not improve from 1.28936
Epoch 669/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4128 - val_loss: 1.2941 - val_accuracy: 0.3976

Epoch 00669: val_loss did not improve from 1.28936
Epoch 670/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4113 - val_loss: 1.2938 - val_accuracy: 0.4120

Epoch 00670: val_loss did not improve from 1.28936
Epoch 671/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4152 - val_loss: 1.2932 - val_accuracy: 0.4127

Epoch 00671: val_loss did not improve from 1.28936
Epoch 672/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4124 - val_loss: 1.2904 - val_accuracy: 0.4048

Epoch 00672: val_loss did not improve from 1.28936
Epoch 673/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4151 - val_loss: 1.2903 - val_accuracy: 0.4080

Epoch 00673: val_loss did not improve from 1.28936
Epoch 674/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4153 - val_loss: 1.2903 - val_accuracy: 0.4112

Epoch 00674: val_loss did not improve from 1.28936
Epoch 675/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4121 - val_loss: 1.2904 - val_accuracy: 0.4159

Epoch 00675: val_loss did not improve from 1.28936
Epoch 676/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4177 - val_loss: 1.2936 - val_accuracy: 0.4112

Epoch 00676: val_loss did not improve from 1.28936
Epoch 677/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4140 - val_loss: 1.2906 - val_accuracy: 0.4104

Epoch 00677: val_loss did not improve from 1.28936
Epoch 678/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4144 - val_loss: 1.2896 - val_accuracy: 0.4127

Epoch 00678: val_loss did not improve from 1.28936
Epoch 679/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4147 - val_loss: 1.2903 - val_accuracy: 0.4080

Epoch 00679: val_loss did not improve from 1.28936
Epoch 680/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4070 - val_loss: 1.2928 - val_accuracy: 0.4072

Epoch 00680: val_loss did not improve from 1.28936
Epoch 681/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4151 - val_loss: 1.2902 - val_accuracy: 0.4072

Epoch 00681: val_loss did not improve from 1.28936
Epoch 682/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4138 - val_loss: 1.2902 - val_accuracy: 0.4104

Epoch 00682: val_loss did not improve from 1.28936
Epoch 683/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4108 - val_loss: 1.2925 - val_accuracy: 0.4024

Epoch 00683: val_loss did not improve from 1.28936
Epoch 684/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4158 - val_loss: 1.2921 - val_accuracy: 0.4064

Epoch 00684: val_loss did not improve from 1.28936
Epoch 685/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4171 - val_loss: 1.2894 - val_accuracy: 0.4127

Epoch 00685: val_loss did not improve from 1.28936
Epoch 686/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4117 - val_loss: 1.2894 - val_accuracy: 0.4032

Epoch 00686: val_loss did not improve from 1.28936
Epoch 687/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4139 - val_loss: 1.2923 - val_accuracy: 0.4008

Epoch 00687: val_loss did not improve from 1.28936
Epoch 688/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4130 - val_loss: 1.2947 - val_accuracy: 0.4096

Epoch 00688: val_loss did not improve from 1.28936
Epoch 689/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4151 - val_loss: 1.2925 - val_accuracy: 0.4096

Epoch 00689: val_loss did not improve from 1.28936
Epoch 690/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4066 - val_loss: 1.2933 - val_accuracy: 0.4024

Epoch 00690: val_loss did not improve from 1.28936
Epoch 691/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4157 - val_loss: 1.2913 - val_accuracy: 0.4104

Epoch 00691: val_loss did not improve from 1.28936
Epoch 692/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4166 - val_loss: 1.2934 - val_accuracy: 0.4143

Epoch 00692: val_loss did not improve from 1.28936
Epoch 693/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4073 - val_loss: 1.2920 - val_accuracy: 0.4040

Epoch 00693: val_loss did not improve from 1.28936
Epoch 694/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4164 - val_loss: 1.2892 - val_accuracy: 0.4151

Epoch 00694: val_loss improved from 1.28936 to 1.28923, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 695/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4156 - val_loss: 1.2896 - val_accuracy: 0.4159

Epoch 00695: val_loss did not improve from 1.28923
Epoch 696/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4174 - val_loss: 1.2894 - val_accuracy: 0.4167

Epoch 00696: val_loss did not improve from 1.28923
Epoch 697/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4154 - val_loss: 1.2905 - val_accuracy: 0.4127

Epoch 00697: val_loss did not improve from 1.28923
Epoch 698/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4115 - val_loss: 1.2917 - val_accuracy: 0.4112

Epoch 00698: val_loss did not improve from 1.28923
Epoch 699/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4113 - val_loss: 1.2910 - val_accuracy: 0.4120

Epoch 00699: val_loss did not improve from 1.28923
Epoch 700/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4174 - val_loss: 1.2908 - val_accuracy: 0.4088

Epoch 00700: val_loss did not improve from 1.28923
Epoch 701/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4167 - val_loss: 1.2888 - val_accuracy: 0.4096

Epoch 00701: val_loss improved from 1.28923 to 1.28883, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 702/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4097 - val_loss: 1.2913 - val_accuracy: 0.4096

Epoch 00702: val_loss did not improve from 1.28883
Epoch 703/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4161 - val_loss: 1.2897 - val_accuracy: 0.4096

Epoch 00703: val_loss did not improve from 1.28883
Epoch 704/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4147 - val_loss: 1.2907 - val_accuracy: 0.4056

Epoch 00704: val_loss did not improve from 1.28883
Epoch 705/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4110 - val_loss: 1.2897 - val_accuracy: 0.4104

Epoch 00705: val_loss did not improve from 1.28883
Epoch 706/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4166 - val_loss: 1.2888 - val_accuracy: 0.4040

Epoch 00706: val_loss improved from 1.28883 to 1.28876, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 707/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4156 - val_loss: 1.2881 - val_accuracy: 0.4127

Epoch 00707: val_loss improved from 1.28876 to 1.28808, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 708/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4153 - val_loss: 1.2891 - val_accuracy: 0.4064

Epoch 00708: val_loss did not improve from 1.28808
Epoch 709/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4119 - val_loss: 1.2906 - val_accuracy: 0.4016

Epoch 00709: val_loss did not improve from 1.28808
Epoch 710/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4161 - val_loss: 1.2902 - val_accuracy: 0.4112

Epoch 00710: val_loss did not improve from 1.28808
Epoch 711/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4150 - val_loss: 1.2915 - val_accuracy: 0.4040

Epoch 00711: val_loss did not improve from 1.28808
Epoch 712/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4152 - val_loss: 1.2916 - val_accuracy: 0.3984

Epoch 00712: val_loss did not improve from 1.28808
Epoch 713/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4161 - val_loss: 1.2895 - val_accuracy: 0.4040

Epoch 00713: val_loss did not improve from 1.28808
Epoch 714/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4103 - val_loss: 1.2878 - val_accuracy: 0.4151

Epoch 00714: val_loss improved from 1.28808 to 1.28779, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 715/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4165 - val_loss: 1.2911 - val_accuracy: 0.4088

Epoch 00715: val_loss did not improve from 1.28779
Epoch 716/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4167 - val_loss: 1.2887 - val_accuracy: 0.4112

Epoch 00716: val_loss did not improve from 1.28779
Epoch 717/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4192 - val_loss: 1.2916 - val_accuracy: 0.4056

Epoch 00717: val_loss did not improve from 1.28779
Epoch 718/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4156 - val_loss: 1.2897 - val_accuracy: 0.4072

Epoch 00718: val_loss did not improve from 1.28779
Epoch 719/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4141 - val_loss: 1.2882 - val_accuracy: 0.4135

Epoch 00719: val_loss did not improve from 1.28779
Epoch 720/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4128 - val_loss: 1.2903 - val_accuracy: 0.4048

Epoch 00720: val_loss did not improve from 1.28779
Epoch 721/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4123 - val_loss: 1.2885 - val_accuracy: 0.4112

Epoch 00721: val_loss did not improve from 1.28779
Epoch 722/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4173 - val_loss: 1.2898 - val_accuracy: 0.4175

Epoch 00722: val_loss did not improve from 1.28779
Epoch 723/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4135 - val_loss: 1.2907 - val_accuracy: 0.4056

Epoch 00723: val_loss did not improve from 1.28779
Epoch 724/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4140 - val_loss: 1.2876 - val_accuracy: 0.4112

Epoch 00724: val_loss improved from 1.28779 to 1.28761, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 725/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4138 - val_loss: 1.2901 - val_accuracy: 0.4143

Epoch 00725: val_loss did not improve from 1.28761
Epoch 726/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4151 - val_loss: 1.2904 - val_accuracy: 0.4040

Epoch 00726: val_loss did not improve from 1.28761
Epoch 727/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4174 - val_loss: 1.2895 - val_accuracy: 0.4096

Epoch 00727: val_loss did not improve from 1.28761
Epoch 728/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4154 - val_loss: 1.2885 - val_accuracy: 0.4040

Epoch 00728: val_loss did not improve from 1.28761
Epoch 729/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4182 - val_loss: 1.2892 - val_accuracy: 0.4120

Epoch 00729: val_loss did not improve from 1.28761
Epoch 730/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4128 - val_loss: 1.2900 - val_accuracy: 0.4024

Epoch 00730: val_loss did not improve from 1.28761
Epoch 731/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4169 - val_loss: 1.2881 - val_accuracy: 0.4088

Epoch 00731: val_loss did not improve from 1.28761
Epoch 732/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4162 - val_loss: 1.2908 - val_accuracy: 0.4040

Epoch 00732: val_loss did not improve from 1.28761
Epoch 733/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4120 - val_loss: 1.2907 - val_accuracy: 0.4135

Epoch 00733: val_loss did not improve from 1.28761
Epoch 734/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4121 - val_loss: 1.2900 - val_accuracy: 0.4175

Epoch 00734: val_loss did not improve from 1.28761
Epoch 735/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4143 - val_loss: 1.2874 - val_accuracy: 0.4127

Epoch 00735: val_loss improved from 1.28761 to 1.28738, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 736/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4163 - val_loss: 1.2911 - val_accuracy: 0.4032

Epoch 00736: val_loss did not improve from 1.28738
Epoch 737/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4187 - val_loss: 1.3004 - val_accuracy: 0.4000

Epoch 00737: val_loss did not improve from 1.28738
Epoch 738/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4073 - val_loss: 1.2997 - val_accuracy: 0.3896

Epoch 00738: val_loss did not improve from 1.28738
Epoch 739/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4097 - val_loss: 1.2897 - val_accuracy: 0.4088

Epoch 00739: val_loss did not improve from 1.28738
Epoch 740/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4157 - val_loss: 1.2956 - val_accuracy: 0.4016

Epoch 00740: val_loss did not improve from 1.28738
Epoch 741/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4114 - val_loss: 1.2939 - val_accuracy: 0.3984

Epoch 00741: val_loss did not improve from 1.28738
Epoch 742/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4161 - val_loss: 1.2884 - val_accuracy: 0.4104

Epoch 00742: val_loss did not improve from 1.28738
Epoch 743/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4143 - val_loss: 1.2875 - val_accuracy: 0.4096

Epoch 00743: val_loss did not improve from 1.28738
Epoch 744/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4170 - val_loss: 1.2881 - val_accuracy: 0.4080

Epoch 00744: val_loss did not improve from 1.28738
Epoch 745/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4152 - val_loss: 1.2875 - val_accuracy: 0.4135

Epoch 00745: val_loss did not improve from 1.28738
Epoch 746/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4125 - val_loss: 1.2884 - val_accuracy: 0.4016

Epoch 00746: val_loss did not improve from 1.28738
Epoch 747/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4186 - val_loss: 1.2879 - val_accuracy: 0.4159

Epoch 00747: val_loss did not improve from 1.28738
Epoch 748/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4173 - val_loss: 1.2881 - val_accuracy: 0.4096

Epoch 00748: val_loss did not improve from 1.28738
Epoch 749/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4102 - val_loss: 1.2884 - val_accuracy: 0.4056

Epoch 00749: val_loss did not improve from 1.28738
Epoch 750/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4123 - val_loss: 1.2898 - val_accuracy: 0.4135

Epoch 00750: val_loss did not improve from 1.28738
Epoch 751/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4122 - val_loss: 1.2942 - val_accuracy: 0.4024

Epoch 00751: val_loss did not improve from 1.28738
Epoch 752/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4155 - val_loss: 1.2924 - val_accuracy: 0.4000

Epoch 00752: val_loss did not improve from 1.28738
Epoch 753/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4144 - val_loss: 1.2917 - val_accuracy: 0.4088

Epoch 00753: val_loss did not improve from 1.28738
Epoch 754/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4169 - val_loss: 1.2881 - val_accuracy: 0.4064

Epoch 00754: val_loss did not improve from 1.28738
Epoch 755/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4164 - val_loss: 1.2870 - val_accuracy: 0.4151

Epoch 00755: val_loss improved from 1.28738 to 1.28704, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 756/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4120 - val_loss: 1.2875 - val_accuracy: 0.4096

Epoch 00756: val_loss did not improve from 1.28704
Epoch 757/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4140 - val_loss: 1.2879 - val_accuracy: 0.4088

Epoch 00757: val_loss did not improve from 1.28704
Epoch 758/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4115 - val_loss: 1.2899 - val_accuracy: 0.4016

Epoch 00758: val_loss did not improve from 1.28704
Epoch 759/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4170 - val_loss: 1.2885 - val_accuracy: 0.4040

Epoch 00759: val_loss did not improve from 1.28704
Epoch 760/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4172 - val_loss: 1.2922 - val_accuracy: 0.4167

Epoch 00760: val_loss did not improve from 1.28704
Epoch 761/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4145 - val_loss: 1.2908 - val_accuracy: 0.4000

Epoch 00761: val_loss did not improve from 1.28704
Epoch 762/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4171 - val_loss: 1.2884 - val_accuracy: 0.4024

Epoch 00762: val_loss did not improve from 1.28704
Epoch 763/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4121 - val_loss: 1.2878 - val_accuracy: 0.4088

Epoch 00763: val_loss did not improve from 1.28704
Epoch 764/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4151 - val_loss: 1.2866 - val_accuracy: 0.4064

Epoch 00764: val_loss improved from 1.28704 to 1.28659, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 765/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4165 - val_loss: 1.2875 - val_accuracy: 0.4096

Epoch 00765: val_loss did not improve from 1.28659
Epoch 766/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4152 - val_loss: 1.2891 - val_accuracy: 0.4056

Epoch 00766: val_loss did not improve from 1.28659
Epoch 767/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4174 - val_loss: 1.2879 - val_accuracy: 0.4000

Epoch 00767: val_loss did not improve from 1.28659
Epoch 768/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4175 - val_loss: 1.2891 - val_accuracy: 0.4120

Epoch 00768: val_loss did not improve from 1.28659
Epoch 769/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4156 - val_loss: 1.2878 - val_accuracy: 0.4024

Epoch 00769: val_loss did not improve from 1.28659
Epoch 770/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4136 - val_loss: 1.2910 - val_accuracy: 0.4159

Epoch 00770: val_loss did not improve from 1.28659
Epoch 771/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4167 - val_loss: 1.2891 - val_accuracy: 0.4024

Epoch 00771: val_loss did not improve from 1.28659
Epoch 772/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4138 - val_loss: 1.2859 - val_accuracy: 0.4088

Epoch 00772: val_loss improved from 1.28659 to 1.28592, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 773/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4145 - val_loss: 1.2864 - val_accuracy: 0.4167

Epoch 00773: val_loss did not improve from 1.28592
Epoch 774/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4143 - val_loss: 1.2856 - val_accuracy: 0.4080

Epoch 00774: val_loss improved from 1.28592 to 1.28561, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 775/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4151 - val_loss: 1.2879 - val_accuracy: 0.4104

Epoch 00775: val_loss did not improve from 1.28561
Epoch 776/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4138 - val_loss: 1.2876 - val_accuracy: 0.4000

Epoch 00776: val_loss did not improve from 1.28561
Epoch 777/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4135 - val_loss: 1.2885 - val_accuracy: 0.4000

Epoch 00777: val_loss did not improve from 1.28561
Epoch 778/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4167 - val_loss: 1.2892 - val_accuracy: 0.4120

Epoch 00778: val_loss did not improve from 1.28561
Epoch 779/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4184 - val_loss: 1.2868 - val_accuracy: 0.4024

Epoch 00779: val_loss did not improve from 1.28561
Epoch 780/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4131 - val_loss: 1.2877 - val_accuracy: 0.4008

Epoch 00780: val_loss did not improve from 1.28561
Epoch 781/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4162 - val_loss: 1.2888 - val_accuracy: 0.4064

Epoch 00781: val_loss did not improve from 1.28561
Epoch 782/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4173 - val_loss: 1.2875 - val_accuracy: 0.4143

Epoch 00782: val_loss did not improve from 1.28561
Epoch 783/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4143 - val_loss: 1.2872 - val_accuracy: 0.4040

Epoch 00783: val_loss did not improve from 1.28561
Epoch 784/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4126 - val_loss: 1.2889 - val_accuracy: 0.4104

Epoch 00784: val_loss did not improve from 1.28561
Epoch 785/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4163 - val_loss: 1.2853 - val_accuracy: 0.4072

Epoch 00785: val_loss improved from 1.28561 to 1.28535, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 786/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4150 - val_loss: 1.2875 - val_accuracy: 0.4127

Epoch 00786: val_loss did not improve from 1.28535
Epoch 787/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4121 - val_loss: 1.2881 - val_accuracy: 0.4048

Epoch 00787: val_loss did not improve from 1.28535
Epoch 788/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4136 - val_loss: 1.2899 - val_accuracy: 0.4183

Epoch 00788: val_loss did not improve from 1.28535
Epoch 789/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4155 - val_loss: 1.2865 - val_accuracy: 0.4088

Epoch 00789: val_loss did not improve from 1.28535
Epoch 790/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4081 - val_loss: 1.2905 - val_accuracy: 0.3984

Epoch 00790: val_loss did not improve from 1.28535
Epoch 791/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4176 - val_loss: 1.2897 - val_accuracy: 0.4064

Epoch 00791: val_loss did not improve from 1.28535
Epoch 792/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4120 - val_loss: 1.2897 - val_accuracy: 0.4120

Epoch 00792: val_loss did not improve from 1.28535
Epoch 793/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4157 - val_loss: 1.2901 - val_accuracy: 0.4016

Epoch 00793: val_loss did not improve from 1.28535
Epoch 794/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4175 - val_loss: 1.2876 - val_accuracy: 0.4151

Epoch 00794: val_loss did not improve from 1.28535
Epoch 795/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4174 - val_loss: 1.2858 - val_accuracy: 0.4040

Epoch 00795: val_loss did not improve from 1.28535
Epoch 796/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4184 - val_loss: 1.2859 - val_accuracy: 0.4032

Epoch 00796: val_loss did not improve from 1.28535
Epoch 797/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4167 - val_loss: 1.2880 - val_accuracy: 0.4080

Epoch 00797: val_loss did not improve from 1.28535
Epoch 798/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4194 - val_loss: 1.2863 - val_accuracy: 0.4143

Epoch 00798: val_loss did not improve from 1.28535
Epoch 799/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4141 - val_loss: 1.2871 - val_accuracy: 0.4088

Epoch 00799: val_loss did not improve from 1.28535
Epoch 800/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4168 - val_loss: 1.2905 - val_accuracy: 0.4064

Epoch 00800: val_loss did not improve from 1.28535
Epoch 801/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4058 - val_loss: 1.2895 - val_accuracy: 0.4016

Epoch 00801: val_loss did not improve from 1.28535
Epoch 802/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4173 - val_loss: 1.2868 - val_accuracy: 0.4072

Epoch 00802: val_loss did not improve from 1.28535
Epoch 803/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4169 - val_loss: 1.2897 - val_accuracy: 0.4024

Epoch 00803: val_loss did not improve from 1.28535
Epoch 804/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4172 - val_loss: 1.2840 - val_accuracy: 0.4127

Epoch 00804: val_loss improved from 1.28535 to 1.28403, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 805/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4174 - val_loss: 1.2876 - val_accuracy: 0.4056

Epoch 00805: val_loss did not improve from 1.28403
Epoch 806/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4107 - val_loss: 1.2882 - val_accuracy: 0.4016

Epoch 00806: val_loss did not improve from 1.28403
Epoch 807/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4193 - val_loss: 1.2873 - val_accuracy: 0.4104

Epoch 00807: val_loss did not improve from 1.28403
Epoch 808/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4168 - val_loss: 1.2888 - val_accuracy: 0.4064

Epoch 00808: val_loss did not improve from 1.28403
Epoch 809/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4191 - val_loss: 1.2886 - val_accuracy: 0.4056

Epoch 00809: val_loss did not improve from 1.28403
Epoch 810/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4189 - val_loss: 1.2872 - val_accuracy: 0.4032

Epoch 00810: val_loss did not improve from 1.28403
Epoch 811/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4167 - val_loss: 1.2861 - val_accuracy: 0.4064

Epoch 00811: val_loss did not improve from 1.28403
Epoch 812/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4176 - val_loss: 1.2850 - val_accuracy: 0.4080

Epoch 00812: val_loss did not improve from 1.28403
Epoch 813/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4143 - val_loss: 1.2919 - val_accuracy: 0.4032

Epoch 00813: val_loss did not improve from 1.28403
Epoch 814/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4197 - val_loss: 1.2911 - val_accuracy: 0.4088

Epoch 00814: val_loss did not improve from 1.28403
Epoch 815/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4202 - val_loss: 1.2859 - val_accuracy: 0.4064

Epoch 00815: val_loss did not improve from 1.28403
Epoch 816/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4124 - val_loss: 1.2869 - val_accuracy: 0.4056

Epoch 00816: val_loss did not improve from 1.28403
Epoch 817/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4190 - val_loss: 1.2904 - val_accuracy: 0.4127

Epoch 00817: val_loss did not improve from 1.28403
Epoch 818/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4196 - val_loss: 1.2875 - val_accuracy: 0.4104

Epoch 00818: val_loss did not improve from 1.28403
Epoch 819/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4179 - val_loss: 1.2860 - val_accuracy: 0.4167

Epoch 00819: val_loss did not improve from 1.28403
Epoch 820/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4188 - val_loss: 1.2859 - val_accuracy: 0.4040

Epoch 00820: val_loss did not improve from 1.28403
Epoch 821/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4177 - val_loss: 1.2895 - val_accuracy: 0.4096

Epoch 00821: val_loss did not improve from 1.28403
Epoch 822/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4191 - val_loss: 1.2900 - val_accuracy: 0.4143

Epoch 00822: val_loss did not improve from 1.28403
Epoch 823/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4177 - val_loss: 1.2882 - val_accuracy: 0.4056

Epoch 00823: val_loss did not improve from 1.28403
Epoch 824/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4160 - val_loss: 1.2876 - val_accuracy: 0.4096

Epoch 00824: val_loss did not improve from 1.28403
Epoch 825/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4149 - val_loss: 1.2845 - val_accuracy: 0.4080

Epoch 00825: val_loss did not improve from 1.28403
Epoch 826/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4112 - val_loss: 1.2900 - val_accuracy: 0.4040

Epoch 00826: val_loss did not improve from 1.28403
Epoch 827/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4164 - val_loss: 1.2885 - val_accuracy: 0.4127

Epoch 00827: val_loss did not improve from 1.28403
Epoch 828/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4155 - val_loss: 1.2861 - val_accuracy: 0.4056

Epoch 00828: val_loss did not improve from 1.28403
Epoch 829/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4191 - val_loss: 1.2880 - val_accuracy: 0.4008

Epoch 00829: val_loss did not improve from 1.28403
Epoch 830/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4153 - val_loss: 1.2897 - val_accuracy: 0.4088

Epoch 00830: val_loss did not improve from 1.28403
Epoch 831/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4197 - val_loss: 1.2878 - val_accuracy: 0.4120

Epoch 00831: val_loss did not improve from 1.28403
Epoch 832/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4144 - val_loss: 1.2875 - val_accuracy: 0.4000

Epoch 00832: val_loss did not improve from 1.28403
Epoch 833/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4168 - val_loss: 1.2874 - val_accuracy: 0.4056

Epoch 00833: val_loss did not improve from 1.28403
Epoch 834/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4174 - val_loss: 1.2870 - val_accuracy: 0.4056

Epoch 00834: val_loss did not improve from 1.28403
Epoch 835/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4182 - val_loss: 1.2868 - val_accuracy: 0.4127

Epoch 00835: val_loss did not improve from 1.28403
Epoch 836/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4171 - val_loss: 1.2876 - val_accuracy: 0.4024

Epoch 00836: val_loss did not improve from 1.28403
Epoch 837/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4191 - val_loss: 1.2875 - val_accuracy: 0.4127

Epoch 00837: val_loss did not improve from 1.28403
Epoch 838/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4166 - val_loss: 1.2846 - val_accuracy: 0.4072

Epoch 00838: val_loss did not improve from 1.28403
Epoch 839/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4176 - val_loss: 1.2883 - val_accuracy: 0.3992

Epoch 00839: val_loss did not improve from 1.28403
Epoch 840/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4163 - val_loss: 1.2869 - val_accuracy: 0.4088

Epoch 00840: val_loss did not improve from 1.28403
Epoch 841/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4143 - val_loss: 1.2838 - val_accuracy: 0.4088

Epoch 00841: val_loss improved from 1.28403 to 1.28377, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 842/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4165 - val_loss: 1.2861 - val_accuracy: 0.4064

Epoch 00842: val_loss did not improve from 1.28377
Epoch 843/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4183 - val_loss: 1.2899 - val_accuracy: 0.4032

Epoch 00843: val_loss did not improve from 1.28377
Epoch 844/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4160 - val_loss: 1.2922 - val_accuracy: 0.4072

Epoch 00844: val_loss did not improve from 1.28377
Epoch 845/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4203 - val_loss: 1.2875 - val_accuracy: 0.4135

Epoch 00845: val_loss did not improve from 1.28377
Epoch 846/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4182 - val_loss: 1.2845 - val_accuracy: 0.4088

Epoch 00846: val_loss did not improve from 1.28377
Epoch 847/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4143 - val_loss: 1.2899 - val_accuracy: 0.4040

Epoch 00847: val_loss did not improve from 1.28377
Epoch 848/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4174 - val_loss: 1.2868 - val_accuracy: 0.4120

Epoch 00848: val_loss did not improve from 1.28377
Epoch 849/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4190 - val_loss: 1.2865 - val_accuracy: 0.4096

Epoch 00849: val_loss did not improve from 1.28377
Epoch 850/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4166 - val_loss: 1.2841 - val_accuracy: 0.4096

Epoch 00850: val_loss did not improve from 1.28377
Epoch 851/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4173 - val_loss: 1.2874 - val_accuracy: 0.4167

Epoch 00851: val_loss did not improve from 1.28377
Epoch 852/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4169 - val_loss: 1.2863 - val_accuracy: 0.4072

Epoch 00852: val_loss did not improve from 1.28377
Epoch 853/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4158 - val_loss: 1.2856 - val_accuracy: 0.4199

Epoch 00853: val_loss did not improve from 1.28377
Epoch 854/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4189 - val_loss: 1.2864 - val_accuracy: 0.4175

Epoch 00854: val_loss did not improve from 1.28377
Epoch 855/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4187 - val_loss: 1.2858 - val_accuracy: 0.4127

Epoch 00855: val_loss did not improve from 1.28377
Epoch 856/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4171 - val_loss: 1.2846 - val_accuracy: 0.4135

Epoch 00856: val_loss did not improve from 1.28377
Epoch 857/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4107 - val_loss: 1.2895 - val_accuracy: 0.4048

Epoch 00857: val_loss did not improve from 1.28377
Epoch 858/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4192 - val_loss: 1.2846 - val_accuracy: 0.4135

Epoch 00858: val_loss did not improve from 1.28377
Epoch 859/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4171 - val_loss: 1.2858 - val_accuracy: 0.4080

Epoch 00859: val_loss did not improve from 1.28377
Epoch 860/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4162 - val_loss: 1.2867 - val_accuracy: 0.4072

Epoch 00860: val_loss did not improve from 1.28377
Epoch 861/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4178 - val_loss: 1.2859 - val_accuracy: 0.4024

Epoch 00861: val_loss did not improve from 1.28377
Epoch 862/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4194 - val_loss: 1.2866 - val_accuracy: 0.4088

Epoch 00862: val_loss did not improve from 1.28377
Epoch 863/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4119 - val_loss: 1.2834 - val_accuracy: 0.4104

Epoch 00863: val_loss improved from 1.28377 to 1.28345, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 864/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4132 - val_loss: 1.2877 - val_accuracy: 0.4040

Epoch 00864: val_loss did not improve from 1.28345
Epoch 865/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4169 - val_loss: 1.2872 - val_accuracy: 0.4167

Epoch 00865: val_loss did not improve from 1.28345
Epoch 866/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4156 - val_loss: 1.2895 - val_accuracy: 0.4127

Epoch 00866: val_loss did not improve from 1.28345
Epoch 867/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4178 - val_loss: 1.2861 - val_accuracy: 0.4048

Epoch 00867: val_loss did not improve from 1.28345
Epoch 868/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4215 - val_loss: 1.2827 - val_accuracy: 0.4112

Epoch 00868: val_loss improved from 1.28345 to 1.28275, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 869/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4210 - val_loss: 1.2887 - val_accuracy: 0.4135

Epoch 00869: val_loss did not improve from 1.28275
Epoch 870/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4181 - val_loss: 1.2835 - val_accuracy: 0.4032

Epoch 00870: val_loss did not improve from 1.28275
Epoch 871/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4163 - val_loss: 1.2841 - val_accuracy: 0.4088

Epoch 00871: val_loss did not improve from 1.28275
Epoch 872/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4159 - val_loss: 1.2882 - val_accuracy: 0.4072

Epoch 00872: val_loss did not improve from 1.28275
Epoch 873/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4146 - val_loss: 1.2871 - val_accuracy: 0.4016

Epoch 00873: val_loss did not improve from 1.28275
Epoch 874/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4125 - val_loss: 1.2858 - val_accuracy: 0.4056

Epoch 00874: val_loss did not improve from 1.28275
Epoch 875/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4154 - val_loss: 1.2861 - val_accuracy: 0.4112

Epoch 00875: val_loss did not improve from 1.28275
Epoch 876/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4155 - val_loss: 1.2877 - val_accuracy: 0.3984

Epoch 00876: val_loss did not improve from 1.28275
Epoch 877/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4176 - val_loss: 1.2856 - val_accuracy: 0.4135

Epoch 00877: val_loss did not improve from 1.28275
Epoch 878/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4170 - val_loss: 1.2868 - val_accuracy: 0.4072

Epoch 00878: val_loss did not improve from 1.28275
Epoch 879/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4147 - val_loss: 1.2834 - val_accuracy: 0.4096

Epoch 00879: val_loss did not improve from 1.28275
Epoch 880/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4179 - val_loss: 1.2869 - val_accuracy: 0.4112

Epoch 00880: val_loss did not improve from 1.28275
Epoch 881/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4197 - val_loss: 1.2856 - val_accuracy: 0.4120

Epoch 00881: val_loss did not improve from 1.28275
Epoch 882/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4203 - val_loss: 1.2849 - val_accuracy: 0.4239

Epoch 00882: val_loss did not improve from 1.28275
Epoch 883/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4187 - val_loss: 1.2871 - val_accuracy: 0.4104

Epoch 00883: val_loss did not improve from 1.28275
Epoch 884/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4170 - val_loss: 1.2845 - val_accuracy: 0.4088

Epoch 00884: val_loss did not improve from 1.28275
Epoch 885/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4172 - val_loss: 1.2859 - val_accuracy: 0.4000

Epoch 00885: val_loss did not improve from 1.28275
Epoch 886/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4140 - val_loss: 1.2894 - val_accuracy: 0.4008

Epoch 00886: val_loss did not improve from 1.28275
Epoch 887/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4165 - val_loss: 1.2861 - val_accuracy: 0.4032

Epoch 00887: val_loss did not improve from 1.28275
Epoch 888/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4204 - val_loss: 1.2857 - val_accuracy: 0.4096

Epoch 00888: val_loss did not improve from 1.28275
Epoch 889/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4195 - val_loss: 1.2859 - val_accuracy: 0.4048

Epoch 00889: val_loss did not improve from 1.28275
Epoch 890/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4159 - val_loss: 1.2839 - val_accuracy: 0.4127

Epoch 00890: val_loss did not improve from 1.28275
Epoch 891/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4135 - val_loss: 1.2889 - val_accuracy: 0.4064

Epoch 00891: val_loss did not improve from 1.28275
Epoch 892/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4151 - val_loss: 1.2852 - val_accuracy: 0.4112

Epoch 00892: val_loss did not improve from 1.28275
Epoch 893/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4182 - val_loss: 1.2866 - val_accuracy: 0.4064

Epoch 00893: val_loss did not improve from 1.28275
Epoch 894/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4128 - val_loss: 1.2875 - val_accuracy: 0.4024

Epoch 00894: val_loss did not improve from 1.28275
Epoch 895/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4159 - val_loss: 1.2830 - val_accuracy: 0.4143

Epoch 00895: val_loss did not improve from 1.28275
Epoch 896/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4151 - val_loss: 1.2833 - val_accuracy: 0.4120

Epoch 00896: val_loss did not improve from 1.28275
Epoch 897/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4169 - val_loss: 1.2831 - val_accuracy: 0.4088

Epoch 00897: val_loss did not improve from 1.28275
Epoch 898/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4192 - val_loss: 1.2837 - val_accuracy: 0.4096

Epoch 00898: val_loss did not improve from 1.28275
Epoch 899/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4187 - val_loss: 1.2873 - val_accuracy: 0.4104

Epoch 00899: val_loss did not improve from 1.28275
Epoch 900/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4120 - val_loss: 1.2839 - val_accuracy: 0.3960

Epoch 00900: val_loss did not improve from 1.28275
Epoch 901/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4186 - val_loss: 1.2855 - val_accuracy: 0.4080

Epoch 00901: val_loss did not improve from 1.28275
Epoch 902/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4180 - val_loss: 1.2882 - val_accuracy: 0.3976

Epoch 00902: val_loss did not improve from 1.28275
Epoch 903/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4209 - val_loss: 1.2887 - val_accuracy: 0.4151

Epoch 00903: val_loss did not improve from 1.28275
Epoch 904/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4173 - val_loss: 1.2871 - val_accuracy: 0.4072

Epoch 00904: val_loss did not improve from 1.28275
Epoch 905/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4162 - val_loss: 1.2841 - val_accuracy: 0.4120

Epoch 00905: val_loss did not improve from 1.28275
Epoch 906/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4196 - val_loss: 1.2828 - val_accuracy: 0.4056

Epoch 00906: val_loss did not improve from 1.28275
Epoch 907/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4166 - val_loss: 1.2814 - val_accuracy: 0.4064

Epoch 00907: val_loss improved from 1.28275 to 1.28141, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 908/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4149 - val_loss: 1.2829 - val_accuracy: 0.4088

Epoch 00908: val_loss did not improve from 1.28141
Epoch 909/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4157 - val_loss: 1.2816 - val_accuracy: 0.4143

Epoch 00909: val_loss did not improve from 1.28141
Epoch 910/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4117 - val_loss: 1.2893 - val_accuracy: 0.3984

Epoch 00910: val_loss did not improve from 1.28141
Epoch 911/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4197 - val_loss: 1.2869 - val_accuracy: 0.4048

Epoch 00911: val_loss did not improve from 1.28141
Epoch 912/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4215 - val_loss: 1.2830 - val_accuracy: 0.4143

Epoch 00912: val_loss did not improve from 1.28141
Epoch 913/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4175 - val_loss: 1.2831 - val_accuracy: 0.4096

Epoch 00913: val_loss did not improve from 1.28141
Epoch 914/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4197 - val_loss: 1.2827 - val_accuracy: 0.4056

Epoch 00914: val_loss did not improve from 1.28141
Epoch 915/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4151 - val_loss: 1.2826 - val_accuracy: 0.4056

Epoch 00915: val_loss did not improve from 1.28141
Epoch 916/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4200 - val_loss: 1.2844 - val_accuracy: 0.4056

Epoch 00916: val_loss did not improve from 1.28141
Epoch 917/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4177 - val_loss: 1.2828 - val_accuracy: 0.4096

Epoch 00917: val_loss did not improve from 1.28141
Epoch 918/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4170 - val_loss: 1.2823 - val_accuracy: 0.4143

Epoch 00918: val_loss did not improve from 1.28141
Epoch 919/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4180 - val_loss: 1.2874 - val_accuracy: 0.4072

Epoch 00919: val_loss did not improve from 1.28141
Epoch 920/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4206 - val_loss: 1.2840 - val_accuracy: 0.4135

Epoch 00920: val_loss did not improve from 1.28141
Epoch 921/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4186 - val_loss: 1.2840 - val_accuracy: 0.4175

Epoch 00921: val_loss did not improve from 1.28141
Epoch 922/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4196 - val_loss: 1.2851 - val_accuracy: 0.4191

Epoch 00922: val_loss did not improve from 1.28141
Epoch 923/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4197 - val_loss: 1.2803 - val_accuracy: 0.4143

Epoch 00923: val_loss improved from 1.28141 to 1.28029, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 924/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4172 - val_loss: 1.2863 - val_accuracy: 0.4032

Epoch 00924: val_loss did not improve from 1.28029
Epoch 925/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4159 - val_loss: 1.2889 - val_accuracy: 0.4064

Epoch 00925: val_loss did not improve from 1.28029
Epoch 926/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4121 - val_loss: 1.2850 - val_accuracy: 0.3976

Epoch 00926: val_loss did not improve from 1.28029
Epoch 927/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4195 - val_loss: 1.2880 - val_accuracy: 0.4088

Epoch 00927: val_loss did not improve from 1.28029
Epoch 928/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4175 - val_loss: 1.2850 - val_accuracy: 0.4080

Epoch 00928: val_loss did not improve from 1.28029
Epoch 929/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4166 - val_loss: 1.2866 - val_accuracy: 0.4032

Epoch 00929: val_loss did not improve from 1.28029
Epoch 930/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4164 - val_loss: 1.2827 - val_accuracy: 0.4072

Epoch 00930: val_loss did not improve from 1.28029
Epoch 931/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4180 - val_loss: 1.2859 - val_accuracy: 0.4167

Epoch 00931: val_loss did not improve from 1.28029
Epoch 932/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4153 - val_loss: 1.2811 - val_accuracy: 0.4135

Epoch 00932: val_loss did not improve from 1.28029
Epoch 933/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4174 - val_loss: 1.2845 - val_accuracy: 0.4151

Epoch 00933: val_loss did not improve from 1.28029
Epoch 934/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4190 - val_loss: 1.2835 - val_accuracy: 0.4135

Epoch 00934: val_loss did not improve from 1.28029
Epoch 935/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4194 - val_loss: 1.2842 - val_accuracy: 0.4112

Epoch 00935: val_loss did not improve from 1.28029
Epoch 936/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4178 - val_loss: 1.2833 - val_accuracy: 0.4112

Epoch 00936: val_loss did not improve from 1.28029
Epoch 937/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4191 - val_loss: 1.2853 - val_accuracy: 0.4120

Epoch 00937: val_loss did not improve from 1.28029
Epoch 938/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4194 - val_loss: 1.2846 - val_accuracy: 0.4088

Epoch 00938: val_loss did not improve from 1.28029
Epoch 939/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4208 - val_loss: 1.2833 - val_accuracy: 0.4008

Epoch 00939: val_loss did not improve from 1.28029
Epoch 940/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4191 - val_loss: 1.2824 - val_accuracy: 0.4135

Epoch 00940: val_loss did not improve from 1.28029
Epoch 941/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4202 - val_loss: 1.2852 - val_accuracy: 0.4151

Epoch 00941: val_loss did not improve from 1.28029
Epoch 942/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4202 - val_loss: 1.2847 - val_accuracy: 0.4151

Epoch 00942: val_loss did not improve from 1.28029
Epoch 943/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4145 - val_loss: 1.2838 - val_accuracy: 0.4040

Epoch 00943: val_loss did not improve from 1.28029
Epoch 944/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4160 - val_loss: 1.2851 - val_accuracy: 0.4048

Epoch 00944: val_loss did not improve from 1.28029
Epoch 945/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4221 - val_loss: 1.2805 - val_accuracy: 0.4096

Epoch 00945: val_loss did not improve from 1.28029
Epoch 946/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4201 - val_loss: 1.2817 - val_accuracy: 0.4143

Epoch 00946: val_loss did not improve from 1.28029
Epoch 947/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4181 - val_loss: 1.2845 - val_accuracy: 0.4104

Epoch 00947: val_loss did not improve from 1.28029
Epoch 948/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4205 - val_loss: 1.2807 - val_accuracy: 0.4104

Epoch 00948: val_loss did not improve from 1.28029
Epoch 949/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4203 - val_loss: 1.2848 - val_accuracy: 0.3984

Epoch 00949: val_loss did not improve from 1.28029
Epoch 950/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4190 - val_loss: 1.2834 - val_accuracy: 0.4151

Epoch 00950: val_loss did not improve from 1.28029
Epoch 951/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4164 - val_loss: 1.2871 - val_accuracy: 0.4072

Epoch 00951: val_loss did not improve from 1.28029
Epoch 952/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4068 - val_loss: 1.2906 - val_accuracy: 0.3888

Epoch 00952: val_loss did not improve from 1.28029
Epoch 953/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4142 - val_loss: 1.2870 - val_accuracy: 0.4104

Epoch 00953: val_loss did not improve from 1.28029
Epoch 954/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4149 - val_loss: 1.2852 - val_accuracy: 0.4064

Epoch 00954: val_loss did not improve from 1.28029
Epoch 955/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4164 - val_loss: 1.2824 - val_accuracy: 0.4096

Epoch 00955: val_loss did not improve from 1.28029
Epoch 956/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4166 - val_loss: 1.2842 - val_accuracy: 0.4135

Epoch 00956: val_loss did not improve from 1.28029
Epoch 957/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4224 - val_loss: 1.2850 - val_accuracy: 0.4191

Epoch 00957: val_loss did not improve from 1.28029
Epoch 958/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4203 - val_loss: 1.2810 - val_accuracy: 0.4127

Epoch 00958: val_loss did not improve from 1.28029
Epoch 959/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4153 - val_loss: 1.2816 - val_accuracy: 0.4080

Epoch 00959: val_loss did not improve from 1.28029
Epoch 960/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4134 - val_loss: 1.2830 - val_accuracy: 0.4151

Epoch 00960: val_loss did not improve from 1.28029
Epoch 961/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4177 - val_loss: 1.2855 - val_accuracy: 0.4104

Epoch 00961: val_loss did not improve from 1.28029
Epoch 962/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4190 - val_loss: 1.2843 - val_accuracy: 0.4040

Epoch 00962: val_loss did not improve from 1.28029
Epoch 963/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4193 - val_loss: 1.2831 - val_accuracy: 0.4159

Epoch 00963: val_loss did not improve from 1.28029
Epoch 964/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4159 - val_loss: 1.2833 - val_accuracy: 0.4032

Epoch 00964: val_loss did not improve from 1.28029
Epoch 965/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4176 - val_loss: 1.2830 - val_accuracy: 0.4167

Epoch 00965: val_loss did not improve from 1.28029
Epoch 966/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4161 - val_loss: 1.2842 - val_accuracy: 0.4096

Epoch 00966: val_loss did not improve from 1.28029
Epoch 967/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4150 - val_loss: 1.2817 - val_accuracy: 0.4104

Epoch 00967: val_loss did not improve from 1.28029
Epoch 968/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4170 - val_loss: 1.2851 - val_accuracy: 0.4096

Epoch 00968: val_loss did not improve from 1.28029
Epoch 969/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4180 - val_loss: 1.2831 - val_accuracy: 0.4104

Epoch 00969: val_loss did not improve from 1.28029
Epoch 970/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4170 - val_loss: 1.2852 - val_accuracy: 0.4120

Epoch 00970: val_loss did not improve from 1.28029
Epoch 971/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4187 - val_loss: 1.2818 - val_accuracy: 0.4127

Epoch 00971: val_loss did not improve from 1.28029
Epoch 972/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4173 - val_loss: 1.2819 - val_accuracy: 0.4135

Epoch 00972: val_loss did not improve from 1.28029
Epoch 973/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4221 - val_loss: 1.2858 - val_accuracy: 0.4120

Epoch 00973: val_loss did not improve from 1.28029
Epoch 974/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4185 - val_loss: 1.2833 - val_accuracy: 0.4048

Epoch 00974: val_loss did not improve from 1.28029
Epoch 975/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4157 - val_loss: 1.2819 - val_accuracy: 0.4135

Epoch 00975: val_loss did not improve from 1.28029
Epoch 976/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4189 - val_loss: 1.2889 - val_accuracy: 0.4032

Epoch 00976: val_loss did not improve from 1.28029
Epoch 977/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4171 - val_loss: 1.2858 - val_accuracy: 0.4008

Epoch 00977: val_loss did not improve from 1.28029
Epoch 978/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4199 - val_loss: 1.2860 - val_accuracy: 0.4088

Epoch 00978: val_loss did not improve from 1.28029
Epoch 979/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4211 - val_loss: 1.2817 - val_accuracy: 0.4151

Epoch 00979: val_loss did not improve from 1.28029
Epoch 980/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4179 - val_loss: 1.2811 - val_accuracy: 0.3968

Epoch 00980: val_loss did not improve from 1.28029
Epoch 981/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4185 - val_loss: 1.2835 - val_accuracy: 0.4032

Epoch 00981: val_loss did not improve from 1.28029
Epoch 982/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4188 - val_loss: 1.2897 - val_accuracy: 0.3936

Epoch 00982: val_loss did not improve from 1.28029
Epoch 983/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4174 - val_loss: 1.2822 - val_accuracy: 0.4088

Epoch 00983: val_loss did not improve from 1.28029
Epoch 984/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4171 - val_loss: 1.2864 - val_accuracy: 0.4056

Epoch 00984: val_loss did not improve from 1.28029
Epoch 985/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4150 - val_loss: 1.2862 - val_accuracy: 0.4008

Epoch 00985: val_loss did not improve from 1.28029
Epoch 986/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4185 - val_loss: 1.2807 - val_accuracy: 0.4135

Epoch 00986: val_loss did not improve from 1.28029
Epoch 987/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4180 - val_loss: 1.2831 - val_accuracy: 0.4112

Epoch 00987: val_loss did not improve from 1.28029
Epoch 988/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4166 - val_loss: 1.2824 - val_accuracy: 0.4024

Epoch 00988: val_loss did not improve from 1.28029
Epoch 989/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4190 - val_loss: 1.2795 - val_accuracy: 0.4151

Epoch 00989: val_loss improved from 1.28029 to 1.27954, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 990/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4174 - val_loss: 1.2813 - val_accuracy: 0.4143

Epoch 00990: val_loss did not improve from 1.27954
Epoch 991/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4185 - val_loss: 1.2795 - val_accuracy: 0.4135

Epoch 00991: val_loss improved from 1.27954 to 1.27952, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 992/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4180 - val_loss: 1.2822 - val_accuracy: 0.4080

Epoch 00992: val_loss did not improve from 1.27952
Epoch 993/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4196 - val_loss: 1.2818 - val_accuracy: 0.4112

Epoch 00993: val_loss did not improve from 1.27952
Epoch 994/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4112 - val_loss: 1.2864 - val_accuracy: 0.4040

Epoch 00994: val_loss did not improve from 1.27952
Epoch 995/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4122 - val_loss: 1.2871 - val_accuracy: 0.3976

Epoch 00995: val_loss did not improve from 1.27952
Epoch 996/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4206 - val_loss: 1.2866 - val_accuracy: 0.4151

Epoch 00996: val_loss did not improve from 1.27952
Epoch 997/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4205 - val_loss: 1.2790 - val_accuracy: 0.4151

Epoch 00997: val_loss improved from 1.27952 to 1.27897, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 998/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4148 - val_loss: 1.2869 - val_accuracy: 0.4040

Epoch 00998: val_loss did not improve from 1.27897
Epoch 999/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4124 - val_loss: 1.2847 - val_accuracy: 0.4120

Epoch 00999: val_loss did not improve from 1.27897
Epoch 1000/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4168 - val_loss: 1.2787 - val_accuracy: 0.4127

Epoch 01000: val_loss improved from 1.27897 to 1.27871, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1001/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4191 - val_loss: 1.2803 - val_accuracy: 0.4135

Epoch 01001: val_loss did not improve from 1.27871
Epoch 1002/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4186 - val_loss: 1.2826 - val_accuracy: 0.4080

Epoch 01002: val_loss did not improve from 1.27871
Epoch 1003/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4205 - val_loss: 1.2807 - val_accuracy: 0.4151

Epoch 01003: val_loss did not improve from 1.27871
Epoch 1004/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4206 - val_loss: 1.2810 - val_accuracy: 0.4040

Epoch 01004: val_loss did not improve from 1.27871
Epoch 1005/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4218 - val_loss: 1.2807 - val_accuracy: 0.4167

Epoch 01005: val_loss did not improve from 1.27871
Epoch 1006/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4230 - val_loss: 1.2802 - val_accuracy: 0.4239

Epoch 01006: val_loss did not improve from 1.27871
Epoch 1007/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4198 - val_loss: 1.2820 - val_accuracy: 0.4143

Epoch 01007: val_loss did not improve from 1.27871
Epoch 1008/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4203 - val_loss: 1.2780 - val_accuracy: 0.4143

Epoch 01008: val_loss improved from 1.27871 to 1.27803, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1009/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4150 - val_loss: 1.2799 - val_accuracy: 0.4127

Epoch 01009: val_loss did not improve from 1.27803
Epoch 1010/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4179 - val_loss: 1.2784 - val_accuracy: 0.4048

Epoch 01010: val_loss did not improve from 1.27803
Epoch 1011/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4167 - val_loss: 1.2794 - val_accuracy: 0.4120

Epoch 01011: val_loss did not improve from 1.27803
Epoch 1012/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4163 - val_loss: 1.2807 - val_accuracy: 0.4175

Epoch 01012: val_loss did not improve from 1.27803
Epoch 1013/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4219 - val_loss: 1.2789 - val_accuracy: 0.4112

Epoch 01013: val_loss did not improve from 1.27803
Epoch 1014/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4217 - val_loss: 1.2843 - val_accuracy: 0.4120

Epoch 01014: val_loss did not improve from 1.27803
Epoch 1015/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4184 - val_loss: 1.2805 - val_accuracy: 0.4143

Epoch 01015: val_loss did not improve from 1.27803
Epoch 1016/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4183 - val_loss: 1.2803 - val_accuracy: 0.4072

Epoch 01016: val_loss did not improve from 1.27803
Epoch 1017/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4219 - val_loss: 1.2780 - val_accuracy: 0.4088

Epoch 01017: val_loss improved from 1.27803 to 1.27797, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1018/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4216 - val_loss: 1.2789 - val_accuracy: 0.4080

Epoch 01018: val_loss did not improve from 1.27797
Epoch 1019/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4186 - val_loss: 1.2855 - val_accuracy: 0.4096

Epoch 01019: val_loss did not improve from 1.27797
Epoch 1020/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4174 - val_loss: 1.2822 - val_accuracy: 0.4143

Epoch 01020: val_loss did not improve from 1.27797
Epoch 1021/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4173 - val_loss: 1.2781 - val_accuracy: 0.4127

Epoch 01021: val_loss did not improve from 1.27797
Epoch 1022/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4212 - val_loss: 1.2842 - val_accuracy: 0.4151

Epoch 01022: val_loss did not improve from 1.27797
Epoch 1023/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4205 - val_loss: 1.2794 - val_accuracy: 0.4127

Epoch 01023: val_loss did not improve from 1.27797
Epoch 1024/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4208 - val_loss: 1.2798 - val_accuracy: 0.4191

Epoch 01024: val_loss did not improve from 1.27797
Epoch 1025/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4200 - val_loss: 1.2835 - val_accuracy: 0.4080

Epoch 01025: val_loss did not improve from 1.27797
Epoch 1026/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4202 - val_loss: 1.2800 - val_accuracy: 0.4080

Epoch 01026: val_loss did not improve from 1.27797
Epoch 1027/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4203 - val_loss: 1.2814 - val_accuracy: 0.4143

Epoch 01027: val_loss did not improve from 1.27797
Epoch 1028/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4207 - val_loss: 1.2782 - val_accuracy: 0.4008

Epoch 01028: val_loss did not improve from 1.27797
Epoch 1029/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4196 - val_loss: 1.2804 - val_accuracy: 0.4104

Epoch 01029: val_loss did not improve from 1.27797
Epoch 1030/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4147 - val_loss: 1.2798 - val_accuracy: 0.4096

Epoch 01030: val_loss did not improve from 1.27797
Epoch 1031/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4186 - val_loss: 1.2830 - val_accuracy: 0.4167

Epoch 01031: val_loss did not improve from 1.27797
Epoch 1032/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4210 - val_loss: 1.2823 - val_accuracy: 0.4135

Epoch 01032: val_loss did not improve from 1.27797
Epoch 1033/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4215 - val_loss: 1.2831 - val_accuracy: 0.4120

Epoch 01033: val_loss did not improve from 1.27797
Epoch 1034/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4223 - val_loss: 1.2779 - val_accuracy: 0.4175

Epoch 01034: val_loss improved from 1.27797 to 1.27786, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1035/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4232 - val_loss: 1.2820 - val_accuracy: 0.4183

Epoch 01035: val_loss did not improve from 1.27786
Epoch 1036/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4211 - val_loss: 1.2806 - val_accuracy: 0.4072

Epoch 01036: val_loss did not improve from 1.27786
Epoch 1037/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4190 - val_loss: 1.2772 - val_accuracy: 0.4096

Epoch 01037: val_loss improved from 1.27786 to 1.27724, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1038/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4169 - val_loss: 1.2779 - val_accuracy: 0.4112

Epoch 01038: val_loss did not improve from 1.27724
Epoch 1039/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4205 - val_loss: 1.2829 - val_accuracy: 0.4080

Epoch 01039: val_loss did not improve from 1.27724
Epoch 1040/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4181 - val_loss: 1.2809 - val_accuracy: 0.4096

Epoch 01040: val_loss did not improve from 1.27724
Epoch 1041/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4186 - val_loss: 1.2817 - val_accuracy: 0.4175

Epoch 01041: val_loss did not improve from 1.27724
Epoch 1042/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4189 - val_loss: 1.2790 - val_accuracy: 0.4120

Epoch 01042: val_loss did not improve from 1.27724
Epoch 1043/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4215 - val_loss: 1.2781 - val_accuracy: 0.4088

Epoch 01043: val_loss did not improve from 1.27724
Epoch 1044/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4213 - val_loss: 1.2799 - val_accuracy: 0.4112

Epoch 01044: val_loss did not improve from 1.27724
Epoch 1045/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4170 - val_loss: 1.2771 - val_accuracy: 0.4159

Epoch 01045: val_loss improved from 1.27724 to 1.27711, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1046/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4166 - val_loss: 1.2789 - val_accuracy: 0.4080

Epoch 01046: val_loss did not improve from 1.27711
Epoch 1047/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4190 - val_loss: 1.2782 - val_accuracy: 0.4104

Epoch 01047: val_loss did not improve from 1.27711
Epoch 1048/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4203 - val_loss: 1.2770 - val_accuracy: 0.4175

Epoch 01048: val_loss improved from 1.27711 to 1.27701, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1049/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4211 - val_loss: 1.2802 - val_accuracy: 0.4159

Epoch 01049: val_loss did not improve from 1.27701
Epoch 1050/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4211 - val_loss: 1.2802 - val_accuracy: 0.4096

Epoch 01050: val_loss did not improve from 1.27701
Epoch 1051/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4182 - val_loss: 1.2806 - val_accuracy: 0.4072

Epoch 01051: val_loss did not improve from 1.27701
Epoch 1052/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4196 - val_loss: 1.2815 - val_accuracy: 0.4120

Epoch 01052: val_loss did not improve from 1.27701
Epoch 1053/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4138 - val_loss: 1.2797 - val_accuracy: 0.4135

Epoch 01053: val_loss did not improve from 1.27701
Epoch 1054/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4187 - val_loss: 1.2800 - val_accuracy: 0.4175

Epoch 01054: val_loss did not improve from 1.27701
Epoch 1055/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4245 - val_loss: 1.2796 - val_accuracy: 0.4159

Epoch 01055: val_loss did not improve from 1.27701
Epoch 1056/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4230 - val_loss: 1.2825 - val_accuracy: 0.4016

Epoch 01056: val_loss did not improve from 1.27701
Epoch 1057/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4181 - val_loss: 1.2837 - val_accuracy: 0.4048

Epoch 01057: val_loss did not improve from 1.27701
Epoch 1058/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4198 - val_loss: 1.2772 - val_accuracy: 0.4064

Epoch 01058: val_loss did not improve from 1.27701
Epoch 1059/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4208 - val_loss: 1.2775 - val_accuracy: 0.4207

Epoch 01059: val_loss did not improve from 1.27701
Epoch 1060/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4235 - val_loss: 1.2802 - val_accuracy: 0.4159

Epoch 01060: val_loss did not improve from 1.27701
Epoch 1061/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4218 - val_loss: 1.2760 - val_accuracy: 0.4096

Epoch 01061: val_loss improved from 1.27701 to 1.27602, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1062/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4206 - val_loss: 1.2840 - val_accuracy: 0.4024

Epoch 01062: val_loss did not improve from 1.27602
Epoch 1063/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4205 - val_loss: 1.2787 - val_accuracy: 0.4151

Epoch 01063: val_loss did not improve from 1.27602
Epoch 1064/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4196 - val_loss: 1.2819 - val_accuracy: 0.4056

Epoch 01064: val_loss did not improve from 1.27602
Epoch 1065/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4190 - val_loss: 1.2799 - val_accuracy: 0.4120

Epoch 01065: val_loss did not improve from 1.27602
Epoch 1066/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4181 - val_loss: 1.2770 - val_accuracy: 0.4151

Epoch 01066: val_loss did not improve from 1.27602
Epoch 1067/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4164 - val_loss: 1.2766 - val_accuracy: 0.4143

Epoch 01067: val_loss did not improve from 1.27602
Epoch 1068/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4199 - val_loss: 1.2805 - val_accuracy: 0.4135

Epoch 01068: val_loss did not improve from 1.27602
Epoch 1069/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4208 - val_loss: 1.2801 - val_accuracy: 0.4040

Epoch 01069: val_loss did not improve from 1.27602
Epoch 1070/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4227 - val_loss: 1.2794 - val_accuracy: 0.4159

Epoch 01070: val_loss did not improve from 1.27602
Epoch 1071/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4229 - val_loss: 1.2881 - val_accuracy: 0.4104

Epoch 01071: val_loss did not improve from 1.27602
Epoch 1072/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4153 - val_loss: 1.2828 - val_accuracy: 0.4072

Epoch 01072: val_loss did not improve from 1.27602
Epoch 1073/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4175 - val_loss: 1.2772 - val_accuracy: 0.4143

Epoch 01073: val_loss did not improve from 1.27602
Epoch 1074/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4211 - val_loss: 1.2845 - val_accuracy: 0.4088

Epoch 01074: val_loss did not improve from 1.27602
Epoch 1075/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4217 - val_loss: 1.2880 - val_accuracy: 0.4072

Epoch 01075: val_loss did not improve from 1.27602
Epoch 1076/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4212 - val_loss: 1.2834 - val_accuracy: 0.3960

Epoch 01076: val_loss did not improve from 1.27602
Epoch 1077/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4210 - val_loss: 1.2798 - val_accuracy: 0.4120

Epoch 01077: val_loss did not improve from 1.27602
Epoch 1078/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4199 - val_loss: 1.2804 - val_accuracy: 0.4104

Epoch 01078: val_loss did not improve from 1.27602
Epoch 1079/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4190 - val_loss: 1.2787 - val_accuracy: 0.4072

Epoch 01079: val_loss did not improve from 1.27602
Epoch 1080/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4198 - val_loss: 1.2778 - val_accuracy: 0.4135

Epoch 01080: val_loss did not improve from 1.27602
Epoch 1081/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4183 - val_loss: 1.2786 - val_accuracy: 0.4096

Epoch 01081: val_loss did not improve from 1.27602
Epoch 1082/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4197 - val_loss: 1.2811 - val_accuracy: 0.4127

Epoch 01082: val_loss did not improve from 1.27602
Epoch 1083/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4190 - val_loss: 1.2766 - val_accuracy: 0.4112

Epoch 01083: val_loss did not improve from 1.27602
Epoch 1084/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4206 - val_loss: 1.2761 - val_accuracy: 0.4223

Epoch 01084: val_loss did not improve from 1.27602
Epoch 1085/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4222 - val_loss: 1.2805 - val_accuracy: 0.4104

Epoch 01085: val_loss did not improve from 1.27602
Epoch 1086/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4198 - val_loss: 1.2795 - val_accuracy: 0.4223

Epoch 01086: val_loss did not improve from 1.27602
Epoch 1087/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4201 - val_loss: 1.2781 - val_accuracy: 0.4159

Epoch 01087: val_loss did not improve from 1.27602
Epoch 1088/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4205 - val_loss: 1.2770 - val_accuracy: 0.4127

Epoch 01088: val_loss did not improve from 1.27602
Epoch 1089/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4184 - val_loss: 1.2797 - val_accuracy: 0.4143

Epoch 01089: val_loss did not improve from 1.27602
Epoch 1090/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4194 - val_loss: 1.2818 - val_accuracy: 0.3968

Epoch 01090: val_loss did not improve from 1.27602
Epoch 1091/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4190 - val_loss: 1.2796 - val_accuracy: 0.4088

Epoch 01091: val_loss did not improve from 1.27602
Epoch 1092/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4167 - val_loss: 1.2771 - val_accuracy: 0.4127

Epoch 01092: val_loss did not improve from 1.27602
Epoch 1093/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4230 - val_loss: 1.2799 - val_accuracy: 0.4072

Epoch 01093: val_loss did not improve from 1.27602
Epoch 1094/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4168 - val_loss: 1.2802 - val_accuracy: 0.4072

Epoch 01094: val_loss did not improve from 1.27602
Epoch 1095/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4198 - val_loss: 1.2768 - val_accuracy: 0.4080

Epoch 01095: val_loss did not improve from 1.27602
Epoch 1096/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4195 - val_loss: 1.2767 - val_accuracy: 0.4104

Epoch 01096: val_loss did not improve from 1.27602
Epoch 1097/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4211 - val_loss: 1.2810 - val_accuracy: 0.4072

Epoch 01097: val_loss did not improve from 1.27602
Epoch 1098/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4183 - val_loss: 1.2762 - val_accuracy: 0.4104

Epoch 01098: val_loss did not improve from 1.27602
Epoch 1099/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4186 - val_loss: 1.2833 - val_accuracy: 0.4120

Epoch 01099: val_loss did not improve from 1.27602
Epoch 1100/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4195 - val_loss: 1.2835 - val_accuracy: 0.4048

Epoch 01100: val_loss did not improve from 1.27602
Epoch 1101/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4160 - val_loss: 1.2786 - val_accuracy: 0.4207

Epoch 01101: val_loss did not improve from 1.27602
Epoch 1102/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4205 - val_loss: 1.2768 - val_accuracy: 0.4159

Epoch 01102: val_loss did not improve from 1.27602
Epoch 1103/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4164 - val_loss: 1.2768 - val_accuracy: 0.4167

Epoch 01103: val_loss did not improve from 1.27602
Epoch 1104/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4208 - val_loss: 1.2808 - val_accuracy: 0.4223

Epoch 01104: val_loss did not improve from 1.27602
Epoch 1105/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4206 - val_loss: 1.2775 - val_accuracy: 0.4056

Epoch 01105: val_loss did not improve from 1.27602
Epoch 1106/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4187 - val_loss: 1.2770 - val_accuracy: 0.4167

Epoch 01106: val_loss did not improve from 1.27602
Epoch 1107/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4179 - val_loss: 1.2806 - val_accuracy: 0.4112

Epoch 01107: val_loss did not improve from 1.27602
Epoch 1108/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4200 - val_loss: 1.2781 - val_accuracy: 0.4032

Epoch 01108: val_loss did not improve from 1.27602
Epoch 1109/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4159 - val_loss: 1.2785 - val_accuracy: 0.4104

Epoch 01109: val_loss did not improve from 1.27602
Epoch 1110/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4187 - val_loss: 1.2784 - val_accuracy: 0.4016

Epoch 01110: val_loss did not improve from 1.27602
Epoch 1111/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4182 - val_loss: 1.2776 - val_accuracy: 0.4088

Epoch 01111: val_loss did not improve from 1.27602
Epoch 1112/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4221 - val_loss: 1.2799 - val_accuracy: 0.4127

Epoch 01112: val_loss did not improve from 1.27602
Epoch 1113/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4217 - val_loss: 1.2795 - val_accuracy: 0.4143

Epoch 01113: val_loss did not improve from 1.27602
Epoch 1114/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4188 - val_loss: 1.2766 - val_accuracy: 0.4080

Epoch 01114: val_loss did not improve from 1.27602
Epoch 1115/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4186 - val_loss: 1.2788 - val_accuracy: 0.4175

Epoch 01115: val_loss did not improve from 1.27602
Epoch 1116/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4198 - val_loss: 1.2768 - val_accuracy: 0.4223

Epoch 01116: val_loss did not improve from 1.27602
Epoch 1117/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4204 - val_loss: 1.2784 - val_accuracy: 0.4191

Epoch 01117: val_loss did not improve from 1.27602
Epoch 1118/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4166 - val_loss: 1.2831 - val_accuracy: 0.4064

Epoch 01118: val_loss did not improve from 1.27602
Epoch 1119/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4202 - val_loss: 1.2764 - val_accuracy: 0.4120

Epoch 01119: val_loss did not improve from 1.27602
Epoch 1120/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4205 - val_loss: 1.2779 - val_accuracy: 0.4127

Epoch 01120: val_loss did not improve from 1.27602
Epoch 1121/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4153 - val_loss: 1.2788 - val_accuracy: 0.4056

Epoch 01121: val_loss did not improve from 1.27602
Epoch 1122/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4208 - val_loss: 1.2778 - val_accuracy: 0.4088

Epoch 01122: val_loss did not improve from 1.27602
Epoch 1123/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4188 - val_loss: 1.2762 - val_accuracy: 0.4143

Epoch 01123: val_loss did not improve from 1.27602
Epoch 1124/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4216 - val_loss: 1.2760 - val_accuracy: 0.4135

Epoch 01124: val_loss improved from 1.27602 to 1.27597, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1125/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4193 - val_loss: 1.2787 - val_accuracy: 0.4096

Epoch 01125: val_loss did not improve from 1.27597
Epoch 1126/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4220 - val_loss: 1.2767 - val_accuracy: 0.4151

Epoch 01126: val_loss did not improve from 1.27597
Epoch 1127/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4236 - val_loss: 1.2760 - val_accuracy: 0.4135

Epoch 01127: val_loss did not improve from 1.27597
Epoch 1128/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4235 - val_loss: 1.2775 - val_accuracy: 0.4127

Epoch 01128: val_loss did not improve from 1.27597
Epoch 1129/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4214 - val_loss: 1.2762 - val_accuracy: 0.4167

Epoch 01129: val_loss did not improve from 1.27597
Epoch 1130/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4179 - val_loss: 1.2819 - val_accuracy: 0.3952

Epoch 01130: val_loss did not improve from 1.27597
Epoch 1131/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4204 - val_loss: 1.2785 - val_accuracy: 0.4151

Epoch 01131: val_loss did not improve from 1.27597
Epoch 1132/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4195 - val_loss: 1.2760 - val_accuracy: 0.4120

Epoch 01132: val_loss did not improve from 1.27597
Epoch 1133/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4182 - val_loss: 1.2770 - val_accuracy: 0.4112

Epoch 01133: val_loss did not improve from 1.27597
Epoch 1134/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4197 - val_loss: 1.2759 - val_accuracy: 0.4223

Epoch 01134: val_loss improved from 1.27597 to 1.27586, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1135/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4195 - val_loss: 1.2767 - val_accuracy: 0.4096

Epoch 01135: val_loss did not improve from 1.27586
Epoch 1136/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4176 - val_loss: 1.2806 - val_accuracy: 0.4040

Epoch 01136: val_loss did not improve from 1.27586
Epoch 1137/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4179 - val_loss: 1.2768 - val_accuracy: 0.4104

Epoch 01137: val_loss did not improve from 1.27586
Epoch 1138/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4208 - val_loss: 1.2786 - val_accuracy: 0.4143

Epoch 01138: val_loss did not improve from 1.27586
Epoch 1139/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4212 - val_loss: 1.2767 - val_accuracy: 0.4199

Epoch 01139: val_loss did not improve from 1.27586
Epoch 1140/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4218 - val_loss: 1.2773 - val_accuracy: 0.4120

Epoch 01140: val_loss did not improve from 1.27586
Epoch 1141/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4214 - val_loss: 1.2817 - val_accuracy: 0.4080

Epoch 01141: val_loss did not improve from 1.27586
Epoch 1142/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4159 - val_loss: 1.2817 - val_accuracy: 0.3976

Epoch 01142: val_loss did not improve from 1.27586
Epoch 1143/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4156 - val_loss: 1.2757 - val_accuracy: 0.4048

Epoch 01143: val_loss improved from 1.27586 to 1.27571, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1144/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4179 - val_loss: 1.2759 - val_accuracy: 0.4000

Epoch 01144: val_loss did not improve from 1.27571
Epoch 1145/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4205 - val_loss: 1.2813 - val_accuracy: 0.4120

Epoch 01145: val_loss did not improve from 1.27571
Epoch 1146/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4177 - val_loss: 1.2762 - val_accuracy: 0.4135

Epoch 01146: val_loss did not improve from 1.27571
Epoch 1147/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4224 - val_loss: 1.2810 - val_accuracy: 0.4112

Epoch 01147: val_loss did not improve from 1.27571
Epoch 1148/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4219 - val_loss: 1.2811 - val_accuracy: 0.4024

Epoch 01148: val_loss did not improve from 1.27571
Epoch 1149/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4215 - val_loss: 1.2793 - val_accuracy: 0.4024

Epoch 01149: val_loss did not improve from 1.27571
Epoch 1150/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4168 - val_loss: 1.2855 - val_accuracy: 0.4000

Epoch 01150: val_loss did not improve from 1.27571
Epoch 1151/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4224 - val_loss: 1.2795 - val_accuracy: 0.4064

Epoch 01151: val_loss did not improve from 1.27571
Epoch 1152/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4154 - val_loss: 1.2758 - val_accuracy: 0.4143

Epoch 01152: val_loss did not improve from 1.27571
Epoch 1153/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4154 - val_loss: 1.2814 - val_accuracy: 0.4064

Epoch 01153: val_loss did not improve from 1.27571
Epoch 1154/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4201 - val_loss: 1.2766 - val_accuracy: 0.4151

Epoch 01154: val_loss did not improve from 1.27571
Epoch 1155/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4195 - val_loss: 1.2777 - val_accuracy: 0.4064

Epoch 01155: val_loss did not improve from 1.27571
Epoch 1156/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4181 - val_loss: 1.2783 - val_accuracy: 0.4040

Epoch 01156: val_loss did not improve from 1.27571
Epoch 1157/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4178 - val_loss: 1.2774 - val_accuracy: 0.4080

Epoch 01157: val_loss did not improve from 1.27571
Epoch 1158/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4191 - val_loss: 1.2760 - val_accuracy: 0.4127

Epoch 01158: val_loss did not improve from 1.27571
Epoch 1159/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4192 - val_loss: 1.2771 - val_accuracy: 0.4112

Epoch 01159: val_loss did not improve from 1.27571
Epoch 1160/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4191 - val_loss: 1.2745 - val_accuracy: 0.4072

Epoch 01160: val_loss improved from 1.27571 to 1.27446, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1161/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4186 - val_loss: 1.2775 - val_accuracy: 0.4167

Epoch 01161: val_loss did not improve from 1.27446
Epoch 1162/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4190 - val_loss: 1.2794 - val_accuracy: 0.4088

Epoch 01162: val_loss did not improve from 1.27446
Epoch 1163/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4155 - val_loss: 1.2798 - val_accuracy: 0.4135

Epoch 01163: val_loss did not improve from 1.27446
Epoch 1164/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4214 - val_loss: 1.2767 - val_accuracy: 0.4135

Epoch 01164: val_loss did not improve from 1.27446
Epoch 1165/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4213 - val_loss: 1.2762 - val_accuracy: 0.4112

Epoch 01165: val_loss did not improve from 1.27446
Epoch 1166/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4221 - val_loss: 1.2756 - val_accuracy: 0.4191

Epoch 01166: val_loss did not improve from 1.27446
Epoch 1167/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4216 - val_loss: 1.2800 - val_accuracy: 0.4032

Epoch 01167: val_loss did not improve from 1.27446
Epoch 1168/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4150 - val_loss: 1.2754 - val_accuracy: 0.4072

Epoch 01168: val_loss did not improve from 1.27446
Epoch 1169/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4198 - val_loss: 1.2774 - val_accuracy: 0.4191

Epoch 01169: val_loss did not improve from 1.27446
Epoch 1170/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4216 - val_loss: 1.2749 - val_accuracy: 0.4072

Epoch 01170: val_loss did not improve from 1.27446
Epoch 1171/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4220 - val_loss: 1.2807 - val_accuracy: 0.4056

Epoch 01171: val_loss did not improve from 1.27446
Epoch 1172/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4193 - val_loss: 1.2762 - val_accuracy: 0.4112

Epoch 01172: val_loss did not improve from 1.27446
Epoch 1173/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4165 - val_loss: 1.2771 - val_accuracy: 0.4072

Epoch 01173: val_loss did not improve from 1.27446
Epoch 1174/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4178 - val_loss: 1.2758 - val_accuracy: 0.4104

Epoch 01174: val_loss did not improve from 1.27446
Epoch 1175/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4206 - val_loss: 1.2797 - val_accuracy: 0.4151

Epoch 01175: val_loss did not improve from 1.27446
Epoch 1176/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4182 - val_loss: 1.2762 - val_accuracy: 0.4135

Epoch 01176: val_loss did not improve from 1.27446
Epoch 1177/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4209 - val_loss: 1.2779 - val_accuracy: 0.4207

Epoch 01177: val_loss did not improve from 1.27446
Epoch 1178/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4249 - val_loss: 1.2788 - val_accuracy: 0.4096

Epoch 01178: val_loss did not improve from 1.27446
Epoch 1179/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4206 - val_loss: 1.2771 - val_accuracy: 0.4088

Epoch 01179: val_loss did not improve from 1.27446
Epoch 1180/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4217 - val_loss: 1.2761 - val_accuracy: 0.4191

Epoch 01180: val_loss did not improve from 1.27446
Epoch 1181/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4189 - val_loss: 1.2755 - val_accuracy: 0.4056

Epoch 01181: val_loss did not improve from 1.27446
Epoch 1182/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4197 - val_loss: 1.2785 - val_accuracy: 0.4080

Epoch 01182: val_loss did not improve from 1.27446
Epoch 1183/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4208 - val_loss: 1.2770 - val_accuracy: 0.4183

Epoch 01183: val_loss did not improve from 1.27446
Epoch 1184/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4222 - val_loss: 1.2756 - val_accuracy: 0.4191

Epoch 01184: val_loss did not improve from 1.27446
Epoch 1185/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4189 - val_loss: 1.2795 - val_accuracy: 0.4191

Epoch 01185: val_loss did not improve from 1.27446
Epoch 1186/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4210 - val_loss: 1.2775 - val_accuracy: 0.4032

Epoch 01186: val_loss did not improve from 1.27446
Epoch 1187/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4182 - val_loss: 1.2784 - val_accuracy: 0.4072

Epoch 01187: val_loss did not improve from 1.27446
Epoch 1188/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4168 - val_loss: 1.2786 - val_accuracy: 0.4135

Epoch 01188: val_loss did not improve from 1.27446
Epoch 1189/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4225 - val_loss: 1.2760 - val_accuracy: 0.4151

Epoch 01189: val_loss did not improve from 1.27446
Epoch 1190/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4199 - val_loss: 1.2759 - val_accuracy: 0.4143

Epoch 01190: val_loss did not improve from 1.27446
Epoch 1191/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4226 - val_loss: 1.2784 - val_accuracy: 0.4120

Epoch 01191: val_loss did not improve from 1.27446
Epoch 1192/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4161 - val_loss: 1.2780 - val_accuracy: 0.4008

Epoch 01192: val_loss did not improve from 1.27446
Epoch 1193/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4220 - val_loss: 1.2780 - val_accuracy: 0.4159

Epoch 01193: val_loss did not improve from 1.27446
Epoch 1194/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4194 - val_loss: 1.2787 - val_accuracy: 0.4104

Epoch 01194: val_loss did not improve from 1.27446
Epoch 1195/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4231 - val_loss: 1.2781 - val_accuracy: 0.4207

Epoch 01195: val_loss did not improve from 1.27446
Epoch 1196/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4216 - val_loss: 1.2766 - val_accuracy: 0.4080

Epoch 01196: val_loss did not improve from 1.27446
Epoch 1197/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4233 - val_loss: 1.2769 - val_accuracy: 0.4191

Epoch 01197: val_loss did not improve from 1.27446
Epoch 1198/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4196 - val_loss: 1.2781 - val_accuracy: 0.4199

Epoch 01198: val_loss did not improve from 1.27446
Epoch 1199/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4191 - val_loss: 1.2811 - val_accuracy: 0.3952

Epoch 01199: val_loss did not improve from 1.27446
Epoch 1200/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4234 - val_loss: 1.2899 - val_accuracy: 0.3928

Epoch 01200: val_loss did not improve from 1.27446
Epoch 1201/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4187 - val_loss: 1.2761 - val_accuracy: 0.4104

Epoch 01201: val_loss did not improve from 1.27446
Epoch 1202/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4186 - val_loss: 1.2759 - val_accuracy: 0.4088

Epoch 01202: val_loss did not improve from 1.27446
Epoch 1203/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4190 - val_loss: 1.2833 - val_accuracy: 0.4072

Epoch 01203: val_loss did not improve from 1.27446
Epoch 1204/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4207 - val_loss: 1.2770 - val_accuracy: 0.4064

Epoch 01204: val_loss did not improve from 1.27446
Epoch 1205/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4207 - val_loss: 1.2761 - val_accuracy: 0.4135

Epoch 01205: val_loss did not improve from 1.27446
Epoch 1206/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4161 - val_loss: 1.2797 - val_accuracy: 0.4104

Epoch 01206: val_loss did not improve from 1.27446
Epoch 1207/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4177 - val_loss: 1.2771 - val_accuracy: 0.4096

Epoch 01207: val_loss did not improve from 1.27446
Epoch 1208/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4184 - val_loss: 1.2786 - val_accuracy: 0.4151

Epoch 01208: val_loss did not improve from 1.27446
Epoch 1209/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4203 - val_loss: 1.2758 - val_accuracy: 0.4183

Epoch 01209: val_loss did not improve from 1.27446
Epoch 1210/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4215 - val_loss: 1.2744 - val_accuracy: 0.4167

Epoch 01210: val_loss improved from 1.27446 to 1.27436, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1211/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4197 - val_loss: 1.2761 - val_accuracy: 0.4215

Epoch 01211: val_loss did not improve from 1.27436
Epoch 1212/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4205 - val_loss: 1.2771 - val_accuracy: 0.4096

Epoch 01212: val_loss did not improve from 1.27436
Epoch 1213/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4212 - val_loss: 1.2756 - val_accuracy: 0.4127

Epoch 01213: val_loss did not improve from 1.27436
Epoch 1214/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4215 - val_loss: 1.2779 - val_accuracy: 0.4175

Epoch 01214: val_loss did not improve from 1.27436
Epoch 1215/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4181 - val_loss: 1.2755 - val_accuracy: 0.4143

Epoch 01215: val_loss did not improve from 1.27436
Epoch 1216/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4155 - val_loss: 1.2841 - val_accuracy: 0.4120

Epoch 01216: val_loss did not improve from 1.27436
Epoch 1217/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4188 - val_loss: 1.2759 - val_accuracy: 0.4040

Epoch 01217: val_loss did not improve from 1.27436
Epoch 1218/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4214 - val_loss: 1.2791 - val_accuracy: 0.4175

Epoch 01218: val_loss did not improve from 1.27436
Epoch 1219/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4204 - val_loss: 1.2793 - val_accuracy: 0.4135

Epoch 01219: val_loss did not improve from 1.27436
Epoch 1220/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4180 - val_loss: 1.2740 - val_accuracy: 0.4151

Epoch 01220: val_loss improved from 1.27436 to 1.27404, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1221/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4197 - val_loss: 1.2770 - val_accuracy: 0.4127

Epoch 01221: val_loss did not improve from 1.27404
Epoch 1222/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4201 - val_loss: 1.2782 - val_accuracy: 0.4215

Epoch 01222: val_loss did not improve from 1.27404
Epoch 1223/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4208 - val_loss: 1.2758 - val_accuracy: 0.4096

Epoch 01223: val_loss did not improve from 1.27404
Epoch 1224/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4168 - val_loss: 1.2787 - val_accuracy: 0.4135

Epoch 01224: val_loss did not improve from 1.27404
Epoch 1225/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4225 - val_loss: 1.2798 - val_accuracy: 0.4207

Epoch 01225: val_loss did not improve from 1.27404
Epoch 1226/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4230 - val_loss: 1.2740 - val_accuracy: 0.4064

Epoch 01226: val_loss improved from 1.27404 to 1.27395, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1227/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4216 - val_loss: 1.2792 - val_accuracy: 0.4040

Epoch 01227: val_loss did not improve from 1.27395
Epoch 1228/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4231 - val_loss: 1.2742 - val_accuracy: 0.4207

Epoch 01228: val_loss did not improve from 1.27395
Epoch 1229/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4224 - val_loss: 1.2749 - val_accuracy: 0.4112

Epoch 01229: val_loss did not improve from 1.27395
Epoch 1230/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4217 - val_loss: 1.2782 - val_accuracy: 0.4048

Epoch 01230: val_loss did not improve from 1.27395
Epoch 1231/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4225 - val_loss: 1.2791 - val_accuracy: 0.4104

Epoch 01231: val_loss did not improve from 1.27395
Epoch 1232/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4201 - val_loss: 1.2755 - val_accuracy: 0.4040

Epoch 01232: val_loss did not improve from 1.27395
Epoch 1233/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4194 - val_loss: 1.2775 - val_accuracy: 0.4096

Epoch 01233: val_loss did not improve from 1.27395
Epoch 1234/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4204 - val_loss: 1.2764 - val_accuracy: 0.4159

Epoch 01234: val_loss did not improve from 1.27395
Epoch 1235/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4201 - val_loss: 1.2767 - val_accuracy: 0.4127

Epoch 01235: val_loss did not improve from 1.27395
Epoch 1236/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4190 - val_loss: 1.2833 - val_accuracy: 0.4024

Epoch 01236: val_loss did not improve from 1.27395
Epoch 1237/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4194 - val_loss: 1.2802 - val_accuracy: 0.3992

Epoch 01237: val_loss did not improve from 1.27395
Epoch 1238/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4190 - val_loss: 1.2795 - val_accuracy: 0.4064

Epoch 01238: val_loss did not improve from 1.27395
Epoch 1239/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4220 - val_loss: 1.2748 - val_accuracy: 0.4199

Epoch 01239: val_loss did not improve from 1.27395
Epoch 1240/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4208 - val_loss: 1.2777 - val_accuracy: 0.4127

Epoch 01240: val_loss did not improve from 1.27395
Epoch 1241/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4227 - val_loss: 1.2762 - val_accuracy: 0.4032

Epoch 01241: val_loss did not improve from 1.27395
Epoch 1242/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4204 - val_loss: 1.2754 - val_accuracy: 0.4191

Epoch 01242: val_loss did not improve from 1.27395
Epoch 1243/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4187 - val_loss: 1.2754 - val_accuracy: 0.4199

Epoch 01243: val_loss did not improve from 1.27395
Epoch 1244/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4211 - val_loss: 1.2750 - val_accuracy: 0.4127

Epoch 01244: val_loss did not improve from 1.27395
Epoch 1245/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4198 - val_loss: 1.2781 - val_accuracy: 0.4104

Epoch 01245: val_loss did not improve from 1.27395
Epoch 1246/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4213 - val_loss: 1.2773 - val_accuracy: 0.4143

Epoch 01246: val_loss did not improve from 1.27395
Epoch 1247/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4234 - val_loss: 1.2754 - val_accuracy: 0.4112

Epoch 01247: val_loss did not improve from 1.27395
Epoch 1248/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4190 - val_loss: 1.2756 - val_accuracy: 0.4167

Epoch 01248: val_loss did not improve from 1.27395
Epoch 1249/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4170 - val_loss: 1.2780 - val_accuracy: 0.4191

Epoch 01249: val_loss did not improve from 1.27395
Epoch 1250/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4197 - val_loss: 1.2754 - val_accuracy: 0.4104

Epoch 01250: val_loss did not improve from 1.27395
Epoch 1251/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4188 - val_loss: 1.2769 - val_accuracy: 0.4072

Epoch 01251: val_loss did not improve from 1.27395
Epoch 1252/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4224 - val_loss: 1.2779 - val_accuracy: 0.4135

Epoch 01252: val_loss did not improve from 1.27395
Epoch 1253/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4205 - val_loss: 1.2774 - val_accuracy: 0.4135

Epoch 01253: val_loss did not improve from 1.27395
Epoch 1254/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4178 - val_loss: 1.2763 - val_accuracy: 0.4024

Epoch 01254: val_loss did not improve from 1.27395
Epoch 1255/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4235 - val_loss: 1.2878 - val_accuracy: 0.4040

Epoch 01255: val_loss did not improve from 1.27395
Epoch 1256/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4128 - val_loss: 1.2776 - val_accuracy: 0.4127

Epoch 01256: val_loss did not improve from 1.27395
Epoch 1257/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4143 - val_loss: 1.2783 - val_accuracy: 0.4096

Epoch 01257: val_loss did not improve from 1.27395
Epoch 1258/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4197 - val_loss: 1.2747 - val_accuracy: 0.4183

Epoch 01258: val_loss did not improve from 1.27395
Epoch 1259/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4177 - val_loss: 1.2748 - val_accuracy: 0.4199

Epoch 01259: val_loss did not improve from 1.27395
Epoch 1260/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4234 - val_loss: 1.2788 - val_accuracy: 0.4207

Epoch 01260: val_loss did not improve from 1.27395
Epoch 1261/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4244 - val_loss: 1.2757 - val_accuracy: 0.4159

Epoch 01261: val_loss did not improve from 1.27395
Epoch 1262/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4120 - val_loss: 1.2811 - val_accuracy: 0.4088

Epoch 01262: val_loss did not improve from 1.27395
Epoch 1263/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4199 - val_loss: 1.2805 - val_accuracy: 0.4199

Epoch 01263: val_loss did not improve from 1.27395
Epoch 1264/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4193 - val_loss: 1.2776 - val_accuracy: 0.4072

Epoch 01264: val_loss did not improve from 1.27395
Epoch 1265/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4188 - val_loss: 1.2749 - val_accuracy: 0.4127

Epoch 01265: val_loss did not improve from 1.27395
Epoch 1266/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4198 - val_loss: 1.2757 - val_accuracy: 0.4088

Epoch 01266: val_loss did not improve from 1.27395
Epoch 1267/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4212 - val_loss: 1.2784 - val_accuracy: 0.4080

Epoch 01267: val_loss did not improve from 1.27395
Epoch 1268/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4182 - val_loss: 1.2770 - val_accuracy: 0.4175

Epoch 01268: val_loss did not improve from 1.27395
Epoch 1269/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4252 - val_loss: 1.2754 - val_accuracy: 0.4159

Epoch 01269: val_loss did not improve from 1.27395
Epoch 1270/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4222 - val_loss: 1.2745 - val_accuracy: 0.4159

Epoch 01270: val_loss did not improve from 1.27395
Epoch 1271/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4226 - val_loss: 1.2759 - val_accuracy: 0.4199

Epoch 01271: val_loss did not improve from 1.27395
Epoch 1272/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4203 - val_loss: 1.2742 - val_accuracy: 0.4072

Epoch 01272: val_loss did not improve from 1.27395
Epoch 1273/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4201 - val_loss: 1.2813 - val_accuracy: 0.4072

Epoch 01273: val_loss did not improve from 1.27395
Epoch 1274/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4222 - val_loss: 1.2806 - val_accuracy: 0.4064

Epoch 01274: val_loss did not improve from 1.27395
Epoch 1275/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4191 - val_loss: 1.2785 - val_accuracy: 0.3968

Epoch 01275: val_loss did not improve from 1.27395
Epoch 1276/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4233 - val_loss: 1.2786 - val_accuracy: 0.4064

Epoch 01276: val_loss did not improve from 1.27395
Epoch 1277/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4205 - val_loss: 1.2780 - val_accuracy: 0.3928

Epoch 01277: val_loss did not improve from 1.27395
Epoch 1278/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4201 - val_loss: 1.2779 - val_accuracy: 0.4151

Epoch 01278: val_loss did not improve from 1.27395
Epoch 1279/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4195 - val_loss: 1.2733 - val_accuracy: 0.4104

Epoch 01279: val_loss improved from 1.27395 to 1.27331, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1280/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4252 - val_loss: 1.2746 - val_accuracy: 0.4143

Epoch 01280: val_loss did not improve from 1.27331
Epoch 1281/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4197 - val_loss: 1.2775 - val_accuracy: 0.3976

Epoch 01281: val_loss did not improve from 1.27331
Epoch 1282/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4188 - val_loss: 1.2753 - val_accuracy: 0.4000

Epoch 01282: val_loss did not improve from 1.27331
Epoch 1283/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4207 - val_loss: 1.2797 - val_accuracy: 0.4104

Epoch 01283: val_loss did not improve from 1.27331
Epoch 1284/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4167 - val_loss: 1.2773 - val_accuracy: 0.3992

Epoch 01284: val_loss did not improve from 1.27331
Epoch 1285/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4198 - val_loss: 1.2768 - val_accuracy: 0.4175

Epoch 01285: val_loss did not improve from 1.27331
Epoch 1286/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4229 - val_loss: 1.2774 - val_accuracy: 0.4104

Epoch 01286: val_loss did not improve from 1.27331
Epoch 1287/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4183 - val_loss: 1.2770 - val_accuracy: 0.4127

Epoch 01287: val_loss did not improve from 1.27331
Epoch 1288/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4237 - val_loss: 1.2753 - val_accuracy: 0.4247

Epoch 01288: val_loss did not improve from 1.27331
Epoch 1289/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4244 - val_loss: 1.2780 - val_accuracy: 0.4199

Epoch 01289: val_loss did not improve from 1.27331
Epoch 1290/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4178 - val_loss: 1.2798 - val_accuracy: 0.4104

Epoch 01290: val_loss did not improve from 1.27331
Epoch 1291/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4182 - val_loss: 1.2733 - val_accuracy: 0.4143

Epoch 01291: val_loss improved from 1.27331 to 1.27325, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1292/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4181 - val_loss: 1.2803 - val_accuracy: 0.4080

Epoch 01292: val_loss did not improve from 1.27325
Epoch 1293/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4183 - val_loss: 1.2750 - val_accuracy: 0.4207

Epoch 01293: val_loss did not improve from 1.27325
Epoch 1294/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4254 - val_loss: 1.2795 - val_accuracy: 0.4175

Epoch 01294: val_loss did not improve from 1.27325
Epoch 1295/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4220 - val_loss: 1.2756 - val_accuracy: 0.4159

Epoch 01295: val_loss did not improve from 1.27325
Epoch 1296/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4199 - val_loss: 1.2795 - val_accuracy: 0.4080

Epoch 01296: val_loss did not improve from 1.27325
Epoch 1297/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4200 - val_loss: 1.2755 - val_accuracy: 0.4143

Epoch 01297: val_loss did not improve from 1.27325
Epoch 1298/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4228 - val_loss: 1.2774 - val_accuracy: 0.4120

Epoch 01298: val_loss did not improve from 1.27325
Epoch 1299/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4205 - val_loss: 1.2739 - val_accuracy: 0.4167

Epoch 01299: val_loss did not improve from 1.27325
Epoch 1300/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4205 - val_loss: 1.2738 - val_accuracy: 0.4151

Epoch 01300: val_loss did not improve from 1.27325
Epoch 1301/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4253 - val_loss: 1.2728 - val_accuracy: 0.4207

Epoch 01301: val_loss improved from 1.27325 to 1.27276, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1302/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4209 - val_loss: 1.2766 - val_accuracy: 0.4112

Epoch 01302: val_loss did not improve from 1.27276
Epoch 1303/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4205 - val_loss: 1.2732 - val_accuracy: 0.4120

Epoch 01303: val_loss did not improve from 1.27276
Epoch 1304/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4237 - val_loss: 1.2754 - val_accuracy: 0.4183

Epoch 01304: val_loss did not improve from 1.27276
Epoch 1305/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4200 - val_loss: 1.2788 - val_accuracy: 0.3976

Epoch 01305: val_loss did not improve from 1.27276
Epoch 1306/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4199 - val_loss: 1.2784 - val_accuracy: 0.4127

Epoch 01306: val_loss did not improve from 1.27276
Epoch 1307/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4185 - val_loss: 1.2776 - val_accuracy: 0.4056

Epoch 01307: val_loss did not improve from 1.27276
Epoch 1308/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4185 - val_loss: 1.2754 - val_accuracy: 0.4135

Epoch 01308: val_loss did not improve from 1.27276
Epoch 1309/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4221 - val_loss: 1.2825 - val_accuracy: 0.4064

Epoch 01309: val_loss did not improve from 1.27276
Epoch 1310/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4188 - val_loss: 1.2740 - val_accuracy: 0.4135

Epoch 01310: val_loss did not improve from 1.27276
Epoch 1311/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4221 - val_loss: 1.2751 - val_accuracy: 0.4159

Epoch 01311: val_loss did not improve from 1.27276
Epoch 1312/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4221 - val_loss: 1.2769 - val_accuracy: 0.4096

Epoch 01312: val_loss did not improve from 1.27276
Epoch 1313/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4195 - val_loss: 1.2747 - val_accuracy: 0.4151

Epoch 01313: val_loss did not improve from 1.27276
Epoch 1314/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4244 - val_loss: 1.2764 - val_accuracy: 0.4215

Epoch 01314: val_loss did not improve from 1.27276
Epoch 1315/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4229 - val_loss: 1.2769 - val_accuracy: 0.4112

Epoch 01315: val_loss did not improve from 1.27276
Epoch 1316/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4201 - val_loss: 1.2760 - val_accuracy: 0.4127

Epoch 01316: val_loss did not improve from 1.27276
Epoch 1317/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4208 - val_loss: 1.2763 - val_accuracy: 0.4096

Epoch 01317: val_loss did not improve from 1.27276
Epoch 1318/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4232 - val_loss: 1.2743 - val_accuracy: 0.4064

Epoch 01318: val_loss did not improve from 1.27276
Epoch 1319/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4197 - val_loss: 1.2762 - val_accuracy: 0.4127

Epoch 01319: val_loss did not improve from 1.27276
Epoch 1320/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4191 - val_loss: 1.2764 - val_accuracy: 0.4112

Epoch 01320: val_loss did not improve from 1.27276
Epoch 1321/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4204 - val_loss: 1.2775 - val_accuracy: 0.4120

Epoch 01321: val_loss did not improve from 1.27276
Epoch 1322/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4201 - val_loss: 1.2766 - val_accuracy: 0.4112

Epoch 01322: val_loss did not improve from 1.27276
Epoch 1323/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4220 - val_loss: 1.2742 - val_accuracy: 0.4175

Epoch 01323: val_loss did not improve from 1.27276
Epoch 1324/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4245 - val_loss: 1.2729 - val_accuracy: 0.4127

Epoch 01324: val_loss did not improve from 1.27276
Epoch 1325/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4204 - val_loss: 1.2759 - val_accuracy: 0.4088

Epoch 01325: val_loss did not improve from 1.27276
Epoch 1326/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4212 - val_loss: 1.2796 - val_accuracy: 0.4072

Epoch 01326: val_loss did not improve from 1.27276
Epoch 1327/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4219 - val_loss: 1.2770 - val_accuracy: 0.4127

Epoch 01327: val_loss did not improve from 1.27276
Epoch 1328/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4242 - val_loss: 1.2767 - val_accuracy: 0.4088

Epoch 01328: val_loss did not improve from 1.27276
Epoch 1329/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4214 - val_loss: 1.2754 - val_accuracy: 0.4040

Epoch 01329: val_loss did not improve from 1.27276
Epoch 1330/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4200 - val_loss: 1.2800 - val_accuracy: 0.4040

Epoch 01330: val_loss did not improve from 1.27276
Epoch 1331/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4182 - val_loss: 1.2753 - val_accuracy: 0.4080

Epoch 01331: val_loss did not improve from 1.27276
Epoch 1332/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4183 - val_loss: 1.2730 - val_accuracy: 0.4215

Epoch 01332: val_loss did not improve from 1.27276
Epoch 1333/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4225 - val_loss: 1.2784 - val_accuracy: 0.4088

Epoch 01333: val_loss did not improve from 1.27276
Epoch 1334/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4222 - val_loss: 1.2740 - val_accuracy: 0.4112

Epoch 01334: val_loss did not improve from 1.27276
Epoch 1335/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4204 - val_loss: 1.2775 - val_accuracy: 0.4056

Epoch 01335: val_loss did not improve from 1.27276
Epoch 1336/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4235 - val_loss: 1.2827 - val_accuracy: 0.4127

Epoch 01336: val_loss did not improve from 1.27276
Epoch 1337/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4174 - val_loss: 1.2814 - val_accuracy: 0.4032

Epoch 01337: val_loss did not improve from 1.27276
Epoch 1338/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4170 - val_loss: 1.2845 - val_accuracy: 0.4040

Epoch 01338: val_loss did not improve from 1.27276
Epoch 1339/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4183 - val_loss: 1.2752 - val_accuracy: 0.4151

Epoch 01339: val_loss did not improve from 1.27276
Epoch 1340/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4203 - val_loss: 1.2753 - val_accuracy: 0.4127

Epoch 01340: val_loss did not improve from 1.27276
Epoch 1341/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4195 - val_loss: 1.2740 - val_accuracy: 0.4104

Epoch 01341: val_loss did not improve from 1.27276
Epoch 1342/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4194 - val_loss: 1.2782 - val_accuracy: 0.4064

Epoch 01342: val_loss did not improve from 1.27276
Epoch 1343/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4193 - val_loss: 1.2767 - val_accuracy: 0.4159

Epoch 01343: val_loss did not improve from 1.27276
Epoch 1344/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4246 - val_loss: 1.2757 - val_accuracy: 0.4135

Epoch 01344: val_loss did not improve from 1.27276
Epoch 1345/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4194 - val_loss: 1.2743 - val_accuracy: 0.4207

Epoch 01345: val_loss did not improve from 1.27276
Epoch 1346/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4227 - val_loss: 1.2770 - val_accuracy: 0.4143

Epoch 01346: val_loss did not improve from 1.27276
Epoch 1347/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4199 - val_loss: 1.2772 - val_accuracy: 0.4175

Epoch 01347: val_loss did not improve from 1.27276
Epoch 1348/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4196 - val_loss: 1.2817 - val_accuracy: 0.4032

Epoch 01348: val_loss did not improve from 1.27276
Epoch 1349/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4141 - val_loss: 1.2775 - val_accuracy: 0.4151

Epoch 01349: val_loss did not improve from 1.27276
Epoch 1350/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4187 - val_loss: 1.2779 - val_accuracy: 0.4096

Epoch 01350: val_loss did not improve from 1.27276
Epoch 1351/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4183 - val_loss: 1.2769 - val_accuracy: 0.4040

Epoch 01351: val_loss did not improve from 1.27276
Epoch 1352/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4212 - val_loss: 1.2763 - val_accuracy: 0.4175

Epoch 01352: val_loss did not improve from 1.27276
Epoch 1353/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4220 - val_loss: 1.2745 - val_accuracy: 0.4215

Epoch 01353: val_loss did not improve from 1.27276
Epoch 1354/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4250 - val_loss: 1.2750 - val_accuracy: 0.4120

Epoch 01354: val_loss did not improve from 1.27276
Epoch 1355/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4221 - val_loss: 1.2745 - val_accuracy: 0.4151

Epoch 01355: val_loss did not improve from 1.27276
Epoch 1356/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4206 - val_loss: 1.2741 - val_accuracy: 0.4159

Epoch 01356: val_loss did not improve from 1.27276
Epoch 1357/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4225 - val_loss: 1.2750 - val_accuracy: 0.4215

Epoch 01357: val_loss did not improve from 1.27276
Epoch 1358/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4201 - val_loss: 1.2784 - val_accuracy: 0.4032

Epoch 01358: val_loss did not improve from 1.27276
Epoch 1359/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4191 - val_loss: 1.2787 - val_accuracy: 0.4000

Epoch 01359: val_loss did not improve from 1.27276
Epoch 1360/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4199 - val_loss: 1.2770 - val_accuracy: 0.4199

Epoch 01360: val_loss did not improve from 1.27276
Epoch 1361/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4218 - val_loss: 1.2746 - val_accuracy: 0.4151

Epoch 01361: val_loss did not improve from 1.27276
Epoch 1362/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4209 - val_loss: 1.2742 - val_accuracy: 0.4175

Epoch 01362: val_loss did not improve from 1.27276
Epoch 1363/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4244 - val_loss: 1.2772 - val_accuracy: 0.4135

Epoch 01363: val_loss did not improve from 1.27276
Epoch 1364/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4230 - val_loss: 1.2724 - val_accuracy: 0.4096

Epoch 01364: val_loss improved from 1.27276 to 1.27237, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1365/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4217 - val_loss: 1.2737 - val_accuracy: 0.4183

Epoch 01365: val_loss did not improve from 1.27237
Epoch 1366/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4235 - val_loss: 1.2812 - val_accuracy: 0.4056

Epoch 01366: val_loss did not improve from 1.27237
Epoch 1367/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4198 - val_loss: 1.2731 - val_accuracy: 0.4207

Epoch 01367: val_loss did not improve from 1.27237
Epoch 1368/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4225 - val_loss: 1.2755 - val_accuracy: 0.4127

Epoch 01368: val_loss did not improve from 1.27237
Epoch 1369/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4196 - val_loss: 1.2718 - val_accuracy: 0.4255

Epoch 01369: val_loss improved from 1.27237 to 1.27178, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1370/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4153 - val_loss: 1.2738 - val_accuracy: 0.4112

Epoch 01370: val_loss did not improve from 1.27178
Epoch 1371/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4246 - val_loss: 1.2741 - val_accuracy: 0.4191

Epoch 01371: val_loss did not improve from 1.27178
Epoch 1372/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4238 - val_loss: 1.2765 - val_accuracy: 0.4135

Epoch 01372: val_loss did not improve from 1.27178
Epoch 1373/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4199 - val_loss: 1.2750 - val_accuracy: 0.4120

Epoch 01373: val_loss did not improve from 1.27178
Epoch 1374/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4177 - val_loss: 1.2761 - val_accuracy: 0.4064

Epoch 01374: val_loss did not improve from 1.27178
Epoch 1375/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4213 - val_loss: 1.2749 - val_accuracy: 0.4104

Epoch 01375: val_loss did not improve from 1.27178
Epoch 1376/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4228 - val_loss: 1.2746 - val_accuracy: 0.4159

Epoch 01376: val_loss did not improve from 1.27178
Epoch 1377/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4215 - val_loss: 1.2785 - val_accuracy: 0.4064

Epoch 01377: val_loss did not improve from 1.27178
Epoch 1378/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4239 - val_loss: 1.2756 - val_accuracy: 0.4223

Epoch 01378: val_loss did not improve from 1.27178
Epoch 1379/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4210 - val_loss: 1.2762 - val_accuracy: 0.4072

Epoch 01379: val_loss did not improve from 1.27178
Epoch 1380/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4229 - val_loss: 1.2766 - val_accuracy: 0.4112

Epoch 01380: val_loss did not improve from 1.27178
Epoch 1381/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4244 - val_loss: 1.2757 - val_accuracy: 0.4151

Epoch 01381: val_loss did not improve from 1.27178
Epoch 1382/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4219 - val_loss: 1.2762 - val_accuracy: 0.4143

Epoch 01382: val_loss did not improve from 1.27178
Epoch 1383/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4233 - val_loss: 1.2729 - val_accuracy: 0.4175

Epoch 01383: val_loss did not improve from 1.27178
Epoch 1384/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4197 - val_loss: 1.2741 - val_accuracy: 0.4104

Epoch 01384: val_loss did not improve from 1.27178
Epoch 1385/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4211 - val_loss: 1.2765 - val_accuracy: 0.4096

Epoch 01385: val_loss did not improve from 1.27178
Epoch 1386/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4233 - val_loss: 1.2768 - val_accuracy: 0.4191

Epoch 01386: val_loss did not improve from 1.27178
Epoch 1387/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4211 - val_loss: 1.2737 - val_accuracy: 0.4120

Epoch 01387: val_loss did not improve from 1.27178
Epoch 1388/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4217 - val_loss: 1.2751 - val_accuracy: 0.4112

Epoch 01388: val_loss did not improve from 1.27178
Epoch 1389/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4162 - val_loss: 1.2769 - val_accuracy: 0.3976

Epoch 01389: val_loss did not improve from 1.27178
Epoch 1390/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4174 - val_loss: 1.2722 - val_accuracy: 0.4143

Epoch 01390: val_loss did not improve from 1.27178
Epoch 1391/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4265 - val_loss: 1.2750 - val_accuracy: 0.4199

Epoch 01391: val_loss did not improve from 1.27178
Epoch 1392/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4206 - val_loss: 1.2766 - val_accuracy: 0.4104

Epoch 01392: val_loss did not improve from 1.27178
Epoch 1393/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4208 - val_loss: 1.2790 - val_accuracy: 0.4056

Epoch 01393: val_loss did not improve from 1.27178
Epoch 1394/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4162 - val_loss: 1.2763 - val_accuracy: 0.4064

Epoch 01394: val_loss did not improve from 1.27178
Epoch 1395/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4192 - val_loss: 1.2805 - val_accuracy: 0.4167

Epoch 01395: val_loss did not improve from 1.27178
Epoch 1396/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4246 - val_loss: 1.2731 - val_accuracy: 0.4207

Epoch 01396: val_loss did not improve from 1.27178
Epoch 1397/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4223 - val_loss: 1.2741 - val_accuracy: 0.4255

Epoch 01397: val_loss did not improve from 1.27178
Epoch 1398/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4198 - val_loss: 1.2770 - val_accuracy: 0.4000

Epoch 01398: val_loss did not improve from 1.27178
Epoch 1399/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4224 - val_loss: 1.2752 - val_accuracy: 0.4127

Epoch 01399: val_loss did not improve from 1.27178
Epoch 1400/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4244 - val_loss: 1.2783 - val_accuracy: 0.4167

Epoch 01400: val_loss did not improve from 1.27178
Epoch 1401/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4192 - val_loss: 1.2756 - val_accuracy: 0.4088

Epoch 01401: val_loss did not improve from 1.27178
Epoch 1402/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4216 - val_loss: 1.2788 - val_accuracy: 0.4151

Epoch 01402: val_loss did not improve from 1.27178
Epoch 1403/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4202 - val_loss: 1.2780 - val_accuracy: 0.4143

Epoch 01403: val_loss did not improve from 1.27178
Epoch 1404/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4217 - val_loss: 1.2767 - val_accuracy: 0.4072

Epoch 01404: val_loss did not improve from 1.27178
Epoch 1405/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4222 - val_loss: 1.2750 - val_accuracy: 0.4183

Epoch 01405: val_loss did not improve from 1.27178
Epoch 1406/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4218 - val_loss: 1.2755 - val_accuracy: 0.4135

Epoch 01406: val_loss did not improve from 1.27178
Epoch 1407/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4247 - val_loss: 1.2767 - val_accuracy: 0.4167

Epoch 01407: val_loss did not improve from 1.27178
Epoch 1408/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4203 - val_loss: 1.2763 - val_accuracy: 0.4159

Epoch 01408: val_loss did not improve from 1.27178
Epoch 1409/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4204 - val_loss: 1.2738 - val_accuracy: 0.4159

Epoch 01409: val_loss did not improve from 1.27178
Epoch 1410/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4256 - val_loss: 1.2743 - val_accuracy: 0.4112

Epoch 01410: val_loss did not improve from 1.27178
Epoch 1411/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4210 - val_loss: 1.2823 - val_accuracy: 0.4064

Epoch 01411: val_loss did not improve from 1.27178
Epoch 1412/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4153 - val_loss: 1.2773 - val_accuracy: 0.4080

Epoch 01412: val_loss did not improve from 1.27178
Epoch 1413/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4200 - val_loss: 1.2742 - val_accuracy: 0.4151

Epoch 01413: val_loss did not improve from 1.27178
Epoch 1414/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4214 - val_loss: 1.2757 - val_accuracy: 0.4199

Epoch 01414: val_loss did not improve from 1.27178
Epoch 1415/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4220 - val_loss: 1.2747 - val_accuracy: 0.4112

Epoch 01415: val_loss did not improve from 1.27178
Epoch 1416/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4217 - val_loss: 1.2752 - val_accuracy: 0.4120

Epoch 01416: val_loss did not improve from 1.27178
Epoch 1417/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4216 - val_loss: 1.2761 - val_accuracy: 0.4088

Epoch 01417: val_loss did not improve from 1.27178
Epoch 1418/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4197 - val_loss: 1.2771 - val_accuracy: 0.4008

Epoch 01418: val_loss did not improve from 1.27178
Epoch 1419/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4182 - val_loss: 1.2797 - val_accuracy: 0.4120

Epoch 01419: val_loss did not improve from 1.27178
Epoch 1420/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4226 - val_loss: 1.2730 - val_accuracy: 0.4104

Epoch 01420: val_loss did not improve from 1.27178
Epoch 1421/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4230 - val_loss: 1.2742 - val_accuracy: 0.4215

Epoch 01421: val_loss did not improve from 1.27178
Epoch 1422/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4250 - val_loss: 1.2756 - val_accuracy: 0.4167

Epoch 01422: val_loss did not improve from 1.27178
Epoch 1423/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4219 - val_loss: 1.2785 - val_accuracy: 0.4040

Epoch 01423: val_loss did not improve from 1.27178
Epoch 1424/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4147 - val_loss: 1.2801 - val_accuracy: 0.3976

Epoch 01424: val_loss did not improve from 1.27178
Epoch 1425/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4229 - val_loss: 1.2783 - val_accuracy: 0.4191

Epoch 01425: val_loss did not improve from 1.27178
Epoch 1426/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4200 - val_loss: 1.2787 - val_accuracy: 0.4088

Epoch 01426: val_loss did not improve from 1.27178
Epoch 1427/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4183 - val_loss: 1.2755 - val_accuracy: 0.4215

Epoch 01427: val_loss did not improve from 1.27178
Epoch 1428/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4228 - val_loss: 1.2759 - val_accuracy: 0.4135

Epoch 01428: val_loss did not improve from 1.27178
Epoch 1429/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4211 - val_loss: 1.2732 - val_accuracy: 0.4112

Epoch 01429: val_loss did not improve from 1.27178
Epoch 1430/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4233 - val_loss: 1.2740 - val_accuracy: 0.4255

Epoch 01430: val_loss did not improve from 1.27178
Epoch 1431/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4230 - val_loss: 1.2755 - val_accuracy: 0.4080

Epoch 01431: val_loss did not improve from 1.27178
Epoch 1432/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4206 - val_loss: 1.2746 - val_accuracy: 0.4104

Epoch 01432: val_loss did not improve from 1.27178
Epoch 1433/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4198 - val_loss: 1.2753 - val_accuracy: 0.4191

Epoch 01433: val_loss did not improve from 1.27178
Epoch 1434/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4212 - val_loss: 1.2723 - val_accuracy: 0.4080

Epoch 01434: val_loss did not improve from 1.27178
Epoch 1435/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4198 - val_loss: 1.2752 - val_accuracy: 0.4191

Epoch 01435: val_loss did not improve from 1.27178
Epoch 1436/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4219 - val_loss: 1.2762 - val_accuracy: 0.4151

Epoch 01436: val_loss did not improve from 1.27178
Epoch 1437/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4198 - val_loss: 1.2760 - val_accuracy: 0.4120

Epoch 01437: val_loss did not improve from 1.27178
Epoch 1438/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4213 - val_loss: 1.2727 - val_accuracy: 0.4199

Epoch 01438: val_loss did not improve from 1.27178
Epoch 1439/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4254 - val_loss: 1.2767 - val_accuracy: 0.4048

Epoch 01439: val_loss did not improve from 1.27178
Epoch 1440/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4224 - val_loss: 1.2805 - val_accuracy: 0.4127

Epoch 01440: val_loss did not improve from 1.27178
Epoch 1441/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4222 - val_loss: 1.2730 - val_accuracy: 0.4183

Epoch 01441: val_loss did not improve from 1.27178
Epoch 1442/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4182 - val_loss: 1.2713 - val_accuracy: 0.4239

Epoch 01442: val_loss improved from 1.27178 to 1.27127, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1443/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4197 - val_loss: 1.2802 - val_accuracy: 0.4096

Epoch 01443: val_loss did not improve from 1.27127
Epoch 1444/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4190 - val_loss: 1.2746 - val_accuracy: 0.4072

Epoch 01444: val_loss did not improve from 1.27127
Epoch 1445/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4230 - val_loss: 1.2742 - val_accuracy: 0.4231

Epoch 01445: val_loss did not improve from 1.27127
Epoch 1446/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4185 - val_loss: 1.2757 - val_accuracy: 0.4080

Epoch 01446: val_loss did not improve from 1.27127
Epoch 1447/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4229 - val_loss: 1.2765 - val_accuracy: 0.4191

Epoch 01447: val_loss did not improve from 1.27127
Epoch 1448/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4195 - val_loss: 1.2728 - val_accuracy: 0.4175

Epoch 01448: val_loss did not improve from 1.27127
Epoch 1449/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4218 - val_loss: 1.2735 - val_accuracy: 0.4191

Epoch 01449: val_loss did not improve from 1.27127
Epoch 1450/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4201 - val_loss: 1.2745 - val_accuracy: 0.4112

Epoch 01450: val_loss did not improve from 1.27127
Epoch 1451/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4221 - val_loss: 1.2761 - val_accuracy: 0.4040

Epoch 01451: val_loss did not improve from 1.27127
Epoch 1452/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4198 - val_loss: 1.2750 - val_accuracy: 0.4135

Epoch 01452: val_loss did not improve from 1.27127
Epoch 1453/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4208 - val_loss: 1.2753 - val_accuracy: 0.4143

Epoch 01453: val_loss did not improve from 1.27127
Epoch 1454/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4195 - val_loss: 1.2761 - val_accuracy: 0.4072

Epoch 01454: val_loss did not improve from 1.27127
Epoch 1455/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4264 - val_loss: 1.2771 - val_accuracy: 0.4191

Epoch 01455: val_loss did not improve from 1.27127
Epoch 1456/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4177 - val_loss: 1.2779 - val_accuracy: 0.4096

Epoch 01456: val_loss did not improve from 1.27127
Epoch 1457/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4193 - val_loss: 1.2782 - val_accuracy: 0.4072

Epoch 01457: val_loss did not improve from 1.27127
Epoch 1458/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4247 - val_loss: 1.2733 - val_accuracy: 0.4175

Epoch 01458: val_loss did not improve from 1.27127
Epoch 1459/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4234 - val_loss: 1.2734 - val_accuracy: 0.4191

Epoch 01459: val_loss did not improve from 1.27127
Epoch 1460/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4205 - val_loss: 1.2772 - val_accuracy: 0.4127

Epoch 01460: val_loss did not improve from 1.27127
Epoch 1461/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4215 - val_loss: 1.2767 - val_accuracy: 0.4159

Epoch 01461: val_loss did not improve from 1.27127
Epoch 1462/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4241 - val_loss: 1.2736 - val_accuracy: 0.4199

Epoch 01462: val_loss did not improve from 1.27127
Epoch 1463/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4229 - val_loss: 1.2720 - val_accuracy: 0.4127

Epoch 01463: val_loss did not improve from 1.27127
Epoch 1464/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4235 - val_loss: 1.2771 - val_accuracy: 0.4183

Epoch 01464: val_loss did not improve from 1.27127
Epoch 1465/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4236 - val_loss: 1.2760 - val_accuracy: 0.4135

Epoch 01465: val_loss did not improve from 1.27127
Epoch 1466/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4205 - val_loss: 1.2735 - val_accuracy: 0.4159

Epoch 01466: val_loss did not improve from 1.27127
Epoch 1467/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4215 - val_loss: 1.2754 - val_accuracy: 0.4183

Epoch 01467: val_loss did not improve from 1.27127
Epoch 1468/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4188 - val_loss: 1.2735 - val_accuracy: 0.4151

Epoch 01468: val_loss did not improve from 1.27127
Epoch 1469/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4193 - val_loss: 1.2736 - val_accuracy: 0.4056

Epoch 01469: val_loss did not improve from 1.27127
Epoch 1470/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4213 - val_loss: 1.2737 - val_accuracy: 0.4207

Epoch 01470: val_loss did not improve from 1.27127
Epoch 1471/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4218 - val_loss: 1.2751 - val_accuracy: 0.4064

Epoch 01471: val_loss did not improve from 1.27127
Epoch 1472/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4202 - val_loss: 1.2751 - val_accuracy: 0.4167

Epoch 01472: val_loss did not improve from 1.27127
Epoch 1473/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4217 - val_loss: 1.2738 - val_accuracy: 0.4159

Epoch 01473: val_loss did not improve from 1.27127
Epoch 1474/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4229 - val_loss: 1.2786 - val_accuracy: 0.4096

Epoch 01474: val_loss did not improve from 1.27127
Epoch 1475/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4236 - val_loss: 1.2783 - val_accuracy: 0.4151

Epoch 01475: val_loss did not improve from 1.27127
Epoch 1476/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4201 - val_loss: 1.2736 - val_accuracy: 0.4159

Epoch 01476: val_loss did not improve from 1.27127
Epoch 1477/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4196 - val_loss: 1.2748 - val_accuracy: 0.4143

Epoch 01477: val_loss did not improve from 1.27127
Epoch 1478/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4226 - val_loss: 1.2744 - val_accuracy: 0.4159

Epoch 01478: val_loss did not improve from 1.27127
Epoch 1479/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4223 - val_loss: 1.2744 - val_accuracy: 0.4199

Epoch 01479: val_loss did not improve from 1.27127
Epoch 1480/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4220 - val_loss: 1.2721 - val_accuracy: 0.4127

Epoch 01480: val_loss did not improve from 1.27127
Epoch 1481/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4229 - val_loss: 1.2779 - val_accuracy: 0.4199

Epoch 01481: val_loss did not improve from 1.27127
Epoch 1482/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4234 - val_loss: 1.2746 - val_accuracy: 0.4000

Epoch 01482: val_loss did not improve from 1.27127
Epoch 1483/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4198 - val_loss: 1.2771 - val_accuracy: 0.4064

Epoch 01483: val_loss did not improve from 1.27127
Epoch 1484/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4219 - val_loss: 1.2727 - val_accuracy: 0.4191

Epoch 01484: val_loss did not improve from 1.27127
Epoch 1485/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4224 - val_loss: 1.2735 - val_accuracy: 0.4183

Epoch 01485: val_loss did not improve from 1.27127
Epoch 1486/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4186 - val_loss: 1.2740 - val_accuracy: 0.4143

Epoch 01486: val_loss did not improve from 1.27127
Epoch 1487/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4195 - val_loss: 1.2769 - val_accuracy: 0.4127

Epoch 01487: val_loss did not improve from 1.27127
Epoch 1488/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4195 - val_loss: 1.2716 - val_accuracy: 0.4072

Epoch 01488: val_loss did not improve from 1.27127
Epoch 1489/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4190 - val_loss: 1.2704 - val_accuracy: 0.4159

Epoch 01489: val_loss improved from 1.27127 to 1.27043, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1490/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4242 - val_loss: 1.2725 - val_accuracy: 0.4255

Epoch 01490: val_loss did not improve from 1.27043
Epoch 1491/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4196 - val_loss: 1.2757 - val_accuracy: 0.4064

Epoch 01491: val_loss did not improve from 1.27043
Epoch 1492/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4200 - val_loss: 1.2724 - val_accuracy: 0.4135

Epoch 01492: val_loss did not improve from 1.27043
Epoch 1493/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4213 - val_loss: 1.2745 - val_accuracy: 0.4215

Epoch 01493: val_loss did not improve from 1.27043
Epoch 1494/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4213 - val_loss: 1.2763 - val_accuracy: 0.4064

Epoch 01494: val_loss did not improve from 1.27043
Epoch 1495/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4213 - val_loss: 1.2756 - val_accuracy: 0.4127

Epoch 01495: val_loss did not improve from 1.27043
Epoch 1496/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4222 - val_loss: 1.2792 - val_accuracy: 0.4143

Epoch 01496: val_loss did not improve from 1.27043
Epoch 1497/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4218 - val_loss: 1.2749 - val_accuracy: 0.4159

Epoch 01497: val_loss did not improve from 1.27043
Epoch 1498/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4208 - val_loss: 1.2784 - val_accuracy: 0.4072

Epoch 01498: val_loss did not improve from 1.27043
Epoch 1499/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4194 - val_loss: 1.2797 - val_accuracy: 0.4040

Epoch 01499: val_loss did not improve from 1.27043
Epoch 1500/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4163 - val_loss: 1.2760 - val_accuracy: 0.4040

Epoch 01500: val_loss did not improve from 1.27043
Epoch 1501/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4193 - val_loss: 1.2759 - val_accuracy: 0.4072

Epoch 01501: val_loss did not improve from 1.27043
Epoch 1502/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4205 - val_loss: 1.2777 - val_accuracy: 0.4080

Epoch 01502: val_loss did not improve from 1.27043
Epoch 1503/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4227 - val_loss: 1.2811 - val_accuracy: 0.4064

Epoch 01503: val_loss did not improve from 1.27043
Epoch 1504/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4221 - val_loss: 1.2778 - val_accuracy: 0.4104

Epoch 01504: val_loss did not improve from 1.27043
Epoch 1505/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4239 - val_loss: 1.2766 - val_accuracy: 0.4080

Epoch 01505: val_loss did not improve from 1.27043
Epoch 1506/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4255 - val_loss: 1.2763 - val_accuracy: 0.4199

Epoch 01506: val_loss did not improve from 1.27043
Epoch 1507/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4218 - val_loss: 1.2741 - val_accuracy: 0.4072

Epoch 01507: val_loss did not improve from 1.27043
Epoch 1508/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4180 - val_loss: 1.2778 - val_accuracy: 0.4008

Epoch 01508: val_loss did not improve from 1.27043
Epoch 1509/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4212 - val_loss: 1.2863 - val_accuracy: 0.3984

Epoch 01509: val_loss did not improve from 1.27043
Epoch 1510/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4208 - val_loss: 1.2775 - val_accuracy: 0.4056

Epoch 01510: val_loss did not improve from 1.27043
Epoch 1511/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4175 - val_loss: 1.2791 - val_accuracy: 0.4072

Epoch 01511: val_loss did not improve from 1.27043
Epoch 1512/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4192 - val_loss: 1.2771 - val_accuracy: 0.4159

Epoch 01512: val_loss did not improve from 1.27043
Epoch 1513/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4222 - val_loss: 1.2726 - val_accuracy: 0.4175

Epoch 01513: val_loss did not improve from 1.27043
Epoch 1514/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4219 - val_loss: 1.2721 - val_accuracy: 0.4120

Epoch 01514: val_loss did not improve from 1.27043
Epoch 1515/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4237 - val_loss: 1.2801 - val_accuracy: 0.4040

Epoch 01515: val_loss did not improve from 1.27043
Epoch 1516/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4203 - val_loss: 1.2738 - val_accuracy: 0.4215

Epoch 01516: val_loss did not improve from 1.27043
Epoch 1517/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4228 - val_loss: 1.2727 - val_accuracy: 0.4199

Epoch 01517: val_loss did not improve from 1.27043
Epoch 1518/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4221 - val_loss: 1.2716 - val_accuracy: 0.4215

Epoch 01518: val_loss did not improve from 1.27043
Epoch 1519/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4279 - val_loss: 1.2766 - val_accuracy: 0.4135

Epoch 01519: val_loss did not improve from 1.27043
Epoch 1520/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4220 - val_loss: 1.2719 - val_accuracy: 0.4159

Epoch 01520: val_loss did not improve from 1.27043
Epoch 1521/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4212 - val_loss: 1.2730 - val_accuracy: 0.4120

Epoch 01521: val_loss did not improve from 1.27043
Epoch 1522/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4210 - val_loss: 1.2757 - val_accuracy: 0.4072

Epoch 01522: val_loss did not improve from 1.27043
Epoch 1523/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4218 - val_loss: 1.2702 - val_accuracy: 0.4151

Epoch 01523: val_loss improved from 1.27043 to 1.27020, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1524/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4213 - val_loss: 1.2730 - val_accuracy: 0.4096

Epoch 01524: val_loss did not improve from 1.27020
Epoch 1525/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4166 - val_loss: 1.2730 - val_accuracy: 0.4072

Epoch 01525: val_loss did not improve from 1.27020
Epoch 1526/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4228 - val_loss: 1.2728 - val_accuracy: 0.4215

Epoch 01526: val_loss did not improve from 1.27020
Epoch 1527/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4229 - val_loss: 1.2740 - val_accuracy: 0.4104

Epoch 01527: val_loss did not improve from 1.27020
Epoch 1528/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4185 - val_loss: 1.2778 - val_accuracy: 0.4072

Epoch 01528: val_loss did not improve from 1.27020
Epoch 1529/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4243 - val_loss: 1.2692 - val_accuracy: 0.4215

Epoch 01529: val_loss improved from 1.27020 to 1.26925, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1530/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4223 - val_loss: 1.2727 - val_accuracy: 0.4175

Epoch 01530: val_loss did not improve from 1.26925
Epoch 1531/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4216 - val_loss: 1.2768 - val_accuracy: 0.4104

Epoch 01531: val_loss did not improve from 1.26925
Epoch 1532/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4225 - val_loss: 1.2726 - val_accuracy: 0.4191

Epoch 01532: val_loss did not improve from 1.26925
Epoch 1533/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4227 - val_loss: 1.2754 - val_accuracy: 0.4096

Epoch 01533: val_loss did not improve from 1.26925
Epoch 1534/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4225 - val_loss: 1.2751 - val_accuracy: 0.4167

Epoch 01534: val_loss did not improve from 1.26925
Epoch 1535/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4216 - val_loss: 1.2744 - val_accuracy: 0.4159

Epoch 01535: val_loss did not improve from 1.26925
Epoch 1536/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4232 - val_loss: 1.2758 - val_accuracy: 0.4096

Epoch 01536: val_loss did not improve from 1.26925
Epoch 1537/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4212 - val_loss: 1.2727 - val_accuracy: 0.4032

Epoch 01537: val_loss did not improve from 1.26925
Epoch 1538/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4191 - val_loss: 1.2738 - val_accuracy: 0.4159

Epoch 01538: val_loss did not improve from 1.26925
Epoch 1539/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4296 - val_loss: 1.2749 - val_accuracy: 0.4143

Epoch 01539: val_loss did not improve from 1.26925
Epoch 1540/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4199 - val_loss: 1.2726 - val_accuracy: 0.4135

Epoch 01540: val_loss did not improve from 1.26925
Epoch 1541/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4211 - val_loss: 1.2755 - val_accuracy: 0.4159

Epoch 01541: val_loss did not improve from 1.26925
Epoch 1542/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4255 - val_loss: 1.2755 - val_accuracy: 0.4199

Epoch 01542: val_loss did not improve from 1.26925
Epoch 1543/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4148 - val_loss: 1.2730 - val_accuracy: 0.4151

Epoch 01543: val_loss did not improve from 1.26925
Epoch 1544/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4232 - val_loss: 1.2743 - val_accuracy: 0.4151

Epoch 01544: val_loss did not improve from 1.26925
Epoch 1545/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4239 - val_loss: 1.2784 - val_accuracy: 0.4104

Epoch 01545: val_loss did not improve from 1.26925
Epoch 1546/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4206 - val_loss: 1.2706 - val_accuracy: 0.4135

Epoch 01546: val_loss did not improve from 1.26925
Epoch 1547/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4247 - val_loss: 1.2714 - val_accuracy: 0.4191

Epoch 01547: val_loss did not improve from 1.26925
Epoch 1548/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4182 - val_loss: 1.2744 - val_accuracy: 0.4127

Epoch 01548: val_loss did not improve from 1.26925
Epoch 1549/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4209 - val_loss: 1.2764 - val_accuracy: 0.4080

Epoch 01549: val_loss did not improve from 1.26925
Epoch 1550/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4244 - val_loss: 1.2708 - val_accuracy: 0.4143

Epoch 01550: val_loss did not improve from 1.26925
Epoch 1551/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4224 - val_loss: 1.2751 - val_accuracy: 0.4064

Epoch 01551: val_loss did not improve from 1.26925
Epoch 1552/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4186 - val_loss: 1.2752 - val_accuracy: 0.4048

Epoch 01552: val_loss did not improve from 1.26925
Epoch 1553/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4210 - val_loss: 1.2706 - val_accuracy: 0.4199

Epoch 01553: val_loss did not improve from 1.26925
Epoch 1554/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4248 - val_loss: 1.2725 - val_accuracy: 0.4143

Epoch 01554: val_loss did not improve from 1.26925
Epoch 1555/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4244 - val_loss: 1.2724 - val_accuracy: 0.4183

Epoch 01555: val_loss did not improve from 1.26925
Epoch 1556/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4212 - val_loss: 1.2711 - val_accuracy: 0.4231

Epoch 01556: val_loss did not improve from 1.26925
Epoch 1557/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4239 - val_loss: 1.2717 - val_accuracy: 0.4207

Epoch 01557: val_loss did not improve from 1.26925
Epoch 1558/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4183 - val_loss: 1.2757 - val_accuracy: 0.4080

Epoch 01558: val_loss did not improve from 1.26925
Epoch 1559/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4211 - val_loss: 1.2718 - val_accuracy: 0.4167

Epoch 01559: val_loss did not improve from 1.26925
Epoch 1560/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4235 - val_loss: 1.2738 - val_accuracy: 0.4175

Epoch 01560: val_loss did not improve from 1.26925
Epoch 1561/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4219 - val_loss: 1.2717 - val_accuracy: 0.4135

Epoch 01561: val_loss did not improve from 1.26925
Epoch 1562/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4217 - val_loss: 1.2717 - val_accuracy: 0.4199

Epoch 01562: val_loss did not improve from 1.26925
Epoch 1563/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4234 - val_loss: 1.2716 - val_accuracy: 0.4143

Epoch 01563: val_loss did not improve from 1.26925
Epoch 1564/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4248 - val_loss: 1.2733 - val_accuracy: 0.4135

Epoch 01564: val_loss did not improve from 1.26925
Epoch 1565/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4248 - val_loss: 1.2764 - val_accuracy: 0.4104

Epoch 01565: val_loss did not improve from 1.26925
Epoch 1566/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4204 - val_loss: 1.2731 - val_accuracy: 0.4135

Epoch 01566: val_loss did not improve from 1.26925
Epoch 1567/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4213 - val_loss: 1.2759 - val_accuracy: 0.4024

Epoch 01567: val_loss did not improve from 1.26925
Epoch 1568/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4239 - val_loss: 1.2741 - val_accuracy: 0.4151

Epoch 01568: val_loss did not improve from 1.26925
Epoch 1569/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4222 - val_loss: 1.2719 - val_accuracy: 0.4175

Epoch 01569: val_loss did not improve from 1.26925
Epoch 1570/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4267 - val_loss: 1.2774 - val_accuracy: 0.4104

Epoch 01570: val_loss did not improve from 1.26925
Epoch 1571/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4215 - val_loss: 1.2763 - val_accuracy: 0.4167

Epoch 01571: val_loss did not improve from 1.26925
Epoch 1572/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4224 - val_loss: 1.2751 - val_accuracy: 0.4223

Epoch 01572: val_loss did not improve from 1.26925
Epoch 1573/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4230 - val_loss: 1.2695 - val_accuracy: 0.4191

Epoch 01573: val_loss did not improve from 1.26925
Epoch 1574/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4217 - val_loss: 1.2776 - val_accuracy: 0.4112

Epoch 01574: val_loss did not improve from 1.26925
Epoch 1575/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4193 - val_loss: 1.2738 - val_accuracy: 0.4088

Epoch 01575: val_loss did not improve from 1.26925
Epoch 1576/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4205 - val_loss: 1.2742 - val_accuracy: 0.4135

Epoch 01576: val_loss did not improve from 1.26925
Epoch 1577/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4235 - val_loss: 1.2750 - val_accuracy: 0.4127

Epoch 01577: val_loss did not improve from 1.26925
Epoch 1578/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4232 - val_loss: 1.2734 - val_accuracy: 0.4183

Epoch 01578: val_loss did not improve from 1.26925
Epoch 1579/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4243 - val_loss: 1.2721 - val_accuracy: 0.4120

Epoch 01579: val_loss did not improve from 1.26925
Epoch 1580/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4280 - val_loss: 1.2715 - val_accuracy: 0.4104

Epoch 01580: val_loss did not improve from 1.26925
Epoch 1581/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4205 - val_loss: 1.2736 - val_accuracy: 0.4151

Epoch 01581: val_loss did not improve from 1.26925
Epoch 1582/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4206 - val_loss: 1.2728 - val_accuracy: 0.4167

Epoch 01582: val_loss did not improve from 1.26925
Epoch 1583/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4255 - val_loss: 1.2716 - val_accuracy: 0.4151

Epoch 01583: val_loss did not improve from 1.26925
Epoch 1584/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4257 - val_loss: 1.2717 - val_accuracy: 0.4239

Epoch 01584: val_loss did not improve from 1.26925
Epoch 1585/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4221 - val_loss: 1.2724 - val_accuracy: 0.4159

Epoch 01585: val_loss did not improve from 1.26925
Epoch 1586/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4205 - val_loss: 1.2783 - val_accuracy: 0.4096

Epoch 01586: val_loss did not improve from 1.26925
Epoch 1587/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4244 - val_loss: 1.2758 - val_accuracy: 0.4183

Epoch 01587: val_loss did not improve from 1.26925
Epoch 1588/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4198 - val_loss: 1.2715 - val_accuracy: 0.4135

Epoch 01588: val_loss did not improve from 1.26925
Epoch 1589/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4205 - val_loss: 1.2724 - val_accuracy: 0.4112

Epoch 01589: val_loss did not improve from 1.26925
Epoch 1590/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4213 - val_loss: 1.2733 - val_accuracy: 0.4167

Epoch 01590: val_loss did not improve from 1.26925
Epoch 1591/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4250 - val_loss: 1.2742 - val_accuracy: 0.4231

Epoch 01591: val_loss did not improve from 1.26925
Epoch 1592/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4229 - val_loss: 1.2717 - val_accuracy: 0.4151

Epoch 01592: val_loss did not improve from 1.26925
Epoch 1593/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4244 - val_loss: 1.2764 - val_accuracy: 0.4064

Epoch 01593: val_loss did not improve from 1.26925
Epoch 1594/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4203 - val_loss: 1.2732 - val_accuracy: 0.4167

Epoch 01594: val_loss did not improve from 1.26925
Epoch 1595/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4268 - val_loss: 1.2713 - val_accuracy: 0.4112

Epoch 01595: val_loss did not improve from 1.26925
Epoch 1596/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4170 - val_loss: 1.2709 - val_accuracy: 0.4112

Epoch 01596: val_loss did not improve from 1.26925
Epoch 1597/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4221 - val_loss: 1.2761 - val_accuracy: 0.4104

Epoch 01597: val_loss did not improve from 1.26925
Epoch 1598/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4216 - val_loss: 1.2739 - val_accuracy: 0.4151

Epoch 01598: val_loss did not improve from 1.26925
Epoch 1599/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4247 - val_loss: 1.2712 - val_accuracy: 0.4120

Epoch 01599: val_loss did not improve from 1.26925
Epoch 1600/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4204 - val_loss: 1.2718 - val_accuracy: 0.4127

Epoch 01600: val_loss did not improve from 1.26925
Epoch 1601/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4259 - val_loss: 1.2750 - val_accuracy: 0.4064

Epoch 01601: val_loss did not improve from 1.26925
Epoch 1602/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4246 - val_loss: 1.2784 - val_accuracy: 0.3936

Epoch 01602: val_loss did not improve from 1.26925
Epoch 1603/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4229 - val_loss: 1.2728 - val_accuracy: 0.4016

Epoch 01603: val_loss did not improve from 1.26925
Epoch 1604/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4227 - val_loss: 1.2733 - val_accuracy: 0.4135

Epoch 01604: val_loss did not improve from 1.26925
Epoch 1605/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4257 - val_loss: 1.2754 - val_accuracy: 0.4183

Epoch 01605: val_loss did not improve from 1.26925
Epoch 1606/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4263 - val_loss: 1.2726 - val_accuracy: 0.4096

Epoch 01606: val_loss did not improve from 1.26925
Epoch 1607/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4245 - val_loss: 1.2760 - val_accuracy: 0.4167

Epoch 01607: val_loss did not improve from 1.26925
Epoch 1608/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4174 - val_loss: 1.2706 - val_accuracy: 0.4191

Epoch 01608: val_loss did not improve from 1.26925
Epoch 1609/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4217 - val_loss: 1.2729 - val_accuracy: 0.4199

Epoch 01609: val_loss did not improve from 1.26925
Epoch 1610/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4205 - val_loss: 1.2723 - val_accuracy: 0.4135

Epoch 01610: val_loss did not improve from 1.26925
Epoch 1611/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4232 - val_loss: 1.2785 - val_accuracy: 0.4120

Epoch 01611: val_loss did not improve from 1.26925
Epoch 1612/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4192 - val_loss: 1.2749 - val_accuracy: 0.4000

Epoch 01612: val_loss did not improve from 1.26925
Epoch 1613/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4240 - val_loss: 1.2734 - val_accuracy: 0.4072

Epoch 01613: val_loss did not improve from 1.26925
Epoch 1614/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4222 - val_loss: 1.2717 - val_accuracy: 0.4048

Epoch 01614: val_loss did not improve from 1.26925
Epoch 1615/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4188 - val_loss: 1.2719 - val_accuracy: 0.4159

Epoch 01615: val_loss did not improve from 1.26925
Epoch 1616/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4215 - val_loss: 1.2740 - val_accuracy: 0.4120

Epoch 01616: val_loss did not improve from 1.26925
Epoch 1617/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4227 - val_loss: 1.2709 - val_accuracy: 0.4159

Epoch 01617: val_loss did not improve from 1.26925
Epoch 1618/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4225 - val_loss: 1.2754 - val_accuracy: 0.4151

Epoch 01618: val_loss did not improve from 1.26925
Epoch 1619/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4213 - val_loss: 1.2736 - val_accuracy: 0.4032

Epoch 01619: val_loss did not improve from 1.26925
Epoch 1620/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4212 - val_loss: 1.2714 - val_accuracy: 0.4183

Epoch 01620: val_loss did not improve from 1.26925
Epoch 1621/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4209 - val_loss: 1.2766 - val_accuracy: 0.4183

Epoch 01621: val_loss did not improve from 1.26925
Epoch 1622/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4236 - val_loss: 1.2724 - val_accuracy: 0.4151

Epoch 01622: val_loss did not improve from 1.26925
Epoch 1623/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4241 - val_loss: 1.2712 - val_accuracy: 0.4088

Epoch 01623: val_loss did not improve from 1.26925
Epoch 1624/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4240 - val_loss: 1.2720 - val_accuracy: 0.4199

Epoch 01624: val_loss did not improve from 1.26925
Epoch 1625/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4233 - val_loss: 1.2710 - val_accuracy: 0.4175

Epoch 01625: val_loss did not improve from 1.26925
Epoch 1626/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4212 - val_loss: 1.2703 - val_accuracy: 0.4032

Epoch 01626: val_loss did not improve from 1.26925
Epoch 1627/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4220 - val_loss: 1.2759 - val_accuracy: 0.4112

Epoch 01627: val_loss did not improve from 1.26925
Epoch 1628/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4267 - val_loss: 1.2740 - val_accuracy: 0.4072

Epoch 01628: val_loss did not improve from 1.26925
Epoch 1629/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4240 - val_loss: 1.2733 - val_accuracy: 0.4056

Epoch 01629: val_loss did not improve from 1.26925
Epoch 1630/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4221 - val_loss: 1.2728 - val_accuracy: 0.4056

Epoch 01630: val_loss did not improve from 1.26925
Epoch 1631/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4267 - val_loss: 1.2729 - val_accuracy: 0.4112

Epoch 01631: val_loss did not improve from 1.26925
Epoch 1632/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4244 - val_loss: 1.2738 - val_accuracy: 0.4048

Epoch 01632: val_loss did not improve from 1.26925
Epoch 1633/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4228 - val_loss: 1.2734 - val_accuracy: 0.4040

Epoch 01633: val_loss did not improve from 1.26925
Epoch 1634/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4262 - val_loss: 1.2722 - val_accuracy: 0.4072

Epoch 01634: val_loss did not improve from 1.26925
Epoch 1635/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4267 - val_loss: 1.2765 - val_accuracy: 0.4120

Epoch 01635: val_loss did not improve from 1.26925
Epoch 1636/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4246 - val_loss: 1.2730 - val_accuracy: 0.4040

Epoch 01636: val_loss did not improve from 1.26925
Epoch 1637/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4276 - val_loss: 1.2717 - val_accuracy: 0.4199

Epoch 01637: val_loss did not improve from 1.26925
Epoch 1638/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4245 - val_loss: 1.2750 - val_accuracy: 0.4183

Epoch 01638: val_loss did not improve from 1.26925
Epoch 1639/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4219 - val_loss: 1.2699 - val_accuracy: 0.4159

Epoch 01639: val_loss did not improve from 1.26925
Epoch 1640/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4265 - val_loss: 1.2747 - val_accuracy: 0.4175

Epoch 01640: val_loss did not improve from 1.26925
Epoch 1641/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4223 - val_loss: 1.2734 - val_accuracy: 0.4159

Epoch 01641: val_loss did not improve from 1.26925
Epoch 1642/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4207 - val_loss: 1.2710 - val_accuracy: 0.4151

Epoch 01642: val_loss did not improve from 1.26925
Epoch 1643/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4252 - val_loss: 1.2747 - val_accuracy: 0.4183

Epoch 01643: val_loss did not improve from 1.26925
Epoch 1644/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4261 - val_loss: 1.2728 - val_accuracy: 0.4159

Epoch 01644: val_loss did not improve from 1.26925
Epoch 1645/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4249 - val_loss: 1.2721 - val_accuracy: 0.4191

Epoch 01645: val_loss did not improve from 1.26925
Epoch 1646/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4255 - val_loss: 1.2717 - val_accuracy: 0.4175

Epoch 01646: val_loss did not improve from 1.26925
Epoch 1647/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4275 - val_loss: 1.2727 - val_accuracy: 0.4104

Epoch 01647: val_loss did not improve from 1.26925
Epoch 1648/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4279 - val_loss: 1.2717 - val_accuracy: 0.4104

Epoch 01648: val_loss did not improve from 1.26925
Epoch 1649/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4258 - val_loss: 1.2724 - val_accuracy: 0.4191

Epoch 01649: val_loss did not improve from 1.26925
Epoch 1650/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4247 - val_loss: 1.2741 - val_accuracy: 0.4072

Epoch 01650: val_loss did not improve from 1.26925
Epoch 1651/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4221 - val_loss: 1.2749 - val_accuracy: 0.4096

Epoch 01651: val_loss did not improve from 1.26925
Epoch 1652/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4218 - val_loss: 1.2711 - val_accuracy: 0.4143

Epoch 01652: val_loss did not improve from 1.26925
Epoch 1653/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4268 - val_loss: 1.2744 - val_accuracy: 0.4000

Epoch 01653: val_loss did not improve from 1.26925
Epoch 1654/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4154 - val_loss: 1.2781 - val_accuracy: 0.4072

Epoch 01654: val_loss did not improve from 1.26925
Epoch 1655/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4169 - val_loss: 1.2744 - val_accuracy: 0.3976

Epoch 01655: val_loss did not improve from 1.26925
Epoch 1656/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4200 - val_loss: 1.2712 - val_accuracy: 0.4175

Epoch 01656: val_loss did not improve from 1.26925
Epoch 1657/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4273 - val_loss: 1.2734 - val_accuracy: 0.4135

Epoch 01657: val_loss did not improve from 1.26925
Epoch 1658/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4162 - val_loss: 1.2772 - val_accuracy: 0.4080

Epoch 01658: val_loss did not improve from 1.26925
Epoch 1659/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4214 - val_loss: 1.2757 - val_accuracy: 0.4096

Epoch 01659: val_loss did not improve from 1.26925
Epoch 1660/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4249 - val_loss: 1.2761 - val_accuracy: 0.4215

Epoch 01660: val_loss did not improve from 1.26925
Epoch 1661/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4179 - val_loss: 1.2736 - val_accuracy: 0.4016

Epoch 01661: val_loss did not improve from 1.26925
Epoch 1662/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4207 - val_loss: 1.2726 - val_accuracy: 0.4143

Epoch 01662: val_loss did not improve from 1.26925
Epoch 1663/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4242 - val_loss: 1.2725 - val_accuracy: 0.4112

Epoch 01663: val_loss did not improve from 1.26925
Epoch 1664/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4260 - val_loss: 1.2719 - val_accuracy: 0.4072

Epoch 01664: val_loss did not improve from 1.26925
Epoch 1665/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4267 - val_loss: 1.2710 - val_accuracy: 0.4151

Epoch 01665: val_loss did not improve from 1.26925
Epoch 1666/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4210 - val_loss: 1.2752 - val_accuracy: 0.4127

Epoch 01666: val_loss did not improve from 1.26925
Epoch 1667/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4239 - val_loss: 1.2732 - val_accuracy: 0.4096

Epoch 01667: val_loss did not improve from 1.26925
Epoch 1668/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4203 - val_loss: 1.2723 - val_accuracy: 0.4127

Epoch 01668: val_loss did not improve from 1.26925
Epoch 1669/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4265 - val_loss: 1.2709 - val_accuracy: 0.4104

Epoch 01669: val_loss did not improve from 1.26925
Epoch 1670/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4264 - val_loss: 1.2726 - val_accuracy: 0.4040

Epoch 01670: val_loss did not improve from 1.26925
Epoch 1671/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4243 - val_loss: 1.2738 - val_accuracy: 0.4104

Epoch 01671: val_loss did not improve from 1.26925
Epoch 1672/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4181 - val_loss: 1.2714 - val_accuracy: 0.4048

Epoch 01672: val_loss did not improve from 1.26925
Epoch 1673/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4257 - val_loss: 1.2688 - val_accuracy: 0.4223

Epoch 01673: val_loss improved from 1.26925 to 1.26877, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1674/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4265 - val_loss: 1.2727 - val_accuracy: 0.4231

Epoch 01674: val_loss did not improve from 1.26877
Epoch 1675/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4198 - val_loss: 1.2709 - val_accuracy: 0.4112

Epoch 01675: val_loss did not improve from 1.26877
Epoch 1676/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4207 - val_loss: 1.2713 - val_accuracy: 0.4191

Epoch 01676: val_loss did not improve from 1.26877
Epoch 1677/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4229 - val_loss: 1.2733 - val_accuracy: 0.4104

Epoch 01677: val_loss did not improve from 1.26877
Epoch 1678/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4229 - val_loss: 1.2765 - val_accuracy: 0.4135

Epoch 01678: val_loss did not improve from 1.26877
Epoch 1679/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4244 - val_loss: 1.2695 - val_accuracy: 0.4167

Epoch 01679: val_loss did not improve from 1.26877
Epoch 1680/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4226 - val_loss: 1.2719 - val_accuracy: 0.4112

Epoch 01680: val_loss did not improve from 1.26877
Epoch 1681/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4208 - val_loss: 1.2735 - val_accuracy: 0.4072

Epoch 01681: val_loss did not improve from 1.26877
Epoch 1682/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4232 - val_loss: 1.2730 - val_accuracy: 0.4064

Epoch 01682: val_loss did not improve from 1.26877
Epoch 1683/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4261 - val_loss: 1.2688 - val_accuracy: 0.4159

Epoch 01683: val_loss improved from 1.26877 to 1.26877, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1684/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4227 - val_loss: 1.2696 - val_accuracy: 0.4135

Epoch 01684: val_loss did not improve from 1.26877
Epoch 1685/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4235 - val_loss: 1.2692 - val_accuracy: 0.4112

Epoch 01685: val_loss did not improve from 1.26877
Epoch 1686/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4241 - val_loss: 1.2716 - val_accuracy: 0.4143

Epoch 01686: val_loss did not improve from 1.26877
Epoch 1687/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4248 - val_loss: 1.2741 - val_accuracy: 0.4088

Epoch 01687: val_loss did not improve from 1.26877
Epoch 1688/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4219 - val_loss: 1.2703 - val_accuracy: 0.4120

Epoch 01688: val_loss did not improve from 1.26877
Epoch 1689/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4236 - val_loss: 1.2718 - val_accuracy: 0.4159

Epoch 01689: val_loss did not improve from 1.26877
Epoch 1690/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4222 - val_loss: 1.2693 - val_accuracy: 0.4175

Epoch 01690: val_loss did not improve from 1.26877
Epoch 1691/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4241 - val_loss: 1.2699 - val_accuracy: 0.4191

Epoch 01691: val_loss did not improve from 1.26877
Epoch 1692/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4205 - val_loss: 1.2743 - val_accuracy: 0.4183

Epoch 01692: val_loss did not improve from 1.26877
Epoch 1693/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4229 - val_loss: 1.2724 - val_accuracy: 0.4151

Epoch 01693: val_loss did not improve from 1.26877
Epoch 1694/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4233 - val_loss: 1.2690 - val_accuracy: 0.4175

Epoch 01694: val_loss did not improve from 1.26877
Epoch 1695/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4308 - val_loss: 1.2755 - val_accuracy: 0.4191

Epoch 01695: val_loss did not improve from 1.26877
Epoch 1696/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4249 - val_loss: 1.2708 - val_accuracy: 0.4151

Epoch 01696: val_loss did not improve from 1.26877
Epoch 1697/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4270 - val_loss: 1.2706 - val_accuracy: 0.4120

Epoch 01697: val_loss did not improve from 1.26877
Epoch 1698/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4189 - val_loss: 1.2697 - val_accuracy: 0.4159

Epoch 01698: val_loss did not improve from 1.26877
Epoch 1699/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4275 - val_loss: 1.2706 - val_accuracy: 0.4191

Epoch 01699: val_loss did not improve from 1.26877
Epoch 1700/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4224 - val_loss: 1.2713 - val_accuracy: 0.4135

Epoch 01700: val_loss did not improve from 1.26877
Epoch 1701/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4232 - val_loss: 1.2728 - val_accuracy: 0.4088

Epoch 01701: val_loss did not improve from 1.26877
Epoch 1702/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4249 - val_loss: 1.2730 - val_accuracy: 0.4135

Epoch 01702: val_loss did not improve from 1.26877
Epoch 1703/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4246 - val_loss: 1.2746 - val_accuracy: 0.3960

Epoch 01703: val_loss did not improve from 1.26877
Epoch 1704/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4172 - val_loss: 1.2727 - val_accuracy: 0.4104

Epoch 01704: val_loss did not improve from 1.26877
Epoch 1705/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4241 - val_loss: 1.2738 - val_accuracy: 0.4175

Epoch 01705: val_loss did not improve from 1.26877
Epoch 1706/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4267 - val_loss: 1.2729 - val_accuracy: 0.4096

Epoch 01706: val_loss did not improve from 1.26877
Epoch 1707/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4220 - val_loss: 1.2735 - val_accuracy: 0.4080

Epoch 01707: val_loss did not improve from 1.26877
Epoch 1708/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4213 - val_loss: 1.2707 - val_accuracy: 0.4135

Epoch 01708: val_loss did not improve from 1.26877
Epoch 1709/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4237 - val_loss: 1.2715 - val_accuracy: 0.4135

Epoch 01709: val_loss did not improve from 1.26877
Epoch 1710/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4234 - val_loss: 1.2733 - val_accuracy: 0.4104

Epoch 01710: val_loss did not improve from 1.26877
Epoch 1711/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4244 - val_loss: 1.2735 - val_accuracy: 0.4143

Epoch 01711: val_loss did not improve from 1.26877
Epoch 1712/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4242 - val_loss: 1.2712 - val_accuracy: 0.4199

Epoch 01712: val_loss did not improve from 1.26877
Epoch 1713/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4216 - val_loss: 1.2686 - val_accuracy: 0.4143

Epoch 01713: val_loss improved from 1.26877 to 1.26865, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1714/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4198 - val_loss: 1.2712 - val_accuracy: 0.4207

Epoch 01714: val_loss did not improve from 1.26865
Epoch 1715/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4282 - val_loss: 1.2689 - val_accuracy: 0.4072

Epoch 01715: val_loss did not improve from 1.26865
Epoch 1716/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4179 - val_loss: 1.2729 - val_accuracy: 0.4112

Epoch 01716: val_loss did not improve from 1.26865
Epoch 1717/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4218 - val_loss: 1.2734 - val_accuracy: 0.4215

Epoch 01717: val_loss did not improve from 1.26865
Epoch 1718/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4251 - val_loss: 1.2687 - val_accuracy: 0.4255

Epoch 01718: val_loss did not improve from 1.26865
Epoch 1719/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4271 - val_loss: 1.2732 - val_accuracy: 0.4104

Epoch 01719: val_loss did not improve from 1.26865
Epoch 1720/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4240 - val_loss: 1.2705 - val_accuracy: 0.4112

Epoch 01720: val_loss did not improve from 1.26865
Epoch 1721/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4275 - val_loss: 1.2705 - val_accuracy: 0.4088

Epoch 01721: val_loss did not improve from 1.26865
Epoch 1722/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4267 - val_loss: 1.2711 - val_accuracy: 0.4143

Epoch 01722: val_loss did not improve from 1.26865
Epoch 1723/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4258 - val_loss: 1.2708 - val_accuracy: 0.4112

Epoch 01723: val_loss did not improve from 1.26865
Epoch 1724/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4216 - val_loss: 1.2743 - val_accuracy: 0.4183

Epoch 01724: val_loss did not improve from 1.26865
Epoch 1725/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4260 - val_loss: 1.2688 - val_accuracy: 0.4231

Epoch 01725: val_loss did not improve from 1.26865
Epoch 1726/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4205 - val_loss: 1.2737 - val_accuracy: 0.4215

Epoch 01726: val_loss did not improve from 1.26865
Epoch 1727/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4213 - val_loss: 1.2770 - val_accuracy: 0.4104

Epoch 01727: val_loss did not improve from 1.26865
Epoch 1728/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4221 - val_loss: 1.2695 - val_accuracy: 0.4032

Epoch 01728: val_loss did not improve from 1.26865
Epoch 1729/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4304 - val_loss: 1.2729 - val_accuracy: 0.4151

Epoch 01729: val_loss did not improve from 1.26865
Epoch 1730/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4283 - val_loss: 1.2699 - val_accuracy: 0.4207

Epoch 01730: val_loss did not improve from 1.26865
Epoch 1731/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4245 - val_loss: 1.2710 - val_accuracy: 0.4080

Epoch 01731: val_loss did not improve from 1.26865
Epoch 1732/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4232 - val_loss: 1.2713 - val_accuracy: 0.4072

Epoch 01732: val_loss did not improve from 1.26865
Epoch 1733/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4246 - val_loss: 1.2732 - val_accuracy: 0.4112

Epoch 01733: val_loss did not improve from 1.26865
Epoch 1734/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4225 - val_loss: 1.2704 - val_accuracy: 0.4191

Epoch 01734: val_loss did not improve from 1.26865
Epoch 1735/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4252 - val_loss: 1.2759 - val_accuracy: 0.4120

Epoch 01735: val_loss did not improve from 1.26865
Epoch 1736/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4219 - val_loss: 1.2711 - val_accuracy: 0.4024

Epoch 01736: val_loss did not improve from 1.26865
Epoch 1737/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4236 - val_loss: 1.2701 - val_accuracy: 0.4159

Epoch 01737: val_loss did not improve from 1.26865
Epoch 1738/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4251 - val_loss: 1.2745 - val_accuracy: 0.4167

Epoch 01738: val_loss did not improve from 1.26865
Epoch 1739/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4209 - val_loss: 1.2735 - val_accuracy: 0.4143

Epoch 01739: val_loss did not improve from 1.26865
Epoch 1740/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4290 - val_loss: 1.2690 - val_accuracy: 0.4159

Epoch 01740: val_loss did not improve from 1.26865
Epoch 1741/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4282 - val_loss: 1.2698 - val_accuracy: 0.4120

Epoch 01741: val_loss did not improve from 1.26865
Epoch 1742/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4260 - val_loss: 1.2711 - val_accuracy: 0.4127

Epoch 01742: val_loss did not improve from 1.26865
Epoch 1743/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4250 - val_loss: 1.2710 - val_accuracy: 0.4072

Epoch 01743: val_loss did not improve from 1.26865
Epoch 1744/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4249 - val_loss: 1.2729 - val_accuracy: 0.4056

Epoch 01744: val_loss did not improve from 1.26865
Epoch 1745/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4245 - val_loss: 1.2733 - val_accuracy: 0.4127

Epoch 01745: val_loss did not improve from 1.26865
Epoch 1746/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4201 - val_loss: 1.2713 - val_accuracy: 0.4120

Epoch 01746: val_loss did not improve from 1.26865
Epoch 1747/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4270 - val_loss: 1.2678 - val_accuracy: 0.4112

Epoch 01747: val_loss improved from 1.26865 to 1.26784, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1748/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4252 - val_loss: 1.2690 - val_accuracy: 0.4120

Epoch 01748: val_loss did not improve from 1.26784
Epoch 1749/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4257 - val_loss: 1.2683 - val_accuracy: 0.4064

Epoch 01749: val_loss did not improve from 1.26784
Epoch 1750/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4252 - val_loss: 1.2740 - val_accuracy: 0.4183

Epoch 01750: val_loss did not improve from 1.26784
Epoch 1751/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4240 - val_loss: 1.2732 - val_accuracy: 0.4135

Epoch 01751: val_loss did not improve from 1.26784
Epoch 1752/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4188 - val_loss: 1.2695 - val_accuracy: 0.4112

Epoch 01752: val_loss did not improve from 1.26784
Epoch 1753/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4228 - val_loss: 1.2718 - val_accuracy: 0.4215

Epoch 01753: val_loss did not improve from 1.26784
Epoch 1754/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4268 - val_loss: 1.2692 - val_accuracy: 0.4143

Epoch 01754: val_loss did not improve from 1.26784
Epoch 1755/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4237 - val_loss: 1.2724 - val_accuracy: 0.4143

Epoch 01755: val_loss did not improve from 1.26784
Epoch 1756/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4271 - val_loss: 1.2680 - val_accuracy: 0.4191

Epoch 01756: val_loss did not improve from 1.26784
Epoch 1757/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4260 - val_loss: 1.2718 - val_accuracy: 0.4167

Epoch 01757: val_loss did not improve from 1.26784
Epoch 1758/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4226 - val_loss: 1.2745 - val_accuracy: 0.4191

Epoch 01758: val_loss did not improve from 1.26784
Epoch 1759/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4242 - val_loss: 1.2684 - val_accuracy: 0.4112

Epoch 01759: val_loss did not improve from 1.26784
Epoch 1760/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4206 - val_loss: 1.2697 - val_accuracy: 0.4159

Epoch 01760: val_loss did not improve from 1.26784
Epoch 1761/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4258 - val_loss: 1.2724 - val_accuracy: 0.4151

Epoch 01761: val_loss did not improve from 1.26784
Epoch 1762/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4244 - val_loss: 1.2707 - val_accuracy: 0.4143

Epoch 01762: val_loss did not improve from 1.26784
Epoch 1763/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4188 - val_loss: 1.2701 - val_accuracy: 0.4064

Epoch 01763: val_loss did not improve from 1.26784
Epoch 1764/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4252 - val_loss: 1.2722 - val_accuracy: 0.4040

Epoch 01764: val_loss did not improve from 1.26784
Epoch 1765/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4252 - val_loss: 1.2693 - val_accuracy: 0.4183

Epoch 01765: val_loss did not improve from 1.26784
Epoch 1766/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4242 - val_loss: 1.2714 - val_accuracy: 0.4096

Epoch 01766: val_loss did not improve from 1.26784
Epoch 1767/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4228 - val_loss: 1.2704 - val_accuracy: 0.4120

Epoch 01767: val_loss did not improve from 1.26784
Epoch 1768/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4258 - val_loss: 1.2739 - val_accuracy: 0.4120

Epoch 01768: val_loss did not improve from 1.26784
Epoch 1769/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4224 - val_loss: 1.2691 - val_accuracy: 0.4127

Epoch 01769: val_loss did not improve from 1.26784
Epoch 1770/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4227 - val_loss: 1.2743 - val_accuracy: 0.4096

Epoch 01770: val_loss did not improve from 1.26784
Epoch 1771/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4273 - val_loss: 1.2727 - val_accuracy: 0.4120

Epoch 01771: val_loss did not improve from 1.26784
Epoch 1772/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4236 - val_loss: 1.2722 - val_accuracy: 0.4064

Epoch 01772: val_loss did not improve from 1.26784
Epoch 1773/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4240 - val_loss: 1.2734 - val_accuracy: 0.4183

Epoch 01773: val_loss did not improve from 1.26784
Epoch 1774/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4242 - val_loss: 1.2723 - val_accuracy: 0.4024

Epoch 01774: val_loss did not improve from 1.26784
Epoch 1775/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4254 - val_loss: 1.2702 - val_accuracy: 0.4151

Epoch 01775: val_loss did not improve from 1.26784
Epoch 1776/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4205 - val_loss: 1.2719 - val_accuracy: 0.4199

Epoch 01776: val_loss did not improve from 1.26784
Epoch 1777/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4246 - val_loss: 1.2726 - val_accuracy: 0.4088

Epoch 01777: val_loss did not improve from 1.26784
Epoch 1778/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4243 - val_loss: 1.2715 - val_accuracy: 0.4151

Epoch 01778: val_loss did not improve from 1.26784
Epoch 1779/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4229 - val_loss: 1.2730 - val_accuracy: 0.4048

Epoch 01779: val_loss did not improve from 1.26784
Epoch 1780/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4247 - val_loss: 1.2710 - val_accuracy: 0.4159

Epoch 01780: val_loss did not improve from 1.26784
Epoch 1781/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4267 - val_loss: 1.2716 - val_accuracy: 0.4056

Epoch 01781: val_loss did not improve from 1.26784
Epoch 1782/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4253 - val_loss: 1.2696 - val_accuracy: 0.4088

Epoch 01782: val_loss did not improve from 1.26784
Epoch 1783/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4262 - val_loss: 1.2687 - val_accuracy: 0.4215

Epoch 01783: val_loss did not improve from 1.26784
Epoch 1784/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4216 - val_loss: 1.2701 - val_accuracy: 0.4159

Epoch 01784: val_loss did not improve from 1.26784
Epoch 1785/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4207 - val_loss: 1.2740 - val_accuracy: 0.4000

Epoch 01785: val_loss did not improve from 1.26784
Epoch 1786/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4209 - val_loss: 1.2709 - val_accuracy: 0.4159

Epoch 01786: val_loss did not improve from 1.26784
Epoch 1787/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4240 - val_loss: 1.2720 - val_accuracy: 0.4143

Epoch 01787: val_loss did not improve from 1.26784
Epoch 1788/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4277 - val_loss: 1.2727 - val_accuracy: 0.4096

Epoch 01788: val_loss did not improve from 1.26784
Epoch 1789/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4241 - val_loss: 1.2721 - val_accuracy: 0.4112

Epoch 01789: val_loss did not improve from 1.26784
Epoch 1790/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4282 - val_loss: 1.2705 - val_accuracy: 0.4159

Epoch 01790: val_loss did not improve from 1.26784
Epoch 1791/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4257 - val_loss: 1.2704 - val_accuracy: 0.4000

Epoch 01791: val_loss did not improve from 1.26784
Epoch 1792/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4236 - val_loss: 1.2688 - val_accuracy: 0.4127

Epoch 01792: val_loss did not improve from 1.26784
Epoch 1793/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4256 - val_loss: 1.2697 - val_accuracy: 0.4104

Epoch 01793: val_loss did not improve from 1.26784
Epoch 1794/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4267 - val_loss: 1.2721 - val_accuracy: 0.4120

Epoch 01794: val_loss did not improve from 1.26784
Epoch 1795/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4228 - val_loss: 1.2708 - val_accuracy: 0.4032

Epoch 01795: val_loss did not improve from 1.26784
Epoch 1796/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4239 - val_loss: 1.2742 - val_accuracy: 0.4183

Epoch 01796: val_loss did not improve from 1.26784
Epoch 1797/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4241 - val_loss: 1.2680 - val_accuracy: 0.4159

Epoch 01797: val_loss did not improve from 1.26784
Epoch 1798/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4269 - val_loss: 1.2713 - val_accuracy: 0.4223

Epoch 01798: val_loss did not improve from 1.26784
Epoch 1799/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4212 - val_loss: 1.2693 - val_accuracy: 0.4072

Epoch 01799: val_loss did not improve from 1.26784
Epoch 1800/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4262 - val_loss: 1.2753 - val_accuracy: 0.4191

Epoch 01800: val_loss did not improve from 1.26784
Epoch 1801/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4233 - val_loss: 1.2682 - val_accuracy: 0.4151

Epoch 01801: val_loss did not improve from 1.26784
Epoch 1802/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4255 - val_loss: 1.2751 - val_accuracy: 0.4151

Epoch 01802: val_loss did not improve from 1.26784
Epoch 1803/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4171 - val_loss: 1.2784 - val_accuracy: 0.4135

Epoch 01803: val_loss did not improve from 1.26784
Epoch 1804/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4221 - val_loss: 1.2700 - val_accuracy: 0.4207

Epoch 01804: val_loss did not improve from 1.26784
Epoch 1805/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4265 - val_loss: 1.2710 - val_accuracy: 0.4080

Epoch 01805: val_loss did not improve from 1.26784
Epoch 1806/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4276 - val_loss: 1.2675 - val_accuracy: 0.4215

Epoch 01806: val_loss improved from 1.26784 to 1.26750, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1807/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4252 - val_loss: 1.2741 - val_accuracy: 0.4127

Epoch 01807: val_loss did not improve from 1.26750
Epoch 1808/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4213 - val_loss: 1.2720 - val_accuracy: 0.4032

Epoch 01808: val_loss did not improve from 1.26750
Epoch 1809/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4279 - val_loss: 1.2678 - val_accuracy: 0.4167

Epoch 01809: val_loss did not improve from 1.26750
Epoch 1810/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4240 - val_loss: 1.2736 - val_accuracy: 0.4088

Epoch 01810: val_loss did not improve from 1.26750
Epoch 1811/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4252 - val_loss: 1.2730 - val_accuracy: 0.4104

Epoch 01811: val_loss did not improve from 1.26750
Epoch 1812/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4207 - val_loss: 1.2683 - val_accuracy: 0.4127

Epoch 01812: val_loss did not improve from 1.26750
Epoch 1813/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4261 - val_loss: 1.2711 - val_accuracy: 0.4056

Epoch 01813: val_loss did not improve from 1.26750
Epoch 1814/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4220 - val_loss: 1.2728 - val_accuracy: 0.4112

Epoch 01814: val_loss did not improve from 1.26750
Epoch 1815/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4241 - val_loss: 1.2714 - val_accuracy: 0.4112

Epoch 01815: val_loss did not improve from 1.26750
Epoch 1816/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4250 - val_loss: 1.2687 - val_accuracy: 0.4024

Epoch 01816: val_loss did not improve from 1.26750
Epoch 1817/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4197 - val_loss: 1.2725 - val_accuracy: 0.4112

Epoch 01817: val_loss did not improve from 1.26750
Epoch 1818/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4226 - val_loss: 1.2719 - val_accuracy: 0.4183

Epoch 01818: val_loss did not improve from 1.26750
Epoch 1819/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4213 - val_loss: 1.2711 - val_accuracy: 0.4104

Epoch 01819: val_loss did not improve from 1.26750
Epoch 1820/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4216 - val_loss: 1.2717 - val_accuracy: 0.4000

Epoch 01820: val_loss did not improve from 1.26750
Epoch 1821/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4234 - val_loss: 1.2771 - val_accuracy: 0.4072

Epoch 01821: val_loss did not improve from 1.26750
Epoch 1822/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4195 - val_loss: 1.2756 - val_accuracy: 0.4104

Epoch 01822: val_loss did not improve from 1.26750
Epoch 1823/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4236 - val_loss: 1.2672 - val_accuracy: 0.4175

Epoch 01823: val_loss improved from 1.26750 to 1.26721, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1824/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4252 - val_loss: 1.2740 - val_accuracy: 0.4120

Epoch 01824: val_loss did not improve from 1.26721
Epoch 1825/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4239 - val_loss: 1.2699 - val_accuracy: 0.4096

Epoch 01825: val_loss did not improve from 1.26721
Epoch 1826/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4189 - val_loss: 1.2801 - val_accuracy: 0.4096

Epoch 01826: val_loss did not improve from 1.26721
Epoch 1827/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4221 - val_loss: 1.2721 - val_accuracy: 0.4096

Epoch 01827: val_loss did not improve from 1.26721
Epoch 1828/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4255 - val_loss: 1.2695 - val_accuracy: 0.4223

Epoch 01828: val_loss did not improve from 1.26721
Epoch 1829/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4209 - val_loss: 1.2737 - val_accuracy: 0.4151

Epoch 01829: val_loss did not improve from 1.26721
Epoch 1830/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4285 - val_loss: 1.2720 - val_accuracy: 0.4104

Epoch 01830: val_loss did not improve from 1.26721
Epoch 1831/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4283 - val_loss: 1.2707 - val_accuracy: 0.4151

Epoch 01831: val_loss did not improve from 1.26721
Epoch 1832/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4218 - val_loss: 1.2746 - val_accuracy: 0.4032

Epoch 01832: val_loss did not improve from 1.26721
Epoch 1833/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4253 - val_loss: 1.2718 - val_accuracy: 0.4088

Epoch 01833: val_loss did not improve from 1.26721
Epoch 1834/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4251 - val_loss: 1.2674 - val_accuracy: 0.4104

Epoch 01834: val_loss did not improve from 1.26721
Epoch 1835/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4265 - val_loss: 1.2707 - val_accuracy: 0.4104

Epoch 01835: val_loss did not improve from 1.26721
Epoch 1836/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4246 - val_loss: 1.2729 - val_accuracy: 0.4112

Epoch 01836: val_loss did not improve from 1.26721
Epoch 1837/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4239 - val_loss: 1.2722 - val_accuracy: 0.4151

Epoch 01837: val_loss did not improve from 1.26721
Epoch 1838/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4275 - val_loss: 1.2728 - val_accuracy: 0.4056

Epoch 01838: val_loss did not improve from 1.26721
Epoch 1839/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4209 - val_loss: 1.2737 - val_accuracy: 0.4048

Epoch 01839: val_loss did not improve from 1.26721
Epoch 1840/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4254 - val_loss: 1.2720 - val_accuracy: 0.4096

Epoch 01840: val_loss did not improve from 1.26721
Epoch 1841/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4260 - val_loss: 1.2692 - val_accuracy: 0.4143

Epoch 01841: val_loss did not improve from 1.26721
Epoch 1842/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4236 - val_loss: 1.2771 - val_accuracy: 0.4167

Epoch 01842: val_loss did not improve from 1.26721
Epoch 1843/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4254 - val_loss: 1.2750 - val_accuracy: 0.4159

Epoch 01843: val_loss did not improve from 1.26721
Epoch 1844/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4235 - val_loss: 1.2707 - val_accuracy: 0.4112

Epoch 01844: val_loss did not improve from 1.26721
Epoch 1845/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4245 - val_loss: 1.2700 - val_accuracy: 0.4127

Epoch 01845: val_loss did not improve from 1.26721
Epoch 1846/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4289 - val_loss: 1.2730 - val_accuracy: 0.4120

Epoch 01846: val_loss did not improve from 1.26721
Epoch 1847/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4238 - val_loss: 1.2733 - val_accuracy: 0.4135

Epoch 01847: val_loss did not improve from 1.26721
Epoch 1848/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4253 - val_loss: 1.2734 - val_accuracy: 0.4135

Epoch 01848: val_loss did not improve from 1.26721
Epoch 1849/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4275 - val_loss: 1.2708 - val_accuracy: 0.4040

Epoch 01849: val_loss did not improve from 1.26721
Epoch 1850/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4240 - val_loss: 1.2688 - val_accuracy: 0.4112

Epoch 01850: val_loss did not improve from 1.26721
Epoch 1851/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4263 - val_loss: 1.2709 - val_accuracy: 0.4231

Epoch 01851: val_loss did not improve from 1.26721
Epoch 1852/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4248 - val_loss: 1.2686 - val_accuracy: 0.4191

Epoch 01852: val_loss did not improve from 1.26721
Epoch 1853/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4249 - val_loss: 1.2708 - val_accuracy: 0.4104

Epoch 01853: val_loss did not improve from 1.26721
Epoch 1854/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4260 - val_loss: 1.2709 - val_accuracy: 0.4175

Epoch 01854: val_loss did not improve from 1.26721
Epoch 1855/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4217 - val_loss: 1.2679 - val_accuracy: 0.4120

Epoch 01855: val_loss did not improve from 1.26721
Epoch 1856/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4219 - val_loss: 1.2687 - val_accuracy: 0.4120

Epoch 01856: val_loss did not improve from 1.26721
Epoch 1857/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4267 - val_loss: 1.2675 - val_accuracy: 0.4056

Epoch 01857: val_loss did not improve from 1.26721
Epoch 1858/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4225 - val_loss: 1.2738 - val_accuracy: 0.4096

Epoch 01858: val_loss did not improve from 1.26721
Epoch 1859/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4279 - val_loss: 1.2704 - val_accuracy: 0.4167

Epoch 01859: val_loss did not improve from 1.26721
Epoch 1860/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4239 - val_loss: 1.2681 - val_accuracy: 0.4183

Epoch 01860: val_loss did not improve from 1.26721
Epoch 1861/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4279 - val_loss: 1.2717 - val_accuracy: 0.4135

Epoch 01861: val_loss did not improve from 1.26721
Epoch 1862/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4248 - val_loss: 1.2754 - val_accuracy: 0.4135

Epoch 01862: val_loss did not improve from 1.26721
Epoch 1863/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4279 - val_loss: 1.2687 - val_accuracy: 0.4175

Epoch 01863: val_loss did not improve from 1.26721
Epoch 1864/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4269 - val_loss: 1.2715 - val_accuracy: 0.4167

Epoch 01864: val_loss did not improve from 1.26721
Epoch 1865/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4263 - val_loss: 1.2745 - val_accuracy: 0.4143

Epoch 01865: val_loss did not improve from 1.26721
Epoch 1866/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4233 - val_loss: 1.2740 - val_accuracy: 0.4135

Epoch 01866: val_loss did not improve from 1.26721
Epoch 1867/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4225 - val_loss: 1.2718 - val_accuracy: 0.4056

Epoch 01867: val_loss did not improve from 1.26721
Epoch 1868/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4244 - val_loss: 1.2693 - val_accuracy: 0.4048

Epoch 01868: val_loss did not improve from 1.26721
Epoch 1869/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4256 - val_loss: 1.2710 - val_accuracy: 0.4088

Epoch 01869: val_loss did not improve from 1.26721
Epoch 1870/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4239 - val_loss: 1.2676 - val_accuracy: 0.4127

Epoch 01870: val_loss did not improve from 1.26721
Epoch 1871/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4252 - val_loss: 1.2692 - val_accuracy: 0.4159

Epoch 01871: val_loss did not improve from 1.26721
Epoch 1872/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4232 - val_loss: 1.2683 - val_accuracy: 0.4120

Epoch 01872: val_loss did not improve from 1.26721
Epoch 1873/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4210 - val_loss: 1.2702 - val_accuracy: 0.4104

Epoch 01873: val_loss did not improve from 1.26721
Epoch 1874/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4237 - val_loss: 1.2716 - val_accuracy: 0.4120

Epoch 01874: val_loss did not improve from 1.26721
Epoch 1875/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4260 - val_loss: 1.2683 - val_accuracy: 0.4143

Epoch 01875: val_loss did not improve from 1.26721
Epoch 1876/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4246 - val_loss: 1.2687 - val_accuracy: 0.4175

Epoch 01876: val_loss did not improve from 1.26721
Epoch 1877/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4262 - val_loss: 1.2688 - val_accuracy: 0.4135

Epoch 01877: val_loss did not improve from 1.26721
Epoch 1878/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4168 - val_loss: 1.2712 - val_accuracy: 0.4024

Epoch 01878: val_loss did not improve from 1.26721
Epoch 1879/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4284 - val_loss: 1.2708 - val_accuracy: 0.4151

Epoch 01879: val_loss did not improve from 1.26721
Epoch 1880/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4267 - val_loss: 1.2677 - val_accuracy: 0.4215

Epoch 01880: val_loss did not improve from 1.26721
Epoch 1881/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4219 - val_loss: 1.2733 - val_accuracy: 0.4000

Epoch 01881: val_loss did not improve from 1.26721
Epoch 1882/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4227 - val_loss: 1.2738 - val_accuracy: 0.4239

Epoch 01882: val_loss did not improve from 1.26721
Epoch 1883/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4256 - val_loss: 1.2716 - val_accuracy: 0.4207

Epoch 01883: val_loss did not improve from 1.26721
Epoch 1884/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4244 - val_loss: 1.2656 - val_accuracy: 0.4175

Epoch 01884: val_loss improved from 1.26721 to 1.26560, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1885/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4280 - val_loss: 1.2701 - val_accuracy: 0.4127

Epoch 01885: val_loss did not improve from 1.26560
Epoch 1886/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4264 - val_loss: 1.2680 - val_accuracy: 0.4183

Epoch 01886: val_loss did not improve from 1.26560
Epoch 1887/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4221 - val_loss: 1.2719 - val_accuracy: 0.4064

Epoch 01887: val_loss did not improve from 1.26560
Epoch 1888/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4272 - val_loss: 1.2755 - val_accuracy: 0.4135

Epoch 01888: val_loss did not improve from 1.26560
Epoch 1889/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4175 - val_loss: 1.2700 - val_accuracy: 0.4151

Epoch 01889: val_loss did not improve from 1.26560
Epoch 1890/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4256 - val_loss: 1.2712 - val_accuracy: 0.4175

Epoch 01890: val_loss did not improve from 1.26560
Epoch 1891/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4258 - val_loss: 1.2722 - val_accuracy: 0.4048

Epoch 01891: val_loss did not improve from 1.26560
Epoch 1892/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4246 - val_loss: 1.2719 - val_accuracy: 0.4127

Epoch 01892: val_loss did not improve from 1.26560
Epoch 1893/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4260 - val_loss: 1.2701 - val_accuracy: 0.4151

Epoch 01893: val_loss did not improve from 1.26560
Epoch 1894/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4220 - val_loss: 1.2729 - val_accuracy: 0.4024

Epoch 01894: val_loss did not improve from 1.26560
Epoch 1895/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4267 - val_loss: 1.2756 - val_accuracy: 0.4072

Epoch 01895: val_loss did not improve from 1.26560
Epoch 1896/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4220 - val_loss: 1.2714 - val_accuracy: 0.4159

Epoch 01896: val_loss did not improve from 1.26560
Epoch 1897/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4229 - val_loss: 1.2692 - val_accuracy: 0.4151

Epoch 01897: val_loss did not improve from 1.26560
Epoch 1898/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4222 - val_loss: 1.2708 - val_accuracy: 0.4127

Epoch 01898: val_loss did not improve from 1.26560
Epoch 1899/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4275 - val_loss: 1.2676 - val_accuracy: 0.4175

Epoch 01899: val_loss did not improve from 1.26560
Epoch 1900/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4266 - val_loss: 1.2698 - val_accuracy: 0.4135

Epoch 01900: val_loss did not improve from 1.26560
Epoch 1901/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4297 - val_loss: 1.2683 - val_accuracy: 0.4239

Epoch 01901: val_loss did not improve from 1.26560
Epoch 1902/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4283 - val_loss: 1.2704 - val_accuracy: 0.4159

Epoch 01902: val_loss did not improve from 1.26560
Epoch 1903/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4267 - val_loss: 1.2713 - val_accuracy: 0.4080

Epoch 01903: val_loss did not improve from 1.26560
Epoch 1904/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4291 - val_loss: 1.2773 - val_accuracy: 0.4000

Epoch 01904: val_loss did not improve from 1.26560
Epoch 1905/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4212 - val_loss: 1.2761 - val_accuracy: 0.4072

Epoch 01905: val_loss did not improve from 1.26560
Epoch 1906/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4267 - val_loss: 1.2709 - val_accuracy: 0.4159

Epoch 01906: val_loss did not improve from 1.26560
Epoch 1907/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4276 - val_loss: 1.2704 - val_accuracy: 0.4167

Epoch 01907: val_loss did not improve from 1.26560
Epoch 1908/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4255 - val_loss: 1.2731 - val_accuracy: 0.4096

Epoch 01908: val_loss did not improve from 1.26560
Epoch 1909/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4222 - val_loss: 1.2708 - val_accuracy: 0.4207

Epoch 01909: val_loss did not improve from 1.26560
Epoch 1910/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4219 - val_loss: 1.2710 - val_accuracy: 0.4120

Epoch 01910: val_loss did not improve from 1.26560
Epoch 1911/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4274 - val_loss: 1.2748 - val_accuracy: 0.4056

Epoch 01911: val_loss did not improve from 1.26560
Epoch 1912/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4289 - val_loss: 1.2697 - val_accuracy: 0.4239

Epoch 01912: val_loss did not improve from 1.26560
Epoch 1913/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4281 - val_loss: 1.2689 - val_accuracy: 0.4151

Epoch 01913: val_loss did not improve from 1.26560
Epoch 1914/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4227 - val_loss: 1.2680 - val_accuracy: 0.4167

Epoch 01914: val_loss did not improve from 1.26560
Epoch 1915/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4274 - val_loss: 1.2701 - val_accuracy: 0.4167

Epoch 01915: val_loss did not improve from 1.26560
Epoch 1916/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4250 - val_loss: 1.2722 - val_accuracy: 0.4159

Epoch 01916: val_loss did not improve from 1.26560
Epoch 1917/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4224 - val_loss: 1.2692 - val_accuracy: 0.4112

Epoch 01917: val_loss did not improve from 1.26560
Epoch 1918/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4254 - val_loss: 1.2673 - val_accuracy: 0.4327

Epoch 01918: val_loss did not improve from 1.26560
Epoch 1919/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4282 - val_loss: 1.2690 - val_accuracy: 0.4191

Epoch 01919: val_loss did not improve from 1.26560
Epoch 1920/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4221 - val_loss: 1.2705 - val_accuracy: 0.4048

Epoch 01920: val_loss did not improve from 1.26560
Epoch 1921/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4247 - val_loss: 1.2691 - val_accuracy: 0.4143

Epoch 01921: val_loss did not improve from 1.26560
Epoch 1922/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4267 - val_loss: 1.2743 - val_accuracy: 0.4104

Epoch 01922: val_loss did not improve from 1.26560
Epoch 1923/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4148 - val_loss: 1.2788 - val_accuracy: 0.4104

Epoch 01923: val_loss did not improve from 1.26560
Epoch 1924/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4236 - val_loss: 1.2777 - val_accuracy: 0.4064

Epoch 01924: val_loss did not improve from 1.26560
Epoch 1925/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4192 - val_loss: 1.2723 - val_accuracy: 0.4112

Epoch 01925: val_loss did not improve from 1.26560
Epoch 1926/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4235 - val_loss: 1.2648 - val_accuracy: 0.4231

Epoch 01926: val_loss improved from 1.26560 to 1.26478, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1927/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4252 - val_loss: 1.2700 - val_accuracy: 0.4167

Epoch 01927: val_loss did not improve from 1.26478
Epoch 1928/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4244 - val_loss: 1.2672 - val_accuracy: 0.4271

Epoch 01928: val_loss did not improve from 1.26478
Epoch 1929/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4249 - val_loss: 1.2652 - val_accuracy: 0.4183

Epoch 01929: val_loss did not improve from 1.26478
Epoch 1930/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4240 - val_loss: 1.2682 - val_accuracy: 0.4151

Epoch 01930: val_loss did not improve from 1.26478
Epoch 1931/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4284 - val_loss: 1.2712 - val_accuracy: 0.4191

Epoch 01931: val_loss did not improve from 1.26478
Epoch 1932/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4266 - val_loss: 1.2716 - val_accuracy: 0.4167

Epoch 01932: val_loss did not improve from 1.26478
Epoch 1933/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4260 - val_loss: 1.2685 - val_accuracy: 0.4207

Epoch 01933: val_loss did not improve from 1.26478
Epoch 1934/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4249 - val_loss: 1.2701 - val_accuracy: 0.4159

Epoch 01934: val_loss did not improve from 1.26478
Epoch 1935/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4255 - val_loss: 1.2734 - val_accuracy: 0.4127

Epoch 01935: val_loss did not improve from 1.26478
Epoch 1936/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4294 - val_loss: 1.2689 - val_accuracy: 0.4167

Epoch 01936: val_loss did not improve from 1.26478
Epoch 1937/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4246 - val_loss: 1.2697 - val_accuracy: 0.4167

Epoch 01937: val_loss did not improve from 1.26478
Epoch 1938/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4276 - val_loss: 1.2691 - val_accuracy: 0.4143

Epoch 01938: val_loss did not improve from 1.26478
Epoch 1939/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4238 - val_loss: 1.2728 - val_accuracy: 0.4112

Epoch 01939: val_loss did not improve from 1.26478
Epoch 1940/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4241 - val_loss: 1.2688 - val_accuracy: 0.4104

Epoch 01940: val_loss did not improve from 1.26478
Epoch 1941/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4237 - val_loss: 1.2668 - val_accuracy: 0.4215

Epoch 01941: val_loss did not improve from 1.26478
Epoch 1942/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4291 - val_loss: 1.2678 - val_accuracy: 0.4159

Epoch 01942: val_loss did not improve from 1.26478
Epoch 1943/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4244 - val_loss: 1.2706 - val_accuracy: 0.4183

Epoch 01943: val_loss did not improve from 1.26478
Epoch 1944/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4252 - val_loss: 1.2686 - val_accuracy: 0.4143

Epoch 01944: val_loss did not improve from 1.26478
Epoch 1945/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4276 - val_loss: 1.2698 - val_accuracy: 0.4151

Epoch 01945: val_loss did not improve from 1.26478
Epoch 1946/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4262 - val_loss: 1.2699 - val_accuracy: 0.4167

Epoch 01946: val_loss did not improve from 1.26478
Epoch 1947/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4207 - val_loss: 1.2717 - val_accuracy: 0.4167

Epoch 01947: val_loss did not improve from 1.26478
Epoch 1948/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4256 - val_loss: 1.2748 - val_accuracy: 0.4120

Epoch 01948: val_loss did not improve from 1.26478
Epoch 1949/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4185 - val_loss: 1.2703 - val_accuracy: 0.4199

Epoch 01949: val_loss did not improve from 1.26478
Epoch 1950/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4244 - val_loss: 1.2683 - val_accuracy: 0.4112

Epoch 01950: val_loss did not improve from 1.26478
Epoch 1951/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4238 - val_loss: 1.2755 - val_accuracy: 0.4127

Epoch 01951: val_loss did not improve from 1.26478
Epoch 1952/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4293 - val_loss: 1.2659 - val_accuracy: 0.4143

Epoch 01952: val_loss did not improve from 1.26478
Epoch 1953/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4295 - val_loss: 1.2694 - val_accuracy: 0.4127

Epoch 01953: val_loss did not improve from 1.26478
Epoch 1954/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4290 - val_loss: 1.2718 - val_accuracy: 0.4080

Epoch 01954: val_loss did not improve from 1.26478
Epoch 1955/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4275 - val_loss: 1.2711 - val_accuracy: 0.4127

Epoch 01955: val_loss did not improve from 1.26478
Epoch 1956/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4229 - val_loss: 1.2682 - val_accuracy: 0.4072

Epoch 01956: val_loss did not improve from 1.26478
Epoch 1957/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4256 - val_loss: 1.2670 - val_accuracy: 0.4223

Epoch 01957: val_loss did not improve from 1.26478
Epoch 1958/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4289 - val_loss: 1.2689 - val_accuracy: 0.4064

Epoch 01958: val_loss did not improve from 1.26478
Epoch 1959/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4223 - val_loss: 1.2708 - val_accuracy: 0.4159

Epoch 01959: val_loss did not improve from 1.26478
Epoch 1960/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4263 - val_loss: 1.2693 - val_accuracy: 0.4223

Epoch 01960: val_loss did not improve from 1.26478
Epoch 1961/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4291 - val_loss: 1.2669 - val_accuracy: 0.4167

Epoch 01961: val_loss did not improve from 1.26478
Epoch 1962/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4181 - val_loss: 1.2760 - val_accuracy: 0.3992

Epoch 01962: val_loss did not improve from 1.26478
Epoch 1963/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4234 - val_loss: 1.2698 - val_accuracy: 0.4104

Epoch 01963: val_loss did not improve from 1.26478
Epoch 1964/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4271 - val_loss: 1.2672 - val_accuracy: 0.4120

Epoch 01964: val_loss did not improve from 1.26478
Epoch 1965/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4267 - val_loss: 1.2682 - val_accuracy: 0.4295

Epoch 01965: val_loss did not improve from 1.26478
Epoch 1966/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4301 - val_loss: 1.2681 - val_accuracy: 0.4143

Epoch 01966: val_loss did not improve from 1.26478
Epoch 1967/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4295 - val_loss: 1.2712 - val_accuracy: 0.4215

Epoch 01967: val_loss did not improve from 1.26478
Epoch 1968/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4316 - val_loss: 1.2687 - val_accuracy: 0.4191

Epoch 01968: val_loss did not improve from 1.26478
Epoch 1969/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4292 - val_loss: 1.2681 - val_accuracy: 0.4167

Epoch 01969: val_loss did not improve from 1.26478
Epoch 1970/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4272 - val_loss: 1.2755 - val_accuracy: 0.4080

Epoch 01970: val_loss did not improve from 1.26478
Epoch 1971/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4257 - val_loss: 1.2687 - val_accuracy: 0.4159

Epoch 01971: val_loss did not improve from 1.26478
Epoch 1972/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4187 - val_loss: 1.2633 - val_accuracy: 0.4159

Epoch 01972: val_loss improved from 1.26478 to 1.26332, saving model to ./results/NN_thk_class/aggr_theta/ckpt_1
Epoch 1973/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4283 - val_loss: 1.2730 - val_accuracy: 0.4135

Epoch 01973: val_loss did not improve from 1.26332
Epoch 1974/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4283 - val_loss: 1.2709 - val_accuracy: 0.4151

Epoch 01974: val_loss did not improve from 1.26332
Epoch 1975/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4256 - val_loss: 1.2676 - val_accuracy: 0.4064

Epoch 01975: val_loss did not improve from 1.26332
Epoch 1976/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4203 - val_loss: 1.2696 - val_accuracy: 0.4127

Epoch 01976: val_loss did not improve from 1.26332
Epoch 1977/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4262 - val_loss: 1.2702 - val_accuracy: 0.4207

Epoch 01977: val_loss did not improve from 1.26332
Epoch 1978/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4253 - val_loss: 1.2683 - val_accuracy: 0.4151

Epoch 01978: val_loss did not improve from 1.26332
Epoch 1979/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4256 - val_loss: 1.2669 - val_accuracy: 0.4207

Epoch 01979: val_loss did not improve from 1.26332
Epoch 1980/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4258 - val_loss: 1.2683 - val_accuracy: 0.4175

Epoch 01980: val_loss did not improve from 1.26332
Epoch 1981/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4253 - val_loss: 1.2713 - val_accuracy: 0.4151

Epoch 01981: val_loss did not improve from 1.26332
Epoch 1982/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4271 - val_loss: 1.2685 - val_accuracy: 0.4135

Epoch 01982: val_loss did not improve from 1.26332
Epoch 1983/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4253 - val_loss: 1.2703 - val_accuracy: 0.4143

Epoch 01983: val_loss did not improve from 1.26332
Epoch 1984/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4258 - val_loss: 1.2708 - val_accuracy: 0.4159

Epoch 01984: val_loss did not improve from 1.26332
Epoch 1985/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4228 - val_loss: 1.2703 - val_accuracy: 0.4135

Epoch 01985: val_loss did not improve from 1.26332
Epoch 1986/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4275 - val_loss: 1.2669 - val_accuracy: 0.4120

Epoch 01986: val_loss did not improve from 1.26332
Epoch 1987/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4308 - val_loss: 1.2686 - val_accuracy: 0.4215

Epoch 01987: val_loss did not improve from 1.26332
Epoch 1988/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4283 - val_loss: 1.2686 - val_accuracy: 0.4112

Epoch 01988: val_loss did not improve from 1.26332
Epoch 1989/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4267 - val_loss: 1.2663 - val_accuracy: 0.4143

Epoch 01989: val_loss did not improve from 1.26332
Epoch 1990/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4244 - val_loss: 1.2686 - val_accuracy: 0.4151

Epoch 01990: val_loss did not improve from 1.26332
Epoch 1991/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4213 - val_loss: 1.2706 - val_accuracy: 0.4112

Epoch 01991: val_loss did not improve from 1.26332
Epoch 1992/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4229 - val_loss: 1.2693 - val_accuracy: 0.4135

Epoch 01992: val_loss did not improve from 1.26332
Epoch 1993/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4274 - val_loss: 1.2672 - val_accuracy: 0.4151

Epoch 01993: val_loss did not improve from 1.26332
Epoch 1994/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4320 - val_loss: 1.2700 - val_accuracy: 0.4167

Epoch 01994: val_loss did not improve from 1.26332
Epoch 1995/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4271 - val_loss: 1.2665 - val_accuracy: 0.4159

Epoch 01995: val_loss did not improve from 1.26332
Epoch 1996/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4261 - val_loss: 1.2672 - val_accuracy: 0.4215

Epoch 01996: val_loss did not improve from 1.26332
Epoch 1997/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4267 - val_loss: 1.2707 - val_accuracy: 0.4151

Epoch 01997: val_loss did not improve from 1.26332
Epoch 1998/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4260 - val_loss: 1.2724 - val_accuracy: 0.4104

Epoch 01998: val_loss did not improve from 1.26332
Epoch 1999/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4242 - val_loss: 1.2678 - val_accuracy: 0.4175

Epoch 01999: val_loss did not improve from 1.26332
Epoch 2000/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4246 - val_loss: 1.2697 - val_accuracy: 0.4143

Epoch 02000: val_loss did not improve from 1.26332
Epoch 2001/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4274 - val_loss: 1.2681 - val_accuracy: 0.4231

Epoch 02001: val_loss did not improve from 1.26332
Epoch 2002/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4264 - val_loss: 1.2677 - val_accuracy: 0.4127

Epoch 02002: val_loss did not improve from 1.26332
Epoch 2003/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4257 - val_loss: 1.2685 - val_accuracy: 0.4096

Epoch 02003: val_loss did not improve from 1.26332
Epoch 2004/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4213 - val_loss: 1.2659 - val_accuracy: 0.4183

Epoch 02004: val_loss did not improve from 1.26332
Epoch 2005/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4260 - val_loss: 1.2733 - val_accuracy: 0.4127

Epoch 02005: val_loss did not improve from 1.26332
Epoch 2006/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4257 - val_loss: 1.2678 - val_accuracy: 0.4135

Epoch 02006: val_loss did not improve from 1.26332
Epoch 2007/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4201 - val_loss: 1.2704 - val_accuracy: 0.4080

Epoch 02007: val_loss did not improve from 1.26332
Epoch 2008/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4229 - val_loss: 1.2686 - val_accuracy: 0.4159

Epoch 02008: val_loss did not improve from 1.26332
Epoch 2009/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4217 - val_loss: 1.2690 - val_accuracy: 0.4159

Epoch 02009: val_loss did not improve from 1.26332
Epoch 2010/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4204 - val_loss: 1.2706 - val_accuracy: 0.4088

Epoch 02010: val_loss did not improve from 1.26332
Epoch 2011/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4222 - val_loss: 1.2698 - val_accuracy: 0.4032

Epoch 02011: val_loss did not improve from 1.26332
Epoch 2012/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4265 - val_loss: 1.2712 - val_accuracy: 0.4112

Epoch 02012: val_loss did not improve from 1.26332
Epoch 2013/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4282 - val_loss: 1.2659 - val_accuracy: 0.4143

Epoch 02013: val_loss did not improve from 1.26332
Epoch 2014/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4213 - val_loss: 1.2702 - val_accuracy: 0.4183

Epoch 02014: val_loss did not improve from 1.26332
Epoch 2015/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4281 - val_loss: 1.2657 - val_accuracy: 0.4112

Epoch 02015: val_loss did not improve from 1.26332
Epoch 2016/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4224 - val_loss: 1.2659 - val_accuracy: 0.4080

Epoch 02016: val_loss did not improve from 1.26332
Epoch 2017/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4289 - val_loss: 1.2745 - val_accuracy: 0.4080

Epoch 02017: val_loss did not improve from 1.26332
Epoch 2018/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4206 - val_loss: 1.2691 - val_accuracy: 0.4143

Epoch 02018: val_loss did not improve from 1.26332
Epoch 2019/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4236 - val_loss: 1.2690 - val_accuracy: 0.4143

Epoch 02019: val_loss did not improve from 1.26332
Epoch 2020/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4224 - val_loss: 1.2677 - val_accuracy: 0.4175

Epoch 02020: val_loss did not improve from 1.26332
Epoch 2021/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4287 - val_loss: 1.2684 - val_accuracy: 0.4151

Epoch 02021: val_loss did not improve from 1.26332
Epoch 2022/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4277 - val_loss: 1.2676 - val_accuracy: 0.4167

Epoch 02022: val_loss did not improve from 1.26332
Epoch 2023/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4278 - val_loss: 1.2669 - val_accuracy: 0.4112

Epoch 02023: val_loss did not improve from 1.26332
Epoch 2024/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4218 - val_loss: 1.2680 - val_accuracy: 0.4072

Epoch 02024: val_loss did not improve from 1.26332
Epoch 2025/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4250 - val_loss: 1.2681 - val_accuracy: 0.4072

Epoch 02025: val_loss did not improve from 1.26332
Epoch 2026/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4236 - val_loss: 1.2693 - val_accuracy: 0.4127

Epoch 02026: val_loss did not improve from 1.26332
Epoch 2027/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4270 - val_loss: 1.2699 - val_accuracy: 0.4167

Epoch 02027: val_loss did not improve from 1.26332
Epoch 2028/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4275 - val_loss: 1.2681 - val_accuracy: 0.4143

Epoch 02028: val_loss did not improve from 1.26332
Epoch 2029/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4235 - val_loss: 1.2681 - val_accuracy: 0.4120

Epoch 02029: val_loss did not improve from 1.26332
Epoch 2030/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4251 - val_loss: 1.2663 - val_accuracy: 0.4151

Epoch 02030: val_loss did not improve from 1.26332
Epoch 2031/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4283 - val_loss: 1.2679 - val_accuracy: 0.4112

Epoch 02031: val_loss did not improve from 1.26332
Epoch 2032/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4227 - val_loss: 1.2700 - val_accuracy: 0.4104

Epoch 02032: val_loss did not improve from 1.26332
Epoch 2033/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4267 - val_loss: 1.2734 - val_accuracy: 0.4072

Epoch 02033: val_loss did not improve from 1.26332
Epoch 2034/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4257 - val_loss: 1.2679 - val_accuracy: 0.4072

Epoch 02034: val_loss did not improve from 1.26332
Epoch 2035/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4250 - val_loss: 1.2690 - val_accuracy: 0.4120

Epoch 02035: val_loss did not improve from 1.26332
Epoch 2036/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4260 - val_loss: 1.2695 - val_accuracy: 0.4143

Epoch 02036: val_loss did not improve from 1.26332
Epoch 2037/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4231 - val_loss: 1.2733 - val_accuracy: 0.4120

Epoch 02037: val_loss did not improve from 1.26332
Epoch 2038/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4260 - val_loss: 1.2703 - val_accuracy: 0.4008

Epoch 02038: val_loss did not improve from 1.26332
Epoch 2039/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4234 - val_loss: 1.2683 - val_accuracy: 0.4135

Epoch 02039: val_loss did not improve from 1.26332
Epoch 2040/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4247 - val_loss: 1.2685 - val_accuracy: 0.4112

Epoch 02040: val_loss did not improve from 1.26332
Epoch 2041/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4260 - val_loss: 1.2676 - val_accuracy: 0.4151

Epoch 02041: val_loss did not improve from 1.26332
Epoch 2042/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4280 - val_loss: 1.2687 - val_accuracy: 0.4231

Epoch 02042: val_loss did not improve from 1.26332
Epoch 2043/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4308 - val_loss: 1.2741 - val_accuracy: 0.4135

Epoch 02043: val_loss did not improve from 1.26332
Epoch 2044/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4229 - val_loss: 1.2728 - val_accuracy: 0.4080

Epoch 02044: val_loss did not improve from 1.26332
Epoch 2045/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4268 - val_loss: 1.2703 - val_accuracy: 0.4183

Epoch 02045: val_loss did not improve from 1.26332
Epoch 2046/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4249 - val_loss: 1.2685 - val_accuracy: 0.4135

Epoch 02046: val_loss did not improve from 1.26332
Epoch 2047/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4235 - val_loss: 1.2712 - val_accuracy: 0.3928

Epoch 02047: val_loss did not improve from 1.26332
Epoch 2048/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4221 - val_loss: 1.2686 - val_accuracy: 0.4120

Epoch 02048: val_loss did not improve from 1.26332
Epoch 2049/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4221 - val_loss: 1.2712 - val_accuracy: 0.4127

Epoch 02049: val_loss did not improve from 1.26332
Epoch 2050/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4270 - val_loss: 1.2714 - val_accuracy: 0.4183

Epoch 02050: val_loss did not improve from 1.26332
Epoch 2051/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4229 - val_loss: 1.2713 - val_accuracy: 0.4135

Epoch 02051: val_loss did not improve from 1.26332
Epoch 2052/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4244 - val_loss: 1.2676 - val_accuracy: 0.4048

Epoch 02052: val_loss did not improve from 1.26332
Epoch 2053/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4242 - val_loss: 1.2710 - val_accuracy: 0.4080

Epoch 02053: val_loss did not improve from 1.26332
Epoch 2054/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4294 - val_loss: 1.2700 - val_accuracy: 0.4167

Epoch 02054: val_loss did not improve from 1.26332
Epoch 2055/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4243 - val_loss: 1.2687 - val_accuracy: 0.4080

Epoch 02055: val_loss did not improve from 1.26332
Epoch 2056/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4283 - val_loss: 1.2666 - val_accuracy: 0.4120

Epoch 02056: val_loss did not improve from 1.26332
Epoch 2057/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4321 - val_loss: 1.2684 - val_accuracy: 0.4151

Epoch 02057: val_loss did not improve from 1.26332
Epoch 2058/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4276 - val_loss: 1.2681 - val_accuracy: 0.4175

Epoch 02058: val_loss did not improve from 1.26332
Epoch 2059/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4234 - val_loss: 1.2693 - val_accuracy: 0.4064

Epoch 02059: val_loss did not improve from 1.26332
Epoch 2060/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4328 - val_loss: 1.2671 - val_accuracy: 0.4223

Epoch 02060: val_loss did not improve from 1.26332
Epoch 2061/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4225 - val_loss: 1.2706 - val_accuracy: 0.4104

Epoch 02061: val_loss did not improve from 1.26332
Epoch 2062/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4286 - val_loss: 1.2691 - val_accuracy: 0.4207

Epoch 02062: val_loss did not improve from 1.26332
Epoch 2063/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4281 - val_loss: 1.2656 - val_accuracy: 0.4159

Epoch 02063: val_loss did not improve from 1.26332
Epoch 2064/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4222 - val_loss: 1.2734 - val_accuracy: 0.4072

Epoch 02064: val_loss did not improve from 1.26332
Epoch 2065/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4292 - val_loss: 1.2680 - val_accuracy: 0.4127

Epoch 02065: val_loss did not improve from 1.26332
Epoch 2066/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4222 - val_loss: 1.2662 - val_accuracy: 0.4183

Epoch 02066: val_loss did not improve from 1.26332
Epoch 2067/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4250 - val_loss: 1.2737 - val_accuracy: 0.4072

Epoch 02067: val_loss did not improve from 1.26332
Epoch 2068/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4282 - val_loss: 1.2776 - val_accuracy: 0.4080

Epoch 02068: val_loss did not improve from 1.26332
Epoch 2069/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4213 - val_loss: 1.2673 - val_accuracy: 0.4112

Epoch 02069: val_loss did not improve from 1.26332
Epoch 2070/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4312 - val_loss: 1.2722 - val_accuracy: 0.4024

Epoch 02070: val_loss did not improve from 1.26332
Epoch 2071/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4232 - val_loss: 1.2694 - val_accuracy: 0.4056

Epoch 02071: val_loss did not improve from 1.26332
Epoch 2072/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4269 - val_loss: 1.2715 - val_accuracy: 0.4191

Epoch 02072: val_loss did not improve from 1.26332
Epoch 2073/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4283 - val_loss: 1.2663 - val_accuracy: 0.4175

Epoch 02073: val_loss did not improve from 1.26332
Epoch 2074/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4260 - val_loss: 1.2700 - val_accuracy: 0.4159

Epoch 02074: val_loss did not improve from 1.26332
Epoch 2075/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4283 - val_loss: 1.2693 - val_accuracy: 0.4183

Epoch 02075: val_loss did not improve from 1.26332
Epoch 2076/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4276 - val_loss: 1.2698 - val_accuracy: 0.4151

Epoch 02076: val_loss did not improve from 1.26332
Epoch 2077/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4255 - val_loss: 1.2698 - val_accuracy: 0.4167

Epoch 02077: val_loss did not improve from 1.26332
Epoch 2078/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4272 - val_loss: 1.2691 - val_accuracy: 0.4183

Epoch 02078: val_loss did not improve from 1.26332
Epoch 2079/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4217 - val_loss: 1.2658 - val_accuracy: 0.4096

Epoch 02079: val_loss did not improve from 1.26332
Epoch 2080/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4278 - val_loss: 1.2678 - val_accuracy: 0.4096

Epoch 02080: val_loss did not improve from 1.26332
Epoch 2081/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4247 - val_loss: 1.2676 - val_accuracy: 0.4072

Epoch 02081: val_loss did not improve from 1.26332
Epoch 2082/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4230 - val_loss: 1.2726 - val_accuracy: 0.4104

Epoch 02082: val_loss did not improve from 1.26332
Epoch 2083/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4238 - val_loss: 1.2724 - val_accuracy: 0.4072

Epoch 02083: val_loss did not improve from 1.26332
Epoch 2084/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4305 - val_loss: 1.2799 - val_accuracy: 0.3984

Epoch 02084: val_loss did not improve from 1.26332
Epoch 2085/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4198 - val_loss: 1.2746 - val_accuracy: 0.4024

Epoch 02085: val_loss did not improve from 1.26332
Epoch 2086/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4211 - val_loss: 1.2684 - val_accuracy: 0.4191

Epoch 02086: val_loss did not improve from 1.26332
Epoch 2087/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4298 - val_loss: 1.2692 - val_accuracy: 0.4064

Epoch 02087: val_loss did not improve from 1.26332
Epoch 2088/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4269 - val_loss: 1.2702 - val_accuracy: 0.4072

Epoch 02088: val_loss did not improve from 1.26332
Epoch 2089/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4265 - val_loss: 1.2685 - val_accuracy: 0.4048

Epoch 02089: val_loss did not improve from 1.26332
Epoch 2090/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4248 - val_loss: 1.2671 - val_accuracy: 0.4143

Epoch 02090: val_loss did not improve from 1.26332
Epoch 2091/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4321 - val_loss: 1.2679 - val_accuracy: 0.4096

Epoch 02091: val_loss did not improve from 1.26332
Epoch 2092/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4237 - val_loss: 1.2669 - val_accuracy: 0.4088

Epoch 02092: val_loss did not improve from 1.26332
Epoch 2093/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4200 - val_loss: 1.2692 - val_accuracy: 0.4175

Epoch 02093: val_loss did not improve from 1.26332
Epoch 2094/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4201 - val_loss: 1.2748 - val_accuracy: 0.4112

Epoch 02094: val_loss did not improve from 1.26332
Epoch 2095/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4263 - val_loss: 1.2677 - val_accuracy: 0.4135

Epoch 02095: val_loss did not improve from 1.26332
Epoch 2096/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4169 - val_loss: 1.2666 - val_accuracy: 0.4215

Epoch 02096: val_loss did not improve from 1.26332
Epoch 2097/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4284 - val_loss: 1.2700 - val_accuracy: 0.4175

Epoch 02097: val_loss did not improve from 1.26332
Epoch 2098/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4308 - val_loss: 1.2638 - val_accuracy: 0.4231

Epoch 02098: val_loss did not improve from 1.26332
Epoch 2099/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4269 - val_loss: 1.2687 - val_accuracy: 0.4167

Epoch 02099: val_loss did not improve from 1.26332
Epoch 2100/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4274 - val_loss: 1.2671 - val_accuracy: 0.4207

Epoch 02100: val_loss did not improve from 1.26332
Epoch 2101/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4190 - val_loss: 1.2769 - val_accuracy: 0.4040

Epoch 02101: val_loss did not improve from 1.26332
Epoch 2102/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4246 - val_loss: 1.2694 - val_accuracy: 0.4151

Epoch 02102: val_loss did not improve from 1.26332
Epoch 2103/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4234 - val_loss: 1.2679 - val_accuracy: 0.4135

Epoch 02103: val_loss did not improve from 1.26332
Epoch 2104/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4266 - val_loss: 1.2689 - val_accuracy: 0.4143

Epoch 02104: val_loss did not improve from 1.26332
Epoch 2105/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4244 - val_loss: 1.2665 - val_accuracy: 0.4104

Epoch 02105: val_loss did not improve from 1.26332
Epoch 2106/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4294 - val_loss: 1.2674 - val_accuracy: 0.4151

Epoch 02106: val_loss did not improve from 1.26332
Epoch 2107/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4263 - val_loss: 1.2652 - val_accuracy: 0.4135

Epoch 02107: val_loss did not improve from 1.26332
Epoch 2108/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4222 - val_loss: 1.2668 - val_accuracy: 0.4064

Epoch 02108: val_loss did not improve from 1.26332
Epoch 2109/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4291 - val_loss: 1.2712 - val_accuracy: 0.4127

Epoch 02109: val_loss did not improve from 1.26332
Epoch 2110/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4254 - val_loss: 1.2691 - val_accuracy: 0.4096

Epoch 02110: val_loss did not improve from 1.26332
Epoch 2111/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4259 - val_loss: 1.2659 - val_accuracy: 0.4167

Epoch 02111: val_loss did not improve from 1.26332
Epoch 2112/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4240 - val_loss: 1.2672 - val_accuracy: 0.4080

Epoch 02112: val_loss did not improve from 1.26332
Epoch 2113/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4252 - val_loss: 1.2660 - val_accuracy: 0.4183

Epoch 02113: val_loss did not improve from 1.26332
Epoch 2114/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4266 - val_loss: 1.2697 - val_accuracy: 0.4135

Epoch 02114: val_loss did not improve from 1.26332
Epoch 2115/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4207 - val_loss: 1.2661 - val_accuracy: 0.4120

Epoch 02115: val_loss did not improve from 1.26332
Epoch 2116/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4239 - val_loss: 1.2655 - val_accuracy: 0.4159

Epoch 02116: val_loss did not improve from 1.26332
Epoch 2117/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4288 - val_loss: 1.2677 - val_accuracy: 0.4135

Epoch 02117: val_loss did not improve from 1.26332
Epoch 2118/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4269 - val_loss: 1.2695 - val_accuracy: 0.4112

Epoch 02118: val_loss did not improve from 1.26332
Epoch 2119/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4227 - val_loss: 1.2682 - val_accuracy: 0.4135

Epoch 02119: val_loss did not improve from 1.26332
Epoch 2120/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4275 - val_loss: 1.2673 - val_accuracy: 0.4104

Epoch 02120: val_loss did not improve from 1.26332
Epoch 2121/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4209 - val_loss: 1.2689 - val_accuracy: 0.4143

Epoch 02121: val_loss did not improve from 1.26332
Epoch 2122/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4259 - val_loss: 1.2677 - val_accuracy: 0.4167

Epoch 02122: val_loss did not improve from 1.26332
Epoch 2123/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4292 - val_loss: 1.2648 - val_accuracy: 0.4199

Epoch 02123: val_loss did not improve from 1.26332
Epoch 2124/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4274 - val_loss: 1.2666 - val_accuracy: 0.4215

Epoch 02124: val_loss did not improve from 1.26332
Epoch 2125/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4272 - val_loss: 1.2673 - val_accuracy: 0.4183

Epoch 02125: val_loss did not improve from 1.26332
Epoch 2126/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4306 - val_loss: 1.2681 - val_accuracy: 0.4183

Epoch 02126: val_loss did not improve from 1.26332
Epoch 2127/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4247 - val_loss: 1.2692 - val_accuracy: 0.4127

Epoch 02127: val_loss did not improve from 1.26332
Epoch 2128/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4259 - val_loss: 1.2699 - val_accuracy: 0.4104

Epoch 02128: val_loss did not improve from 1.26332
Epoch 2129/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4268 - val_loss: 1.2669 - val_accuracy: 0.4120

Epoch 02129: val_loss did not improve from 1.26332
Epoch 2130/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4273 - val_loss: 1.2680 - val_accuracy: 0.4064

Epoch 02130: val_loss did not improve from 1.26332
Epoch 2131/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4266 - val_loss: 1.2685 - val_accuracy: 0.4096

Epoch 02131: val_loss did not improve from 1.26332
Epoch 2132/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4284 - val_loss: 1.2674 - val_accuracy: 0.4199

Epoch 02132: val_loss did not improve from 1.26332
Epoch 2133/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4267 - val_loss: 1.2677 - val_accuracy: 0.4127

Epoch 02133: val_loss did not improve from 1.26332
Epoch 2134/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4250 - val_loss: 1.2720 - val_accuracy: 0.4135

Epoch 02134: val_loss did not improve from 1.26332
Epoch 2135/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4221 - val_loss: 1.2735 - val_accuracy: 0.4112

Epoch 02135: val_loss did not improve from 1.26332
Epoch 2136/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4216 - val_loss: 1.2649 - val_accuracy: 0.4167

Epoch 02136: val_loss did not improve from 1.26332
Epoch 2137/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4282 - val_loss: 1.2711 - val_accuracy: 0.4088

Epoch 02137: val_loss did not improve from 1.26332
Epoch 2138/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4236 - val_loss: 1.2700 - val_accuracy: 0.4112

Epoch 02138: val_loss did not improve from 1.26332
Epoch 2139/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4277 - val_loss: 1.2668 - val_accuracy: 0.4167

Epoch 02139: val_loss did not improve from 1.26332
Epoch 2140/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4248 - val_loss: 1.2691 - val_accuracy: 0.4096

Epoch 02140: val_loss did not improve from 1.26332
Epoch 2141/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4244 - val_loss: 1.2695 - val_accuracy: 0.4088

Epoch 02141: val_loss did not improve from 1.26332
Epoch 2142/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4270 - val_loss: 1.2725 - val_accuracy: 0.4056

Epoch 02142: val_loss did not improve from 1.26332
Epoch 2143/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4256 - val_loss: 1.2731 - val_accuracy: 0.4080

Epoch 02143: val_loss did not improve from 1.26332
Epoch 2144/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4204 - val_loss: 1.2695 - val_accuracy: 0.4080

Epoch 02144: val_loss did not improve from 1.26332
Epoch 2145/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4275 - val_loss: 1.2722 - val_accuracy: 0.4183

Epoch 02145: val_loss did not improve from 1.26332
Epoch 2146/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4295 - val_loss: 1.2703 - val_accuracy: 0.4080

Epoch 02146: val_loss did not improve from 1.26332
Epoch 2147/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4266 - val_loss: 1.2686 - val_accuracy: 0.4135

Epoch 02147: val_loss did not improve from 1.26332
Epoch 2148/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4249 - val_loss: 1.2683 - val_accuracy: 0.4183

Epoch 02148: val_loss did not improve from 1.26332
Epoch 2149/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4206 - val_loss: 1.2678 - val_accuracy: 0.4008

Epoch 02149: val_loss did not improve from 1.26332
Epoch 2150/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4280 - val_loss: 1.2688 - val_accuracy: 0.4215

Epoch 02150: val_loss did not improve from 1.26332
Epoch 2151/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4286 - val_loss: 1.2685 - val_accuracy: 0.4159

Epoch 02151: val_loss did not improve from 1.26332
Epoch 2152/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4248 - val_loss: 1.2709 - val_accuracy: 0.4064

Epoch 02152: val_loss did not improve from 1.26332
Epoch 2153/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4227 - val_loss: 1.2682 - val_accuracy: 0.4112

Epoch 02153: val_loss did not improve from 1.26332
Epoch 2154/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4214 - val_loss: 1.2722 - val_accuracy: 0.4112

Epoch 02154: val_loss did not improve from 1.26332
Epoch 2155/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4253 - val_loss: 1.2683 - val_accuracy: 0.4112

Epoch 02155: val_loss did not improve from 1.26332
Epoch 2156/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4271 - val_loss: 1.2666 - val_accuracy: 0.4199

Epoch 02156: val_loss did not improve from 1.26332
Epoch 2157/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4314 - val_loss: 1.2713 - val_accuracy: 0.4215

Epoch 02157: val_loss did not improve from 1.26332
Epoch 2158/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4314 - val_loss: 1.2677 - val_accuracy: 0.4215

Epoch 02158: val_loss did not improve from 1.26332
Epoch 2159/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4251 - val_loss: 1.2708 - val_accuracy: 0.4096

Epoch 02159: val_loss did not improve from 1.26332
Epoch 2160/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4230 - val_loss: 1.2693 - val_accuracy: 0.4072

Epoch 02160: val_loss did not improve from 1.26332
Epoch 2161/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4301 - val_loss: 1.2694 - val_accuracy: 0.4151

Epoch 02161: val_loss did not improve from 1.26332
Epoch 2162/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4236 - val_loss: 1.2731 - val_accuracy: 0.4135

Epoch 02162: val_loss did not improve from 1.26332
Epoch 2163/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4294 - val_loss: 1.2703 - val_accuracy: 0.4183

Epoch 02163: val_loss did not improve from 1.26332
Epoch 2164/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4299 - val_loss: 1.2692 - val_accuracy: 0.4143

Epoch 02164: val_loss did not improve from 1.26332
Epoch 2165/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4296 - val_loss: 1.2677 - val_accuracy: 0.4247

Epoch 02165: val_loss did not improve from 1.26332
Epoch 2166/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4275 - val_loss: 1.2713 - val_accuracy: 0.4143

Epoch 02166: val_loss did not improve from 1.26332
Epoch 2167/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4259 - val_loss: 1.2713 - val_accuracy: 0.4167

Epoch 02167: val_loss did not improve from 1.26332
Epoch 2168/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4257 - val_loss: 1.2706 - val_accuracy: 0.4151

Epoch 02168: val_loss did not improve from 1.26332
Epoch 2169/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4266 - val_loss: 1.2695 - val_accuracy: 0.4072

Epoch 02169: val_loss did not improve from 1.26332
Epoch 2170/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4298 - val_loss: 1.2649 - val_accuracy: 0.4135

Epoch 02170: val_loss did not improve from 1.26332
Epoch 2171/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4267 - val_loss: 1.2672 - val_accuracy: 0.4127

Epoch 02171: val_loss did not improve from 1.26332
Epoch 2172/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4278 - val_loss: 1.2675 - val_accuracy: 0.4088

Epoch 02172: val_loss did not improve from 1.26332
Epoch 02172: early stopping
*************************** Fold #: 2 ***************************
Model: "sequential_61"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_244 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_245 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_246 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_247 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6091 - accuracy: 0.2591 - val_loss: 1.6057 - val_accuracy: 0.2916

Epoch 00001: val_loss improved from inf to 1.60568, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2/10000
12/12 - 0s - loss: 1.6033 - accuracy: 0.2849 - val_loss: 1.6008 - val_accuracy: 0.3347

Epoch 00002: val_loss improved from 1.60568 to 1.60079, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 3/10000
12/12 - 0s - loss: 1.5973 - accuracy: 0.2952 - val_loss: 1.5933 - val_accuracy: 0.3363

Epoch 00003: val_loss improved from 1.60079 to 1.59326, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 4/10000
12/12 - 0s - loss: 1.5891 - accuracy: 0.3071 - val_loss: 1.5817 - val_accuracy: 0.3100

Epoch 00004: val_loss improved from 1.59326 to 1.58170, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 5/10000
12/12 - 0s - loss: 1.5762 - accuracy: 0.3291 - val_loss: 1.5648 - val_accuracy: 0.3426

Epoch 00005: val_loss improved from 1.58170 to 1.56477, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 6/10000
12/12 - 0s - loss: 1.5565 - accuracy: 0.3233 - val_loss: 1.5400 - val_accuracy: 0.3450

Epoch 00006: val_loss improved from 1.56477 to 1.54003, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 7/10000
12/12 - 0s - loss: 1.5300 - accuracy: 0.3413 - val_loss: 1.5072 - val_accuracy: 0.3538

Epoch 00007: val_loss improved from 1.54003 to 1.50715, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 8/10000
12/12 - 0s - loss: 1.4950 - accuracy: 0.3552 - val_loss: 1.4660 - val_accuracy: 0.3689

Epoch 00008: val_loss improved from 1.50715 to 1.46602, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 9/10000
12/12 - 0s - loss: 1.4545 - accuracy: 0.3642 - val_loss: 1.4234 - val_accuracy: 0.3641

Epoch 00009: val_loss improved from 1.46602 to 1.42340, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 10/10000
12/12 - 0s - loss: 1.4141 - accuracy: 0.3771 - val_loss: 1.3862 - val_accuracy: 0.3793

Epoch 00010: val_loss improved from 1.42340 to 1.38619, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 11/10000
12/12 - 0s - loss: 1.3816 - accuracy: 0.3750 - val_loss: 1.3597 - val_accuracy: 0.3729

Epoch 00011: val_loss improved from 1.38619 to 1.35968, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 12/10000
12/12 - 0s - loss: 1.3605 - accuracy: 0.3837 - val_loss: 1.3451 - val_accuracy: 0.4064

Epoch 00012: val_loss improved from 1.35968 to 1.34507, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 13/10000
12/12 - 0s - loss: 1.3453 - accuracy: 0.3857 - val_loss: 1.3381 - val_accuracy: 0.3817

Epoch 00013: val_loss improved from 1.34507 to 1.33809, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 14/10000
12/12 - 0s - loss: 1.3403 - accuracy: 0.3897 - val_loss: 1.3376 - val_accuracy: 0.3968

Epoch 00014: val_loss improved from 1.33809 to 1.33757, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 15/10000
12/12 - 0s - loss: 1.3368 - accuracy: 0.3897 - val_loss: 1.3415 - val_accuracy: 0.4024

Epoch 00015: val_loss did not improve from 1.33757
Epoch 16/10000
12/12 - 0s - loss: 1.3370 - accuracy: 0.4008 - val_loss: 1.3348 - val_accuracy: 0.3912

Epoch 00016: val_loss improved from 1.33757 to 1.33484, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 17/10000
12/12 - 0s - loss: 1.3375 - accuracy: 0.3889 - val_loss: 1.3304 - val_accuracy: 0.3825

Epoch 00017: val_loss improved from 1.33484 to 1.33043, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 18/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3882 - val_loss: 1.3281 - val_accuracy: 0.3873

Epoch 00018: val_loss improved from 1.33043 to 1.32808, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 19/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3888 - val_loss: 1.3282 - val_accuracy: 0.3817

Epoch 00019: val_loss did not improve from 1.32808
Epoch 20/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3908 - val_loss: 1.3339 - val_accuracy: 0.3865

Epoch 00020: val_loss did not improve from 1.32808
Epoch 21/10000
12/12 - 0s - loss: 1.3311 - accuracy: 0.3965 - val_loss: 1.3287 - val_accuracy: 0.3896

Epoch 00021: val_loss did not improve from 1.32808
Epoch 22/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3917 - val_loss: 1.3291 - val_accuracy: 0.3825

Epoch 00022: val_loss did not improve from 1.32808
Epoch 23/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3918 - val_loss: 1.3341 - val_accuracy: 0.3705

Epoch 00023: val_loss did not improve from 1.32808
Epoch 24/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3914 - val_loss: 1.3278 - val_accuracy: 0.3865

Epoch 00024: val_loss improved from 1.32808 to 1.32778, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 25/10000
12/12 - 0s - loss: 1.3298 - accuracy: 0.3879 - val_loss: 1.3288 - val_accuracy: 0.3857

Epoch 00025: val_loss did not improve from 1.32778
Epoch 26/10000
12/12 - 0s - loss: 1.3309 - accuracy: 0.3910 - val_loss: 1.3315 - val_accuracy: 0.3904

Epoch 00026: val_loss did not improve from 1.32778
Epoch 27/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3938 - val_loss: 1.3295 - val_accuracy: 0.3936

Epoch 00027: val_loss did not improve from 1.32778
Epoch 28/10000
12/12 - 0s - loss: 1.3295 - accuracy: 0.3979 - val_loss: 1.3281 - val_accuracy: 0.3801

Epoch 00028: val_loss did not improve from 1.32778
Epoch 29/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.4000 - val_loss: 1.3320 - val_accuracy: 0.3944

Epoch 00029: val_loss did not improve from 1.32778
Epoch 30/10000
12/12 - 0s - loss: 1.3292 - accuracy: 0.3893 - val_loss: 1.3296 - val_accuracy: 0.3873

Epoch 00030: val_loss did not improve from 1.32778
Epoch 31/10000
12/12 - 0s - loss: 1.3287 - accuracy: 0.3949 - val_loss: 1.3315 - val_accuracy: 0.3849

Epoch 00031: val_loss did not improve from 1.32778
Epoch 32/10000
12/12 - 0s - loss: 1.3292 - accuracy: 0.3923 - val_loss: 1.3281 - val_accuracy: 0.3952

Epoch 00032: val_loss did not improve from 1.32778
Epoch 33/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3955 - val_loss: 1.3334 - val_accuracy: 0.4024

Epoch 00033: val_loss did not improve from 1.32778
Epoch 34/10000
12/12 - 0s - loss: 1.3295 - accuracy: 0.3963 - val_loss: 1.3317 - val_accuracy: 0.3849

Epoch 00034: val_loss did not improve from 1.32778
Epoch 35/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3919 - val_loss: 1.3407 - val_accuracy: 0.3904

Epoch 00035: val_loss did not improve from 1.32778
Epoch 36/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3874 - val_loss: 1.3282 - val_accuracy: 0.3777

Epoch 00036: val_loss did not improve from 1.32778
Epoch 37/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3915 - val_loss: 1.3274 - val_accuracy: 0.3928

Epoch 00037: val_loss improved from 1.32778 to 1.32740, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 38/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3940 - val_loss: 1.3293 - val_accuracy: 0.3912

Epoch 00038: val_loss did not improve from 1.32740
Epoch 39/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3973 - val_loss: 1.3268 - val_accuracy: 0.3904

Epoch 00039: val_loss improved from 1.32740 to 1.32680, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 40/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3967 - val_loss: 1.3256 - val_accuracy: 0.3944

Epoch 00040: val_loss improved from 1.32680 to 1.32557, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 41/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3953 - val_loss: 1.3287 - val_accuracy: 0.3896

Epoch 00041: val_loss did not improve from 1.32557
Epoch 42/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3951 - val_loss: 1.3323 - val_accuracy: 0.3920

Epoch 00042: val_loss did not improve from 1.32557
Epoch 43/10000
12/12 - 0s - loss: 1.3284 - accuracy: 0.3981 - val_loss: 1.3280 - val_accuracy: 0.3857

Epoch 00043: val_loss did not improve from 1.32557
Epoch 44/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3957 - val_loss: 1.3282 - val_accuracy: 0.3793

Epoch 00044: val_loss did not improve from 1.32557
Epoch 45/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3964 - val_loss: 1.3334 - val_accuracy: 0.3952

Epoch 00045: val_loss did not improve from 1.32557
Epoch 46/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3981 - val_loss: 1.3258 - val_accuracy: 0.3849

Epoch 00046: val_loss did not improve from 1.32557
Epoch 47/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3905 - val_loss: 1.3255 - val_accuracy: 0.3825

Epoch 00047: val_loss improved from 1.32557 to 1.32545, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 48/10000
12/12 - 0s - loss: 1.3257 - accuracy: 0.3971 - val_loss: 1.3262 - val_accuracy: 0.4024

Epoch 00048: val_loss did not improve from 1.32545
Epoch 49/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3983 - val_loss: 1.3257 - val_accuracy: 0.3920

Epoch 00049: val_loss did not improve from 1.32545
Epoch 50/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3978 - val_loss: 1.3255 - val_accuracy: 0.3920

Epoch 00050: val_loss did not improve from 1.32545
Epoch 51/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3941 - val_loss: 1.3335 - val_accuracy: 0.3960

Epoch 00051: val_loss did not improve from 1.32545
Epoch 52/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3966 - val_loss: 1.3243 - val_accuracy: 0.3833

Epoch 00052: val_loss improved from 1.32545 to 1.32429, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 53/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3957 - val_loss: 1.3253 - val_accuracy: 0.3904

Epoch 00053: val_loss did not improve from 1.32429
Epoch 54/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3930 - val_loss: 1.3287 - val_accuracy: 0.3825

Epoch 00054: val_loss did not improve from 1.32429
Epoch 55/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3926 - val_loss: 1.3264 - val_accuracy: 0.3833

Epoch 00055: val_loss did not improve from 1.32429
Epoch 56/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3966 - val_loss: 1.3242 - val_accuracy: 0.4064

Epoch 00056: val_loss improved from 1.32429 to 1.32423, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 57/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3944 - val_loss: 1.3237 - val_accuracy: 0.3880

Epoch 00057: val_loss improved from 1.32423 to 1.32368, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 58/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3954 - val_loss: 1.3257 - val_accuracy: 0.3833

Epoch 00058: val_loss did not improve from 1.32368
Epoch 59/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3889 - val_loss: 1.3278 - val_accuracy: 0.3833

Epoch 00059: val_loss did not improve from 1.32368
Epoch 60/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3852 - val_loss: 1.3314 - val_accuracy: 0.3857

Epoch 00060: val_loss did not improve from 1.32368
Epoch 61/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3937 - val_loss: 1.3235 - val_accuracy: 0.3904

Epoch 00061: val_loss improved from 1.32368 to 1.32346, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 62/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3952 - val_loss: 1.3243 - val_accuracy: 0.3992

Epoch 00062: val_loss did not improve from 1.32346
Epoch 63/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3933 - val_loss: 1.3237 - val_accuracy: 0.3873

Epoch 00063: val_loss did not improve from 1.32346
Epoch 64/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3973 - val_loss: 1.3244 - val_accuracy: 0.3785

Epoch 00064: val_loss did not improve from 1.32346
Epoch 65/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3963 - val_loss: 1.3300 - val_accuracy: 0.3976

Epoch 00065: val_loss did not improve from 1.32346
Epoch 66/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3981 - val_loss: 1.3238 - val_accuracy: 0.3960

Epoch 00066: val_loss did not improve from 1.32346
Epoch 67/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3957 - val_loss: 1.3229 - val_accuracy: 0.3857

Epoch 00067: val_loss improved from 1.32346 to 1.32291, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 68/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3939 - val_loss: 1.3293 - val_accuracy: 0.4016

Epoch 00068: val_loss did not improve from 1.32291
Epoch 69/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3960 - val_loss: 1.3227 - val_accuracy: 0.3857

Epoch 00069: val_loss improved from 1.32291 to 1.32269, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 70/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3926 - val_loss: 1.3295 - val_accuracy: 0.4032

Epoch 00070: val_loss did not improve from 1.32269
Epoch 71/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3932 - val_loss: 1.3221 - val_accuracy: 0.3817

Epoch 00071: val_loss improved from 1.32269 to 1.32214, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 72/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3933 - val_loss: 1.3214 - val_accuracy: 0.3841

Epoch 00072: val_loss improved from 1.32214 to 1.32144, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 73/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3971 - val_loss: 1.3217 - val_accuracy: 0.3944

Epoch 00073: val_loss did not improve from 1.32144
Epoch 74/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3992 - val_loss: 1.3241 - val_accuracy: 0.3865

Epoch 00074: val_loss did not improve from 1.32144
Epoch 75/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3923 - val_loss: 1.3236 - val_accuracy: 0.3904

Epoch 00075: val_loss did not improve from 1.32144
Epoch 76/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3899 - val_loss: 1.3351 - val_accuracy: 0.4024

Epoch 00076: val_loss did not improve from 1.32144
Epoch 77/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3956 - val_loss: 1.3261 - val_accuracy: 0.3801

Epoch 00077: val_loss did not improve from 1.32144
Epoch 78/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3971 - val_loss: 1.3306 - val_accuracy: 0.4056

Epoch 00078: val_loss did not improve from 1.32144
Epoch 79/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3944 - val_loss: 1.3229 - val_accuracy: 0.3825

Epoch 00079: val_loss did not improve from 1.32144
Epoch 80/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3945 - val_loss: 1.3266 - val_accuracy: 0.3849

Epoch 00080: val_loss did not improve from 1.32144
Epoch 81/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3970 - val_loss: 1.3233 - val_accuracy: 0.3873

Epoch 00081: val_loss did not improve from 1.32144
Epoch 82/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3920 - val_loss: 1.3280 - val_accuracy: 0.3936

Epoch 00082: val_loss did not improve from 1.32144
Epoch 83/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3952 - val_loss: 1.3237 - val_accuracy: 0.3960

Epoch 00083: val_loss did not improve from 1.32144
Epoch 84/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3950 - val_loss: 1.3212 - val_accuracy: 0.3825

Epoch 00084: val_loss improved from 1.32144 to 1.32116, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 85/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3929 - val_loss: 1.3212 - val_accuracy: 0.3936

Epoch 00085: val_loss did not improve from 1.32116
Epoch 86/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3915 - val_loss: 1.3229 - val_accuracy: 0.3976

Epoch 00086: val_loss did not improve from 1.32116
Epoch 87/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3919 - val_loss: 1.3241 - val_accuracy: 0.3984

Epoch 00087: val_loss did not improve from 1.32116
Epoch 88/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3929 - val_loss: 1.3242 - val_accuracy: 0.3912

Epoch 00088: val_loss did not improve from 1.32116
Epoch 89/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.4000 - val_loss: 1.3238 - val_accuracy: 0.3865

Epoch 00089: val_loss did not improve from 1.32116
Epoch 90/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3980 - val_loss: 1.3226 - val_accuracy: 0.3976

Epoch 00090: val_loss did not improve from 1.32116
Epoch 91/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3968 - val_loss: 1.3234 - val_accuracy: 0.3968

Epoch 00091: val_loss did not improve from 1.32116
Epoch 92/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3955 - val_loss: 1.3235 - val_accuracy: 0.3920

Epoch 00092: val_loss did not improve from 1.32116
Epoch 93/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3980 - val_loss: 1.3216 - val_accuracy: 0.3896

Epoch 00093: val_loss did not improve from 1.32116
Epoch 94/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3960 - val_loss: 1.3220 - val_accuracy: 0.3944

Epoch 00094: val_loss did not improve from 1.32116
Epoch 95/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3934 - val_loss: 1.3212 - val_accuracy: 0.3888

Epoch 00095: val_loss did not improve from 1.32116
Epoch 96/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3959 - val_loss: 1.3234 - val_accuracy: 0.4048

Epoch 00096: val_loss did not improve from 1.32116
Epoch 97/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3985 - val_loss: 1.3204 - val_accuracy: 0.3968

Epoch 00097: val_loss improved from 1.32116 to 1.32038, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 98/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3987 - val_loss: 1.3217 - val_accuracy: 0.3976

Epoch 00098: val_loss did not improve from 1.32038
Epoch 99/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3965 - val_loss: 1.3248 - val_accuracy: 0.3904

Epoch 00099: val_loss did not improve from 1.32038
Epoch 100/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3942 - val_loss: 1.3230 - val_accuracy: 0.3833

Epoch 00100: val_loss did not improve from 1.32038
Epoch 101/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3896 - val_loss: 1.3223 - val_accuracy: 0.3920

Epoch 00101: val_loss did not improve from 1.32038
Epoch 102/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3895 - val_loss: 1.3257 - val_accuracy: 0.3968

Epoch 00102: val_loss did not improve from 1.32038
Epoch 103/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3965 - val_loss: 1.3215 - val_accuracy: 0.3928

Epoch 00103: val_loss did not improve from 1.32038
Epoch 104/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3943 - val_loss: 1.3255 - val_accuracy: 0.3984

Epoch 00104: val_loss did not improve from 1.32038
Epoch 105/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3957 - val_loss: 1.3206 - val_accuracy: 0.3904

Epoch 00105: val_loss did not improve from 1.32038
Epoch 106/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3957 - val_loss: 1.3199 - val_accuracy: 0.3865

Epoch 00106: val_loss improved from 1.32038 to 1.31990, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 107/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3967 - val_loss: 1.3228 - val_accuracy: 0.3960

Epoch 00107: val_loss did not improve from 1.31990
Epoch 108/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3926 - val_loss: 1.3213 - val_accuracy: 0.3896

Epoch 00108: val_loss did not improve from 1.31990
Epoch 109/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3924 - val_loss: 1.3199 - val_accuracy: 0.3912

Epoch 00109: val_loss improved from 1.31990 to 1.31987, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 110/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3973 - val_loss: 1.3250 - val_accuracy: 0.4000

Epoch 00110: val_loss did not improve from 1.31987
Epoch 111/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3984 - val_loss: 1.3213 - val_accuracy: 0.3944

Epoch 00111: val_loss did not improve from 1.31987
Epoch 112/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3976 - val_loss: 1.3190 - val_accuracy: 0.3928

Epoch 00112: val_loss improved from 1.31987 to 1.31905, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 113/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3956 - val_loss: 1.3220 - val_accuracy: 0.4048

Epoch 00113: val_loss did not improve from 1.31905
Epoch 114/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3953 - val_loss: 1.3203 - val_accuracy: 0.3833

Epoch 00114: val_loss did not improve from 1.31905
Epoch 115/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3930 - val_loss: 1.3229 - val_accuracy: 0.3928

Epoch 00115: val_loss did not improve from 1.31905
Epoch 116/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3926 - val_loss: 1.3216 - val_accuracy: 0.3976

Epoch 00116: val_loss did not improve from 1.31905
Epoch 117/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3978 - val_loss: 1.3198 - val_accuracy: 0.3825

Epoch 00117: val_loss did not improve from 1.31905
Epoch 118/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3941 - val_loss: 1.3317 - val_accuracy: 0.4040

Epoch 00118: val_loss did not improve from 1.31905
Epoch 119/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3944 - val_loss: 1.3204 - val_accuracy: 0.3825

Epoch 00119: val_loss did not improve from 1.31905
Epoch 120/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3986 - val_loss: 1.3187 - val_accuracy: 0.3976

Epoch 00120: val_loss improved from 1.31905 to 1.31872, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 121/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3929 - val_loss: 1.3232 - val_accuracy: 0.3960

Epoch 00121: val_loss did not improve from 1.31872
Epoch 122/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3959 - val_loss: 1.3196 - val_accuracy: 0.3896

Epoch 00122: val_loss did not improve from 1.31872
Epoch 123/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3988 - val_loss: 1.3185 - val_accuracy: 0.3896

Epoch 00123: val_loss improved from 1.31872 to 1.31846, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 124/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3951 - val_loss: 1.3262 - val_accuracy: 0.3976

Epoch 00124: val_loss did not improve from 1.31846
Epoch 125/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3983 - val_loss: 1.3194 - val_accuracy: 0.3857

Epoch 00125: val_loss did not improve from 1.31846
Epoch 126/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3965 - val_loss: 1.3210 - val_accuracy: 0.4080

Epoch 00126: val_loss did not improve from 1.31846
Epoch 127/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3942 - val_loss: 1.3175 - val_accuracy: 0.3857

Epoch 00127: val_loss improved from 1.31846 to 1.31745, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 128/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3984 - val_loss: 1.3205 - val_accuracy: 0.3984

Epoch 00128: val_loss did not improve from 1.31745
Epoch 129/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3969 - val_loss: 1.3213 - val_accuracy: 0.4024

Epoch 00129: val_loss did not improve from 1.31745
Epoch 130/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3993 - val_loss: 1.3187 - val_accuracy: 0.3912

Epoch 00130: val_loss did not improve from 1.31745
Epoch 131/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3987 - val_loss: 1.3183 - val_accuracy: 0.4016

Epoch 00131: val_loss did not improve from 1.31745
Epoch 132/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3978 - val_loss: 1.3202 - val_accuracy: 0.4024

Epoch 00132: val_loss did not improve from 1.31745
Epoch 133/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3979 - val_loss: 1.3191 - val_accuracy: 0.3896

Epoch 00133: val_loss did not improve from 1.31745
Epoch 134/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3939 - val_loss: 1.3186 - val_accuracy: 0.3960

Epoch 00134: val_loss did not improve from 1.31745
Epoch 135/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3957 - val_loss: 1.3276 - val_accuracy: 0.4072

Epoch 00135: val_loss did not improve from 1.31745
Epoch 136/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3972 - val_loss: 1.3231 - val_accuracy: 0.3865

Epoch 00136: val_loss did not improve from 1.31745
Epoch 137/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3960 - val_loss: 1.3203 - val_accuracy: 0.4056

Epoch 00137: val_loss did not improve from 1.31745
Epoch 138/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3966 - val_loss: 1.3184 - val_accuracy: 0.4032

Epoch 00138: val_loss did not improve from 1.31745
Epoch 139/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.4017 - val_loss: 1.3176 - val_accuracy: 0.3936

Epoch 00139: val_loss did not improve from 1.31745
Epoch 140/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3968 - val_loss: 1.3189 - val_accuracy: 0.3952

Epoch 00140: val_loss did not improve from 1.31745
Epoch 141/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3927 - val_loss: 1.3231 - val_accuracy: 0.3960

Epoch 00141: val_loss did not improve from 1.31745
Epoch 142/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3999 - val_loss: 1.3183 - val_accuracy: 0.3912

Epoch 00142: val_loss did not improve from 1.31745
Epoch 143/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3994 - val_loss: 1.3192 - val_accuracy: 0.3976

Epoch 00143: val_loss did not improve from 1.31745
Epoch 144/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3957 - val_loss: 1.3167 - val_accuracy: 0.3960

Epoch 00144: val_loss improved from 1.31745 to 1.31670, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 145/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3985 - val_loss: 1.3183 - val_accuracy: 0.3936

Epoch 00145: val_loss did not improve from 1.31670
Epoch 146/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3972 - val_loss: 1.3228 - val_accuracy: 0.4080

Epoch 00146: val_loss did not improve from 1.31670
Epoch 147/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3999 - val_loss: 1.3181 - val_accuracy: 0.3825

Epoch 00147: val_loss did not improve from 1.31670
Epoch 148/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3899 - val_loss: 1.3203 - val_accuracy: 0.4008

Epoch 00148: val_loss did not improve from 1.31670
Epoch 149/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3999 - val_loss: 1.3197 - val_accuracy: 0.4016

Epoch 00149: val_loss did not improve from 1.31670
Epoch 150/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.4010 - val_loss: 1.3179 - val_accuracy: 0.3968

Epoch 00150: val_loss did not improve from 1.31670
Epoch 151/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4006 - val_loss: 1.3168 - val_accuracy: 0.3992

Epoch 00151: val_loss did not improve from 1.31670
Epoch 152/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4017 - val_loss: 1.3174 - val_accuracy: 0.4024

Epoch 00152: val_loss did not improve from 1.31670
Epoch 153/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3998 - val_loss: 1.3171 - val_accuracy: 0.3904

Epoch 00153: val_loss did not improve from 1.31670
Epoch 154/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3954 - val_loss: 1.3181 - val_accuracy: 0.3968

Epoch 00154: val_loss did not improve from 1.31670
Epoch 155/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3980 - val_loss: 1.3258 - val_accuracy: 0.3976

Epoch 00155: val_loss did not improve from 1.31670
Epoch 156/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3942 - val_loss: 1.3181 - val_accuracy: 0.3865

Epoch 00156: val_loss did not improve from 1.31670
Epoch 157/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3972 - val_loss: 1.3247 - val_accuracy: 0.4080

Epoch 00157: val_loss did not improve from 1.31670
Epoch 158/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4008 - val_loss: 1.3184 - val_accuracy: 0.3976

Epoch 00158: val_loss did not improve from 1.31670
Epoch 159/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.4023 - val_loss: 1.3200 - val_accuracy: 0.3841

Epoch 00159: val_loss did not improve from 1.31670
Epoch 160/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3884 - val_loss: 1.3207 - val_accuracy: 0.3912

Epoch 00160: val_loss did not improve from 1.31670
Epoch 161/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3949 - val_loss: 1.3169 - val_accuracy: 0.4024

Epoch 00161: val_loss did not improve from 1.31670
Epoch 162/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3993 - val_loss: 1.3193 - val_accuracy: 0.4000

Epoch 00162: val_loss did not improve from 1.31670
Epoch 163/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3971 - val_loss: 1.3167 - val_accuracy: 0.3944

Epoch 00163: val_loss improved from 1.31670 to 1.31666, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 164/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3950 - val_loss: 1.3171 - val_accuracy: 0.3968

Epoch 00164: val_loss did not improve from 1.31666
Epoch 165/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3981 - val_loss: 1.3152 - val_accuracy: 0.4000

Epoch 00165: val_loss improved from 1.31666 to 1.31524, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 166/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.4046 - val_loss: 1.3196 - val_accuracy: 0.4120

Epoch 00166: val_loss did not improve from 1.31524
Epoch 167/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3988 - val_loss: 1.3178 - val_accuracy: 0.4016

Epoch 00167: val_loss did not improve from 1.31524
Epoch 168/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3949 - val_loss: 1.3182 - val_accuracy: 0.3968

Epoch 00168: val_loss did not improve from 1.31524
Epoch 169/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3911 - val_loss: 1.3183 - val_accuracy: 0.4000

Epoch 00169: val_loss did not improve from 1.31524
Epoch 170/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3997 - val_loss: 1.3151 - val_accuracy: 0.3968

Epoch 00170: val_loss improved from 1.31524 to 1.31509, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 171/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3979 - val_loss: 1.3168 - val_accuracy: 0.4096

Epoch 00171: val_loss did not improve from 1.31509
Epoch 172/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3979 - val_loss: 1.3172 - val_accuracy: 0.4096

Epoch 00172: val_loss did not improve from 1.31509
Epoch 173/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.4035 - val_loss: 1.3148 - val_accuracy: 0.3968

Epoch 00173: val_loss improved from 1.31509 to 1.31480, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 174/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3983 - val_loss: 1.3167 - val_accuracy: 0.3976

Epoch 00174: val_loss did not improve from 1.31480
Epoch 175/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4006 - val_loss: 1.3168 - val_accuracy: 0.3960

Epoch 00175: val_loss did not improve from 1.31480
Epoch 176/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4007 - val_loss: 1.3150 - val_accuracy: 0.4056

Epoch 00176: val_loss did not improve from 1.31480
Epoch 177/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3995 - val_loss: 1.3157 - val_accuracy: 0.4024

Epoch 00177: val_loss did not improve from 1.31480
Epoch 178/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3957 - val_loss: 1.3174 - val_accuracy: 0.4000

Epoch 00178: val_loss did not improve from 1.31480
Epoch 179/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4012 - val_loss: 1.3153 - val_accuracy: 0.3984

Epoch 00179: val_loss did not improve from 1.31480
Epoch 180/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4009 - val_loss: 1.3169 - val_accuracy: 0.4048

Epoch 00180: val_loss did not improve from 1.31480
Epoch 181/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3981 - val_loss: 1.3157 - val_accuracy: 0.3968

Epoch 00181: val_loss did not improve from 1.31480
Epoch 182/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3973 - val_loss: 1.3160 - val_accuracy: 0.3984

Epoch 00182: val_loss did not improve from 1.31480
Epoch 183/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3940 - val_loss: 1.3191 - val_accuracy: 0.4000

Epoch 00183: val_loss did not improve from 1.31480
Epoch 184/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4013 - val_loss: 1.3153 - val_accuracy: 0.3984

Epoch 00184: val_loss did not improve from 1.31480
Epoch 185/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4012 - val_loss: 1.3148 - val_accuracy: 0.4040

Epoch 00185: val_loss did not improve from 1.31480
Epoch 186/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.4043 - val_loss: 1.3144 - val_accuracy: 0.3976

Epoch 00186: val_loss improved from 1.31480 to 1.31440, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 187/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3981 - val_loss: 1.3194 - val_accuracy: 0.4088

Epoch 00187: val_loss did not improve from 1.31440
Epoch 188/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4044 - val_loss: 1.3176 - val_accuracy: 0.3880

Epoch 00188: val_loss did not improve from 1.31440
Epoch 189/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3965 - val_loss: 1.3210 - val_accuracy: 0.4016

Epoch 00189: val_loss did not improve from 1.31440
Epoch 190/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3990 - val_loss: 1.3149 - val_accuracy: 0.3984

Epoch 00190: val_loss did not improve from 1.31440
Epoch 191/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4035 - val_loss: 1.3137 - val_accuracy: 0.3968

Epoch 00191: val_loss improved from 1.31440 to 1.31373, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 192/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3989 - val_loss: 1.3140 - val_accuracy: 0.3960

Epoch 00192: val_loss did not improve from 1.31373
Epoch 193/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3932 - val_loss: 1.3233 - val_accuracy: 0.4135

Epoch 00193: val_loss did not improve from 1.31373
Epoch 194/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4001 - val_loss: 1.3134 - val_accuracy: 0.4000

Epoch 00194: val_loss improved from 1.31373 to 1.31340, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 195/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3998 - val_loss: 1.3125 - val_accuracy: 0.3928

Epoch 00195: val_loss improved from 1.31340 to 1.31246, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 196/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3931 - val_loss: 1.3157 - val_accuracy: 0.4048

Epoch 00196: val_loss did not improve from 1.31246
Epoch 197/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3988 - val_loss: 1.3151 - val_accuracy: 0.3968

Epoch 00197: val_loss did not improve from 1.31246
Epoch 198/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4018 - val_loss: 1.3152 - val_accuracy: 0.4008

Epoch 00198: val_loss did not improve from 1.31246
Epoch 199/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4019 - val_loss: 1.3172 - val_accuracy: 0.4088

Epoch 00199: val_loss did not improve from 1.31246
Epoch 200/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4015 - val_loss: 1.3161 - val_accuracy: 0.3912

Epoch 00200: val_loss did not improve from 1.31246
Epoch 201/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4018 - val_loss: 1.3188 - val_accuracy: 0.4016

Epoch 00201: val_loss did not improve from 1.31246
Epoch 202/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4016 - val_loss: 1.3134 - val_accuracy: 0.3960

Epoch 00202: val_loss did not improve from 1.31246
Epoch 203/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4004 - val_loss: 1.3151 - val_accuracy: 0.3968

Epoch 00203: val_loss did not improve from 1.31246
Epoch 204/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3970 - val_loss: 1.3165 - val_accuracy: 0.4032

Epoch 00204: val_loss did not improve from 1.31246
Epoch 205/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4014 - val_loss: 1.3144 - val_accuracy: 0.3976

Epoch 00205: val_loss did not improve from 1.31246
Epoch 206/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3987 - val_loss: 1.3148 - val_accuracy: 0.4016

Epoch 00206: val_loss did not improve from 1.31246
Epoch 207/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3978 - val_loss: 1.3166 - val_accuracy: 0.4024

Epoch 00207: val_loss did not improve from 1.31246
Epoch 208/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3987 - val_loss: 1.3164 - val_accuracy: 0.4048

Epoch 00208: val_loss did not improve from 1.31246
Epoch 209/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4000 - val_loss: 1.3146 - val_accuracy: 0.3992

Epoch 00209: val_loss did not improve from 1.31246
Epoch 210/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3950 - val_loss: 1.3216 - val_accuracy: 0.3944

Epoch 00210: val_loss did not improve from 1.31246
Epoch 211/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3991 - val_loss: 1.3165 - val_accuracy: 0.3960

Epoch 00211: val_loss did not improve from 1.31246
Epoch 212/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3981 - val_loss: 1.3146 - val_accuracy: 0.3976

Epoch 00212: val_loss did not improve from 1.31246
Epoch 213/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4029 - val_loss: 1.3159 - val_accuracy: 0.4048

Epoch 00213: val_loss did not improve from 1.31246
Epoch 214/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4005 - val_loss: 1.3206 - val_accuracy: 0.4024

Epoch 00214: val_loss did not improve from 1.31246
Epoch 215/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4035 - val_loss: 1.3143 - val_accuracy: 0.4056

Epoch 00215: val_loss did not improve from 1.31246
Epoch 216/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4017 - val_loss: 1.3145 - val_accuracy: 0.3968

Epoch 00216: val_loss did not improve from 1.31246
Epoch 217/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3976 - val_loss: 1.3215 - val_accuracy: 0.3992

Epoch 00217: val_loss did not improve from 1.31246
Epoch 218/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3996 - val_loss: 1.3155 - val_accuracy: 0.4056

Epoch 00218: val_loss did not improve from 1.31246
Epoch 219/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4022 - val_loss: 1.3129 - val_accuracy: 0.4008

Epoch 00219: val_loss did not improve from 1.31246
Epoch 220/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3969 - val_loss: 1.3136 - val_accuracy: 0.4024

Epoch 00220: val_loss did not improve from 1.31246
Epoch 221/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4018 - val_loss: 1.3139 - val_accuracy: 0.4135

Epoch 00221: val_loss did not improve from 1.31246
Epoch 222/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4003 - val_loss: 1.3145 - val_accuracy: 0.4016

Epoch 00222: val_loss did not improve from 1.31246
Epoch 223/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3965 - val_loss: 1.3150 - val_accuracy: 0.4064

Epoch 00223: val_loss did not improve from 1.31246
Epoch 224/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4013 - val_loss: 1.3150 - val_accuracy: 0.4032

Epoch 00224: val_loss did not improve from 1.31246
Epoch 225/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3972 - val_loss: 1.3174 - val_accuracy: 0.4080

Epoch 00225: val_loss did not improve from 1.31246
Epoch 226/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4015 - val_loss: 1.3124 - val_accuracy: 0.4000

Epoch 00226: val_loss improved from 1.31246 to 1.31237, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 227/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3988 - val_loss: 1.3148 - val_accuracy: 0.4056

Epoch 00227: val_loss did not improve from 1.31237
Epoch 228/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4058 - val_loss: 1.3158 - val_accuracy: 0.4048

Epoch 00228: val_loss did not improve from 1.31237
Epoch 229/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4035 - val_loss: 1.3150 - val_accuracy: 0.4088

Epoch 00229: val_loss did not improve from 1.31237
Epoch 230/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3994 - val_loss: 1.3147 - val_accuracy: 0.3920

Epoch 00230: val_loss did not improve from 1.31237
Epoch 231/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3982 - val_loss: 1.3180 - val_accuracy: 0.4135

Epoch 00231: val_loss did not improve from 1.31237
Epoch 232/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4012 - val_loss: 1.3127 - val_accuracy: 0.4000

Epoch 00232: val_loss did not improve from 1.31237
Epoch 233/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3984 - val_loss: 1.3137 - val_accuracy: 0.4024

Epoch 00233: val_loss did not improve from 1.31237
Epoch 234/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4049 - val_loss: 1.3149 - val_accuracy: 0.4008

Epoch 00234: val_loss did not improve from 1.31237
Epoch 235/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4005 - val_loss: 1.3142 - val_accuracy: 0.4112

Epoch 00235: val_loss did not improve from 1.31237
Epoch 236/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4009 - val_loss: 1.3150 - val_accuracy: 0.4072

Epoch 00236: val_loss did not improve from 1.31237
Epoch 237/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4023 - val_loss: 1.3130 - val_accuracy: 0.4048

Epoch 00237: val_loss did not improve from 1.31237
Epoch 238/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4050 - val_loss: 1.3127 - val_accuracy: 0.4000

Epoch 00238: val_loss did not improve from 1.31237
Epoch 239/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3920 - val_loss: 1.3187 - val_accuracy: 0.4072

Epoch 00239: val_loss did not improve from 1.31237
Epoch 240/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3999 - val_loss: 1.3131 - val_accuracy: 0.4024

Epoch 00240: val_loss did not improve from 1.31237
Epoch 241/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4039 - val_loss: 1.3137 - val_accuracy: 0.3992

Epoch 00241: val_loss did not improve from 1.31237
Epoch 242/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4027 - val_loss: 1.3132 - val_accuracy: 0.3976

Epoch 00242: val_loss did not improve from 1.31237
Epoch 243/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3965 - val_loss: 1.3179 - val_accuracy: 0.4143

Epoch 00243: val_loss did not improve from 1.31237
Epoch 244/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4040 - val_loss: 1.3126 - val_accuracy: 0.3968

Epoch 00244: val_loss did not improve from 1.31237
Epoch 245/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3997 - val_loss: 1.3175 - val_accuracy: 0.4191

Epoch 00245: val_loss did not improve from 1.31237
Epoch 246/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4019 - val_loss: 1.3114 - val_accuracy: 0.3984

Epoch 00246: val_loss improved from 1.31237 to 1.31136, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 247/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4012 - val_loss: 1.3119 - val_accuracy: 0.4032

Epoch 00247: val_loss did not improve from 1.31136
Epoch 248/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3985 - val_loss: 1.3280 - val_accuracy: 0.4127

Epoch 00248: val_loss did not improve from 1.31136
Epoch 249/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3988 - val_loss: 1.3116 - val_accuracy: 0.3944

Epoch 00249: val_loss did not improve from 1.31136
Epoch 250/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4038 - val_loss: 1.3168 - val_accuracy: 0.4048

Epoch 00250: val_loss did not improve from 1.31136
Epoch 251/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4002 - val_loss: 1.3171 - val_accuracy: 0.4024

Epoch 00251: val_loss did not improve from 1.31136
Epoch 252/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4022 - val_loss: 1.3128 - val_accuracy: 0.4008

Epoch 00252: val_loss did not improve from 1.31136
Epoch 253/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4035 - val_loss: 1.3124 - val_accuracy: 0.3952

Epoch 00253: val_loss did not improve from 1.31136
Epoch 254/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3994 - val_loss: 1.3131 - val_accuracy: 0.4096

Epoch 00254: val_loss did not improve from 1.31136
Epoch 255/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4002 - val_loss: 1.3181 - val_accuracy: 0.4143

Epoch 00255: val_loss did not improve from 1.31136
Epoch 256/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4002 - val_loss: 1.3113 - val_accuracy: 0.3928

Epoch 00256: val_loss improved from 1.31136 to 1.31131, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 257/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3978 - val_loss: 1.3124 - val_accuracy: 0.4096

Epoch 00257: val_loss did not improve from 1.31131
Epoch 258/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4022 - val_loss: 1.3118 - val_accuracy: 0.4032

Epoch 00258: val_loss did not improve from 1.31131
Epoch 259/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3984 - val_loss: 1.3188 - val_accuracy: 0.4072

Epoch 00259: val_loss did not improve from 1.31131
Epoch 260/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3983 - val_loss: 1.3151 - val_accuracy: 0.4024

Epoch 00260: val_loss did not improve from 1.31131
Epoch 261/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4036 - val_loss: 1.3143 - val_accuracy: 0.4016

Epoch 00261: val_loss did not improve from 1.31131
Epoch 262/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4019 - val_loss: 1.3112 - val_accuracy: 0.4040

Epoch 00262: val_loss improved from 1.31131 to 1.31124, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 263/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4019 - val_loss: 1.3105 - val_accuracy: 0.4040

Epoch 00263: val_loss improved from 1.31124 to 1.31053, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 264/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4045 - val_loss: 1.3126 - val_accuracy: 0.4064

Epoch 00264: val_loss did not improve from 1.31053
Epoch 265/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4021 - val_loss: 1.3123 - val_accuracy: 0.4088

Epoch 00265: val_loss did not improve from 1.31053
Epoch 266/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4050 - val_loss: 1.3113 - val_accuracy: 0.3968

Epoch 00266: val_loss did not improve from 1.31053
Epoch 267/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4040 - val_loss: 1.3123 - val_accuracy: 0.4016

Epoch 00267: val_loss did not improve from 1.31053
Epoch 268/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3930 - val_loss: 1.3190 - val_accuracy: 0.4127

Epoch 00268: val_loss did not improve from 1.31053
Epoch 269/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4031 - val_loss: 1.3116 - val_accuracy: 0.3920

Epoch 00269: val_loss did not improve from 1.31053
Epoch 270/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3958 - val_loss: 1.3132 - val_accuracy: 0.4104

Epoch 00270: val_loss did not improve from 1.31053
Epoch 271/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4004 - val_loss: 1.3113 - val_accuracy: 0.4120

Epoch 00271: val_loss did not improve from 1.31053
Epoch 272/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3996 - val_loss: 1.3106 - val_accuracy: 0.4000

Epoch 00272: val_loss did not improve from 1.31053
Epoch 273/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4049 - val_loss: 1.3191 - val_accuracy: 0.4135

Epoch 00273: val_loss did not improve from 1.31053
Epoch 274/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.4024 - val_loss: 1.3157 - val_accuracy: 0.3936

Epoch 00274: val_loss did not improve from 1.31053
Epoch 275/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4050 - val_loss: 1.3119 - val_accuracy: 0.4159

Epoch 00275: val_loss did not improve from 1.31053
Epoch 276/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3981 - val_loss: 1.3239 - val_accuracy: 0.4096

Epoch 00276: val_loss did not improve from 1.31053
Epoch 277/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3996 - val_loss: 1.3119 - val_accuracy: 0.3904

Epoch 00277: val_loss did not improve from 1.31053
Epoch 278/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4027 - val_loss: 1.3130 - val_accuracy: 0.4143

Epoch 00278: val_loss did not improve from 1.31053
Epoch 279/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4028 - val_loss: 1.3121 - val_accuracy: 0.4143

Epoch 00279: val_loss did not improve from 1.31053
Epoch 280/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4050 - val_loss: 1.3127 - val_accuracy: 0.4127

Epoch 00280: val_loss did not improve from 1.31053
Epoch 281/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4074 - val_loss: 1.3104 - val_accuracy: 0.3896

Epoch 00281: val_loss improved from 1.31053 to 1.31036, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 282/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3942 - val_loss: 1.3126 - val_accuracy: 0.4072

Epoch 00282: val_loss did not improve from 1.31036
Epoch 283/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4025 - val_loss: 1.3129 - val_accuracy: 0.4112

Epoch 00283: val_loss did not improve from 1.31036
Epoch 284/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4041 - val_loss: 1.3099 - val_accuracy: 0.4024

Epoch 00284: val_loss improved from 1.31036 to 1.30993, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 285/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4050 - val_loss: 1.3122 - val_accuracy: 0.4096

Epoch 00285: val_loss did not improve from 1.30993
Epoch 286/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4019 - val_loss: 1.3123 - val_accuracy: 0.3992

Epoch 00286: val_loss did not improve from 1.30993
Epoch 287/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4017 - val_loss: 1.3156 - val_accuracy: 0.4120

Epoch 00287: val_loss did not improve from 1.30993
Epoch 288/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4054 - val_loss: 1.3119 - val_accuracy: 0.4048

Epoch 00288: val_loss did not improve from 1.30993
Epoch 289/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4064 - val_loss: 1.3125 - val_accuracy: 0.4080

Epoch 00289: val_loss did not improve from 1.30993
Epoch 290/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4043 - val_loss: 1.3144 - val_accuracy: 0.4096

Epoch 00290: val_loss did not improve from 1.30993
Epoch 291/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4035 - val_loss: 1.3126 - val_accuracy: 0.3984

Epoch 00291: val_loss did not improve from 1.30993
Epoch 292/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4032 - val_loss: 1.3121 - val_accuracy: 0.4080

Epoch 00292: val_loss did not improve from 1.30993
Epoch 293/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.3976 - val_loss: 1.3119 - val_accuracy: 0.4024

Epoch 00293: val_loss did not improve from 1.30993
Epoch 294/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4022 - val_loss: 1.3122 - val_accuracy: 0.4127

Epoch 00294: val_loss did not improve from 1.30993
Epoch 295/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.3996 - val_loss: 1.3131 - val_accuracy: 0.4167

Epoch 00295: val_loss did not improve from 1.30993
Epoch 296/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4034 - val_loss: 1.3114 - val_accuracy: 0.4016

Epoch 00296: val_loss did not improve from 1.30993
Epoch 297/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4071 - val_loss: 1.3127 - val_accuracy: 0.4167

Epoch 00297: val_loss did not improve from 1.30993
Epoch 298/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4004 - val_loss: 1.3094 - val_accuracy: 0.4024

Epoch 00298: val_loss improved from 1.30993 to 1.30943, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 299/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4035 - val_loss: 1.3153 - val_accuracy: 0.4064

Epoch 00299: val_loss did not improve from 1.30943
Epoch 300/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4067 - val_loss: 1.3087 - val_accuracy: 0.4072

Epoch 00300: val_loss improved from 1.30943 to 1.30866, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 301/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4052 - val_loss: 1.3107 - val_accuracy: 0.4080

Epoch 00301: val_loss did not improve from 1.30866
Epoch 302/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4069 - val_loss: 1.3098 - val_accuracy: 0.3944

Epoch 00302: val_loss did not improve from 1.30866
Epoch 303/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4002 - val_loss: 1.3114 - val_accuracy: 0.4151

Epoch 00303: val_loss did not improve from 1.30866
Epoch 304/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4035 - val_loss: 1.3115 - val_accuracy: 0.4096

Epoch 00304: val_loss did not improve from 1.30866
Epoch 305/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4082 - val_loss: 1.3103 - val_accuracy: 0.4040

Epoch 00305: val_loss did not improve from 1.30866
Epoch 306/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4017 - val_loss: 1.3138 - val_accuracy: 0.4127

Epoch 00306: val_loss did not improve from 1.30866
Epoch 307/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4050 - val_loss: 1.3101 - val_accuracy: 0.4032

Epoch 00307: val_loss did not improve from 1.30866
Epoch 308/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4075 - val_loss: 1.3122 - val_accuracy: 0.4127

Epoch 00308: val_loss did not improve from 1.30866
Epoch 309/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4054 - val_loss: 1.3101 - val_accuracy: 0.4056

Epoch 00309: val_loss did not improve from 1.30866
Epoch 310/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4092 - val_loss: 1.3107 - val_accuracy: 0.4048

Epoch 00310: val_loss did not improve from 1.30866
Epoch 311/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4010 - val_loss: 1.3221 - val_accuracy: 0.4151

Epoch 00311: val_loss did not improve from 1.30866
Epoch 312/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3979 - val_loss: 1.3097 - val_accuracy: 0.4048

Epoch 00312: val_loss did not improve from 1.30866
Epoch 313/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4032 - val_loss: 1.3170 - val_accuracy: 0.3904

Epoch 00313: val_loss did not improve from 1.30866
Epoch 314/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4008 - val_loss: 1.3153 - val_accuracy: 0.4112

Epoch 00314: val_loss did not improve from 1.30866
Epoch 315/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4009 - val_loss: 1.3135 - val_accuracy: 0.4104

Epoch 00315: val_loss did not improve from 1.30866
Epoch 316/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4052 - val_loss: 1.3085 - val_accuracy: 0.4064

Epoch 00316: val_loss improved from 1.30866 to 1.30850, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 317/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4058 - val_loss: 1.3086 - val_accuracy: 0.4056

Epoch 00317: val_loss did not improve from 1.30850
Epoch 318/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4023 - val_loss: 1.3076 - val_accuracy: 0.4040

Epoch 00318: val_loss improved from 1.30850 to 1.30759, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 319/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4046 - val_loss: 1.3091 - val_accuracy: 0.4096

Epoch 00319: val_loss did not improve from 1.30759
Epoch 320/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4029 - val_loss: 1.3113 - val_accuracy: 0.4159

Epoch 00320: val_loss did not improve from 1.30759
Epoch 321/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4040 - val_loss: 1.3097 - val_accuracy: 0.4000

Epoch 00321: val_loss did not improve from 1.30759
Epoch 322/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4027 - val_loss: 1.3102 - val_accuracy: 0.4104

Epoch 00322: val_loss did not improve from 1.30759
Epoch 323/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4028 - val_loss: 1.3152 - val_accuracy: 0.4056

Epoch 00323: val_loss did not improve from 1.30759
Epoch 324/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4061 - val_loss: 1.3092 - val_accuracy: 0.4032

Epoch 00324: val_loss did not improve from 1.30759
Epoch 325/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4062 - val_loss: 1.3089 - val_accuracy: 0.4056

Epoch 00325: val_loss did not improve from 1.30759
Epoch 326/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3947 - val_loss: 1.3131 - val_accuracy: 0.4175

Epoch 00326: val_loss did not improve from 1.30759
Epoch 327/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4033 - val_loss: 1.3121 - val_accuracy: 0.4135

Epoch 00327: val_loss did not improve from 1.30759
Epoch 328/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3988 - val_loss: 1.3082 - val_accuracy: 0.3920

Epoch 00328: val_loss did not improve from 1.30759
Epoch 329/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4038 - val_loss: 1.3104 - val_accuracy: 0.3992

Epoch 00329: val_loss did not improve from 1.30759
Epoch 330/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4053 - val_loss: 1.3088 - val_accuracy: 0.4096

Epoch 00330: val_loss did not improve from 1.30759
Epoch 331/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4047 - val_loss: 1.3094 - val_accuracy: 0.4000

Epoch 00331: val_loss did not improve from 1.30759
Epoch 332/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4024 - val_loss: 1.3093 - val_accuracy: 0.4072

Epoch 00332: val_loss did not improve from 1.30759
Epoch 333/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4054 - val_loss: 1.3094 - val_accuracy: 0.4000

Epoch 00333: val_loss did not improve from 1.30759
Epoch 334/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4072 - val_loss: 1.3101 - val_accuracy: 0.4048

Epoch 00334: val_loss did not improve from 1.30759
Epoch 335/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4012 - val_loss: 1.3071 - val_accuracy: 0.4024

Epoch 00335: val_loss improved from 1.30759 to 1.30714, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 336/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4079 - val_loss: 1.3078 - val_accuracy: 0.4032

Epoch 00336: val_loss did not improve from 1.30714
Epoch 337/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4028 - val_loss: 1.3088 - val_accuracy: 0.4096

Epoch 00337: val_loss did not improve from 1.30714
Epoch 338/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4051 - val_loss: 1.3070 - val_accuracy: 0.4048

Epoch 00338: val_loss improved from 1.30714 to 1.30697, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 339/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4044 - val_loss: 1.3089 - val_accuracy: 0.4000

Epoch 00339: val_loss did not improve from 1.30697
Epoch 340/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4046 - val_loss: 1.3070 - val_accuracy: 0.4072

Epoch 00340: val_loss did not improve from 1.30697
Epoch 341/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4040 - val_loss: 1.3082 - val_accuracy: 0.4135

Epoch 00341: val_loss did not improve from 1.30697
Epoch 342/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4069 - val_loss: 1.3076 - val_accuracy: 0.4064

Epoch 00342: val_loss did not improve from 1.30697
Epoch 343/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4071 - val_loss: 1.3068 - val_accuracy: 0.4032

Epoch 00343: val_loss improved from 1.30697 to 1.30677, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 344/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4068 - val_loss: 1.3080 - val_accuracy: 0.4048

Epoch 00344: val_loss did not improve from 1.30677
Epoch 345/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4085 - val_loss: 1.3069 - val_accuracy: 0.4088

Epoch 00345: val_loss did not improve from 1.30677
Epoch 346/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4099 - val_loss: 1.3065 - val_accuracy: 0.4048

Epoch 00346: val_loss improved from 1.30677 to 1.30654, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 347/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4069 - val_loss: 1.3080 - val_accuracy: 0.3976

Epoch 00347: val_loss did not improve from 1.30654
Epoch 348/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4045 - val_loss: 1.3119 - val_accuracy: 0.4175

Epoch 00348: val_loss did not improve from 1.30654
Epoch 349/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4027 - val_loss: 1.3082 - val_accuracy: 0.4008

Epoch 00349: val_loss did not improve from 1.30654
Epoch 350/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4001 - val_loss: 1.3123 - val_accuracy: 0.4072

Epoch 00350: val_loss did not improve from 1.30654
Epoch 351/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4058 - val_loss: 1.3060 - val_accuracy: 0.3984

Epoch 00351: val_loss improved from 1.30654 to 1.30600, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 352/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4069 - val_loss: 1.3073 - val_accuracy: 0.4080

Epoch 00352: val_loss did not improve from 1.30600
Epoch 353/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4053 - val_loss: 1.3081 - val_accuracy: 0.4104

Epoch 00353: val_loss did not improve from 1.30600
Epoch 354/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4072 - val_loss: 1.3081 - val_accuracy: 0.4080

Epoch 00354: val_loss did not improve from 1.30600
Epoch 355/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4097 - val_loss: 1.3073 - val_accuracy: 0.4000

Epoch 00355: val_loss did not improve from 1.30600
Epoch 356/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4027 - val_loss: 1.3122 - val_accuracy: 0.4167

Epoch 00356: val_loss did not improve from 1.30600
Epoch 357/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4068 - val_loss: 1.3078 - val_accuracy: 0.4016

Epoch 00357: val_loss did not improve from 1.30600
Epoch 358/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4059 - val_loss: 1.3097 - val_accuracy: 0.4167

Epoch 00358: val_loss did not improve from 1.30600
Epoch 359/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4043 - val_loss: 1.3162 - val_accuracy: 0.4088

Epoch 00359: val_loss did not improve from 1.30600
Epoch 360/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4041 - val_loss: 1.3087 - val_accuracy: 0.3960

Epoch 00360: val_loss did not improve from 1.30600
Epoch 361/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4083 - val_loss: 1.3075 - val_accuracy: 0.4048

Epoch 00361: val_loss did not improve from 1.30600
Epoch 362/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4077 - val_loss: 1.3070 - val_accuracy: 0.4064

Epoch 00362: val_loss did not improve from 1.30600
Epoch 363/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4047 - val_loss: 1.3091 - val_accuracy: 0.4120

Epoch 00363: val_loss did not improve from 1.30600
Epoch 364/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4069 - val_loss: 1.3057 - val_accuracy: 0.4064

Epoch 00364: val_loss improved from 1.30600 to 1.30565, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 365/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.3996 - val_loss: 1.3053 - val_accuracy: 0.4040

Epoch 00365: val_loss improved from 1.30565 to 1.30530, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 366/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4043 - val_loss: 1.3112 - val_accuracy: 0.4191

Epoch 00366: val_loss did not improve from 1.30530
Epoch 367/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4074 - val_loss: 1.3083 - val_accuracy: 0.4016

Epoch 00367: val_loss did not improve from 1.30530
Epoch 368/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.3984 - val_loss: 1.3103 - val_accuracy: 0.4096

Epoch 00368: val_loss did not improve from 1.30530
Epoch 369/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4037 - val_loss: 1.3115 - val_accuracy: 0.4112

Epoch 00369: val_loss did not improve from 1.30530
Epoch 370/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4071 - val_loss: 1.3086 - val_accuracy: 0.4040

Epoch 00370: val_loss did not improve from 1.30530
Epoch 371/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4027 - val_loss: 1.3162 - val_accuracy: 0.4120

Epoch 00371: val_loss did not improve from 1.30530
Epoch 372/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4053 - val_loss: 1.3069 - val_accuracy: 0.4040

Epoch 00372: val_loss did not improve from 1.30530
Epoch 373/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4076 - val_loss: 1.3054 - val_accuracy: 0.4000

Epoch 00373: val_loss did not improve from 1.30530
Epoch 374/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4036 - val_loss: 1.3062 - val_accuracy: 0.4159

Epoch 00374: val_loss did not improve from 1.30530
Epoch 375/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4098 - val_loss: 1.3160 - val_accuracy: 0.4199

Epoch 00375: val_loss did not improve from 1.30530
Epoch 376/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4050 - val_loss: 1.3063 - val_accuracy: 0.4016

Epoch 00376: val_loss did not improve from 1.30530
Epoch 377/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4097 - val_loss: 1.3063 - val_accuracy: 0.4096

Epoch 00377: val_loss did not improve from 1.30530
Epoch 378/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4091 - val_loss: 1.3063 - val_accuracy: 0.4135

Epoch 00378: val_loss did not improve from 1.30530
Epoch 379/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4058 - val_loss: 1.3074 - val_accuracy: 0.4127

Epoch 00379: val_loss did not improve from 1.30530
Epoch 380/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4090 - val_loss: 1.3064 - val_accuracy: 0.4120

Epoch 00380: val_loss did not improve from 1.30530
Epoch 381/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4048 - val_loss: 1.3082 - val_accuracy: 0.4143

Epoch 00381: val_loss did not improve from 1.30530
Epoch 382/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4067 - val_loss: 1.3052 - val_accuracy: 0.4112

Epoch 00382: val_loss improved from 1.30530 to 1.30523, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 383/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4072 - val_loss: 1.3072 - val_accuracy: 0.4191

Epoch 00383: val_loss did not improve from 1.30523
Epoch 384/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4074 - val_loss: 1.3058 - val_accuracy: 0.4056

Epoch 00384: val_loss did not improve from 1.30523
Epoch 385/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4001 - val_loss: 1.3155 - val_accuracy: 0.4096

Epoch 00385: val_loss did not improve from 1.30523
Epoch 386/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4029 - val_loss: 1.3078 - val_accuracy: 0.4056

Epoch 00386: val_loss did not improve from 1.30523
Epoch 387/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4100 - val_loss: 1.3048 - val_accuracy: 0.4040

Epoch 00387: val_loss improved from 1.30523 to 1.30478, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 388/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4075 - val_loss: 1.3068 - val_accuracy: 0.4199

Epoch 00388: val_loss did not improve from 1.30478
Epoch 389/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4089 - val_loss: 1.3057 - val_accuracy: 0.4143

Epoch 00389: val_loss did not improve from 1.30478
Epoch 390/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4075 - val_loss: 1.3055 - val_accuracy: 0.4135

Epoch 00390: val_loss did not improve from 1.30478
Epoch 391/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4087 - val_loss: 1.3051 - val_accuracy: 0.4120

Epoch 00391: val_loss did not improve from 1.30478
Epoch 392/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4089 - val_loss: 1.3051 - val_accuracy: 0.4135

Epoch 00392: val_loss did not improve from 1.30478
Epoch 393/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4074 - val_loss: 1.3031 - val_accuracy: 0.4072

Epoch 00393: val_loss improved from 1.30478 to 1.30308, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 394/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4074 - val_loss: 1.3031 - val_accuracy: 0.3976

Epoch 00394: val_loss did not improve from 1.30308
Epoch 395/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3953 - val_loss: 1.3118 - val_accuracy: 0.4231

Epoch 00395: val_loss did not improve from 1.30308
Epoch 396/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4057 - val_loss: 1.3039 - val_accuracy: 0.4151

Epoch 00396: val_loss did not improve from 1.30308
Epoch 397/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4039 - val_loss: 1.3044 - val_accuracy: 0.4135

Epoch 00397: val_loss did not improve from 1.30308
Epoch 398/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4101 - val_loss: 1.3055 - val_accuracy: 0.4104

Epoch 00398: val_loss did not improve from 1.30308
Epoch 399/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4048 - val_loss: 1.3076 - val_accuracy: 0.4175

Epoch 00399: val_loss did not improve from 1.30308
Epoch 400/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4091 - val_loss: 1.3059 - val_accuracy: 0.4040

Epoch 00400: val_loss did not improve from 1.30308
Epoch 401/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4049 - val_loss: 1.3051 - val_accuracy: 0.4040

Epoch 00401: val_loss did not improve from 1.30308
Epoch 402/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4027 - val_loss: 1.3149 - val_accuracy: 0.4040

Epoch 00402: val_loss did not improve from 1.30308
Epoch 403/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4046 - val_loss: 1.3058 - val_accuracy: 0.4040

Epoch 00403: val_loss did not improve from 1.30308
Epoch 404/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4092 - val_loss: 1.3042 - val_accuracy: 0.4040

Epoch 00404: val_loss did not improve from 1.30308
Epoch 405/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4066 - val_loss: 1.3040 - val_accuracy: 0.4159

Epoch 00405: val_loss did not improve from 1.30308
Epoch 406/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4059 - val_loss: 1.3051 - val_accuracy: 0.4167

Epoch 00406: val_loss did not improve from 1.30308
Epoch 407/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4072 - val_loss: 1.3025 - val_accuracy: 0.4135

Epoch 00407: val_loss improved from 1.30308 to 1.30247, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 408/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4066 - val_loss: 1.3042 - val_accuracy: 0.4080

Epoch 00408: val_loss did not improve from 1.30247
Epoch 409/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4052 - val_loss: 1.3065 - val_accuracy: 0.4183

Epoch 00409: val_loss did not improve from 1.30247
Epoch 410/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4094 - val_loss: 1.3051 - val_accuracy: 0.4080

Epoch 00410: val_loss did not improve from 1.30247
Epoch 411/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4074 - val_loss: 1.3040 - val_accuracy: 0.4024

Epoch 00411: val_loss did not improve from 1.30247
Epoch 412/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4089 - val_loss: 1.3031 - val_accuracy: 0.4032

Epoch 00412: val_loss did not improve from 1.30247
Epoch 413/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4079 - val_loss: 1.3026 - val_accuracy: 0.4151

Epoch 00413: val_loss did not improve from 1.30247
Epoch 414/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4120 - val_loss: 1.3059 - val_accuracy: 0.4159

Epoch 00414: val_loss did not improve from 1.30247
Epoch 415/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4089 - val_loss: 1.3033 - val_accuracy: 0.4032

Epoch 00415: val_loss did not improve from 1.30247
Epoch 416/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4076 - val_loss: 1.3034 - val_accuracy: 0.4127

Epoch 00416: val_loss did not improve from 1.30247
Epoch 417/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4119 - val_loss: 1.3036 - val_accuracy: 0.4120

Epoch 00417: val_loss did not improve from 1.30247
Epoch 418/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4083 - val_loss: 1.3039 - val_accuracy: 0.4112

Epoch 00418: val_loss did not improve from 1.30247
Epoch 419/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4074 - val_loss: 1.3042 - val_accuracy: 0.4167

Epoch 00419: val_loss did not improve from 1.30247
Epoch 420/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4098 - val_loss: 1.3023 - val_accuracy: 0.4183

Epoch 00420: val_loss improved from 1.30247 to 1.30227, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 421/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4080 - val_loss: 1.3016 - val_accuracy: 0.4104

Epoch 00421: val_loss improved from 1.30227 to 1.30163, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 422/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4088 - val_loss: 1.3057 - val_accuracy: 0.4167

Epoch 00422: val_loss did not improve from 1.30163
Epoch 423/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4076 - val_loss: 1.3075 - val_accuracy: 0.4167

Epoch 00423: val_loss did not improve from 1.30163
Epoch 424/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4083 - val_loss: 1.3060 - val_accuracy: 0.4215

Epoch 00424: val_loss did not improve from 1.30163
Epoch 425/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4067 - val_loss: 1.3057 - val_accuracy: 0.3968

Epoch 00425: val_loss did not improve from 1.30163
Epoch 426/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4082 - val_loss: 1.3106 - val_accuracy: 0.4056

Epoch 00426: val_loss did not improve from 1.30163
Epoch 427/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4093 - val_loss: 1.3037 - val_accuracy: 0.3960

Epoch 00427: val_loss did not improve from 1.30163
Epoch 428/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4119 - val_loss: 1.3024 - val_accuracy: 0.4143

Epoch 00428: val_loss did not improve from 1.30163
Epoch 429/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4091 - val_loss: 1.3075 - val_accuracy: 0.4191

Epoch 00429: val_loss did not improve from 1.30163
Epoch 430/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4063 - val_loss: 1.3051 - val_accuracy: 0.4064

Epoch 00430: val_loss did not improve from 1.30163
Epoch 431/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4127 - val_loss: 1.3027 - val_accuracy: 0.4120

Epoch 00431: val_loss did not improve from 1.30163
Epoch 432/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4081 - val_loss: 1.3010 - val_accuracy: 0.4096

Epoch 00432: val_loss improved from 1.30163 to 1.30099, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 433/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4112 - val_loss: 1.3025 - val_accuracy: 0.4080

Epoch 00433: val_loss did not improve from 1.30099
Epoch 434/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4106 - val_loss: 1.3068 - val_accuracy: 0.4048

Epoch 00434: val_loss did not improve from 1.30099
Epoch 435/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4106 - val_loss: 1.3038 - val_accuracy: 0.4008

Epoch 00435: val_loss did not improve from 1.30099
Epoch 436/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4076 - val_loss: 1.3069 - val_accuracy: 0.4159

Epoch 00436: val_loss did not improve from 1.30099
Epoch 437/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4072 - val_loss: 1.3085 - val_accuracy: 0.4159

Epoch 00437: val_loss did not improve from 1.30099
Epoch 438/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4112 - val_loss: 1.3057 - val_accuracy: 0.4032

Epoch 00438: val_loss did not improve from 1.30099
Epoch 439/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4089 - val_loss: 1.3061 - val_accuracy: 0.3992

Epoch 00439: val_loss did not improve from 1.30099
Epoch 440/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4074 - val_loss: 1.3071 - val_accuracy: 0.4127

Epoch 00440: val_loss did not improve from 1.30099
Epoch 441/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4110 - val_loss: 1.3029 - val_accuracy: 0.4104

Epoch 00441: val_loss did not improve from 1.30099
Epoch 442/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4107 - val_loss: 1.3039 - val_accuracy: 0.4048

Epoch 00442: val_loss did not improve from 1.30099
Epoch 443/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4107 - val_loss: 1.3031 - val_accuracy: 0.4024

Epoch 00443: val_loss did not improve from 1.30099
Epoch 444/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4037 - val_loss: 1.3081 - val_accuracy: 0.4151

Epoch 00444: val_loss did not improve from 1.30099
Epoch 445/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.3988 - val_loss: 1.3075 - val_accuracy: 0.4159

Epoch 00445: val_loss did not improve from 1.30099
Epoch 446/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4112 - val_loss: 1.3028 - val_accuracy: 0.4000

Epoch 00446: val_loss did not improve from 1.30099
Epoch 447/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4051 - val_loss: 1.3025 - val_accuracy: 0.4199

Epoch 00447: val_loss did not improve from 1.30099
Epoch 448/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4078 - val_loss: 1.3052 - val_accuracy: 0.4215

Epoch 00448: val_loss did not improve from 1.30099
Epoch 449/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4082 - val_loss: 1.3037 - val_accuracy: 0.4056

Epoch 00449: val_loss did not improve from 1.30099
Epoch 450/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4079 - val_loss: 1.3040 - val_accuracy: 0.4088

Epoch 00450: val_loss did not improve from 1.30099
Epoch 451/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4143 - val_loss: 1.3061 - val_accuracy: 0.4064

Epoch 00451: val_loss did not improve from 1.30099
Epoch 452/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4081 - val_loss: 1.3058 - val_accuracy: 0.4199

Epoch 00452: val_loss did not improve from 1.30099
Epoch 453/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4111 - val_loss: 1.3022 - val_accuracy: 0.4151

Epoch 00453: val_loss did not improve from 1.30099
Epoch 454/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4105 - val_loss: 1.3008 - val_accuracy: 0.4191

Epoch 00454: val_loss improved from 1.30099 to 1.30079, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 455/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4092 - val_loss: 1.3109 - val_accuracy: 0.4167

Epoch 00455: val_loss did not improve from 1.30079
Epoch 456/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4035 - val_loss: 1.3015 - val_accuracy: 0.4135

Epoch 00456: val_loss did not improve from 1.30079
Epoch 457/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4074 - val_loss: 1.3046 - val_accuracy: 0.4159

Epoch 00457: val_loss did not improve from 1.30079
Epoch 458/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4085 - val_loss: 1.3111 - val_accuracy: 0.4151

Epoch 00458: val_loss did not improve from 1.30079
Epoch 459/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4067 - val_loss: 1.3083 - val_accuracy: 0.3968

Epoch 00459: val_loss did not improve from 1.30079
Epoch 460/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4113 - val_loss: 1.3026 - val_accuracy: 0.4104

Epoch 00460: val_loss did not improve from 1.30079
Epoch 461/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4044 - val_loss: 1.3017 - val_accuracy: 0.4191

Epoch 00461: val_loss did not improve from 1.30079
Epoch 462/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4099 - val_loss: 1.3059 - val_accuracy: 0.4159

Epoch 00462: val_loss did not improve from 1.30079
Epoch 463/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4096 - val_loss: 1.3023 - val_accuracy: 0.4112

Epoch 00463: val_loss did not improve from 1.30079
Epoch 464/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4108 - val_loss: 1.3060 - val_accuracy: 0.4072

Epoch 00464: val_loss did not improve from 1.30079
Epoch 465/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4098 - val_loss: 1.3078 - val_accuracy: 0.4127

Epoch 00465: val_loss did not improve from 1.30079
Epoch 466/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4141 - val_loss: 1.3021 - val_accuracy: 0.4016

Epoch 00466: val_loss did not improve from 1.30079
Epoch 467/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4109 - val_loss: 1.3023 - val_accuracy: 0.4112

Epoch 00467: val_loss did not improve from 1.30079
Epoch 468/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4149 - val_loss: 1.3031 - val_accuracy: 0.4016

Epoch 00468: val_loss did not improve from 1.30079
Epoch 469/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4143 - val_loss: 1.3074 - val_accuracy: 0.4167

Epoch 00469: val_loss did not improve from 1.30079
Epoch 470/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4067 - val_loss: 1.3092 - val_accuracy: 0.4159

Epoch 00470: val_loss did not improve from 1.30079
Epoch 471/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4116 - val_loss: 1.3014 - val_accuracy: 0.4175

Epoch 00471: val_loss did not improve from 1.30079
Epoch 472/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4101 - val_loss: 1.3025 - val_accuracy: 0.4151

Epoch 00472: val_loss did not improve from 1.30079
Epoch 473/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4097 - val_loss: 1.3025 - val_accuracy: 0.3968

Epoch 00473: val_loss did not improve from 1.30079
Epoch 474/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4111 - val_loss: 1.3089 - val_accuracy: 0.4032

Epoch 00474: val_loss did not improve from 1.30079
Epoch 475/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4109 - val_loss: 1.3035 - val_accuracy: 0.4112

Epoch 00475: val_loss did not improve from 1.30079
Epoch 476/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4104 - val_loss: 1.3014 - val_accuracy: 0.3976

Epoch 00476: val_loss did not improve from 1.30079
Epoch 477/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4095 - val_loss: 1.3004 - val_accuracy: 0.4135

Epoch 00477: val_loss improved from 1.30079 to 1.30038, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 478/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4114 - val_loss: 1.3009 - val_accuracy: 0.4143

Epoch 00478: val_loss did not improve from 1.30038
Epoch 479/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4093 - val_loss: 1.3075 - val_accuracy: 0.4120

Epoch 00479: val_loss did not improve from 1.30038
Epoch 480/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4139 - val_loss: 1.3009 - val_accuracy: 0.4032

Epoch 00480: val_loss did not improve from 1.30038
Epoch 481/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4078 - val_loss: 1.3004 - val_accuracy: 0.4104

Epoch 00481: val_loss improved from 1.30038 to 1.30037, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 482/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4091 - val_loss: 1.3004 - val_accuracy: 0.4064

Epoch 00482: val_loss improved from 1.30037 to 1.30035, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 483/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4046 - val_loss: 1.3061 - val_accuracy: 0.4064

Epoch 00483: val_loss did not improve from 1.30035
Epoch 484/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4101 - val_loss: 1.3018 - val_accuracy: 0.4032

Epoch 00484: val_loss did not improve from 1.30035
Epoch 485/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4103 - val_loss: 1.3015 - val_accuracy: 0.4024

Epoch 00485: val_loss did not improve from 1.30035
Epoch 486/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4091 - val_loss: 1.3035 - val_accuracy: 0.4008

Epoch 00486: val_loss did not improve from 1.30035
Epoch 487/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4104 - val_loss: 1.3002 - val_accuracy: 0.4151

Epoch 00487: val_loss improved from 1.30035 to 1.30015, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 488/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4105 - val_loss: 1.3003 - val_accuracy: 0.3984

Epoch 00488: val_loss did not improve from 1.30015
Epoch 489/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4142 - val_loss: 1.3018 - val_accuracy: 0.4032

Epoch 00489: val_loss did not improve from 1.30015
Epoch 490/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4151 - val_loss: 1.3004 - val_accuracy: 0.4096

Epoch 00490: val_loss did not improve from 1.30015
Epoch 491/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4112 - val_loss: 1.3000 - val_accuracy: 0.4056

Epoch 00491: val_loss improved from 1.30015 to 1.29997, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 492/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4093 - val_loss: 1.2998 - val_accuracy: 0.4024

Epoch 00492: val_loss improved from 1.29997 to 1.29979, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 493/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4120 - val_loss: 1.3052 - val_accuracy: 0.4127

Epoch 00493: val_loss did not improve from 1.29979
Epoch 494/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4128 - val_loss: 1.2983 - val_accuracy: 0.4048

Epoch 00494: val_loss improved from 1.29979 to 1.29826, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 495/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4059 - val_loss: 1.3001 - val_accuracy: 0.4088

Epoch 00495: val_loss did not improve from 1.29826
Epoch 496/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4123 - val_loss: 1.3029 - val_accuracy: 0.4215

Epoch 00496: val_loss did not improve from 1.29826
Epoch 497/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4094 - val_loss: 1.3005 - val_accuracy: 0.4151

Epoch 00497: val_loss did not improve from 1.29826
Epoch 498/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4084 - val_loss: 1.2990 - val_accuracy: 0.4143

Epoch 00498: val_loss did not improve from 1.29826
Epoch 499/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4120 - val_loss: 1.2992 - val_accuracy: 0.4120

Epoch 00499: val_loss did not improve from 1.29826
Epoch 500/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4120 - val_loss: 1.2996 - val_accuracy: 0.4024

Epoch 00500: val_loss did not improve from 1.29826
Epoch 501/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4122 - val_loss: 1.2996 - val_accuracy: 0.4104

Epoch 00501: val_loss did not improve from 1.29826
Epoch 502/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4116 - val_loss: 1.3072 - val_accuracy: 0.4072

Epoch 00502: val_loss did not improve from 1.29826
Epoch 503/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4121 - val_loss: 1.3001 - val_accuracy: 0.4104

Epoch 00503: val_loss did not improve from 1.29826
Epoch 504/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4112 - val_loss: 1.3019 - val_accuracy: 0.4104

Epoch 00504: val_loss did not improve from 1.29826
Epoch 505/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4134 - val_loss: 1.3024 - val_accuracy: 0.4048

Epoch 00505: val_loss did not improve from 1.29826
Epoch 506/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4087 - val_loss: 1.2990 - val_accuracy: 0.4072

Epoch 00506: val_loss did not improve from 1.29826
Epoch 507/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4150 - val_loss: 1.2993 - val_accuracy: 0.4056

Epoch 00507: val_loss did not improve from 1.29826
Epoch 508/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4121 - val_loss: 1.3003 - val_accuracy: 0.4080

Epoch 00508: val_loss did not improve from 1.29826
Epoch 509/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4128 - val_loss: 1.2998 - val_accuracy: 0.4127

Epoch 00509: val_loss did not improve from 1.29826
Epoch 510/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4091 - val_loss: 1.3000 - val_accuracy: 0.4199

Epoch 00510: val_loss did not improve from 1.29826
Epoch 511/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4126 - val_loss: 1.2995 - val_accuracy: 0.4088

Epoch 00511: val_loss did not improve from 1.29826
Epoch 512/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4114 - val_loss: 1.3029 - val_accuracy: 0.4127

Epoch 00512: val_loss did not improve from 1.29826
Epoch 513/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4143 - val_loss: 1.3014 - val_accuracy: 0.4096

Epoch 00513: val_loss did not improve from 1.29826
Epoch 514/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4141 - val_loss: 1.3064 - val_accuracy: 0.4072

Epoch 00514: val_loss did not improve from 1.29826
Epoch 515/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4143 - val_loss: 1.3003 - val_accuracy: 0.4016

Epoch 00515: val_loss did not improve from 1.29826
Epoch 516/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4105 - val_loss: 1.2992 - val_accuracy: 0.4064

Epoch 00516: val_loss did not improve from 1.29826
Epoch 517/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4129 - val_loss: 1.3049 - val_accuracy: 0.4112

Epoch 00517: val_loss did not improve from 1.29826
Epoch 518/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4137 - val_loss: 1.2999 - val_accuracy: 0.4112

Epoch 00518: val_loss did not improve from 1.29826
Epoch 519/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4129 - val_loss: 1.3006 - val_accuracy: 0.4080

Epoch 00519: val_loss did not improve from 1.29826
Epoch 520/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4141 - val_loss: 1.3011 - val_accuracy: 0.4064

Epoch 00520: val_loss did not improve from 1.29826
Epoch 521/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4163 - val_loss: 1.3005 - val_accuracy: 0.4032

Epoch 00521: val_loss did not improve from 1.29826
Epoch 522/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4147 - val_loss: 1.2992 - val_accuracy: 0.4104

Epoch 00522: val_loss did not improve from 1.29826
Epoch 523/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4138 - val_loss: 1.3022 - val_accuracy: 0.4088

Epoch 00523: val_loss did not improve from 1.29826
Epoch 524/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4114 - val_loss: 1.3008 - val_accuracy: 0.4040

Epoch 00524: val_loss did not improve from 1.29826
Epoch 525/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4103 - val_loss: 1.2992 - val_accuracy: 0.4040

Epoch 00525: val_loss did not improve from 1.29826
Epoch 526/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4129 - val_loss: 1.3064 - val_accuracy: 0.4064

Epoch 00526: val_loss did not improve from 1.29826
Epoch 527/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4131 - val_loss: 1.2986 - val_accuracy: 0.4080

Epoch 00527: val_loss did not improve from 1.29826
Epoch 528/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4123 - val_loss: 1.3015 - val_accuracy: 0.4239

Epoch 00528: val_loss did not improve from 1.29826
Epoch 529/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4111 - val_loss: 1.3032 - val_accuracy: 0.4191

Epoch 00529: val_loss did not improve from 1.29826
Epoch 530/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4108 - val_loss: 1.3015 - val_accuracy: 0.4064

Epoch 00530: val_loss did not improve from 1.29826
Epoch 531/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4108 - val_loss: 1.3019 - val_accuracy: 0.4191

Epoch 00531: val_loss did not improve from 1.29826
Epoch 532/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4098 - val_loss: 1.2993 - val_accuracy: 0.4024

Epoch 00532: val_loss did not improve from 1.29826
Epoch 533/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4133 - val_loss: 1.3069 - val_accuracy: 0.4207

Epoch 00533: val_loss did not improve from 1.29826
Epoch 534/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4093 - val_loss: 1.3010 - val_accuracy: 0.3968

Epoch 00534: val_loss did not improve from 1.29826
Epoch 535/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4127 - val_loss: 1.3023 - val_accuracy: 0.4143

Epoch 00535: val_loss did not improve from 1.29826
Epoch 536/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4102 - val_loss: 1.2978 - val_accuracy: 0.4104

Epoch 00536: val_loss improved from 1.29826 to 1.29777, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 537/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4171 - val_loss: 1.2999 - val_accuracy: 0.4072

Epoch 00537: val_loss did not improve from 1.29777
Epoch 538/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4078 - val_loss: 1.3047 - val_accuracy: 0.4167

Epoch 00538: val_loss did not improve from 1.29777
Epoch 539/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4145 - val_loss: 1.2979 - val_accuracy: 0.4143

Epoch 00539: val_loss did not improve from 1.29777
Epoch 540/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4115 - val_loss: 1.2980 - val_accuracy: 0.4104

Epoch 00540: val_loss did not improve from 1.29777
Epoch 541/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4119 - val_loss: 1.2982 - val_accuracy: 0.4080

Epoch 00541: val_loss did not improve from 1.29777
Epoch 542/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4116 - val_loss: 1.3003 - val_accuracy: 0.4048

Epoch 00542: val_loss did not improve from 1.29777
Epoch 543/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4131 - val_loss: 1.2978 - val_accuracy: 0.4112

Epoch 00543: val_loss did not improve from 1.29777
Epoch 544/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4123 - val_loss: 1.3026 - val_accuracy: 0.4239

Epoch 00544: val_loss did not improve from 1.29777
Epoch 545/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4095 - val_loss: 1.2964 - val_accuracy: 0.4151

Epoch 00545: val_loss improved from 1.29777 to 1.29643, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 546/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4102 - val_loss: 1.2958 - val_accuracy: 0.4143

Epoch 00546: val_loss improved from 1.29643 to 1.29576, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 547/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4114 - val_loss: 1.2973 - val_accuracy: 0.4104

Epoch 00547: val_loss did not improve from 1.29576
Epoch 548/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4056 - val_loss: 1.2987 - val_accuracy: 0.4056

Epoch 00548: val_loss did not improve from 1.29576
Epoch 549/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4108 - val_loss: 1.2973 - val_accuracy: 0.4008

Epoch 00549: val_loss did not improve from 1.29576
Epoch 550/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4094 - val_loss: 1.3028 - val_accuracy: 0.4167

Epoch 00550: val_loss did not improve from 1.29576
Epoch 551/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4092 - val_loss: 1.2959 - val_accuracy: 0.4127

Epoch 00551: val_loss did not improve from 1.29576
Epoch 552/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4101 - val_loss: 1.3013 - val_accuracy: 0.4159

Epoch 00552: val_loss did not improve from 1.29576
Epoch 553/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4120 - val_loss: 1.2968 - val_accuracy: 0.4112

Epoch 00553: val_loss did not improve from 1.29576
Epoch 554/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4123 - val_loss: 1.2956 - val_accuracy: 0.4072

Epoch 00554: val_loss improved from 1.29576 to 1.29558, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 555/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4109 - val_loss: 1.2977 - val_accuracy: 0.4032

Epoch 00555: val_loss did not improve from 1.29558
Epoch 556/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4134 - val_loss: 1.2950 - val_accuracy: 0.4167

Epoch 00556: val_loss improved from 1.29558 to 1.29503, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 557/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4131 - val_loss: 1.2930 - val_accuracy: 0.4143

Epoch 00557: val_loss improved from 1.29503 to 1.29305, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 558/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4129 - val_loss: 1.2949 - val_accuracy: 0.4127

Epoch 00558: val_loss did not improve from 1.29305
Epoch 559/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4128 - val_loss: 1.3080 - val_accuracy: 0.4104

Epoch 00559: val_loss did not improve from 1.29305
Epoch 560/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4135 - val_loss: 1.2943 - val_accuracy: 0.4056

Epoch 00560: val_loss did not improve from 1.29305
Epoch 561/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4143 - val_loss: 1.2945 - val_accuracy: 0.4096

Epoch 00561: val_loss did not improve from 1.29305
Epoch 562/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4155 - val_loss: 1.2985 - val_accuracy: 0.4151

Epoch 00562: val_loss did not improve from 1.29305
Epoch 563/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4180 - val_loss: 1.2964 - val_accuracy: 0.4024

Epoch 00563: val_loss did not improve from 1.29305
Epoch 564/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4132 - val_loss: 1.2964 - val_accuracy: 0.4080

Epoch 00564: val_loss did not improve from 1.29305
Epoch 565/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4137 - val_loss: 1.2950 - val_accuracy: 0.4127

Epoch 00565: val_loss did not improve from 1.29305
Epoch 566/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4076 - val_loss: 1.3014 - val_accuracy: 0.4167

Epoch 00566: val_loss did not improve from 1.29305
Epoch 567/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4119 - val_loss: 1.2977 - val_accuracy: 0.4072

Epoch 00567: val_loss did not improve from 1.29305
Epoch 568/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4123 - val_loss: 1.2991 - val_accuracy: 0.3976

Epoch 00568: val_loss did not improve from 1.29305
Epoch 569/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4060 - val_loss: 1.2974 - val_accuracy: 0.4247

Epoch 00569: val_loss did not improve from 1.29305
Epoch 570/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4117 - val_loss: 1.3000 - val_accuracy: 0.4104

Epoch 00570: val_loss did not improve from 1.29305
Epoch 571/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4136 - val_loss: 1.2999 - val_accuracy: 0.4056

Epoch 00571: val_loss did not improve from 1.29305
Epoch 572/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4157 - val_loss: 1.3006 - val_accuracy: 0.4183

Epoch 00572: val_loss did not improve from 1.29305
Epoch 573/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4145 - val_loss: 1.2967 - val_accuracy: 0.4072

Epoch 00573: val_loss did not improve from 1.29305
Epoch 574/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4160 - val_loss: 1.2965 - val_accuracy: 0.4127

Epoch 00574: val_loss did not improve from 1.29305
Epoch 575/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4126 - val_loss: 1.2959 - val_accuracy: 0.4255

Epoch 00575: val_loss did not improve from 1.29305
Epoch 576/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4124 - val_loss: 1.2953 - val_accuracy: 0.4127

Epoch 00576: val_loss did not improve from 1.29305
Epoch 577/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4103 - val_loss: 1.2994 - val_accuracy: 0.4112

Epoch 00577: val_loss did not improve from 1.29305
Epoch 578/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4148 - val_loss: 1.2977 - val_accuracy: 0.4016

Epoch 00578: val_loss did not improve from 1.29305
Epoch 579/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4096 - val_loss: 1.2971 - val_accuracy: 0.4167

Epoch 00579: val_loss did not improve from 1.29305
Epoch 580/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4138 - val_loss: 1.2944 - val_accuracy: 0.4000

Epoch 00580: val_loss did not improve from 1.29305
Epoch 581/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4107 - val_loss: 1.2980 - val_accuracy: 0.4072

Epoch 00581: val_loss did not improve from 1.29305
Epoch 582/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4116 - val_loss: 1.2957 - val_accuracy: 0.4223

Epoch 00582: val_loss did not improve from 1.29305
Epoch 583/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4129 - val_loss: 1.2953 - val_accuracy: 0.4191

Epoch 00583: val_loss did not improve from 1.29305
Epoch 584/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4166 - val_loss: 1.2946 - val_accuracy: 0.4112

Epoch 00584: val_loss did not improve from 1.29305
Epoch 585/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4161 - val_loss: 1.2952 - val_accuracy: 0.4080

Epoch 00585: val_loss did not improve from 1.29305
Epoch 586/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4122 - val_loss: 1.2984 - val_accuracy: 0.4223

Epoch 00586: val_loss did not improve from 1.29305
Epoch 587/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4162 - val_loss: 1.2983 - val_accuracy: 0.4135

Epoch 00587: val_loss did not improve from 1.29305
Epoch 588/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4151 - val_loss: 1.2965 - val_accuracy: 0.4104

Epoch 00588: val_loss did not improve from 1.29305
Epoch 589/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4142 - val_loss: 1.2956 - val_accuracy: 0.4199

Epoch 00589: val_loss did not improve from 1.29305
Epoch 590/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4138 - val_loss: 1.2984 - val_accuracy: 0.4120

Epoch 00590: val_loss did not improve from 1.29305
Epoch 591/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4169 - val_loss: 1.2938 - val_accuracy: 0.4104

Epoch 00591: val_loss did not improve from 1.29305
Epoch 592/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4156 - val_loss: 1.2931 - val_accuracy: 0.4096

Epoch 00592: val_loss did not improve from 1.29305
Epoch 593/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4178 - val_loss: 1.2941 - val_accuracy: 0.4096

Epoch 00593: val_loss did not improve from 1.29305
Epoch 594/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4171 - val_loss: 1.2931 - val_accuracy: 0.4135

Epoch 00594: val_loss did not improve from 1.29305
Epoch 595/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4144 - val_loss: 1.2951 - val_accuracy: 0.4143

Epoch 00595: val_loss did not improve from 1.29305
Epoch 596/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4116 - val_loss: 1.2949 - val_accuracy: 0.4151

Epoch 00596: val_loss did not improve from 1.29305
Epoch 597/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4151 - val_loss: 1.2977 - val_accuracy: 0.4008

Epoch 00597: val_loss did not improve from 1.29305
Epoch 598/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4140 - val_loss: 1.2992 - val_accuracy: 0.4080

Epoch 00598: val_loss did not improve from 1.29305
Epoch 599/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4137 - val_loss: 1.2947 - val_accuracy: 0.4080

Epoch 00599: val_loss did not improve from 1.29305
Epoch 600/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4136 - val_loss: 1.2944 - val_accuracy: 0.4104

Epoch 00600: val_loss did not improve from 1.29305
Epoch 601/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4110 - val_loss: 1.2960 - val_accuracy: 0.4120

Epoch 00601: val_loss did not improve from 1.29305
Epoch 602/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4129 - val_loss: 1.2963 - val_accuracy: 0.4167

Epoch 00602: val_loss did not improve from 1.29305
Epoch 603/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4157 - val_loss: 1.2935 - val_accuracy: 0.4072

Epoch 00603: val_loss did not improve from 1.29305
Epoch 604/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4169 - val_loss: 1.2924 - val_accuracy: 0.4088

Epoch 00604: val_loss improved from 1.29305 to 1.29237, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 605/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4142 - val_loss: 1.2988 - val_accuracy: 0.4096

Epoch 00605: val_loss did not improve from 1.29237
Epoch 606/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4123 - val_loss: 1.2913 - val_accuracy: 0.4231

Epoch 00606: val_loss improved from 1.29237 to 1.29133, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 607/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4136 - val_loss: 1.2939 - val_accuracy: 0.4135

Epoch 00607: val_loss did not improve from 1.29133
Epoch 608/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4143 - val_loss: 1.2958 - val_accuracy: 0.4120

Epoch 00608: val_loss did not improve from 1.29133
Epoch 609/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4133 - val_loss: 1.2959 - val_accuracy: 0.4048

Epoch 00609: val_loss did not improve from 1.29133
Epoch 610/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4155 - val_loss: 1.2939 - val_accuracy: 0.4088

Epoch 00610: val_loss did not improve from 1.29133
Epoch 611/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4114 - val_loss: 1.2917 - val_accuracy: 0.4159

Epoch 00611: val_loss did not improve from 1.29133
Epoch 612/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4138 - val_loss: 1.2917 - val_accuracy: 0.4120

Epoch 00612: val_loss did not improve from 1.29133
Epoch 613/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4151 - val_loss: 1.2931 - val_accuracy: 0.4088

Epoch 00613: val_loss did not improve from 1.29133
Epoch 614/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4162 - val_loss: 1.2937 - val_accuracy: 0.4143

Epoch 00614: val_loss did not improve from 1.29133
Epoch 615/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4177 - val_loss: 1.2929 - val_accuracy: 0.4112

Epoch 00615: val_loss did not improve from 1.29133
Epoch 616/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4182 - val_loss: 1.2953 - val_accuracy: 0.4104

Epoch 00616: val_loss did not improve from 1.29133
Epoch 617/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4110 - val_loss: 1.2946 - val_accuracy: 0.4207

Epoch 00617: val_loss did not improve from 1.29133
Epoch 618/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4178 - val_loss: 1.2964 - val_accuracy: 0.4127

Epoch 00618: val_loss did not improve from 1.29133
Epoch 619/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4148 - val_loss: 1.2906 - val_accuracy: 0.4120

Epoch 00619: val_loss improved from 1.29133 to 1.29057, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 620/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4141 - val_loss: 1.2912 - val_accuracy: 0.4223

Epoch 00620: val_loss did not improve from 1.29057
Epoch 621/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4179 - val_loss: 1.2923 - val_accuracy: 0.4167

Epoch 00621: val_loss did not improve from 1.29057
Epoch 622/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4180 - val_loss: 1.2916 - val_accuracy: 0.4048

Epoch 00622: val_loss did not improve from 1.29057
Epoch 623/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4154 - val_loss: 1.2941 - val_accuracy: 0.4096

Epoch 00623: val_loss did not improve from 1.29057
Epoch 624/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4163 - val_loss: 1.2972 - val_accuracy: 0.4120

Epoch 00624: val_loss did not improve from 1.29057
Epoch 625/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4149 - val_loss: 1.2921 - val_accuracy: 0.4167

Epoch 00625: val_loss did not improve from 1.29057
Epoch 626/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4177 - val_loss: 1.2918 - val_accuracy: 0.4207

Epoch 00626: val_loss did not improve from 1.29057
Epoch 627/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4165 - val_loss: 1.2908 - val_accuracy: 0.4088

Epoch 00627: val_loss did not improve from 1.29057
Epoch 628/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4161 - val_loss: 1.2933 - val_accuracy: 0.4143

Epoch 00628: val_loss did not improve from 1.29057
Epoch 629/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4138 - val_loss: 1.2908 - val_accuracy: 0.4175

Epoch 00629: val_loss did not improve from 1.29057
Epoch 630/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4172 - val_loss: 1.2896 - val_accuracy: 0.4175

Epoch 00630: val_loss improved from 1.29057 to 1.28960, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 631/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4175 - val_loss: 1.2916 - val_accuracy: 0.4151

Epoch 00631: val_loss did not improve from 1.28960
Epoch 632/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4141 - val_loss: 1.2926 - val_accuracy: 0.4048

Epoch 00632: val_loss did not improve from 1.28960
Epoch 633/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4179 - val_loss: 1.2924 - val_accuracy: 0.4167

Epoch 00633: val_loss did not improve from 1.28960
Epoch 634/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4151 - val_loss: 1.2894 - val_accuracy: 0.4191

Epoch 00634: val_loss improved from 1.28960 to 1.28943, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 635/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4160 - val_loss: 1.2916 - val_accuracy: 0.4175

Epoch 00635: val_loss did not improve from 1.28943
Epoch 636/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4156 - val_loss: 1.2996 - val_accuracy: 0.4167

Epoch 00636: val_loss did not improve from 1.28943
Epoch 637/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4151 - val_loss: 1.2957 - val_accuracy: 0.4096

Epoch 00637: val_loss did not improve from 1.28943
Epoch 638/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4135 - val_loss: 1.2897 - val_accuracy: 0.4032

Epoch 00638: val_loss did not improve from 1.28943
Epoch 639/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4169 - val_loss: 1.2919 - val_accuracy: 0.4088

Epoch 00639: val_loss did not improve from 1.28943
Epoch 640/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4164 - val_loss: 1.2939 - val_accuracy: 0.4175

Epoch 00640: val_loss did not improve from 1.28943
Epoch 641/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4198 - val_loss: 1.2926 - val_accuracy: 0.4191

Epoch 00641: val_loss did not improve from 1.28943
Epoch 642/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4176 - val_loss: 1.2887 - val_accuracy: 0.4120

Epoch 00642: val_loss improved from 1.28943 to 1.28870, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 643/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4151 - val_loss: 1.2884 - val_accuracy: 0.4120

Epoch 00643: val_loss improved from 1.28870 to 1.28835, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 644/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4131 - val_loss: 1.2974 - val_accuracy: 0.4135

Epoch 00644: val_loss did not improve from 1.28835
Epoch 645/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4054 - val_loss: 1.2921 - val_accuracy: 0.4048

Epoch 00645: val_loss did not improve from 1.28835
Epoch 646/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4158 - val_loss: 1.2895 - val_accuracy: 0.4000

Epoch 00646: val_loss did not improve from 1.28835
Epoch 647/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4182 - val_loss: 1.2906 - val_accuracy: 0.4096

Epoch 00647: val_loss did not improve from 1.28835
Epoch 648/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4167 - val_loss: 1.2926 - val_accuracy: 0.4120

Epoch 00648: val_loss did not improve from 1.28835
Epoch 649/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4140 - val_loss: 1.2950 - val_accuracy: 0.4127

Epoch 00649: val_loss did not improve from 1.28835
Epoch 650/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4183 - val_loss: 1.2913 - val_accuracy: 0.4199

Epoch 00650: val_loss did not improve from 1.28835
Epoch 651/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4169 - val_loss: 1.2885 - val_accuracy: 0.4143

Epoch 00651: val_loss did not improve from 1.28835
Epoch 652/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4164 - val_loss: 1.2899 - val_accuracy: 0.4143

Epoch 00652: val_loss did not improve from 1.28835
Epoch 653/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4170 - val_loss: 1.2902 - val_accuracy: 0.4215

Epoch 00653: val_loss did not improve from 1.28835
Epoch 654/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4077 - val_loss: 1.3092 - val_accuracy: 0.4207

Epoch 00654: val_loss did not improve from 1.28835
Epoch 655/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4143 - val_loss: 1.2901 - val_accuracy: 0.4048

Epoch 00655: val_loss did not improve from 1.28835
Epoch 656/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4173 - val_loss: 1.2927 - val_accuracy: 0.4064

Epoch 00656: val_loss did not improve from 1.28835
Epoch 657/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4180 - val_loss: 1.2928 - val_accuracy: 0.4167

Epoch 00657: val_loss did not improve from 1.28835
Epoch 658/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4171 - val_loss: 1.2901 - val_accuracy: 0.4112

Epoch 00658: val_loss did not improve from 1.28835
Epoch 659/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4195 - val_loss: 1.2881 - val_accuracy: 0.4064

Epoch 00659: val_loss improved from 1.28835 to 1.28806, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 660/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4179 - val_loss: 1.2887 - val_accuracy: 0.4167

Epoch 00660: val_loss did not improve from 1.28806
Epoch 661/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4169 - val_loss: 1.2913 - val_accuracy: 0.4151

Epoch 00661: val_loss did not improve from 1.28806
Epoch 662/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4109 - val_loss: 1.2890 - val_accuracy: 0.4127

Epoch 00662: val_loss did not improve from 1.28806
Epoch 663/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4174 - val_loss: 1.2907 - val_accuracy: 0.4247

Epoch 00663: val_loss did not improve from 1.28806
Epoch 664/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4169 - val_loss: 1.2867 - val_accuracy: 0.4167

Epoch 00664: val_loss improved from 1.28806 to 1.28666, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 665/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4173 - val_loss: 1.2883 - val_accuracy: 0.4191

Epoch 00665: val_loss did not improve from 1.28666
Epoch 666/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4217 - val_loss: 1.2912 - val_accuracy: 0.4175

Epoch 00666: val_loss did not improve from 1.28666
Epoch 667/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4198 - val_loss: 1.2927 - val_accuracy: 0.4191

Epoch 00667: val_loss did not improve from 1.28666
Epoch 668/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4191 - val_loss: 1.2907 - val_accuracy: 0.4151

Epoch 00668: val_loss did not improve from 1.28666
Epoch 669/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4174 - val_loss: 1.2907 - val_accuracy: 0.4151

Epoch 00669: val_loss did not improve from 1.28666
Epoch 670/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4187 - val_loss: 1.2871 - val_accuracy: 0.4175

Epoch 00670: val_loss did not improve from 1.28666
Epoch 671/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4134 - val_loss: 1.2893 - val_accuracy: 0.4104

Epoch 00671: val_loss did not improve from 1.28666
Epoch 672/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4182 - val_loss: 1.2924 - val_accuracy: 0.4064

Epoch 00672: val_loss did not improve from 1.28666
Epoch 673/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4217 - val_loss: 1.2947 - val_accuracy: 0.4112

Epoch 00673: val_loss did not improve from 1.28666
Epoch 674/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4164 - val_loss: 1.2912 - val_accuracy: 0.4199

Epoch 00674: val_loss did not improve from 1.28666
Epoch 675/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4192 - val_loss: 1.2897 - val_accuracy: 0.4135

Epoch 00675: val_loss did not improve from 1.28666
Epoch 676/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4169 - val_loss: 1.2885 - val_accuracy: 0.4112

Epoch 00676: val_loss did not improve from 1.28666
Epoch 677/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4191 - val_loss: 1.2882 - val_accuracy: 0.4088

Epoch 00677: val_loss did not improve from 1.28666
Epoch 678/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4199 - val_loss: 1.2869 - val_accuracy: 0.4120

Epoch 00678: val_loss did not improve from 1.28666
Epoch 679/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4174 - val_loss: 1.2883 - val_accuracy: 0.4096

Epoch 00679: val_loss did not improve from 1.28666
Epoch 680/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4172 - val_loss: 1.2932 - val_accuracy: 0.4080

Epoch 00680: val_loss did not improve from 1.28666
Epoch 681/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4173 - val_loss: 1.2856 - val_accuracy: 0.4311

Epoch 00681: val_loss improved from 1.28666 to 1.28555, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 682/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4174 - val_loss: 1.2892 - val_accuracy: 0.4223

Epoch 00682: val_loss did not improve from 1.28555
Epoch 683/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4226 - val_loss: 1.2938 - val_accuracy: 0.4104

Epoch 00683: val_loss did not improve from 1.28555
Epoch 684/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4206 - val_loss: 1.2894 - val_accuracy: 0.4112

Epoch 00684: val_loss did not improve from 1.28555
Epoch 685/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4193 - val_loss: 1.2910 - val_accuracy: 0.4247

Epoch 00685: val_loss did not improve from 1.28555
Epoch 686/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4177 - val_loss: 1.2884 - val_accuracy: 0.4247

Epoch 00686: val_loss did not improve from 1.28555
Epoch 687/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4159 - val_loss: 1.2937 - val_accuracy: 0.4239

Epoch 00687: val_loss did not improve from 1.28555
Epoch 688/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4133 - val_loss: 1.2860 - val_accuracy: 0.4223

Epoch 00688: val_loss did not improve from 1.28555
Epoch 689/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4177 - val_loss: 1.2974 - val_accuracy: 0.4135

Epoch 00689: val_loss did not improve from 1.28555
Epoch 690/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4167 - val_loss: 1.2871 - val_accuracy: 0.4191

Epoch 00690: val_loss did not improve from 1.28555
Epoch 691/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4166 - val_loss: 1.2889 - val_accuracy: 0.4239

Epoch 00691: val_loss did not improve from 1.28555
Epoch 692/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4187 - val_loss: 1.2885 - val_accuracy: 0.4072

Epoch 00692: val_loss did not improve from 1.28555
Epoch 693/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4183 - val_loss: 1.2887 - val_accuracy: 0.4120

Epoch 00693: val_loss did not improve from 1.28555
Epoch 694/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4186 - val_loss: 1.2894 - val_accuracy: 0.4191

Epoch 00694: val_loss did not improve from 1.28555
Epoch 695/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4216 - val_loss: 1.2859 - val_accuracy: 0.4143

Epoch 00695: val_loss did not improve from 1.28555
Epoch 696/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4197 - val_loss: 1.2869 - val_accuracy: 0.4151

Epoch 00696: val_loss did not improve from 1.28555
Epoch 697/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4185 - val_loss: 1.2884 - val_accuracy: 0.4191

Epoch 00697: val_loss did not improve from 1.28555
Epoch 698/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4182 - val_loss: 1.2844 - val_accuracy: 0.4159

Epoch 00698: val_loss improved from 1.28555 to 1.28439, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 699/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4187 - val_loss: 1.2866 - val_accuracy: 0.4183

Epoch 00699: val_loss did not improve from 1.28439
Epoch 700/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4205 - val_loss: 1.2898 - val_accuracy: 0.4104

Epoch 00700: val_loss did not improve from 1.28439
Epoch 701/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4178 - val_loss: 1.2939 - val_accuracy: 0.4048

Epoch 00701: val_loss did not improve from 1.28439
Epoch 702/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4143 - val_loss: 1.2859 - val_accuracy: 0.4048

Epoch 00702: val_loss did not improve from 1.28439
Epoch 703/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4189 - val_loss: 1.2887 - val_accuracy: 0.4271

Epoch 00703: val_loss did not improve from 1.28439
Epoch 704/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4178 - val_loss: 1.2985 - val_accuracy: 0.4104

Epoch 00704: val_loss did not improve from 1.28439
Epoch 705/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4213 - val_loss: 1.2884 - val_accuracy: 0.4215

Epoch 00705: val_loss did not improve from 1.28439
Epoch 706/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4151 - val_loss: 1.3002 - val_accuracy: 0.4183

Epoch 00706: val_loss did not improve from 1.28439
Epoch 707/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4196 - val_loss: 1.2937 - val_accuracy: 0.4175

Epoch 00707: val_loss did not improve from 1.28439
Epoch 708/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4167 - val_loss: 1.2862 - val_accuracy: 0.4096

Epoch 00708: val_loss did not improve from 1.28439
Epoch 709/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4156 - val_loss: 1.2880 - val_accuracy: 0.4151

Epoch 00709: val_loss did not improve from 1.28439
Epoch 710/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4171 - val_loss: 1.2927 - val_accuracy: 0.4127

Epoch 00710: val_loss did not improve from 1.28439
Epoch 711/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4184 - val_loss: 1.2845 - val_accuracy: 0.4048

Epoch 00711: val_loss did not improve from 1.28439
Epoch 712/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4179 - val_loss: 1.2868 - val_accuracy: 0.4056

Epoch 00712: val_loss did not improve from 1.28439
Epoch 713/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4122 - val_loss: 1.2866 - val_accuracy: 0.4143

Epoch 00713: val_loss did not improve from 1.28439
Epoch 714/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4186 - val_loss: 1.2871 - val_accuracy: 0.4151

Epoch 00714: val_loss did not improve from 1.28439
Epoch 715/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4226 - val_loss: 1.2848 - val_accuracy: 0.4040

Epoch 00715: val_loss did not improve from 1.28439
Epoch 716/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4210 - val_loss: 1.2854 - val_accuracy: 0.4127

Epoch 00716: val_loss did not improve from 1.28439
Epoch 717/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4215 - val_loss: 1.2937 - val_accuracy: 0.4143

Epoch 00717: val_loss did not improve from 1.28439
Epoch 718/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4167 - val_loss: 1.2838 - val_accuracy: 0.4135

Epoch 00718: val_loss improved from 1.28439 to 1.28379, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 719/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4236 - val_loss: 1.2840 - val_accuracy: 0.4072

Epoch 00719: val_loss did not improve from 1.28379
Epoch 720/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4161 - val_loss: 1.2919 - val_accuracy: 0.4159

Epoch 00720: val_loss did not improve from 1.28379
Epoch 721/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4209 - val_loss: 1.2886 - val_accuracy: 0.4223

Epoch 00721: val_loss did not improve from 1.28379
Epoch 722/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4192 - val_loss: 1.2854 - val_accuracy: 0.4151

Epoch 00722: val_loss did not improve from 1.28379
Epoch 723/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4174 - val_loss: 1.2897 - val_accuracy: 0.4175

Epoch 00723: val_loss did not improve from 1.28379
Epoch 724/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4213 - val_loss: 1.2878 - val_accuracy: 0.4096

Epoch 00724: val_loss did not improve from 1.28379
Epoch 725/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4216 - val_loss: 1.2886 - val_accuracy: 0.4175

Epoch 00725: val_loss did not improve from 1.28379
Epoch 726/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4158 - val_loss: 1.2866 - val_accuracy: 0.4127

Epoch 00726: val_loss did not improve from 1.28379
Epoch 727/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4078 - val_loss: 1.2950 - val_accuracy: 0.4112

Epoch 00727: val_loss did not improve from 1.28379
Epoch 728/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4149 - val_loss: 1.2909 - val_accuracy: 0.4104

Epoch 00728: val_loss did not improve from 1.28379
Epoch 729/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4168 - val_loss: 1.2835 - val_accuracy: 0.4080

Epoch 00729: val_loss improved from 1.28379 to 1.28354, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 730/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4127 - val_loss: 1.2852 - val_accuracy: 0.4151

Epoch 00730: val_loss did not improve from 1.28354
Epoch 731/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4172 - val_loss: 1.2896 - val_accuracy: 0.4175

Epoch 00731: val_loss did not improve from 1.28354
Epoch 732/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4134 - val_loss: 1.2843 - val_accuracy: 0.4191

Epoch 00732: val_loss did not improve from 1.28354
Epoch 733/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4218 - val_loss: 1.2881 - val_accuracy: 0.4207

Epoch 00733: val_loss did not improve from 1.28354
Epoch 734/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4186 - val_loss: 1.2859 - val_accuracy: 0.4207

Epoch 00734: val_loss did not improve from 1.28354
Epoch 735/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4215 - val_loss: 1.2852 - val_accuracy: 0.4239

Epoch 00735: val_loss did not improve from 1.28354
Epoch 736/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4210 - val_loss: 1.2936 - val_accuracy: 0.4183

Epoch 00736: val_loss did not improve from 1.28354
Epoch 737/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4191 - val_loss: 1.2845 - val_accuracy: 0.4223

Epoch 00737: val_loss did not improve from 1.28354
Epoch 738/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4174 - val_loss: 1.2882 - val_accuracy: 0.4135

Epoch 00738: val_loss did not improve from 1.28354
Epoch 739/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4208 - val_loss: 1.2925 - val_accuracy: 0.4135

Epoch 00739: val_loss did not improve from 1.28354
Epoch 740/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4158 - val_loss: 1.2846 - val_accuracy: 0.4175

Epoch 00740: val_loss did not improve from 1.28354
Epoch 741/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4230 - val_loss: 1.2842 - val_accuracy: 0.4080

Epoch 00741: val_loss did not improve from 1.28354
Epoch 742/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4224 - val_loss: 1.2852 - val_accuracy: 0.4167

Epoch 00742: val_loss did not improve from 1.28354
Epoch 743/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4211 - val_loss: 1.2854 - val_accuracy: 0.4127

Epoch 00743: val_loss did not improve from 1.28354
Epoch 744/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4205 - val_loss: 1.2861 - val_accuracy: 0.4135

Epoch 00744: val_loss did not improve from 1.28354
Epoch 745/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4205 - val_loss: 1.2836 - val_accuracy: 0.4120

Epoch 00745: val_loss did not improve from 1.28354
Epoch 746/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4219 - val_loss: 1.2851 - val_accuracy: 0.4215

Epoch 00746: val_loss did not improve from 1.28354
Epoch 747/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4170 - val_loss: 1.2875 - val_accuracy: 0.4183

Epoch 00747: val_loss did not improve from 1.28354
Epoch 748/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4186 - val_loss: 1.2895 - val_accuracy: 0.4143

Epoch 00748: val_loss did not improve from 1.28354
Epoch 749/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4181 - val_loss: 1.2843 - val_accuracy: 0.4112

Epoch 00749: val_loss did not improve from 1.28354
Epoch 750/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4182 - val_loss: 1.2829 - val_accuracy: 0.4064

Epoch 00750: val_loss improved from 1.28354 to 1.28289, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 751/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4210 - val_loss: 1.2889 - val_accuracy: 0.4151

Epoch 00751: val_loss did not improve from 1.28289
Epoch 752/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4195 - val_loss: 1.2829 - val_accuracy: 0.4096

Epoch 00752: val_loss did not improve from 1.28289
Epoch 753/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4190 - val_loss: 1.2836 - val_accuracy: 0.4191

Epoch 00753: val_loss did not improve from 1.28289
Epoch 754/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4211 - val_loss: 1.2829 - val_accuracy: 0.4239

Epoch 00754: val_loss improved from 1.28289 to 1.28286, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 755/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4200 - val_loss: 1.2833 - val_accuracy: 0.4215

Epoch 00755: val_loss did not improve from 1.28286
Epoch 756/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4202 - val_loss: 1.2856 - val_accuracy: 0.4199

Epoch 00756: val_loss did not improve from 1.28286
Epoch 757/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4222 - val_loss: 1.2819 - val_accuracy: 0.4159

Epoch 00757: val_loss improved from 1.28286 to 1.28193, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 758/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4203 - val_loss: 1.2815 - val_accuracy: 0.4255

Epoch 00758: val_loss improved from 1.28193 to 1.28150, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 759/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4213 - val_loss: 1.2903 - val_accuracy: 0.4143

Epoch 00759: val_loss did not improve from 1.28150
Epoch 760/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4208 - val_loss: 1.2909 - val_accuracy: 0.4175

Epoch 00760: val_loss did not improve from 1.28150
Epoch 761/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4169 - val_loss: 1.2819 - val_accuracy: 0.4104

Epoch 00761: val_loss did not improve from 1.28150
Epoch 762/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4198 - val_loss: 1.2818 - val_accuracy: 0.4167

Epoch 00762: val_loss did not improve from 1.28150
Epoch 763/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4196 - val_loss: 1.2828 - val_accuracy: 0.4167

Epoch 00763: val_loss did not improve from 1.28150
Epoch 764/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4219 - val_loss: 1.2856 - val_accuracy: 0.4151

Epoch 00764: val_loss did not improve from 1.28150
Epoch 765/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4200 - val_loss: 1.2852 - val_accuracy: 0.4104

Epoch 00765: val_loss did not improve from 1.28150
Epoch 766/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4167 - val_loss: 1.2884 - val_accuracy: 0.4255

Epoch 00766: val_loss did not improve from 1.28150
Epoch 767/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4196 - val_loss: 1.2847 - val_accuracy: 0.4151

Epoch 00767: val_loss did not improve from 1.28150
Epoch 768/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4229 - val_loss: 1.2842 - val_accuracy: 0.4127

Epoch 00768: val_loss did not improve from 1.28150
Epoch 769/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4190 - val_loss: 1.2838 - val_accuracy: 0.4112

Epoch 00769: val_loss did not improve from 1.28150
Epoch 770/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4232 - val_loss: 1.2865 - val_accuracy: 0.4207

Epoch 00770: val_loss did not improve from 1.28150
Epoch 771/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4209 - val_loss: 1.2863 - val_accuracy: 0.4135

Epoch 00771: val_loss did not improve from 1.28150
Epoch 772/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4235 - val_loss: 1.2889 - val_accuracy: 0.4175

Epoch 00772: val_loss did not improve from 1.28150
Epoch 773/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4123 - val_loss: 1.2833 - val_accuracy: 0.4143

Epoch 00773: val_loss did not improve from 1.28150
Epoch 774/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4207 - val_loss: 1.2876 - val_accuracy: 0.4175

Epoch 00774: val_loss did not improve from 1.28150
Epoch 775/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4209 - val_loss: 1.2891 - val_accuracy: 0.4167

Epoch 00775: val_loss did not improve from 1.28150
Epoch 776/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4201 - val_loss: 1.2835 - val_accuracy: 0.4135

Epoch 00776: val_loss did not improve from 1.28150
Epoch 777/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4183 - val_loss: 1.2829 - val_accuracy: 0.4072

Epoch 00777: val_loss did not improve from 1.28150
Epoch 778/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4205 - val_loss: 1.2854 - val_accuracy: 0.4127

Epoch 00778: val_loss did not improve from 1.28150
Epoch 779/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4207 - val_loss: 1.2888 - val_accuracy: 0.4175

Epoch 00779: val_loss did not improve from 1.28150
Epoch 780/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4200 - val_loss: 1.2910 - val_accuracy: 0.4263

Epoch 00780: val_loss did not improve from 1.28150
Epoch 781/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4190 - val_loss: 1.2823 - val_accuracy: 0.4135

Epoch 00781: val_loss did not improve from 1.28150
Epoch 782/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4181 - val_loss: 1.2824 - val_accuracy: 0.4159

Epoch 00782: val_loss did not improve from 1.28150
Epoch 783/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4201 - val_loss: 1.2862 - val_accuracy: 0.4159

Epoch 00783: val_loss did not improve from 1.28150
Epoch 784/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4245 - val_loss: 1.2849 - val_accuracy: 0.4183

Epoch 00784: val_loss did not improve from 1.28150
Epoch 785/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4236 - val_loss: 1.2844 - val_accuracy: 0.4263

Epoch 00785: val_loss did not improve from 1.28150
Epoch 786/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4220 - val_loss: 1.2841 - val_accuracy: 0.4255

Epoch 00786: val_loss did not improve from 1.28150
Epoch 787/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4194 - val_loss: 1.2852 - val_accuracy: 0.4199

Epoch 00787: val_loss did not improve from 1.28150
Epoch 788/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4233 - val_loss: 1.2819 - val_accuracy: 0.4271

Epoch 00788: val_loss did not improve from 1.28150
Epoch 789/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4229 - val_loss: 1.2824 - val_accuracy: 0.4247

Epoch 00789: val_loss did not improve from 1.28150
Epoch 790/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4187 - val_loss: 1.2876 - val_accuracy: 0.4199

Epoch 00790: val_loss did not improve from 1.28150
Epoch 791/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4205 - val_loss: 1.2800 - val_accuracy: 0.4311

Epoch 00791: val_loss improved from 1.28150 to 1.28001, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 792/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4236 - val_loss: 1.2848 - val_accuracy: 0.4303

Epoch 00792: val_loss did not improve from 1.28001
Epoch 793/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4183 - val_loss: 1.2799 - val_accuracy: 0.4295

Epoch 00793: val_loss improved from 1.28001 to 1.27987, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 794/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4232 - val_loss: 1.2852 - val_accuracy: 0.4191

Epoch 00794: val_loss did not improve from 1.27987
Epoch 795/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4199 - val_loss: 1.2828 - val_accuracy: 0.4247

Epoch 00795: val_loss did not improve from 1.27987
Epoch 796/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4245 - val_loss: 1.2854 - val_accuracy: 0.4167

Epoch 00796: val_loss did not improve from 1.27987
Epoch 797/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4225 - val_loss: 1.2897 - val_accuracy: 0.4215

Epoch 00797: val_loss did not improve from 1.27987
Epoch 798/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4200 - val_loss: 1.2827 - val_accuracy: 0.4263

Epoch 00798: val_loss did not improve from 1.27987
Epoch 799/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4229 - val_loss: 1.2817 - val_accuracy: 0.4255

Epoch 00799: val_loss did not improve from 1.27987
Epoch 800/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4234 - val_loss: 1.2795 - val_accuracy: 0.4255

Epoch 00800: val_loss improved from 1.27987 to 1.27947, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 801/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4153 - val_loss: 1.2854 - val_accuracy: 0.4143

Epoch 00801: val_loss did not improve from 1.27947
Epoch 802/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4256 - val_loss: 1.2975 - val_accuracy: 0.4080

Epoch 00802: val_loss did not improve from 1.27947
Epoch 803/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4239 - val_loss: 1.2822 - val_accuracy: 0.4255

Epoch 00803: val_loss did not improve from 1.27947
Epoch 804/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4213 - val_loss: 1.2826 - val_accuracy: 0.4135

Epoch 00804: val_loss did not improve from 1.27947
Epoch 805/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4218 - val_loss: 1.2881 - val_accuracy: 0.4231

Epoch 00805: val_loss did not improve from 1.27947
Epoch 806/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4223 - val_loss: 1.2821 - val_accuracy: 0.4104

Epoch 00806: val_loss did not improve from 1.27947
Epoch 807/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4201 - val_loss: 1.2804 - val_accuracy: 0.4247

Epoch 00807: val_loss did not improve from 1.27947
Epoch 808/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4194 - val_loss: 1.2846 - val_accuracy: 0.4183

Epoch 00808: val_loss did not improve from 1.27947
Epoch 809/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4222 - val_loss: 1.2805 - val_accuracy: 0.4167

Epoch 00809: val_loss did not improve from 1.27947
Epoch 810/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4243 - val_loss: 1.2831 - val_accuracy: 0.4215

Epoch 00810: val_loss did not improve from 1.27947
Epoch 811/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4211 - val_loss: 1.2801 - val_accuracy: 0.4295

Epoch 00811: val_loss did not improve from 1.27947
Epoch 812/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4193 - val_loss: 1.2848 - val_accuracy: 0.4183

Epoch 00812: val_loss did not improve from 1.27947
Epoch 813/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4187 - val_loss: 1.2823 - val_accuracy: 0.4263

Epoch 00813: val_loss did not improve from 1.27947
Epoch 814/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4173 - val_loss: 1.2813 - val_accuracy: 0.4159

Epoch 00814: val_loss did not improve from 1.27947
Epoch 815/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4200 - val_loss: 1.2871 - val_accuracy: 0.4295

Epoch 00815: val_loss did not improve from 1.27947
Epoch 816/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4182 - val_loss: 1.2787 - val_accuracy: 0.4231

Epoch 00816: val_loss improved from 1.27947 to 1.27872, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 817/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4234 - val_loss: 1.2788 - val_accuracy: 0.4127

Epoch 00817: val_loss did not improve from 1.27872
Epoch 818/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4228 - val_loss: 1.2796 - val_accuracy: 0.4175

Epoch 00818: val_loss did not improve from 1.27872
Epoch 819/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4238 - val_loss: 1.2825 - val_accuracy: 0.4215

Epoch 00819: val_loss did not improve from 1.27872
Epoch 820/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4235 - val_loss: 1.2853 - val_accuracy: 0.4112

Epoch 00820: val_loss did not improve from 1.27872
Epoch 821/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4246 - val_loss: 1.2852 - val_accuracy: 0.4215

Epoch 00821: val_loss did not improve from 1.27872
Epoch 822/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4237 - val_loss: 1.2846 - val_accuracy: 0.4223

Epoch 00822: val_loss did not improve from 1.27872
Epoch 823/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4236 - val_loss: 1.2815 - val_accuracy: 0.4199

Epoch 00823: val_loss did not improve from 1.27872
Epoch 824/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4220 - val_loss: 1.2785 - val_accuracy: 0.4335

Epoch 00824: val_loss improved from 1.27872 to 1.27848, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 825/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4249 - val_loss: 1.2877 - val_accuracy: 0.4239

Epoch 00825: val_loss did not improve from 1.27848
Epoch 826/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4186 - val_loss: 1.2823 - val_accuracy: 0.4175

Epoch 00826: val_loss did not improve from 1.27848
Epoch 827/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4177 - val_loss: 1.2808 - val_accuracy: 0.4151

Epoch 00827: val_loss did not improve from 1.27848
Epoch 828/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4206 - val_loss: 1.2855 - val_accuracy: 0.4207

Epoch 00828: val_loss did not improve from 1.27848
Epoch 829/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4210 - val_loss: 1.2807 - val_accuracy: 0.4159

Epoch 00829: val_loss did not improve from 1.27848
Epoch 830/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4256 - val_loss: 1.2808 - val_accuracy: 0.4159

Epoch 00830: val_loss did not improve from 1.27848
Epoch 831/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4238 - val_loss: 1.2794 - val_accuracy: 0.4143

Epoch 00831: val_loss did not improve from 1.27848
Epoch 832/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4214 - val_loss: 1.2842 - val_accuracy: 0.4183

Epoch 00832: val_loss did not improve from 1.27848
Epoch 833/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4191 - val_loss: 1.2857 - val_accuracy: 0.4191

Epoch 00833: val_loss did not improve from 1.27848
Epoch 834/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4183 - val_loss: 1.2821 - val_accuracy: 0.4096

Epoch 00834: val_loss did not improve from 1.27848
Epoch 835/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4164 - val_loss: 1.2852 - val_accuracy: 0.4199

Epoch 00835: val_loss did not improve from 1.27848
Epoch 836/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4254 - val_loss: 1.2820 - val_accuracy: 0.4135

Epoch 00836: val_loss did not improve from 1.27848
Epoch 837/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4227 - val_loss: 1.2798 - val_accuracy: 0.4207

Epoch 00837: val_loss did not improve from 1.27848
Epoch 838/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4229 - val_loss: 1.2806 - val_accuracy: 0.4143

Epoch 00838: val_loss did not improve from 1.27848
Epoch 839/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4211 - val_loss: 1.2804 - val_accuracy: 0.4231

Epoch 00839: val_loss did not improve from 1.27848
Epoch 840/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4236 - val_loss: 1.2829 - val_accuracy: 0.4239

Epoch 00840: val_loss did not improve from 1.27848
Epoch 841/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4212 - val_loss: 1.2791 - val_accuracy: 0.4167

Epoch 00841: val_loss did not improve from 1.27848
Epoch 842/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4195 - val_loss: 1.2788 - val_accuracy: 0.4167

Epoch 00842: val_loss did not improve from 1.27848
Epoch 843/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4216 - val_loss: 1.2797 - val_accuracy: 0.4151

Epoch 00843: val_loss did not improve from 1.27848
Epoch 844/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4250 - val_loss: 1.2804 - val_accuracy: 0.4263

Epoch 00844: val_loss did not improve from 1.27848
Epoch 845/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4226 - val_loss: 1.2846 - val_accuracy: 0.4135

Epoch 00845: val_loss did not improve from 1.27848
Epoch 846/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4261 - val_loss: 1.2782 - val_accuracy: 0.4199

Epoch 00846: val_loss improved from 1.27848 to 1.27822, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 847/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4249 - val_loss: 1.2795 - val_accuracy: 0.4279

Epoch 00847: val_loss did not improve from 1.27822
Epoch 848/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4200 - val_loss: 1.2798 - val_accuracy: 0.4191

Epoch 00848: val_loss did not improve from 1.27822
Epoch 849/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4223 - val_loss: 1.2792 - val_accuracy: 0.4207

Epoch 00849: val_loss did not improve from 1.27822
Epoch 850/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4255 - val_loss: 1.2788 - val_accuracy: 0.4207

Epoch 00850: val_loss did not improve from 1.27822
Epoch 851/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4213 - val_loss: 1.2777 - val_accuracy: 0.4127

Epoch 00851: val_loss improved from 1.27822 to 1.27769, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 852/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4235 - val_loss: 1.2809 - val_accuracy: 0.4151

Epoch 00852: val_loss did not improve from 1.27769
Epoch 853/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4266 - val_loss: 1.2791 - val_accuracy: 0.4255

Epoch 00853: val_loss did not improve from 1.27769
Epoch 854/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4229 - val_loss: 1.2796 - val_accuracy: 0.4223

Epoch 00854: val_loss did not improve from 1.27769
Epoch 855/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4221 - val_loss: 1.2807 - val_accuracy: 0.4263

Epoch 00855: val_loss did not improve from 1.27769
Epoch 856/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4217 - val_loss: 1.2779 - val_accuracy: 0.4247

Epoch 00856: val_loss did not improve from 1.27769
Epoch 857/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4255 - val_loss: 1.2800 - val_accuracy: 0.4215

Epoch 00857: val_loss did not improve from 1.27769
Epoch 858/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4247 - val_loss: 1.2833 - val_accuracy: 0.4231

Epoch 00858: val_loss did not improve from 1.27769
Epoch 859/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4201 - val_loss: 1.2778 - val_accuracy: 0.4191

Epoch 00859: val_loss did not improve from 1.27769
Epoch 860/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4229 - val_loss: 1.2793 - val_accuracy: 0.4295

Epoch 00860: val_loss did not improve from 1.27769
Epoch 861/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4243 - val_loss: 1.2821 - val_accuracy: 0.4207

Epoch 00861: val_loss did not improve from 1.27769
Epoch 862/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4230 - val_loss: 1.2795 - val_accuracy: 0.4303

Epoch 00862: val_loss did not improve from 1.27769
Epoch 863/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4231 - val_loss: 1.2865 - val_accuracy: 0.4143

Epoch 00863: val_loss did not improve from 1.27769
Epoch 864/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4190 - val_loss: 1.2791 - val_accuracy: 0.4207

Epoch 00864: val_loss did not improve from 1.27769
Epoch 865/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4226 - val_loss: 1.2791 - val_accuracy: 0.4215

Epoch 00865: val_loss did not improve from 1.27769
Epoch 866/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4224 - val_loss: 1.2801 - val_accuracy: 0.4223

Epoch 00866: val_loss did not improve from 1.27769
Epoch 867/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4280 - val_loss: 1.2799 - val_accuracy: 0.4255

Epoch 00867: val_loss did not improve from 1.27769
Epoch 868/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4244 - val_loss: 1.2767 - val_accuracy: 0.4239

Epoch 00868: val_loss improved from 1.27769 to 1.27667, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 869/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4264 - val_loss: 1.2771 - val_accuracy: 0.4287

Epoch 00869: val_loss did not improve from 1.27667
Epoch 870/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4218 - val_loss: 1.2770 - val_accuracy: 0.4183

Epoch 00870: val_loss did not improve from 1.27667
Epoch 871/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4201 - val_loss: 1.2787 - val_accuracy: 0.4191

Epoch 00871: val_loss did not improve from 1.27667
Epoch 872/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4212 - val_loss: 1.2955 - val_accuracy: 0.4096

Epoch 00872: val_loss did not improve from 1.27667
Epoch 873/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4163 - val_loss: 1.2772 - val_accuracy: 0.4199

Epoch 00873: val_loss did not improve from 1.27667
Epoch 874/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4254 - val_loss: 1.2768 - val_accuracy: 0.4255

Epoch 00874: val_loss did not improve from 1.27667
Epoch 875/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4221 - val_loss: 1.2818 - val_accuracy: 0.4215

Epoch 00875: val_loss did not improve from 1.27667
Epoch 876/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4207 - val_loss: 1.2789 - val_accuracy: 0.4231

Epoch 00876: val_loss did not improve from 1.27667
Epoch 877/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4250 - val_loss: 1.2789 - val_accuracy: 0.4207

Epoch 00877: val_loss did not improve from 1.27667
Epoch 878/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4236 - val_loss: 1.2874 - val_accuracy: 0.4263

Epoch 00878: val_loss did not improve from 1.27667
Epoch 879/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4179 - val_loss: 1.2772 - val_accuracy: 0.4183

Epoch 00879: val_loss did not improve from 1.27667
Epoch 880/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4234 - val_loss: 1.2803 - val_accuracy: 0.4271

Epoch 00880: val_loss did not improve from 1.27667
Epoch 881/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4250 - val_loss: 1.2811 - val_accuracy: 0.4191

Epoch 00881: val_loss did not improve from 1.27667
Epoch 882/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4245 - val_loss: 1.2841 - val_accuracy: 0.4223

Epoch 00882: val_loss did not improve from 1.27667
Epoch 883/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4202 - val_loss: 1.2754 - val_accuracy: 0.4255

Epoch 00883: val_loss improved from 1.27667 to 1.27543, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 884/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4253 - val_loss: 1.2770 - val_accuracy: 0.4271

Epoch 00884: val_loss did not improve from 1.27543
Epoch 885/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4229 - val_loss: 1.2776 - val_accuracy: 0.4207

Epoch 00885: val_loss did not improve from 1.27543
Epoch 886/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4256 - val_loss: 1.2805 - val_accuracy: 0.4223

Epoch 00886: val_loss did not improve from 1.27543
Epoch 887/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4270 - val_loss: 1.2767 - val_accuracy: 0.4231

Epoch 00887: val_loss did not improve from 1.27543
Epoch 888/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4242 - val_loss: 1.2783 - val_accuracy: 0.4207

Epoch 00888: val_loss did not improve from 1.27543
Epoch 889/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4229 - val_loss: 1.2843 - val_accuracy: 0.4231

Epoch 00889: val_loss did not improve from 1.27543
Epoch 890/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4190 - val_loss: 1.2847 - val_accuracy: 0.4135

Epoch 00890: val_loss did not improve from 1.27543
Epoch 891/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4236 - val_loss: 1.2830 - val_accuracy: 0.4159

Epoch 00891: val_loss did not improve from 1.27543
Epoch 892/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4198 - val_loss: 1.2775 - val_accuracy: 0.4207

Epoch 00892: val_loss did not improve from 1.27543
Epoch 893/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4230 - val_loss: 1.2804 - val_accuracy: 0.4223

Epoch 00893: val_loss did not improve from 1.27543
Epoch 894/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4210 - val_loss: 1.2791 - val_accuracy: 0.4231

Epoch 00894: val_loss did not improve from 1.27543
Epoch 895/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4230 - val_loss: 1.2775 - val_accuracy: 0.4239

Epoch 00895: val_loss did not improve from 1.27543
Epoch 896/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4298 - val_loss: 1.2817 - val_accuracy: 0.4183

Epoch 00896: val_loss did not improve from 1.27543
Epoch 897/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4261 - val_loss: 1.2790 - val_accuracy: 0.4223

Epoch 00897: val_loss did not improve from 1.27543
Epoch 898/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4225 - val_loss: 1.2781 - val_accuracy: 0.4151

Epoch 00898: val_loss did not improve from 1.27543
Epoch 899/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4250 - val_loss: 1.2787 - val_accuracy: 0.4191

Epoch 00899: val_loss did not improve from 1.27543
Epoch 900/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4215 - val_loss: 1.2787 - val_accuracy: 0.4303

Epoch 00900: val_loss did not improve from 1.27543
Epoch 901/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4200 - val_loss: 1.2757 - val_accuracy: 0.4263

Epoch 00901: val_loss did not improve from 1.27543
Epoch 902/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4229 - val_loss: 1.2772 - val_accuracy: 0.4199

Epoch 00902: val_loss did not improve from 1.27543
Epoch 903/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4215 - val_loss: 1.2805 - val_accuracy: 0.4215

Epoch 00903: val_loss did not improve from 1.27543
Epoch 904/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4247 - val_loss: 1.2776 - val_accuracy: 0.4143

Epoch 00904: val_loss did not improve from 1.27543
Epoch 905/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4258 - val_loss: 1.2794 - val_accuracy: 0.4175

Epoch 00905: val_loss did not improve from 1.27543
Epoch 906/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4224 - val_loss: 1.2773 - val_accuracy: 0.4199

Epoch 00906: val_loss did not improve from 1.27543
Epoch 907/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4214 - val_loss: 1.2781 - val_accuracy: 0.4247

Epoch 00907: val_loss did not improve from 1.27543
Epoch 908/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4254 - val_loss: 1.2767 - val_accuracy: 0.4295

Epoch 00908: val_loss did not improve from 1.27543
Epoch 909/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4259 - val_loss: 1.2777 - val_accuracy: 0.4199

Epoch 00909: val_loss did not improve from 1.27543
Epoch 910/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4264 - val_loss: 1.2754 - val_accuracy: 0.4191

Epoch 00910: val_loss improved from 1.27543 to 1.27542, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 911/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4230 - val_loss: 1.2760 - val_accuracy: 0.4255

Epoch 00911: val_loss did not improve from 1.27542
Epoch 912/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4212 - val_loss: 1.2807 - val_accuracy: 0.4255

Epoch 00912: val_loss did not improve from 1.27542
Epoch 913/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4255 - val_loss: 1.2780 - val_accuracy: 0.4247

Epoch 00913: val_loss did not improve from 1.27542
Epoch 914/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4203 - val_loss: 1.2791 - val_accuracy: 0.4104

Epoch 00914: val_loss did not improve from 1.27542
Epoch 915/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4226 - val_loss: 1.2797 - val_accuracy: 0.4143

Epoch 00915: val_loss did not improve from 1.27542
Epoch 916/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4208 - val_loss: 1.2761 - val_accuracy: 0.4183

Epoch 00916: val_loss did not improve from 1.27542
Epoch 917/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4244 - val_loss: 1.2765 - val_accuracy: 0.4271

Epoch 00917: val_loss did not improve from 1.27542
Epoch 918/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4208 - val_loss: 1.2775 - val_accuracy: 0.4127

Epoch 00918: val_loss did not improve from 1.27542
Epoch 919/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4209 - val_loss: 1.2789 - val_accuracy: 0.4247

Epoch 00919: val_loss did not improve from 1.27542
Epoch 920/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4208 - val_loss: 1.2794 - val_accuracy: 0.4135

Epoch 00920: val_loss did not improve from 1.27542
Epoch 921/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4220 - val_loss: 1.2800 - val_accuracy: 0.4135

Epoch 00921: val_loss did not improve from 1.27542
Epoch 922/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4232 - val_loss: 1.2825 - val_accuracy: 0.4215

Epoch 00922: val_loss did not improve from 1.27542
Epoch 923/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4205 - val_loss: 1.2790 - val_accuracy: 0.4159

Epoch 00923: val_loss did not improve from 1.27542
Epoch 924/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4205 - val_loss: 1.2821 - val_accuracy: 0.4080

Epoch 00924: val_loss did not improve from 1.27542
Epoch 925/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4174 - val_loss: 1.2777 - val_accuracy: 0.4231

Epoch 00925: val_loss did not improve from 1.27542
Epoch 926/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4249 - val_loss: 1.2800 - val_accuracy: 0.4239

Epoch 00926: val_loss did not improve from 1.27542
Epoch 927/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4212 - val_loss: 1.2765 - val_accuracy: 0.4223

Epoch 00927: val_loss did not improve from 1.27542
Epoch 928/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4251 - val_loss: 1.2752 - val_accuracy: 0.4239

Epoch 00928: val_loss improved from 1.27542 to 1.27525, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 929/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4255 - val_loss: 1.2767 - val_accuracy: 0.4175

Epoch 00929: val_loss did not improve from 1.27525
Epoch 930/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4258 - val_loss: 1.2760 - val_accuracy: 0.4151

Epoch 00930: val_loss did not improve from 1.27525
Epoch 931/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4262 - val_loss: 1.2775 - val_accuracy: 0.4247

Epoch 00931: val_loss did not improve from 1.27525
Epoch 932/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4224 - val_loss: 1.2801 - val_accuracy: 0.4175

Epoch 00932: val_loss did not improve from 1.27525
Epoch 933/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4229 - val_loss: 1.2798 - val_accuracy: 0.4135

Epoch 00933: val_loss did not improve from 1.27525
Epoch 934/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4232 - val_loss: 1.2870 - val_accuracy: 0.4056

Epoch 00934: val_loss did not improve from 1.27525
Epoch 935/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4165 - val_loss: 1.2774 - val_accuracy: 0.4127

Epoch 00935: val_loss did not improve from 1.27525
Epoch 936/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4181 - val_loss: 1.2786 - val_accuracy: 0.4088

Epoch 00936: val_loss did not improve from 1.27525
Epoch 937/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4219 - val_loss: 1.2785 - val_accuracy: 0.4175

Epoch 00937: val_loss did not improve from 1.27525
Epoch 938/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4247 - val_loss: 1.2849 - val_accuracy: 0.4191

Epoch 00938: val_loss did not improve from 1.27525
Epoch 939/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4248 - val_loss: 1.2767 - val_accuracy: 0.4199

Epoch 00939: val_loss did not improve from 1.27525
Epoch 940/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4232 - val_loss: 1.2800 - val_accuracy: 0.4199

Epoch 00940: val_loss did not improve from 1.27525
Epoch 941/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4238 - val_loss: 1.2759 - val_accuracy: 0.4120

Epoch 00941: val_loss did not improve from 1.27525
Epoch 942/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4218 - val_loss: 1.2751 - val_accuracy: 0.4231

Epoch 00942: val_loss improved from 1.27525 to 1.27507, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 943/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4227 - val_loss: 1.2834 - val_accuracy: 0.4159

Epoch 00943: val_loss did not improve from 1.27507
Epoch 944/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4256 - val_loss: 1.2821 - val_accuracy: 0.4175

Epoch 00944: val_loss did not improve from 1.27507
Epoch 945/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4235 - val_loss: 1.2777 - val_accuracy: 0.4231

Epoch 00945: val_loss did not improve from 1.27507
Epoch 946/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4272 - val_loss: 1.2782 - val_accuracy: 0.4183

Epoch 00946: val_loss did not improve from 1.27507
Epoch 947/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4236 - val_loss: 1.2779 - val_accuracy: 0.4303

Epoch 00947: val_loss did not improve from 1.27507
Epoch 948/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4276 - val_loss: 1.2753 - val_accuracy: 0.4183

Epoch 00948: val_loss did not improve from 1.27507
Epoch 949/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4206 - val_loss: 1.2782 - val_accuracy: 0.4199

Epoch 00949: val_loss did not improve from 1.27507
Epoch 950/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4234 - val_loss: 1.2793 - val_accuracy: 0.4271

Epoch 00950: val_loss did not improve from 1.27507
Epoch 951/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4199 - val_loss: 1.2768 - val_accuracy: 0.4239

Epoch 00951: val_loss did not improve from 1.27507
Epoch 952/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4277 - val_loss: 1.2758 - val_accuracy: 0.4199

Epoch 00952: val_loss did not improve from 1.27507
Epoch 953/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4267 - val_loss: 1.2759 - val_accuracy: 0.4239

Epoch 00953: val_loss did not improve from 1.27507
Epoch 954/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4246 - val_loss: 1.2746 - val_accuracy: 0.4295

Epoch 00954: val_loss improved from 1.27507 to 1.27460, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 955/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4232 - val_loss: 1.2849 - val_accuracy: 0.4175

Epoch 00955: val_loss did not improve from 1.27460
Epoch 956/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4242 - val_loss: 1.2765 - val_accuracy: 0.4319

Epoch 00956: val_loss did not improve from 1.27460
Epoch 957/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4207 - val_loss: 1.2789 - val_accuracy: 0.4215

Epoch 00957: val_loss did not improve from 1.27460
Epoch 958/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4233 - val_loss: 1.2806 - val_accuracy: 0.4199

Epoch 00958: val_loss did not improve from 1.27460
Epoch 959/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4247 - val_loss: 1.2783 - val_accuracy: 0.4239

Epoch 00959: val_loss did not improve from 1.27460
Epoch 960/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4249 - val_loss: 1.2750 - val_accuracy: 0.4207

Epoch 00960: val_loss did not improve from 1.27460
Epoch 961/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4271 - val_loss: 1.2749 - val_accuracy: 0.4263

Epoch 00961: val_loss did not improve from 1.27460
Epoch 962/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4280 - val_loss: 1.2733 - val_accuracy: 0.4191

Epoch 00962: val_loss improved from 1.27460 to 1.27328, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 963/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4279 - val_loss: 1.2753 - val_accuracy: 0.4247

Epoch 00963: val_loss did not improve from 1.27328
Epoch 964/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4235 - val_loss: 1.2763 - val_accuracy: 0.4263

Epoch 00964: val_loss did not improve from 1.27328
Epoch 965/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4213 - val_loss: 1.2758 - val_accuracy: 0.4120

Epoch 00965: val_loss did not improve from 1.27328
Epoch 966/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4234 - val_loss: 1.2818 - val_accuracy: 0.4127

Epoch 00966: val_loss did not improve from 1.27328
Epoch 967/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4254 - val_loss: 1.2747 - val_accuracy: 0.4175

Epoch 00967: val_loss did not improve from 1.27328
Epoch 968/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4258 - val_loss: 1.2769 - val_accuracy: 0.4271

Epoch 00968: val_loss did not improve from 1.27328
Epoch 969/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4232 - val_loss: 1.2792 - val_accuracy: 0.4127

Epoch 00969: val_loss did not improve from 1.27328
Epoch 970/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4258 - val_loss: 1.2786 - val_accuracy: 0.4112

Epoch 00970: val_loss did not improve from 1.27328
Epoch 971/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4291 - val_loss: 1.2758 - val_accuracy: 0.4199

Epoch 00971: val_loss did not improve from 1.27328
Epoch 972/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4258 - val_loss: 1.2826 - val_accuracy: 0.4215

Epoch 00972: val_loss did not improve from 1.27328
Epoch 973/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4247 - val_loss: 1.2785 - val_accuracy: 0.4207

Epoch 00973: val_loss did not improve from 1.27328
Epoch 974/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4244 - val_loss: 1.2764 - val_accuracy: 0.4175

Epoch 00974: val_loss did not improve from 1.27328
Epoch 975/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4209 - val_loss: 1.2768 - val_accuracy: 0.4223

Epoch 00975: val_loss did not improve from 1.27328
Epoch 976/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4213 - val_loss: 1.2917 - val_accuracy: 0.4135

Epoch 00976: val_loss did not improve from 1.27328
Epoch 977/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4229 - val_loss: 1.2804 - val_accuracy: 0.4319

Epoch 00977: val_loss did not improve from 1.27328
Epoch 978/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4217 - val_loss: 1.2739 - val_accuracy: 0.4271

Epoch 00978: val_loss did not improve from 1.27328
Epoch 979/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4215 - val_loss: 1.2775 - val_accuracy: 0.4207

Epoch 00979: val_loss did not improve from 1.27328
Epoch 980/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4238 - val_loss: 1.2771 - val_accuracy: 0.4279

Epoch 00980: val_loss did not improve from 1.27328
Epoch 981/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4257 - val_loss: 1.2765 - val_accuracy: 0.4247

Epoch 00981: val_loss did not improve from 1.27328
Epoch 982/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4270 - val_loss: 1.2827 - val_accuracy: 0.4199

Epoch 00982: val_loss did not improve from 1.27328
Epoch 983/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4244 - val_loss: 1.2764 - val_accuracy: 0.4199

Epoch 00983: val_loss did not improve from 1.27328
Epoch 984/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4263 - val_loss: 1.2776 - val_accuracy: 0.4231

Epoch 00984: val_loss did not improve from 1.27328
Epoch 985/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4244 - val_loss: 1.2775 - val_accuracy: 0.4183

Epoch 00985: val_loss did not improve from 1.27328
Epoch 986/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4213 - val_loss: 1.2774 - val_accuracy: 0.4199

Epoch 00986: val_loss did not improve from 1.27328
Epoch 987/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4244 - val_loss: 1.2759 - val_accuracy: 0.4231

Epoch 00987: val_loss did not improve from 1.27328
Epoch 988/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4226 - val_loss: 1.2794 - val_accuracy: 0.4207

Epoch 00988: val_loss did not improve from 1.27328
Epoch 989/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4240 - val_loss: 1.2755 - val_accuracy: 0.4215

Epoch 00989: val_loss did not improve from 1.27328
Epoch 990/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4185 - val_loss: 1.2786 - val_accuracy: 0.4255

Epoch 00990: val_loss did not improve from 1.27328
Epoch 991/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4239 - val_loss: 1.2782 - val_accuracy: 0.4167

Epoch 00991: val_loss did not improve from 1.27328
Epoch 992/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4256 - val_loss: 1.2744 - val_accuracy: 0.4135

Epoch 00992: val_loss did not improve from 1.27328
Epoch 993/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4242 - val_loss: 1.2788 - val_accuracy: 0.4239

Epoch 00993: val_loss did not improve from 1.27328
Epoch 994/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4275 - val_loss: 1.2732 - val_accuracy: 0.4167

Epoch 00994: val_loss improved from 1.27328 to 1.27322, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 995/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4264 - val_loss: 1.2771 - val_accuracy: 0.4191

Epoch 00995: val_loss did not improve from 1.27322
Epoch 996/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4252 - val_loss: 1.2781 - val_accuracy: 0.4112

Epoch 00996: val_loss did not improve from 1.27322
Epoch 997/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4213 - val_loss: 1.2752 - val_accuracy: 0.4159

Epoch 00997: val_loss did not improve from 1.27322
Epoch 998/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4236 - val_loss: 1.2764 - val_accuracy: 0.4271

Epoch 00998: val_loss did not improve from 1.27322
Epoch 999/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4244 - val_loss: 1.2795 - val_accuracy: 0.4215

Epoch 00999: val_loss did not improve from 1.27322
Epoch 1000/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4267 - val_loss: 1.2764 - val_accuracy: 0.4247

Epoch 01000: val_loss did not improve from 1.27322
Epoch 1001/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4262 - val_loss: 1.2777 - val_accuracy: 0.4183

Epoch 01001: val_loss did not improve from 1.27322
Epoch 1002/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4270 - val_loss: 1.2736 - val_accuracy: 0.4239

Epoch 01002: val_loss did not improve from 1.27322
Epoch 1003/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4241 - val_loss: 1.2764 - val_accuracy: 0.4247

Epoch 01003: val_loss did not improve from 1.27322
Epoch 1004/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4215 - val_loss: 1.2822 - val_accuracy: 0.4175

Epoch 01004: val_loss did not improve from 1.27322
Epoch 1005/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4253 - val_loss: 1.2749 - val_accuracy: 0.4247

Epoch 01005: val_loss did not improve from 1.27322
Epoch 1006/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4251 - val_loss: 1.2741 - val_accuracy: 0.4191

Epoch 01006: val_loss did not improve from 1.27322
Epoch 1007/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4227 - val_loss: 1.2771 - val_accuracy: 0.4239

Epoch 01007: val_loss did not improve from 1.27322
Epoch 1008/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4224 - val_loss: 1.2708 - val_accuracy: 0.4199

Epoch 01008: val_loss improved from 1.27322 to 1.27080, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1009/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4233 - val_loss: 1.2752 - val_accuracy: 0.4263

Epoch 01009: val_loss did not improve from 1.27080
Epoch 1010/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4222 - val_loss: 1.2764 - val_accuracy: 0.4239

Epoch 01010: val_loss did not improve from 1.27080
Epoch 1011/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4260 - val_loss: 1.2838 - val_accuracy: 0.4215

Epoch 01011: val_loss did not improve from 1.27080
Epoch 1012/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4200 - val_loss: 1.2784 - val_accuracy: 0.4135

Epoch 01012: val_loss did not improve from 1.27080
Epoch 1013/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4213 - val_loss: 1.2723 - val_accuracy: 0.4215

Epoch 01013: val_loss did not improve from 1.27080
Epoch 1014/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4250 - val_loss: 1.2785 - val_accuracy: 0.4263

Epoch 01014: val_loss did not improve from 1.27080
Epoch 1015/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4235 - val_loss: 1.2758 - val_accuracy: 0.4223

Epoch 01015: val_loss did not improve from 1.27080
Epoch 1016/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4276 - val_loss: 1.2740 - val_accuracy: 0.4167

Epoch 01016: val_loss did not improve from 1.27080
Epoch 1017/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4229 - val_loss: 1.2757 - val_accuracy: 0.4199

Epoch 01017: val_loss did not improve from 1.27080
Epoch 1018/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4230 - val_loss: 1.2763 - val_accuracy: 0.4239

Epoch 01018: val_loss did not improve from 1.27080
Epoch 1019/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4198 - val_loss: 1.2722 - val_accuracy: 0.4311

Epoch 01019: val_loss did not improve from 1.27080
Epoch 1020/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4215 - val_loss: 1.2746 - val_accuracy: 0.4239

Epoch 01020: val_loss did not improve from 1.27080
Epoch 1021/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4210 - val_loss: 1.2757 - val_accuracy: 0.4199

Epoch 01021: val_loss did not improve from 1.27080
Epoch 1022/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4238 - val_loss: 1.2746 - val_accuracy: 0.4135

Epoch 01022: val_loss did not improve from 1.27080
Epoch 1023/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4209 - val_loss: 1.2747 - val_accuracy: 0.4215

Epoch 01023: val_loss did not improve from 1.27080
Epoch 1024/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4260 - val_loss: 1.2740 - val_accuracy: 0.4143

Epoch 01024: val_loss did not improve from 1.27080
Epoch 1025/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4217 - val_loss: 1.2741 - val_accuracy: 0.4199

Epoch 01025: val_loss did not improve from 1.27080
Epoch 1026/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4266 - val_loss: 1.2763 - val_accuracy: 0.4175

Epoch 01026: val_loss did not improve from 1.27080
Epoch 1027/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4239 - val_loss: 1.2726 - val_accuracy: 0.4207

Epoch 01027: val_loss did not improve from 1.27080
Epoch 1028/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4278 - val_loss: 1.2751 - val_accuracy: 0.4239

Epoch 01028: val_loss did not improve from 1.27080
Epoch 1029/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4239 - val_loss: 1.2750 - val_accuracy: 0.4223

Epoch 01029: val_loss did not improve from 1.27080
Epoch 1030/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4301 - val_loss: 1.2771 - val_accuracy: 0.4207

Epoch 01030: val_loss did not improve from 1.27080
Epoch 1031/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4230 - val_loss: 1.2756 - val_accuracy: 0.4191

Epoch 01031: val_loss did not improve from 1.27080
Epoch 1032/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4237 - val_loss: 1.2797 - val_accuracy: 0.4159

Epoch 01032: val_loss did not improve from 1.27080
Epoch 1033/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4247 - val_loss: 1.2742 - val_accuracy: 0.4191

Epoch 01033: val_loss did not improve from 1.27080
Epoch 1034/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4287 - val_loss: 1.2750 - val_accuracy: 0.4239

Epoch 01034: val_loss did not improve from 1.27080
Epoch 1035/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4255 - val_loss: 1.2748 - val_accuracy: 0.4207

Epoch 01035: val_loss did not improve from 1.27080
Epoch 1036/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4244 - val_loss: 1.2744 - val_accuracy: 0.4231

Epoch 01036: val_loss did not improve from 1.27080
Epoch 1037/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4234 - val_loss: 1.2721 - val_accuracy: 0.4191

Epoch 01037: val_loss did not improve from 1.27080
Epoch 1038/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4244 - val_loss: 1.2765 - val_accuracy: 0.4199

Epoch 01038: val_loss did not improve from 1.27080
Epoch 1039/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4272 - val_loss: 1.2774 - val_accuracy: 0.4231

Epoch 01039: val_loss did not improve from 1.27080
Epoch 1040/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4254 - val_loss: 1.2778 - val_accuracy: 0.4263

Epoch 01040: val_loss did not improve from 1.27080
Epoch 1041/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4190 - val_loss: 1.2757 - val_accuracy: 0.4231

Epoch 01041: val_loss did not improve from 1.27080
Epoch 1042/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4237 - val_loss: 1.2773 - val_accuracy: 0.4135

Epoch 01042: val_loss did not improve from 1.27080
Epoch 1043/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4239 - val_loss: 1.2746 - val_accuracy: 0.4223

Epoch 01043: val_loss did not improve from 1.27080
Epoch 1044/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4254 - val_loss: 1.2764 - val_accuracy: 0.4127

Epoch 01044: val_loss did not improve from 1.27080
Epoch 1045/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4246 - val_loss: 1.2789 - val_accuracy: 0.4143

Epoch 01045: val_loss did not improve from 1.27080
Epoch 1046/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4241 - val_loss: 1.2774 - val_accuracy: 0.4287

Epoch 01046: val_loss did not improve from 1.27080
Epoch 1047/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4236 - val_loss: 1.2722 - val_accuracy: 0.4191

Epoch 01047: val_loss did not improve from 1.27080
Epoch 1048/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4239 - val_loss: 1.2727 - val_accuracy: 0.4191

Epoch 01048: val_loss did not improve from 1.27080
Epoch 1049/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4294 - val_loss: 1.2745 - val_accuracy: 0.4271

Epoch 01049: val_loss did not improve from 1.27080
Epoch 1050/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4275 - val_loss: 1.2750 - val_accuracy: 0.4215

Epoch 01050: val_loss did not improve from 1.27080
Epoch 1051/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4187 - val_loss: 1.2871 - val_accuracy: 0.4231

Epoch 01051: val_loss did not improve from 1.27080
Epoch 1052/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4244 - val_loss: 1.2749 - val_accuracy: 0.4215

Epoch 01052: val_loss did not improve from 1.27080
Epoch 1053/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4245 - val_loss: 1.2728 - val_accuracy: 0.4199

Epoch 01053: val_loss did not improve from 1.27080
Epoch 1054/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4204 - val_loss: 1.2706 - val_accuracy: 0.4335

Epoch 01054: val_loss improved from 1.27080 to 1.27064, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1055/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4243 - val_loss: 1.2790 - val_accuracy: 0.4263

Epoch 01055: val_loss did not improve from 1.27064
Epoch 1056/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4213 - val_loss: 1.2748 - val_accuracy: 0.4255

Epoch 01056: val_loss did not improve from 1.27064
Epoch 1057/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4247 - val_loss: 1.2783 - val_accuracy: 0.4303

Epoch 01057: val_loss did not improve from 1.27064
Epoch 1058/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4234 - val_loss: 1.2732 - val_accuracy: 0.4247

Epoch 01058: val_loss did not improve from 1.27064
Epoch 1059/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4268 - val_loss: 1.2742 - val_accuracy: 0.4215

Epoch 01059: val_loss did not improve from 1.27064
Epoch 1060/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4233 - val_loss: 1.2738 - val_accuracy: 0.4143

Epoch 01060: val_loss did not improve from 1.27064
Epoch 1061/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4239 - val_loss: 1.2823 - val_accuracy: 0.4239

Epoch 01061: val_loss did not improve from 1.27064
Epoch 1062/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4261 - val_loss: 1.2752 - val_accuracy: 0.4207

Epoch 01062: val_loss did not improve from 1.27064
Epoch 1063/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4247 - val_loss: 1.2716 - val_accuracy: 0.4207

Epoch 01063: val_loss did not improve from 1.27064
Epoch 1064/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4252 - val_loss: 1.2794 - val_accuracy: 0.4279

Epoch 01064: val_loss did not improve from 1.27064
Epoch 1065/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4254 - val_loss: 1.2818 - val_accuracy: 0.4151

Epoch 01065: val_loss did not improve from 1.27064
Epoch 1066/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4254 - val_loss: 1.2735 - val_accuracy: 0.4247

Epoch 01066: val_loss did not improve from 1.27064
Epoch 1067/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4183 - val_loss: 1.2759 - val_accuracy: 0.4231

Epoch 01067: val_loss did not improve from 1.27064
Epoch 1068/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4203 - val_loss: 1.2755 - val_accuracy: 0.4112

Epoch 01068: val_loss did not improve from 1.27064
Epoch 1069/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4257 - val_loss: 1.2780 - val_accuracy: 0.4159

Epoch 01069: val_loss did not improve from 1.27064
Epoch 1070/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4253 - val_loss: 1.2775 - val_accuracy: 0.4215

Epoch 01070: val_loss did not improve from 1.27064
Epoch 1071/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4231 - val_loss: 1.2859 - val_accuracy: 0.4175

Epoch 01071: val_loss did not improve from 1.27064
Epoch 1072/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4211 - val_loss: 1.2752 - val_accuracy: 0.4120

Epoch 01072: val_loss did not improve from 1.27064
Epoch 1073/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4244 - val_loss: 1.2733 - val_accuracy: 0.4199

Epoch 01073: val_loss did not improve from 1.27064
Epoch 1074/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4252 - val_loss: 1.2724 - val_accuracy: 0.4159

Epoch 01074: val_loss did not improve from 1.27064
Epoch 1075/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4250 - val_loss: 1.2744 - val_accuracy: 0.4159

Epoch 01075: val_loss did not improve from 1.27064
Epoch 1076/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4278 - val_loss: 1.2739 - val_accuracy: 0.4279

Epoch 01076: val_loss did not improve from 1.27064
Epoch 1077/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4276 - val_loss: 1.2759 - val_accuracy: 0.4311

Epoch 01077: val_loss did not improve from 1.27064
Epoch 1078/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4283 - val_loss: 1.2742 - val_accuracy: 0.4327

Epoch 01078: val_loss did not improve from 1.27064
Epoch 1079/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4296 - val_loss: 1.2727 - val_accuracy: 0.4135

Epoch 01079: val_loss did not improve from 1.27064
Epoch 1080/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4208 - val_loss: 1.2742 - val_accuracy: 0.4167

Epoch 01080: val_loss did not improve from 1.27064
Epoch 1081/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4223 - val_loss: 1.2763 - val_accuracy: 0.4231

Epoch 01081: val_loss did not improve from 1.27064
Epoch 1082/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4226 - val_loss: 1.2823 - val_accuracy: 0.4223

Epoch 01082: val_loss did not improve from 1.27064
Epoch 1083/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4267 - val_loss: 1.2738 - val_accuracy: 0.4135

Epoch 01083: val_loss did not improve from 1.27064
Epoch 1084/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4268 - val_loss: 1.2731 - val_accuracy: 0.4175

Epoch 01084: val_loss did not improve from 1.27064
Epoch 1085/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4268 - val_loss: 1.2762 - val_accuracy: 0.4247

Epoch 01085: val_loss did not improve from 1.27064
Epoch 1086/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4257 - val_loss: 1.2720 - val_accuracy: 0.4151

Epoch 01086: val_loss did not improve from 1.27064
Epoch 1087/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4256 - val_loss: 1.2723 - val_accuracy: 0.4223

Epoch 01087: val_loss did not improve from 1.27064
Epoch 1088/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4258 - val_loss: 1.2701 - val_accuracy: 0.4239

Epoch 01088: val_loss improved from 1.27064 to 1.27011, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1089/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4243 - val_loss: 1.2746 - val_accuracy: 0.4239

Epoch 01089: val_loss did not improve from 1.27011
Epoch 1090/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4222 - val_loss: 1.2788 - val_accuracy: 0.4167

Epoch 01090: val_loss did not improve from 1.27011
Epoch 1091/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4283 - val_loss: 1.2708 - val_accuracy: 0.4191

Epoch 01091: val_loss did not improve from 1.27011
Epoch 1092/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4265 - val_loss: 1.2753 - val_accuracy: 0.4167

Epoch 01092: val_loss did not improve from 1.27011
Epoch 1093/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4280 - val_loss: 1.2846 - val_accuracy: 0.4151

Epoch 01093: val_loss did not improve from 1.27011
Epoch 1094/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4279 - val_loss: 1.2779 - val_accuracy: 0.4303

Epoch 01094: val_loss did not improve from 1.27011
Epoch 1095/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4238 - val_loss: 1.2756 - val_accuracy: 0.4215

Epoch 01095: val_loss did not improve from 1.27011
Epoch 1096/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4235 - val_loss: 1.2723 - val_accuracy: 0.4135

Epoch 01096: val_loss did not improve from 1.27011
Epoch 1097/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4254 - val_loss: 1.2776 - val_accuracy: 0.4151

Epoch 01097: val_loss did not improve from 1.27011
Epoch 1098/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4257 - val_loss: 1.2786 - val_accuracy: 0.4207

Epoch 01098: val_loss did not improve from 1.27011
Epoch 1099/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4285 - val_loss: 1.2743 - val_accuracy: 0.4175

Epoch 01099: val_loss did not improve from 1.27011
Epoch 1100/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4251 - val_loss: 1.2781 - val_accuracy: 0.4223

Epoch 01100: val_loss did not improve from 1.27011
Epoch 1101/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4260 - val_loss: 1.2757 - val_accuracy: 0.4199

Epoch 01101: val_loss did not improve from 1.27011
Epoch 1102/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4282 - val_loss: 1.2790 - val_accuracy: 0.4064

Epoch 01102: val_loss did not improve from 1.27011
Epoch 1103/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4256 - val_loss: 1.2750 - val_accuracy: 0.4159

Epoch 01103: val_loss did not improve from 1.27011
Epoch 1104/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4277 - val_loss: 1.2799 - val_accuracy: 0.4199

Epoch 01104: val_loss did not improve from 1.27011
Epoch 1105/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4277 - val_loss: 1.2728 - val_accuracy: 0.4215

Epoch 01105: val_loss did not improve from 1.27011
Epoch 1106/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4258 - val_loss: 1.2740 - val_accuracy: 0.4151

Epoch 01106: val_loss did not improve from 1.27011
Epoch 1107/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4268 - val_loss: 1.2734 - val_accuracy: 0.4223

Epoch 01107: val_loss did not improve from 1.27011
Epoch 1108/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4252 - val_loss: 1.2779 - val_accuracy: 0.4255

Epoch 01108: val_loss did not improve from 1.27011
Epoch 1109/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4291 - val_loss: 1.2717 - val_accuracy: 0.4215

Epoch 01109: val_loss did not improve from 1.27011
Epoch 1110/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4277 - val_loss: 1.2712 - val_accuracy: 0.4199

Epoch 01110: val_loss did not improve from 1.27011
Epoch 1111/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4254 - val_loss: 1.2728 - val_accuracy: 0.4367

Epoch 01111: val_loss did not improve from 1.27011
Epoch 1112/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4261 - val_loss: 1.2802 - val_accuracy: 0.4239

Epoch 01112: val_loss did not improve from 1.27011
Epoch 1113/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4204 - val_loss: 1.2718 - val_accuracy: 0.4287

Epoch 01113: val_loss did not improve from 1.27011
Epoch 1114/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4254 - val_loss: 1.2759 - val_accuracy: 0.4199

Epoch 01114: val_loss did not improve from 1.27011
Epoch 1115/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4275 - val_loss: 1.2732 - val_accuracy: 0.4167

Epoch 01115: val_loss did not improve from 1.27011
Epoch 1116/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4226 - val_loss: 1.2739 - val_accuracy: 0.4207

Epoch 01116: val_loss did not improve from 1.27011
Epoch 1117/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4240 - val_loss: 1.2874 - val_accuracy: 0.4159

Epoch 01117: val_loss did not improve from 1.27011
Epoch 1118/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4246 - val_loss: 1.2754 - val_accuracy: 0.4112

Epoch 01118: val_loss did not improve from 1.27011
Epoch 1119/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4242 - val_loss: 1.2787 - val_accuracy: 0.4239

Epoch 01119: val_loss did not improve from 1.27011
Epoch 1120/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4237 - val_loss: 1.2741 - val_accuracy: 0.4151

Epoch 01120: val_loss did not improve from 1.27011
Epoch 1121/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4263 - val_loss: 1.2748 - val_accuracy: 0.4183

Epoch 01121: val_loss did not improve from 1.27011
Epoch 1122/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4246 - val_loss: 1.2715 - val_accuracy: 0.4183

Epoch 01122: val_loss did not improve from 1.27011
Epoch 1123/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4164 - val_loss: 1.2901 - val_accuracy: 0.4151

Epoch 01123: val_loss did not improve from 1.27011
Epoch 1124/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4219 - val_loss: 1.2777 - val_accuracy: 0.4255

Epoch 01124: val_loss did not improve from 1.27011
Epoch 1125/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4227 - val_loss: 1.2840 - val_accuracy: 0.4143

Epoch 01125: val_loss did not improve from 1.27011
Epoch 1126/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4222 - val_loss: 1.2717 - val_accuracy: 0.4127

Epoch 01126: val_loss did not improve from 1.27011
Epoch 1127/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4226 - val_loss: 1.2777 - val_accuracy: 0.4199

Epoch 01127: val_loss did not improve from 1.27011
Epoch 1128/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4277 - val_loss: 1.2738 - val_accuracy: 0.4223

Epoch 01128: val_loss did not improve from 1.27011
Epoch 1129/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4283 - val_loss: 1.2743 - val_accuracy: 0.4311

Epoch 01129: val_loss did not improve from 1.27011
Epoch 1130/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4248 - val_loss: 1.2743 - val_accuracy: 0.4311

Epoch 01130: val_loss did not improve from 1.27011
Epoch 1131/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4275 - val_loss: 1.2741 - val_accuracy: 0.4271

Epoch 01131: val_loss did not improve from 1.27011
Epoch 1132/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4260 - val_loss: 1.2719 - val_accuracy: 0.4255

Epoch 01132: val_loss did not improve from 1.27011
Epoch 1133/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4238 - val_loss: 1.2722 - val_accuracy: 0.4183

Epoch 01133: val_loss did not improve from 1.27011
Epoch 1134/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4262 - val_loss: 1.2738 - val_accuracy: 0.4175

Epoch 01134: val_loss did not improve from 1.27011
Epoch 1135/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4249 - val_loss: 1.2711 - val_accuracy: 0.4191

Epoch 01135: val_loss did not improve from 1.27011
Epoch 1136/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4252 - val_loss: 1.2742 - val_accuracy: 0.4191

Epoch 01136: val_loss did not improve from 1.27011
Epoch 1137/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4272 - val_loss: 1.2733 - val_accuracy: 0.4207

Epoch 01137: val_loss did not improve from 1.27011
Epoch 1138/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4294 - val_loss: 1.2711 - val_accuracy: 0.4271

Epoch 01138: val_loss did not improve from 1.27011
Epoch 1139/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4255 - val_loss: 1.2691 - val_accuracy: 0.4279

Epoch 01139: val_loss improved from 1.27011 to 1.26912, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1140/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4233 - val_loss: 1.2783 - val_accuracy: 0.4287

Epoch 01140: val_loss did not improve from 1.26912
Epoch 1141/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4237 - val_loss: 1.2744 - val_accuracy: 0.4239

Epoch 01141: val_loss did not improve from 1.26912
Epoch 1142/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4198 - val_loss: 1.2717 - val_accuracy: 0.4191

Epoch 01142: val_loss did not improve from 1.26912
Epoch 1143/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4286 - val_loss: 1.2735 - val_accuracy: 0.4127

Epoch 01143: val_loss did not improve from 1.26912
Epoch 1144/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4236 - val_loss: 1.2776 - val_accuracy: 0.4311

Epoch 01144: val_loss did not improve from 1.26912
Epoch 1145/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4217 - val_loss: 1.2729 - val_accuracy: 0.4247

Epoch 01145: val_loss did not improve from 1.26912
Epoch 1146/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4255 - val_loss: 1.2726 - val_accuracy: 0.4215

Epoch 01146: val_loss did not improve from 1.26912
Epoch 1147/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4242 - val_loss: 1.2717 - val_accuracy: 0.4231

Epoch 01147: val_loss did not improve from 1.26912
Epoch 1148/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4252 - val_loss: 1.2763 - val_accuracy: 0.4239

Epoch 01148: val_loss did not improve from 1.26912
Epoch 1149/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4181 - val_loss: 1.2748 - val_accuracy: 0.4319

Epoch 01149: val_loss did not improve from 1.26912
Epoch 1150/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4237 - val_loss: 1.2694 - val_accuracy: 0.4215

Epoch 01150: val_loss did not improve from 1.26912
Epoch 1151/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4263 - val_loss: 1.2738 - val_accuracy: 0.4199

Epoch 01151: val_loss did not improve from 1.26912
Epoch 1152/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4276 - val_loss: 1.2723 - val_accuracy: 0.4183

Epoch 01152: val_loss did not improve from 1.26912
Epoch 1153/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4294 - val_loss: 1.2749 - val_accuracy: 0.4183

Epoch 01153: val_loss did not improve from 1.26912
Epoch 1154/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4256 - val_loss: 1.2746 - val_accuracy: 0.4159

Epoch 01154: val_loss did not improve from 1.26912
Epoch 1155/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4254 - val_loss: 1.2733 - val_accuracy: 0.4175

Epoch 01155: val_loss did not improve from 1.26912
Epoch 1156/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4223 - val_loss: 1.2831 - val_accuracy: 0.4175

Epoch 01156: val_loss did not improve from 1.26912
Epoch 1157/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4233 - val_loss: 1.2727 - val_accuracy: 0.4167

Epoch 01157: val_loss did not improve from 1.26912
Epoch 1158/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4238 - val_loss: 1.2710 - val_accuracy: 0.4120

Epoch 01158: val_loss did not improve from 1.26912
Epoch 1159/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4281 - val_loss: 1.2727 - val_accuracy: 0.4279

Epoch 01159: val_loss did not improve from 1.26912
Epoch 1160/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4267 - val_loss: 1.2750 - val_accuracy: 0.4215

Epoch 01160: val_loss did not improve from 1.26912
Epoch 1161/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4268 - val_loss: 1.2712 - val_accuracy: 0.4263

Epoch 01161: val_loss did not improve from 1.26912
Epoch 1162/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4221 - val_loss: 1.2747 - val_accuracy: 0.4183

Epoch 01162: val_loss did not improve from 1.26912
Epoch 1163/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4247 - val_loss: 1.2742 - val_accuracy: 0.4295

Epoch 01163: val_loss did not improve from 1.26912
Epoch 1164/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4280 - val_loss: 1.2721 - val_accuracy: 0.4231

Epoch 01164: val_loss did not improve from 1.26912
Epoch 1165/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4269 - val_loss: 1.2738 - val_accuracy: 0.4247

Epoch 01165: val_loss did not improve from 1.26912
Epoch 1166/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4215 - val_loss: 1.2726 - val_accuracy: 0.4183

Epoch 01166: val_loss did not improve from 1.26912
Epoch 1167/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4289 - val_loss: 1.2738 - val_accuracy: 0.4263

Epoch 01167: val_loss did not improve from 1.26912
Epoch 1168/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4272 - val_loss: 1.2743 - val_accuracy: 0.4215

Epoch 01168: val_loss did not improve from 1.26912
Epoch 1169/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4219 - val_loss: 1.2773 - val_accuracy: 0.4231

Epoch 01169: val_loss did not improve from 1.26912
Epoch 1170/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4250 - val_loss: 1.2767 - val_accuracy: 0.4215

Epoch 01170: val_loss did not improve from 1.26912
Epoch 1171/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4225 - val_loss: 1.2740 - val_accuracy: 0.4151

Epoch 01171: val_loss did not improve from 1.26912
Epoch 1172/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4207 - val_loss: 1.2727 - val_accuracy: 0.4207

Epoch 01172: val_loss did not improve from 1.26912
Epoch 1173/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4222 - val_loss: 1.2843 - val_accuracy: 0.4120

Epoch 01173: val_loss did not improve from 1.26912
Epoch 1174/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4250 - val_loss: 1.2707 - val_accuracy: 0.4311

Epoch 01174: val_loss did not improve from 1.26912
Epoch 1175/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4284 - val_loss: 1.2736 - val_accuracy: 0.4327

Epoch 01175: val_loss did not improve from 1.26912
Epoch 1176/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4277 - val_loss: 1.2767 - val_accuracy: 0.4223

Epoch 01176: val_loss did not improve from 1.26912
Epoch 1177/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4250 - val_loss: 1.2720 - val_accuracy: 0.4287

Epoch 01177: val_loss did not improve from 1.26912
Epoch 1178/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4264 - val_loss: 1.2727 - val_accuracy: 0.4255

Epoch 01178: val_loss did not improve from 1.26912
Epoch 1179/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4264 - val_loss: 1.2755 - val_accuracy: 0.4215

Epoch 01179: val_loss did not improve from 1.26912
Epoch 1180/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4267 - val_loss: 1.2779 - val_accuracy: 0.4239

Epoch 01180: val_loss did not improve from 1.26912
Epoch 1181/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4235 - val_loss: 1.2740 - val_accuracy: 0.4207

Epoch 01181: val_loss did not improve from 1.26912
Epoch 1182/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4245 - val_loss: 1.2780 - val_accuracy: 0.4263

Epoch 01182: val_loss did not improve from 1.26912
Epoch 1183/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4257 - val_loss: 1.2717 - val_accuracy: 0.4199

Epoch 01183: val_loss did not improve from 1.26912
Epoch 1184/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4270 - val_loss: 1.2758 - val_accuracy: 0.4223

Epoch 01184: val_loss did not improve from 1.26912
Epoch 1185/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4239 - val_loss: 1.2689 - val_accuracy: 0.4239

Epoch 01185: val_loss improved from 1.26912 to 1.26892, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1186/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4254 - val_loss: 1.2764 - val_accuracy: 0.4199

Epoch 01186: val_loss did not improve from 1.26892
Epoch 1187/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4213 - val_loss: 1.2732 - val_accuracy: 0.4255

Epoch 01187: val_loss did not improve from 1.26892
Epoch 1188/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4248 - val_loss: 1.2756 - val_accuracy: 0.4199

Epoch 01188: val_loss did not improve from 1.26892
Epoch 1189/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4259 - val_loss: 1.2742 - val_accuracy: 0.4199

Epoch 01189: val_loss did not improve from 1.26892
Epoch 1190/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4281 - val_loss: 1.2750 - val_accuracy: 0.4223

Epoch 01190: val_loss did not improve from 1.26892
Epoch 1191/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4251 - val_loss: 1.2712 - val_accuracy: 0.4191

Epoch 01191: val_loss did not improve from 1.26892
Epoch 1192/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4254 - val_loss: 1.2742 - val_accuracy: 0.4223

Epoch 01192: val_loss did not improve from 1.26892
Epoch 1193/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4284 - val_loss: 1.2714 - val_accuracy: 0.4255

Epoch 01193: val_loss did not improve from 1.26892
Epoch 1194/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4283 - val_loss: 1.2742 - val_accuracy: 0.4199

Epoch 01194: val_loss did not improve from 1.26892
Epoch 1195/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4254 - val_loss: 1.2712 - val_accuracy: 0.4223

Epoch 01195: val_loss did not improve from 1.26892
Epoch 1196/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4266 - val_loss: 1.2755 - val_accuracy: 0.4247

Epoch 01196: val_loss did not improve from 1.26892
Epoch 1197/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4276 - val_loss: 1.2704 - val_accuracy: 0.4271

Epoch 01197: val_loss did not improve from 1.26892
Epoch 1198/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4240 - val_loss: 1.2714 - val_accuracy: 0.4199

Epoch 01198: val_loss did not improve from 1.26892
Epoch 1199/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4296 - val_loss: 1.2739 - val_accuracy: 0.4191

Epoch 01199: val_loss did not improve from 1.26892
Epoch 1200/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4231 - val_loss: 1.2767 - val_accuracy: 0.4287

Epoch 01200: val_loss did not improve from 1.26892
Epoch 1201/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4230 - val_loss: 1.2834 - val_accuracy: 0.4112

Epoch 01201: val_loss did not improve from 1.26892
Epoch 1202/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4267 - val_loss: 1.2710 - val_accuracy: 0.4255

Epoch 01202: val_loss did not improve from 1.26892
Epoch 1203/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4276 - val_loss: 1.2725 - val_accuracy: 0.4255

Epoch 01203: val_loss did not improve from 1.26892
Epoch 1204/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4271 - val_loss: 1.2728 - val_accuracy: 0.4223

Epoch 01204: val_loss did not improve from 1.26892
Epoch 1205/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4240 - val_loss: 1.2714 - val_accuracy: 0.4151

Epoch 01205: val_loss did not improve from 1.26892
Epoch 1206/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4284 - val_loss: 1.2699 - val_accuracy: 0.4311

Epoch 01206: val_loss did not improve from 1.26892
Epoch 1207/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4270 - val_loss: 1.2734 - val_accuracy: 0.4207

Epoch 01207: val_loss did not improve from 1.26892
Epoch 1208/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4303 - val_loss: 1.2735 - val_accuracy: 0.4303

Epoch 01208: val_loss did not improve from 1.26892
Epoch 1209/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4251 - val_loss: 1.2749 - val_accuracy: 0.4223

Epoch 01209: val_loss did not improve from 1.26892
Epoch 1210/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4310 - val_loss: 1.2742 - val_accuracy: 0.4255

Epoch 01210: val_loss did not improve from 1.26892
Epoch 1211/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4253 - val_loss: 1.2710 - val_accuracy: 0.4239

Epoch 01211: val_loss did not improve from 1.26892
Epoch 1212/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4275 - val_loss: 1.2704 - val_accuracy: 0.4183

Epoch 01212: val_loss did not improve from 1.26892
Epoch 1213/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4267 - val_loss: 1.2819 - val_accuracy: 0.4247

Epoch 01213: val_loss did not improve from 1.26892
Epoch 1214/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4285 - val_loss: 1.2722 - val_accuracy: 0.4231

Epoch 01214: val_loss did not improve from 1.26892
Epoch 1215/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4267 - val_loss: 1.2709 - val_accuracy: 0.4303

Epoch 01215: val_loss did not improve from 1.26892
Epoch 1216/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4284 - val_loss: 1.2719 - val_accuracy: 0.4263

Epoch 01216: val_loss did not improve from 1.26892
Epoch 1217/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4260 - val_loss: 1.2725 - val_accuracy: 0.4231

Epoch 01217: val_loss did not improve from 1.26892
Epoch 1218/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4230 - val_loss: 1.2720 - val_accuracy: 0.4215

Epoch 01218: val_loss did not improve from 1.26892
Epoch 1219/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4276 - val_loss: 1.2723 - val_accuracy: 0.4207

Epoch 01219: val_loss did not improve from 1.26892
Epoch 1220/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4286 - val_loss: 1.2752 - val_accuracy: 0.4175

Epoch 01220: val_loss did not improve from 1.26892
Epoch 1221/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4275 - val_loss: 1.2727 - val_accuracy: 0.4215

Epoch 01221: val_loss did not improve from 1.26892
Epoch 1222/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4298 - val_loss: 1.2717 - val_accuracy: 0.4279

Epoch 01222: val_loss did not improve from 1.26892
Epoch 1223/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4283 - val_loss: 1.2747 - val_accuracy: 0.4263

Epoch 01223: val_loss did not improve from 1.26892
Epoch 1224/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4290 - val_loss: 1.2721 - val_accuracy: 0.4279

Epoch 01224: val_loss did not improve from 1.26892
Epoch 1225/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4245 - val_loss: 1.2695 - val_accuracy: 0.4303

Epoch 01225: val_loss did not improve from 1.26892
Epoch 1226/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4264 - val_loss: 1.2721 - val_accuracy: 0.4207

Epoch 01226: val_loss did not improve from 1.26892
Epoch 1227/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4283 - val_loss: 1.2695 - val_accuracy: 0.4263

Epoch 01227: val_loss did not improve from 1.26892
Epoch 1228/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4215 - val_loss: 1.2707 - val_accuracy: 0.4271

Epoch 01228: val_loss did not improve from 1.26892
Epoch 1229/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4273 - val_loss: 1.2785 - val_accuracy: 0.4271

Epoch 01229: val_loss did not improve from 1.26892
Epoch 1230/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4296 - val_loss: 1.2700 - val_accuracy: 0.4255

Epoch 01230: val_loss did not improve from 1.26892
Epoch 1231/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4313 - val_loss: 1.2707 - val_accuracy: 0.4279

Epoch 01231: val_loss did not improve from 1.26892
Epoch 1232/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4255 - val_loss: 1.2692 - val_accuracy: 0.4271

Epoch 01232: val_loss did not improve from 1.26892
Epoch 1233/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4289 - val_loss: 1.2717 - val_accuracy: 0.4271

Epoch 01233: val_loss did not improve from 1.26892
Epoch 1234/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4292 - val_loss: 1.2709 - val_accuracy: 0.4279

Epoch 01234: val_loss did not improve from 1.26892
Epoch 1235/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4252 - val_loss: 1.2777 - val_accuracy: 0.4175

Epoch 01235: val_loss did not improve from 1.26892
Epoch 1236/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4281 - val_loss: 1.2716 - val_accuracy: 0.4223

Epoch 01236: val_loss did not improve from 1.26892
Epoch 1237/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4293 - val_loss: 1.2719 - val_accuracy: 0.4295

Epoch 01237: val_loss did not improve from 1.26892
Epoch 1238/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4275 - val_loss: 1.2733 - val_accuracy: 0.4263

Epoch 01238: val_loss did not improve from 1.26892
Epoch 1239/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4252 - val_loss: 1.2720 - val_accuracy: 0.4215

Epoch 01239: val_loss did not improve from 1.26892
Epoch 1240/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4290 - val_loss: 1.2773 - val_accuracy: 0.4207

Epoch 01240: val_loss did not improve from 1.26892
Epoch 1241/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4254 - val_loss: 1.2708 - val_accuracy: 0.4207

Epoch 01241: val_loss did not improve from 1.26892
Epoch 1242/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4303 - val_loss: 1.2763 - val_accuracy: 0.4183

Epoch 01242: val_loss did not improve from 1.26892
Epoch 1243/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4248 - val_loss: 1.2709 - val_accuracy: 0.4120

Epoch 01243: val_loss did not improve from 1.26892
Epoch 1244/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4231 - val_loss: 1.2737 - val_accuracy: 0.4159

Epoch 01244: val_loss did not improve from 1.26892
Epoch 1245/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4267 - val_loss: 1.2718 - val_accuracy: 0.4247

Epoch 01245: val_loss did not improve from 1.26892
Epoch 1246/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4260 - val_loss: 1.2730 - val_accuracy: 0.4247

Epoch 01246: val_loss did not improve from 1.26892
Epoch 1247/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4250 - val_loss: 1.2733 - val_accuracy: 0.4056

Epoch 01247: val_loss did not improve from 1.26892
Epoch 1248/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4239 - val_loss: 1.2820 - val_accuracy: 0.4183

Epoch 01248: val_loss did not improve from 1.26892
Epoch 1249/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4229 - val_loss: 1.2742 - val_accuracy: 0.4271

Epoch 01249: val_loss did not improve from 1.26892
Epoch 1250/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4264 - val_loss: 1.2699 - val_accuracy: 0.4263

Epoch 01250: val_loss did not improve from 1.26892
Epoch 1251/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4232 - val_loss: 1.2754 - val_accuracy: 0.4183

Epoch 01251: val_loss did not improve from 1.26892
Epoch 1252/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4251 - val_loss: 1.2762 - val_accuracy: 0.4279

Epoch 01252: val_loss did not improve from 1.26892
Epoch 1253/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4260 - val_loss: 1.2689 - val_accuracy: 0.4255

Epoch 01253: val_loss did not improve from 1.26892
Epoch 1254/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4260 - val_loss: 1.2732 - val_accuracy: 0.4303

Epoch 01254: val_loss did not improve from 1.26892
Epoch 1255/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4260 - val_loss: 1.2741 - val_accuracy: 0.4247

Epoch 01255: val_loss did not improve from 1.26892
Epoch 1256/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4242 - val_loss: 1.2709 - val_accuracy: 0.4231

Epoch 01256: val_loss did not improve from 1.26892
Epoch 1257/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4264 - val_loss: 1.2683 - val_accuracy: 0.4295

Epoch 01257: val_loss improved from 1.26892 to 1.26832, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1258/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4256 - val_loss: 1.2722 - val_accuracy: 0.4239

Epoch 01258: val_loss did not improve from 1.26832
Epoch 1259/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4295 - val_loss: 1.2727 - val_accuracy: 0.4335

Epoch 01259: val_loss did not improve from 1.26832
Epoch 1260/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4229 - val_loss: 1.2688 - val_accuracy: 0.4207

Epoch 01260: val_loss did not improve from 1.26832
Epoch 1261/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4253 - val_loss: 1.2707 - val_accuracy: 0.4263

Epoch 01261: val_loss did not improve from 1.26832
Epoch 1262/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4291 - val_loss: 1.2711 - val_accuracy: 0.4239

Epoch 01262: val_loss did not improve from 1.26832
Epoch 1263/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4267 - val_loss: 1.2719 - val_accuracy: 0.4279

Epoch 01263: val_loss did not improve from 1.26832
Epoch 1264/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4271 - val_loss: 1.2719 - val_accuracy: 0.4247

Epoch 01264: val_loss did not improve from 1.26832
Epoch 1265/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4297 - val_loss: 1.2706 - val_accuracy: 0.4191

Epoch 01265: val_loss did not improve from 1.26832
Epoch 1266/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4261 - val_loss: 1.2806 - val_accuracy: 0.4271

Epoch 01266: val_loss did not improve from 1.26832
Epoch 1267/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4297 - val_loss: 1.2691 - val_accuracy: 0.4247

Epoch 01267: val_loss did not improve from 1.26832
Epoch 1268/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4288 - val_loss: 1.2711 - val_accuracy: 0.4287

Epoch 01268: val_loss did not improve from 1.26832
Epoch 1269/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4339 - val_loss: 1.2703 - val_accuracy: 0.4295

Epoch 01269: val_loss did not improve from 1.26832
Epoch 1270/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4321 - val_loss: 1.2683 - val_accuracy: 0.4239

Epoch 01270: val_loss improved from 1.26832 to 1.26829, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1271/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4290 - val_loss: 1.2737 - val_accuracy: 0.4271

Epoch 01271: val_loss did not improve from 1.26829
Epoch 1272/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4307 - val_loss: 1.2781 - val_accuracy: 0.4159

Epoch 01272: val_loss did not improve from 1.26829
Epoch 1273/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4242 - val_loss: 1.2682 - val_accuracy: 0.4223

Epoch 01273: val_loss improved from 1.26829 to 1.26821, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1274/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4253 - val_loss: 1.2682 - val_accuracy: 0.4231

Epoch 01274: val_loss improved from 1.26821 to 1.26819, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1275/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4301 - val_loss: 1.2723 - val_accuracy: 0.4295

Epoch 01275: val_loss did not improve from 1.26819
Epoch 1276/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4279 - val_loss: 1.2736 - val_accuracy: 0.4255

Epoch 01276: val_loss did not improve from 1.26819
Epoch 1277/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4277 - val_loss: 1.2728 - val_accuracy: 0.4183

Epoch 01277: val_loss did not improve from 1.26819
Epoch 1278/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4275 - val_loss: 1.2752 - val_accuracy: 0.4287

Epoch 01278: val_loss did not improve from 1.26819
Epoch 1279/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4260 - val_loss: 1.2758 - val_accuracy: 0.4231

Epoch 01279: val_loss did not improve from 1.26819
Epoch 1280/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4240 - val_loss: 1.2753 - val_accuracy: 0.4239

Epoch 01280: val_loss did not improve from 1.26819
Epoch 1281/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4265 - val_loss: 1.2711 - val_accuracy: 0.4255

Epoch 01281: val_loss did not improve from 1.26819
Epoch 1282/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4271 - val_loss: 1.2751 - val_accuracy: 0.4191

Epoch 01282: val_loss did not improve from 1.26819
Epoch 1283/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4255 - val_loss: 1.2698 - val_accuracy: 0.4207

Epoch 01283: val_loss did not improve from 1.26819
Epoch 1284/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4271 - val_loss: 1.2710 - val_accuracy: 0.4271

Epoch 01284: val_loss did not improve from 1.26819
Epoch 1285/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4278 - val_loss: 1.2704 - val_accuracy: 0.4239

Epoch 01285: val_loss did not improve from 1.26819
Epoch 1286/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4257 - val_loss: 1.2752 - val_accuracy: 0.4303

Epoch 01286: val_loss did not improve from 1.26819
Epoch 1287/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4289 - val_loss: 1.2689 - val_accuracy: 0.4279

Epoch 01287: val_loss did not improve from 1.26819
Epoch 1288/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4248 - val_loss: 1.2710 - val_accuracy: 0.4319

Epoch 01288: val_loss did not improve from 1.26819
Epoch 1289/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4292 - val_loss: 1.2736 - val_accuracy: 0.4239

Epoch 01289: val_loss did not improve from 1.26819
Epoch 1290/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4244 - val_loss: 1.2695 - val_accuracy: 0.4175

Epoch 01290: val_loss did not improve from 1.26819
Epoch 1291/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4284 - val_loss: 1.2706 - val_accuracy: 0.4279

Epoch 01291: val_loss did not improve from 1.26819
Epoch 1292/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4234 - val_loss: 1.2727 - val_accuracy: 0.4271

Epoch 01292: val_loss did not improve from 1.26819
Epoch 1293/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4244 - val_loss: 1.2710 - val_accuracy: 0.4207

Epoch 01293: val_loss did not improve from 1.26819
Epoch 1294/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4260 - val_loss: 1.2745 - val_accuracy: 0.4175

Epoch 01294: val_loss did not improve from 1.26819
Epoch 1295/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4267 - val_loss: 1.2716 - val_accuracy: 0.4223

Epoch 01295: val_loss did not improve from 1.26819
Epoch 1296/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4275 - val_loss: 1.2702 - val_accuracy: 0.4183

Epoch 01296: val_loss did not improve from 1.26819
Epoch 1297/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4273 - val_loss: 1.2724 - val_accuracy: 0.4191

Epoch 01297: val_loss did not improve from 1.26819
Epoch 1298/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4289 - val_loss: 1.2704 - val_accuracy: 0.4239

Epoch 01298: val_loss did not improve from 1.26819
Epoch 1299/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4280 - val_loss: 1.2695 - val_accuracy: 0.4303

Epoch 01299: val_loss did not improve from 1.26819
Epoch 1300/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4278 - val_loss: 1.2737 - val_accuracy: 0.4223

Epoch 01300: val_loss did not improve from 1.26819
Epoch 1301/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4298 - val_loss: 1.2747 - val_accuracy: 0.4151

Epoch 01301: val_loss did not improve from 1.26819
Epoch 1302/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4306 - val_loss: 1.2720 - val_accuracy: 0.4303

Epoch 01302: val_loss did not improve from 1.26819
Epoch 1303/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4268 - val_loss: 1.2728 - val_accuracy: 0.4215

Epoch 01303: val_loss did not improve from 1.26819
Epoch 1304/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4275 - val_loss: 1.2729 - val_accuracy: 0.4239

Epoch 01304: val_loss did not improve from 1.26819
Epoch 1305/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4284 - val_loss: 1.2683 - val_accuracy: 0.4223

Epoch 01305: val_loss did not improve from 1.26819
Epoch 1306/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4288 - val_loss: 1.2703 - val_accuracy: 0.4287

Epoch 01306: val_loss did not improve from 1.26819
Epoch 1307/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4275 - val_loss: 1.2708 - val_accuracy: 0.4255

Epoch 01307: val_loss did not improve from 1.26819
Epoch 1308/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4297 - val_loss: 1.2729 - val_accuracy: 0.4247

Epoch 01308: val_loss did not improve from 1.26819
Epoch 1309/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4279 - val_loss: 1.2722 - val_accuracy: 0.4215

Epoch 01309: val_loss did not improve from 1.26819
Epoch 1310/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4309 - val_loss: 1.2702 - val_accuracy: 0.4199

Epoch 01310: val_loss did not improve from 1.26819
Epoch 1311/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4311 - val_loss: 1.2714 - val_accuracy: 0.4247

Epoch 01311: val_loss did not improve from 1.26819
Epoch 1312/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4308 - val_loss: 1.2708 - val_accuracy: 0.4335

Epoch 01312: val_loss did not improve from 1.26819
Epoch 1313/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4300 - val_loss: 1.2713 - val_accuracy: 0.4263

Epoch 01313: val_loss did not improve from 1.26819
Epoch 1314/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4298 - val_loss: 1.2755 - val_accuracy: 0.4271

Epoch 01314: val_loss did not improve from 1.26819
Epoch 1315/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4264 - val_loss: 1.2706 - val_accuracy: 0.4247

Epoch 01315: val_loss did not improve from 1.26819
Epoch 1316/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4272 - val_loss: 1.2693 - val_accuracy: 0.4143

Epoch 01316: val_loss did not improve from 1.26819
Epoch 1317/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4233 - val_loss: 1.2844 - val_accuracy: 0.4231

Epoch 01317: val_loss did not improve from 1.26819
Epoch 1318/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4258 - val_loss: 1.2685 - val_accuracy: 0.4263

Epoch 01318: val_loss did not improve from 1.26819
Epoch 1319/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4239 - val_loss: 1.2674 - val_accuracy: 0.4191

Epoch 01319: val_loss improved from 1.26819 to 1.26743, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1320/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4267 - val_loss: 1.2684 - val_accuracy: 0.4223

Epoch 01320: val_loss did not improve from 1.26743
Epoch 1321/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4252 - val_loss: 1.2705 - val_accuracy: 0.4351

Epoch 01321: val_loss did not improve from 1.26743
Epoch 1322/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4238 - val_loss: 1.2719 - val_accuracy: 0.4231

Epoch 01322: val_loss did not improve from 1.26743
Epoch 1323/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4270 - val_loss: 1.2773 - val_accuracy: 0.4191

Epoch 01323: val_loss did not improve from 1.26743
Epoch 1324/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4172 - val_loss: 1.2711 - val_accuracy: 0.4183

Epoch 01324: val_loss did not improve from 1.26743
Epoch 1325/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4214 - val_loss: 1.2870 - val_accuracy: 0.4183

Epoch 01325: val_loss did not improve from 1.26743
Epoch 1326/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4205 - val_loss: 1.2681 - val_accuracy: 0.4279

Epoch 01326: val_loss did not improve from 1.26743
Epoch 1327/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4284 - val_loss: 1.2744 - val_accuracy: 0.4311

Epoch 01327: val_loss did not improve from 1.26743
Epoch 1328/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4275 - val_loss: 1.2701 - val_accuracy: 0.4215

Epoch 01328: val_loss did not improve from 1.26743
Epoch 1329/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4277 - val_loss: 1.2744 - val_accuracy: 0.4191

Epoch 01329: val_loss did not improve from 1.26743
Epoch 1330/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4297 - val_loss: 1.2745 - val_accuracy: 0.4207

Epoch 01330: val_loss did not improve from 1.26743
Epoch 1331/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4281 - val_loss: 1.2711 - val_accuracy: 0.4311

Epoch 01331: val_loss did not improve from 1.26743
Epoch 1332/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4288 - val_loss: 1.2730 - val_accuracy: 0.4199

Epoch 01332: val_loss did not improve from 1.26743
Epoch 1333/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4280 - val_loss: 1.2762 - val_accuracy: 0.4223

Epoch 01333: val_loss did not improve from 1.26743
Epoch 1334/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4297 - val_loss: 1.2742 - val_accuracy: 0.4151

Epoch 01334: val_loss did not improve from 1.26743
Epoch 1335/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4265 - val_loss: 1.2730 - val_accuracy: 0.4247

Epoch 01335: val_loss did not improve from 1.26743
Epoch 1336/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4305 - val_loss: 1.2697 - val_accuracy: 0.4199

Epoch 01336: val_loss did not improve from 1.26743
Epoch 1337/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4291 - val_loss: 1.2730 - val_accuracy: 0.4199

Epoch 01337: val_loss did not improve from 1.26743
Epoch 1338/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4310 - val_loss: 1.2688 - val_accuracy: 0.4271

Epoch 01338: val_loss did not improve from 1.26743
Epoch 1339/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4301 - val_loss: 1.2730 - val_accuracy: 0.4231

Epoch 01339: val_loss did not improve from 1.26743
Epoch 1340/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4298 - val_loss: 1.2684 - val_accuracy: 0.4223

Epoch 01340: val_loss did not improve from 1.26743
Epoch 1341/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4285 - val_loss: 1.2697 - val_accuracy: 0.4239

Epoch 01341: val_loss did not improve from 1.26743
Epoch 1342/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4276 - val_loss: 1.2722 - val_accuracy: 0.4231

Epoch 01342: val_loss did not improve from 1.26743
Epoch 1343/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4280 - val_loss: 1.2683 - val_accuracy: 0.4231

Epoch 01343: val_loss did not improve from 1.26743
Epoch 1344/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4292 - val_loss: 1.2753 - val_accuracy: 0.4207

Epoch 01344: val_loss did not improve from 1.26743
Epoch 1345/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4275 - val_loss: 1.2672 - val_accuracy: 0.4279

Epoch 01345: val_loss improved from 1.26743 to 1.26715, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1346/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4254 - val_loss: 1.2719 - val_accuracy: 0.4231

Epoch 01346: val_loss did not improve from 1.26715
Epoch 1347/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4277 - val_loss: 1.2681 - val_accuracy: 0.4279

Epoch 01347: val_loss did not improve from 1.26715
Epoch 1348/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4226 - val_loss: 1.2767 - val_accuracy: 0.4239

Epoch 01348: val_loss did not improve from 1.26715
Epoch 1349/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4271 - val_loss: 1.2722 - val_accuracy: 0.4191

Epoch 01349: val_loss did not improve from 1.26715
Epoch 1350/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4296 - val_loss: 1.2701 - val_accuracy: 0.4215

Epoch 01350: val_loss did not improve from 1.26715
Epoch 1351/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4276 - val_loss: 1.2700 - val_accuracy: 0.4151

Epoch 01351: val_loss did not improve from 1.26715
Epoch 1352/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4296 - val_loss: 1.2714 - val_accuracy: 0.4287

Epoch 01352: val_loss did not improve from 1.26715
Epoch 1353/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4293 - val_loss: 1.2688 - val_accuracy: 0.4239

Epoch 01353: val_loss did not improve from 1.26715
Epoch 1354/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4268 - val_loss: 1.2713 - val_accuracy: 0.4215

Epoch 01354: val_loss did not improve from 1.26715
Epoch 1355/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4273 - val_loss: 1.2781 - val_accuracy: 0.4127

Epoch 01355: val_loss did not improve from 1.26715
Epoch 1356/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4265 - val_loss: 1.2718 - val_accuracy: 0.4279

Epoch 01356: val_loss did not improve from 1.26715
Epoch 1357/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4292 - val_loss: 1.2717 - val_accuracy: 0.4231

Epoch 01357: val_loss did not improve from 1.26715
Epoch 1358/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4283 - val_loss: 1.2684 - val_accuracy: 0.4231

Epoch 01358: val_loss did not improve from 1.26715
Epoch 1359/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4270 - val_loss: 1.2716 - val_accuracy: 0.4215

Epoch 01359: val_loss did not improve from 1.26715
Epoch 1360/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4286 - val_loss: 1.2709 - val_accuracy: 0.4223

Epoch 01360: val_loss did not improve from 1.26715
Epoch 1361/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4246 - val_loss: 1.2714 - val_accuracy: 0.4207

Epoch 01361: val_loss did not improve from 1.26715
Epoch 1362/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4237 - val_loss: 1.2720 - val_accuracy: 0.4207

Epoch 01362: val_loss did not improve from 1.26715
Epoch 1363/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4267 - val_loss: 1.2674 - val_accuracy: 0.4223

Epoch 01363: val_loss did not improve from 1.26715
Epoch 1364/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4249 - val_loss: 1.2727 - val_accuracy: 0.4255

Epoch 01364: val_loss did not improve from 1.26715
Epoch 1365/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4255 - val_loss: 1.2675 - val_accuracy: 0.4215

Epoch 01365: val_loss did not improve from 1.26715
Epoch 1366/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4264 - val_loss: 1.2736 - val_accuracy: 0.4199

Epoch 01366: val_loss did not improve from 1.26715
Epoch 1367/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4287 - val_loss: 1.2697 - val_accuracy: 0.4207

Epoch 01367: val_loss did not improve from 1.26715
Epoch 1368/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4297 - val_loss: 1.2769 - val_accuracy: 0.4279

Epoch 01368: val_loss did not improve from 1.26715
Epoch 1369/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4286 - val_loss: 1.2692 - val_accuracy: 0.4279

Epoch 01369: val_loss did not improve from 1.26715
Epoch 1370/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4251 - val_loss: 1.2739 - val_accuracy: 0.4215

Epoch 01370: val_loss did not improve from 1.26715
Epoch 1371/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4216 - val_loss: 1.2714 - val_accuracy: 0.4239

Epoch 01371: val_loss did not improve from 1.26715
Epoch 1372/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4252 - val_loss: 1.2697 - val_accuracy: 0.4263

Epoch 01372: val_loss did not improve from 1.26715
Epoch 1373/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4283 - val_loss: 1.2689 - val_accuracy: 0.4311

Epoch 01373: val_loss did not improve from 1.26715
Epoch 1374/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4229 - val_loss: 1.2771 - val_accuracy: 0.4247

Epoch 01374: val_loss did not improve from 1.26715
Epoch 1375/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4253 - val_loss: 1.2672 - val_accuracy: 0.4279

Epoch 01375: val_loss did not improve from 1.26715
Epoch 1376/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4295 - val_loss: 1.2699 - val_accuracy: 0.4247

Epoch 01376: val_loss did not improve from 1.26715
Epoch 1377/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4291 - val_loss: 1.2703 - val_accuracy: 0.4207

Epoch 01377: val_loss did not improve from 1.26715
Epoch 1378/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4270 - val_loss: 1.2682 - val_accuracy: 0.4231

Epoch 01378: val_loss did not improve from 1.26715
Epoch 1379/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4292 - val_loss: 1.2707 - val_accuracy: 0.4167

Epoch 01379: val_loss did not improve from 1.26715
Epoch 1380/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4318 - val_loss: 1.2738 - val_accuracy: 0.4255

Epoch 01380: val_loss did not improve from 1.26715
Epoch 1381/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4283 - val_loss: 1.2729 - val_accuracy: 0.4215

Epoch 01381: val_loss did not improve from 1.26715
Epoch 1382/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4289 - val_loss: 1.2713 - val_accuracy: 0.4199

Epoch 01382: val_loss did not improve from 1.26715
Epoch 1383/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4297 - val_loss: 1.2691 - val_accuracy: 0.4239

Epoch 01383: val_loss did not improve from 1.26715
Epoch 1384/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4296 - val_loss: 1.2738 - val_accuracy: 0.4167

Epoch 01384: val_loss did not improve from 1.26715
Epoch 1385/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4244 - val_loss: 1.2716 - val_accuracy: 0.4191

Epoch 01385: val_loss did not improve from 1.26715
Epoch 1386/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4281 - val_loss: 1.2689 - val_accuracy: 0.4239

Epoch 01386: val_loss did not improve from 1.26715
Epoch 1387/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4277 - val_loss: 1.2708 - val_accuracy: 0.4151

Epoch 01387: val_loss did not improve from 1.26715
Epoch 1388/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4260 - val_loss: 1.2705 - val_accuracy: 0.4279

Epoch 01388: val_loss did not improve from 1.26715
Epoch 1389/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4268 - val_loss: 1.2771 - val_accuracy: 0.4239

Epoch 01389: val_loss did not improve from 1.26715
Epoch 1390/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4259 - val_loss: 1.2678 - val_accuracy: 0.4279

Epoch 01390: val_loss did not improve from 1.26715
Epoch 1391/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4304 - val_loss: 1.2761 - val_accuracy: 0.4191

Epoch 01391: val_loss did not improve from 1.26715
Epoch 1392/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4283 - val_loss: 1.2690 - val_accuracy: 0.4231

Epoch 01392: val_loss did not improve from 1.26715
Epoch 1393/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4264 - val_loss: 1.2833 - val_accuracy: 0.4263

Epoch 01393: val_loss did not improve from 1.26715
Epoch 1394/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4277 - val_loss: 1.2673 - val_accuracy: 0.4319

Epoch 01394: val_loss did not improve from 1.26715
Epoch 1395/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4252 - val_loss: 1.2726 - val_accuracy: 0.4183

Epoch 01395: val_loss did not improve from 1.26715
Epoch 1396/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4267 - val_loss: 1.2678 - val_accuracy: 0.4311

Epoch 01396: val_loss did not improve from 1.26715
Epoch 1397/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4293 - val_loss: 1.2674 - val_accuracy: 0.4271

Epoch 01397: val_loss did not improve from 1.26715
Epoch 1398/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4289 - val_loss: 1.2711 - val_accuracy: 0.4271

Epoch 01398: val_loss did not improve from 1.26715
Epoch 1399/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4310 - val_loss: 1.2702 - val_accuracy: 0.4215

Epoch 01399: val_loss did not improve from 1.26715
Epoch 1400/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4312 - val_loss: 1.2675 - val_accuracy: 0.4239

Epoch 01400: val_loss did not improve from 1.26715
Epoch 1401/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4285 - val_loss: 1.2678 - val_accuracy: 0.4183

Epoch 01401: val_loss did not improve from 1.26715
Epoch 1402/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4271 - val_loss: 1.2685 - val_accuracy: 0.4303

Epoch 01402: val_loss did not improve from 1.26715
Epoch 1403/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4295 - val_loss: 1.2693 - val_accuracy: 0.4303

Epoch 01403: val_loss did not improve from 1.26715
Epoch 1404/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4317 - val_loss: 1.2742 - val_accuracy: 0.4239

Epoch 01404: val_loss did not improve from 1.26715
Epoch 1405/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4286 - val_loss: 1.2746 - val_accuracy: 0.4183

Epoch 01405: val_loss did not improve from 1.26715
Epoch 1406/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4261 - val_loss: 1.2753 - val_accuracy: 0.4239

Epoch 01406: val_loss did not improve from 1.26715
Epoch 1407/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4258 - val_loss: 1.2714 - val_accuracy: 0.4287

Epoch 01407: val_loss did not improve from 1.26715
Epoch 1408/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4302 - val_loss: 1.2711 - val_accuracy: 0.4215

Epoch 01408: val_loss did not improve from 1.26715
Epoch 1409/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4283 - val_loss: 1.2713 - val_accuracy: 0.4255

Epoch 01409: val_loss did not improve from 1.26715
Epoch 1410/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4236 - val_loss: 1.2735 - val_accuracy: 0.4207

Epoch 01410: val_loss did not improve from 1.26715
Epoch 1411/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4269 - val_loss: 1.2683 - val_accuracy: 0.4183

Epoch 01411: val_loss did not improve from 1.26715
Epoch 1412/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4237 - val_loss: 1.2757 - val_accuracy: 0.4191

Epoch 01412: val_loss did not improve from 1.26715
Epoch 1413/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4327 - val_loss: 1.2708 - val_accuracy: 0.4191

Epoch 01413: val_loss did not improve from 1.26715
Epoch 1414/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4306 - val_loss: 1.2728 - val_accuracy: 0.4271

Epoch 01414: val_loss did not improve from 1.26715
Epoch 1415/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4259 - val_loss: 1.2720 - val_accuracy: 0.4239

Epoch 01415: val_loss did not improve from 1.26715
Epoch 1416/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4248 - val_loss: 1.2890 - val_accuracy: 0.4151

Epoch 01416: val_loss did not improve from 1.26715
Epoch 1417/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4228 - val_loss: 1.2769 - val_accuracy: 0.4167

Epoch 01417: val_loss did not improve from 1.26715
Epoch 1418/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4275 - val_loss: 1.2725 - val_accuracy: 0.4271

Epoch 01418: val_loss did not improve from 1.26715
Epoch 1419/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4274 - val_loss: 1.2683 - val_accuracy: 0.4295

Epoch 01419: val_loss did not improve from 1.26715
Epoch 1420/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4273 - val_loss: 1.2704 - val_accuracy: 0.4279

Epoch 01420: val_loss did not improve from 1.26715
Epoch 1421/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4306 - val_loss: 1.2783 - val_accuracy: 0.4135

Epoch 01421: val_loss did not improve from 1.26715
Epoch 1422/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4284 - val_loss: 1.2684 - val_accuracy: 0.4303

Epoch 01422: val_loss did not improve from 1.26715
Epoch 1423/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4252 - val_loss: 1.2750 - val_accuracy: 0.4271

Epoch 01423: val_loss did not improve from 1.26715
Epoch 1424/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4233 - val_loss: 1.2709 - val_accuracy: 0.4143

Epoch 01424: val_loss did not improve from 1.26715
Epoch 1425/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4279 - val_loss: 1.2718 - val_accuracy: 0.4175

Epoch 01425: val_loss did not improve from 1.26715
Epoch 1426/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4281 - val_loss: 1.2733 - val_accuracy: 0.4151

Epoch 01426: val_loss did not improve from 1.26715
Epoch 1427/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4288 - val_loss: 1.2700 - val_accuracy: 0.4247

Epoch 01427: val_loss did not improve from 1.26715
Epoch 1428/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4290 - val_loss: 1.2715 - val_accuracy: 0.4311

Epoch 01428: val_loss did not improve from 1.26715
Epoch 1429/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4291 - val_loss: 1.2704 - val_accuracy: 0.4247

Epoch 01429: val_loss did not improve from 1.26715
Epoch 1430/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4285 - val_loss: 1.2700 - val_accuracy: 0.4279

Epoch 01430: val_loss did not improve from 1.26715
Epoch 1431/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4260 - val_loss: 1.2710 - val_accuracy: 0.4327

Epoch 01431: val_loss did not improve from 1.26715
Epoch 1432/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4264 - val_loss: 1.2693 - val_accuracy: 0.4343

Epoch 01432: val_loss did not improve from 1.26715
Epoch 1433/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4257 - val_loss: 1.2686 - val_accuracy: 0.4287

Epoch 01433: val_loss did not improve from 1.26715
Epoch 1434/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4270 - val_loss: 1.2689 - val_accuracy: 0.4335

Epoch 01434: val_loss did not improve from 1.26715
Epoch 1435/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4306 - val_loss: 1.2718 - val_accuracy: 0.4247

Epoch 01435: val_loss did not improve from 1.26715
Epoch 1436/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4293 - val_loss: 1.2691 - val_accuracy: 0.4303

Epoch 01436: val_loss did not improve from 1.26715
Epoch 1437/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4289 - val_loss: 1.2703 - val_accuracy: 0.4231

Epoch 01437: val_loss did not improve from 1.26715
Epoch 1438/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4262 - val_loss: 1.2662 - val_accuracy: 0.4279

Epoch 01438: val_loss improved from 1.26715 to 1.26623, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1439/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4284 - val_loss: 1.2711 - val_accuracy: 0.4319

Epoch 01439: val_loss did not improve from 1.26623
Epoch 1440/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4314 - val_loss: 1.2670 - val_accuracy: 0.4398

Epoch 01440: val_loss did not improve from 1.26623
Epoch 1441/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4236 - val_loss: 1.2657 - val_accuracy: 0.4327

Epoch 01441: val_loss improved from 1.26623 to 1.26566, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1442/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4252 - val_loss: 1.2690 - val_accuracy: 0.4199

Epoch 01442: val_loss did not improve from 1.26566
Epoch 1443/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4275 - val_loss: 1.2671 - val_accuracy: 0.4319

Epoch 01443: val_loss did not improve from 1.26566
Epoch 1444/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4259 - val_loss: 1.2733 - val_accuracy: 0.4207

Epoch 01444: val_loss did not improve from 1.26566
Epoch 1445/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4288 - val_loss: 1.2740 - val_accuracy: 0.4255

Epoch 01445: val_loss did not improve from 1.26566
Epoch 1446/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4266 - val_loss: 1.2704 - val_accuracy: 0.4335

Epoch 01446: val_loss did not improve from 1.26566
Epoch 1447/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4260 - val_loss: 1.2679 - val_accuracy: 0.4335

Epoch 01447: val_loss did not improve from 1.26566
Epoch 1448/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4266 - val_loss: 1.2763 - val_accuracy: 0.4247

Epoch 01448: val_loss did not improve from 1.26566
Epoch 1449/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4295 - val_loss: 1.2673 - val_accuracy: 0.4255

Epoch 01449: val_loss did not improve from 1.26566
Epoch 1450/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4248 - val_loss: 1.2708 - val_accuracy: 0.4143

Epoch 01450: val_loss did not improve from 1.26566
Epoch 1451/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4243 - val_loss: 1.2696 - val_accuracy: 0.4207

Epoch 01451: val_loss did not improve from 1.26566
Epoch 1452/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4236 - val_loss: 1.2742 - val_accuracy: 0.4199

Epoch 01452: val_loss did not improve from 1.26566
Epoch 1453/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4271 - val_loss: 1.2660 - val_accuracy: 0.4191

Epoch 01453: val_loss did not improve from 1.26566
Epoch 1454/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4272 - val_loss: 1.2684 - val_accuracy: 0.4319

Epoch 01454: val_loss did not improve from 1.26566
Epoch 1455/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4279 - val_loss: 1.2715 - val_accuracy: 0.4239

Epoch 01455: val_loss did not improve from 1.26566
Epoch 1456/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4307 - val_loss: 1.2716 - val_accuracy: 0.4135

Epoch 01456: val_loss did not improve from 1.26566
Epoch 1457/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4271 - val_loss: 1.2698 - val_accuracy: 0.4279

Epoch 01457: val_loss did not improve from 1.26566
Epoch 1458/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4307 - val_loss: 1.2767 - val_accuracy: 0.4167

Epoch 01458: val_loss did not improve from 1.26566
Epoch 1459/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4296 - val_loss: 1.2704 - val_accuracy: 0.4151

Epoch 01459: val_loss did not improve from 1.26566
Epoch 1460/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4306 - val_loss: 1.2726 - val_accuracy: 0.4167

Epoch 01460: val_loss did not improve from 1.26566
Epoch 1461/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4269 - val_loss: 1.2680 - val_accuracy: 0.4239

Epoch 01461: val_loss did not improve from 1.26566
Epoch 1462/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4310 - val_loss: 1.2715 - val_accuracy: 0.4390

Epoch 01462: val_loss did not improve from 1.26566
Epoch 1463/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4297 - val_loss: 1.2717 - val_accuracy: 0.4247

Epoch 01463: val_loss did not improve from 1.26566
Epoch 1464/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4256 - val_loss: 1.2862 - val_accuracy: 0.4120

Epoch 01464: val_loss did not improve from 1.26566
Epoch 1465/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4269 - val_loss: 1.2670 - val_accuracy: 0.4207

Epoch 01465: val_loss did not improve from 1.26566
Epoch 1466/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4313 - val_loss: 1.2702 - val_accuracy: 0.4263

Epoch 01466: val_loss did not improve from 1.26566
Epoch 1467/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4281 - val_loss: 1.2685 - val_accuracy: 0.4167

Epoch 01467: val_loss did not improve from 1.26566
Epoch 1468/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4282 - val_loss: 1.2818 - val_accuracy: 0.4143

Epoch 01468: val_loss did not improve from 1.26566
Epoch 1469/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4299 - val_loss: 1.2756 - val_accuracy: 0.4247

Epoch 01469: val_loss did not improve from 1.26566
Epoch 1470/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4251 - val_loss: 1.2725 - val_accuracy: 0.4215

Epoch 01470: val_loss did not improve from 1.26566
Epoch 1471/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4328 - val_loss: 1.2700 - val_accuracy: 0.4255

Epoch 01471: val_loss did not improve from 1.26566
Epoch 1472/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4303 - val_loss: 1.2732 - val_accuracy: 0.4311

Epoch 01472: val_loss did not improve from 1.26566
Epoch 1473/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4270 - val_loss: 1.2747 - val_accuracy: 0.4191

Epoch 01473: val_loss did not improve from 1.26566
Epoch 1474/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4325 - val_loss: 1.2707 - val_accuracy: 0.4175

Epoch 01474: val_loss did not improve from 1.26566
Epoch 1475/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4254 - val_loss: 1.2686 - val_accuracy: 0.4239

Epoch 01475: val_loss did not improve from 1.26566
Epoch 1476/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4254 - val_loss: 1.2729 - val_accuracy: 0.4239

Epoch 01476: val_loss did not improve from 1.26566
Epoch 1477/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4273 - val_loss: 1.2685 - val_accuracy: 0.4303

Epoch 01477: val_loss did not improve from 1.26566
Epoch 1478/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4308 - val_loss: 1.2683 - val_accuracy: 0.4207

Epoch 01478: val_loss did not improve from 1.26566
Epoch 1479/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4275 - val_loss: 1.2689 - val_accuracy: 0.4207

Epoch 01479: val_loss did not improve from 1.26566
Epoch 1480/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4257 - val_loss: 1.2776 - val_accuracy: 0.4191

Epoch 01480: val_loss did not improve from 1.26566
Epoch 1481/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4298 - val_loss: 1.2691 - val_accuracy: 0.4335

Epoch 01481: val_loss did not improve from 1.26566
Epoch 1482/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4250 - val_loss: 1.2723 - val_accuracy: 0.4327

Epoch 01482: val_loss did not improve from 1.26566
Epoch 1483/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4229 - val_loss: 1.2768 - val_accuracy: 0.4263

Epoch 01483: val_loss did not improve from 1.26566
Epoch 1484/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4247 - val_loss: 1.2706 - val_accuracy: 0.4247

Epoch 01484: val_loss did not improve from 1.26566
Epoch 1485/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4290 - val_loss: 1.2729 - val_accuracy: 0.4223

Epoch 01485: val_loss did not improve from 1.26566
Epoch 1486/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4252 - val_loss: 1.2723 - val_accuracy: 0.4231

Epoch 01486: val_loss did not improve from 1.26566
Epoch 1487/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4295 - val_loss: 1.2700 - val_accuracy: 0.4231

Epoch 01487: val_loss did not improve from 1.26566
Epoch 1488/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4299 - val_loss: 1.2718 - val_accuracy: 0.4231

Epoch 01488: val_loss did not improve from 1.26566
Epoch 1489/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4273 - val_loss: 1.2765 - val_accuracy: 0.4127

Epoch 01489: val_loss did not improve from 1.26566
Epoch 1490/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4309 - val_loss: 1.2690 - val_accuracy: 0.4263

Epoch 01490: val_loss did not improve from 1.26566
Epoch 1491/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4298 - val_loss: 1.2720 - val_accuracy: 0.4231

Epoch 01491: val_loss did not improve from 1.26566
Epoch 1492/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4293 - val_loss: 1.2704 - val_accuracy: 0.4215

Epoch 01492: val_loss did not improve from 1.26566
Epoch 1493/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4281 - val_loss: 1.2691 - val_accuracy: 0.4279

Epoch 01493: val_loss did not improve from 1.26566
Epoch 1494/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4317 - val_loss: 1.2731 - val_accuracy: 0.4255

Epoch 01494: val_loss did not improve from 1.26566
Epoch 1495/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4260 - val_loss: 1.2788 - val_accuracy: 0.4247

Epoch 01495: val_loss did not improve from 1.26566
Epoch 1496/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4302 - val_loss: 1.2727 - val_accuracy: 0.4319

Epoch 01496: val_loss did not improve from 1.26566
Epoch 1497/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4274 - val_loss: 1.2766 - val_accuracy: 0.4239

Epoch 01497: val_loss did not improve from 1.26566
Epoch 1498/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4254 - val_loss: 1.2695 - val_accuracy: 0.4191

Epoch 01498: val_loss did not improve from 1.26566
Epoch 1499/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4307 - val_loss: 1.2692 - val_accuracy: 0.4183

Epoch 01499: val_loss did not improve from 1.26566
Epoch 1500/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4298 - val_loss: 1.2696 - val_accuracy: 0.4247

Epoch 01500: val_loss did not improve from 1.26566
Epoch 1501/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4276 - val_loss: 1.2704 - val_accuracy: 0.4175

Epoch 01501: val_loss did not improve from 1.26566
Epoch 1502/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4273 - val_loss: 1.2677 - val_accuracy: 0.4263

Epoch 01502: val_loss did not improve from 1.26566
Epoch 1503/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4313 - val_loss: 1.2715 - val_accuracy: 0.4287

Epoch 01503: val_loss did not improve from 1.26566
Epoch 1504/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4227 - val_loss: 1.2839 - val_accuracy: 0.4143

Epoch 01504: val_loss did not improve from 1.26566
Epoch 1505/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4269 - val_loss: 1.2673 - val_accuracy: 0.4271

Epoch 01505: val_loss did not improve from 1.26566
Epoch 1506/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4277 - val_loss: 1.2671 - val_accuracy: 0.4311

Epoch 01506: val_loss did not improve from 1.26566
Epoch 1507/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4287 - val_loss: 1.2679 - val_accuracy: 0.4255

Epoch 01507: val_loss did not improve from 1.26566
Epoch 1508/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4274 - val_loss: 1.2693 - val_accuracy: 0.4335

Epoch 01508: val_loss did not improve from 1.26566
Epoch 1509/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4283 - val_loss: 1.2720 - val_accuracy: 0.4239

Epoch 01509: val_loss did not improve from 1.26566
Epoch 1510/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4314 - val_loss: 1.2703 - val_accuracy: 0.4247

Epoch 01510: val_loss did not improve from 1.26566
Epoch 1511/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4284 - val_loss: 1.2684 - val_accuracy: 0.4255

Epoch 01511: val_loss did not improve from 1.26566
Epoch 1512/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4268 - val_loss: 1.2665 - val_accuracy: 0.4255

Epoch 01512: val_loss did not improve from 1.26566
Epoch 1513/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4275 - val_loss: 1.2730 - val_accuracy: 0.4207

Epoch 01513: val_loss did not improve from 1.26566
Epoch 1514/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4285 - val_loss: 1.2708 - val_accuracy: 0.4263

Epoch 01514: val_loss did not improve from 1.26566
Epoch 1515/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4296 - val_loss: 1.2716 - val_accuracy: 0.4183

Epoch 01515: val_loss did not improve from 1.26566
Epoch 1516/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4316 - val_loss: 1.2699 - val_accuracy: 0.4223

Epoch 01516: val_loss did not improve from 1.26566
Epoch 1517/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4246 - val_loss: 1.2696 - val_accuracy: 0.4135

Epoch 01517: val_loss did not improve from 1.26566
Epoch 1518/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4297 - val_loss: 1.2691 - val_accuracy: 0.4183

Epoch 01518: val_loss did not improve from 1.26566
Epoch 1519/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4292 - val_loss: 1.2700 - val_accuracy: 0.4143

Epoch 01519: val_loss did not improve from 1.26566
Epoch 1520/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4286 - val_loss: 1.2721 - val_accuracy: 0.4183

Epoch 01520: val_loss did not improve from 1.26566
Epoch 1521/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4289 - val_loss: 1.2719 - val_accuracy: 0.4247

Epoch 01521: val_loss did not improve from 1.26566
Epoch 1522/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4296 - val_loss: 1.2684 - val_accuracy: 0.4231

Epoch 01522: val_loss did not improve from 1.26566
Epoch 1523/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4314 - val_loss: 1.2682 - val_accuracy: 0.4335

Epoch 01523: val_loss did not improve from 1.26566
Epoch 1524/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4278 - val_loss: 1.2720 - val_accuracy: 0.4215

Epoch 01524: val_loss did not improve from 1.26566
Epoch 1525/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4325 - val_loss: 1.2721 - val_accuracy: 0.4295

Epoch 01525: val_loss did not improve from 1.26566
Epoch 1526/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4284 - val_loss: 1.2769 - val_accuracy: 0.4183

Epoch 01526: val_loss did not improve from 1.26566
Epoch 1527/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4253 - val_loss: 1.2699 - val_accuracy: 0.4279

Epoch 01527: val_loss did not improve from 1.26566
Epoch 1528/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4317 - val_loss: 1.2684 - val_accuracy: 0.4335

Epoch 01528: val_loss did not improve from 1.26566
Epoch 1529/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4302 - val_loss: 1.2679 - val_accuracy: 0.4183

Epoch 01529: val_loss did not improve from 1.26566
Epoch 1530/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4258 - val_loss: 1.2684 - val_accuracy: 0.4231

Epoch 01530: val_loss did not improve from 1.26566
Epoch 1531/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4281 - val_loss: 1.2695 - val_accuracy: 0.4287

Epoch 01531: val_loss did not improve from 1.26566
Epoch 1532/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4310 - val_loss: 1.2676 - val_accuracy: 0.4247

Epoch 01532: val_loss did not improve from 1.26566
Epoch 1533/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4290 - val_loss: 1.2698 - val_accuracy: 0.4159

Epoch 01533: val_loss did not improve from 1.26566
Epoch 1534/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4276 - val_loss: 1.2696 - val_accuracy: 0.4303

Epoch 01534: val_loss did not improve from 1.26566
Epoch 1535/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4314 - val_loss: 1.2680 - val_accuracy: 0.4247

Epoch 01535: val_loss did not improve from 1.26566
Epoch 1536/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4248 - val_loss: 1.2757 - val_accuracy: 0.4183

Epoch 01536: val_loss did not improve from 1.26566
Epoch 1537/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4277 - val_loss: 1.2702 - val_accuracy: 0.4263

Epoch 01537: val_loss did not improve from 1.26566
Epoch 1538/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4261 - val_loss: 1.2705 - val_accuracy: 0.4271

Epoch 01538: val_loss did not improve from 1.26566
Epoch 1539/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4283 - val_loss: 1.2659 - val_accuracy: 0.4239

Epoch 01539: val_loss did not improve from 1.26566
Epoch 1540/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4258 - val_loss: 1.2787 - val_accuracy: 0.4231

Epoch 01540: val_loss did not improve from 1.26566
Epoch 1541/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4264 - val_loss: 1.2672 - val_accuracy: 0.4239

Epoch 01541: val_loss did not improve from 1.26566
Epoch 1542/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4275 - val_loss: 1.2727 - val_accuracy: 0.4183

Epoch 01542: val_loss did not improve from 1.26566
Epoch 1543/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4242 - val_loss: 1.2719 - val_accuracy: 0.4247

Epoch 01543: val_loss did not improve from 1.26566
Epoch 1544/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4313 - val_loss: 1.2693 - val_accuracy: 0.4311

Epoch 01544: val_loss did not improve from 1.26566
Epoch 1545/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4287 - val_loss: 1.2712 - val_accuracy: 0.4215

Epoch 01545: val_loss did not improve from 1.26566
Epoch 1546/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4298 - val_loss: 1.2661 - val_accuracy: 0.4231

Epoch 01546: val_loss did not improve from 1.26566
Epoch 1547/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4319 - val_loss: 1.2685 - val_accuracy: 0.4191

Epoch 01547: val_loss did not improve from 1.26566
Epoch 1548/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4289 - val_loss: 1.2662 - val_accuracy: 0.4247

Epoch 01548: val_loss did not improve from 1.26566
Epoch 1549/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4320 - val_loss: 1.2676 - val_accuracy: 0.4191

Epoch 01549: val_loss did not improve from 1.26566
Epoch 1550/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4285 - val_loss: 1.2678 - val_accuracy: 0.4414

Epoch 01550: val_loss did not improve from 1.26566
Epoch 1551/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4283 - val_loss: 1.2696 - val_accuracy: 0.4247

Epoch 01551: val_loss did not improve from 1.26566
Epoch 1552/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4285 - val_loss: 1.2728 - val_accuracy: 0.4295

Epoch 01552: val_loss did not improve from 1.26566
Epoch 1553/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4248 - val_loss: 1.2726 - val_accuracy: 0.4255

Epoch 01553: val_loss did not improve from 1.26566
Epoch 1554/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4274 - val_loss: 1.2714 - val_accuracy: 0.4207

Epoch 01554: val_loss did not improve from 1.26566
Epoch 1555/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4282 - val_loss: 1.2698 - val_accuracy: 0.4271

Epoch 01555: val_loss did not improve from 1.26566
Epoch 1556/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4236 - val_loss: 1.2772 - val_accuracy: 0.4247

Epoch 01556: val_loss did not improve from 1.26566
Epoch 1557/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4251 - val_loss: 1.2648 - val_accuracy: 0.4319

Epoch 01557: val_loss improved from 1.26566 to 1.26480, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1558/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4272 - val_loss: 1.2696 - val_accuracy: 0.4247

Epoch 01558: val_loss did not improve from 1.26480
Epoch 1559/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4258 - val_loss: 1.2697 - val_accuracy: 0.4199

Epoch 01559: val_loss did not improve from 1.26480
Epoch 1560/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4291 - val_loss: 1.2695 - val_accuracy: 0.4167

Epoch 01560: val_loss did not improve from 1.26480
Epoch 1561/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4298 - val_loss: 1.2660 - val_accuracy: 0.4295

Epoch 01561: val_loss did not improve from 1.26480
Epoch 1562/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4301 - val_loss: 1.2700 - val_accuracy: 0.4271

Epoch 01562: val_loss did not improve from 1.26480
Epoch 1563/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4293 - val_loss: 1.2683 - val_accuracy: 0.4239

Epoch 01563: val_loss did not improve from 1.26480
Epoch 1564/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4283 - val_loss: 1.2709 - val_accuracy: 0.4215

Epoch 01564: val_loss did not improve from 1.26480
Epoch 1565/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4283 - val_loss: 1.2665 - val_accuracy: 0.4271

Epoch 01565: val_loss did not improve from 1.26480
Epoch 1566/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4321 - val_loss: 1.2707 - val_accuracy: 0.4295

Epoch 01566: val_loss did not improve from 1.26480
Epoch 1567/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4309 - val_loss: 1.2676 - val_accuracy: 0.4311

Epoch 01567: val_loss did not improve from 1.26480
Epoch 1568/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4269 - val_loss: 1.2689 - val_accuracy: 0.4199

Epoch 01568: val_loss did not improve from 1.26480
Epoch 1569/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4260 - val_loss: 1.2784 - val_accuracy: 0.4183

Epoch 01569: val_loss did not improve from 1.26480
Epoch 1570/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4284 - val_loss: 1.2674 - val_accuracy: 0.4255

Epoch 01570: val_loss did not improve from 1.26480
Epoch 1571/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4306 - val_loss: 1.2714 - val_accuracy: 0.4335

Epoch 01571: val_loss did not improve from 1.26480
Epoch 1572/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4316 - val_loss: 1.2694 - val_accuracy: 0.4263

Epoch 01572: val_loss did not improve from 1.26480
Epoch 1573/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4275 - val_loss: 1.2693 - val_accuracy: 0.4295

Epoch 01573: val_loss did not improve from 1.26480
Epoch 1574/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4287 - val_loss: 1.2721 - val_accuracy: 0.4263

Epoch 01574: val_loss did not improve from 1.26480
Epoch 1575/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4288 - val_loss: 1.2712 - val_accuracy: 0.4263

Epoch 01575: val_loss did not improve from 1.26480
Epoch 1576/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4279 - val_loss: 1.2713 - val_accuracy: 0.4239

Epoch 01576: val_loss did not improve from 1.26480
Epoch 1577/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4234 - val_loss: 1.2733 - val_accuracy: 0.4239

Epoch 01577: val_loss did not improve from 1.26480
Epoch 1578/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4285 - val_loss: 1.2692 - val_accuracy: 0.4287

Epoch 01578: val_loss did not improve from 1.26480
Epoch 1579/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4270 - val_loss: 1.2716 - val_accuracy: 0.4247

Epoch 01579: val_loss did not improve from 1.26480
Epoch 1580/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4295 - val_loss: 1.2735 - val_accuracy: 0.4223

Epoch 01580: val_loss did not improve from 1.26480
Epoch 1581/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4274 - val_loss: 1.2690 - val_accuracy: 0.4247

Epoch 01581: val_loss did not improve from 1.26480
Epoch 1582/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4278 - val_loss: 1.2702 - val_accuracy: 0.4247

Epoch 01582: val_loss did not improve from 1.26480
Epoch 1583/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4271 - val_loss: 1.2742 - val_accuracy: 0.4263

Epoch 01583: val_loss did not improve from 1.26480
Epoch 1584/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4260 - val_loss: 1.2684 - val_accuracy: 0.4311

Epoch 01584: val_loss did not improve from 1.26480
Epoch 1585/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4287 - val_loss: 1.2666 - val_accuracy: 0.4367

Epoch 01585: val_loss did not improve from 1.26480
Epoch 1586/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4292 - val_loss: 1.2657 - val_accuracy: 0.4167

Epoch 01586: val_loss did not improve from 1.26480
Epoch 1587/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4314 - val_loss: 1.2686 - val_accuracy: 0.4255

Epoch 01587: val_loss did not improve from 1.26480
Epoch 1588/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4308 - val_loss: 1.2784 - val_accuracy: 0.4215

Epoch 01588: val_loss did not improve from 1.26480
Epoch 1589/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4245 - val_loss: 1.2673 - val_accuracy: 0.4279

Epoch 01589: val_loss did not improve from 1.26480
Epoch 1590/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4278 - val_loss: 1.2760 - val_accuracy: 0.4279

Epoch 01590: val_loss did not improve from 1.26480
Epoch 1591/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4287 - val_loss: 1.2688 - val_accuracy: 0.4255

Epoch 01591: val_loss did not improve from 1.26480
Epoch 1592/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4251 - val_loss: 1.2720 - val_accuracy: 0.4215

Epoch 01592: val_loss did not improve from 1.26480
Epoch 1593/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4282 - val_loss: 1.2768 - val_accuracy: 0.4151

Epoch 01593: val_loss did not improve from 1.26480
Epoch 1594/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4234 - val_loss: 1.2723 - val_accuracy: 0.4319

Epoch 01594: val_loss did not improve from 1.26480
Epoch 1595/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4277 - val_loss: 1.2721 - val_accuracy: 0.4215

Epoch 01595: val_loss did not improve from 1.26480
Epoch 1596/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4299 - val_loss: 1.2712 - val_accuracy: 0.4287

Epoch 01596: val_loss did not improve from 1.26480
Epoch 1597/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4290 - val_loss: 1.2725 - val_accuracy: 0.4167

Epoch 01597: val_loss did not improve from 1.26480
Epoch 1598/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4269 - val_loss: 1.2704 - val_accuracy: 0.4159

Epoch 01598: val_loss did not improve from 1.26480
Epoch 1599/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4238 - val_loss: 1.2739 - val_accuracy: 0.4239

Epoch 01599: val_loss did not improve from 1.26480
Epoch 1600/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4293 - val_loss: 1.2698 - val_accuracy: 0.4263

Epoch 01600: val_loss did not improve from 1.26480
Epoch 1601/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4329 - val_loss: 1.2798 - val_accuracy: 0.4247

Epoch 01601: val_loss did not improve from 1.26480
Epoch 1602/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4233 - val_loss: 1.2664 - val_accuracy: 0.4287

Epoch 01602: val_loss did not improve from 1.26480
Epoch 1603/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4276 - val_loss: 1.2693 - val_accuracy: 0.4231

Epoch 01603: val_loss did not improve from 1.26480
Epoch 1604/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4274 - val_loss: 1.2694 - val_accuracy: 0.4231

Epoch 01604: val_loss did not improve from 1.26480
Epoch 1605/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4287 - val_loss: 1.2686 - val_accuracy: 0.4287

Epoch 01605: val_loss did not improve from 1.26480
Epoch 1606/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4294 - val_loss: 1.2682 - val_accuracy: 0.4223

Epoch 01606: val_loss did not improve from 1.26480
Epoch 1607/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4291 - val_loss: 1.2706 - val_accuracy: 0.4223

Epoch 01607: val_loss did not improve from 1.26480
Epoch 1608/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4288 - val_loss: 1.2703 - val_accuracy: 0.4199

Epoch 01608: val_loss did not improve from 1.26480
Epoch 1609/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4335 - val_loss: 1.2722 - val_accuracy: 0.4143

Epoch 01609: val_loss did not improve from 1.26480
Epoch 1610/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4314 - val_loss: 1.2697 - val_accuracy: 0.4367

Epoch 01610: val_loss did not improve from 1.26480
Epoch 1611/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4316 - val_loss: 1.2674 - val_accuracy: 0.4255

Epoch 01611: val_loss did not improve from 1.26480
Epoch 1612/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4336 - val_loss: 1.2729 - val_accuracy: 0.4207

Epoch 01612: val_loss did not improve from 1.26480
Epoch 1613/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4316 - val_loss: 1.2676 - val_accuracy: 0.4327

Epoch 01613: val_loss did not improve from 1.26480
Epoch 1614/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4278 - val_loss: 1.2665 - val_accuracy: 0.4327

Epoch 01614: val_loss did not improve from 1.26480
Epoch 1615/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4301 - val_loss: 1.2677 - val_accuracy: 0.4335

Epoch 01615: val_loss did not improve from 1.26480
Epoch 1616/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4287 - val_loss: 1.2691 - val_accuracy: 0.4335

Epoch 01616: val_loss did not improve from 1.26480
Epoch 1617/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4329 - val_loss: 1.2689 - val_accuracy: 0.4343

Epoch 01617: val_loss did not improve from 1.26480
Epoch 1618/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4291 - val_loss: 1.2750 - val_accuracy: 0.4223

Epoch 01618: val_loss did not improve from 1.26480
Epoch 1619/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4287 - val_loss: 1.2733 - val_accuracy: 0.4199

Epoch 01619: val_loss did not improve from 1.26480
Epoch 1620/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4281 - val_loss: 1.2733 - val_accuracy: 0.4159

Epoch 01620: val_loss did not improve from 1.26480
Epoch 1621/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4272 - val_loss: 1.2688 - val_accuracy: 0.4207

Epoch 01621: val_loss did not improve from 1.26480
Epoch 1622/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4289 - val_loss: 1.2710 - val_accuracy: 0.4271

Epoch 01622: val_loss did not improve from 1.26480
Epoch 1623/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4300 - val_loss: 1.2674 - val_accuracy: 0.4263

Epoch 01623: val_loss did not improve from 1.26480
Epoch 1624/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4258 - val_loss: 1.2677 - val_accuracy: 0.4223

Epoch 01624: val_loss did not improve from 1.26480
Epoch 1625/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4285 - val_loss: 1.2705 - val_accuracy: 0.4335

Epoch 01625: val_loss did not improve from 1.26480
Epoch 1626/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4303 - val_loss: 1.2645 - val_accuracy: 0.4295

Epoch 01626: val_loss improved from 1.26480 to 1.26452, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1627/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4241 - val_loss: 1.2657 - val_accuracy: 0.4303

Epoch 01627: val_loss did not improve from 1.26452
Epoch 1628/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4287 - val_loss: 1.2689 - val_accuracy: 0.4199

Epoch 01628: val_loss did not improve from 1.26452
Epoch 1629/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4274 - val_loss: 1.2718 - val_accuracy: 0.4247

Epoch 01629: val_loss did not improve from 1.26452
Epoch 1630/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4272 - val_loss: 1.2750 - val_accuracy: 0.4175

Epoch 01630: val_loss did not improve from 1.26452
Epoch 1631/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4277 - val_loss: 1.2752 - val_accuracy: 0.4104

Epoch 01631: val_loss did not improve from 1.26452
Epoch 1632/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4239 - val_loss: 1.2778 - val_accuracy: 0.4064

Epoch 01632: val_loss did not improve from 1.26452
Epoch 1633/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4280 - val_loss: 1.2709 - val_accuracy: 0.4239

Epoch 01633: val_loss did not improve from 1.26452
Epoch 1634/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4266 - val_loss: 1.2789 - val_accuracy: 0.4303

Epoch 01634: val_loss did not improve from 1.26452
Epoch 1635/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4241 - val_loss: 1.2705 - val_accuracy: 0.4215

Epoch 01635: val_loss did not improve from 1.26452
Epoch 1636/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4296 - val_loss: 1.2682 - val_accuracy: 0.4263

Epoch 01636: val_loss did not improve from 1.26452
Epoch 1637/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4256 - val_loss: 1.2684 - val_accuracy: 0.4327

Epoch 01637: val_loss did not improve from 1.26452
Epoch 1638/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4270 - val_loss: 1.2719 - val_accuracy: 0.4239

Epoch 01638: val_loss did not improve from 1.26452
Epoch 1639/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4309 - val_loss: 1.2703 - val_accuracy: 0.4207

Epoch 01639: val_loss did not improve from 1.26452
Epoch 1640/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4314 - val_loss: 1.2708 - val_accuracy: 0.4223

Epoch 01640: val_loss did not improve from 1.26452
Epoch 1641/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4287 - val_loss: 1.2708 - val_accuracy: 0.4351

Epoch 01641: val_loss did not improve from 1.26452
Epoch 1642/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4303 - val_loss: 1.2669 - val_accuracy: 0.4255

Epoch 01642: val_loss did not improve from 1.26452
Epoch 1643/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4267 - val_loss: 1.2690 - val_accuracy: 0.4223

Epoch 01643: val_loss did not improve from 1.26452
Epoch 1644/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4308 - val_loss: 1.2724 - val_accuracy: 0.4319

Epoch 01644: val_loss did not improve from 1.26452
Epoch 1645/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4276 - val_loss: 1.2647 - val_accuracy: 0.4295

Epoch 01645: val_loss did not improve from 1.26452
Epoch 1646/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4314 - val_loss: 1.2710 - val_accuracy: 0.4231

Epoch 01646: val_loss did not improve from 1.26452
Epoch 1647/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4260 - val_loss: 1.2732 - val_accuracy: 0.4271

Epoch 01647: val_loss did not improve from 1.26452
Epoch 1648/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4270 - val_loss: 1.2641 - val_accuracy: 0.4287

Epoch 01648: val_loss improved from 1.26452 to 1.26414, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1649/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4237 - val_loss: 1.2672 - val_accuracy: 0.4367

Epoch 01649: val_loss did not improve from 1.26414
Epoch 1650/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4227 - val_loss: 1.2703 - val_accuracy: 0.4263

Epoch 01650: val_loss did not improve from 1.26414
Epoch 1651/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4315 - val_loss: 1.2685 - val_accuracy: 0.4223

Epoch 01651: val_loss did not improve from 1.26414
Epoch 1652/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4294 - val_loss: 1.2666 - val_accuracy: 0.4255

Epoch 01652: val_loss did not improve from 1.26414
Epoch 1653/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4291 - val_loss: 1.2674 - val_accuracy: 0.4319

Epoch 01653: val_loss did not improve from 1.26414
Epoch 1654/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4275 - val_loss: 1.2673 - val_accuracy: 0.4223

Epoch 01654: val_loss did not improve from 1.26414
Epoch 1655/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4274 - val_loss: 1.2673 - val_accuracy: 0.4255

Epoch 01655: val_loss did not improve from 1.26414
Epoch 1656/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4301 - val_loss: 1.2671 - val_accuracy: 0.4191

Epoch 01656: val_loss did not improve from 1.26414
Epoch 1657/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4289 - val_loss: 1.2661 - val_accuracy: 0.4311

Epoch 01657: val_loss did not improve from 1.26414
Epoch 1658/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4274 - val_loss: 1.2711 - val_accuracy: 0.4287

Epoch 01658: val_loss did not improve from 1.26414
Epoch 1659/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4254 - val_loss: 1.2693 - val_accuracy: 0.4223

Epoch 01659: val_loss did not improve from 1.26414
Epoch 1660/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4264 - val_loss: 1.2682 - val_accuracy: 0.4247

Epoch 01660: val_loss did not improve from 1.26414
Epoch 1661/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4289 - val_loss: 1.2650 - val_accuracy: 0.4303

Epoch 01661: val_loss did not improve from 1.26414
Epoch 1662/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4256 - val_loss: 1.2849 - val_accuracy: 0.4104

Epoch 01662: val_loss did not improve from 1.26414
Epoch 1663/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4247 - val_loss: 1.2671 - val_accuracy: 0.4239

Epoch 01663: val_loss did not improve from 1.26414
Epoch 1664/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4317 - val_loss: 1.2677 - val_accuracy: 0.4303

Epoch 01664: val_loss did not improve from 1.26414
Epoch 1665/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4282 - val_loss: 1.2701 - val_accuracy: 0.4199

Epoch 01665: val_loss did not improve from 1.26414
Epoch 1666/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4297 - val_loss: 1.2664 - val_accuracy: 0.4343

Epoch 01666: val_loss did not improve from 1.26414
Epoch 1667/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4291 - val_loss: 1.2693 - val_accuracy: 0.4247

Epoch 01667: val_loss did not improve from 1.26414
Epoch 1668/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4273 - val_loss: 1.2754 - val_accuracy: 0.4143

Epoch 01668: val_loss did not improve from 1.26414
Epoch 1669/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4264 - val_loss: 1.2645 - val_accuracy: 0.4279

Epoch 01669: val_loss did not improve from 1.26414
Epoch 1670/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4318 - val_loss: 1.2674 - val_accuracy: 0.4279

Epoch 01670: val_loss did not improve from 1.26414
Epoch 1671/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4302 - val_loss: 1.2671 - val_accuracy: 0.4223

Epoch 01671: val_loss did not improve from 1.26414
Epoch 1672/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4296 - val_loss: 1.2671 - val_accuracy: 0.4319

Epoch 01672: val_loss did not improve from 1.26414
Epoch 1673/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4284 - val_loss: 1.2667 - val_accuracy: 0.4263

Epoch 01673: val_loss did not improve from 1.26414
Epoch 1674/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4303 - val_loss: 1.2705 - val_accuracy: 0.4295

Epoch 01674: val_loss did not improve from 1.26414
Epoch 1675/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4311 - val_loss: 1.2698 - val_accuracy: 0.4239

Epoch 01675: val_loss did not improve from 1.26414
Epoch 1676/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4305 - val_loss: 1.2714 - val_accuracy: 0.4175

Epoch 01676: val_loss did not improve from 1.26414
Epoch 1677/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4274 - val_loss: 1.2669 - val_accuracy: 0.4287

Epoch 01677: val_loss did not improve from 1.26414
Epoch 1678/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4306 - val_loss: 1.2682 - val_accuracy: 0.4287

Epoch 01678: val_loss did not improve from 1.26414
Epoch 1679/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4282 - val_loss: 1.2716 - val_accuracy: 0.4231

Epoch 01679: val_loss did not improve from 1.26414
Epoch 1680/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4312 - val_loss: 1.2741 - val_accuracy: 0.4159

Epoch 01680: val_loss did not improve from 1.26414
Epoch 1681/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4256 - val_loss: 1.2761 - val_accuracy: 0.4279

Epoch 01681: val_loss did not improve from 1.26414
Epoch 1682/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4305 - val_loss: 1.2722 - val_accuracy: 0.4183

Epoch 01682: val_loss did not improve from 1.26414
Epoch 1683/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4328 - val_loss: 1.2702 - val_accuracy: 0.4255

Epoch 01683: val_loss did not improve from 1.26414
Epoch 1684/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4254 - val_loss: 1.2709 - val_accuracy: 0.4183

Epoch 01684: val_loss did not improve from 1.26414
Epoch 1685/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4229 - val_loss: 1.2673 - val_accuracy: 0.4303

Epoch 01685: val_loss did not improve from 1.26414
Epoch 1686/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4303 - val_loss: 1.2762 - val_accuracy: 0.4255

Epoch 01686: val_loss did not improve from 1.26414
Epoch 1687/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4228 - val_loss: 1.2732 - val_accuracy: 0.4239

Epoch 01687: val_loss did not improve from 1.26414
Epoch 1688/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4325 - val_loss: 1.2690 - val_accuracy: 0.4335

Epoch 01688: val_loss did not improve from 1.26414
Epoch 1689/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4324 - val_loss: 1.2711 - val_accuracy: 0.4327

Epoch 01689: val_loss did not improve from 1.26414
Epoch 1690/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4261 - val_loss: 1.2904 - val_accuracy: 0.4040

Epoch 01690: val_loss did not improve from 1.26414
Epoch 1691/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4285 - val_loss: 1.2693 - val_accuracy: 0.4135

Epoch 01691: val_loss did not improve from 1.26414
Epoch 1692/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4296 - val_loss: 1.2690 - val_accuracy: 0.4263

Epoch 01692: val_loss did not improve from 1.26414
Epoch 1693/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4302 - val_loss: 1.2708 - val_accuracy: 0.4231

Epoch 01693: val_loss did not improve from 1.26414
Epoch 1694/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4299 - val_loss: 1.2687 - val_accuracy: 0.4231

Epoch 01694: val_loss did not improve from 1.26414
Epoch 1695/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4322 - val_loss: 1.2700 - val_accuracy: 0.4303

Epoch 01695: val_loss did not improve from 1.26414
Epoch 1696/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4328 - val_loss: 1.2685 - val_accuracy: 0.4255

Epoch 01696: val_loss did not improve from 1.26414
Epoch 1697/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4315 - val_loss: 1.2700 - val_accuracy: 0.4231

Epoch 01697: val_loss did not improve from 1.26414
Epoch 1698/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4285 - val_loss: 1.2693 - val_accuracy: 0.4287

Epoch 01698: val_loss did not improve from 1.26414
Epoch 1699/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4277 - val_loss: 1.2704 - val_accuracy: 0.4183

Epoch 01699: val_loss did not improve from 1.26414
Epoch 1700/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4298 - val_loss: 1.2678 - val_accuracy: 0.4199

Epoch 01700: val_loss did not improve from 1.26414
Epoch 1701/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4288 - val_loss: 1.2696 - val_accuracy: 0.4167

Epoch 01701: val_loss did not improve from 1.26414
Epoch 1702/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4329 - val_loss: 1.2718 - val_accuracy: 0.4215

Epoch 01702: val_loss did not improve from 1.26414
Epoch 1703/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4289 - val_loss: 1.2666 - val_accuracy: 0.4247

Epoch 01703: val_loss did not improve from 1.26414
Epoch 1704/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4239 - val_loss: 1.2665 - val_accuracy: 0.4287

Epoch 01704: val_loss did not improve from 1.26414
Epoch 1705/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4261 - val_loss: 1.2686 - val_accuracy: 0.4279

Epoch 01705: val_loss did not improve from 1.26414
Epoch 1706/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4308 - val_loss: 1.2706 - val_accuracy: 0.4271

Epoch 01706: val_loss did not improve from 1.26414
Epoch 1707/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4245 - val_loss: 1.2667 - val_accuracy: 0.4319

Epoch 01707: val_loss did not improve from 1.26414
Epoch 1708/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4278 - val_loss: 1.2740 - val_accuracy: 0.4231

Epoch 01708: val_loss did not improve from 1.26414
Epoch 1709/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4280 - val_loss: 1.2675 - val_accuracy: 0.4199

Epoch 01709: val_loss did not improve from 1.26414
Epoch 1710/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4309 - val_loss: 1.2706 - val_accuracy: 0.4199

Epoch 01710: val_loss did not improve from 1.26414
Epoch 1711/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4319 - val_loss: 1.2723 - val_accuracy: 0.4207

Epoch 01711: val_loss did not improve from 1.26414
Epoch 1712/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4314 - val_loss: 1.2655 - val_accuracy: 0.4191

Epoch 01712: val_loss did not improve from 1.26414
Epoch 1713/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4252 - val_loss: 1.2684 - val_accuracy: 0.4311

Epoch 01713: val_loss did not improve from 1.26414
Epoch 1714/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4292 - val_loss: 1.2665 - val_accuracy: 0.4263

Epoch 01714: val_loss did not improve from 1.26414
Epoch 1715/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4264 - val_loss: 1.2659 - val_accuracy: 0.4271

Epoch 01715: val_loss did not improve from 1.26414
Epoch 1716/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4298 - val_loss: 1.2703 - val_accuracy: 0.4191

Epoch 01716: val_loss did not improve from 1.26414
Epoch 1717/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4305 - val_loss: 1.2760 - val_accuracy: 0.4279

Epoch 01717: val_loss did not improve from 1.26414
Epoch 1718/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4271 - val_loss: 1.2661 - val_accuracy: 0.4255

Epoch 01718: val_loss did not improve from 1.26414
Epoch 1719/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4303 - val_loss: 1.2660 - val_accuracy: 0.4295

Epoch 01719: val_loss did not improve from 1.26414
Epoch 1720/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4302 - val_loss: 1.2684 - val_accuracy: 0.4303

Epoch 01720: val_loss did not improve from 1.26414
Epoch 1721/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4317 - val_loss: 1.2712 - val_accuracy: 0.4287

Epoch 01721: val_loss did not improve from 1.26414
Epoch 1722/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4297 - val_loss: 1.2673 - val_accuracy: 0.4255

Epoch 01722: val_loss did not improve from 1.26414
Epoch 1723/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4297 - val_loss: 1.2686 - val_accuracy: 0.4191

Epoch 01723: val_loss did not improve from 1.26414
Epoch 1724/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4315 - val_loss: 1.2692 - val_accuracy: 0.4279

Epoch 01724: val_loss did not improve from 1.26414
Epoch 1725/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4327 - val_loss: 1.2688 - val_accuracy: 0.4343

Epoch 01725: val_loss did not improve from 1.26414
Epoch 1726/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4264 - val_loss: 1.2677 - val_accuracy: 0.4231

Epoch 01726: val_loss did not improve from 1.26414
Epoch 1727/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4313 - val_loss: 1.2685 - val_accuracy: 0.4088

Epoch 01727: val_loss did not improve from 1.26414
Epoch 1728/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4317 - val_loss: 1.2684 - val_accuracy: 0.4303

Epoch 01728: val_loss did not improve from 1.26414
Epoch 1729/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4287 - val_loss: 1.2693 - val_accuracy: 0.4263

Epoch 01729: val_loss did not improve from 1.26414
Epoch 1730/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4286 - val_loss: 1.2702 - val_accuracy: 0.4175

Epoch 01730: val_loss did not improve from 1.26414
Epoch 1731/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4260 - val_loss: 1.2669 - val_accuracy: 0.4263

Epoch 01731: val_loss did not improve from 1.26414
Epoch 1732/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4297 - val_loss: 1.2658 - val_accuracy: 0.4271

Epoch 01732: val_loss did not improve from 1.26414
Epoch 1733/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4275 - val_loss: 1.2637 - val_accuracy: 0.4319

Epoch 01733: val_loss improved from 1.26414 to 1.26370, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1734/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4273 - val_loss: 1.2753 - val_accuracy: 0.4159

Epoch 01734: val_loss did not improve from 1.26370
Epoch 1735/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4306 - val_loss: 1.2704 - val_accuracy: 0.4183

Epoch 01735: val_loss did not improve from 1.26370
Epoch 1736/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4307 - val_loss: 1.2682 - val_accuracy: 0.4247

Epoch 01736: val_loss did not improve from 1.26370
Epoch 1737/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4292 - val_loss: 1.2724 - val_accuracy: 0.4247

Epoch 01737: val_loss did not improve from 1.26370
Epoch 1738/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4336 - val_loss: 1.2702 - val_accuracy: 0.4215

Epoch 01738: val_loss did not improve from 1.26370
Epoch 1739/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4291 - val_loss: 1.2730 - val_accuracy: 0.4223

Epoch 01739: val_loss did not improve from 1.26370
Epoch 1740/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4299 - val_loss: 1.2644 - val_accuracy: 0.4239

Epoch 01740: val_loss did not improve from 1.26370
Epoch 1741/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4286 - val_loss: 1.2709 - val_accuracy: 0.4255

Epoch 01741: val_loss did not improve from 1.26370
Epoch 1742/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4311 - val_loss: 1.2684 - val_accuracy: 0.4183

Epoch 01742: val_loss did not improve from 1.26370
Epoch 1743/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4294 - val_loss: 1.2683 - val_accuracy: 0.4239

Epoch 01743: val_loss did not improve from 1.26370
Epoch 1744/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4274 - val_loss: 1.2702 - val_accuracy: 0.4303

Epoch 01744: val_loss did not improve from 1.26370
Epoch 1745/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4306 - val_loss: 1.2706 - val_accuracy: 0.4191

Epoch 01745: val_loss did not improve from 1.26370
Epoch 1746/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4269 - val_loss: 1.2764 - val_accuracy: 0.4127

Epoch 01746: val_loss did not improve from 1.26370
Epoch 1747/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4317 - val_loss: 1.2725 - val_accuracy: 0.4191

Epoch 01747: val_loss did not improve from 1.26370
Epoch 1748/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4338 - val_loss: 1.2706 - val_accuracy: 0.4215

Epoch 01748: val_loss did not improve from 1.26370
Epoch 1749/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4320 - val_loss: 1.2722 - val_accuracy: 0.4199

Epoch 01749: val_loss did not improve from 1.26370
Epoch 1750/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4252 - val_loss: 1.2684 - val_accuracy: 0.4255

Epoch 01750: val_loss did not improve from 1.26370
Epoch 1751/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4307 - val_loss: 1.2699 - val_accuracy: 0.4287

Epoch 01751: val_loss did not improve from 1.26370
Epoch 1752/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4296 - val_loss: 1.2681 - val_accuracy: 0.4263

Epoch 01752: val_loss did not improve from 1.26370
Epoch 1753/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4322 - val_loss: 1.2665 - val_accuracy: 0.4279

Epoch 01753: val_loss did not improve from 1.26370
Epoch 1754/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4300 - val_loss: 1.2745 - val_accuracy: 0.4167

Epoch 01754: val_loss did not improve from 1.26370
Epoch 1755/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4322 - val_loss: 1.2683 - val_accuracy: 0.4239

Epoch 01755: val_loss did not improve from 1.26370
Epoch 1756/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4303 - val_loss: 1.2667 - val_accuracy: 0.4271

Epoch 01756: val_loss did not improve from 1.26370
Epoch 1757/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4277 - val_loss: 1.2685 - val_accuracy: 0.4279

Epoch 01757: val_loss did not improve from 1.26370
Epoch 1758/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4302 - val_loss: 1.2693 - val_accuracy: 0.4175

Epoch 01758: val_loss did not improve from 1.26370
Epoch 1759/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4337 - val_loss: 1.2672 - val_accuracy: 0.4319

Epoch 01759: val_loss did not improve from 1.26370
Epoch 1760/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4298 - val_loss: 1.2722 - val_accuracy: 0.4183

Epoch 01760: val_loss did not improve from 1.26370
Epoch 1761/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4322 - val_loss: 1.2661 - val_accuracy: 0.4167

Epoch 01761: val_loss did not improve from 1.26370
Epoch 1762/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4300 - val_loss: 1.2661 - val_accuracy: 0.4223

Epoch 01762: val_loss did not improve from 1.26370
Epoch 1763/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4336 - val_loss: 1.2722 - val_accuracy: 0.4167

Epoch 01763: val_loss did not improve from 1.26370
Epoch 1764/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4318 - val_loss: 1.2696 - val_accuracy: 0.4215

Epoch 01764: val_loss did not improve from 1.26370
Epoch 1765/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4286 - val_loss: 1.2678 - val_accuracy: 0.4135

Epoch 01765: val_loss did not improve from 1.26370
Epoch 1766/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4305 - val_loss: 1.2671 - val_accuracy: 0.4247

Epoch 01766: val_loss did not improve from 1.26370
Epoch 1767/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4293 - val_loss: 1.2721 - val_accuracy: 0.4159

Epoch 01767: val_loss did not improve from 1.26370
Epoch 1768/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4331 - val_loss: 1.2670 - val_accuracy: 0.4127

Epoch 01768: val_loss did not improve from 1.26370
Epoch 1769/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4318 - val_loss: 1.2706 - val_accuracy: 0.4151

Epoch 01769: val_loss did not improve from 1.26370
Epoch 1770/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4329 - val_loss: 1.2689 - val_accuracy: 0.4191

Epoch 01770: val_loss did not improve from 1.26370
Epoch 1771/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4307 - val_loss: 1.2692 - val_accuracy: 0.4263

Epoch 01771: val_loss did not improve from 1.26370
Epoch 1772/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4303 - val_loss: 1.2673 - val_accuracy: 0.4239

Epoch 01772: val_loss did not improve from 1.26370
Epoch 1773/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4314 - val_loss: 1.2657 - val_accuracy: 0.4359

Epoch 01773: val_loss did not improve from 1.26370
Epoch 1774/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4298 - val_loss: 1.2718 - val_accuracy: 0.4199

Epoch 01774: val_loss did not improve from 1.26370
Epoch 1775/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4307 - val_loss: 1.2709 - val_accuracy: 0.4135

Epoch 01775: val_loss did not improve from 1.26370
Epoch 1776/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4317 - val_loss: 1.2706 - val_accuracy: 0.4167

Epoch 01776: val_loss did not improve from 1.26370
Epoch 1777/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4270 - val_loss: 1.2727 - val_accuracy: 0.4239

Epoch 01777: val_loss did not improve from 1.26370
Epoch 1778/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4267 - val_loss: 1.2688 - val_accuracy: 0.4231

Epoch 01778: val_loss did not improve from 1.26370
Epoch 1779/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4252 - val_loss: 1.2679 - val_accuracy: 0.4207

Epoch 01779: val_loss did not improve from 1.26370
Epoch 1780/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4279 - val_loss: 1.2664 - val_accuracy: 0.4279

Epoch 01780: val_loss did not improve from 1.26370
Epoch 1781/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4286 - val_loss: 1.2754 - val_accuracy: 0.4247

Epoch 01781: val_loss did not improve from 1.26370
Epoch 1782/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4290 - val_loss: 1.2689 - val_accuracy: 0.4167

Epoch 01782: val_loss did not improve from 1.26370
Epoch 1783/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4291 - val_loss: 1.2697 - val_accuracy: 0.4231

Epoch 01783: val_loss did not improve from 1.26370
Epoch 1784/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4292 - val_loss: 1.2650 - val_accuracy: 0.4255

Epoch 01784: val_loss did not improve from 1.26370
Epoch 1785/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4309 - val_loss: 1.2692 - val_accuracy: 0.4295

Epoch 01785: val_loss did not improve from 1.26370
Epoch 1786/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4291 - val_loss: 1.2649 - val_accuracy: 0.4231

Epoch 01786: val_loss did not improve from 1.26370
Epoch 1787/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4325 - val_loss: 1.2680 - val_accuracy: 0.4199

Epoch 01787: val_loss did not improve from 1.26370
Epoch 1788/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4348 - val_loss: 1.2677 - val_accuracy: 0.4175

Epoch 01788: val_loss did not improve from 1.26370
Epoch 1789/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4332 - val_loss: 1.2717 - val_accuracy: 0.4263

Epoch 01789: val_loss did not improve from 1.26370
Epoch 1790/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4325 - val_loss: 1.2752 - val_accuracy: 0.4183

Epoch 01790: val_loss did not improve from 1.26370
Epoch 1791/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4319 - val_loss: 1.2701 - val_accuracy: 0.4151

Epoch 01791: val_loss did not improve from 1.26370
Epoch 1792/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4284 - val_loss: 1.2678 - val_accuracy: 0.4127

Epoch 01792: val_loss did not improve from 1.26370
Epoch 1793/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4263 - val_loss: 1.2751 - val_accuracy: 0.4151

Epoch 01793: val_loss did not improve from 1.26370
Epoch 1794/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4288 - val_loss: 1.2657 - val_accuracy: 0.4175

Epoch 01794: val_loss did not improve from 1.26370
Epoch 1795/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4326 - val_loss: 1.2708 - val_accuracy: 0.4271

Epoch 01795: val_loss did not improve from 1.26370
Epoch 1796/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4328 - val_loss: 1.2662 - val_accuracy: 0.4295

Epoch 01796: val_loss did not improve from 1.26370
Epoch 1797/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4301 - val_loss: 1.2662 - val_accuracy: 0.4295

Epoch 01797: val_loss did not improve from 1.26370
Epoch 1798/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4304 - val_loss: 1.2776 - val_accuracy: 0.4167

Epoch 01798: val_loss did not improve from 1.26370
Epoch 1799/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4273 - val_loss: 1.2660 - val_accuracy: 0.4311

Epoch 01799: val_loss did not improve from 1.26370
Epoch 1800/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4298 - val_loss: 1.2648 - val_accuracy: 0.4255

Epoch 01800: val_loss did not improve from 1.26370
Epoch 1801/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4260 - val_loss: 1.2683 - val_accuracy: 0.4255

Epoch 01801: val_loss did not improve from 1.26370
Epoch 1802/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4265 - val_loss: 1.2663 - val_accuracy: 0.4223

Epoch 01802: val_loss did not improve from 1.26370
Epoch 1803/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4321 - val_loss: 1.2754 - val_accuracy: 0.4223

Epoch 01803: val_loss did not improve from 1.26370
Epoch 1804/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4296 - val_loss: 1.2652 - val_accuracy: 0.4303

Epoch 01804: val_loss did not improve from 1.26370
Epoch 1805/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4333 - val_loss: 1.2712 - val_accuracy: 0.4271

Epoch 01805: val_loss did not improve from 1.26370
Epoch 1806/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4286 - val_loss: 1.2702 - val_accuracy: 0.4088

Epoch 01806: val_loss did not improve from 1.26370
Epoch 1807/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4286 - val_loss: 1.2643 - val_accuracy: 0.4287

Epoch 01807: val_loss did not improve from 1.26370
Epoch 1808/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4278 - val_loss: 1.2650 - val_accuracy: 0.4367

Epoch 01808: val_loss did not improve from 1.26370
Epoch 1809/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4311 - val_loss: 1.2667 - val_accuracy: 0.4311

Epoch 01809: val_loss did not improve from 1.26370
Epoch 1810/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4337 - val_loss: 1.2625 - val_accuracy: 0.4335

Epoch 01810: val_loss improved from 1.26370 to 1.26247, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1811/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4294 - val_loss: 1.2650 - val_accuracy: 0.4311

Epoch 01811: val_loss did not improve from 1.26247
Epoch 1812/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4317 - val_loss: 1.2653 - val_accuracy: 0.4151

Epoch 01812: val_loss did not improve from 1.26247
Epoch 1813/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4309 - val_loss: 1.2677 - val_accuracy: 0.4303

Epoch 01813: val_loss did not improve from 1.26247
Epoch 1814/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4320 - val_loss: 1.2655 - val_accuracy: 0.4263

Epoch 01814: val_loss did not improve from 1.26247
Epoch 1815/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4302 - val_loss: 1.2675 - val_accuracy: 0.4167

Epoch 01815: val_loss did not improve from 1.26247
Epoch 1816/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4258 - val_loss: 1.2648 - val_accuracy: 0.4327

Epoch 01816: val_loss did not improve from 1.26247
Epoch 1817/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4284 - val_loss: 1.2704 - val_accuracy: 0.4239

Epoch 01817: val_loss did not improve from 1.26247
Epoch 1818/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4317 - val_loss: 1.2714 - val_accuracy: 0.4191

Epoch 01818: val_loss did not improve from 1.26247
Epoch 1819/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4326 - val_loss: 1.2650 - val_accuracy: 0.4343

Epoch 01819: val_loss did not improve from 1.26247
Epoch 1820/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4268 - val_loss: 1.2646 - val_accuracy: 0.4263

Epoch 01820: val_loss did not improve from 1.26247
Epoch 1821/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4325 - val_loss: 1.2670 - val_accuracy: 0.4279

Epoch 01821: val_loss did not improve from 1.26247
Epoch 1822/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4304 - val_loss: 1.2701 - val_accuracy: 0.4263

Epoch 01822: val_loss did not improve from 1.26247
Epoch 1823/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4306 - val_loss: 1.2669 - val_accuracy: 0.4231

Epoch 01823: val_loss did not improve from 1.26247
Epoch 1824/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4307 - val_loss: 1.2699 - val_accuracy: 0.4255

Epoch 01824: val_loss did not improve from 1.26247
Epoch 1825/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4314 - val_loss: 1.2661 - val_accuracy: 0.4255

Epoch 01825: val_loss did not improve from 1.26247
Epoch 1826/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4324 - val_loss: 1.2683 - val_accuracy: 0.4263

Epoch 01826: val_loss did not improve from 1.26247
Epoch 1827/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4295 - val_loss: 1.2670 - val_accuracy: 0.4215

Epoch 01827: val_loss did not improve from 1.26247
Epoch 1828/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4321 - val_loss: 1.2700 - val_accuracy: 0.4231

Epoch 01828: val_loss did not improve from 1.26247
Epoch 1829/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4325 - val_loss: 1.2631 - val_accuracy: 0.4279

Epoch 01829: val_loss did not improve from 1.26247
Epoch 1830/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4296 - val_loss: 1.2667 - val_accuracy: 0.4295

Epoch 01830: val_loss did not improve from 1.26247
Epoch 1831/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4314 - val_loss: 1.2688 - val_accuracy: 0.4239

Epoch 01831: val_loss did not improve from 1.26247
Epoch 1832/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4306 - val_loss: 1.2682 - val_accuracy: 0.4127

Epoch 01832: val_loss did not improve from 1.26247
Epoch 1833/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4295 - val_loss: 1.2684 - val_accuracy: 0.4287

Epoch 01833: val_loss did not improve from 1.26247
Epoch 1834/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4283 - val_loss: 1.2653 - val_accuracy: 0.4271

Epoch 01834: val_loss did not improve from 1.26247
Epoch 1835/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4272 - val_loss: 1.2646 - val_accuracy: 0.4462

Epoch 01835: val_loss did not improve from 1.26247
Epoch 1836/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4296 - val_loss: 1.2641 - val_accuracy: 0.4303

Epoch 01836: val_loss did not improve from 1.26247
Epoch 1837/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4314 - val_loss: 1.2691 - val_accuracy: 0.4287

Epoch 01837: val_loss did not improve from 1.26247
Epoch 1838/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4318 - val_loss: 1.2729 - val_accuracy: 0.4112

Epoch 01838: val_loss did not improve from 1.26247
Epoch 1839/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4278 - val_loss: 1.2657 - val_accuracy: 0.4319

Epoch 01839: val_loss did not improve from 1.26247
Epoch 1840/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4303 - val_loss: 1.2686 - val_accuracy: 0.4223

Epoch 01840: val_loss did not improve from 1.26247
Epoch 1841/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4306 - val_loss: 1.2655 - val_accuracy: 0.4287

Epoch 01841: val_loss did not improve from 1.26247
Epoch 1842/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4280 - val_loss: 1.2706 - val_accuracy: 0.4191

Epoch 01842: val_loss did not improve from 1.26247
Epoch 1843/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4271 - val_loss: 1.2695 - val_accuracy: 0.4183

Epoch 01843: val_loss did not improve from 1.26247
Epoch 1844/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4294 - val_loss: 1.2651 - val_accuracy: 0.4311

Epoch 01844: val_loss did not improve from 1.26247
Epoch 1845/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4299 - val_loss: 1.2674 - val_accuracy: 0.4390

Epoch 01845: val_loss did not improve from 1.26247
Epoch 1846/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4304 - val_loss: 1.2679 - val_accuracy: 0.4263

Epoch 01846: val_loss did not improve from 1.26247
Epoch 1847/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4334 - val_loss: 1.2669 - val_accuracy: 0.4343

Epoch 01847: val_loss did not improve from 1.26247
Epoch 1848/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4330 - val_loss: 1.2759 - val_accuracy: 0.4191

Epoch 01848: val_loss did not improve from 1.26247
Epoch 1849/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4301 - val_loss: 1.2714 - val_accuracy: 0.4151

Epoch 01849: val_loss did not improve from 1.26247
Epoch 1850/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4282 - val_loss: 1.2724 - val_accuracy: 0.4151

Epoch 01850: val_loss did not improve from 1.26247
Epoch 1851/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4314 - val_loss: 1.2707 - val_accuracy: 0.4127

Epoch 01851: val_loss did not improve from 1.26247
Epoch 1852/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4337 - val_loss: 1.2688 - val_accuracy: 0.4287

Epoch 01852: val_loss did not improve from 1.26247
Epoch 1853/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4303 - val_loss: 1.2697 - val_accuracy: 0.4287

Epoch 01853: val_loss did not improve from 1.26247
Epoch 1854/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4341 - val_loss: 1.2653 - val_accuracy: 0.4287

Epoch 01854: val_loss did not improve from 1.26247
Epoch 1855/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4346 - val_loss: 1.2687 - val_accuracy: 0.4167

Epoch 01855: val_loss did not improve from 1.26247
Epoch 1856/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4289 - val_loss: 1.2703 - val_accuracy: 0.4311

Epoch 01856: val_loss did not improve from 1.26247
Epoch 1857/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4285 - val_loss: 1.2671 - val_accuracy: 0.4199

Epoch 01857: val_loss did not improve from 1.26247
Epoch 1858/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4316 - val_loss: 1.2778 - val_accuracy: 0.4207

Epoch 01858: val_loss did not improve from 1.26247
Epoch 1859/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4314 - val_loss: 1.2677 - val_accuracy: 0.4239

Epoch 01859: val_loss did not improve from 1.26247
Epoch 1860/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4325 - val_loss: 1.2673 - val_accuracy: 0.4191

Epoch 01860: val_loss did not improve from 1.26247
Epoch 1861/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4306 - val_loss: 1.2710 - val_accuracy: 0.4295

Epoch 01861: val_loss did not improve from 1.26247
Epoch 1862/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4302 - val_loss: 1.2659 - val_accuracy: 0.4303

Epoch 01862: val_loss did not improve from 1.26247
Epoch 1863/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4300 - val_loss: 1.2664 - val_accuracy: 0.4271

Epoch 01863: val_loss did not improve from 1.26247
Epoch 1864/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4303 - val_loss: 1.2661 - val_accuracy: 0.4231

Epoch 01864: val_loss did not improve from 1.26247
Epoch 1865/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4300 - val_loss: 1.2712 - val_accuracy: 0.4247

Epoch 01865: val_loss did not improve from 1.26247
Epoch 1866/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4306 - val_loss: 1.2680 - val_accuracy: 0.4263

Epoch 01866: val_loss did not improve from 1.26247
Epoch 1867/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4335 - val_loss: 1.2669 - val_accuracy: 0.4279

Epoch 01867: val_loss did not improve from 1.26247
Epoch 1868/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4340 - val_loss: 1.2717 - val_accuracy: 0.4223

Epoch 01868: val_loss did not improve from 1.26247
Epoch 1869/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4320 - val_loss: 1.2671 - val_accuracy: 0.4279

Epoch 01869: val_loss did not improve from 1.26247
Epoch 1870/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4322 - val_loss: 1.2690 - val_accuracy: 0.4319

Epoch 01870: val_loss did not improve from 1.26247
Epoch 1871/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4288 - val_loss: 1.2647 - val_accuracy: 0.4295

Epoch 01871: val_loss did not improve from 1.26247
Epoch 1872/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4319 - val_loss: 1.2686 - val_accuracy: 0.4279

Epoch 01872: val_loss did not improve from 1.26247
Epoch 1873/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4279 - val_loss: 1.2659 - val_accuracy: 0.4223

Epoch 01873: val_loss did not improve from 1.26247
Epoch 1874/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4325 - val_loss: 1.2703 - val_accuracy: 0.4239

Epoch 01874: val_loss did not improve from 1.26247
Epoch 1875/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4293 - val_loss: 1.2647 - val_accuracy: 0.4359

Epoch 01875: val_loss did not improve from 1.26247
Epoch 1876/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4295 - val_loss: 1.2660 - val_accuracy: 0.4375

Epoch 01876: val_loss did not improve from 1.26247
Epoch 1877/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4345 - val_loss: 1.2675 - val_accuracy: 0.4255

Epoch 01877: val_loss did not improve from 1.26247
Epoch 1878/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4306 - val_loss: 1.2662 - val_accuracy: 0.4191

Epoch 01878: val_loss did not improve from 1.26247
Epoch 1879/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4304 - val_loss: 1.2680 - val_accuracy: 0.4279

Epoch 01879: val_loss did not improve from 1.26247
Epoch 1880/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4279 - val_loss: 1.2701 - val_accuracy: 0.4279

Epoch 01880: val_loss did not improve from 1.26247
Epoch 1881/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4284 - val_loss: 1.2664 - val_accuracy: 0.4215

Epoch 01881: val_loss did not improve from 1.26247
Epoch 1882/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4288 - val_loss: 1.2715 - val_accuracy: 0.4207

Epoch 01882: val_loss did not improve from 1.26247
Epoch 1883/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4328 - val_loss: 1.2713 - val_accuracy: 0.4159

Epoch 01883: val_loss did not improve from 1.26247
Epoch 1884/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4324 - val_loss: 1.2714 - val_accuracy: 0.4175

Epoch 01884: val_loss did not improve from 1.26247
Epoch 1885/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4299 - val_loss: 1.2699 - val_accuracy: 0.4303

Epoch 01885: val_loss did not improve from 1.26247
Epoch 1886/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4322 - val_loss: 1.2665 - val_accuracy: 0.4255

Epoch 01886: val_loss did not improve from 1.26247
Epoch 1887/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4312 - val_loss: 1.2661 - val_accuracy: 0.4223

Epoch 01887: val_loss did not improve from 1.26247
Epoch 1888/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4323 - val_loss: 1.2694 - val_accuracy: 0.4167

Epoch 01888: val_loss did not improve from 1.26247
Epoch 1889/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4315 - val_loss: 1.2655 - val_accuracy: 0.4223

Epoch 01889: val_loss did not improve from 1.26247
Epoch 1890/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4302 - val_loss: 1.2670 - val_accuracy: 0.4247

Epoch 01890: val_loss did not improve from 1.26247
Epoch 1891/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4291 - val_loss: 1.2644 - val_accuracy: 0.4223

Epoch 01891: val_loss did not improve from 1.26247
Epoch 1892/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4310 - val_loss: 1.2699 - val_accuracy: 0.4199

Epoch 01892: val_loss did not improve from 1.26247
Epoch 1893/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4285 - val_loss: 1.2699 - val_accuracy: 0.4247

Epoch 01893: val_loss did not improve from 1.26247
Epoch 1894/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4323 - val_loss: 1.2647 - val_accuracy: 0.4263

Epoch 01894: val_loss did not improve from 1.26247
Epoch 1895/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4289 - val_loss: 1.2642 - val_accuracy: 0.4231

Epoch 01895: val_loss did not improve from 1.26247
Epoch 1896/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4293 - val_loss: 1.2688 - val_accuracy: 0.4263

Epoch 01896: val_loss did not improve from 1.26247
Epoch 1897/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4296 - val_loss: 1.2680 - val_accuracy: 0.4199

Epoch 01897: val_loss did not improve from 1.26247
Epoch 1898/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4306 - val_loss: 1.2650 - val_accuracy: 0.4199

Epoch 01898: val_loss did not improve from 1.26247
Epoch 1899/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4311 - val_loss: 1.2670 - val_accuracy: 0.4223

Epoch 01899: val_loss did not improve from 1.26247
Epoch 1900/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4303 - val_loss: 1.2708 - val_accuracy: 0.4359

Epoch 01900: val_loss did not improve from 1.26247
Epoch 1901/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4318 - val_loss: 1.2688 - val_accuracy: 0.4207

Epoch 01901: val_loss did not improve from 1.26247
Epoch 1902/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4309 - val_loss: 1.2682 - val_accuracy: 0.4263

Epoch 01902: val_loss did not improve from 1.26247
Epoch 1903/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4310 - val_loss: 1.2690 - val_accuracy: 0.4199

Epoch 01903: val_loss did not improve from 1.26247
Epoch 1904/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4316 - val_loss: 1.2676 - val_accuracy: 0.4311

Epoch 01904: val_loss did not improve from 1.26247
Epoch 1905/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4314 - val_loss: 1.2724 - val_accuracy: 0.4239

Epoch 01905: val_loss did not improve from 1.26247
Epoch 1906/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4304 - val_loss: 1.2696 - val_accuracy: 0.4247

Epoch 01906: val_loss did not improve from 1.26247
Epoch 1907/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4304 - val_loss: 1.2691 - val_accuracy: 0.4287

Epoch 01907: val_loss did not improve from 1.26247
Epoch 1908/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4313 - val_loss: 1.2659 - val_accuracy: 0.4303

Epoch 01908: val_loss did not improve from 1.26247
Epoch 1909/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4324 - val_loss: 1.2656 - val_accuracy: 0.4287

Epoch 01909: val_loss did not improve from 1.26247
Epoch 1910/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4301 - val_loss: 1.2689 - val_accuracy: 0.4287

Epoch 01910: val_loss did not improve from 1.26247
Epoch 1911/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4318 - val_loss: 1.2638 - val_accuracy: 0.4295

Epoch 01911: val_loss did not improve from 1.26247
Epoch 1912/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4312 - val_loss: 1.2674 - val_accuracy: 0.4247

Epoch 01912: val_loss did not improve from 1.26247
Epoch 1913/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4276 - val_loss: 1.2684 - val_accuracy: 0.4223

Epoch 01913: val_loss did not improve from 1.26247
Epoch 1914/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4286 - val_loss: 1.2704 - val_accuracy: 0.4359

Epoch 01914: val_loss did not improve from 1.26247
Epoch 1915/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4306 - val_loss: 1.2663 - val_accuracy: 0.4335

Epoch 01915: val_loss did not improve from 1.26247
Epoch 1916/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4275 - val_loss: 1.2799 - val_accuracy: 0.4159

Epoch 01916: val_loss did not improve from 1.26247
Epoch 1917/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4322 - val_loss: 1.2737 - val_accuracy: 0.4191

Epoch 01917: val_loss did not improve from 1.26247
Epoch 1918/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4353 - val_loss: 1.2722 - val_accuracy: 0.4112

Epoch 01918: val_loss did not improve from 1.26247
Epoch 1919/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4351 - val_loss: 1.2675 - val_accuracy: 0.4271

Epoch 01919: val_loss did not improve from 1.26247
Epoch 1920/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4341 - val_loss: 1.2644 - val_accuracy: 0.4199

Epoch 01920: val_loss did not improve from 1.26247
Epoch 1921/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4283 - val_loss: 1.2668 - val_accuracy: 0.4279

Epoch 01921: val_loss did not improve from 1.26247
Epoch 1922/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4360 - val_loss: 1.2656 - val_accuracy: 0.4199

Epoch 01922: val_loss did not improve from 1.26247
Epoch 1923/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4305 - val_loss: 1.2680 - val_accuracy: 0.4287

Epoch 01923: val_loss did not improve from 1.26247
Epoch 1924/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4329 - val_loss: 1.2702 - val_accuracy: 0.4239

Epoch 01924: val_loss did not improve from 1.26247
Epoch 1925/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4306 - val_loss: 1.2710 - val_accuracy: 0.4215

Epoch 01925: val_loss did not improve from 1.26247
Epoch 1926/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4345 - val_loss: 1.2671 - val_accuracy: 0.4263

Epoch 01926: val_loss did not improve from 1.26247
Epoch 1927/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4310 - val_loss: 1.2666 - val_accuracy: 0.4311

Epoch 01927: val_loss did not improve from 1.26247
Epoch 1928/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4335 - val_loss: 1.2674 - val_accuracy: 0.4239

Epoch 01928: val_loss did not improve from 1.26247
Epoch 1929/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4263 - val_loss: 1.2731 - val_accuracy: 0.4167

Epoch 01929: val_loss did not improve from 1.26247
Epoch 1930/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4306 - val_loss: 1.2739 - val_accuracy: 0.4167

Epoch 01930: val_loss did not improve from 1.26247
Epoch 1931/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4282 - val_loss: 1.2679 - val_accuracy: 0.4263

Epoch 01931: val_loss did not improve from 1.26247
Epoch 1932/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4309 - val_loss: 1.2750 - val_accuracy: 0.4231

Epoch 01932: val_loss did not improve from 1.26247
Epoch 1933/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4326 - val_loss: 1.2666 - val_accuracy: 0.4311

Epoch 01933: val_loss did not improve from 1.26247
Epoch 1934/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4269 - val_loss: 1.2750 - val_accuracy: 0.4303

Epoch 01934: val_loss did not improve from 1.26247
Epoch 1935/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4309 - val_loss: 1.2687 - val_accuracy: 0.4271

Epoch 01935: val_loss did not improve from 1.26247
Epoch 1936/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4303 - val_loss: 1.2651 - val_accuracy: 0.4104

Epoch 01936: val_loss did not improve from 1.26247
Epoch 1937/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4291 - val_loss: 1.2681 - val_accuracy: 0.4143

Epoch 01937: val_loss did not improve from 1.26247
Epoch 1938/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4306 - val_loss: 1.2659 - val_accuracy: 0.4199

Epoch 01938: val_loss did not improve from 1.26247
Epoch 1939/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4320 - val_loss: 1.2676 - val_accuracy: 0.4231

Epoch 01939: val_loss did not improve from 1.26247
Epoch 1940/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4328 - val_loss: 1.2688 - val_accuracy: 0.4231

Epoch 01940: val_loss did not improve from 1.26247
Epoch 1941/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4350 - val_loss: 1.2630 - val_accuracy: 0.4167

Epoch 01941: val_loss did not improve from 1.26247
Epoch 1942/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4323 - val_loss: 1.2676 - val_accuracy: 0.4223

Epoch 01942: val_loss did not improve from 1.26247
Epoch 1943/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4337 - val_loss: 1.2650 - val_accuracy: 0.4215

Epoch 01943: val_loss did not improve from 1.26247
Epoch 1944/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4285 - val_loss: 1.2662 - val_accuracy: 0.4295

Epoch 01944: val_loss did not improve from 1.26247
Epoch 1945/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4318 - val_loss: 1.2688 - val_accuracy: 0.4127

Epoch 01945: val_loss did not improve from 1.26247
Epoch 1946/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4303 - val_loss: 1.2675 - val_accuracy: 0.4239

Epoch 01946: val_loss did not improve from 1.26247
Epoch 1947/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4324 - val_loss: 1.2678 - val_accuracy: 0.4183

Epoch 01947: val_loss did not improve from 1.26247
Epoch 1948/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4283 - val_loss: 1.2659 - val_accuracy: 0.4303

Epoch 01948: val_loss did not improve from 1.26247
Epoch 1949/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4258 - val_loss: 1.2731 - val_accuracy: 0.4247

Epoch 01949: val_loss did not improve from 1.26247
Epoch 1950/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4313 - val_loss: 1.2705 - val_accuracy: 0.4112

Epoch 01950: val_loss did not improve from 1.26247
Epoch 1951/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4310 - val_loss: 1.2731 - val_accuracy: 0.4159

Epoch 01951: val_loss did not improve from 1.26247
Epoch 1952/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4322 - val_loss: 1.2649 - val_accuracy: 0.4287

Epoch 01952: val_loss did not improve from 1.26247
Epoch 1953/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4318 - val_loss: 1.2743 - val_accuracy: 0.4263

Epoch 01953: val_loss did not improve from 1.26247
Epoch 1954/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4284 - val_loss: 1.2673 - val_accuracy: 0.4199

Epoch 01954: val_loss did not improve from 1.26247
Epoch 1955/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4364 - val_loss: 1.2685 - val_accuracy: 0.4215

Epoch 01955: val_loss did not improve from 1.26247
Epoch 1956/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4323 - val_loss: 1.2690 - val_accuracy: 0.4231

Epoch 01956: val_loss did not improve from 1.26247
Epoch 1957/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4286 - val_loss: 1.2702 - val_accuracy: 0.4239

Epoch 01957: val_loss did not improve from 1.26247
Epoch 1958/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4260 - val_loss: 1.2624 - val_accuracy: 0.4287

Epoch 01958: val_loss improved from 1.26247 to 1.26241, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 1959/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4297 - val_loss: 1.2648 - val_accuracy: 0.4255

Epoch 01959: val_loss did not improve from 1.26241
Epoch 1960/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4288 - val_loss: 1.2696 - val_accuracy: 0.4175

Epoch 01960: val_loss did not improve from 1.26241
Epoch 1961/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4315 - val_loss: 1.2700 - val_accuracy: 0.4255

Epoch 01961: val_loss did not improve from 1.26241
Epoch 1962/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4310 - val_loss: 1.2670 - val_accuracy: 0.4191

Epoch 01962: val_loss did not improve from 1.26241
Epoch 1963/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4287 - val_loss: 1.2656 - val_accuracy: 0.4223

Epoch 01963: val_loss did not improve from 1.26241
Epoch 1964/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4289 - val_loss: 1.2648 - val_accuracy: 0.4335

Epoch 01964: val_loss did not improve from 1.26241
Epoch 1965/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4318 - val_loss: 1.2646 - val_accuracy: 0.4319

Epoch 01965: val_loss did not improve from 1.26241
Epoch 1966/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4269 - val_loss: 1.2628 - val_accuracy: 0.4303

Epoch 01966: val_loss did not improve from 1.26241
Epoch 1967/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4291 - val_loss: 1.2646 - val_accuracy: 0.4295

Epoch 01967: val_loss did not improve from 1.26241
Epoch 1968/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4352 - val_loss: 1.2669 - val_accuracy: 0.4175

Epoch 01968: val_loss did not improve from 1.26241
Epoch 1969/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4329 - val_loss: 1.2646 - val_accuracy: 0.4343

Epoch 01969: val_loss did not improve from 1.26241
Epoch 1970/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4279 - val_loss: 1.2652 - val_accuracy: 0.4247

Epoch 01970: val_loss did not improve from 1.26241
Epoch 1971/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4286 - val_loss: 1.2657 - val_accuracy: 0.4247

Epoch 01971: val_loss did not improve from 1.26241
Epoch 1972/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4292 - val_loss: 1.2646 - val_accuracy: 0.4255

Epoch 01972: val_loss did not improve from 1.26241
Epoch 1973/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4220 - val_loss: 1.2710 - val_accuracy: 0.4223

Epoch 01973: val_loss did not improve from 1.26241
Epoch 1974/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4323 - val_loss: 1.2676 - val_accuracy: 0.4319

Epoch 01974: val_loss did not improve from 1.26241
Epoch 1975/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4334 - val_loss: 1.2648 - val_accuracy: 0.4255

Epoch 01975: val_loss did not improve from 1.26241
Epoch 1976/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4312 - val_loss: 1.2677 - val_accuracy: 0.4207

Epoch 01976: val_loss did not improve from 1.26241
Epoch 1977/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4346 - val_loss: 1.2710 - val_accuracy: 0.4215

Epoch 01977: val_loss did not improve from 1.26241
Epoch 1978/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4330 - val_loss: 1.2654 - val_accuracy: 0.4135

Epoch 01978: val_loss did not improve from 1.26241
Epoch 1979/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4335 - val_loss: 1.2655 - val_accuracy: 0.4327

Epoch 01979: val_loss did not improve from 1.26241
Epoch 1980/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4331 - val_loss: 1.2654 - val_accuracy: 0.4279

Epoch 01980: val_loss did not improve from 1.26241
Epoch 1981/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4329 - val_loss: 1.2679 - val_accuracy: 0.4255

Epoch 01981: val_loss did not improve from 1.26241
Epoch 1982/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4323 - val_loss: 1.2681 - val_accuracy: 0.4199

Epoch 01982: val_loss did not improve from 1.26241
Epoch 1983/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4320 - val_loss: 1.2639 - val_accuracy: 0.4279

Epoch 01983: val_loss did not improve from 1.26241
Epoch 1984/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4286 - val_loss: 1.2663 - val_accuracy: 0.4183

Epoch 01984: val_loss did not improve from 1.26241
Epoch 1985/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4305 - val_loss: 1.2671 - val_accuracy: 0.4287

Epoch 01985: val_loss did not improve from 1.26241
Epoch 1986/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4293 - val_loss: 1.2740 - val_accuracy: 0.4175

Epoch 01986: val_loss did not improve from 1.26241
Epoch 1987/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4300 - val_loss: 1.2664 - val_accuracy: 0.4295

Epoch 01987: val_loss did not improve from 1.26241
Epoch 1988/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4286 - val_loss: 1.2653 - val_accuracy: 0.4271

Epoch 01988: val_loss did not improve from 1.26241
Epoch 1989/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4312 - val_loss: 1.2680 - val_accuracy: 0.4175

Epoch 01989: val_loss did not improve from 1.26241
Epoch 1990/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4341 - val_loss: 1.2663 - val_accuracy: 0.4207

Epoch 01990: val_loss did not improve from 1.26241
Epoch 1991/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4310 - val_loss: 1.2666 - val_accuracy: 0.4295

Epoch 01991: val_loss did not improve from 1.26241
Epoch 1992/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4306 - val_loss: 1.2654 - val_accuracy: 0.4207

Epoch 01992: val_loss did not improve from 1.26241
Epoch 1993/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4283 - val_loss: 1.2663 - val_accuracy: 0.4175

Epoch 01993: val_loss did not improve from 1.26241
Epoch 1994/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4290 - val_loss: 1.2714 - val_accuracy: 0.4167

Epoch 01994: val_loss did not improve from 1.26241
Epoch 1995/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4324 - val_loss: 1.2676 - val_accuracy: 0.4215

Epoch 01995: val_loss did not improve from 1.26241
Epoch 1996/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4310 - val_loss: 1.2650 - val_accuracy: 0.4215

Epoch 01996: val_loss did not improve from 1.26241
Epoch 1997/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4301 - val_loss: 1.2664 - val_accuracy: 0.4295

Epoch 01997: val_loss did not improve from 1.26241
Epoch 1998/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4331 - val_loss: 1.2659 - val_accuracy: 0.4151

Epoch 01998: val_loss did not improve from 1.26241
Epoch 1999/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4351 - val_loss: 1.2688 - val_accuracy: 0.4223

Epoch 01999: val_loss did not improve from 1.26241
Epoch 2000/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4325 - val_loss: 1.2615 - val_accuracy: 0.4398

Epoch 02000: val_loss improved from 1.26241 to 1.26152, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2001/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4325 - val_loss: 1.2668 - val_accuracy: 0.4263

Epoch 02001: val_loss did not improve from 1.26152
Epoch 2002/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4314 - val_loss: 1.2697 - val_accuracy: 0.4223

Epoch 02002: val_loss did not improve from 1.26152
Epoch 2003/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4266 - val_loss: 1.2720 - val_accuracy: 0.4247

Epoch 02003: val_loss did not improve from 1.26152
Epoch 2004/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4257 - val_loss: 1.2717 - val_accuracy: 0.4207

Epoch 02004: val_loss did not improve from 1.26152
Epoch 2005/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4337 - val_loss: 1.2655 - val_accuracy: 0.4327

Epoch 02005: val_loss did not improve from 1.26152
Epoch 2006/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4341 - val_loss: 1.2701 - val_accuracy: 0.4159

Epoch 02006: val_loss did not improve from 1.26152
Epoch 2007/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4289 - val_loss: 1.2641 - val_accuracy: 0.4239

Epoch 02007: val_loss did not improve from 1.26152
Epoch 2008/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4289 - val_loss: 1.2683 - val_accuracy: 0.4231

Epoch 02008: val_loss did not improve from 1.26152
Epoch 2009/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4334 - val_loss: 1.2633 - val_accuracy: 0.4327

Epoch 02009: val_loss did not improve from 1.26152
Epoch 2010/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4349 - val_loss: 1.2665 - val_accuracy: 0.4247

Epoch 02010: val_loss did not improve from 1.26152
Epoch 2011/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4330 - val_loss: 1.2661 - val_accuracy: 0.4215

Epoch 02011: val_loss did not improve from 1.26152
Epoch 2012/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4329 - val_loss: 1.2664 - val_accuracy: 0.4247

Epoch 02012: val_loss did not improve from 1.26152
Epoch 2013/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4329 - val_loss: 1.2673 - val_accuracy: 0.4191

Epoch 02013: val_loss did not improve from 1.26152
Epoch 2014/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4313 - val_loss: 1.2666 - val_accuracy: 0.4263

Epoch 02014: val_loss did not improve from 1.26152
Epoch 2015/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4329 - val_loss: 1.2706 - val_accuracy: 0.4143

Epoch 02015: val_loss did not improve from 1.26152
Epoch 2016/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4304 - val_loss: 1.2639 - val_accuracy: 0.4151

Epoch 02016: val_loss did not improve from 1.26152
Epoch 2017/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4319 - val_loss: 1.2678 - val_accuracy: 0.4263

Epoch 02017: val_loss did not improve from 1.26152
Epoch 2018/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4322 - val_loss: 1.2620 - val_accuracy: 0.4255

Epoch 02018: val_loss did not improve from 1.26152
Epoch 2019/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4328 - val_loss: 1.2656 - val_accuracy: 0.4271

Epoch 02019: val_loss did not improve from 1.26152
Epoch 2020/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4351 - val_loss: 1.2635 - val_accuracy: 0.4183

Epoch 02020: val_loss did not improve from 1.26152
Epoch 2021/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4315 - val_loss: 1.2660 - val_accuracy: 0.4255

Epoch 02021: val_loss did not improve from 1.26152
Epoch 2022/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4356 - val_loss: 1.2684 - val_accuracy: 0.4175

Epoch 02022: val_loss did not improve from 1.26152
Epoch 2023/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4355 - val_loss: 1.2619 - val_accuracy: 0.4255

Epoch 02023: val_loss did not improve from 1.26152
Epoch 2024/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4344 - val_loss: 1.2669 - val_accuracy: 0.4223

Epoch 02024: val_loss did not improve from 1.26152
Epoch 2025/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4341 - val_loss: 1.2640 - val_accuracy: 0.4422

Epoch 02025: val_loss did not improve from 1.26152
Epoch 2026/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4335 - val_loss: 1.2638 - val_accuracy: 0.4231

Epoch 02026: val_loss did not improve from 1.26152
Epoch 2027/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4300 - val_loss: 1.2663 - val_accuracy: 0.4215

Epoch 02027: val_loss did not improve from 1.26152
Epoch 2028/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4313 - val_loss: 1.2641 - val_accuracy: 0.4295

Epoch 02028: val_loss did not improve from 1.26152
Epoch 2029/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4286 - val_loss: 1.2661 - val_accuracy: 0.4167

Epoch 02029: val_loss did not improve from 1.26152
Epoch 2030/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4290 - val_loss: 1.2642 - val_accuracy: 0.4096

Epoch 02030: val_loss did not improve from 1.26152
Epoch 2031/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4300 - val_loss: 1.2656 - val_accuracy: 0.4303

Epoch 02031: val_loss did not improve from 1.26152
Epoch 2032/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4298 - val_loss: 1.2664 - val_accuracy: 0.4191

Epoch 02032: val_loss did not improve from 1.26152
Epoch 2033/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4294 - val_loss: 1.2685 - val_accuracy: 0.4159

Epoch 02033: val_loss did not improve from 1.26152
Epoch 2034/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4305 - val_loss: 1.2659 - val_accuracy: 0.4199

Epoch 02034: val_loss did not improve from 1.26152
Epoch 2035/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4340 - val_loss: 1.2660 - val_accuracy: 0.4375

Epoch 02035: val_loss did not improve from 1.26152
Epoch 2036/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4314 - val_loss: 1.2660 - val_accuracy: 0.4327

Epoch 02036: val_loss did not improve from 1.26152
Epoch 2037/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4343 - val_loss: 1.2701 - val_accuracy: 0.4215

Epoch 02037: val_loss did not improve from 1.26152
Epoch 2038/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4314 - val_loss: 1.2616 - val_accuracy: 0.4207

Epoch 02038: val_loss did not improve from 1.26152
Epoch 2039/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4275 - val_loss: 1.2663 - val_accuracy: 0.4223

Epoch 02039: val_loss did not improve from 1.26152
Epoch 2040/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4301 - val_loss: 1.2648 - val_accuracy: 0.4311

Epoch 02040: val_loss did not improve from 1.26152
Epoch 2041/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4300 - val_loss: 1.2622 - val_accuracy: 0.4279

Epoch 02041: val_loss did not improve from 1.26152
Epoch 2042/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4242 - val_loss: 1.2624 - val_accuracy: 0.4359

Epoch 02042: val_loss did not improve from 1.26152
Epoch 2043/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4294 - val_loss: 1.2626 - val_accuracy: 0.4231

Epoch 02043: val_loss did not improve from 1.26152
Epoch 2044/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4323 - val_loss: 1.2654 - val_accuracy: 0.4247

Epoch 02044: val_loss did not improve from 1.26152
Epoch 2045/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4321 - val_loss: 1.2638 - val_accuracy: 0.4239

Epoch 02045: val_loss did not improve from 1.26152
Epoch 2046/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4278 - val_loss: 1.2765 - val_accuracy: 0.4135

Epoch 02046: val_loss did not improve from 1.26152
Epoch 2047/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4302 - val_loss: 1.2668 - val_accuracy: 0.4319

Epoch 02047: val_loss did not improve from 1.26152
Epoch 2048/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4295 - val_loss: 1.2632 - val_accuracy: 0.4231

Epoch 02048: val_loss did not improve from 1.26152
Epoch 2049/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4341 - val_loss: 1.2662 - val_accuracy: 0.4279

Epoch 02049: val_loss did not improve from 1.26152
Epoch 2050/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4318 - val_loss: 1.2620 - val_accuracy: 0.4303

Epoch 02050: val_loss did not improve from 1.26152
Epoch 2051/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4309 - val_loss: 1.2666 - val_accuracy: 0.4343

Epoch 02051: val_loss did not improve from 1.26152
Epoch 2052/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4305 - val_loss: 1.2649 - val_accuracy: 0.4247

Epoch 02052: val_loss did not improve from 1.26152
Epoch 2053/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4322 - val_loss: 1.2647 - val_accuracy: 0.4207

Epoch 02053: val_loss did not improve from 1.26152
Epoch 2054/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4329 - val_loss: 1.2637 - val_accuracy: 0.4215

Epoch 02054: val_loss did not improve from 1.26152
Epoch 2055/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4292 - val_loss: 1.2674 - val_accuracy: 0.4112

Epoch 02055: val_loss did not improve from 1.26152
Epoch 2056/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4346 - val_loss: 1.2671 - val_accuracy: 0.4263

Epoch 02056: val_loss did not improve from 1.26152
Epoch 2057/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4335 - val_loss: 1.2663 - val_accuracy: 0.4215

Epoch 02057: val_loss did not improve from 1.26152
Epoch 2058/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4332 - val_loss: 1.2654 - val_accuracy: 0.4231

Epoch 02058: val_loss did not improve from 1.26152
Epoch 2059/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4298 - val_loss: 1.2679 - val_accuracy: 0.4390

Epoch 02059: val_loss did not improve from 1.26152
Epoch 2060/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4323 - val_loss: 1.2639 - val_accuracy: 0.4231

Epoch 02060: val_loss did not improve from 1.26152
Epoch 2061/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4327 - val_loss: 1.2682 - val_accuracy: 0.4215

Epoch 02061: val_loss did not improve from 1.26152
Epoch 2062/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4341 - val_loss: 1.2670 - val_accuracy: 0.4271

Epoch 02062: val_loss did not improve from 1.26152
Epoch 2063/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4306 - val_loss: 1.2691 - val_accuracy: 0.4151

Epoch 02063: val_loss did not improve from 1.26152
Epoch 2064/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4298 - val_loss: 1.2644 - val_accuracy: 0.4223

Epoch 02064: val_loss did not improve from 1.26152
Epoch 2065/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4331 - val_loss: 1.2683 - val_accuracy: 0.4127

Epoch 02065: val_loss did not improve from 1.26152
Epoch 2066/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4276 - val_loss: 1.2740 - val_accuracy: 0.4159

Epoch 02066: val_loss did not improve from 1.26152
Epoch 2067/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4329 - val_loss: 1.2649 - val_accuracy: 0.4207

Epoch 02067: val_loss did not improve from 1.26152
Epoch 2068/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4331 - val_loss: 1.2677 - val_accuracy: 0.4263

Epoch 02068: val_loss did not improve from 1.26152
Epoch 2069/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4324 - val_loss: 1.2639 - val_accuracy: 0.4247

Epoch 02069: val_loss did not improve from 1.26152
Epoch 2070/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4297 - val_loss: 1.2656 - val_accuracy: 0.4255

Epoch 02070: val_loss did not improve from 1.26152
Epoch 2071/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4310 - val_loss: 1.2682 - val_accuracy: 0.4287

Epoch 02071: val_loss did not improve from 1.26152
Epoch 2072/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4233 - val_loss: 1.2697 - val_accuracy: 0.4239

Epoch 02072: val_loss did not improve from 1.26152
Epoch 2073/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4291 - val_loss: 1.2662 - val_accuracy: 0.4247

Epoch 02073: val_loss did not improve from 1.26152
Epoch 2074/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4337 - val_loss: 1.2659 - val_accuracy: 0.4279

Epoch 02074: val_loss did not improve from 1.26152
Epoch 2075/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4310 - val_loss: 1.2727 - val_accuracy: 0.4191

Epoch 02075: val_loss did not improve from 1.26152
Epoch 2076/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4277 - val_loss: 1.2641 - val_accuracy: 0.4470

Epoch 02076: val_loss did not improve from 1.26152
Epoch 2077/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4320 - val_loss: 1.2663 - val_accuracy: 0.4279

Epoch 02077: val_loss did not improve from 1.26152
Epoch 2078/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4293 - val_loss: 1.2708 - val_accuracy: 0.4191

Epoch 02078: val_loss did not improve from 1.26152
Epoch 2079/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4353 - val_loss: 1.2674 - val_accuracy: 0.4311

Epoch 02079: val_loss did not improve from 1.26152
Epoch 2080/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4291 - val_loss: 1.2636 - val_accuracy: 0.4335

Epoch 02080: val_loss did not improve from 1.26152
Epoch 2081/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4305 - val_loss: 1.2690 - val_accuracy: 0.4151

Epoch 02081: val_loss did not improve from 1.26152
Epoch 2082/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4317 - val_loss: 1.2640 - val_accuracy: 0.4295

Epoch 02082: val_loss did not improve from 1.26152
Epoch 2083/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4324 - val_loss: 1.2659 - val_accuracy: 0.4319

Epoch 02083: val_loss did not improve from 1.26152
Epoch 2084/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4312 - val_loss: 1.2716 - val_accuracy: 0.4175

Epoch 02084: val_loss did not improve from 1.26152
Epoch 2085/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4338 - val_loss: 1.2638 - val_accuracy: 0.4263

Epoch 02085: val_loss did not improve from 1.26152
Epoch 2086/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4360 - val_loss: 1.2678 - val_accuracy: 0.4215

Epoch 02086: val_loss did not improve from 1.26152
Epoch 2087/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4350 - val_loss: 1.2655 - val_accuracy: 0.4223

Epoch 02087: val_loss did not improve from 1.26152
Epoch 2088/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4303 - val_loss: 1.2666 - val_accuracy: 0.4207

Epoch 02088: val_loss did not improve from 1.26152
Epoch 2089/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4334 - val_loss: 1.2649 - val_accuracy: 0.4279

Epoch 02089: val_loss did not improve from 1.26152
Epoch 2090/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4309 - val_loss: 1.2643 - val_accuracy: 0.4215

Epoch 02090: val_loss did not improve from 1.26152
Epoch 2091/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4306 - val_loss: 1.2769 - val_accuracy: 0.4096

Epoch 02091: val_loss did not improve from 1.26152
Epoch 2092/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4370 - val_loss: 1.2639 - val_accuracy: 0.4271

Epoch 02092: val_loss did not improve from 1.26152
Epoch 2093/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4334 - val_loss: 1.2664 - val_accuracy: 0.4271

Epoch 02093: val_loss did not improve from 1.26152
Epoch 2094/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4328 - val_loss: 1.2665 - val_accuracy: 0.4263

Epoch 02094: val_loss did not improve from 1.26152
Epoch 2095/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4321 - val_loss: 1.2653 - val_accuracy: 0.4311

Epoch 02095: val_loss did not improve from 1.26152
Epoch 2096/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4298 - val_loss: 1.2668 - val_accuracy: 0.4303

Epoch 02096: val_loss did not improve from 1.26152
Epoch 2097/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4347 - val_loss: 1.2698 - val_accuracy: 0.4279

Epoch 02097: val_loss did not improve from 1.26152
Epoch 2098/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4302 - val_loss: 1.2649 - val_accuracy: 0.4231

Epoch 02098: val_loss did not improve from 1.26152
Epoch 2099/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4254 - val_loss: 1.2651 - val_accuracy: 0.4143

Epoch 02099: val_loss did not improve from 1.26152
Epoch 2100/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4274 - val_loss: 1.2651 - val_accuracy: 0.4271

Epoch 02100: val_loss did not improve from 1.26152
Epoch 2101/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4331 - val_loss: 1.2640 - val_accuracy: 0.4287

Epoch 02101: val_loss did not improve from 1.26152
Epoch 2102/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4337 - val_loss: 1.2674 - val_accuracy: 0.4191

Epoch 02102: val_loss did not improve from 1.26152
Epoch 2103/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4304 - val_loss: 1.2697 - val_accuracy: 0.4191

Epoch 02103: val_loss did not improve from 1.26152
Epoch 2104/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4306 - val_loss: 1.2702 - val_accuracy: 0.4295

Epoch 02104: val_loss did not improve from 1.26152
Epoch 2105/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4289 - val_loss: 1.2655 - val_accuracy: 0.4263

Epoch 02105: val_loss did not improve from 1.26152
Epoch 2106/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4307 - val_loss: 1.2616 - val_accuracy: 0.4335

Epoch 02106: val_loss did not improve from 1.26152
Epoch 2107/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4313 - val_loss: 1.2655 - val_accuracy: 0.4303

Epoch 02107: val_loss did not improve from 1.26152
Epoch 2108/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4296 - val_loss: 1.2738 - val_accuracy: 0.4231

Epoch 02108: val_loss did not improve from 1.26152
Epoch 2109/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4326 - val_loss: 1.2637 - val_accuracy: 0.4271

Epoch 02109: val_loss did not improve from 1.26152
Epoch 2110/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4308 - val_loss: 1.2644 - val_accuracy: 0.4319

Epoch 02110: val_loss did not improve from 1.26152
Epoch 2111/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4320 - val_loss: 1.2654 - val_accuracy: 0.4311

Epoch 02111: val_loss did not improve from 1.26152
Epoch 2112/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4337 - val_loss: 1.2634 - val_accuracy: 0.4335

Epoch 02112: val_loss did not improve from 1.26152
Epoch 2113/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4332 - val_loss: 1.2665 - val_accuracy: 0.4279

Epoch 02113: val_loss did not improve from 1.26152
Epoch 2114/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4321 - val_loss: 1.2666 - val_accuracy: 0.4287

Epoch 02114: val_loss did not improve from 1.26152
Epoch 2115/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4353 - val_loss: 1.2617 - val_accuracy: 0.4263

Epoch 02115: val_loss did not improve from 1.26152
Epoch 2116/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4329 - val_loss: 1.2661 - val_accuracy: 0.4343

Epoch 02116: val_loss did not improve from 1.26152
Epoch 2117/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4332 - val_loss: 1.2663 - val_accuracy: 0.4231

Epoch 02117: val_loss did not improve from 1.26152
Epoch 2118/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4272 - val_loss: 1.2675 - val_accuracy: 0.4231

Epoch 02118: val_loss did not improve from 1.26152
Epoch 2119/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4326 - val_loss: 1.2646 - val_accuracy: 0.4343

Epoch 02119: val_loss did not improve from 1.26152
Epoch 2120/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4310 - val_loss: 1.2710 - val_accuracy: 0.4215

Epoch 02120: val_loss did not improve from 1.26152
Epoch 2121/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4353 - val_loss: 1.2722 - val_accuracy: 0.4279

Epoch 02121: val_loss did not improve from 1.26152
Epoch 2122/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4313 - val_loss: 1.2662 - val_accuracy: 0.4287

Epoch 02122: val_loss did not improve from 1.26152
Epoch 2123/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4305 - val_loss: 1.2655 - val_accuracy: 0.4311

Epoch 02123: val_loss did not improve from 1.26152
Epoch 2124/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4303 - val_loss: 1.2628 - val_accuracy: 0.4295

Epoch 02124: val_loss did not improve from 1.26152
Epoch 2125/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4299 - val_loss: 1.2699 - val_accuracy: 0.4199

Epoch 02125: val_loss did not improve from 1.26152
Epoch 2126/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4262 - val_loss: 1.2609 - val_accuracy: 0.4303

Epoch 02126: val_loss improved from 1.26152 to 1.26087, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2127/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4324 - val_loss: 1.2656 - val_accuracy: 0.4335

Epoch 02127: val_loss did not improve from 1.26087
Epoch 2128/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4322 - val_loss: 1.2655 - val_accuracy: 0.4279

Epoch 02128: val_loss did not improve from 1.26087
Epoch 2129/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4301 - val_loss: 1.2639 - val_accuracy: 0.4271

Epoch 02129: val_loss did not improve from 1.26087
Epoch 2130/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4306 - val_loss: 1.2626 - val_accuracy: 0.4255

Epoch 02130: val_loss did not improve from 1.26087
Epoch 2131/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4272 - val_loss: 1.2703 - val_accuracy: 0.4223

Epoch 02131: val_loss did not improve from 1.26087
Epoch 2132/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4377 - val_loss: 1.2641 - val_accuracy: 0.4255

Epoch 02132: val_loss did not improve from 1.26087
Epoch 2133/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4250 - val_loss: 1.2719 - val_accuracy: 0.4175

Epoch 02133: val_loss did not improve from 1.26087
Epoch 2134/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4297 - val_loss: 1.2681 - val_accuracy: 0.4255

Epoch 02134: val_loss did not improve from 1.26087
Epoch 2135/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4304 - val_loss: 1.2682 - val_accuracy: 0.4287

Epoch 02135: val_loss did not improve from 1.26087
Epoch 2136/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4322 - val_loss: 1.2652 - val_accuracy: 0.4135

Epoch 02136: val_loss did not improve from 1.26087
Epoch 2137/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4314 - val_loss: 1.2692 - val_accuracy: 0.4207

Epoch 02137: val_loss did not improve from 1.26087
Epoch 2138/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4313 - val_loss: 1.2638 - val_accuracy: 0.4191

Epoch 02138: val_loss did not improve from 1.26087
Epoch 2139/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4301 - val_loss: 1.2672 - val_accuracy: 0.4183

Epoch 02139: val_loss did not improve from 1.26087
Epoch 2140/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4292 - val_loss: 1.2670 - val_accuracy: 0.4359

Epoch 02140: val_loss did not improve from 1.26087
Epoch 2141/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4301 - val_loss: 1.2644 - val_accuracy: 0.4175

Epoch 02141: val_loss did not improve from 1.26087
Epoch 2142/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4316 - val_loss: 1.2750 - val_accuracy: 0.4255

Epoch 02142: val_loss did not improve from 1.26087
Epoch 2143/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4332 - val_loss: 1.2624 - val_accuracy: 0.4287

Epoch 02143: val_loss did not improve from 1.26087
Epoch 2144/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4307 - val_loss: 1.2690 - val_accuracy: 0.4207

Epoch 02144: val_loss did not improve from 1.26087
Epoch 2145/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4345 - val_loss: 1.2657 - val_accuracy: 0.4207

Epoch 02145: val_loss did not improve from 1.26087
Epoch 2146/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4329 - val_loss: 1.2660 - val_accuracy: 0.4223

Epoch 02146: val_loss did not improve from 1.26087
Epoch 2147/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4309 - val_loss: 1.2700 - val_accuracy: 0.4223

Epoch 02147: val_loss did not improve from 1.26087
Epoch 2148/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4279 - val_loss: 1.2662 - val_accuracy: 0.4295

Epoch 02148: val_loss did not improve from 1.26087
Epoch 2149/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4284 - val_loss: 1.2700 - val_accuracy: 0.4159

Epoch 02149: val_loss did not improve from 1.26087
Epoch 2150/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4324 - val_loss: 1.2627 - val_accuracy: 0.4223

Epoch 02150: val_loss did not improve from 1.26087
Epoch 2151/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4340 - val_loss: 1.2634 - val_accuracy: 0.4263

Epoch 02151: val_loss did not improve from 1.26087
Epoch 2152/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4312 - val_loss: 1.2716 - val_accuracy: 0.4112

Epoch 02152: val_loss did not improve from 1.26087
Epoch 2153/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4306 - val_loss: 1.2700 - val_accuracy: 0.4151

Epoch 02153: val_loss did not improve from 1.26087
Epoch 2154/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4317 - val_loss: 1.2618 - val_accuracy: 0.4311

Epoch 02154: val_loss did not improve from 1.26087
Epoch 2155/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4350 - val_loss: 1.2646 - val_accuracy: 0.4183

Epoch 02155: val_loss did not improve from 1.26087
Epoch 2156/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4329 - val_loss: 1.2649 - val_accuracy: 0.4223

Epoch 02156: val_loss did not improve from 1.26087
Epoch 2157/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4312 - val_loss: 1.2771 - val_accuracy: 0.4080

Epoch 02157: val_loss did not improve from 1.26087
Epoch 2158/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4270 - val_loss: 1.2705 - val_accuracy: 0.4151

Epoch 02158: val_loss did not improve from 1.26087
Epoch 2159/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4304 - val_loss: 1.2657 - val_accuracy: 0.4167

Epoch 02159: val_loss did not improve from 1.26087
Epoch 2160/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4301 - val_loss: 1.2604 - val_accuracy: 0.4303

Epoch 02160: val_loss improved from 1.26087 to 1.26041, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2161/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4329 - val_loss: 1.2653 - val_accuracy: 0.4303

Epoch 02161: val_loss did not improve from 1.26041
Epoch 2162/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4325 - val_loss: 1.2629 - val_accuracy: 0.4287

Epoch 02162: val_loss did not improve from 1.26041
Epoch 2163/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4314 - val_loss: 1.2740 - val_accuracy: 0.4215

Epoch 02163: val_loss did not improve from 1.26041
Epoch 2164/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4326 - val_loss: 1.2626 - val_accuracy: 0.4319

Epoch 02164: val_loss did not improve from 1.26041
Epoch 2165/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4320 - val_loss: 1.2672 - val_accuracy: 0.4231

Epoch 02165: val_loss did not improve from 1.26041
Epoch 2166/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4338 - val_loss: 1.2659 - val_accuracy: 0.4335

Epoch 02166: val_loss did not improve from 1.26041
Epoch 2167/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4289 - val_loss: 1.2664 - val_accuracy: 0.4255

Epoch 02167: val_loss did not improve from 1.26041
Epoch 2168/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4340 - val_loss: 1.2706 - val_accuracy: 0.4143

Epoch 02168: val_loss did not improve from 1.26041
Epoch 2169/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4298 - val_loss: 1.2629 - val_accuracy: 0.4231

Epoch 02169: val_loss did not improve from 1.26041
Epoch 2170/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4267 - val_loss: 1.2682 - val_accuracy: 0.4239

Epoch 02170: val_loss did not improve from 1.26041
Epoch 2171/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4333 - val_loss: 1.2654 - val_accuracy: 0.4287

Epoch 02171: val_loss did not improve from 1.26041
Epoch 2172/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4305 - val_loss: 1.2673 - val_accuracy: 0.4175

Epoch 02172: val_loss did not improve from 1.26041
Epoch 2173/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4316 - val_loss: 1.2741 - val_accuracy: 0.4223

Epoch 02173: val_loss did not improve from 1.26041
Epoch 2174/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4290 - val_loss: 1.2743 - val_accuracy: 0.4263

Epoch 02174: val_loss did not improve from 1.26041
Epoch 2175/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4267 - val_loss: 1.2639 - val_accuracy: 0.4303

Epoch 02175: val_loss did not improve from 1.26041
Epoch 2176/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4324 - val_loss: 1.2640 - val_accuracy: 0.4287

Epoch 02176: val_loss did not improve from 1.26041
Epoch 2177/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4344 - val_loss: 1.2683 - val_accuracy: 0.4215

Epoch 02177: val_loss did not improve from 1.26041
Epoch 2178/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4329 - val_loss: 1.2626 - val_accuracy: 0.4207

Epoch 02178: val_loss did not improve from 1.26041
Epoch 2179/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4340 - val_loss: 1.2656 - val_accuracy: 0.4191

Epoch 02179: val_loss did not improve from 1.26041
Epoch 2180/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4314 - val_loss: 1.2617 - val_accuracy: 0.4207

Epoch 02180: val_loss did not improve from 1.26041
Epoch 2181/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4311 - val_loss: 1.2777 - val_accuracy: 0.4127

Epoch 02181: val_loss did not improve from 1.26041
Epoch 2182/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4260 - val_loss: 1.2663 - val_accuracy: 0.4191

Epoch 02182: val_loss did not improve from 1.26041
Epoch 2183/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4322 - val_loss: 1.2703 - val_accuracy: 0.4207

Epoch 02183: val_loss did not improve from 1.26041
Epoch 2184/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4334 - val_loss: 1.2627 - val_accuracy: 0.4255

Epoch 02184: val_loss did not improve from 1.26041
Epoch 2185/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4316 - val_loss: 1.2702 - val_accuracy: 0.4247

Epoch 02185: val_loss did not improve from 1.26041
Epoch 2186/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4352 - val_loss: 1.2644 - val_accuracy: 0.4207

Epoch 02186: val_loss did not improve from 1.26041
Epoch 2187/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4356 - val_loss: 1.2692 - val_accuracy: 0.4311

Epoch 02187: val_loss did not improve from 1.26041
Epoch 2188/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4298 - val_loss: 1.2653 - val_accuracy: 0.4295

Epoch 02188: val_loss did not improve from 1.26041
Epoch 2189/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4315 - val_loss: 1.2665 - val_accuracy: 0.4295

Epoch 02189: val_loss did not improve from 1.26041
Epoch 2190/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4345 - val_loss: 1.2712 - val_accuracy: 0.4199

Epoch 02190: val_loss did not improve from 1.26041
Epoch 2191/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4335 - val_loss: 1.2633 - val_accuracy: 0.4247

Epoch 02191: val_loss did not improve from 1.26041
Epoch 2192/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4314 - val_loss: 1.2647 - val_accuracy: 0.4199

Epoch 02192: val_loss did not improve from 1.26041
Epoch 2193/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4334 - val_loss: 1.2642 - val_accuracy: 0.4279

Epoch 02193: val_loss did not improve from 1.26041
Epoch 2194/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4319 - val_loss: 1.2661 - val_accuracy: 0.4271

Epoch 02194: val_loss did not improve from 1.26041
Epoch 2195/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4334 - val_loss: 1.2674 - val_accuracy: 0.4255

Epoch 02195: val_loss did not improve from 1.26041
Epoch 2196/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4349 - val_loss: 1.2640 - val_accuracy: 0.4263

Epoch 02196: val_loss did not improve from 1.26041
Epoch 2197/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4322 - val_loss: 1.2662 - val_accuracy: 0.4271

Epoch 02197: val_loss did not improve from 1.26041
Epoch 2198/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4315 - val_loss: 1.2636 - val_accuracy: 0.4319

Epoch 02198: val_loss did not improve from 1.26041
Epoch 2199/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4351 - val_loss: 1.2643 - val_accuracy: 0.4279

Epoch 02199: val_loss did not improve from 1.26041
Epoch 2200/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4318 - val_loss: 1.2662 - val_accuracy: 0.4319

Epoch 02200: val_loss did not improve from 1.26041
Epoch 2201/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4314 - val_loss: 1.2658 - val_accuracy: 0.4239

Epoch 02201: val_loss did not improve from 1.26041
Epoch 2202/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4280 - val_loss: 1.2683 - val_accuracy: 0.4215

Epoch 02202: val_loss did not improve from 1.26041
Epoch 2203/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4355 - val_loss: 1.2664 - val_accuracy: 0.4199

Epoch 02203: val_loss did not improve from 1.26041
Epoch 2204/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4297 - val_loss: 1.2612 - val_accuracy: 0.4351

Epoch 02204: val_loss did not improve from 1.26041
Epoch 2205/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4337 - val_loss: 1.2652 - val_accuracy: 0.4239

Epoch 02205: val_loss did not improve from 1.26041
Epoch 2206/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4330 - val_loss: 1.2624 - val_accuracy: 0.4319

Epoch 02206: val_loss did not improve from 1.26041
Epoch 2207/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4326 - val_loss: 1.2708 - val_accuracy: 0.4263

Epoch 02207: val_loss did not improve from 1.26041
Epoch 2208/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4340 - val_loss: 1.2672 - val_accuracy: 0.4199

Epoch 02208: val_loss did not improve from 1.26041
Epoch 2209/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4321 - val_loss: 1.2670 - val_accuracy: 0.4303

Epoch 02209: val_loss did not improve from 1.26041
Epoch 2210/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4297 - val_loss: 1.2720 - val_accuracy: 0.4215

Epoch 02210: val_loss did not improve from 1.26041
Epoch 2211/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4363 - val_loss: 1.2709 - val_accuracy: 0.4199

Epoch 02211: val_loss did not improve from 1.26041
Epoch 2212/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4314 - val_loss: 1.2616 - val_accuracy: 0.4255

Epoch 02212: val_loss did not improve from 1.26041
Epoch 2213/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4365 - val_loss: 1.2670 - val_accuracy: 0.4271

Epoch 02213: val_loss did not improve from 1.26041
Epoch 2214/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4315 - val_loss: 1.2649 - val_accuracy: 0.4231

Epoch 02214: val_loss did not improve from 1.26041
Epoch 2215/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4329 - val_loss: 1.2764 - val_accuracy: 0.4167

Epoch 02215: val_loss did not improve from 1.26041
Epoch 2216/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4345 - val_loss: 1.2628 - val_accuracy: 0.4183

Epoch 02216: val_loss did not improve from 1.26041
Epoch 2217/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4308 - val_loss: 1.2721 - val_accuracy: 0.4247

Epoch 02217: val_loss did not improve from 1.26041
Epoch 2218/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4249 - val_loss: 1.2713 - val_accuracy: 0.4239

Epoch 02218: val_loss did not improve from 1.26041
Epoch 2219/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4304 - val_loss: 1.2616 - val_accuracy: 0.4390

Epoch 02219: val_loss did not improve from 1.26041
Epoch 2220/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4337 - val_loss: 1.2629 - val_accuracy: 0.4191

Epoch 02220: val_loss did not improve from 1.26041
Epoch 2221/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4329 - val_loss: 1.2636 - val_accuracy: 0.4191

Epoch 02221: val_loss did not improve from 1.26041
Epoch 2222/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4327 - val_loss: 1.2653 - val_accuracy: 0.4343

Epoch 02222: val_loss did not improve from 1.26041
Epoch 2223/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4326 - val_loss: 1.2715 - val_accuracy: 0.4135

Epoch 02223: val_loss did not improve from 1.26041
Epoch 2224/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4325 - val_loss: 1.2684 - val_accuracy: 0.4223

Epoch 02224: val_loss did not improve from 1.26041
Epoch 2225/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4293 - val_loss: 1.2632 - val_accuracy: 0.4319

Epoch 02225: val_loss did not improve from 1.26041
Epoch 2226/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4318 - val_loss: 1.2690 - val_accuracy: 0.4255

Epoch 02226: val_loss did not improve from 1.26041
Epoch 2227/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4311 - val_loss: 1.2630 - val_accuracy: 0.4231

Epoch 02227: val_loss did not improve from 1.26041
Epoch 2228/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4287 - val_loss: 1.2717 - val_accuracy: 0.4239

Epoch 02228: val_loss did not improve from 1.26041
Epoch 2229/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4308 - val_loss: 1.2641 - val_accuracy: 0.4319

Epoch 02229: val_loss did not improve from 1.26041
Epoch 2230/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4338 - val_loss: 1.2609 - val_accuracy: 0.4255

Epoch 02230: val_loss did not improve from 1.26041
Epoch 2231/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4295 - val_loss: 1.2641 - val_accuracy: 0.4167

Epoch 02231: val_loss did not improve from 1.26041
Epoch 2232/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4306 - val_loss: 1.2637 - val_accuracy: 0.4199

Epoch 02232: val_loss did not improve from 1.26041
Epoch 2233/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4303 - val_loss: 1.2605 - val_accuracy: 0.4295

Epoch 02233: val_loss did not improve from 1.26041
Epoch 2234/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4286 - val_loss: 1.2675 - val_accuracy: 0.4263

Epoch 02234: val_loss did not improve from 1.26041
Epoch 2235/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4277 - val_loss: 1.2644 - val_accuracy: 0.4223

Epoch 02235: val_loss did not improve from 1.26041
Epoch 2236/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4317 - val_loss: 1.2620 - val_accuracy: 0.4287

Epoch 02236: val_loss did not improve from 1.26041
Epoch 2237/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4338 - val_loss: 1.2645 - val_accuracy: 0.4311

Epoch 02237: val_loss did not improve from 1.26041
Epoch 2238/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4332 - val_loss: 1.2612 - val_accuracy: 0.4263

Epoch 02238: val_loss did not improve from 1.26041
Epoch 2239/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4295 - val_loss: 1.2767 - val_accuracy: 0.4271

Epoch 02239: val_loss did not improve from 1.26041
Epoch 2240/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4337 - val_loss: 1.2627 - val_accuracy: 0.4231

Epoch 02240: val_loss did not improve from 1.26041
Epoch 2241/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4340 - val_loss: 1.2641 - val_accuracy: 0.4247

Epoch 02241: val_loss did not improve from 1.26041
Epoch 2242/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4329 - val_loss: 1.2640 - val_accuracy: 0.4382

Epoch 02242: val_loss did not improve from 1.26041
Epoch 2243/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4322 - val_loss: 1.2675 - val_accuracy: 0.4215

Epoch 02243: val_loss did not improve from 1.26041
Epoch 2244/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4346 - val_loss: 1.2659 - val_accuracy: 0.4287

Epoch 02244: val_loss did not improve from 1.26041
Epoch 2245/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4311 - val_loss: 1.2657 - val_accuracy: 0.4263

Epoch 02245: val_loss did not improve from 1.26041
Epoch 2246/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4355 - val_loss: 1.2653 - val_accuracy: 0.4175

Epoch 02246: val_loss did not improve from 1.26041
Epoch 2247/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4336 - val_loss: 1.2639 - val_accuracy: 0.4319

Epoch 02247: val_loss did not improve from 1.26041
Epoch 2248/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4314 - val_loss: 1.2679 - val_accuracy: 0.4287

Epoch 02248: val_loss did not improve from 1.26041
Epoch 2249/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4322 - val_loss: 1.2628 - val_accuracy: 0.4175

Epoch 02249: val_loss did not improve from 1.26041
Epoch 2250/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4313 - val_loss: 1.2640 - val_accuracy: 0.4367

Epoch 02250: val_loss did not improve from 1.26041
Epoch 2251/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4344 - val_loss: 1.2684 - val_accuracy: 0.4215

Epoch 02251: val_loss did not improve from 1.26041
Epoch 2252/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4319 - val_loss: 1.2597 - val_accuracy: 0.4327

Epoch 02252: val_loss improved from 1.26041 to 1.25971, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2253/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4311 - val_loss: 1.2653 - val_accuracy: 0.4239

Epoch 02253: val_loss did not improve from 1.25971
Epoch 2254/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4318 - val_loss: 1.2627 - val_accuracy: 0.4271

Epoch 02254: val_loss did not improve from 1.25971
Epoch 2255/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4347 - val_loss: 1.2655 - val_accuracy: 0.4207

Epoch 02255: val_loss did not improve from 1.25971
Epoch 2256/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4339 - val_loss: 1.2713 - val_accuracy: 0.4239

Epoch 02256: val_loss did not improve from 1.25971
Epoch 2257/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4309 - val_loss: 1.2616 - val_accuracy: 0.4311

Epoch 02257: val_loss did not improve from 1.25971
Epoch 2258/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4325 - val_loss: 1.2636 - val_accuracy: 0.4263

Epoch 02258: val_loss did not improve from 1.25971
Epoch 2259/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4348 - val_loss: 1.2693 - val_accuracy: 0.4207

Epoch 02259: val_loss did not improve from 1.25971
Epoch 2260/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4308 - val_loss: 1.2676 - val_accuracy: 0.4199

Epoch 02260: val_loss did not improve from 1.25971
Epoch 2261/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4317 - val_loss: 1.2675 - val_accuracy: 0.4223

Epoch 02261: val_loss did not improve from 1.25971
Epoch 2262/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4320 - val_loss: 1.2626 - val_accuracy: 0.4231

Epoch 02262: val_loss did not improve from 1.25971
Epoch 2263/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4306 - val_loss: 1.2653 - val_accuracy: 0.4239

Epoch 02263: val_loss did not improve from 1.25971
Epoch 2264/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4319 - val_loss: 1.2674 - val_accuracy: 0.4327

Epoch 02264: val_loss did not improve from 1.25971
Epoch 2265/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4321 - val_loss: 1.2726 - val_accuracy: 0.4223

Epoch 02265: val_loss did not improve from 1.25971
Epoch 2266/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4312 - val_loss: 1.2644 - val_accuracy: 0.4239

Epoch 02266: val_loss did not improve from 1.25971
Epoch 2267/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4303 - val_loss: 1.2664 - val_accuracy: 0.4287

Epoch 02267: val_loss did not improve from 1.25971
Epoch 2268/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4342 - val_loss: 1.2623 - val_accuracy: 0.4255

Epoch 02268: val_loss did not improve from 1.25971
Epoch 2269/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4305 - val_loss: 1.2684 - val_accuracy: 0.4271

Epoch 02269: val_loss did not improve from 1.25971
Epoch 2270/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4275 - val_loss: 1.2685 - val_accuracy: 0.4127

Epoch 02270: val_loss did not improve from 1.25971
Epoch 2271/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4327 - val_loss: 1.2643 - val_accuracy: 0.4367

Epoch 02271: val_loss did not improve from 1.25971
Epoch 2272/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4308 - val_loss: 1.2732 - val_accuracy: 0.4303

Epoch 02272: val_loss did not improve from 1.25971
Epoch 2273/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4316 - val_loss: 1.2631 - val_accuracy: 0.4303

Epoch 02273: val_loss did not improve from 1.25971
Epoch 2274/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4324 - val_loss: 1.2659 - val_accuracy: 0.4263

Epoch 02274: val_loss did not improve from 1.25971
Epoch 2275/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4295 - val_loss: 1.2599 - val_accuracy: 0.4343

Epoch 02275: val_loss did not improve from 1.25971
Epoch 2276/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4349 - val_loss: 1.2621 - val_accuracy: 0.4327

Epoch 02276: val_loss did not improve from 1.25971
Epoch 2277/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4327 - val_loss: 1.2644 - val_accuracy: 0.4287

Epoch 02277: val_loss did not improve from 1.25971
Epoch 2278/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4279 - val_loss: 1.2658 - val_accuracy: 0.4263

Epoch 02278: val_loss did not improve from 1.25971
Epoch 2279/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4349 - val_loss: 1.2609 - val_accuracy: 0.4295

Epoch 02279: val_loss did not improve from 1.25971
Epoch 2280/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4340 - val_loss: 1.2667 - val_accuracy: 0.4327

Epoch 02280: val_loss did not improve from 1.25971
Epoch 2281/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4308 - val_loss: 1.2649 - val_accuracy: 0.4327

Epoch 02281: val_loss did not improve from 1.25971
Epoch 2282/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4320 - val_loss: 1.2609 - val_accuracy: 0.4319

Epoch 02282: val_loss did not improve from 1.25971
Epoch 2283/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4306 - val_loss: 1.2636 - val_accuracy: 0.4239

Epoch 02283: val_loss did not improve from 1.25971
Epoch 2284/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4341 - val_loss: 1.2633 - val_accuracy: 0.4287

Epoch 02284: val_loss did not improve from 1.25971
Epoch 2285/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4340 - val_loss: 1.2672 - val_accuracy: 0.4271

Epoch 02285: val_loss did not improve from 1.25971
Epoch 2286/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4326 - val_loss: 1.2623 - val_accuracy: 0.4279

Epoch 02286: val_loss did not improve from 1.25971
Epoch 2287/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4340 - val_loss: 1.2657 - val_accuracy: 0.4207

Epoch 02287: val_loss did not improve from 1.25971
Epoch 2288/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4319 - val_loss: 1.2630 - val_accuracy: 0.4167

Epoch 02288: val_loss did not improve from 1.25971
Epoch 2289/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4348 - val_loss: 1.2628 - val_accuracy: 0.4367

Epoch 02289: val_loss did not improve from 1.25971
Epoch 2290/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4312 - val_loss: 1.2649 - val_accuracy: 0.4319

Epoch 02290: val_loss did not improve from 1.25971
Epoch 2291/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4345 - val_loss: 1.2625 - val_accuracy: 0.4191

Epoch 02291: val_loss did not improve from 1.25971
Epoch 2292/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4298 - val_loss: 1.2632 - val_accuracy: 0.4287

Epoch 02292: val_loss did not improve from 1.25971
Epoch 2293/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4334 - val_loss: 1.2744 - val_accuracy: 0.4159

Epoch 02293: val_loss did not improve from 1.25971
Epoch 2294/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4345 - val_loss: 1.2606 - val_accuracy: 0.4255

Epoch 02294: val_loss did not improve from 1.25971
Epoch 2295/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4323 - val_loss: 1.2636 - val_accuracy: 0.4223

Epoch 02295: val_loss did not improve from 1.25971
Epoch 2296/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4307 - val_loss: 1.2637 - val_accuracy: 0.4287

Epoch 02296: val_loss did not improve from 1.25971
Epoch 2297/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4323 - val_loss: 1.2609 - val_accuracy: 0.4271

Epoch 02297: val_loss did not improve from 1.25971
Epoch 2298/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4346 - val_loss: 1.2622 - val_accuracy: 0.4223

Epoch 02298: val_loss did not improve from 1.25971
Epoch 2299/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4352 - val_loss: 1.2707 - val_accuracy: 0.4183

Epoch 02299: val_loss did not improve from 1.25971
Epoch 2300/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4311 - val_loss: 1.2640 - val_accuracy: 0.4255

Epoch 02300: val_loss did not improve from 1.25971
Epoch 2301/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4303 - val_loss: 1.2661 - val_accuracy: 0.4231

Epoch 02301: val_loss did not improve from 1.25971
Epoch 2302/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4319 - val_loss: 1.2673 - val_accuracy: 0.4295

Epoch 02302: val_loss did not improve from 1.25971
Epoch 2303/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4275 - val_loss: 1.2687 - val_accuracy: 0.4231

Epoch 02303: val_loss did not improve from 1.25971
Epoch 2304/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4352 - val_loss: 1.2646 - val_accuracy: 0.4335

Epoch 02304: val_loss did not improve from 1.25971
Epoch 2305/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4301 - val_loss: 1.2619 - val_accuracy: 0.4295

Epoch 02305: val_loss did not improve from 1.25971
Epoch 2306/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4321 - val_loss: 1.2669 - val_accuracy: 0.4231

Epoch 02306: val_loss did not improve from 1.25971
Epoch 2307/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4324 - val_loss: 1.2652 - val_accuracy: 0.4247

Epoch 02307: val_loss did not improve from 1.25971
Epoch 2308/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4315 - val_loss: 1.2640 - val_accuracy: 0.4263

Epoch 02308: val_loss did not improve from 1.25971
Epoch 2309/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4318 - val_loss: 1.2614 - val_accuracy: 0.4303

Epoch 02309: val_loss did not improve from 1.25971
Epoch 2310/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4323 - val_loss: 1.2648 - val_accuracy: 0.4215

Epoch 02310: val_loss did not improve from 1.25971
Epoch 2311/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4346 - val_loss: 1.2693 - val_accuracy: 0.4191

Epoch 02311: val_loss did not improve from 1.25971
Epoch 2312/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4332 - val_loss: 1.2657 - val_accuracy: 0.4303

Epoch 02312: val_loss did not improve from 1.25971
Epoch 2313/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4365 - val_loss: 1.2624 - val_accuracy: 0.4295

Epoch 02313: val_loss did not improve from 1.25971
Epoch 2314/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4322 - val_loss: 1.2703 - val_accuracy: 0.4239

Epoch 02314: val_loss did not improve from 1.25971
Epoch 2315/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4304 - val_loss: 1.2612 - val_accuracy: 0.4135

Epoch 02315: val_loss did not improve from 1.25971
Epoch 2316/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4334 - val_loss: 1.2662 - val_accuracy: 0.4279

Epoch 02316: val_loss did not improve from 1.25971
Epoch 2317/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4343 - val_loss: 1.2648 - val_accuracy: 0.4215

Epoch 02317: val_loss did not improve from 1.25971
Epoch 2318/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4341 - val_loss: 1.2642 - val_accuracy: 0.4223

Epoch 02318: val_loss did not improve from 1.25971
Epoch 2319/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4325 - val_loss: 1.2660 - val_accuracy: 0.4215

Epoch 02319: val_loss did not improve from 1.25971
Epoch 2320/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4320 - val_loss: 1.2667 - val_accuracy: 0.4255

Epoch 02320: val_loss did not improve from 1.25971
Epoch 2321/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4305 - val_loss: 1.2608 - val_accuracy: 0.4271

Epoch 02321: val_loss did not improve from 1.25971
Epoch 2322/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4345 - val_loss: 1.2612 - val_accuracy: 0.4343

Epoch 02322: val_loss did not improve from 1.25971
Epoch 2323/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4292 - val_loss: 1.2633 - val_accuracy: 0.4215

Epoch 02323: val_loss did not improve from 1.25971
Epoch 2324/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4291 - val_loss: 1.2636 - val_accuracy: 0.4223

Epoch 02324: val_loss did not improve from 1.25971
Epoch 2325/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4337 - val_loss: 1.2683 - val_accuracy: 0.4215

Epoch 02325: val_loss did not improve from 1.25971
Epoch 2326/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4339 - val_loss: 1.2618 - val_accuracy: 0.4215

Epoch 02326: val_loss did not improve from 1.25971
Epoch 2327/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4324 - val_loss: 1.2707 - val_accuracy: 0.4287

Epoch 02327: val_loss did not improve from 1.25971
Epoch 2328/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4343 - val_loss: 1.2656 - val_accuracy: 0.4231

Epoch 02328: val_loss did not improve from 1.25971
Epoch 2329/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4368 - val_loss: 1.2654 - val_accuracy: 0.4167

Epoch 02329: val_loss did not improve from 1.25971
Epoch 2330/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4348 - val_loss: 1.2639 - val_accuracy: 0.4327

Epoch 02330: val_loss did not improve from 1.25971
Epoch 2331/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4336 - val_loss: 1.2654 - val_accuracy: 0.4359

Epoch 02331: val_loss did not improve from 1.25971
Epoch 2332/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4281 - val_loss: 1.2668 - val_accuracy: 0.4223

Epoch 02332: val_loss did not improve from 1.25971
Epoch 2333/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4257 - val_loss: 1.2615 - val_accuracy: 0.4303

Epoch 02333: val_loss did not improve from 1.25971
Epoch 2334/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4311 - val_loss: 1.2797 - val_accuracy: 0.4120

Epoch 02334: val_loss did not improve from 1.25971
Epoch 2335/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4323 - val_loss: 1.2675 - val_accuracy: 0.4120

Epoch 02335: val_loss did not improve from 1.25971
Epoch 2336/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4352 - val_loss: 1.2635 - val_accuracy: 0.4239

Epoch 02336: val_loss did not improve from 1.25971
Epoch 2337/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4320 - val_loss: 1.2654 - val_accuracy: 0.4279

Epoch 02337: val_loss did not improve from 1.25971
Epoch 2338/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4296 - val_loss: 1.2611 - val_accuracy: 0.4223

Epoch 02338: val_loss did not improve from 1.25971
Epoch 2339/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4341 - val_loss: 1.2690 - val_accuracy: 0.4120

Epoch 02339: val_loss did not improve from 1.25971
Epoch 2340/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4367 - val_loss: 1.2672 - val_accuracy: 0.4167

Epoch 02340: val_loss did not improve from 1.25971
Epoch 2341/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4349 - val_loss: 1.2638 - val_accuracy: 0.4215

Epoch 02341: val_loss did not improve from 1.25971
Epoch 2342/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4337 - val_loss: 1.2662 - val_accuracy: 0.4191

Epoch 02342: val_loss did not improve from 1.25971
Epoch 2343/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4290 - val_loss: 1.2660 - val_accuracy: 0.4295

Epoch 02343: val_loss did not improve from 1.25971
Epoch 2344/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4291 - val_loss: 1.2639 - val_accuracy: 0.4231

Epoch 02344: val_loss did not improve from 1.25971
Epoch 2345/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4313 - val_loss: 1.2630 - val_accuracy: 0.4319

Epoch 02345: val_loss did not improve from 1.25971
Epoch 2346/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4321 - val_loss: 1.2659 - val_accuracy: 0.4319

Epoch 02346: val_loss did not improve from 1.25971
Epoch 2347/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4314 - val_loss: 1.2651 - val_accuracy: 0.4231

Epoch 02347: val_loss did not improve from 1.25971
Epoch 2348/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4322 - val_loss: 1.2656 - val_accuracy: 0.4343

Epoch 02348: val_loss did not improve from 1.25971
Epoch 2349/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4338 - val_loss: 1.2641 - val_accuracy: 0.4247

Epoch 02349: val_loss did not improve from 1.25971
Epoch 2350/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4313 - val_loss: 1.2630 - val_accuracy: 0.4175

Epoch 02350: val_loss did not improve from 1.25971
Epoch 2351/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4272 - val_loss: 1.2687 - val_accuracy: 0.4279

Epoch 02351: val_loss did not improve from 1.25971
Epoch 2352/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4305 - val_loss: 1.2597 - val_accuracy: 0.4414

Epoch 02352: val_loss did not improve from 1.25971
Epoch 2353/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4316 - val_loss: 1.2655 - val_accuracy: 0.4167

Epoch 02353: val_loss did not improve from 1.25971
Epoch 2354/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4340 - val_loss: 1.2606 - val_accuracy: 0.4287

Epoch 02354: val_loss did not improve from 1.25971
Epoch 2355/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4337 - val_loss: 1.2618 - val_accuracy: 0.4183

Epoch 02355: val_loss did not improve from 1.25971
Epoch 2356/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4345 - val_loss: 1.2646 - val_accuracy: 0.4183

Epoch 02356: val_loss did not improve from 1.25971
Epoch 2357/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4350 - val_loss: 1.2680 - val_accuracy: 0.4167

Epoch 02357: val_loss did not improve from 1.25971
Epoch 2358/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4301 - val_loss: 1.2606 - val_accuracy: 0.4319

Epoch 02358: val_loss did not improve from 1.25971
Epoch 2359/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4338 - val_loss: 1.2628 - val_accuracy: 0.4311

Epoch 02359: val_loss did not improve from 1.25971
Epoch 2360/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4343 - val_loss: 1.2658 - val_accuracy: 0.4151

Epoch 02360: val_loss did not improve from 1.25971
Epoch 2361/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4348 - val_loss: 1.2636 - val_accuracy: 0.4311

Epoch 02361: val_loss did not improve from 1.25971
Epoch 2362/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4357 - val_loss: 1.2652 - val_accuracy: 0.4271

Epoch 02362: val_loss did not improve from 1.25971
Epoch 2363/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4307 - val_loss: 1.2628 - val_accuracy: 0.4239

Epoch 02363: val_loss did not improve from 1.25971
Epoch 2364/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4320 - val_loss: 1.2634 - val_accuracy: 0.4199

Epoch 02364: val_loss did not improve from 1.25971
Epoch 2365/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4329 - val_loss: 1.2666 - val_accuracy: 0.4231

Epoch 02365: val_loss did not improve from 1.25971
Epoch 2366/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4310 - val_loss: 1.2595 - val_accuracy: 0.4335

Epoch 02366: val_loss improved from 1.25971 to 1.25946, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2367/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4319 - val_loss: 1.2695 - val_accuracy: 0.4191

Epoch 02367: val_loss did not improve from 1.25946
Epoch 2368/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4347 - val_loss: 1.2663 - val_accuracy: 0.4247

Epoch 02368: val_loss did not improve from 1.25946
Epoch 2369/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4310 - val_loss: 1.2664 - val_accuracy: 0.4239

Epoch 02369: val_loss did not improve from 1.25946
Epoch 2370/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4353 - val_loss: 1.2630 - val_accuracy: 0.4167

Epoch 02370: val_loss did not improve from 1.25946
Epoch 2371/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4372 - val_loss: 1.2623 - val_accuracy: 0.4183

Epoch 02371: val_loss did not improve from 1.25946
Epoch 2372/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4366 - val_loss: 1.2609 - val_accuracy: 0.4271

Epoch 02372: val_loss did not improve from 1.25946
Epoch 2373/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4329 - val_loss: 1.2618 - val_accuracy: 0.4279

Epoch 02373: val_loss did not improve from 1.25946
Epoch 2374/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4314 - val_loss: 1.2664 - val_accuracy: 0.4207

Epoch 02374: val_loss did not improve from 1.25946
Epoch 2375/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4379 - val_loss: 1.2662 - val_accuracy: 0.4271

Epoch 02375: val_loss did not improve from 1.25946
Epoch 2376/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4279 - val_loss: 1.2624 - val_accuracy: 0.4207

Epoch 02376: val_loss did not improve from 1.25946
Epoch 2377/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4334 - val_loss: 1.2725 - val_accuracy: 0.4207

Epoch 02377: val_loss did not improve from 1.25946
Epoch 2378/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4317 - val_loss: 1.2598 - val_accuracy: 0.4335

Epoch 02378: val_loss did not improve from 1.25946
Epoch 2379/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4347 - val_loss: 1.2641 - val_accuracy: 0.4231

Epoch 02379: val_loss did not improve from 1.25946
Epoch 2380/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4294 - val_loss: 1.2668 - val_accuracy: 0.4231

Epoch 02380: val_loss did not improve from 1.25946
Epoch 2381/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4364 - val_loss: 1.2659 - val_accuracy: 0.4207

Epoch 02381: val_loss did not improve from 1.25946
Epoch 2382/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4357 - val_loss: 1.2630 - val_accuracy: 0.4247

Epoch 02382: val_loss did not improve from 1.25946
Epoch 2383/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4326 - val_loss: 1.2647 - val_accuracy: 0.4231

Epoch 02383: val_loss did not improve from 1.25946
Epoch 2384/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4297 - val_loss: 1.2630 - val_accuracy: 0.4279

Epoch 02384: val_loss did not improve from 1.25946
Epoch 2385/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4324 - val_loss: 1.2658 - val_accuracy: 0.4247

Epoch 02385: val_loss did not improve from 1.25946
Epoch 2386/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4284 - val_loss: 1.2671 - val_accuracy: 0.4199

Epoch 02386: val_loss did not improve from 1.25946
Epoch 2387/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4325 - val_loss: 1.2653 - val_accuracy: 0.4183

Epoch 02387: val_loss did not improve from 1.25946
Epoch 2388/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4304 - val_loss: 1.2639 - val_accuracy: 0.4287

Epoch 02388: val_loss did not improve from 1.25946
Epoch 2389/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4342 - val_loss: 1.2606 - val_accuracy: 0.4263

Epoch 02389: val_loss did not improve from 1.25946
Epoch 2390/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4356 - val_loss: 1.2593 - val_accuracy: 0.4263

Epoch 02390: val_loss improved from 1.25946 to 1.25934, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2391/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4344 - val_loss: 1.2621 - val_accuracy: 0.4255

Epoch 02391: val_loss did not improve from 1.25934
Epoch 2392/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4360 - val_loss: 1.2620 - val_accuracy: 0.4191

Epoch 02392: val_loss did not improve from 1.25934
Epoch 2393/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4302 - val_loss: 1.2744 - val_accuracy: 0.4167

Epoch 02393: val_loss did not improve from 1.25934
Epoch 2394/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4272 - val_loss: 1.2657 - val_accuracy: 0.4247

Epoch 02394: val_loss did not improve from 1.25934
Epoch 2395/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4327 - val_loss: 1.2623 - val_accuracy: 0.4311

Epoch 02395: val_loss did not improve from 1.25934
Epoch 2396/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4323 - val_loss: 1.2660 - val_accuracy: 0.4335

Epoch 02396: val_loss did not improve from 1.25934
Epoch 2397/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4312 - val_loss: 1.2679 - val_accuracy: 0.4279

Epoch 02397: val_loss did not improve from 1.25934
Epoch 2398/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4338 - val_loss: 1.2600 - val_accuracy: 0.4151

Epoch 02398: val_loss did not improve from 1.25934
Epoch 2399/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4342 - val_loss: 1.2614 - val_accuracy: 0.4327

Epoch 02399: val_loss did not improve from 1.25934
Epoch 2400/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4370 - val_loss: 1.2623 - val_accuracy: 0.4271

Epoch 02400: val_loss did not improve from 1.25934
Epoch 2401/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4356 - val_loss: 1.2614 - val_accuracy: 0.4183

Epoch 02401: val_loss did not improve from 1.25934
Epoch 2402/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4327 - val_loss: 1.2648 - val_accuracy: 0.4223

Epoch 02402: val_loss did not improve from 1.25934
Epoch 2403/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4359 - val_loss: 1.2708 - val_accuracy: 0.4175

Epoch 02403: val_loss did not improve from 1.25934
Epoch 2404/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4283 - val_loss: 1.2650 - val_accuracy: 0.4311

Epoch 02404: val_loss did not improve from 1.25934
Epoch 2405/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4337 - val_loss: 1.2614 - val_accuracy: 0.4367

Epoch 02405: val_loss did not improve from 1.25934
Epoch 2406/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4331 - val_loss: 1.2604 - val_accuracy: 0.4239

Epoch 02406: val_loss did not improve from 1.25934
Epoch 2407/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4366 - val_loss: 1.2654 - val_accuracy: 0.4223

Epoch 02407: val_loss did not improve from 1.25934
Epoch 2408/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4322 - val_loss: 1.2663 - val_accuracy: 0.4247

Epoch 02408: val_loss did not improve from 1.25934
Epoch 2409/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4348 - val_loss: 1.2690 - val_accuracy: 0.4183

Epoch 02409: val_loss did not improve from 1.25934
Epoch 2410/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4358 - val_loss: 1.2604 - val_accuracy: 0.4207

Epoch 02410: val_loss did not improve from 1.25934
Epoch 2411/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4305 - val_loss: 1.2668 - val_accuracy: 0.4191

Epoch 02411: val_loss did not improve from 1.25934
Epoch 2412/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4329 - val_loss: 1.2627 - val_accuracy: 0.4183

Epoch 02412: val_loss did not improve from 1.25934
Epoch 2413/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4341 - val_loss: 1.2622 - val_accuracy: 0.4231

Epoch 02413: val_loss did not improve from 1.25934
Epoch 2414/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4315 - val_loss: 1.2718 - val_accuracy: 0.4191

Epoch 02414: val_loss did not improve from 1.25934
Epoch 2415/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4319 - val_loss: 1.2675 - val_accuracy: 0.4295

Epoch 02415: val_loss did not improve from 1.25934
Epoch 2416/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4296 - val_loss: 1.2628 - val_accuracy: 0.4263

Epoch 02416: val_loss did not improve from 1.25934
Epoch 2417/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4345 - val_loss: 1.2648 - val_accuracy: 0.4215

Epoch 02417: val_loss did not improve from 1.25934
Epoch 2418/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4344 - val_loss: 1.2685 - val_accuracy: 0.4088

Epoch 02418: val_loss did not improve from 1.25934
Epoch 2419/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4335 - val_loss: 1.2677 - val_accuracy: 0.4247

Epoch 02419: val_loss did not improve from 1.25934
Epoch 2420/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4301 - val_loss: 1.2857 - val_accuracy: 0.4056

Epoch 02420: val_loss did not improve from 1.25934
Epoch 2421/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4263 - val_loss: 1.2639 - val_accuracy: 0.4406

Epoch 02421: val_loss did not improve from 1.25934
Epoch 2422/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4269 - val_loss: 1.2621 - val_accuracy: 0.4295

Epoch 02422: val_loss did not improve from 1.25934
Epoch 2423/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4334 - val_loss: 1.2664 - val_accuracy: 0.4183

Epoch 02423: val_loss did not improve from 1.25934
Epoch 2424/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4315 - val_loss: 1.2670 - val_accuracy: 0.4159

Epoch 02424: val_loss did not improve from 1.25934
Epoch 2425/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4349 - val_loss: 1.2616 - val_accuracy: 0.4295

Epoch 02425: val_loss did not improve from 1.25934
Epoch 2426/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4264 - val_loss: 1.2659 - val_accuracy: 0.4199

Epoch 02426: val_loss did not improve from 1.25934
Epoch 2427/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4326 - val_loss: 1.2628 - val_accuracy: 0.4319

Epoch 02427: val_loss did not improve from 1.25934
Epoch 2428/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4326 - val_loss: 1.2624 - val_accuracy: 0.4327

Epoch 02428: val_loss did not improve from 1.25934
Epoch 2429/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4349 - val_loss: 1.2660 - val_accuracy: 0.4279

Epoch 02429: val_loss did not improve from 1.25934
Epoch 2430/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4318 - val_loss: 1.2624 - val_accuracy: 0.4271

Epoch 02430: val_loss did not improve from 1.25934
Epoch 2431/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4313 - val_loss: 1.2606 - val_accuracy: 0.4359

Epoch 02431: val_loss did not improve from 1.25934
Epoch 2432/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4349 - val_loss: 1.2629 - val_accuracy: 0.4207

Epoch 02432: val_loss did not improve from 1.25934
Epoch 2433/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4340 - val_loss: 1.2670 - val_accuracy: 0.4175

Epoch 02433: val_loss did not improve from 1.25934
Epoch 2434/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4337 - val_loss: 1.2712 - val_accuracy: 0.4199

Epoch 02434: val_loss did not improve from 1.25934
Epoch 2435/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4329 - val_loss: 1.2668 - val_accuracy: 0.4279

Epoch 02435: val_loss did not improve from 1.25934
Epoch 2436/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4345 - val_loss: 1.2669 - val_accuracy: 0.4279

Epoch 02436: val_loss did not improve from 1.25934
Epoch 2437/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4342 - val_loss: 1.2673 - val_accuracy: 0.4231

Epoch 02437: val_loss did not improve from 1.25934
Epoch 2438/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4356 - val_loss: 1.2673 - val_accuracy: 0.4231

Epoch 02438: val_loss did not improve from 1.25934
Epoch 2439/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4329 - val_loss: 1.2691 - val_accuracy: 0.4175

Epoch 02439: val_loss did not improve from 1.25934
Epoch 2440/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4315 - val_loss: 1.2645 - val_accuracy: 0.4215

Epoch 02440: val_loss did not improve from 1.25934
Epoch 2441/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4338 - val_loss: 1.2600 - val_accuracy: 0.4343

Epoch 02441: val_loss did not improve from 1.25934
Epoch 2442/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4328 - val_loss: 1.2720 - val_accuracy: 0.4191

Epoch 02442: val_loss did not improve from 1.25934
Epoch 2443/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4291 - val_loss: 1.2619 - val_accuracy: 0.4327

Epoch 02443: val_loss did not improve from 1.25934
Epoch 2444/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4318 - val_loss: 1.2611 - val_accuracy: 0.4311

Epoch 02444: val_loss did not improve from 1.25934
Epoch 2445/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4351 - val_loss: 1.2615 - val_accuracy: 0.4406

Epoch 02445: val_loss did not improve from 1.25934
Epoch 2446/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4342 - val_loss: 1.2618 - val_accuracy: 0.4207

Epoch 02446: val_loss did not improve from 1.25934
Epoch 2447/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4340 - val_loss: 1.2707 - val_accuracy: 0.4191

Epoch 02447: val_loss did not improve from 1.25934
Epoch 2448/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4285 - val_loss: 1.2617 - val_accuracy: 0.4199

Epoch 02448: val_loss did not improve from 1.25934
Epoch 2449/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4324 - val_loss: 1.2595 - val_accuracy: 0.4343

Epoch 02449: val_loss did not improve from 1.25934
Epoch 2450/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4328 - val_loss: 1.2630 - val_accuracy: 0.4183

Epoch 02450: val_loss did not improve from 1.25934
Epoch 2451/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4341 - val_loss: 1.2623 - val_accuracy: 0.4303

Epoch 02451: val_loss did not improve from 1.25934
Epoch 2452/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4329 - val_loss: 1.2603 - val_accuracy: 0.4319

Epoch 02452: val_loss did not improve from 1.25934
Epoch 2453/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4304 - val_loss: 1.2695 - val_accuracy: 0.4167

Epoch 02453: val_loss did not improve from 1.25934
Epoch 2454/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4306 - val_loss: 1.2609 - val_accuracy: 0.4359

Epoch 02454: val_loss did not improve from 1.25934
Epoch 2455/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4333 - val_loss: 1.2627 - val_accuracy: 0.4207

Epoch 02455: val_loss did not improve from 1.25934
Epoch 2456/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4360 - val_loss: 1.2631 - val_accuracy: 0.4231

Epoch 02456: val_loss did not improve from 1.25934
Epoch 2457/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4319 - val_loss: 1.2621 - val_accuracy: 0.4279

Epoch 02457: val_loss did not improve from 1.25934
Epoch 2458/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4290 - val_loss: 1.2617 - val_accuracy: 0.4271

Epoch 02458: val_loss did not improve from 1.25934
Epoch 2459/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4254 - val_loss: 1.2748 - val_accuracy: 0.4199

Epoch 02459: val_loss did not improve from 1.25934
Epoch 2460/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4245 - val_loss: 1.2623 - val_accuracy: 0.4311

Epoch 02460: val_loss did not improve from 1.25934
Epoch 2461/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4352 - val_loss: 1.2615 - val_accuracy: 0.4271

Epoch 02461: val_loss did not improve from 1.25934
Epoch 2462/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4386 - val_loss: 1.2615 - val_accuracy: 0.4215

Epoch 02462: val_loss did not improve from 1.25934
Epoch 2463/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4302 - val_loss: 1.2615 - val_accuracy: 0.4287

Epoch 02463: val_loss did not improve from 1.25934
Epoch 2464/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4293 - val_loss: 1.2649 - val_accuracy: 0.4239

Epoch 02464: val_loss did not improve from 1.25934
Epoch 2465/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4293 - val_loss: 1.2661 - val_accuracy: 0.4263

Epoch 02465: val_loss did not improve from 1.25934
Epoch 2466/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4295 - val_loss: 1.2607 - val_accuracy: 0.4390

Epoch 02466: val_loss did not improve from 1.25934
Epoch 2467/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4329 - val_loss: 1.2689 - val_accuracy: 0.4223

Epoch 02467: val_loss did not improve from 1.25934
Epoch 2468/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4268 - val_loss: 1.2630 - val_accuracy: 0.4175

Epoch 02468: val_loss did not improve from 1.25934
Epoch 2469/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4254 - val_loss: 1.2612 - val_accuracy: 0.4367

Epoch 02469: val_loss did not improve from 1.25934
Epoch 2470/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4352 - val_loss: 1.2671 - val_accuracy: 0.4247

Epoch 02470: val_loss did not improve from 1.25934
Epoch 2471/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4369 - val_loss: 1.2620 - val_accuracy: 0.4175

Epoch 02471: val_loss did not improve from 1.25934
Epoch 2472/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4317 - val_loss: 1.2612 - val_accuracy: 0.4199

Epoch 02472: val_loss did not improve from 1.25934
Epoch 2473/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4292 - val_loss: 1.2669 - val_accuracy: 0.4207

Epoch 02473: val_loss did not improve from 1.25934
Epoch 2474/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4301 - val_loss: 1.2654 - val_accuracy: 0.4303

Epoch 02474: val_loss did not improve from 1.25934
Epoch 2475/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4360 - val_loss: 1.2725 - val_accuracy: 0.4279

Epoch 02475: val_loss did not improve from 1.25934
Epoch 2476/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4316 - val_loss: 1.2637 - val_accuracy: 0.4279

Epoch 02476: val_loss did not improve from 1.25934
Epoch 2477/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4319 - val_loss: 1.2622 - val_accuracy: 0.4319

Epoch 02477: val_loss did not improve from 1.25934
Epoch 2478/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4324 - val_loss: 1.2597 - val_accuracy: 0.4359

Epoch 02478: val_loss did not improve from 1.25934
Epoch 2479/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4355 - val_loss: 1.2657 - val_accuracy: 0.4335

Epoch 02479: val_loss did not improve from 1.25934
Epoch 2480/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4340 - val_loss: 1.2647 - val_accuracy: 0.4223

Epoch 02480: val_loss did not improve from 1.25934
Epoch 2481/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4353 - val_loss: 1.2732 - val_accuracy: 0.4183

Epoch 02481: val_loss did not improve from 1.25934
Epoch 2482/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4323 - val_loss: 1.2674 - val_accuracy: 0.4183

Epoch 02482: val_loss did not improve from 1.25934
Epoch 2483/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4252 - val_loss: 1.2647 - val_accuracy: 0.4231

Epoch 02483: val_loss did not improve from 1.25934
Epoch 2484/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4283 - val_loss: 1.2634 - val_accuracy: 0.4247

Epoch 02484: val_loss did not improve from 1.25934
Epoch 2485/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4329 - val_loss: 1.2631 - val_accuracy: 0.4279

Epoch 02485: val_loss did not improve from 1.25934
Epoch 2486/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4367 - val_loss: 1.2658 - val_accuracy: 0.4279

Epoch 02486: val_loss did not improve from 1.25934
Epoch 2487/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4332 - val_loss: 1.2602 - val_accuracy: 0.4231

Epoch 02487: val_loss did not improve from 1.25934
Epoch 2488/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4345 - val_loss: 1.2606 - val_accuracy: 0.4303

Epoch 02488: val_loss did not improve from 1.25934
Epoch 2489/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4326 - val_loss: 1.2603 - val_accuracy: 0.4271

Epoch 02489: val_loss did not improve from 1.25934
Epoch 2490/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4339 - val_loss: 1.2705 - val_accuracy: 0.4167

Epoch 02490: val_loss did not improve from 1.25934
Epoch 2491/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4268 - val_loss: 1.2595 - val_accuracy: 0.4239

Epoch 02491: val_loss did not improve from 1.25934
Epoch 2492/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4327 - val_loss: 1.2623 - val_accuracy: 0.4295

Epoch 02492: val_loss did not improve from 1.25934
Epoch 2493/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4351 - val_loss: 1.2621 - val_accuracy: 0.4303

Epoch 02493: val_loss did not improve from 1.25934
Epoch 2494/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4352 - val_loss: 1.2666 - val_accuracy: 0.4207

Epoch 02494: val_loss did not improve from 1.25934
Epoch 2495/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4342 - val_loss: 1.2597 - val_accuracy: 0.4279

Epoch 02495: val_loss did not improve from 1.25934
Epoch 2496/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4357 - val_loss: 1.2669 - val_accuracy: 0.4207

Epoch 02496: val_loss did not improve from 1.25934
Epoch 2497/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4327 - val_loss: 1.2619 - val_accuracy: 0.4271

Epoch 02497: val_loss did not improve from 1.25934
Epoch 2498/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4319 - val_loss: 1.2621 - val_accuracy: 0.4335

Epoch 02498: val_loss did not improve from 1.25934
Epoch 2499/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4319 - val_loss: 1.2688 - val_accuracy: 0.4191

Epoch 02499: val_loss did not improve from 1.25934
Epoch 2500/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4353 - val_loss: 1.2612 - val_accuracy: 0.4247

Epoch 02500: val_loss did not improve from 1.25934
Epoch 2501/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4337 - val_loss: 1.2634 - val_accuracy: 0.4287

Epoch 02501: val_loss did not improve from 1.25934
Epoch 2502/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4349 - val_loss: 1.2636 - val_accuracy: 0.4231

Epoch 02502: val_loss did not improve from 1.25934
Epoch 2503/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4337 - val_loss: 1.2645 - val_accuracy: 0.4247

Epoch 02503: val_loss did not improve from 1.25934
Epoch 2504/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4346 - val_loss: 1.2641 - val_accuracy: 0.4223

Epoch 02504: val_loss did not improve from 1.25934
Epoch 2505/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4242 - val_loss: 1.2774 - val_accuracy: 0.4143

Epoch 02505: val_loss did not improve from 1.25934
Epoch 2506/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4324 - val_loss: 1.2670 - val_accuracy: 0.4175

Epoch 02506: val_loss did not improve from 1.25934
Epoch 2507/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4314 - val_loss: 1.2625 - val_accuracy: 0.4382

Epoch 02507: val_loss did not improve from 1.25934
Epoch 2508/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4333 - val_loss: 1.2607 - val_accuracy: 0.4231

Epoch 02508: val_loss did not improve from 1.25934
Epoch 2509/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4355 - val_loss: 1.2638 - val_accuracy: 0.4319

Epoch 02509: val_loss did not improve from 1.25934
Epoch 2510/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4316 - val_loss: 1.2671 - val_accuracy: 0.4231

Epoch 02510: val_loss did not improve from 1.25934
Epoch 2511/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4331 - val_loss: 1.2638 - val_accuracy: 0.4367

Epoch 02511: val_loss did not improve from 1.25934
Epoch 2512/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4345 - val_loss: 1.2621 - val_accuracy: 0.4295

Epoch 02512: val_loss did not improve from 1.25934
Epoch 2513/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4352 - val_loss: 1.2638 - val_accuracy: 0.4247

Epoch 02513: val_loss did not improve from 1.25934
Epoch 2514/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4337 - val_loss: 1.2679 - val_accuracy: 0.4167

Epoch 02514: val_loss did not improve from 1.25934
Epoch 2515/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4314 - val_loss: 1.2611 - val_accuracy: 0.4183

Epoch 02515: val_loss did not improve from 1.25934
Epoch 2516/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4315 - val_loss: 1.2622 - val_accuracy: 0.4303

Epoch 02516: val_loss did not improve from 1.25934
Epoch 2517/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4322 - val_loss: 1.2622 - val_accuracy: 0.4327

Epoch 02517: val_loss did not improve from 1.25934
Epoch 2518/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4367 - val_loss: 1.2641 - val_accuracy: 0.4239

Epoch 02518: val_loss did not improve from 1.25934
Epoch 2519/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4336 - val_loss: 1.2674 - val_accuracy: 0.4183

Epoch 02519: val_loss did not improve from 1.25934
Epoch 2520/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4285 - val_loss: 1.2627 - val_accuracy: 0.4215

Epoch 02520: val_loss did not improve from 1.25934
Epoch 2521/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4342 - val_loss: 1.2634 - val_accuracy: 0.4255

Epoch 02521: val_loss did not improve from 1.25934
Epoch 2522/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4317 - val_loss: 1.2638 - val_accuracy: 0.4279

Epoch 02522: val_loss did not improve from 1.25934
Epoch 2523/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4332 - val_loss: 1.2600 - val_accuracy: 0.4271

Epoch 02523: val_loss did not improve from 1.25934
Epoch 2524/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4314 - val_loss: 1.2587 - val_accuracy: 0.4263

Epoch 02524: val_loss improved from 1.25934 to 1.25874, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2525/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4365 - val_loss: 1.2656 - val_accuracy: 0.4263

Epoch 02525: val_loss did not improve from 1.25874
Epoch 2526/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4357 - val_loss: 1.2673 - val_accuracy: 0.4167

Epoch 02526: val_loss did not improve from 1.25874
Epoch 2527/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4321 - val_loss: 1.2634 - val_accuracy: 0.4207

Epoch 02527: val_loss did not improve from 1.25874
Epoch 2528/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4326 - val_loss: 1.2658 - val_accuracy: 0.4175

Epoch 02528: val_loss did not improve from 1.25874
Epoch 2529/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4330 - val_loss: 1.2628 - val_accuracy: 0.4247

Epoch 02529: val_loss did not improve from 1.25874
Epoch 2530/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4339 - val_loss: 1.2667 - val_accuracy: 0.4271

Epoch 02530: val_loss did not improve from 1.25874
Epoch 2531/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4365 - val_loss: 1.2602 - val_accuracy: 0.4287

Epoch 02531: val_loss did not improve from 1.25874
Epoch 2532/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4326 - val_loss: 1.2606 - val_accuracy: 0.4287

Epoch 02532: val_loss did not improve from 1.25874
Epoch 2533/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4324 - val_loss: 1.2654 - val_accuracy: 0.4287

Epoch 02533: val_loss did not improve from 1.25874
Epoch 2534/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4345 - val_loss: 1.2643 - val_accuracy: 0.4311

Epoch 02534: val_loss did not improve from 1.25874
Epoch 2535/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4384 - val_loss: 1.2620 - val_accuracy: 0.4343

Epoch 02535: val_loss did not improve from 1.25874
Epoch 2536/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4312 - val_loss: 1.2625 - val_accuracy: 0.4239

Epoch 02536: val_loss did not improve from 1.25874
Epoch 2537/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4348 - val_loss: 1.2673 - val_accuracy: 0.4183

Epoch 02537: val_loss did not improve from 1.25874
Epoch 2538/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4334 - val_loss: 1.2623 - val_accuracy: 0.4271

Epoch 02538: val_loss did not improve from 1.25874
Epoch 2539/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4346 - val_loss: 1.2602 - val_accuracy: 0.4255

Epoch 02539: val_loss did not improve from 1.25874
Epoch 2540/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4296 - val_loss: 1.2603 - val_accuracy: 0.4311

Epoch 02540: val_loss did not improve from 1.25874
Epoch 2541/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4351 - val_loss: 1.2603 - val_accuracy: 0.4271

Epoch 02541: val_loss did not improve from 1.25874
Epoch 2542/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4305 - val_loss: 1.2702 - val_accuracy: 0.4199

Epoch 02542: val_loss did not improve from 1.25874
Epoch 2543/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4305 - val_loss: 1.2651 - val_accuracy: 0.4295

Epoch 02543: val_loss did not improve from 1.25874
Epoch 2544/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4323 - val_loss: 1.2665 - val_accuracy: 0.4287

Epoch 02544: val_loss did not improve from 1.25874
Epoch 2545/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4334 - val_loss: 1.2629 - val_accuracy: 0.4335

Epoch 02545: val_loss did not improve from 1.25874
Epoch 2546/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4317 - val_loss: 1.2620 - val_accuracy: 0.4311

Epoch 02546: val_loss did not improve from 1.25874
Epoch 2547/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4341 - val_loss: 1.2669 - val_accuracy: 0.4279

Epoch 02547: val_loss did not improve from 1.25874
Epoch 2548/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4331 - val_loss: 1.2626 - val_accuracy: 0.4263

Epoch 02548: val_loss did not improve from 1.25874
Epoch 2549/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4335 - val_loss: 1.2582 - val_accuracy: 0.4271

Epoch 02549: val_loss improved from 1.25874 to 1.25819, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2550/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4329 - val_loss: 1.2597 - val_accuracy: 0.4327

Epoch 02550: val_loss did not improve from 1.25819
Epoch 2551/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4292 - val_loss: 1.2665 - val_accuracy: 0.4215

Epoch 02551: val_loss did not improve from 1.25819
Epoch 2552/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4326 - val_loss: 1.2653 - val_accuracy: 0.4271

Epoch 02552: val_loss did not improve from 1.25819
Epoch 2553/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4265 - val_loss: 1.2665 - val_accuracy: 0.4183

Epoch 02553: val_loss did not improve from 1.25819
Epoch 2554/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4282 - val_loss: 1.2640 - val_accuracy: 0.4199

Epoch 02554: val_loss did not improve from 1.25819
Epoch 2555/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4322 - val_loss: 1.2658 - val_accuracy: 0.4167

Epoch 02555: val_loss did not improve from 1.25819
Epoch 2556/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4344 - val_loss: 1.2700 - val_accuracy: 0.4207

Epoch 02556: val_loss did not improve from 1.25819
Epoch 2557/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4369 - val_loss: 1.2585 - val_accuracy: 0.4223

Epoch 02557: val_loss did not improve from 1.25819
Epoch 2558/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4340 - val_loss: 1.2618 - val_accuracy: 0.4311

Epoch 02558: val_loss did not improve from 1.25819
Epoch 2559/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4344 - val_loss: 1.2617 - val_accuracy: 0.4279

Epoch 02559: val_loss did not improve from 1.25819
Epoch 2560/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4311 - val_loss: 1.2606 - val_accuracy: 0.4223

Epoch 02560: val_loss did not improve from 1.25819
Epoch 2561/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4322 - val_loss: 1.2649 - val_accuracy: 0.4199

Epoch 02561: val_loss did not improve from 1.25819
Epoch 2562/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4348 - val_loss: 1.2630 - val_accuracy: 0.4223

Epoch 02562: val_loss did not improve from 1.25819
Epoch 2563/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4348 - val_loss: 1.2624 - val_accuracy: 0.4247

Epoch 02563: val_loss did not improve from 1.25819
Epoch 2564/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4353 - val_loss: 1.2636 - val_accuracy: 0.4207

Epoch 02564: val_loss did not improve from 1.25819
Epoch 2565/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4355 - val_loss: 1.2633 - val_accuracy: 0.4175

Epoch 02565: val_loss did not improve from 1.25819
Epoch 2566/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4352 - val_loss: 1.2682 - val_accuracy: 0.4287

Epoch 02566: val_loss did not improve from 1.25819
Epoch 2567/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4341 - val_loss: 1.2616 - val_accuracy: 0.4207

Epoch 02567: val_loss did not improve from 1.25819
Epoch 2568/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4337 - val_loss: 1.2594 - val_accuracy: 0.4382

Epoch 02568: val_loss did not improve from 1.25819
Epoch 2569/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4340 - val_loss: 1.2588 - val_accuracy: 0.4406

Epoch 02569: val_loss did not improve from 1.25819
Epoch 2570/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4301 - val_loss: 1.2584 - val_accuracy: 0.4303

Epoch 02570: val_loss did not improve from 1.25819
Epoch 2571/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4317 - val_loss: 1.2654 - val_accuracy: 0.4287

Epoch 02571: val_loss did not improve from 1.25819
Epoch 2572/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4330 - val_loss: 1.2623 - val_accuracy: 0.4231

Epoch 02572: val_loss did not improve from 1.25819
Epoch 2573/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4314 - val_loss: 1.2612 - val_accuracy: 0.4279

Epoch 02573: val_loss did not improve from 1.25819
Epoch 2574/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4306 - val_loss: 1.2756 - val_accuracy: 0.4175

Epoch 02574: val_loss did not improve from 1.25819
Epoch 2575/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4288 - val_loss: 1.2595 - val_accuracy: 0.4311

Epoch 02575: val_loss did not improve from 1.25819
Epoch 2576/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4322 - val_loss: 1.2672 - val_accuracy: 0.4359

Epoch 02576: val_loss did not improve from 1.25819
Epoch 2577/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4340 - val_loss: 1.2599 - val_accuracy: 0.4311

Epoch 02577: val_loss did not improve from 1.25819
Epoch 2578/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4337 - val_loss: 1.2693 - val_accuracy: 0.4271

Epoch 02578: val_loss did not improve from 1.25819
Epoch 2579/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4342 - val_loss: 1.2588 - val_accuracy: 0.4247

Epoch 02579: val_loss did not improve from 1.25819
Epoch 2580/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4315 - val_loss: 1.2618 - val_accuracy: 0.4327

Epoch 02580: val_loss did not improve from 1.25819
Epoch 2581/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4365 - val_loss: 1.2633 - val_accuracy: 0.4263

Epoch 02581: val_loss did not improve from 1.25819
Epoch 2582/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4348 - val_loss: 1.2582 - val_accuracy: 0.4271

Epoch 02582: val_loss did not improve from 1.25819
Epoch 2583/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4302 - val_loss: 1.2609 - val_accuracy: 0.4303

Epoch 02583: val_loss did not improve from 1.25819
Epoch 2584/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4325 - val_loss: 1.2637 - val_accuracy: 0.4343

Epoch 02584: val_loss did not improve from 1.25819
Epoch 2585/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4357 - val_loss: 1.2648 - val_accuracy: 0.4223

Epoch 02585: val_loss did not improve from 1.25819
Epoch 2586/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4360 - val_loss: 1.2626 - val_accuracy: 0.4231

Epoch 02586: val_loss did not improve from 1.25819
Epoch 2587/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4359 - val_loss: 1.2606 - val_accuracy: 0.4215

Epoch 02587: val_loss did not improve from 1.25819
Epoch 2588/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4332 - val_loss: 1.2600 - val_accuracy: 0.4303

Epoch 02588: val_loss did not improve from 1.25819
Epoch 2589/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4308 - val_loss: 1.2672 - val_accuracy: 0.4151

Epoch 02589: val_loss did not improve from 1.25819
Epoch 2590/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4369 - val_loss: 1.2655 - val_accuracy: 0.4175

Epoch 02590: val_loss did not improve from 1.25819
Epoch 2591/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4325 - val_loss: 1.2627 - val_accuracy: 0.4191

Epoch 02591: val_loss did not improve from 1.25819
Epoch 2592/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4353 - val_loss: 1.2614 - val_accuracy: 0.4159

Epoch 02592: val_loss did not improve from 1.25819
Epoch 2593/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4368 - val_loss: 1.2616 - val_accuracy: 0.4207

Epoch 02593: val_loss did not improve from 1.25819
Epoch 2594/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4337 - val_loss: 1.2609 - val_accuracy: 0.4319

Epoch 02594: val_loss did not improve from 1.25819
Epoch 2595/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4378 - val_loss: 1.2621 - val_accuracy: 0.4247

Epoch 02595: val_loss did not improve from 1.25819
Epoch 2596/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4352 - val_loss: 1.2633 - val_accuracy: 0.4223

Epoch 02596: val_loss did not improve from 1.25819
Epoch 2597/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4375 - val_loss: 1.2598 - val_accuracy: 0.4239

Epoch 02597: val_loss did not improve from 1.25819
Epoch 2598/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4313 - val_loss: 1.2654 - val_accuracy: 0.4207

Epoch 02598: val_loss did not improve from 1.25819
Epoch 2599/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4289 - val_loss: 1.2625 - val_accuracy: 0.4287

Epoch 02599: val_loss did not improve from 1.25819
Epoch 2600/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4310 - val_loss: 1.2606 - val_accuracy: 0.4199

Epoch 02600: val_loss did not improve from 1.25819
Epoch 2601/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4357 - val_loss: 1.2629 - val_accuracy: 0.4382

Epoch 02601: val_loss did not improve from 1.25819
Epoch 2602/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4329 - val_loss: 1.2618 - val_accuracy: 0.4287

Epoch 02602: val_loss did not improve from 1.25819
Epoch 2603/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4347 - val_loss: 1.2663 - val_accuracy: 0.4215

Epoch 02603: val_loss did not improve from 1.25819
Epoch 2604/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4354 - val_loss: 1.2626 - val_accuracy: 0.4159

Epoch 02604: val_loss did not improve from 1.25819
Epoch 2605/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4335 - val_loss: 1.2639 - val_accuracy: 0.4247

Epoch 02605: val_loss did not improve from 1.25819
Epoch 2606/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4337 - val_loss: 1.2660 - val_accuracy: 0.4279

Epoch 02606: val_loss did not improve from 1.25819
Epoch 2607/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4349 - val_loss: 1.2609 - val_accuracy: 0.4239

Epoch 02607: val_loss did not improve from 1.25819
Epoch 2608/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4355 - val_loss: 1.2660 - val_accuracy: 0.4223

Epoch 02608: val_loss did not improve from 1.25819
Epoch 2609/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4374 - val_loss: 1.2607 - val_accuracy: 0.4183

Epoch 02609: val_loss did not improve from 1.25819
Epoch 2610/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4319 - val_loss: 1.2620 - val_accuracy: 0.4215

Epoch 02610: val_loss did not improve from 1.25819
Epoch 2611/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4364 - val_loss: 1.2628 - val_accuracy: 0.4279

Epoch 02611: val_loss did not improve from 1.25819
Epoch 2612/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4326 - val_loss: 1.2621 - val_accuracy: 0.4295

Epoch 02612: val_loss did not improve from 1.25819
Epoch 2613/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4344 - val_loss: 1.2645 - val_accuracy: 0.4223

Epoch 02613: val_loss did not improve from 1.25819
Epoch 2614/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4340 - val_loss: 1.2635 - val_accuracy: 0.4287

Epoch 02614: val_loss did not improve from 1.25819
Epoch 2615/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4346 - val_loss: 1.2704 - val_accuracy: 0.4255

Epoch 02615: val_loss did not improve from 1.25819
Epoch 2616/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4303 - val_loss: 1.2617 - val_accuracy: 0.4287

Epoch 02616: val_loss did not improve from 1.25819
Epoch 2617/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4297 - val_loss: 1.2671 - val_accuracy: 0.4263

Epoch 02617: val_loss did not improve from 1.25819
Epoch 2618/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4306 - val_loss: 1.2626 - val_accuracy: 0.4231

Epoch 02618: val_loss did not improve from 1.25819
Epoch 2619/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4298 - val_loss: 1.2870 - val_accuracy: 0.4191

Epoch 02619: val_loss did not improve from 1.25819
Epoch 2620/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4311 - val_loss: 1.2585 - val_accuracy: 0.4303

Epoch 02620: val_loss did not improve from 1.25819
Epoch 2621/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4360 - val_loss: 1.2616 - val_accuracy: 0.4263

Epoch 02621: val_loss did not improve from 1.25819
Epoch 2622/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4323 - val_loss: 1.2636 - val_accuracy: 0.4279

Epoch 02622: val_loss did not improve from 1.25819
Epoch 2623/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4350 - val_loss: 1.2591 - val_accuracy: 0.4351

Epoch 02623: val_loss did not improve from 1.25819
Epoch 2624/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4332 - val_loss: 1.2623 - val_accuracy: 0.4279

Epoch 02624: val_loss did not improve from 1.25819
Epoch 2625/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4347 - val_loss: 1.2595 - val_accuracy: 0.4271

Epoch 02625: val_loss did not improve from 1.25819
Epoch 2626/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4295 - val_loss: 1.2624 - val_accuracy: 0.4151

Epoch 02626: val_loss did not improve from 1.25819
Epoch 2627/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4348 - val_loss: 1.2664 - val_accuracy: 0.4231

Epoch 02627: val_loss did not improve from 1.25819
Epoch 2628/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4328 - val_loss: 1.2635 - val_accuracy: 0.4175

Epoch 02628: val_loss did not improve from 1.25819
Epoch 2629/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4327 - val_loss: 1.2611 - val_accuracy: 0.4335

Epoch 02629: val_loss did not improve from 1.25819
Epoch 2630/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4314 - val_loss: 1.2592 - val_accuracy: 0.4183

Epoch 02630: val_loss did not improve from 1.25819
Epoch 2631/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4326 - val_loss: 1.2611 - val_accuracy: 0.4088

Epoch 02631: val_loss did not improve from 1.25819
Epoch 2632/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4330 - val_loss: 1.2682 - val_accuracy: 0.4255

Epoch 02632: val_loss did not improve from 1.25819
Epoch 2633/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4330 - val_loss: 1.2614 - val_accuracy: 0.4207

Epoch 02633: val_loss did not improve from 1.25819
Epoch 2634/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4313 - val_loss: 1.2597 - val_accuracy: 0.4263

Epoch 02634: val_loss did not improve from 1.25819
Epoch 2635/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4310 - val_loss: 1.2663 - val_accuracy: 0.4231

Epoch 02635: val_loss did not improve from 1.25819
Epoch 2636/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4351 - val_loss: 1.2607 - val_accuracy: 0.4223

Epoch 02636: val_loss did not improve from 1.25819
Epoch 2637/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4331 - val_loss: 1.2629 - val_accuracy: 0.4279

Epoch 02637: val_loss did not improve from 1.25819
Epoch 2638/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4349 - val_loss: 1.2605 - val_accuracy: 0.4295

Epoch 02638: val_loss did not improve from 1.25819
Epoch 2639/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4317 - val_loss: 1.2638 - val_accuracy: 0.4247

Epoch 02639: val_loss did not improve from 1.25819
Epoch 2640/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4316 - val_loss: 1.2669 - val_accuracy: 0.4223

Epoch 02640: val_loss did not improve from 1.25819
Epoch 2641/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4337 - val_loss: 1.2664 - val_accuracy: 0.4319

Epoch 02641: val_loss did not improve from 1.25819
Epoch 2642/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4324 - val_loss: 1.2612 - val_accuracy: 0.4303

Epoch 02642: val_loss did not improve from 1.25819
Epoch 2643/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4377 - val_loss: 1.2613 - val_accuracy: 0.4311

Epoch 02643: val_loss did not improve from 1.25819
Epoch 2644/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4327 - val_loss: 1.2614 - val_accuracy: 0.4175

Epoch 02644: val_loss did not improve from 1.25819
Epoch 2645/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4317 - val_loss: 1.2750 - val_accuracy: 0.4215

Epoch 02645: val_loss did not improve from 1.25819
Epoch 2646/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4357 - val_loss: 1.2596 - val_accuracy: 0.4183

Epoch 02646: val_loss did not improve from 1.25819
Epoch 2647/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4328 - val_loss: 1.2630 - val_accuracy: 0.4255

Epoch 02647: val_loss did not improve from 1.25819
Epoch 2648/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4328 - val_loss: 1.2598 - val_accuracy: 0.4335

Epoch 02648: val_loss did not improve from 1.25819
Epoch 2649/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4326 - val_loss: 1.2620 - val_accuracy: 0.4295

Epoch 02649: val_loss did not improve from 1.25819
Epoch 2650/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4367 - val_loss: 1.2585 - val_accuracy: 0.4335

Epoch 02650: val_loss did not improve from 1.25819
Epoch 2651/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4289 - val_loss: 1.2619 - val_accuracy: 0.4231

Epoch 02651: val_loss did not improve from 1.25819
Epoch 2652/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4290 - val_loss: 1.2728 - val_accuracy: 0.4223

Epoch 02652: val_loss did not improve from 1.25819
Epoch 2653/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4308 - val_loss: 1.2605 - val_accuracy: 0.4335

Epoch 02653: val_loss did not improve from 1.25819
Epoch 2654/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4357 - val_loss: 1.2648 - val_accuracy: 0.4247

Epoch 02654: val_loss did not improve from 1.25819
Epoch 2655/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4357 - val_loss: 1.2574 - val_accuracy: 0.4303

Epoch 02655: val_loss improved from 1.25819 to 1.25743, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2656/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4350 - val_loss: 1.2622 - val_accuracy: 0.4231

Epoch 02656: val_loss did not improve from 1.25743
Epoch 2657/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4353 - val_loss: 1.2671 - val_accuracy: 0.4247

Epoch 02657: val_loss did not improve from 1.25743
Epoch 2658/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4372 - val_loss: 1.2644 - val_accuracy: 0.4279

Epoch 02658: val_loss did not improve from 1.25743
Epoch 2659/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4342 - val_loss: 1.2629 - val_accuracy: 0.4247

Epoch 02659: val_loss did not improve from 1.25743
Epoch 2660/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4292 - val_loss: 1.2624 - val_accuracy: 0.4303

Epoch 02660: val_loss did not improve from 1.25743
Epoch 2661/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4347 - val_loss: 1.2699 - val_accuracy: 0.4127

Epoch 02661: val_loss did not improve from 1.25743
Epoch 2662/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4353 - val_loss: 1.2626 - val_accuracy: 0.4295

Epoch 02662: val_loss did not improve from 1.25743
Epoch 2663/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4345 - val_loss: 1.2636 - val_accuracy: 0.4311

Epoch 02663: val_loss did not improve from 1.25743
Epoch 2664/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4329 - val_loss: 1.2622 - val_accuracy: 0.4263

Epoch 02664: val_loss did not improve from 1.25743
Epoch 2665/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4326 - val_loss: 1.2656 - val_accuracy: 0.4247

Epoch 02665: val_loss did not improve from 1.25743
Epoch 2666/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4353 - val_loss: 1.2612 - val_accuracy: 0.4239

Epoch 02666: val_loss did not improve from 1.25743
Epoch 2667/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4374 - val_loss: 1.2597 - val_accuracy: 0.4351

Epoch 02667: val_loss did not improve from 1.25743
Epoch 2668/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4353 - val_loss: 1.2650 - val_accuracy: 0.4271

Epoch 02668: val_loss did not improve from 1.25743
Epoch 2669/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4329 - val_loss: 1.2588 - val_accuracy: 0.4271

Epoch 02669: val_loss did not improve from 1.25743
Epoch 2670/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4335 - val_loss: 1.2608 - val_accuracy: 0.4287

Epoch 02670: val_loss did not improve from 1.25743
Epoch 2671/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4358 - val_loss: 1.2694 - val_accuracy: 0.4143

Epoch 02671: val_loss did not improve from 1.25743
Epoch 2672/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4363 - val_loss: 1.2603 - val_accuracy: 0.4223

Epoch 02672: val_loss did not improve from 1.25743
Epoch 2673/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4368 - val_loss: 1.2601 - val_accuracy: 0.4311

Epoch 02673: val_loss did not improve from 1.25743
Epoch 2674/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4323 - val_loss: 1.2646 - val_accuracy: 0.4239

Epoch 02674: val_loss did not improve from 1.25743
Epoch 2675/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4353 - val_loss: 1.2621 - val_accuracy: 0.4287

Epoch 02675: val_loss did not improve from 1.25743
Epoch 2676/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4338 - val_loss: 1.2600 - val_accuracy: 0.4327

Epoch 02676: val_loss did not improve from 1.25743
Epoch 2677/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4330 - val_loss: 1.2614 - val_accuracy: 0.4303

Epoch 02677: val_loss did not improve from 1.25743
Epoch 2678/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4329 - val_loss: 1.2598 - val_accuracy: 0.4255

Epoch 02678: val_loss did not improve from 1.25743
Epoch 2679/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4336 - val_loss: 1.2745 - val_accuracy: 0.4135

Epoch 02679: val_loss did not improve from 1.25743
Epoch 2680/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4323 - val_loss: 1.2632 - val_accuracy: 0.4255

Epoch 02680: val_loss did not improve from 1.25743
Epoch 2681/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4342 - val_loss: 1.2581 - val_accuracy: 0.4167

Epoch 02681: val_loss did not improve from 1.25743
Epoch 2682/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4348 - val_loss: 1.2634 - val_accuracy: 0.4183

Epoch 02682: val_loss did not improve from 1.25743
Epoch 2683/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4358 - val_loss: 1.2619 - val_accuracy: 0.4143

Epoch 02683: val_loss did not improve from 1.25743
Epoch 2684/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4352 - val_loss: 1.2692 - val_accuracy: 0.4143

Epoch 02684: val_loss did not improve from 1.25743
Epoch 2685/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4329 - val_loss: 1.2605 - val_accuracy: 0.4215

Epoch 02685: val_loss did not improve from 1.25743
Epoch 2686/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4376 - val_loss: 1.2642 - val_accuracy: 0.4231

Epoch 02686: val_loss did not improve from 1.25743
Epoch 2687/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4353 - val_loss: 1.2669 - val_accuracy: 0.4151

Epoch 02687: val_loss did not improve from 1.25743
Epoch 2688/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4356 - val_loss: 1.2654 - val_accuracy: 0.4279

Epoch 02688: val_loss did not improve from 1.25743
Epoch 2689/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4350 - val_loss: 1.2681 - val_accuracy: 0.4215

Epoch 02689: val_loss did not improve from 1.25743
Epoch 2690/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4384 - val_loss: 1.2648 - val_accuracy: 0.4279

Epoch 02690: val_loss did not improve from 1.25743
Epoch 2691/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4356 - val_loss: 1.2608 - val_accuracy: 0.4199

Epoch 02691: val_loss did not improve from 1.25743
Epoch 2692/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4365 - val_loss: 1.2687 - val_accuracy: 0.4223

Epoch 02692: val_loss did not improve from 1.25743
Epoch 2693/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4337 - val_loss: 1.2605 - val_accuracy: 0.4287

Epoch 02693: val_loss did not improve from 1.25743
Epoch 2694/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4283 - val_loss: 1.2637 - val_accuracy: 0.4343

Epoch 02694: val_loss did not improve from 1.25743
Epoch 2695/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4332 - val_loss: 1.2688 - val_accuracy: 0.4207

Epoch 02695: val_loss did not improve from 1.25743
Epoch 2696/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4306 - val_loss: 1.2598 - val_accuracy: 0.4255

Epoch 02696: val_loss did not improve from 1.25743
Epoch 2697/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4350 - val_loss: 1.2648 - val_accuracy: 0.4295

Epoch 02697: val_loss did not improve from 1.25743
Epoch 2698/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4357 - val_loss: 1.2630 - val_accuracy: 0.4311

Epoch 02698: val_loss did not improve from 1.25743
Epoch 2699/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4343 - val_loss: 1.2603 - val_accuracy: 0.4279

Epoch 02699: val_loss did not improve from 1.25743
Epoch 2700/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4328 - val_loss: 1.2586 - val_accuracy: 0.4239

Epoch 02700: val_loss did not improve from 1.25743
Epoch 2701/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4353 - val_loss: 1.2615 - val_accuracy: 0.4207

Epoch 02701: val_loss did not improve from 1.25743
Epoch 2702/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4345 - val_loss: 1.2628 - val_accuracy: 0.4319

Epoch 02702: val_loss did not improve from 1.25743
Epoch 2703/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4349 - val_loss: 1.2635 - val_accuracy: 0.4279

Epoch 02703: val_loss did not improve from 1.25743
Epoch 2704/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4352 - val_loss: 1.2605 - val_accuracy: 0.4247

Epoch 02704: val_loss did not improve from 1.25743
Epoch 2705/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4331 - val_loss: 1.2606 - val_accuracy: 0.4311

Epoch 02705: val_loss did not improve from 1.25743
Epoch 2706/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4376 - val_loss: 1.2570 - val_accuracy: 0.4303

Epoch 02706: val_loss improved from 1.25743 to 1.25705, saving model to ./results/NN_thk_class/aggr_theta/ckpt_2
Epoch 2707/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4298 - val_loss: 1.2637 - val_accuracy: 0.4247

Epoch 02707: val_loss did not improve from 1.25705
Epoch 2708/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4384 - val_loss: 1.2600 - val_accuracy: 0.4255

Epoch 02708: val_loss did not improve from 1.25705
Epoch 2709/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4367 - val_loss: 1.2603 - val_accuracy: 0.4287

Epoch 02709: val_loss did not improve from 1.25705
Epoch 2710/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4348 - val_loss: 1.2608 - val_accuracy: 0.4191

Epoch 02710: val_loss did not improve from 1.25705
Epoch 2711/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4345 - val_loss: 1.2616 - val_accuracy: 0.4159

Epoch 02711: val_loss did not improve from 1.25705
Epoch 2712/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4339 - val_loss: 1.2641 - val_accuracy: 0.4295

Epoch 02712: val_loss did not improve from 1.25705
Epoch 2713/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4374 - val_loss: 1.2614 - val_accuracy: 0.4207

Epoch 02713: val_loss did not improve from 1.25705
Epoch 2714/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4365 - val_loss: 1.2609 - val_accuracy: 0.4239

Epoch 02714: val_loss did not improve from 1.25705
Epoch 2715/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4324 - val_loss: 1.2637 - val_accuracy: 0.4295

Epoch 02715: val_loss did not improve from 1.25705
Epoch 2716/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4353 - val_loss: 1.2584 - val_accuracy: 0.4319

Epoch 02716: val_loss did not improve from 1.25705
Epoch 2717/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4359 - val_loss: 1.2640 - val_accuracy: 0.4207

Epoch 02717: val_loss did not improve from 1.25705
Epoch 2718/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4376 - val_loss: 1.2577 - val_accuracy: 0.4398

Epoch 02718: val_loss did not improve from 1.25705
Epoch 2719/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4278 - val_loss: 1.2610 - val_accuracy: 0.4143

Epoch 02719: val_loss did not improve from 1.25705
Epoch 2720/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4321 - val_loss: 1.2608 - val_accuracy: 0.4327

Epoch 02720: val_loss did not improve from 1.25705
Epoch 2721/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4353 - val_loss: 1.2598 - val_accuracy: 0.4319

Epoch 02721: val_loss did not improve from 1.25705
Epoch 2722/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4375 - val_loss: 1.2603 - val_accuracy: 0.4239

Epoch 02722: val_loss did not improve from 1.25705
Epoch 2723/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4326 - val_loss: 1.2601 - val_accuracy: 0.4287

Epoch 02723: val_loss did not improve from 1.25705
Epoch 2724/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4345 - val_loss: 1.2628 - val_accuracy: 0.4120

Epoch 02724: val_loss did not improve from 1.25705
Epoch 2725/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4344 - val_loss: 1.2600 - val_accuracy: 0.4311

Epoch 02725: val_loss did not improve from 1.25705
Epoch 2726/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4337 - val_loss: 1.2681 - val_accuracy: 0.4223

Epoch 02726: val_loss did not improve from 1.25705
Epoch 2727/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4254 - val_loss: 1.2686 - val_accuracy: 0.4175

Epoch 02727: val_loss did not improve from 1.25705
Epoch 2728/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4305 - val_loss: 1.2638 - val_accuracy: 0.4279

Epoch 02728: val_loss did not improve from 1.25705
Epoch 2729/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4338 - val_loss: 1.2645 - val_accuracy: 0.4287

Epoch 02729: val_loss did not improve from 1.25705
Epoch 2730/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4350 - val_loss: 1.2638 - val_accuracy: 0.4287

Epoch 02730: val_loss did not improve from 1.25705
Epoch 2731/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4331 - val_loss: 1.2672 - val_accuracy: 0.4143

Epoch 02731: val_loss did not improve from 1.25705
Epoch 2732/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4353 - val_loss: 1.2658 - val_accuracy: 0.4239

Epoch 02732: val_loss did not improve from 1.25705
Epoch 2733/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4315 - val_loss: 1.2631 - val_accuracy: 0.4247

Epoch 02733: val_loss did not improve from 1.25705
Epoch 2734/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4336 - val_loss: 1.2612 - val_accuracy: 0.4239

Epoch 02734: val_loss did not improve from 1.25705
Epoch 2735/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4365 - val_loss: 1.2631 - val_accuracy: 0.4207

Epoch 02735: val_loss did not improve from 1.25705
Epoch 2736/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4296 - val_loss: 1.2664 - val_accuracy: 0.4295

Epoch 02736: val_loss did not improve from 1.25705
Epoch 2737/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4315 - val_loss: 1.2690 - val_accuracy: 0.4223

Epoch 02737: val_loss did not improve from 1.25705
Epoch 2738/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4291 - val_loss: 1.2636 - val_accuracy: 0.4215

Epoch 02738: val_loss did not improve from 1.25705
Epoch 2739/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4319 - val_loss: 1.2664 - val_accuracy: 0.4287

Epoch 02739: val_loss did not improve from 1.25705
Epoch 2740/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4360 - val_loss: 1.2647 - val_accuracy: 0.4327

Epoch 02740: val_loss did not improve from 1.25705
Epoch 2741/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4358 - val_loss: 1.2590 - val_accuracy: 0.4343

Epoch 02741: val_loss did not improve from 1.25705
Epoch 2742/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4360 - val_loss: 1.2611 - val_accuracy: 0.4303

Epoch 02742: val_loss did not improve from 1.25705
Epoch 2743/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4366 - val_loss: 1.2612 - val_accuracy: 0.4207

Epoch 02743: val_loss did not improve from 1.25705
Epoch 2744/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4392 - val_loss: 1.2598 - val_accuracy: 0.4231

Epoch 02744: val_loss did not improve from 1.25705
Epoch 2745/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4339 - val_loss: 1.2585 - val_accuracy: 0.4311

Epoch 02745: val_loss did not improve from 1.25705
Epoch 2746/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4312 - val_loss: 1.2605 - val_accuracy: 0.4311

Epoch 02746: val_loss did not improve from 1.25705
Epoch 2747/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4315 - val_loss: 1.2788 - val_accuracy: 0.4239

Epoch 02747: val_loss did not improve from 1.25705
Epoch 2748/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4294 - val_loss: 1.2617 - val_accuracy: 0.4343

Epoch 02748: val_loss did not improve from 1.25705
Epoch 2749/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4293 - val_loss: 1.2631 - val_accuracy: 0.4303

Epoch 02749: val_loss did not improve from 1.25705
Epoch 2750/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4320 - val_loss: 1.2614 - val_accuracy: 0.4199

Epoch 02750: val_loss did not improve from 1.25705
Epoch 2751/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4305 - val_loss: 1.2619 - val_accuracy: 0.4231

Epoch 02751: val_loss did not improve from 1.25705
Epoch 2752/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4333 - val_loss: 1.2660 - val_accuracy: 0.4247

Epoch 02752: val_loss did not improve from 1.25705
Epoch 2753/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4356 - val_loss: 1.2627 - val_accuracy: 0.4359

Epoch 02753: val_loss did not improve from 1.25705
Epoch 2754/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4354 - val_loss: 1.2584 - val_accuracy: 0.4287

Epoch 02754: val_loss did not improve from 1.25705
Epoch 2755/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4329 - val_loss: 1.2626 - val_accuracy: 0.4327

Epoch 02755: val_loss did not improve from 1.25705
Epoch 2756/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4338 - val_loss: 1.2611 - val_accuracy: 0.4343

Epoch 02756: val_loss did not improve from 1.25705
Epoch 2757/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4337 - val_loss: 1.2607 - val_accuracy: 0.4223

Epoch 02757: val_loss did not improve from 1.25705
Epoch 2758/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4368 - val_loss: 1.2612 - val_accuracy: 0.4295

Epoch 02758: val_loss did not improve from 1.25705
Epoch 2759/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4375 - val_loss: 1.2618 - val_accuracy: 0.4271

Epoch 02759: val_loss did not improve from 1.25705
Epoch 2760/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4352 - val_loss: 1.2661 - val_accuracy: 0.4215

Epoch 02760: val_loss did not improve from 1.25705
Epoch 2761/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4298 - val_loss: 1.2633 - val_accuracy: 0.4231

Epoch 02761: val_loss did not improve from 1.25705
Epoch 2762/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4336 - val_loss: 1.2611 - val_accuracy: 0.4231

Epoch 02762: val_loss did not improve from 1.25705
Epoch 2763/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4329 - val_loss: 1.2612 - val_accuracy: 0.4159

Epoch 02763: val_loss did not improve from 1.25705
Epoch 2764/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4319 - val_loss: 1.2608 - val_accuracy: 0.4414

Epoch 02764: val_loss did not improve from 1.25705
Epoch 2765/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4335 - val_loss: 1.2583 - val_accuracy: 0.4319

Epoch 02765: val_loss did not improve from 1.25705
Epoch 2766/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4336 - val_loss: 1.2614 - val_accuracy: 0.4327

Epoch 02766: val_loss did not improve from 1.25705
Epoch 2767/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4322 - val_loss: 1.2647 - val_accuracy: 0.4255

Epoch 02767: val_loss did not improve from 1.25705
Epoch 2768/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4338 - val_loss: 1.2625 - val_accuracy: 0.4255

Epoch 02768: val_loss did not improve from 1.25705
Epoch 2769/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4353 - val_loss: 1.2600 - val_accuracy: 0.4311

Epoch 02769: val_loss did not improve from 1.25705
Epoch 2770/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4315 - val_loss: 1.2655 - val_accuracy: 0.4231

Epoch 02770: val_loss did not improve from 1.25705
Epoch 2771/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4331 - val_loss: 1.2663 - val_accuracy: 0.4215

Epoch 02771: val_loss did not improve from 1.25705
Epoch 2772/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4344 - val_loss: 1.2602 - val_accuracy: 0.4335

Epoch 02772: val_loss did not improve from 1.25705
Epoch 2773/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4369 - val_loss: 1.2633 - val_accuracy: 0.4327

Epoch 02773: val_loss did not improve from 1.25705
Epoch 2774/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4314 - val_loss: 1.2605 - val_accuracy: 0.4311

Epoch 02774: val_loss did not improve from 1.25705
Epoch 2775/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4329 - val_loss: 1.2627 - val_accuracy: 0.4271

Epoch 02775: val_loss did not improve from 1.25705
Epoch 2776/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4323 - val_loss: 1.2678 - val_accuracy: 0.4183

Epoch 02776: val_loss did not improve from 1.25705
Epoch 2777/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4335 - val_loss: 1.2624 - val_accuracy: 0.4239

Epoch 02777: val_loss did not improve from 1.25705
Epoch 2778/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4362 - val_loss: 1.2615 - val_accuracy: 0.4183

Epoch 02778: val_loss did not improve from 1.25705
Epoch 2779/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4331 - val_loss: 1.2685 - val_accuracy: 0.4151

Epoch 02779: val_loss did not improve from 1.25705
Epoch 2780/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4337 - val_loss: 1.2603 - val_accuracy: 0.4271

Epoch 02780: val_loss did not improve from 1.25705
Epoch 2781/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4322 - val_loss: 1.2594 - val_accuracy: 0.4247

Epoch 02781: val_loss did not improve from 1.25705
Epoch 2782/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4364 - val_loss: 1.2602 - val_accuracy: 0.4287

Epoch 02782: val_loss did not improve from 1.25705
Epoch 2783/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4334 - val_loss: 1.2637 - val_accuracy: 0.4279

Epoch 02783: val_loss did not improve from 1.25705
Epoch 2784/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4353 - val_loss: 1.2605 - val_accuracy: 0.4263

Epoch 02784: val_loss did not improve from 1.25705
Epoch 2785/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4341 - val_loss: 1.2610 - val_accuracy: 0.4239

Epoch 02785: val_loss did not improve from 1.25705
Epoch 2786/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4345 - val_loss: 1.2594 - val_accuracy: 0.4295

Epoch 02786: val_loss did not improve from 1.25705
Epoch 2787/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4333 - val_loss: 1.2603 - val_accuracy: 0.4335

Epoch 02787: val_loss did not improve from 1.25705
Epoch 2788/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4371 - val_loss: 1.2629 - val_accuracy: 0.4351

Epoch 02788: val_loss did not improve from 1.25705
Epoch 2789/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4322 - val_loss: 1.2597 - val_accuracy: 0.4311

Epoch 02789: val_loss did not improve from 1.25705
Epoch 2790/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4337 - val_loss: 1.2663 - val_accuracy: 0.4255

Epoch 02790: val_loss did not improve from 1.25705
Epoch 2791/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4344 - val_loss: 1.2607 - val_accuracy: 0.4199

Epoch 02791: val_loss did not improve from 1.25705
Epoch 2792/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4357 - val_loss: 1.2636 - val_accuracy: 0.4231

Epoch 02792: val_loss did not improve from 1.25705
Epoch 2793/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4364 - val_loss: 1.2615 - val_accuracy: 0.4287

Epoch 02793: val_loss did not improve from 1.25705
Epoch 2794/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4329 - val_loss: 1.2628 - val_accuracy: 0.4335

Epoch 02794: val_loss did not improve from 1.25705
Epoch 2795/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4346 - val_loss: 1.2687 - val_accuracy: 0.4263

Epoch 02795: val_loss did not improve from 1.25705
Epoch 2796/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4346 - val_loss: 1.2638 - val_accuracy: 0.4231

Epoch 02796: val_loss did not improve from 1.25705
Epoch 2797/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4308 - val_loss: 1.2612 - val_accuracy: 0.4247

Epoch 02797: val_loss did not improve from 1.25705
Epoch 2798/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4317 - val_loss: 1.2592 - val_accuracy: 0.4239

Epoch 02798: val_loss did not improve from 1.25705
Epoch 2799/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4357 - val_loss: 1.2633 - val_accuracy: 0.4287

Epoch 02799: val_loss did not improve from 1.25705
Epoch 2800/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4362 - val_loss: 1.2615 - val_accuracy: 0.4255

Epoch 02800: val_loss did not improve from 1.25705
Epoch 2801/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4357 - val_loss: 1.2606 - val_accuracy: 0.4255

Epoch 02801: val_loss did not improve from 1.25705
Epoch 2802/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4335 - val_loss: 1.2575 - val_accuracy: 0.4247

Epoch 02802: val_loss did not improve from 1.25705
Epoch 2803/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4342 - val_loss: 1.2607 - val_accuracy: 0.4159

Epoch 02803: val_loss did not improve from 1.25705
Epoch 2804/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4384 - val_loss: 1.2612 - val_accuracy: 0.4263

Epoch 02804: val_loss did not improve from 1.25705
Epoch 2805/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4337 - val_loss: 1.2609 - val_accuracy: 0.4271

Epoch 02805: val_loss did not improve from 1.25705
Epoch 2806/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4374 - val_loss: 1.2615 - val_accuracy: 0.4175

Epoch 02806: val_loss did not improve from 1.25705
Epoch 2807/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4359 - val_loss: 1.2596 - val_accuracy: 0.4223

Epoch 02807: val_loss did not improve from 1.25705
Epoch 2808/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4346 - val_loss: 1.2597 - val_accuracy: 0.4247

Epoch 02808: val_loss did not improve from 1.25705
Epoch 2809/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4360 - val_loss: 1.2611 - val_accuracy: 0.4271

Epoch 02809: val_loss did not improve from 1.25705
Epoch 2810/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4360 - val_loss: 1.2626 - val_accuracy: 0.4327

Epoch 02810: val_loss did not improve from 1.25705
Epoch 2811/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4341 - val_loss: 1.2664 - val_accuracy: 0.4279

Epoch 02811: val_loss did not improve from 1.25705
Epoch 2812/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4288 - val_loss: 1.2666 - val_accuracy: 0.4159

Epoch 02812: val_loss did not improve from 1.25705
Epoch 2813/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4340 - val_loss: 1.2602 - val_accuracy: 0.4303

Epoch 02813: val_loss did not improve from 1.25705
Epoch 2814/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4384 - val_loss: 1.2623 - val_accuracy: 0.4199

Epoch 02814: val_loss did not improve from 1.25705
Epoch 2815/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4355 - val_loss: 1.2592 - val_accuracy: 0.4335

Epoch 02815: val_loss did not improve from 1.25705
Epoch 2816/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4362 - val_loss: 1.2614 - val_accuracy: 0.4263

Epoch 02816: val_loss did not improve from 1.25705
Epoch 2817/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4307 - val_loss: 1.2625 - val_accuracy: 0.4239

Epoch 02817: val_loss did not improve from 1.25705
Epoch 2818/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4360 - val_loss: 1.2601 - val_accuracy: 0.4255

Epoch 02818: val_loss did not improve from 1.25705
Epoch 2819/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4313 - val_loss: 1.2628 - val_accuracy: 0.4207

Epoch 02819: val_loss did not improve from 1.25705
Epoch 2820/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4358 - val_loss: 1.2734 - val_accuracy: 0.4191

Epoch 02820: val_loss did not improve from 1.25705
Epoch 2821/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4318 - val_loss: 1.2603 - val_accuracy: 0.4335

Epoch 02821: val_loss did not improve from 1.25705
Epoch 2822/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4338 - val_loss: 1.2659 - val_accuracy: 0.4231

Epoch 02822: val_loss did not improve from 1.25705
Epoch 2823/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4283 - val_loss: 1.2605 - val_accuracy: 0.4311

Epoch 02823: val_loss did not improve from 1.25705
Epoch 2824/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4359 - val_loss: 1.2610 - val_accuracy: 0.4319

Epoch 02824: val_loss did not improve from 1.25705
Epoch 2825/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4327 - val_loss: 1.2596 - val_accuracy: 0.4343

Epoch 02825: val_loss did not improve from 1.25705
Epoch 2826/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4358 - val_loss: 1.2620 - val_accuracy: 0.4263

Epoch 02826: val_loss did not improve from 1.25705
Epoch 2827/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4352 - val_loss: 1.2571 - val_accuracy: 0.4343

Epoch 02827: val_loss did not improve from 1.25705
Epoch 2828/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4315 - val_loss: 1.2639 - val_accuracy: 0.4279

Epoch 02828: val_loss did not improve from 1.25705
Epoch 2829/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4356 - val_loss: 1.2584 - val_accuracy: 0.4351

Epoch 02829: val_loss did not improve from 1.25705
Epoch 2830/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4338 - val_loss: 1.2606 - val_accuracy: 0.4311

Epoch 02830: val_loss did not improve from 1.25705
Epoch 2831/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4372 - val_loss: 1.2624 - val_accuracy: 0.4335

Epoch 02831: val_loss did not improve from 1.25705
Epoch 2832/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4318 - val_loss: 1.2646 - val_accuracy: 0.4263

Epoch 02832: val_loss did not improve from 1.25705
Epoch 2833/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4358 - val_loss: 1.2615 - val_accuracy: 0.4175

Epoch 02833: val_loss did not improve from 1.25705
Epoch 2834/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4345 - val_loss: 1.2598 - val_accuracy: 0.4303

Epoch 02834: val_loss did not improve from 1.25705
Epoch 2835/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4283 - val_loss: 1.2629 - val_accuracy: 0.4414

Epoch 02835: val_loss did not improve from 1.25705
Epoch 2836/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4352 - val_loss: 1.2620 - val_accuracy: 0.4271

Epoch 02836: val_loss did not improve from 1.25705
Epoch 2837/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4368 - val_loss: 1.2613 - val_accuracy: 0.4279

Epoch 02837: val_loss did not improve from 1.25705
Epoch 2838/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4367 - val_loss: 1.2619 - val_accuracy: 0.4271

Epoch 02838: val_loss did not improve from 1.25705
Epoch 2839/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4338 - val_loss: 1.2637 - val_accuracy: 0.4199

Epoch 02839: val_loss did not improve from 1.25705
Epoch 2840/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4311 - val_loss: 1.2627 - val_accuracy: 0.4327

Epoch 02840: val_loss did not improve from 1.25705
Epoch 2841/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4287 - val_loss: 1.2593 - val_accuracy: 0.4303

Epoch 02841: val_loss did not improve from 1.25705
Epoch 2842/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4362 - val_loss: 1.2608 - val_accuracy: 0.4375

Epoch 02842: val_loss did not improve from 1.25705
Epoch 2843/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4349 - val_loss: 1.2658 - val_accuracy: 0.4247

Epoch 02843: val_loss did not improve from 1.25705
Epoch 2844/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4341 - val_loss: 1.2610 - val_accuracy: 0.4239

Epoch 02844: val_loss did not improve from 1.25705
Epoch 2845/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4360 - val_loss: 1.2616 - val_accuracy: 0.4303

Epoch 02845: val_loss did not improve from 1.25705
Epoch 2846/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4343 - val_loss: 1.2597 - val_accuracy: 0.4247

Epoch 02846: val_loss did not improve from 1.25705
Epoch 2847/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4351 - val_loss: 1.2637 - val_accuracy: 0.4271

Epoch 02847: val_loss did not improve from 1.25705
Epoch 2848/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4376 - val_loss: 1.2614 - val_accuracy: 0.4199

Epoch 02848: val_loss did not improve from 1.25705
Epoch 2849/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4337 - val_loss: 1.2625 - val_accuracy: 0.4287

Epoch 02849: val_loss did not improve from 1.25705
Epoch 2850/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4352 - val_loss: 1.2610 - val_accuracy: 0.4271

Epoch 02850: val_loss did not improve from 1.25705
Epoch 2851/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4369 - val_loss: 1.2641 - val_accuracy: 0.4199

Epoch 02851: val_loss did not improve from 1.25705
Epoch 2852/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4373 - val_loss: 1.2653 - val_accuracy: 0.4215

Epoch 02852: val_loss did not improve from 1.25705
Epoch 2853/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4354 - val_loss: 1.2588 - val_accuracy: 0.4319

Epoch 02853: val_loss did not improve from 1.25705
Epoch 2854/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4341 - val_loss: 1.2574 - val_accuracy: 0.4263

Epoch 02854: val_loss did not improve from 1.25705
Epoch 2855/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4371 - val_loss: 1.2638 - val_accuracy: 0.4183

Epoch 02855: val_loss did not improve from 1.25705
Epoch 2856/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4343 - val_loss: 1.2602 - val_accuracy: 0.4255

Epoch 02856: val_loss did not improve from 1.25705
Epoch 2857/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4368 - val_loss: 1.2643 - val_accuracy: 0.4255

Epoch 02857: val_loss did not improve from 1.25705
Epoch 2858/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4304 - val_loss: 1.2653 - val_accuracy: 0.4215

Epoch 02858: val_loss did not improve from 1.25705
Epoch 2859/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4353 - val_loss: 1.2669 - val_accuracy: 0.4191

Epoch 02859: val_loss did not improve from 1.25705
Epoch 2860/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4341 - val_loss: 1.2623 - val_accuracy: 0.4247

Epoch 02860: val_loss did not improve from 1.25705
Epoch 2861/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4337 - val_loss: 1.2600 - val_accuracy: 0.4375

Epoch 02861: val_loss did not improve from 1.25705
Epoch 2862/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4353 - val_loss: 1.2623 - val_accuracy: 0.4382

Epoch 02862: val_loss did not improve from 1.25705
Epoch 2863/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4345 - val_loss: 1.2624 - val_accuracy: 0.4199

Epoch 02863: val_loss did not improve from 1.25705
Epoch 2864/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4335 - val_loss: 1.2671 - val_accuracy: 0.4271

Epoch 02864: val_loss did not improve from 1.25705
Epoch 2865/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4308 - val_loss: 1.2600 - val_accuracy: 0.4215

Epoch 02865: val_loss did not improve from 1.25705
Epoch 2866/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4324 - val_loss: 1.2701 - val_accuracy: 0.4199

Epoch 02866: val_loss did not improve from 1.25705
Epoch 2867/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4312 - val_loss: 1.2617 - val_accuracy: 0.4271

Epoch 02867: val_loss did not improve from 1.25705
Epoch 2868/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4323 - val_loss: 1.2605 - val_accuracy: 0.4255

Epoch 02868: val_loss did not improve from 1.25705
Epoch 2869/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4345 - val_loss: 1.2584 - val_accuracy: 0.4327

Epoch 02869: val_loss did not improve from 1.25705
Epoch 2870/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4326 - val_loss: 1.2629 - val_accuracy: 0.4287

Epoch 02870: val_loss did not improve from 1.25705
Epoch 2871/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4333 - val_loss: 1.2609 - val_accuracy: 0.4271

Epoch 02871: val_loss did not improve from 1.25705
Epoch 2872/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4381 - val_loss: 1.2587 - val_accuracy: 0.4247

Epoch 02872: val_loss did not improve from 1.25705
Epoch 2873/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4312 - val_loss: 1.2613 - val_accuracy: 0.4327

Epoch 02873: val_loss did not improve from 1.25705
Epoch 2874/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4336 - val_loss: 1.2634 - val_accuracy: 0.4327

Epoch 02874: val_loss did not improve from 1.25705
Epoch 2875/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4287 - val_loss: 1.2627 - val_accuracy: 0.4335

Epoch 02875: val_loss did not improve from 1.25705
Epoch 2876/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4303 - val_loss: 1.2598 - val_accuracy: 0.4271

Epoch 02876: val_loss did not improve from 1.25705
Epoch 2877/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4339 - val_loss: 1.2611 - val_accuracy: 0.4287

Epoch 02877: val_loss did not improve from 1.25705
Epoch 2878/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4333 - val_loss: 1.2596 - val_accuracy: 0.4311

Epoch 02878: val_loss did not improve from 1.25705
Epoch 2879/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4348 - val_loss: 1.2621 - val_accuracy: 0.4319

Epoch 02879: val_loss did not improve from 1.25705
Epoch 2880/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4361 - val_loss: 1.2598 - val_accuracy: 0.4335

Epoch 02880: val_loss did not improve from 1.25705
Epoch 2881/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4348 - val_loss: 1.2631 - val_accuracy: 0.4295

Epoch 02881: val_loss did not improve from 1.25705
Epoch 2882/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4368 - val_loss: 1.2586 - val_accuracy: 0.4263

Epoch 02882: val_loss did not improve from 1.25705
Epoch 2883/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4344 - val_loss: 1.2610 - val_accuracy: 0.4271

Epoch 02883: val_loss did not improve from 1.25705
Epoch 2884/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4360 - val_loss: 1.2721 - val_accuracy: 0.4191

Epoch 02884: val_loss did not improve from 1.25705
Epoch 2885/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4284 - val_loss: 1.2579 - val_accuracy: 0.4271

Epoch 02885: val_loss did not improve from 1.25705
Epoch 2886/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4340 - val_loss: 1.2635 - val_accuracy: 0.4231

Epoch 02886: val_loss did not improve from 1.25705
Epoch 2887/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4360 - val_loss: 1.2636 - val_accuracy: 0.4279

Epoch 02887: val_loss did not improve from 1.25705
Epoch 2888/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4295 - val_loss: 1.2688 - val_accuracy: 0.4287

Epoch 02888: val_loss did not improve from 1.25705
Epoch 2889/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4400 - val_loss: 1.2624 - val_accuracy: 0.4311

Epoch 02889: val_loss did not improve from 1.25705
Epoch 2890/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4293 - val_loss: 1.2659 - val_accuracy: 0.4239

Epoch 02890: val_loss did not improve from 1.25705
Epoch 2891/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4329 - val_loss: 1.2622 - val_accuracy: 0.4191

Epoch 02891: val_loss did not improve from 1.25705
Epoch 2892/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4345 - val_loss: 1.2693 - val_accuracy: 0.4167

Epoch 02892: val_loss did not improve from 1.25705
Epoch 2893/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4353 - val_loss: 1.2615 - val_accuracy: 0.4183

Epoch 02893: val_loss did not improve from 1.25705
Epoch 2894/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4339 - val_loss: 1.2628 - val_accuracy: 0.4327

Epoch 02894: val_loss did not improve from 1.25705
Epoch 2895/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4346 - val_loss: 1.2597 - val_accuracy: 0.4303

Epoch 02895: val_loss did not improve from 1.25705
Epoch 2896/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4345 - val_loss: 1.2652 - val_accuracy: 0.4223

Epoch 02896: val_loss did not improve from 1.25705
Epoch 2897/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4354 - val_loss: 1.2583 - val_accuracy: 0.4327

Epoch 02897: val_loss did not improve from 1.25705
Epoch 2898/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4365 - val_loss: 1.2619 - val_accuracy: 0.4231

Epoch 02898: val_loss did not improve from 1.25705
Epoch 2899/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4366 - val_loss: 1.2583 - val_accuracy: 0.4303

Epoch 02899: val_loss did not improve from 1.25705
Epoch 2900/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4351 - val_loss: 1.2574 - val_accuracy: 0.4263

Epoch 02900: val_loss did not improve from 1.25705
Epoch 2901/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4353 - val_loss: 1.2611 - val_accuracy: 0.4223

Epoch 02901: val_loss did not improve from 1.25705
Epoch 2902/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4359 - val_loss: 1.2636 - val_accuracy: 0.4207

Epoch 02902: val_loss did not improve from 1.25705
Epoch 2903/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4366 - val_loss: 1.2632 - val_accuracy: 0.4151

Epoch 02903: val_loss did not improve from 1.25705
Epoch 2904/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4315 - val_loss: 1.2625 - val_accuracy: 0.4271

Epoch 02904: val_loss did not improve from 1.25705
Epoch 2905/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4345 - val_loss: 1.2640 - val_accuracy: 0.4263

Epoch 02905: val_loss did not improve from 1.25705
Epoch 2906/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4338 - val_loss: 1.2763 - val_accuracy: 0.4207

Epoch 02906: val_loss did not improve from 1.25705
Epoch 02906: early stopping
*************************** Fold #: 3 ***************************
Model: "sequential_62"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_248 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_249 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_250 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_251 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6172 - accuracy: 0.2019 - val_loss: 1.6058 - val_accuracy: 0.1888

Epoch 00001: val_loss improved from inf to 1.60576, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 2/10000
12/12 - 0s - loss: 1.6014 - accuracy: 0.2033 - val_loss: 1.5961 - val_accuracy: 0.1960

Epoch 00002: val_loss improved from 1.60576 to 1.59608, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 3/10000
12/12 - 0s - loss: 1.5936 - accuracy: 0.2074 - val_loss: 1.5902 - val_accuracy: 0.2024

Epoch 00003: val_loss improved from 1.59608 to 1.59025, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 4/10000
12/12 - 0s - loss: 1.5870 - accuracy: 0.2151 - val_loss: 1.5833 - val_accuracy: 0.2183

Epoch 00004: val_loss improved from 1.59025 to 1.58331, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 5/10000
12/12 - 0s - loss: 1.5789 - accuracy: 0.2593 - val_loss: 1.5740 - val_accuracy: 0.2518

Epoch 00005: val_loss improved from 1.58331 to 1.57404, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 6/10000
12/12 - 0s - loss: 1.5692 - accuracy: 0.2809 - val_loss: 1.5634 - val_accuracy: 0.2693

Epoch 00006: val_loss improved from 1.57404 to 1.56337, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 7/10000
12/12 - 0s - loss: 1.5574 - accuracy: 0.2841 - val_loss: 1.5500 - val_accuracy: 0.2821

Epoch 00007: val_loss improved from 1.56337 to 1.55005, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 8/10000
12/12 - 0s - loss: 1.5430 - accuracy: 0.3291 - val_loss: 1.5342 - val_accuracy: 0.3211

Epoch 00008: val_loss improved from 1.55005 to 1.53417, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 9/10000
12/12 - 0s - loss: 1.5262 - accuracy: 0.3219 - val_loss: 1.5169 - val_accuracy: 0.3124

Epoch 00009: val_loss improved from 1.53417 to 1.51686, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 10/10000
12/12 - 0s - loss: 1.5072 - accuracy: 0.3496 - val_loss: 1.4961 - val_accuracy: 0.3522

Epoch 00010: val_loss improved from 1.51686 to 1.49606, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 11/10000
12/12 - 0s - loss: 1.4865 - accuracy: 0.3707 - val_loss: 1.4745 - val_accuracy: 0.3554

Epoch 00011: val_loss improved from 1.49606 to 1.47453, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 12/10000
12/12 - 0s - loss: 1.4638 - accuracy: 0.3626 - val_loss: 1.4548 - val_accuracy: 0.3442

Epoch 00012: val_loss improved from 1.47453 to 1.45479, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 13/10000
12/12 - 0s - loss: 1.4416 - accuracy: 0.3756 - val_loss: 1.4289 - val_accuracy: 0.3769

Epoch 00013: val_loss improved from 1.45479 to 1.42892, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 14/10000
12/12 - 0s - loss: 1.4164 - accuracy: 0.3856 - val_loss: 1.4034 - val_accuracy: 0.3793

Epoch 00014: val_loss improved from 1.42892 to 1.40338, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 15/10000
12/12 - 0s - loss: 1.3931 - accuracy: 0.3884 - val_loss: 1.3799 - val_accuracy: 0.3952

Epoch 00015: val_loss improved from 1.40338 to 1.37988, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 16/10000
12/12 - 0s - loss: 1.3752 - accuracy: 0.3921 - val_loss: 1.3627 - val_accuracy: 0.3952

Epoch 00016: val_loss improved from 1.37988 to 1.36266, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 17/10000
12/12 - 0s - loss: 1.3620 - accuracy: 0.3798 - val_loss: 1.3551 - val_accuracy: 0.3753

Epoch 00017: val_loss improved from 1.36266 to 1.35506, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 18/10000
12/12 - 0s - loss: 1.3551 - accuracy: 0.3818 - val_loss: 1.3473 - val_accuracy: 0.3968

Epoch 00018: val_loss improved from 1.35506 to 1.34730, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 19/10000
12/12 - 0s - loss: 1.3492 - accuracy: 0.3820 - val_loss: 1.3462 - val_accuracy: 0.3873

Epoch 00019: val_loss improved from 1.34730 to 1.34616, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 20/10000
12/12 - 0s - loss: 1.3468 - accuracy: 0.3854 - val_loss: 1.3428 - val_accuracy: 0.3729

Epoch 00020: val_loss improved from 1.34616 to 1.34278, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 21/10000
12/12 - 0s - loss: 1.3477 - accuracy: 0.3794 - val_loss: 1.3354 - val_accuracy: 0.4048

Epoch 00021: val_loss improved from 1.34278 to 1.33537, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 22/10000
12/12 - 0s - loss: 1.3423 - accuracy: 0.3890 - val_loss: 1.3366 - val_accuracy: 0.3976

Epoch 00022: val_loss did not improve from 1.33537
Epoch 23/10000
12/12 - 0s - loss: 1.3407 - accuracy: 0.3888 - val_loss: 1.3332 - val_accuracy: 0.3841

Epoch 00023: val_loss improved from 1.33537 to 1.33316, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 24/10000
12/12 - 0s - loss: 1.3398 - accuracy: 0.3859 - val_loss: 1.3322 - val_accuracy: 0.3968

Epoch 00024: val_loss improved from 1.33316 to 1.33217, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 25/10000
12/12 - 0s - loss: 1.3398 - accuracy: 0.3824 - val_loss: 1.3328 - val_accuracy: 0.4024

Epoch 00025: val_loss did not improve from 1.33217
Epoch 26/10000
12/12 - 0s - loss: 1.3442 - accuracy: 0.3759 - val_loss: 1.3332 - val_accuracy: 0.3753

Epoch 00026: val_loss did not improve from 1.33217
Epoch 27/10000
12/12 - 0s - loss: 1.3466 - accuracy: 0.3813 - val_loss: 1.3385 - val_accuracy: 0.3920

Epoch 00027: val_loss did not improve from 1.33217
Epoch 28/10000
12/12 - 0s - loss: 1.3395 - accuracy: 0.3870 - val_loss: 1.3341 - val_accuracy: 0.4024

Epoch 00028: val_loss did not improve from 1.33217
Epoch 29/10000
12/12 - 0s - loss: 1.3371 - accuracy: 0.3911 - val_loss: 1.3305 - val_accuracy: 0.3912

Epoch 00029: val_loss improved from 1.33217 to 1.33047, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 30/10000
12/12 - 0s - loss: 1.3363 - accuracy: 0.3912 - val_loss: 1.3297 - val_accuracy: 0.3968

Epoch 00030: val_loss improved from 1.33047 to 1.32975, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 31/10000
12/12 - 0s - loss: 1.3357 - accuracy: 0.3895 - val_loss: 1.3293 - val_accuracy: 0.3904

Epoch 00031: val_loss improved from 1.32975 to 1.32926, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 32/10000
12/12 - 0s - loss: 1.3355 - accuracy: 0.3903 - val_loss: 1.3305 - val_accuracy: 0.3928

Epoch 00032: val_loss did not improve from 1.32926
Epoch 33/10000
12/12 - 0s - loss: 1.3353 - accuracy: 0.3902 - val_loss: 1.3283 - val_accuracy: 0.3936

Epoch 00033: val_loss improved from 1.32926 to 1.32829, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 34/10000
12/12 - 0s - loss: 1.3365 - accuracy: 0.3883 - val_loss: 1.3305 - val_accuracy: 0.3928

Epoch 00034: val_loss did not improve from 1.32829
Epoch 35/10000
12/12 - 0s - loss: 1.3354 - accuracy: 0.3856 - val_loss: 1.3298 - val_accuracy: 0.3920

Epoch 00035: val_loss did not improve from 1.32829
Epoch 36/10000
12/12 - 0s - loss: 1.3352 - accuracy: 0.3937 - val_loss: 1.3304 - val_accuracy: 0.3880

Epoch 00036: val_loss did not improve from 1.32829
Epoch 37/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3916 - val_loss: 1.3334 - val_accuracy: 0.3841

Epoch 00037: val_loss did not improve from 1.32829
Epoch 38/10000
12/12 - 0s - loss: 1.3382 - accuracy: 0.3859 - val_loss: 1.3299 - val_accuracy: 0.3952

Epoch 00038: val_loss did not improve from 1.32829
Epoch 39/10000
12/12 - 0s - loss: 1.3342 - accuracy: 0.3885 - val_loss: 1.3330 - val_accuracy: 0.3928

Epoch 00039: val_loss did not improve from 1.32829
Epoch 40/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3911 - val_loss: 1.3282 - val_accuracy: 0.3904

Epoch 00040: val_loss improved from 1.32829 to 1.32815, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 41/10000
12/12 - 0s - loss: 1.3344 - accuracy: 0.3893 - val_loss: 1.3304 - val_accuracy: 0.3960

Epoch 00041: val_loss did not improve from 1.32815
Epoch 42/10000
12/12 - 0s - loss: 1.3337 - accuracy: 0.3898 - val_loss: 1.3291 - val_accuracy: 0.3880

Epoch 00042: val_loss did not improve from 1.32815
Epoch 43/10000
12/12 - 0s - loss: 1.3346 - accuracy: 0.3888 - val_loss: 1.3309 - val_accuracy: 0.3841

Epoch 00043: val_loss did not improve from 1.32815
Epoch 44/10000
12/12 - 0s - loss: 1.3345 - accuracy: 0.3913 - val_loss: 1.3293 - val_accuracy: 0.3928

Epoch 00044: val_loss did not improve from 1.32815
Epoch 45/10000
12/12 - 0s - loss: 1.3346 - accuracy: 0.3909 - val_loss: 1.3266 - val_accuracy: 0.3960

Epoch 00045: val_loss improved from 1.32815 to 1.32664, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 46/10000
12/12 - 0s - loss: 1.3337 - accuracy: 0.3912 - val_loss: 1.3267 - val_accuracy: 0.3952

Epoch 00046: val_loss did not improve from 1.32664
Epoch 47/10000
12/12 - 0s - loss: 1.3360 - accuracy: 0.3816 - val_loss: 1.3326 - val_accuracy: 0.3920

Epoch 00047: val_loss did not improve from 1.32664
Epoch 48/10000
12/12 - 0s - loss: 1.3334 - accuracy: 0.3895 - val_loss: 1.3259 - val_accuracy: 0.3944

Epoch 00048: val_loss improved from 1.32664 to 1.32594, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 49/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3964 - val_loss: 1.3256 - val_accuracy: 0.4016

Epoch 00049: val_loss improved from 1.32594 to 1.32565, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 50/10000
12/12 - 0s - loss: 1.3332 - accuracy: 0.3915 - val_loss: 1.3256 - val_accuracy: 0.3833

Epoch 00050: val_loss improved from 1.32565 to 1.32557, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 51/10000
12/12 - 0s - loss: 1.3332 - accuracy: 0.3895 - val_loss: 1.3262 - val_accuracy: 0.3809

Epoch 00051: val_loss did not improve from 1.32557
Epoch 52/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3843 - val_loss: 1.3256 - val_accuracy: 0.3952

Epoch 00052: val_loss improved from 1.32557 to 1.32555, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 53/10000
12/12 - 0s - loss: 1.3334 - accuracy: 0.3840 - val_loss: 1.3235 - val_accuracy: 0.4016

Epoch 00053: val_loss improved from 1.32555 to 1.32349, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 54/10000
12/12 - 0s - loss: 1.3326 - accuracy: 0.3900 - val_loss: 1.3272 - val_accuracy: 0.3952

Epoch 00054: val_loss did not improve from 1.32349
Epoch 55/10000
12/12 - 0s - loss: 1.3311 - accuracy: 0.3908 - val_loss: 1.3241 - val_accuracy: 0.3936

Epoch 00055: val_loss did not improve from 1.32349
Epoch 56/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3942 - val_loss: 1.3275 - val_accuracy: 0.3849

Epoch 00056: val_loss did not improve from 1.32349
Epoch 57/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3926 - val_loss: 1.3281 - val_accuracy: 0.3904

Epoch 00057: val_loss did not improve from 1.32349
Epoch 58/10000
12/12 - 0s - loss: 1.3359 - accuracy: 0.3927 - val_loss: 1.3277 - val_accuracy: 0.3928

Epoch 00058: val_loss did not improve from 1.32349
Epoch 59/10000
12/12 - 0s - loss: 1.3353 - accuracy: 0.3923 - val_loss: 1.3256 - val_accuracy: 0.3952

Epoch 00059: val_loss did not improve from 1.32349
Epoch 60/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3922 - val_loss: 1.3246 - val_accuracy: 0.4008

Epoch 00060: val_loss did not improve from 1.32349
Epoch 61/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3931 - val_loss: 1.3243 - val_accuracy: 0.4000

Epoch 00061: val_loss did not improve from 1.32349
Epoch 62/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3888 - val_loss: 1.3227 - val_accuracy: 0.3849

Epoch 00062: val_loss improved from 1.32349 to 1.32275, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 63/10000
12/12 - 0s - loss: 1.3305 - accuracy: 0.3919 - val_loss: 1.3249 - val_accuracy: 0.3952

Epoch 00063: val_loss did not improve from 1.32275
Epoch 64/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3921 - val_loss: 1.3296 - val_accuracy: 0.3841

Epoch 00064: val_loss did not improve from 1.32275
Epoch 65/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3926 - val_loss: 1.3228 - val_accuracy: 0.3928

Epoch 00065: val_loss did not improve from 1.32275
Epoch 66/10000
12/12 - 0s - loss: 1.3336 - accuracy: 0.3921 - val_loss: 1.3247 - val_accuracy: 0.3968

Epoch 00066: val_loss did not improve from 1.32275
Epoch 67/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3947 - val_loss: 1.3225 - val_accuracy: 0.3984

Epoch 00067: val_loss improved from 1.32275 to 1.32253, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 68/10000
12/12 - 0s - loss: 1.3330 - accuracy: 0.3964 - val_loss: 1.3358 - val_accuracy: 0.3912

Epoch 00068: val_loss did not improve from 1.32253
Epoch 69/10000
12/12 - 0s - loss: 1.3372 - accuracy: 0.3880 - val_loss: 1.3261 - val_accuracy: 0.3873

Epoch 00069: val_loss did not improve from 1.32253
Epoch 70/10000
12/12 - 0s - loss: 1.3316 - accuracy: 0.3934 - val_loss: 1.3233 - val_accuracy: 0.3928

Epoch 00070: val_loss did not improve from 1.32253
Epoch 71/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3923 - val_loss: 1.3236 - val_accuracy: 0.3944

Epoch 00071: val_loss did not improve from 1.32253
Epoch 72/10000
12/12 - 0s - loss: 1.3310 - accuracy: 0.3956 - val_loss: 1.3241 - val_accuracy: 0.3793

Epoch 00072: val_loss did not improve from 1.32253
Epoch 73/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3926 - val_loss: 1.3304 - val_accuracy: 0.3849

Epoch 00073: val_loss did not improve from 1.32253
Epoch 74/10000
12/12 - 0s - loss: 1.3343 - accuracy: 0.3903 - val_loss: 1.3333 - val_accuracy: 0.3928

Epoch 00074: val_loss did not improve from 1.32253
Epoch 75/10000
12/12 - 0s - loss: 1.3386 - accuracy: 0.3870 - val_loss: 1.3387 - val_accuracy: 0.3833

Epoch 00075: val_loss did not improve from 1.32253
Epoch 76/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3935 - val_loss: 1.3238 - val_accuracy: 0.3944

Epoch 00076: val_loss did not improve from 1.32253
Epoch 77/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3964 - val_loss: 1.3215 - val_accuracy: 0.3936

Epoch 00077: val_loss improved from 1.32253 to 1.32153, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 78/10000
12/12 - 0s - loss: 1.3336 - accuracy: 0.3934 - val_loss: 1.3382 - val_accuracy: 0.3785

Epoch 00078: val_loss did not improve from 1.32153
Epoch 79/10000
12/12 - 0s - loss: 1.3354 - accuracy: 0.3879 - val_loss: 1.3237 - val_accuracy: 0.3888

Epoch 00079: val_loss did not improve from 1.32153
Epoch 80/10000
12/12 - 0s - loss: 1.3310 - accuracy: 0.3834 - val_loss: 1.3206 - val_accuracy: 0.4120

Epoch 00080: val_loss improved from 1.32153 to 1.32057, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 81/10000
12/12 - 0s - loss: 1.3314 - accuracy: 0.3859 - val_loss: 1.3246 - val_accuracy: 0.3920

Epoch 00081: val_loss did not improve from 1.32057
Epoch 82/10000
12/12 - 0s - loss: 1.3295 - accuracy: 0.3909 - val_loss: 1.3226 - val_accuracy: 0.3928

Epoch 00082: val_loss did not improve from 1.32057
Epoch 83/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3928 - val_loss: 1.3209 - val_accuracy: 0.3984

Epoch 00083: val_loss did not improve from 1.32057
Epoch 84/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3947 - val_loss: 1.3208 - val_accuracy: 0.3944

Epoch 00084: val_loss did not improve from 1.32057
Epoch 85/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3940 - val_loss: 1.3230 - val_accuracy: 0.3944

Epoch 00085: val_loss did not improve from 1.32057
Epoch 86/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3930 - val_loss: 1.3226 - val_accuracy: 0.3992

Epoch 00086: val_loss did not improve from 1.32057
Epoch 87/10000
12/12 - 0s - loss: 1.3310 - accuracy: 0.3932 - val_loss: 1.3243 - val_accuracy: 0.3888

Epoch 00087: val_loss did not improve from 1.32057
Epoch 88/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3912 - val_loss: 1.3240 - val_accuracy: 0.3785

Epoch 00088: val_loss did not improve from 1.32057
Epoch 89/10000
12/12 - 0s - loss: 1.3307 - accuracy: 0.3940 - val_loss: 1.3197 - val_accuracy: 0.3952

Epoch 00089: val_loss improved from 1.32057 to 1.31970, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 90/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3943 - val_loss: 1.3211 - val_accuracy: 0.3968

Epoch 00090: val_loss did not improve from 1.31970
Epoch 91/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3935 - val_loss: 1.3209 - val_accuracy: 0.3912

Epoch 00091: val_loss did not improve from 1.31970
Epoch 92/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3964 - val_loss: 1.3258 - val_accuracy: 0.3817

Epoch 00092: val_loss did not improve from 1.31970
Epoch 93/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3919 - val_loss: 1.3248 - val_accuracy: 0.3936

Epoch 00093: val_loss did not improve from 1.31970
Epoch 94/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3925 - val_loss: 1.3230 - val_accuracy: 0.3841

Epoch 00094: val_loss did not improve from 1.31970
Epoch 95/10000
12/12 - 0s - loss: 1.3314 - accuracy: 0.3950 - val_loss: 1.3279 - val_accuracy: 0.3841

Epoch 00095: val_loss did not improve from 1.31970
Epoch 96/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3968 - val_loss: 1.3232 - val_accuracy: 0.3968

Epoch 00096: val_loss did not improve from 1.31970
Epoch 97/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3980 - val_loss: 1.3209 - val_accuracy: 0.3880

Epoch 00097: val_loss did not improve from 1.31970
Epoch 98/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3903 - val_loss: 1.3273 - val_accuracy: 0.3801

Epoch 00098: val_loss did not improve from 1.31970
Epoch 99/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.3906 - val_loss: 1.3255 - val_accuracy: 0.3785

Epoch 00099: val_loss did not improve from 1.31970
Epoch 100/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3887 - val_loss: 1.3254 - val_accuracy: 0.3857

Epoch 00100: val_loss did not improve from 1.31970
Epoch 101/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3944 - val_loss: 1.3225 - val_accuracy: 0.3865

Epoch 00101: val_loss did not improve from 1.31970
Epoch 102/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3930 - val_loss: 1.3205 - val_accuracy: 0.3936

Epoch 00102: val_loss did not improve from 1.31970
Epoch 103/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3936 - val_loss: 1.3214 - val_accuracy: 0.4040

Epoch 00103: val_loss did not improve from 1.31970
Epoch 104/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3952 - val_loss: 1.3242 - val_accuracy: 0.3976

Epoch 00104: val_loss did not improve from 1.31970
Epoch 105/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3937 - val_loss: 1.3211 - val_accuracy: 0.3952

Epoch 00105: val_loss did not improve from 1.31970
Epoch 106/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3958 - val_loss: 1.3256 - val_accuracy: 0.3801

Epoch 00106: val_loss did not improve from 1.31970
Epoch 107/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3938 - val_loss: 1.3227 - val_accuracy: 0.3849

Epoch 00107: val_loss did not improve from 1.31970
Epoch 108/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3926 - val_loss: 1.3178 - val_accuracy: 0.3928

Epoch 00108: val_loss improved from 1.31970 to 1.31782, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 109/10000
12/12 - 0s - loss: 1.3276 - accuracy: 0.3959 - val_loss: 1.3258 - val_accuracy: 0.3920

Epoch 00109: val_loss did not improve from 1.31782
Epoch 110/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3915 - val_loss: 1.3212 - val_accuracy: 0.3968

Epoch 00110: val_loss did not improve from 1.31782
Epoch 111/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3934 - val_loss: 1.3186 - val_accuracy: 0.3960

Epoch 00111: val_loss did not improve from 1.31782
Epoch 112/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3936 - val_loss: 1.3255 - val_accuracy: 0.3904

Epoch 00112: val_loss did not improve from 1.31782
Epoch 113/10000
12/12 - 0s - loss: 1.3304 - accuracy: 0.3912 - val_loss: 1.3219 - val_accuracy: 0.3968

Epoch 00113: val_loss did not improve from 1.31782
Epoch 114/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3950 - val_loss: 1.3226 - val_accuracy: 0.3841

Epoch 00114: val_loss did not improve from 1.31782
Epoch 115/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3972 - val_loss: 1.3209 - val_accuracy: 0.3920

Epoch 00115: val_loss did not improve from 1.31782
Epoch 116/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3945 - val_loss: 1.3208 - val_accuracy: 0.4040

Epoch 00116: val_loss did not improve from 1.31782
Epoch 117/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3958 - val_loss: 1.3191 - val_accuracy: 0.3984

Epoch 00117: val_loss did not improve from 1.31782
Epoch 118/10000
12/12 - 0s - loss: 1.3314 - accuracy: 0.3975 - val_loss: 1.3265 - val_accuracy: 0.3809

Epoch 00118: val_loss did not improve from 1.31782
Epoch 119/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.3955 - val_loss: 1.3200 - val_accuracy: 0.3984

Epoch 00119: val_loss did not improve from 1.31782
Epoch 120/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3934 - val_loss: 1.3185 - val_accuracy: 0.3952

Epoch 00120: val_loss did not improve from 1.31782
Epoch 121/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3948 - val_loss: 1.3189 - val_accuracy: 0.3944

Epoch 00121: val_loss did not improve from 1.31782
Epoch 122/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3955 - val_loss: 1.3183 - val_accuracy: 0.3880

Epoch 00122: val_loss did not improve from 1.31782
Epoch 123/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3852 - val_loss: 1.3195 - val_accuracy: 0.4016

Epoch 00123: val_loss did not improve from 1.31782
Epoch 124/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3922 - val_loss: 1.3202 - val_accuracy: 0.4104

Epoch 00124: val_loss did not improve from 1.31782
Epoch 125/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3898 - val_loss: 1.3193 - val_accuracy: 0.3880

Epoch 00125: val_loss did not improve from 1.31782
Epoch 126/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3965 - val_loss: 1.3210 - val_accuracy: 0.3825

Epoch 00126: val_loss did not improve from 1.31782
Epoch 127/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3921 - val_loss: 1.3197 - val_accuracy: 0.3968

Epoch 00127: val_loss did not improve from 1.31782
Epoch 128/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3961 - val_loss: 1.3185 - val_accuracy: 0.3920

Epoch 00128: val_loss did not improve from 1.31782
Epoch 129/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3909 - val_loss: 1.3170 - val_accuracy: 0.4056

Epoch 00129: val_loss improved from 1.31782 to 1.31697, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 130/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3917 - val_loss: 1.3195 - val_accuracy: 0.3976

Epoch 00130: val_loss did not improve from 1.31697
Epoch 131/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3946 - val_loss: 1.3185 - val_accuracy: 0.3968

Epoch 00131: val_loss did not improve from 1.31697
Epoch 132/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3977 - val_loss: 1.3176 - val_accuracy: 0.3928

Epoch 00132: val_loss did not improve from 1.31697
Epoch 133/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3903 - val_loss: 1.3184 - val_accuracy: 0.3944

Epoch 00133: val_loss did not improve from 1.31697
Epoch 134/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3939 - val_loss: 1.3240 - val_accuracy: 0.3904

Epoch 00134: val_loss did not improve from 1.31697
Epoch 135/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3964 - val_loss: 1.3201 - val_accuracy: 0.3849

Epoch 00135: val_loss did not improve from 1.31697
Epoch 136/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3966 - val_loss: 1.3214 - val_accuracy: 0.3833

Epoch 00136: val_loss did not improve from 1.31697
Epoch 137/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3965 - val_loss: 1.3169 - val_accuracy: 0.3968

Epoch 00137: val_loss improved from 1.31697 to 1.31689, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 138/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3965 - val_loss: 1.3194 - val_accuracy: 0.3888

Epoch 00138: val_loss did not improve from 1.31689
Epoch 139/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3948 - val_loss: 1.3192 - val_accuracy: 0.3920

Epoch 00139: val_loss did not improve from 1.31689
Epoch 140/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3933 - val_loss: 1.3163 - val_accuracy: 0.3944

Epoch 00140: val_loss improved from 1.31689 to 1.31631, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 141/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3921 - val_loss: 1.3210 - val_accuracy: 0.3857

Epoch 00141: val_loss did not improve from 1.31631
Epoch 142/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3965 - val_loss: 1.3194 - val_accuracy: 0.3928

Epoch 00142: val_loss did not improve from 1.31631
Epoch 143/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3986 - val_loss: 1.3193 - val_accuracy: 0.3849

Epoch 00143: val_loss did not improve from 1.31631
Epoch 144/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3955 - val_loss: 1.3195 - val_accuracy: 0.3849

Epoch 00144: val_loss did not improve from 1.31631
Epoch 145/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3965 - val_loss: 1.3179 - val_accuracy: 0.3984

Epoch 00145: val_loss did not improve from 1.31631
Epoch 146/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3925 - val_loss: 1.3176 - val_accuracy: 0.3968

Epoch 00146: val_loss did not improve from 1.31631
Epoch 147/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3953 - val_loss: 1.3227 - val_accuracy: 0.3928

Epoch 00147: val_loss did not improve from 1.31631
Epoch 148/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3949 - val_loss: 1.3173 - val_accuracy: 0.3880

Epoch 00148: val_loss did not improve from 1.31631
Epoch 149/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3919 - val_loss: 1.3165 - val_accuracy: 0.3984

Epoch 00149: val_loss did not improve from 1.31631
Epoch 150/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3941 - val_loss: 1.3203 - val_accuracy: 0.3992

Epoch 00150: val_loss did not improve from 1.31631
Epoch 151/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3967 - val_loss: 1.3230 - val_accuracy: 0.3801

Epoch 00151: val_loss did not improve from 1.31631
Epoch 152/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3999 - val_loss: 1.3165 - val_accuracy: 0.4000

Epoch 00152: val_loss did not improve from 1.31631
Epoch 153/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3974 - val_loss: 1.3187 - val_accuracy: 0.4008

Epoch 00153: val_loss did not improve from 1.31631
Epoch 154/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3934 - val_loss: 1.3152 - val_accuracy: 0.3968

Epoch 00154: val_loss improved from 1.31631 to 1.31520, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 155/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3905 - val_loss: 1.3302 - val_accuracy: 0.3880

Epoch 00155: val_loss did not improve from 1.31520
Epoch 156/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3910 - val_loss: 1.3195 - val_accuracy: 0.3976

Epoch 00156: val_loss did not improve from 1.31520
Epoch 157/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3968 - val_loss: 1.3204 - val_accuracy: 0.3992

Epoch 00157: val_loss did not improve from 1.31520
Epoch 158/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3903 - val_loss: 1.3180 - val_accuracy: 0.4048

Epoch 00158: val_loss did not improve from 1.31520
Epoch 159/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3961 - val_loss: 1.3186 - val_accuracy: 0.4008

Epoch 00159: val_loss did not improve from 1.31520
Epoch 160/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3964 - val_loss: 1.3208 - val_accuracy: 0.3753

Epoch 00160: val_loss did not improve from 1.31520
Epoch 161/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3943 - val_loss: 1.3153 - val_accuracy: 0.3968

Epoch 00161: val_loss did not improve from 1.31520
Epoch 162/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3973 - val_loss: 1.3173 - val_accuracy: 0.3928

Epoch 00162: val_loss did not improve from 1.31520
Epoch 163/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3968 - val_loss: 1.3176 - val_accuracy: 0.3968

Epoch 00163: val_loss did not improve from 1.31520
Epoch 164/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3963 - val_loss: 1.3213 - val_accuracy: 0.3833

Epoch 00164: val_loss did not improve from 1.31520
Epoch 165/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3968 - val_loss: 1.3179 - val_accuracy: 0.4008

Epoch 00165: val_loss did not improve from 1.31520
Epoch 166/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3931 - val_loss: 1.3200 - val_accuracy: 0.3769

Epoch 00166: val_loss did not improve from 1.31520
Epoch 167/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3950 - val_loss: 1.3181 - val_accuracy: 0.3896

Epoch 00167: val_loss did not improve from 1.31520
Epoch 168/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3930 - val_loss: 1.3176 - val_accuracy: 0.3992

Epoch 00168: val_loss did not improve from 1.31520
Epoch 169/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3895 - val_loss: 1.3174 - val_accuracy: 0.3880

Epoch 00169: val_loss did not improve from 1.31520
Epoch 170/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3986 - val_loss: 1.3177 - val_accuracy: 0.3904

Epoch 00170: val_loss did not improve from 1.31520
Epoch 171/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3939 - val_loss: 1.3184 - val_accuracy: 0.3968

Epoch 00171: val_loss did not improve from 1.31520
Epoch 172/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3920 - val_loss: 1.3170 - val_accuracy: 0.3904

Epoch 00172: val_loss did not improve from 1.31520
Epoch 173/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3939 - val_loss: 1.3166 - val_accuracy: 0.3984

Epoch 00173: val_loss did not improve from 1.31520
Epoch 174/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3945 - val_loss: 1.3198 - val_accuracy: 0.3960

Epoch 00174: val_loss did not improve from 1.31520
Epoch 175/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3926 - val_loss: 1.3178 - val_accuracy: 0.3952

Epoch 00175: val_loss did not improve from 1.31520
Epoch 176/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3955 - val_loss: 1.3178 - val_accuracy: 0.3809

Epoch 00176: val_loss did not improve from 1.31520
Epoch 177/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3947 - val_loss: 1.3164 - val_accuracy: 0.3984

Epoch 00177: val_loss did not improve from 1.31520
Epoch 178/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3928 - val_loss: 1.3205 - val_accuracy: 0.3857

Epoch 00178: val_loss did not improve from 1.31520
Epoch 179/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3878 - val_loss: 1.3160 - val_accuracy: 0.4135

Epoch 00179: val_loss did not improve from 1.31520
Epoch 180/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3968 - val_loss: 1.3204 - val_accuracy: 0.3849

Epoch 00180: val_loss did not improve from 1.31520
Epoch 181/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.4007 - val_loss: 1.3200 - val_accuracy: 0.3793

Epoch 00181: val_loss did not improve from 1.31520
Epoch 182/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3932 - val_loss: 1.3170 - val_accuracy: 0.4032

Epoch 00182: val_loss did not improve from 1.31520
Epoch 183/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3969 - val_loss: 1.3161 - val_accuracy: 0.3976

Epoch 00183: val_loss did not improve from 1.31520
Epoch 184/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3973 - val_loss: 1.3154 - val_accuracy: 0.3976

Epoch 00184: val_loss did not improve from 1.31520
Epoch 185/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3940 - val_loss: 1.3194 - val_accuracy: 0.3984

Epoch 00185: val_loss did not improve from 1.31520
Epoch 186/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3966 - val_loss: 1.3163 - val_accuracy: 0.4000

Epoch 00186: val_loss did not improve from 1.31520
Epoch 187/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3927 - val_loss: 1.3224 - val_accuracy: 0.3865

Epoch 00187: val_loss did not improve from 1.31520
Epoch 188/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3989 - val_loss: 1.3170 - val_accuracy: 0.3912

Epoch 00188: val_loss did not improve from 1.31520
Epoch 189/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3937 - val_loss: 1.3160 - val_accuracy: 0.3960

Epoch 00189: val_loss did not improve from 1.31520
Epoch 190/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3955 - val_loss: 1.3160 - val_accuracy: 0.3849

Epoch 00190: val_loss did not improve from 1.31520
Epoch 191/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3928 - val_loss: 1.3164 - val_accuracy: 0.3896

Epoch 00191: val_loss did not improve from 1.31520
Epoch 192/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3982 - val_loss: 1.3165 - val_accuracy: 0.3896

Epoch 00192: val_loss did not improve from 1.31520
Epoch 193/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3903 - val_loss: 1.3161 - val_accuracy: 0.4032

Epoch 00193: val_loss did not improve from 1.31520
Epoch 194/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3901 - val_loss: 1.3177 - val_accuracy: 0.3968

Epoch 00194: val_loss did not improve from 1.31520
Epoch 195/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3950 - val_loss: 1.3188 - val_accuracy: 0.4000

Epoch 00195: val_loss did not improve from 1.31520
Epoch 196/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3986 - val_loss: 1.3251 - val_accuracy: 0.3705

Epoch 00196: val_loss did not improve from 1.31520
Epoch 197/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3936 - val_loss: 1.3174 - val_accuracy: 0.3880

Epoch 00197: val_loss did not improve from 1.31520
Epoch 198/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3931 - val_loss: 1.3179 - val_accuracy: 0.3857

Epoch 00198: val_loss did not improve from 1.31520
Epoch 199/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3961 - val_loss: 1.3204 - val_accuracy: 0.3825

Epoch 00199: val_loss did not improve from 1.31520
Epoch 200/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3957 - val_loss: 1.3147 - val_accuracy: 0.3952

Epoch 00200: val_loss improved from 1.31520 to 1.31465, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 201/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3974 - val_loss: 1.3160 - val_accuracy: 0.3976

Epoch 00201: val_loss did not improve from 1.31465
Epoch 202/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3942 - val_loss: 1.3146 - val_accuracy: 0.3825

Epoch 00202: val_loss improved from 1.31465 to 1.31464, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 203/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3871 - val_loss: 1.3140 - val_accuracy: 0.3976

Epoch 00203: val_loss improved from 1.31464 to 1.31396, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 204/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3914 - val_loss: 1.3182 - val_accuracy: 0.3865

Epoch 00204: val_loss did not improve from 1.31396
Epoch 205/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3925 - val_loss: 1.3165 - val_accuracy: 0.3880

Epoch 00205: val_loss did not improve from 1.31396
Epoch 206/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3970 - val_loss: 1.3163 - val_accuracy: 0.3865

Epoch 00206: val_loss did not improve from 1.31396
Epoch 207/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3990 - val_loss: 1.3167 - val_accuracy: 0.4024

Epoch 00207: val_loss did not improve from 1.31396
Epoch 208/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3943 - val_loss: 1.3164 - val_accuracy: 0.4016

Epoch 00208: val_loss did not improve from 1.31396
Epoch 209/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3903 - val_loss: 1.3156 - val_accuracy: 0.4016

Epoch 00209: val_loss did not improve from 1.31396
Epoch 210/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3860 - val_loss: 1.3153 - val_accuracy: 0.3880

Epoch 00210: val_loss did not improve from 1.31396
Epoch 211/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3935 - val_loss: 1.3170 - val_accuracy: 0.3904

Epoch 00211: val_loss did not improve from 1.31396
Epoch 212/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3928 - val_loss: 1.3193 - val_accuracy: 0.3920

Epoch 00212: val_loss did not improve from 1.31396
Epoch 213/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3898 - val_loss: 1.3164 - val_accuracy: 0.4016

Epoch 00213: val_loss did not improve from 1.31396
Epoch 214/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3940 - val_loss: 1.3163 - val_accuracy: 0.3960

Epoch 00214: val_loss did not improve from 1.31396
Epoch 215/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3943 - val_loss: 1.3269 - val_accuracy: 0.3817

Epoch 00215: val_loss did not improve from 1.31396
Epoch 216/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3967 - val_loss: 1.3160 - val_accuracy: 0.3920

Epoch 00216: val_loss did not improve from 1.31396
Epoch 217/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3969 - val_loss: 1.3173 - val_accuracy: 0.3833

Epoch 00217: val_loss did not improve from 1.31396
Epoch 218/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3950 - val_loss: 1.3136 - val_accuracy: 0.3976

Epoch 00218: val_loss improved from 1.31396 to 1.31360, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 219/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3942 - val_loss: 1.3160 - val_accuracy: 0.3912

Epoch 00219: val_loss did not improve from 1.31360
Epoch 220/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3926 - val_loss: 1.3179 - val_accuracy: 0.3904

Epoch 00220: val_loss did not improve from 1.31360
Epoch 221/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3917 - val_loss: 1.3181 - val_accuracy: 0.3936

Epoch 00221: val_loss did not improve from 1.31360
Epoch 222/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3914 - val_loss: 1.3181 - val_accuracy: 0.3896

Epoch 00222: val_loss did not improve from 1.31360
Epoch 223/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3925 - val_loss: 1.3157 - val_accuracy: 0.3880

Epoch 00223: val_loss did not improve from 1.31360
Epoch 224/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3970 - val_loss: 1.3158 - val_accuracy: 0.3992

Epoch 00224: val_loss did not improve from 1.31360
Epoch 225/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3903 - val_loss: 1.3146 - val_accuracy: 0.3873

Epoch 00225: val_loss did not improve from 1.31360
Epoch 226/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3934 - val_loss: 1.3165 - val_accuracy: 0.3880

Epoch 00226: val_loss did not improve from 1.31360
Epoch 227/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3949 - val_loss: 1.3152 - val_accuracy: 0.3952

Epoch 00227: val_loss did not improve from 1.31360
Epoch 228/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3922 - val_loss: 1.3167 - val_accuracy: 0.3809

Epoch 00228: val_loss did not improve from 1.31360
Epoch 229/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3945 - val_loss: 1.3155 - val_accuracy: 0.3920

Epoch 00229: val_loss did not improve from 1.31360
Epoch 230/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3943 - val_loss: 1.3150 - val_accuracy: 0.4032

Epoch 00230: val_loss did not improve from 1.31360
Epoch 231/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3919 - val_loss: 1.3130 - val_accuracy: 0.4064

Epoch 00231: val_loss improved from 1.31360 to 1.31299, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 232/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3940 - val_loss: 1.3194 - val_accuracy: 0.3880

Epoch 00232: val_loss did not improve from 1.31299
Epoch 233/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3961 - val_loss: 1.3216 - val_accuracy: 0.3833

Epoch 00233: val_loss did not improve from 1.31299
Epoch 234/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3906 - val_loss: 1.3180 - val_accuracy: 0.4032

Epoch 00234: val_loss did not improve from 1.31299
Epoch 235/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3927 - val_loss: 1.3175 - val_accuracy: 0.3769

Epoch 00235: val_loss did not improve from 1.31299
Epoch 236/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3996 - val_loss: 1.3166 - val_accuracy: 0.3825

Epoch 00236: val_loss did not improve from 1.31299
Epoch 237/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3919 - val_loss: 1.3162 - val_accuracy: 0.4024

Epoch 00237: val_loss did not improve from 1.31299
Epoch 238/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3931 - val_loss: 1.3158 - val_accuracy: 0.3944

Epoch 00238: val_loss did not improve from 1.31299
Epoch 239/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3955 - val_loss: 1.3147 - val_accuracy: 0.3865

Epoch 00239: val_loss did not improve from 1.31299
Epoch 240/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3922 - val_loss: 1.3157 - val_accuracy: 0.3833

Epoch 00240: val_loss did not improve from 1.31299
Epoch 241/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3919 - val_loss: 1.3150 - val_accuracy: 0.4056

Epoch 00241: val_loss did not improve from 1.31299
Epoch 242/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3982 - val_loss: 1.3222 - val_accuracy: 0.3777

Epoch 00242: val_loss did not improve from 1.31299
Epoch 243/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3988 - val_loss: 1.3158 - val_accuracy: 0.3984

Epoch 00243: val_loss did not improve from 1.31299
Epoch 244/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3916 - val_loss: 1.3175 - val_accuracy: 0.3873

Epoch 00244: val_loss did not improve from 1.31299
Epoch 245/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3895 - val_loss: 1.3137 - val_accuracy: 0.3880

Epoch 00245: val_loss did not improve from 1.31299
Epoch 246/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3989 - val_loss: 1.3163 - val_accuracy: 0.3873

Epoch 00246: val_loss did not improve from 1.31299
Epoch 247/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3956 - val_loss: 1.3136 - val_accuracy: 0.3992

Epoch 00247: val_loss did not improve from 1.31299
Epoch 248/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3957 - val_loss: 1.3179 - val_accuracy: 0.3793

Epoch 00248: val_loss did not improve from 1.31299
Epoch 249/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3949 - val_loss: 1.3149 - val_accuracy: 0.3952

Epoch 00249: val_loss did not improve from 1.31299
Epoch 250/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3938 - val_loss: 1.3134 - val_accuracy: 0.3952

Epoch 00250: val_loss did not improve from 1.31299
Epoch 251/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3940 - val_loss: 1.3156 - val_accuracy: 0.3928

Epoch 00251: val_loss did not improve from 1.31299
Epoch 252/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3956 - val_loss: 1.3168 - val_accuracy: 0.3801

Epoch 00252: val_loss did not improve from 1.31299
Epoch 253/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3922 - val_loss: 1.3152 - val_accuracy: 0.3976

Epoch 00253: val_loss did not improve from 1.31299
Epoch 254/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3928 - val_loss: 1.3160 - val_accuracy: 0.3928

Epoch 00254: val_loss did not improve from 1.31299
Epoch 255/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3932 - val_loss: 1.3160 - val_accuracy: 0.3936

Epoch 00255: val_loss did not improve from 1.31299
Epoch 256/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3989 - val_loss: 1.3243 - val_accuracy: 0.3857

Epoch 00256: val_loss did not improve from 1.31299
Epoch 257/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3953 - val_loss: 1.3186 - val_accuracy: 0.4024

Epoch 00257: val_loss did not improve from 1.31299
Epoch 258/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3937 - val_loss: 1.3230 - val_accuracy: 0.3880

Epoch 00258: val_loss did not improve from 1.31299
Epoch 259/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3950 - val_loss: 1.3149 - val_accuracy: 0.3960

Epoch 00259: val_loss did not improve from 1.31299
Epoch 260/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3988 - val_loss: 1.3167 - val_accuracy: 0.3944

Epoch 00260: val_loss did not improve from 1.31299
Epoch 261/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3942 - val_loss: 1.3181 - val_accuracy: 0.3904

Epoch 00261: val_loss did not improve from 1.31299
Epoch 262/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3976 - val_loss: 1.3169 - val_accuracy: 0.3904

Epoch 00262: val_loss did not improve from 1.31299
Epoch 263/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3980 - val_loss: 1.3154 - val_accuracy: 0.3801

Epoch 00263: val_loss did not improve from 1.31299
Epoch 264/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3964 - val_loss: 1.3134 - val_accuracy: 0.3936

Epoch 00264: val_loss did not improve from 1.31299
Epoch 265/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3943 - val_loss: 1.3129 - val_accuracy: 0.3968

Epoch 00265: val_loss improved from 1.31299 to 1.31290, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 266/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3934 - val_loss: 1.3162 - val_accuracy: 0.3825

Epoch 00266: val_loss did not improve from 1.31290
Epoch 267/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4015 - val_loss: 1.3158 - val_accuracy: 0.3857

Epoch 00267: val_loss did not improve from 1.31290
Epoch 268/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3971 - val_loss: 1.3122 - val_accuracy: 0.3968

Epoch 00268: val_loss improved from 1.31290 to 1.31215, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 269/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3950 - val_loss: 1.3114 - val_accuracy: 0.4024

Epoch 00269: val_loss improved from 1.31215 to 1.31143, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 270/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3920 - val_loss: 1.3146 - val_accuracy: 0.3857

Epoch 00270: val_loss did not improve from 1.31143
Epoch 271/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3965 - val_loss: 1.3125 - val_accuracy: 0.3888

Epoch 00271: val_loss did not improve from 1.31143
Epoch 272/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3926 - val_loss: 1.3154 - val_accuracy: 0.3904

Epoch 00272: val_loss did not improve from 1.31143
Epoch 273/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3959 - val_loss: 1.3134 - val_accuracy: 0.3976

Epoch 00273: val_loss did not improve from 1.31143
Epoch 274/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3960 - val_loss: 1.3152 - val_accuracy: 0.4064

Epoch 00274: val_loss did not improve from 1.31143
Epoch 275/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3946 - val_loss: 1.3127 - val_accuracy: 0.3904

Epoch 00275: val_loss did not improve from 1.31143
Epoch 276/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3934 - val_loss: 1.3124 - val_accuracy: 0.3960

Epoch 00276: val_loss did not improve from 1.31143
Epoch 277/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3950 - val_loss: 1.3135 - val_accuracy: 0.3960

Epoch 00277: val_loss did not improve from 1.31143
Epoch 278/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3965 - val_loss: 1.3130 - val_accuracy: 0.3880

Epoch 00278: val_loss did not improve from 1.31143
Epoch 279/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3931 - val_loss: 1.3145 - val_accuracy: 0.3936

Epoch 00279: val_loss did not improve from 1.31143
Epoch 280/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3957 - val_loss: 1.3131 - val_accuracy: 0.4040

Epoch 00280: val_loss did not improve from 1.31143
Epoch 281/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3972 - val_loss: 1.3191 - val_accuracy: 0.3944

Epoch 00281: val_loss did not improve from 1.31143
Epoch 282/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3926 - val_loss: 1.3120 - val_accuracy: 0.3968

Epoch 00282: val_loss did not improve from 1.31143
Epoch 283/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3965 - val_loss: 1.3112 - val_accuracy: 0.3952

Epoch 00283: val_loss improved from 1.31143 to 1.31118, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 284/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.4027 - val_loss: 1.3161 - val_accuracy: 0.3865

Epoch 00284: val_loss did not improve from 1.31118
Epoch 285/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3975 - val_loss: 1.3146 - val_accuracy: 0.3920

Epoch 00285: val_loss did not improve from 1.31118
Epoch 286/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3936 - val_loss: 1.3135 - val_accuracy: 0.3928

Epoch 00286: val_loss did not improve from 1.31118
Epoch 287/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3978 - val_loss: 1.3126 - val_accuracy: 0.3904

Epoch 00287: val_loss did not improve from 1.31118
Epoch 288/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3980 - val_loss: 1.3114 - val_accuracy: 0.3928

Epoch 00288: val_loss did not improve from 1.31118
Epoch 289/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3932 - val_loss: 1.3138 - val_accuracy: 0.3968

Epoch 00289: val_loss did not improve from 1.31118
Epoch 290/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3945 - val_loss: 1.3097 - val_accuracy: 0.3904

Epoch 00290: val_loss improved from 1.31118 to 1.30975, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 291/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3973 - val_loss: 1.3158 - val_accuracy: 0.3793

Epoch 00291: val_loss did not improve from 1.30975
Epoch 292/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3962 - val_loss: 1.3117 - val_accuracy: 0.3904

Epoch 00292: val_loss did not improve from 1.30975
Epoch 293/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3991 - val_loss: 1.3131 - val_accuracy: 0.3880

Epoch 00293: val_loss did not improve from 1.30975
Epoch 294/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3919 - val_loss: 1.3132 - val_accuracy: 0.3857

Epoch 00294: val_loss did not improve from 1.30975
Epoch 295/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3986 - val_loss: 1.3193 - val_accuracy: 0.3880

Epoch 00295: val_loss did not improve from 1.30975
Epoch 296/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3925 - val_loss: 1.3134 - val_accuracy: 0.3976

Epoch 00296: val_loss did not improve from 1.30975
Epoch 297/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3915 - val_loss: 1.3132 - val_accuracy: 0.3936

Epoch 00297: val_loss did not improve from 1.30975
Epoch 298/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3957 - val_loss: 1.3175 - val_accuracy: 0.3920

Epoch 00298: val_loss did not improve from 1.30975
Epoch 299/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3988 - val_loss: 1.3168 - val_accuracy: 0.3793

Epoch 00299: val_loss did not improve from 1.30975
Epoch 300/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3915 - val_loss: 1.3131 - val_accuracy: 0.3912

Epoch 00300: val_loss did not improve from 1.30975
Epoch 301/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3992 - val_loss: 1.3228 - val_accuracy: 0.3777

Epoch 00301: val_loss did not improve from 1.30975
Epoch 302/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3927 - val_loss: 1.3123 - val_accuracy: 0.3849

Epoch 00302: val_loss did not improve from 1.30975
Epoch 303/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3962 - val_loss: 1.3114 - val_accuracy: 0.3944

Epoch 00303: val_loss did not improve from 1.30975
Epoch 304/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3977 - val_loss: 1.3126 - val_accuracy: 0.3920

Epoch 00304: val_loss did not improve from 1.30975
Epoch 305/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3970 - val_loss: 1.3097 - val_accuracy: 0.3928

Epoch 00305: val_loss improved from 1.30975 to 1.30972, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 306/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3994 - val_loss: 1.3182 - val_accuracy: 0.3896

Epoch 00306: val_loss did not improve from 1.30972
Epoch 307/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3943 - val_loss: 1.3131 - val_accuracy: 0.3928

Epoch 00307: val_loss did not improve from 1.30972
Epoch 308/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3940 - val_loss: 1.3111 - val_accuracy: 0.3896

Epoch 00308: val_loss did not improve from 1.30972
Epoch 309/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3985 - val_loss: 1.3120 - val_accuracy: 0.3912

Epoch 00309: val_loss did not improve from 1.30972
Epoch 310/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3954 - val_loss: 1.3108 - val_accuracy: 0.3849

Epoch 00310: val_loss did not improve from 1.30972
Epoch 311/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3959 - val_loss: 1.3165 - val_accuracy: 0.4032

Epoch 00311: val_loss did not improve from 1.30972
Epoch 312/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3965 - val_loss: 1.3161 - val_accuracy: 0.3801

Epoch 00312: val_loss did not improve from 1.30972
Epoch 313/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3973 - val_loss: 1.3100 - val_accuracy: 0.3896

Epoch 00313: val_loss did not improve from 1.30972
Epoch 314/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3966 - val_loss: 1.3126 - val_accuracy: 0.3912

Epoch 00314: val_loss did not improve from 1.30972
Epoch 315/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3999 - val_loss: 1.3133 - val_accuracy: 0.4000

Epoch 00315: val_loss did not improve from 1.30972
Epoch 316/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3966 - val_loss: 1.3087 - val_accuracy: 0.3920

Epoch 00316: val_loss improved from 1.30972 to 1.30866, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 317/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3942 - val_loss: 1.3129 - val_accuracy: 0.3880

Epoch 00317: val_loss did not improve from 1.30866
Epoch 318/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3950 - val_loss: 1.3168 - val_accuracy: 0.4048

Epoch 00318: val_loss did not improve from 1.30866
Epoch 319/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.4000 - val_loss: 1.3236 - val_accuracy: 0.3745

Epoch 00319: val_loss did not improve from 1.30866
Epoch 320/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3903 - val_loss: 1.3157 - val_accuracy: 0.3952

Epoch 00320: val_loss did not improve from 1.30866
Epoch 321/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3949 - val_loss: 1.3141 - val_accuracy: 0.3841

Epoch 00321: val_loss did not improve from 1.30866
Epoch 322/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3967 - val_loss: 1.3111 - val_accuracy: 0.3936

Epoch 00322: val_loss did not improve from 1.30866
Epoch 323/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3947 - val_loss: 1.3122 - val_accuracy: 0.3904

Epoch 00323: val_loss did not improve from 1.30866
Epoch 324/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3994 - val_loss: 1.3100 - val_accuracy: 0.3912

Epoch 00324: val_loss did not improve from 1.30866
Epoch 325/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3962 - val_loss: 1.3118 - val_accuracy: 0.3857

Epoch 00325: val_loss did not improve from 1.30866
Epoch 326/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3957 - val_loss: 1.3115 - val_accuracy: 0.3920

Epoch 00326: val_loss did not improve from 1.30866
Epoch 327/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4015 - val_loss: 1.3136 - val_accuracy: 0.3896

Epoch 00327: val_loss did not improve from 1.30866
Epoch 328/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3968 - val_loss: 1.3116 - val_accuracy: 0.3912

Epoch 00328: val_loss did not improve from 1.30866
Epoch 329/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3968 - val_loss: 1.3155 - val_accuracy: 0.3912

Epoch 00329: val_loss did not improve from 1.30866
Epoch 330/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3981 - val_loss: 1.3122 - val_accuracy: 0.3960

Epoch 00330: val_loss did not improve from 1.30866
Epoch 331/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3960 - val_loss: 1.3106 - val_accuracy: 0.4016

Epoch 00331: val_loss did not improve from 1.30866
Epoch 332/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3986 - val_loss: 1.3159 - val_accuracy: 0.3968

Epoch 00332: val_loss did not improve from 1.30866
Epoch 333/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3989 - val_loss: 1.3104 - val_accuracy: 0.3936

Epoch 00333: val_loss did not improve from 1.30866
Epoch 334/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3970 - val_loss: 1.3119 - val_accuracy: 0.3888

Epoch 00334: val_loss did not improve from 1.30866
Epoch 335/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4001 - val_loss: 1.3117 - val_accuracy: 0.3873

Epoch 00335: val_loss did not improve from 1.30866
Epoch 336/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3978 - val_loss: 1.3086 - val_accuracy: 0.4000

Epoch 00336: val_loss improved from 1.30866 to 1.30863, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 337/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3957 - val_loss: 1.3109 - val_accuracy: 0.3841

Epoch 00337: val_loss did not improve from 1.30863
Epoch 338/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3967 - val_loss: 1.3112 - val_accuracy: 0.3952

Epoch 00338: val_loss did not improve from 1.30863
Epoch 339/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3922 - val_loss: 1.3100 - val_accuracy: 0.3912

Epoch 00339: val_loss did not improve from 1.30863
Epoch 340/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3957 - val_loss: 1.3089 - val_accuracy: 0.3920

Epoch 00340: val_loss did not improve from 1.30863
Epoch 341/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3967 - val_loss: 1.3109 - val_accuracy: 0.3960

Epoch 00341: val_loss did not improve from 1.30863
Epoch 342/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3985 - val_loss: 1.3099 - val_accuracy: 0.3976

Epoch 00342: val_loss did not improve from 1.30863
Epoch 343/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3998 - val_loss: 1.3087 - val_accuracy: 0.3849

Epoch 00343: val_loss did not improve from 1.30863
Epoch 344/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3979 - val_loss: 1.3102 - val_accuracy: 0.3888

Epoch 00344: val_loss did not improve from 1.30863
Epoch 345/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3951 - val_loss: 1.3091 - val_accuracy: 0.3992

Epoch 00345: val_loss did not improve from 1.30863
Epoch 346/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4019 - val_loss: 1.3122 - val_accuracy: 0.4096

Epoch 00346: val_loss did not improve from 1.30863
Epoch 347/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3957 - val_loss: 1.3159 - val_accuracy: 0.3809

Epoch 00347: val_loss did not improve from 1.30863
Epoch 348/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3980 - val_loss: 1.3087 - val_accuracy: 0.3865

Epoch 00348: val_loss did not improve from 1.30863
Epoch 349/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3963 - val_loss: 1.3115 - val_accuracy: 0.4016

Epoch 00349: val_loss did not improve from 1.30863
Epoch 350/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3983 - val_loss: 1.3075 - val_accuracy: 0.4024

Epoch 00350: val_loss improved from 1.30863 to 1.30753, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 351/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3962 - val_loss: 1.3065 - val_accuracy: 0.3952

Epoch 00351: val_loss improved from 1.30753 to 1.30653, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 352/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3976 - val_loss: 1.3077 - val_accuracy: 0.4000

Epoch 00352: val_loss did not improve from 1.30653
Epoch 353/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3969 - val_loss: 1.3094 - val_accuracy: 0.3952

Epoch 00353: val_loss did not improve from 1.30653
Epoch 354/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3965 - val_loss: 1.3083 - val_accuracy: 0.4000

Epoch 00354: val_loss did not improve from 1.30653
Epoch 355/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3987 - val_loss: 1.3087 - val_accuracy: 0.3920

Epoch 00355: val_loss did not improve from 1.30653
Epoch 356/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3967 - val_loss: 1.3081 - val_accuracy: 0.3841

Epoch 00356: val_loss did not improve from 1.30653
Epoch 357/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3996 - val_loss: 1.3076 - val_accuracy: 0.3865

Epoch 00357: val_loss did not improve from 1.30653
Epoch 358/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3979 - val_loss: 1.3094 - val_accuracy: 0.3976

Epoch 00358: val_loss did not improve from 1.30653
Epoch 359/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4001 - val_loss: 1.3105 - val_accuracy: 0.3928

Epoch 00359: val_loss did not improve from 1.30653
Epoch 360/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3991 - val_loss: 1.3070 - val_accuracy: 0.3936

Epoch 00360: val_loss did not improve from 1.30653
Epoch 361/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3959 - val_loss: 1.3093 - val_accuracy: 0.3968

Epoch 00361: val_loss did not improve from 1.30653
Epoch 362/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4004 - val_loss: 1.3074 - val_accuracy: 0.4048

Epoch 00362: val_loss did not improve from 1.30653
Epoch 363/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3980 - val_loss: 1.3091 - val_accuracy: 0.3865

Epoch 00363: val_loss did not improve from 1.30653
Epoch 364/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4009 - val_loss: 1.3072 - val_accuracy: 0.3888

Epoch 00364: val_loss did not improve from 1.30653
Epoch 365/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4029 - val_loss: 1.3081 - val_accuracy: 0.3968

Epoch 00365: val_loss did not improve from 1.30653
Epoch 366/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3957 - val_loss: 1.3089 - val_accuracy: 0.3992

Epoch 00366: val_loss did not improve from 1.30653
Epoch 367/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3947 - val_loss: 1.3089 - val_accuracy: 0.3952

Epoch 00367: val_loss did not improve from 1.30653
Epoch 368/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3970 - val_loss: 1.3085 - val_accuracy: 0.3968

Epoch 00368: val_loss did not improve from 1.30653
Epoch 369/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3979 - val_loss: 1.3070 - val_accuracy: 0.3984

Epoch 00369: val_loss did not improve from 1.30653
Epoch 370/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3948 - val_loss: 1.3133 - val_accuracy: 0.3857

Epoch 00370: val_loss did not improve from 1.30653
Epoch 371/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4007 - val_loss: 1.3150 - val_accuracy: 0.3920

Epoch 00371: val_loss did not improve from 1.30653
Epoch 372/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3947 - val_loss: 1.3100 - val_accuracy: 0.3984

Epoch 00372: val_loss did not improve from 1.30653
Epoch 373/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3940 - val_loss: 1.3082 - val_accuracy: 0.3936

Epoch 00373: val_loss did not improve from 1.30653
Epoch 374/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3958 - val_loss: 1.3171 - val_accuracy: 0.3865

Epoch 00374: val_loss did not improve from 1.30653
Epoch 375/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3973 - val_loss: 1.3084 - val_accuracy: 0.4016

Epoch 00375: val_loss did not improve from 1.30653
Epoch 376/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3989 - val_loss: 1.3096 - val_accuracy: 0.3920

Epoch 00376: val_loss did not improve from 1.30653
Epoch 377/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3933 - val_loss: 1.3082 - val_accuracy: 0.3984

Epoch 00377: val_loss did not improve from 1.30653
Epoch 378/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3971 - val_loss: 1.3074 - val_accuracy: 0.3896

Epoch 00378: val_loss did not improve from 1.30653
Epoch 379/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3996 - val_loss: 1.3073 - val_accuracy: 0.3888

Epoch 00379: val_loss did not improve from 1.30653
Epoch 380/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3970 - val_loss: 1.3088 - val_accuracy: 0.3857

Epoch 00380: val_loss did not improve from 1.30653
Epoch 381/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3959 - val_loss: 1.3057 - val_accuracy: 0.3912

Epoch 00381: val_loss improved from 1.30653 to 1.30571, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 382/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3973 - val_loss: 1.3075 - val_accuracy: 0.4000

Epoch 00382: val_loss did not improve from 1.30571
Epoch 383/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3981 - val_loss: 1.3072 - val_accuracy: 0.3873

Epoch 00383: val_loss did not improve from 1.30571
Epoch 384/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4013 - val_loss: 1.3090 - val_accuracy: 0.3857

Epoch 00384: val_loss did not improve from 1.30571
Epoch 385/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.3983 - val_loss: 1.3075 - val_accuracy: 0.3952

Epoch 00385: val_loss did not improve from 1.30571
Epoch 386/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.3969 - val_loss: 1.3077 - val_accuracy: 0.3936

Epoch 00386: val_loss did not improve from 1.30571
Epoch 387/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3982 - val_loss: 1.3047 - val_accuracy: 0.3968

Epoch 00387: val_loss improved from 1.30571 to 1.30466, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 388/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4000 - val_loss: 1.3158 - val_accuracy: 0.3912

Epoch 00388: val_loss did not improve from 1.30466
Epoch 389/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3994 - val_loss: 1.3071 - val_accuracy: 0.3984

Epoch 00389: val_loss did not improve from 1.30466
Epoch 390/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3972 - val_loss: 1.3060 - val_accuracy: 0.3968

Epoch 00390: val_loss did not improve from 1.30466
Epoch 391/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3914 - val_loss: 1.3074 - val_accuracy: 0.3880

Epoch 00391: val_loss did not improve from 1.30466
Epoch 392/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.3974 - val_loss: 1.3077 - val_accuracy: 0.3944

Epoch 00392: val_loss did not improve from 1.30466
Epoch 393/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4018 - val_loss: 1.3054 - val_accuracy: 0.4008

Epoch 00393: val_loss did not improve from 1.30466
Epoch 394/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4010 - val_loss: 1.3077 - val_accuracy: 0.3849

Epoch 00394: val_loss did not improve from 1.30466
Epoch 395/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3988 - val_loss: 1.3052 - val_accuracy: 0.3984

Epoch 00395: val_loss did not improve from 1.30466
Epoch 396/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3972 - val_loss: 1.3073 - val_accuracy: 0.3912

Epoch 00396: val_loss did not improve from 1.30466
Epoch 397/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4029 - val_loss: 1.3085 - val_accuracy: 0.3944

Epoch 00397: val_loss did not improve from 1.30466
Epoch 398/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3972 - val_loss: 1.3063 - val_accuracy: 0.3968

Epoch 00398: val_loss did not improve from 1.30466
Epoch 399/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.3975 - val_loss: 1.3056 - val_accuracy: 0.3912

Epoch 00399: val_loss did not improve from 1.30466
Epoch 400/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3973 - val_loss: 1.3080 - val_accuracy: 0.3920

Epoch 00400: val_loss did not improve from 1.30466
Epoch 401/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3966 - val_loss: 1.3072 - val_accuracy: 0.3920

Epoch 00401: val_loss did not improve from 1.30466
Epoch 402/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3984 - val_loss: 1.3068 - val_accuracy: 0.3912

Epoch 00402: val_loss did not improve from 1.30466
Epoch 403/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3964 - val_loss: 1.3067 - val_accuracy: 0.3960

Epoch 00403: val_loss did not improve from 1.30466
Epoch 404/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.3991 - val_loss: 1.3063 - val_accuracy: 0.3888

Epoch 00404: val_loss did not improve from 1.30466
Epoch 405/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4014 - val_loss: 1.3041 - val_accuracy: 0.3960

Epoch 00405: val_loss improved from 1.30466 to 1.30414, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 406/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4004 - val_loss: 1.3077 - val_accuracy: 0.3952

Epoch 00406: val_loss did not improve from 1.30414
Epoch 407/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3987 - val_loss: 1.3070 - val_accuracy: 0.4000

Epoch 00407: val_loss did not improve from 1.30414
Epoch 408/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3981 - val_loss: 1.3028 - val_accuracy: 0.4032

Epoch 00408: val_loss improved from 1.30414 to 1.30283, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 409/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3935 - val_loss: 1.3051 - val_accuracy: 0.3928

Epoch 00409: val_loss did not improve from 1.30283
Epoch 410/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.3977 - val_loss: 1.3055 - val_accuracy: 0.3960

Epoch 00410: val_loss did not improve from 1.30283
Epoch 411/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3983 - val_loss: 1.3050 - val_accuracy: 0.3912

Epoch 00411: val_loss did not improve from 1.30283
Epoch 412/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3951 - val_loss: 1.3040 - val_accuracy: 0.3976

Epoch 00412: val_loss did not improve from 1.30283
Epoch 413/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4002 - val_loss: 1.3072 - val_accuracy: 0.3960

Epoch 00413: val_loss did not improve from 1.30283
Epoch 414/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4004 - val_loss: 1.3064 - val_accuracy: 0.3936

Epoch 00414: val_loss did not improve from 1.30283
Epoch 415/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4008 - val_loss: 1.3070 - val_accuracy: 0.3968

Epoch 00415: val_loss did not improve from 1.30283
Epoch 416/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3981 - val_loss: 1.3110 - val_accuracy: 0.3801

Epoch 00416: val_loss did not improve from 1.30283
Epoch 417/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3988 - val_loss: 1.3080 - val_accuracy: 0.4000

Epoch 00417: val_loss did not improve from 1.30283
Epoch 418/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3979 - val_loss: 1.3100 - val_accuracy: 0.4016

Epoch 00418: val_loss did not improve from 1.30283
Epoch 419/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.3979 - val_loss: 1.3050 - val_accuracy: 0.3944

Epoch 00419: val_loss did not improve from 1.30283
Epoch 420/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3933 - val_loss: 1.3069 - val_accuracy: 0.3880

Epoch 00420: val_loss did not improve from 1.30283
Epoch 421/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3978 - val_loss: 1.3060 - val_accuracy: 0.3960

Epoch 00421: val_loss did not improve from 1.30283
Epoch 422/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.3987 - val_loss: 1.3091 - val_accuracy: 0.3857

Epoch 00422: val_loss did not improve from 1.30283
Epoch 423/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.3990 - val_loss: 1.3047 - val_accuracy: 0.3976

Epoch 00423: val_loss did not improve from 1.30283
Epoch 424/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4008 - val_loss: 1.3043 - val_accuracy: 0.3920

Epoch 00424: val_loss did not improve from 1.30283
Epoch 425/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3997 - val_loss: 1.3032 - val_accuracy: 0.3960

Epoch 00425: val_loss did not improve from 1.30283
Epoch 426/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.3992 - val_loss: 1.3041 - val_accuracy: 0.3880

Epoch 00426: val_loss did not improve from 1.30283
Epoch 427/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.3983 - val_loss: 1.3033 - val_accuracy: 0.3920

Epoch 00427: val_loss did not improve from 1.30283
Epoch 428/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.3978 - val_loss: 1.3050 - val_accuracy: 0.3968

Epoch 00428: val_loss did not improve from 1.30283
Epoch 429/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3987 - val_loss: 1.3047 - val_accuracy: 0.3944

Epoch 00429: val_loss did not improve from 1.30283
Epoch 430/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4041 - val_loss: 1.3116 - val_accuracy: 0.3833

Epoch 00430: val_loss did not improve from 1.30283
Epoch 431/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4009 - val_loss: 1.3095 - val_accuracy: 0.3873

Epoch 00431: val_loss did not improve from 1.30283
Epoch 432/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3959 - val_loss: 1.3044 - val_accuracy: 0.3968

Epoch 00432: val_loss did not improve from 1.30283
Epoch 433/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.3984 - val_loss: 1.3059 - val_accuracy: 0.3976

Epoch 00433: val_loss did not improve from 1.30283
Epoch 434/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.3981 - val_loss: 1.3037 - val_accuracy: 0.3936

Epoch 00434: val_loss did not improve from 1.30283
Epoch 435/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.3989 - val_loss: 1.3074 - val_accuracy: 0.3976

Epoch 00435: val_loss did not improve from 1.30283
Epoch 436/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4003 - val_loss: 1.3060 - val_accuracy: 0.3976

Epoch 00436: val_loss did not improve from 1.30283
Epoch 437/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3979 - val_loss: 1.3103 - val_accuracy: 0.3976

Epoch 00437: val_loss did not improve from 1.30283
Epoch 438/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4020 - val_loss: 1.3056 - val_accuracy: 0.4000

Epoch 00438: val_loss did not improve from 1.30283
Epoch 439/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3996 - val_loss: 1.3071 - val_accuracy: 0.3920

Epoch 00439: val_loss did not improve from 1.30283
Epoch 440/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4006 - val_loss: 1.3036 - val_accuracy: 0.4016

Epoch 00440: val_loss did not improve from 1.30283
Epoch 441/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.3969 - val_loss: 1.3049 - val_accuracy: 0.4056

Epoch 00441: val_loss did not improve from 1.30283
Epoch 442/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.3992 - val_loss: 1.3075 - val_accuracy: 0.3928

Epoch 00442: val_loss did not improve from 1.30283
Epoch 443/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4012 - val_loss: 1.3060 - val_accuracy: 0.3888

Epoch 00443: val_loss did not improve from 1.30283
Epoch 444/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4003 - val_loss: 1.3065 - val_accuracy: 0.4008

Epoch 00444: val_loss did not improve from 1.30283
Epoch 445/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3981 - val_loss: 1.3086 - val_accuracy: 0.3920

Epoch 00445: val_loss did not improve from 1.30283
Epoch 446/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.3992 - val_loss: 1.3038 - val_accuracy: 0.4016

Epoch 00446: val_loss did not improve from 1.30283
Epoch 447/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4017 - val_loss: 1.3076 - val_accuracy: 0.3960

Epoch 00447: val_loss did not improve from 1.30283
Epoch 448/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4006 - val_loss: 1.3041 - val_accuracy: 0.3960

Epoch 00448: val_loss did not improve from 1.30283
Epoch 449/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4006 - val_loss: 1.3048 - val_accuracy: 0.3960

Epoch 00449: val_loss did not improve from 1.30283
Epoch 450/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.3990 - val_loss: 1.3022 - val_accuracy: 0.3952

Epoch 00450: val_loss improved from 1.30283 to 1.30217, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 451/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4019 - val_loss: 1.3056 - val_accuracy: 0.3952

Epoch 00451: val_loss did not improve from 1.30217
Epoch 452/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.3997 - val_loss: 1.3050 - val_accuracy: 0.3992

Epoch 00452: val_loss did not improve from 1.30217
Epoch 453/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.3996 - val_loss: 1.3044 - val_accuracy: 0.3944

Epoch 00453: val_loss did not improve from 1.30217
Epoch 454/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4014 - val_loss: 1.3087 - val_accuracy: 0.3888

Epoch 00454: val_loss did not improve from 1.30217
Epoch 455/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4005 - val_loss: 1.3056 - val_accuracy: 0.3944

Epoch 00455: val_loss did not improve from 1.30217
Epoch 456/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3999 - val_loss: 1.3057 - val_accuracy: 0.3984

Epoch 00456: val_loss did not improve from 1.30217
Epoch 457/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4021 - val_loss: 1.3157 - val_accuracy: 0.3896

Epoch 00457: val_loss did not improve from 1.30217
Epoch 458/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3965 - val_loss: 1.3064 - val_accuracy: 0.3968

Epoch 00458: val_loss did not improve from 1.30217
Epoch 459/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4012 - val_loss: 1.3052 - val_accuracy: 0.3936

Epoch 00459: val_loss did not improve from 1.30217
Epoch 460/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.3999 - val_loss: 1.3078 - val_accuracy: 0.3968

Epoch 00460: val_loss did not improve from 1.30217
Epoch 461/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4018 - val_loss: 1.3036 - val_accuracy: 0.3920

Epoch 00461: val_loss did not improve from 1.30217
Epoch 462/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4039 - val_loss: 1.3040 - val_accuracy: 0.3984

Epoch 00462: val_loss did not improve from 1.30217
Epoch 463/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4023 - val_loss: 1.3050 - val_accuracy: 0.3944

Epoch 00463: val_loss did not improve from 1.30217
Epoch 464/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4026 - val_loss: 1.3081 - val_accuracy: 0.3857

Epoch 00464: val_loss did not improve from 1.30217
Epoch 465/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.3992 - val_loss: 1.3029 - val_accuracy: 0.4000

Epoch 00465: val_loss did not improve from 1.30217
Epoch 466/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3990 - val_loss: 1.3008 - val_accuracy: 0.4008

Epoch 00466: val_loss improved from 1.30217 to 1.30076, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 467/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4046 - val_loss: 1.3039 - val_accuracy: 0.3920

Epoch 00467: val_loss did not improve from 1.30076
Epoch 468/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3991 - val_loss: 1.3045 - val_accuracy: 0.3992

Epoch 00468: val_loss did not improve from 1.30076
Epoch 469/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3987 - val_loss: 1.3021 - val_accuracy: 0.3984

Epoch 00469: val_loss did not improve from 1.30076
Epoch 470/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4020 - val_loss: 1.3116 - val_accuracy: 0.3817

Epoch 00470: val_loss did not improve from 1.30076
Epoch 471/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3996 - val_loss: 1.3000 - val_accuracy: 0.3984

Epoch 00471: val_loss improved from 1.30076 to 1.29995, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 472/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.3995 - val_loss: 1.3006 - val_accuracy: 0.4000

Epoch 00472: val_loss did not improve from 1.29995
Epoch 473/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.3999 - val_loss: 1.3057 - val_accuracy: 0.3936

Epoch 00473: val_loss did not improve from 1.29995
Epoch 474/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.3986 - val_loss: 1.3072 - val_accuracy: 0.4096

Epoch 00474: val_loss did not improve from 1.29995
Epoch 475/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4017 - val_loss: 1.3061 - val_accuracy: 0.4016

Epoch 00475: val_loss did not improve from 1.29995
Epoch 476/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3980 - val_loss: 1.3020 - val_accuracy: 0.3992

Epoch 00476: val_loss did not improve from 1.29995
Epoch 477/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4001 - val_loss: 1.3009 - val_accuracy: 0.3976

Epoch 00477: val_loss did not improve from 1.29995
Epoch 478/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4005 - val_loss: 1.3002 - val_accuracy: 0.3968

Epoch 00478: val_loss did not improve from 1.29995
Epoch 479/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.3993 - val_loss: 1.3019 - val_accuracy: 0.4008

Epoch 00479: val_loss did not improve from 1.29995
Epoch 480/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4029 - val_loss: 1.3003 - val_accuracy: 0.3984

Epoch 00480: val_loss did not improve from 1.29995
Epoch 481/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4004 - val_loss: 1.3036 - val_accuracy: 0.3992

Epoch 00481: val_loss did not improve from 1.29995
Epoch 482/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4039 - val_loss: 1.3023 - val_accuracy: 0.4072

Epoch 00482: val_loss did not improve from 1.29995
Epoch 483/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4022 - val_loss: 1.3025 - val_accuracy: 0.4040

Epoch 00483: val_loss did not improve from 1.29995
Epoch 484/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.3995 - val_loss: 1.2994 - val_accuracy: 0.4016

Epoch 00484: val_loss improved from 1.29995 to 1.29944, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 485/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4011 - val_loss: 1.2993 - val_accuracy: 0.4000

Epoch 00485: val_loss improved from 1.29944 to 1.29935, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 486/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4010 - val_loss: 1.3011 - val_accuracy: 0.4016

Epoch 00486: val_loss did not improve from 1.29935
Epoch 487/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4018 - val_loss: 1.3015 - val_accuracy: 0.3968

Epoch 00487: val_loss did not improve from 1.29935
Epoch 488/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4035 - val_loss: 1.3009 - val_accuracy: 0.4008

Epoch 00488: val_loss did not improve from 1.29935
Epoch 489/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4013 - val_loss: 1.3003 - val_accuracy: 0.3984

Epoch 00489: val_loss did not improve from 1.29935
Epoch 490/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4017 - val_loss: 1.3026 - val_accuracy: 0.3920

Epoch 00490: val_loss did not improve from 1.29935
Epoch 491/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4049 - val_loss: 1.3007 - val_accuracy: 0.3912

Epoch 00491: val_loss did not improve from 1.29935
Epoch 492/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.3993 - val_loss: 1.3018 - val_accuracy: 0.3952

Epoch 00492: val_loss did not improve from 1.29935
Epoch 493/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4046 - val_loss: 1.3000 - val_accuracy: 0.3984

Epoch 00493: val_loss did not improve from 1.29935
Epoch 494/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4012 - val_loss: 1.3078 - val_accuracy: 0.3936

Epoch 00494: val_loss did not improve from 1.29935
Epoch 495/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4021 - val_loss: 1.3003 - val_accuracy: 0.3944

Epoch 00495: val_loss did not improve from 1.29935
Epoch 496/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4041 - val_loss: 1.3033 - val_accuracy: 0.3992

Epoch 00496: val_loss did not improve from 1.29935
Epoch 497/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4007 - val_loss: 1.3006 - val_accuracy: 0.3984

Epoch 00497: val_loss did not improve from 1.29935
Epoch 498/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4013 - val_loss: 1.3019 - val_accuracy: 0.3912

Epoch 00498: val_loss did not improve from 1.29935
Epoch 499/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4016 - val_loss: 1.3041 - val_accuracy: 0.3960

Epoch 00499: val_loss did not improve from 1.29935
Epoch 500/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4035 - val_loss: 1.3058 - val_accuracy: 0.3880

Epoch 00500: val_loss did not improve from 1.29935
Epoch 501/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.3995 - val_loss: 1.3074 - val_accuracy: 0.3912

Epoch 00501: val_loss did not improve from 1.29935
Epoch 502/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4019 - val_loss: 1.3014 - val_accuracy: 0.4000

Epoch 00502: val_loss did not improve from 1.29935
Epoch 503/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4032 - val_loss: 1.2997 - val_accuracy: 0.3976

Epoch 00503: val_loss did not improve from 1.29935
Epoch 504/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4041 - val_loss: 1.3043 - val_accuracy: 0.3880

Epoch 00504: val_loss did not improve from 1.29935
Epoch 505/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4016 - val_loss: 1.3033 - val_accuracy: 0.3976

Epoch 00505: val_loss did not improve from 1.29935
Epoch 506/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4038 - val_loss: 1.3027 - val_accuracy: 0.3984

Epoch 00506: val_loss did not improve from 1.29935
Epoch 507/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4010 - val_loss: 1.3103 - val_accuracy: 0.3936

Epoch 00507: val_loss did not improve from 1.29935
Epoch 508/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.3986 - val_loss: 1.3031 - val_accuracy: 0.3976

Epoch 00508: val_loss did not improve from 1.29935
Epoch 509/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.3998 - val_loss: 1.3014 - val_accuracy: 0.4032

Epoch 00509: val_loss did not improve from 1.29935
Epoch 510/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4020 - val_loss: 1.3035 - val_accuracy: 0.3952

Epoch 00510: val_loss did not improve from 1.29935
Epoch 511/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4046 - val_loss: 1.2994 - val_accuracy: 0.4008

Epoch 00511: val_loss did not improve from 1.29935
Epoch 512/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4027 - val_loss: 1.3034 - val_accuracy: 0.3968

Epoch 00512: val_loss did not improve from 1.29935
Epoch 513/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4027 - val_loss: 1.3047 - val_accuracy: 0.4064

Epoch 00513: val_loss did not improve from 1.29935
Epoch 514/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4050 - val_loss: 1.3096 - val_accuracy: 0.3873

Epoch 00514: val_loss did not improve from 1.29935
Epoch 515/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4038 - val_loss: 1.3014 - val_accuracy: 0.4032

Epoch 00515: val_loss did not improve from 1.29935
Epoch 516/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4054 - val_loss: 1.3037 - val_accuracy: 0.3968

Epoch 00516: val_loss did not improve from 1.29935
Epoch 517/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4022 - val_loss: 1.3026 - val_accuracy: 0.4056

Epoch 00517: val_loss did not improve from 1.29935
Epoch 518/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4027 - val_loss: 1.3005 - val_accuracy: 0.3936

Epoch 00518: val_loss did not improve from 1.29935
Epoch 519/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4053 - val_loss: 1.2989 - val_accuracy: 0.4024

Epoch 00519: val_loss improved from 1.29935 to 1.29892, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 520/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4040 - val_loss: 1.2997 - val_accuracy: 0.3944

Epoch 00520: val_loss did not improve from 1.29892
Epoch 521/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3994 - val_loss: 1.3026 - val_accuracy: 0.4032

Epoch 00521: val_loss did not improve from 1.29892
Epoch 522/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4013 - val_loss: 1.3017 - val_accuracy: 0.3952

Epoch 00522: val_loss did not improve from 1.29892
Epoch 523/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4030 - val_loss: 1.3026 - val_accuracy: 0.3928

Epoch 00523: val_loss did not improve from 1.29892
Epoch 524/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4061 - val_loss: 1.2986 - val_accuracy: 0.4000

Epoch 00524: val_loss improved from 1.29892 to 1.29860, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 525/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4022 - val_loss: 1.3024 - val_accuracy: 0.4032

Epoch 00525: val_loss did not improve from 1.29860
Epoch 526/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4017 - val_loss: 1.3020 - val_accuracy: 0.4024

Epoch 00526: val_loss did not improve from 1.29860
Epoch 527/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4060 - val_loss: 1.3074 - val_accuracy: 0.3904

Epoch 00527: val_loss did not improve from 1.29860
Epoch 528/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4012 - val_loss: 1.3033 - val_accuracy: 0.4016

Epoch 00528: val_loss did not improve from 1.29860
Epoch 529/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4023 - val_loss: 1.3023 - val_accuracy: 0.3928

Epoch 00529: val_loss did not improve from 1.29860
Epoch 530/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4080 - val_loss: 1.2998 - val_accuracy: 0.3928

Epoch 00530: val_loss did not improve from 1.29860
Epoch 531/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4023 - val_loss: 1.2993 - val_accuracy: 0.3992

Epoch 00531: val_loss did not improve from 1.29860
Epoch 532/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.3996 - val_loss: 1.2996 - val_accuracy: 0.4024

Epoch 00532: val_loss did not improve from 1.29860
Epoch 533/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4057 - val_loss: 1.3005 - val_accuracy: 0.3920

Epoch 00533: val_loss did not improve from 1.29860
Epoch 534/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4041 - val_loss: 1.2982 - val_accuracy: 0.3952

Epoch 00534: val_loss improved from 1.29860 to 1.29821, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 535/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4059 - val_loss: 1.2991 - val_accuracy: 0.3944

Epoch 00535: val_loss did not improve from 1.29821
Epoch 536/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4044 - val_loss: 1.3005 - val_accuracy: 0.3912

Epoch 00536: val_loss did not improve from 1.29821
Epoch 537/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4054 - val_loss: 1.3003 - val_accuracy: 0.3944

Epoch 00537: val_loss did not improve from 1.29821
Epoch 538/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4058 - val_loss: 1.3020 - val_accuracy: 0.3873

Epoch 00538: val_loss did not improve from 1.29821
Epoch 539/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.3990 - val_loss: 1.2972 - val_accuracy: 0.4032

Epoch 00539: val_loss improved from 1.29821 to 1.29724, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 540/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4026 - val_loss: 1.2972 - val_accuracy: 0.4024

Epoch 00540: val_loss improved from 1.29724 to 1.29717, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 541/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4058 - val_loss: 1.3001 - val_accuracy: 0.4024

Epoch 00541: val_loss did not improve from 1.29717
Epoch 542/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4008 - val_loss: 1.3007 - val_accuracy: 0.4000

Epoch 00542: val_loss did not improve from 1.29717
Epoch 543/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4016 - val_loss: 1.3055 - val_accuracy: 0.3873

Epoch 00543: val_loss did not improve from 1.29717
Epoch 544/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4043 - val_loss: 1.3003 - val_accuracy: 0.3992

Epoch 00544: val_loss did not improve from 1.29717
Epoch 545/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4004 - val_loss: 1.3028 - val_accuracy: 0.3992

Epoch 00545: val_loss did not improve from 1.29717
Epoch 546/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4043 - val_loss: 1.3073 - val_accuracy: 0.3920

Epoch 00546: val_loss did not improve from 1.29717
Epoch 547/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4014 - val_loss: 1.2996 - val_accuracy: 0.4032

Epoch 00547: val_loss did not improve from 1.29717
Epoch 548/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4000 - val_loss: 1.2978 - val_accuracy: 0.4080

Epoch 00548: val_loss did not improve from 1.29717
Epoch 549/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4050 - val_loss: 1.2958 - val_accuracy: 0.4096

Epoch 00549: val_loss improved from 1.29717 to 1.29576, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 550/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4044 - val_loss: 1.2980 - val_accuracy: 0.3984

Epoch 00550: val_loss did not improve from 1.29576
Epoch 551/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4022 - val_loss: 1.2984 - val_accuracy: 0.3984

Epoch 00551: val_loss did not improve from 1.29576
Epoch 552/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4065 - val_loss: 1.2971 - val_accuracy: 0.3976

Epoch 00552: val_loss did not improve from 1.29576
Epoch 553/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4042 - val_loss: 1.2976 - val_accuracy: 0.4008

Epoch 00553: val_loss did not improve from 1.29576
Epoch 554/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4049 - val_loss: 1.2978 - val_accuracy: 0.3904

Epoch 00554: val_loss did not improve from 1.29576
Epoch 555/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4067 - val_loss: 1.2967 - val_accuracy: 0.4000

Epoch 00555: val_loss did not improve from 1.29576
Epoch 556/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4062 - val_loss: 1.2962 - val_accuracy: 0.3992

Epoch 00556: val_loss did not improve from 1.29576
Epoch 557/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4016 - val_loss: 1.2985 - val_accuracy: 0.4048

Epoch 00557: val_loss did not improve from 1.29576
Epoch 558/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4028 - val_loss: 1.3064 - val_accuracy: 0.3944

Epoch 00558: val_loss did not improve from 1.29576
Epoch 559/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4023 - val_loss: 1.2998 - val_accuracy: 0.4064

Epoch 00559: val_loss did not improve from 1.29576
Epoch 560/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4036 - val_loss: 1.2976 - val_accuracy: 0.3944

Epoch 00560: val_loss did not improve from 1.29576
Epoch 561/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4017 - val_loss: 1.2993 - val_accuracy: 0.3992

Epoch 00561: val_loss did not improve from 1.29576
Epoch 562/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4047 - val_loss: 1.2988 - val_accuracy: 0.3960

Epoch 00562: val_loss did not improve from 1.29576
Epoch 563/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4057 - val_loss: 1.2986 - val_accuracy: 0.3944

Epoch 00563: val_loss did not improve from 1.29576
Epoch 564/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4043 - val_loss: 1.2974 - val_accuracy: 0.4008

Epoch 00564: val_loss did not improve from 1.29576
Epoch 565/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4040 - val_loss: 1.2984 - val_accuracy: 0.4048

Epoch 00565: val_loss did not improve from 1.29576
Epoch 566/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4058 - val_loss: 1.2977 - val_accuracy: 0.4032

Epoch 00566: val_loss did not improve from 1.29576
Epoch 567/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4044 - val_loss: 1.2979 - val_accuracy: 0.4032

Epoch 00567: val_loss did not improve from 1.29576
Epoch 568/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4066 - val_loss: 1.2987 - val_accuracy: 0.3944

Epoch 00568: val_loss did not improve from 1.29576
Epoch 569/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4048 - val_loss: 1.2957 - val_accuracy: 0.4024

Epoch 00569: val_loss improved from 1.29576 to 1.29568, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 570/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4014 - val_loss: 1.2982 - val_accuracy: 0.3992

Epoch 00570: val_loss did not improve from 1.29568
Epoch 571/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4032 - val_loss: 1.2970 - val_accuracy: 0.3992

Epoch 00571: val_loss did not improve from 1.29568
Epoch 572/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4049 - val_loss: 1.2968 - val_accuracy: 0.3976

Epoch 00572: val_loss did not improve from 1.29568
Epoch 573/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4043 - val_loss: 1.2985 - val_accuracy: 0.4048

Epoch 00573: val_loss did not improve from 1.29568
Epoch 574/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4041 - val_loss: 1.2991 - val_accuracy: 0.4040

Epoch 00574: val_loss did not improve from 1.29568
Epoch 575/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4008 - val_loss: 1.2972 - val_accuracy: 0.3976

Epoch 00575: val_loss did not improve from 1.29568
Epoch 576/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4054 - val_loss: 1.2947 - val_accuracy: 0.4072

Epoch 00576: val_loss improved from 1.29568 to 1.29474, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 577/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4048 - val_loss: 1.3001 - val_accuracy: 0.4040

Epoch 00577: val_loss did not improve from 1.29474
Epoch 578/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4032 - val_loss: 1.2969 - val_accuracy: 0.4016

Epoch 00578: val_loss did not improve from 1.29474
Epoch 579/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4074 - val_loss: 1.2987 - val_accuracy: 0.3960

Epoch 00579: val_loss did not improve from 1.29474
Epoch 580/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4050 - val_loss: 1.2952 - val_accuracy: 0.4008

Epoch 00580: val_loss did not improve from 1.29474
Epoch 581/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4067 - val_loss: 1.2961 - val_accuracy: 0.3976

Epoch 00581: val_loss did not improve from 1.29474
Epoch 582/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4033 - val_loss: 1.2966 - val_accuracy: 0.4000

Epoch 00582: val_loss did not improve from 1.29474
Epoch 583/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4070 - val_loss: 1.2972 - val_accuracy: 0.4000

Epoch 00583: val_loss did not improve from 1.29474
Epoch 584/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4037 - val_loss: 1.3038 - val_accuracy: 0.3873

Epoch 00584: val_loss did not improve from 1.29474
Epoch 585/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4027 - val_loss: 1.2996 - val_accuracy: 0.4151

Epoch 00585: val_loss did not improve from 1.29474
Epoch 586/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4044 - val_loss: 1.2966 - val_accuracy: 0.4000

Epoch 00586: val_loss did not improve from 1.29474
Epoch 587/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.3969 - val_loss: 1.2963 - val_accuracy: 0.4112

Epoch 00587: val_loss did not improve from 1.29474
Epoch 588/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4024 - val_loss: 1.2969 - val_accuracy: 0.4056

Epoch 00588: val_loss did not improve from 1.29474
Epoch 589/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4035 - val_loss: 1.2962 - val_accuracy: 0.4112

Epoch 00589: val_loss did not improve from 1.29474
Epoch 590/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4018 - val_loss: 1.2988 - val_accuracy: 0.3976

Epoch 00590: val_loss did not improve from 1.29474
Epoch 591/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4031 - val_loss: 1.2990 - val_accuracy: 0.3992

Epoch 00591: val_loss did not improve from 1.29474
Epoch 592/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4050 - val_loss: 1.2992 - val_accuracy: 0.4024

Epoch 00592: val_loss did not improve from 1.29474
Epoch 593/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4016 - val_loss: 1.2964 - val_accuracy: 0.3968

Epoch 00593: val_loss did not improve from 1.29474
Epoch 594/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4007 - val_loss: 1.2971 - val_accuracy: 0.4056

Epoch 00594: val_loss did not improve from 1.29474
Epoch 595/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4011 - val_loss: 1.2995 - val_accuracy: 0.3912

Epoch 00595: val_loss did not improve from 1.29474
Epoch 596/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4058 - val_loss: 1.2951 - val_accuracy: 0.4008

Epoch 00596: val_loss did not improve from 1.29474
Epoch 597/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4043 - val_loss: 1.2973 - val_accuracy: 0.4024

Epoch 00597: val_loss did not improve from 1.29474
Epoch 598/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4043 - val_loss: 1.2946 - val_accuracy: 0.3968

Epoch 00598: val_loss improved from 1.29474 to 1.29457, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 599/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4044 - val_loss: 1.2945 - val_accuracy: 0.4032

Epoch 00599: val_loss improved from 1.29457 to 1.29453, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 600/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4064 - val_loss: 1.2949 - val_accuracy: 0.3976

Epoch 00600: val_loss did not improve from 1.29453
Epoch 601/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4048 - val_loss: 1.2965 - val_accuracy: 0.3976

Epoch 00601: val_loss did not improve from 1.29453
Epoch 602/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4035 - val_loss: 1.2931 - val_accuracy: 0.4032

Epoch 00602: val_loss improved from 1.29453 to 1.29305, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 603/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4062 - val_loss: 1.3027 - val_accuracy: 0.3952

Epoch 00603: val_loss did not improve from 1.29305
Epoch 604/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4012 - val_loss: 1.2953 - val_accuracy: 0.4016

Epoch 00604: val_loss did not improve from 1.29305
Epoch 605/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4035 - val_loss: 1.2978 - val_accuracy: 0.4032

Epoch 00605: val_loss did not improve from 1.29305
Epoch 606/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4049 - val_loss: 1.3011 - val_accuracy: 0.3952

Epoch 00606: val_loss did not improve from 1.29305
Epoch 607/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4029 - val_loss: 1.2949 - val_accuracy: 0.3984

Epoch 00607: val_loss did not improve from 1.29305
Epoch 608/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4035 - val_loss: 1.2973 - val_accuracy: 0.4016

Epoch 00608: val_loss did not improve from 1.29305
Epoch 609/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4031 - val_loss: 1.2940 - val_accuracy: 0.4032

Epoch 00609: val_loss did not improve from 1.29305
Epoch 610/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4074 - val_loss: 1.2957 - val_accuracy: 0.3944

Epoch 00610: val_loss did not improve from 1.29305
Epoch 611/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4069 - val_loss: 1.2941 - val_accuracy: 0.4024

Epoch 00611: val_loss did not improve from 1.29305
Epoch 612/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4055 - val_loss: 1.2954 - val_accuracy: 0.4008

Epoch 00612: val_loss did not improve from 1.29305
Epoch 613/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4036 - val_loss: 1.2955 - val_accuracy: 0.4032

Epoch 00613: val_loss did not improve from 1.29305
Epoch 614/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4036 - val_loss: 1.2957 - val_accuracy: 0.3944

Epoch 00614: val_loss did not improve from 1.29305
Epoch 615/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4058 - val_loss: 1.3006 - val_accuracy: 0.3928

Epoch 00615: val_loss did not improve from 1.29305
Epoch 616/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4065 - val_loss: 1.2996 - val_accuracy: 0.4024

Epoch 00616: val_loss did not improve from 1.29305
Epoch 617/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4052 - val_loss: 1.2968 - val_accuracy: 0.4032

Epoch 00617: val_loss did not improve from 1.29305
Epoch 618/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4066 - val_loss: 1.2952 - val_accuracy: 0.4016

Epoch 00618: val_loss did not improve from 1.29305
Epoch 619/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4017 - val_loss: 1.2989 - val_accuracy: 0.3952

Epoch 00619: val_loss did not improve from 1.29305
Epoch 620/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.3995 - val_loss: 1.2944 - val_accuracy: 0.3984

Epoch 00620: val_loss did not improve from 1.29305
Epoch 621/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4007 - val_loss: 1.2963 - val_accuracy: 0.3936

Epoch 00621: val_loss did not improve from 1.29305
Epoch 622/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4017 - val_loss: 1.2987 - val_accuracy: 0.3968

Epoch 00622: val_loss did not improve from 1.29305
Epoch 623/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4044 - val_loss: 1.2961 - val_accuracy: 0.4024

Epoch 00623: val_loss did not improve from 1.29305
Epoch 624/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4068 - val_loss: 1.2936 - val_accuracy: 0.3952

Epoch 00624: val_loss did not improve from 1.29305
Epoch 625/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4047 - val_loss: 1.2955 - val_accuracy: 0.4032

Epoch 00625: val_loss did not improve from 1.29305
Epoch 626/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4039 - val_loss: 1.2959 - val_accuracy: 0.3944

Epoch 00626: val_loss did not improve from 1.29305
Epoch 627/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4029 - val_loss: 1.2949 - val_accuracy: 0.4016

Epoch 00627: val_loss did not improve from 1.29305
Epoch 628/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4055 - val_loss: 1.2966 - val_accuracy: 0.3920

Epoch 00628: val_loss did not improve from 1.29305
Epoch 629/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4032 - val_loss: 1.2955 - val_accuracy: 0.3984

Epoch 00629: val_loss did not improve from 1.29305
Epoch 630/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4019 - val_loss: 1.2975 - val_accuracy: 0.4000

Epoch 00630: val_loss did not improve from 1.29305
Epoch 631/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.3992 - val_loss: 1.2964 - val_accuracy: 0.4024

Epoch 00631: val_loss did not improve from 1.29305
Epoch 632/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4022 - val_loss: 1.3030 - val_accuracy: 0.3888

Epoch 00632: val_loss did not improve from 1.29305
Epoch 633/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4043 - val_loss: 1.3010 - val_accuracy: 0.3992

Epoch 00633: val_loss did not improve from 1.29305
Epoch 634/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4003 - val_loss: 1.2972 - val_accuracy: 0.4040

Epoch 00634: val_loss did not improve from 1.29305
Epoch 635/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4039 - val_loss: 1.2942 - val_accuracy: 0.3984

Epoch 00635: val_loss did not improve from 1.29305
Epoch 636/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4038 - val_loss: 1.2940 - val_accuracy: 0.3928

Epoch 00636: val_loss did not improve from 1.29305
Epoch 637/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4043 - val_loss: 1.2928 - val_accuracy: 0.3984

Epoch 00637: val_loss improved from 1.29305 to 1.29277, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 638/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4058 - val_loss: 1.2955 - val_accuracy: 0.3960

Epoch 00638: val_loss did not improve from 1.29277
Epoch 639/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4042 - val_loss: 1.2948 - val_accuracy: 0.4088

Epoch 00639: val_loss did not improve from 1.29277
Epoch 640/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4062 - val_loss: 1.2943 - val_accuracy: 0.4016

Epoch 00640: val_loss did not improve from 1.29277
Epoch 641/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4048 - val_loss: 1.2946 - val_accuracy: 0.4072

Epoch 00641: val_loss did not improve from 1.29277
Epoch 642/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4059 - val_loss: 1.3006 - val_accuracy: 0.4024

Epoch 00642: val_loss did not improve from 1.29277
Epoch 643/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4035 - val_loss: 1.2957 - val_accuracy: 0.3952

Epoch 00643: val_loss did not improve from 1.29277
Epoch 644/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4046 - val_loss: 1.2940 - val_accuracy: 0.3992

Epoch 00644: val_loss did not improve from 1.29277
Epoch 645/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4066 - val_loss: 1.3025 - val_accuracy: 0.3952

Epoch 00645: val_loss did not improve from 1.29277
Epoch 646/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4056 - val_loss: 1.2937 - val_accuracy: 0.3928

Epoch 00646: val_loss did not improve from 1.29277
Epoch 647/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4074 - val_loss: 1.2955 - val_accuracy: 0.4032

Epoch 00647: val_loss did not improve from 1.29277
Epoch 648/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4050 - val_loss: 1.2947 - val_accuracy: 0.4072

Epoch 00648: val_loss did not improve from 1.29277
Epoch 649/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4042 - val_loss: 1.2939 - val_accuracy: 0.3992

Epoch 00649: val_loss did not improve from 1.29277
Epoch 650/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4043 - val_loss: 1.2994 - val_accuracy: 0.3920

Epoch 00650: val_loss did not improve from 1.29277
Epoch 651/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4019 - val_loss: 1.2939 - val_accuracy: 0.4008

Epoch 00651: val_loss did not improve from 1.29277
Epoch 652/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4094 - val_loss: 1.2928 - val_accuracy: 0.3984

Epoch 00652: val_loss did not improve from 1.29277
Epoch 653/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4055 - val_loss: 1.2932 - val_accuracy: 0.3928

Epoch 00653: val_loss did not improve from 1.29277
Epoch 654/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4055 - val_loss: 1.2925 - val_accuracy: 0.3992

Epoch 00654: val_loss improved from 1.29277 to 1.29253, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 655/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4033 - val_loss: 1.2960 - val_accuracy: 0.4008

Epoch 00655: val_loss did not improve from 1.29253
Epoch 656/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4064 - val_loss: 1.2938 - val_accuracy: 0.4016

Epoch 00656: val_loss did not improve from 1.29253
Epoch 657/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4002 - val_loss: 1.3004 - val_accuracy: 0.3960

Epoch 00657: val_loss did not improve from 1.29253
Epoch 658/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4041 - val_loss: 1.2955 - val_accuracy: 0.3936

Epoch 00658: val_loss did not improve from 1.29253
Epoch 659/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4019 - val_loss: 1.2945 - val_accuracy: 0.4008

Epoch 00659: val_loss did not improve from 1.29253
Epoch 660/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4043 - val_loss: 1.2909 - val_accuracy: 0.4080

Epoch 00660: val_loss improved from 1.29253 to 1.29087, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 661/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4054 - val_loss: 1.2961 - val_accuracy: 0.3984

Epoch 00661: val_loss did not improve from 1.29087
Epoch 662/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4064 - val_loss: 1.2938 - val_accuracy: 0.4000

Epoch 00662: val_loss did not improve from 1.29087
Epoch 663/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4055 - val_loss: 1.2945 - val_accuracy: 0.3992

Epoch 00663: val_loss did not improve from 1.29087
Epoch 664/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4069 - val_loss: 1.2948 - val_accuracy: 0.4016

Epoch 00664: val_loss did not improve from 1.29087
Epoch 665/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4035 - val_loss: 1.2984 - val_accuracy: 0.4024

Epoch 00665: val_loss did not improve from 1.29087
Epoch 666/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4050 - val_loss: 1.2909 - val_accuracy: 0.3984

Epoch 00666: val_loss did not improve from 1.29087
Epoch 667/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4056 - val_loss: 1.2911 - val_accuracy: 0.4096

Epoch 00667: val_loss did not improve from 1.29087
Epoch 668/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4085 - val_loss: 1.2973 - val_accuracy: 0.4127

Epoch 00668: val_loss did not improve from 1.29087
Epoch 669/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4010 - val_loss: 1.2997 - val_accuracy: 0.3944

Epoch 00669: val_loss did not improve from 1.29087
Epoch 670/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4054 - val_loss: 1.2947 - val_accuracy: 0.4024

Epoch 00670: val_loss did not improve from 1.29087
Epoch 671/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4045 - val_loss: 1.2951 - val_accuracy: 0.4040

Epoch 00671: val_loss did not improve from 1.29087
Epoch 672/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4038 - val_loss: 1.2932 - val_accuracy: 0.3976

Epoch 00672: val_loss did not improve from 1.29087
Epoch 673/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4035 - val_loss: 1.2924 - val_accuracy: 0.4064

Epoch 00673: val_loss did not improve from 1.29087
Epoch 674/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4064 - val_loss: 1.2965 - val_accuracy: 0.3992

Epoch 00674: val_loss did not improve from 1.29087
Epoch 675/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4042 - val_loss: 1.2952 - val_accuracy: 0.4064

Epoch 00675: val_loss did not improve from 1.29087
Epoch 676/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4043 - val_loss: 1.2924 - val_accuracy: 0.4048

Epoch 00676: val_loss did not improve from 1.29087
Epoch 677/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4074 - val_loss: 1.2903 - val_accuracy: 0.4016

Epoch 00677: val_loss improved from 1.29087 to 1.29028, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 678/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4017 - val_loss: 1.2946 - val_accuracy: 0.3952

Epoch 00678: val_loss did not improve from 1.29028
Epoch 679/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4013 - val_loss: 1.2915 - val_accuracy: 0.4040

Epoch 00679: val_loss did not improve from 1.29028
Epoch 680/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4051 - val_loss: 1.2941 - val_accuracy: 0.4040

Epoch 00680: val_loss did not improve from 1.29028
Epoch 681/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4045 - val_loss: 1.2929 - val_accuracy: 0.4024

Epoch 00681: val_loss did not improve from 1.29028
Epoch 682/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4047 - val_loss: 1.2980 - val_accuracy: 0.4024

Epoch 00682: val_loss did not improve from 1.29028
Epoch 683/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4026 - val_loss: 1.2947 - val_accuracy: 0.3960

Epoch 00683: val_loss did not improve from 1.29028
Epoch 684/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4041 - val_loss: 1.2915 - val_accuracy: 0.4040

Epoch 00684: val_loss did not improve from 1.29028
Epoch 685/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4076 - val_loss: 1.2913 - val_accuracy: 0.4032

Epoch 00685: val_loss did not improve from 1.29028
Epoch 686/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4069 - val_loss: 1.2908 - val_accuracy: 0.4112

Epoch 00686: val_loss did not improve from 1.29028
Epoch 687/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4059 - val_loss: 1.2901 - val_accuracy: 0.4072

Epoch 00687: val_loss improved from 1.29028 to 1.29012, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 688/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4069 - val_loss: 1.2906 - val_accuracy: 0.4048

Epoch 00688: val_loss did not improve from 1.29012
Epoch 689/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4035 - val_loss: 1.3001 - val_accuracy: 0.3936

Epoch 00689: val_loss did not improve from 1.29012
Epoch 690/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4060 - val_loss: 1.2941 - val_accuracy: 0.3968

Epoch 00690: val_loss did not improve from 1.29012
Epoch 691/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4050 - val_loss: 1.2904 - val_accuracy: 0.3992

Epoch 00691: val_loss did not improve from 1.29012
Epoch 692/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4088 - val_loss: 1.2909 - val_accuracy: 0.4032

Epoch 00692: val_loss did not improve from 1.29012
Epoch 693/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4058 - val_loss: 1.2913 - val_accuracy: 0.4040

Epoch 00693: val_loss did not improve from 1.29012
Epoch 694/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4090 - val_loss: 1.2929 - val_accuracy: 0.4040

Epoch 00694: val_loss did not improve from 1.29012
Epoch 695/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4083 - val_loss: 1.2903 - val_accuracy: 0.4016

Epoch 00695: val_loss did not improve from 1.29012
Epoch 696/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4069 - val_loss: 1.2961 - val_accuracy: 0.4056

Epoch 00696: val_loss did not improve from 1.29012
Epoch 697/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4082 - val_loss: 1.2936 - val_accuracy: 0.4127

Epoch 00697: val_loss did not improve from 1.29012
Epoch 698/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4057 - val_loss: 1.2903 - val_accuracy: 0.4080

Epoch 00698: val_loss did not improve from 1.29012
Epoch 699/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4082 - val_loss: 1.2898 - val_accuracy: 0.4016

Epoch 00699: val_loss improved from 1.29012 to 1.28977, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 700/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4036 - val_loss: 1.2969 - val_accuracy: 0.3992

Epoch 00700: val_loss did not improve from 1.28977
Epoch 701/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4067 - val_loss: 1.2925 - val_accuracy: 0.4088

Epoch 00701: val_loss did not improve from 1.28977
Epoch 702/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4094 - val_loss: 1.2909 - val_accuracy: 0.3976

Epoch 00702: val_loss did not improve from 1.28977
Epoch 703/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4029 - val_loss: 1.2924 - val_accuracy: 0.4032

Epoch 00703: val_loss did not improve from 1.28977
Epoch 704/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4022 - val_loss: 1.2951 - val_accuracy: 0.4175

Epoch 00704: val_loss did not improve from 1.28977
Epoch 705/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4110 - val_loss: 1.2977 - val_accuracy: 0.3896

Epoch 00705: val_loss did not improve from 1.28977
Epoch 706/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4083 - val_loss: 1.2910 - val_accuracy: 0.4040

Epoch 00706: val_loss did not improve from 1.28977
Epoch 707/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4074 - val_loss: 1.2927 - val_accuracy: 0.4040

Epoch 00707: val_loss did not improve from 1.28977
Epoch 708/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4043 - val_loss: 1.2939 - val_accuracy: 0.4016

Epoch 00708: val_loss did not improve from 1.28977
Epoch 709/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4053 - val_loss: 1.2915 - val_accuracy: 0.3976

Epoch 00709: val_loss did not improve from 1.28977
Epoch 710/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4097 - val_loss: 1.2909 - val_accuracy: 0.4088

Epoch 00710: val_loss did not improve from 1.28977
Epoch 711/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4066 - val_loss: 1.2949 - val_accuracy: 0.4008

Epoch 00711: val_loss did not improve from 1.28977
Epoch 712/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4058 - val_loss: 1.2927 - val_accuracy: 0.3992

Epoch 00712: val_loss did not improve from 1.28977
Epoch 713/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4060 - val_loss: 1.2905 - val_accuracy: 0.4080

Epoch 00713: val_loss did not improve from 1.28977
Epoch 714/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4074 - val_loss: 1.2961 - val_accuracy: 0.4000

Epoch 00714: val_loss did not improve from 1.28977
Epoch 715/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4013 - val_loss: 1.2954 - val_accuracy: 0.4016

Epoch 00715: val_loss did not improve from 1.28977
Epoch 716/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4056 - val_loss: 1.2965 - val_accuracy: 0.4088

Epoch 00716: val_loss did not improve from 1.28977
Epoch 717/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4045 - val_loss: 1.2964 - val_accuracy: 0.3976

Epoch 00717: val_loss did not improve from 1.28977
Epoch 718/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4091 - val_loss: 1.2940 - val_accuracy: 0.4016

Epoch 00718: val_loss did not improve from 1.28977
Epoch 719/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4056 - val_loss: 1.2896 - val_accuracy: 0.4024

Epoch 00719: val_loss improved from 1.28977 to 1.28961, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 720/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4054 - val_loss: 1.2921 - val_accuracy: 0.4008

Epoch 00720: val_loss did not improve from 1.28961
Epoch 721/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4044 - val_loss: 1.2899 - val_accuracy: 0.4104

Epoch 00721: val_loss did not improve from 1.28961
Epoch 722/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4049 - val_loss: 1.2907 - val_accuracy: 0.4056

Epoch 00722: val_loss did not improve from 1.28961
Epoch 723/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4091 - val_loss: 1.2923 - val_accuracy: 0.4008

Epoch 00723: val_loss did not improve from 1.28961
Epoch 724/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4111 - val_loss: 1.2895 - val_accuracy: 0.4000

Epoch 00724: val_loss improved from 1.28961 to 1.28952, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 725/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4091 - val_loss: 1.2912 - val_accuracy: 0.3992

Epoch 00725: val_loss did not improve from 1.28952
Epoch 726/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4067 - val_loss: 1.2940 - val_accuracy: 0.4032

Epoch 00726: val_loss did not improve from 1.28952
Epoch 727/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4052 - val_loss: 1.2939 - val_accuracy: 0.4000

Epoch 00727: val_loss did not improve from 1.28952
Epoch 728/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4064 - val_loss: 1.2922 - val_accuracy: 0.4016

Epoch 00728: val_loss did not improve from 1.28952
Epoch 729/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4077 - val_loss: 1.2904 - val_accuracy: 0.3960

Epoch 00729: val_loss did not improve from 1.28952
Epoch 730/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4109 - val_loss: 1.2901 - val_accuracy: 0.4048

Epoch 00730: val_loss did not improve from 1.28952
Epoch 731/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4037 - val_loss: 1.2921 - val_accuracy: 0.4096

Epoch 00731: val_loss did not improve from 1.28952
Epoch 732/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4052 - val_loss: 1.2894 - val_accuracy: 0.4127

Epoch 00732: val_loss improved from 1.28952 to 1.28935, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 733/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4091 - val_loss: 1.2883 - val_accuracy: 0.4088

Epoch 00733: val_loss improved from 1.28935 to 1.28832, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 734/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4048 - val_loss: 1.2896 - val_accuracy: 0.4112

Epoch 00734: val_loss did not improve from 1.28832
Epoch 735/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4077 - val_loss: 1.2918 - val_accuracy: 0.4088

Epoch 00735: val_loss did not improve from 1.28832
Epoch 736/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4097 - val_loss: 1.2885 - val_accuracy: 0.4096

Epoch 00736: val_loss did not improve from 1.28832
Epoch 737/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4084 - val_loss: 1.2923 - val_accuracy: 0.4024

Epoch 00737: val_loss did not improve from 1.28832
Epoch 738/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4057 - val_loss: 1.2902 - val_accuracy: 0.4048

Epoch 00738: val_loss did not improve from 1.28832
Epoch 739/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4100 - val_loss: 1.2886 - val_accuracy: 0.4064

Epoch 00739: val_loss did not improve from 1.28832
Epoch 740/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4074 - val_loss: 1.2885 - val_accuracy: 0.4040

Epoch 00740: val_loss did not improve from 1.28832
Epoch 741/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4083 - val_loss: 1.2923 - val_accuracy: 0.4080

Epoch 00741: val_loss did not improve from 1.28832
Epoch 742/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4054 - val_loss: 1.2889 - val_accuracy: 0.4080

Epoch 00742: val_loss did not improve from 1.28832
Epoch 743/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4083 - val_loss: 1.2885 - val_accuracy: 0.4064

Epoch 00743: val_loss did not improve from 1.28832
Epoch 744/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4088 - val_loss: 1.2922 - val_accuracy: 0.4000

Epoch 00744: val_loss did not improve from 1.28832
Epoch 745/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4033 - val_loss: 1.2901 - val_accuracy: 0.4104

Epoch 00745: val_loss did not improve from 1.28832
Epoch 746/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4065 - val_loss: 1.2932 - val_accuracy: 0.4032

Epoch 00746: val_loss did not improve from 1.28832
Epoch 747/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4065 - val_loss: 1.2922 - val_accuracy: 0.3992

Epoch 00747: val_loss did not improve from 1.28832
Epoch 748/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4042 - val_loss: 1.2941 - val_accuracy: 0.4064

Epoch 00748: val_loss did not improve from 1.28832
Epoch 749/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4053 - val_loss: 1.2936 - val_accuracy: 0.3984

Epoch 00749: val_loss did not improve from 1.28832
Epoch 750/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4050 - val_loss: 1.2894 - val_accuracy: 0.4016

Epoch 00750: val_loss did not improve from 1.28832
Epoch 751/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4074 - val_loss: 1.2873 - val_accuracy: 0.4096

Epoch 00751: val_loss improved from 1.28832 to 1.28732, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 752/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4074 - val_loss: 1.2870 - val_accuracy: 0.4088

Epoch 00752: val_loss improved from 1.28732 to 1.28699, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 753/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4088 - val_loss: 1.2938 - val_accuracy: 0.4032

Epoch 00753: val_loss did not improve from 1.28699
Epoch 754/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4035 - val_loss: 1.2902 - val_accuracy: 0.4112

Epoch 00754: val_loss did not improve from 1.28699
Epoch 755/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4085 - val_loss: 1.2892 - val_accuracy: 0.4032

Epoch 00755: val_loss did not improve from 1.28699
Epoch 756/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4084 - val_loss: 1.2929 - val_accuracy: 0.4088

Epoch 00756: val_loss did not improve from 1.28699
Epoch 757/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4065 - val_loss: 1.2906 - val_accuracy: 0.4040

Epoch 00757: val_loss did not improve from 1.28699
Epoch 758/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4074 - val_loss: 1.2973 - val_accuracy: 0.4024

Epoch 00758: val_loss did not improve from 1.28699
Epoch 759/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4052 - val_loss: 1.2876 - val_accuracy: 0.4120

Epoch 00759: val_loss did not improve from 1.28699
Epoch 760/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4074 - val_loss: 1.2890 - val_accuracy: 0.4159

Epoch 00760: val_loss did not improve from 1.28699
Epoch 761/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4083 - val_loss: 1.2871 - val_accuracy: 0.4112

Epoch 00761: val_loss did not improve from 1.28699
Epoch 762/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4079 - val_loss: 1.2896 - val_accuracy: 0.4080

Epoch 00762: val_loss did not improve from 1.28699
Epoch 763/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4062 - val_loss: 1.2878 - val_accuracy: 0.4056

Epoch 00763: val_loss did not improve from 1.28699
Epoch 764/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4065 - val_loss: 1.2898 - val_accuracy: 0.4024

Epoch 00764: val_loss did not improve from 1.28699
Epoch 765/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4055 - val_loss: 1.2879 - val_accuracy: 0.4080

Epoch 00765: val_loss did not improve from 1.28699
Epoch 766/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4087 - val_loss: 1.2909 - val_accuracy: 0.4064

Epoch 00766: val_loss did not improve from 1.28699
Epoch 767/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4105 - val_loss: 1.2934 - val_accuracy: 0.4008

Epoch 00767: val_loss did not improve from 1.28699
Epoch 768/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4072 - val_loss: 1.2940 - val_accuracy: 0.4024

Epoch 00768: val_loss did not improve from 1.28699
Epoch 769/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4009 - val_loss: 1.2908 - val_accuracy: 0.4032

Epoch 00769: val_loss did not improve from 1.28699
Epoch 770/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4081 - val_loss: 1.2931 - val_accuracy: 0.4104

Epoch 00770: val_loss did not improve from 1.28699
Epoch 771/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4072 - val_loss: 1.2911 - val_accuracy: 0.4112

Epoch 00771: val_loss did not improve from 1.28699
Epoch 772/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4045 - val_loss: 1.2923 - val_accuracy: 0.3976

Epoch 00772: val_loss did not improve from 1.28699
Epoch 773/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4081 - val_loss: 1.2914 - val_accuracy: 0.4080

Epoch 00773: val_loss did not improve from 1.28699
Epoch 774/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4063 - val_loss: 1.2970 - val_accuracy: 0.4008

Epoch 00774: val_loss did not improve from 1.28699
Epoch 775/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4055 - val_loss: 1.2961 - val_accuracy: 0.4072

Epoch 00775: val_loss did not improve from 1.28699
Epoch 776/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4055 - val_loss: 1.2905 - val_accuracy: 0.4072

Epoch 00776: val_loss did not improve from 1.28699
Epoch 777/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4103 - val_loss: 1.2909 - val_accuracy: 0.4048

Epoch 00777: val_loss did not improve from 1.28699
Epoch 778/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4073 - val_loss: 1.2918 - val_accuracy: 0.4064

Epoch 00778: val_loss did not improve from 1.28699
Epoch 779/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4083 - val_loss: 1.2871 - val_accuracy: 0.4104

Epoch 00779: val_loss did not improve from 1.28699
Epoch 780/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4043 - val_loss: 1.2910 - val_accuracy: 0.4000

Epoch 00780: val_loss did not improve from 1.28699
Epoch 781/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4071 - val_loss: 1.2919 - val_accuracy: 0.4056

Epoch 00781: val_loss did not improve from 1.28699
Epoch 782/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4059 - val_loss: 1.2877 - val_accuracy: 0.4127

Epoch 00782: val_loss did not improve from 1.28699
Epoch 783/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4098 - val_loss: 1.2868 - val_accuracy: 0.4040

Epoch 00783: val_loss improved from 1.28699 to 1.28677, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 784/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4064 - val_loss: 1.2936 - val_accuracy: 0.3976

Epoch 00784: val_loss did not improve from 1.28677
Epoch 785/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4069 - val_loss: 1.2868 - val_accuracy: 0.4056

Epoch 00785: val_loss did not improve from 1.28677
Epoch 786/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4092 - val_loss: 1.2880 - val_accuracy: 0.4120

Epoch 00786: val_loss did not improve from 1.28677
Epoch 787/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4086 - val_loss: 1.2897 - val_accuracy: 0.3944

Epoch 00787: val_loss did not improve from 1.28677
Epoch 788/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4107 - val_loss: 1.2864 - val_accuracy: 0.4056

Epoch 00788: val_loss improved from 1.28677 to 1.28641, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 789/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4042 - val_loss: 1.2895 - val_accuracy: 0.4096

Epoch 00789: val_loss did not improve from 1.28641
Epoch 790/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4079 - val_loss: 1.2901 - val_accuracy: 0.3976

Epoch 00790: val_loss did not improve from 1.28641
Epoch 791/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4104 - val_loss: 1.2918 - val_accuracy: 0.4088

Epoch 00791: val_loss did not improve from 1.28641
Epoch 792/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4079 - val_loss: 1.2914 - val_accuracy: 0.4096

Epoch 00792: val_loss did not improve from 1.28641
Epoch 793/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4072 - val_loss: 1.2917 - val_accuracy: 0.4104

Epoch 00793: val_loss did not improve from 1.28641
Epoch 794/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4078 - val_loss: 1.2890 - val_accuracy: 0.4048

Epoch 00794: val_loss did not improve from 1.28641
Epoch 795/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4089 - val_loss: 1.2876 - val_accuracy: 0.4088

Epoch 00795: val_loss did not improve from 1.28641
Epoch 796/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4108 - val_loss: 1.2873 - val_accuracy: 0.4151

Epoch 00796: val_loss did not improve from 1.28641
Epoch 797/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4102 - val_loss: 1.2884 - val_accuracy: 0.4032

Epoch 00797: val_loss did not improve from 1.28641
Epoch 798/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4081 - val_loss: 1.2878 - val_accuracy: 0.4080

Epoch 00798: val_loss did not improve from 1.28641
Epoch 799/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4021 - val_loss: 1.2953 - val_accuracy: 0.4135

Epoch 00799: val_loss did not improve from 1.28641
Epoch 800/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4048 - val_loss: 1.2871 - val_accuracy: 0.4120

Epoch 00800: val_loss did not improve from 1.28641
Epoch 801/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4045 - val_loss: 1.2873 - val_accuracy: 0.4088

Epoch 00801: val_loss did not improve from 1.28641
Epoch 802/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4115 - val_loss: 1.2869 - val_accuracy: 0.4040

Epoch 00802: val_loss did not improve from 1.28641
Epoch 803/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4093 - val_loss: 1.2860 - val_accuracy: 0.4112

Epoch 00803: val_loss improved from 1.28641 to 1.28600, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 804/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4053 - val_loss: 1.2869 - val_accuracy: 0.4080

Epoch 00804: val_loss did not improve from 1.28600
Epoch 805/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4063 - val_loss: 1.2883 - val_accuracy: 0.4120

Epoch 00805: val_loss did not improve from 1.28600
Epoch 806/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4046 - val_loss: 1.2872 - val_accuracy: 0.4112

Epoch 00806: val_loss did not improve from 1.28600
Epoch 807/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4066 - val_loss: 1.2882 - val_accuracy: 0.4024

Epoch 00807: val_loss did not improve from 1.28600
Epoch 808/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4083 - val_loss: 1.2880 - val_accuracy: 0.4088

Epoch 00808: val_loss did not improve from 1.28600
Epoch 809/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4084 - val_loss: 1.2924 - val_accuracy: 0.3984

Epoch 00809: val_loss did not improve from 1.28600
Epoch 810/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4048 - val_loss: 1.2954 - val_accuracy: 0.4040

Epoch 00810: val_loss did not improve from 1.28600
Epoch 811/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4087 - val_loss: 1.2900 - val_accuracy: 0.4024

Epoch 00811: val_loss did not improve from 1.28600
Epoch 812/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4093 - val_loss: 1.2892 - val_accuracy: 0.4040

Epoch 00812: val_loss did not improve from 1.28600
Epoch 813/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4058 - val_loss: 1.2911 - val_accuracy: 0.4135

Epoch 00813: val_loss did not improve from 1.28600
Epoch 814/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4108 - val_loss: 1.2868 - val_accuracy: 0.3992

Epoch 00814: val_loss did not improve from 1.28600
Epoch 815/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4090 - val_loss: 1.2935 - val_accuracy: 0.4183

Epoch 00815: val_loss did not improve from 1.28600
Epoch 816/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4079 - val_loss: 1.2880 - val_accuracy: 0.4088

Epoch 00816: val_loss did not improve from 1.28600
Epoch 817/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4106 - val_loss: 1.2894 - val_accuracy: 0.4008

Epoch 00817: val_loss did not improve from 1.28600
Epoch 818/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4103 - val_loss: 1.2861 - val_accuracy: 0.4072

Epoch 00818: val_loss did not improve from 1.28600
Epoch 819/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4069 - val_loss: 1.2862 - val_accuracy: 0.4048

Epoch 00819: val_loss did not improve from 1.28600
Epoch 820/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4088 - val_loss: 1.2850 - val_accuracy: 0.4096

Epoch 00820: val_loss improved from 1.28600 to 1.28498, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 821/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4122 - val_loss: 1.2871 - val_accuracy: 0.4104

Epoch 00821: val_loss did not improve from 1.28498
Epoch 822/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4074 - val_loss: 1.2882 - val_accuracy: 0.3992

Epoch 00822: val_loss did not improve from 1.28498
Epoch 823/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4035 - val_loss: 1.2868 - val_accuracy: 0.4072

Epoch 00823: val_loss did not improve from 1.28498
Epoch 824/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4058 - val_loss: 1.2861 - val_accuracy: 0.3968

Epoch 00824: val_loss did not improve from 1.28498
Epoch 825/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4076 - val_loss: 1.2887 - val_accuracy: 0.3968

Epoch 00825: val_loss did not improve from 1.28498
Epoch 826/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4089 - val_loss: 1.2872 - val_accuracy: 0.4056

Epoch 00826: val_loss did not improve from 1.28498
Epoch 827/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4052 - val_loss: 1.2867 - val_accuracy: 0.4104

Epoch 00827: val_loss did not improve from 1.28498
Epoch 828/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4110 - val_loss: 1.2849 - val_accuracy: 0.4135

Epoch 00828: val_loss improved from 1.28498 to 1.28493, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 829/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4073 - val_loss: 1.2883 - val_accuracy: 0.3992

Epoch 00829: val_loss did not improve from 1.28493
Epoch 830/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4104 - val_loss: 1.2892 - val_accuracy: 0.3960

Epoch 00830: val_loss did not improve from 1.28493
Epoch 831/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4070 - val_loss: 1.2889 - val_accuracy: 0.4167

Epoch 00831: val_loss did not improve from 1.28493
Epoch 832/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4086 - val_loss: 1.2854 - val_accuracy: 0.4032

Epoch 00832: val_loss did not improve from 1.28493
Epoch 833/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4081 - val_loss: 1.2913 - val_accuracy: 0.4080

Epoch 00833: val_loss did not improve from 1.28493
Epoch 834/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4061 - val_loss: 1.2938 - val_accuracy: 0.4231

Epoch 00834: val_loss did not improve from 1.28493
Epoch 835/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4066 - val_loss: 1.2870 - val_accuracy: 0.4072

Epoch 00835: val_loss did not improve from 1.28493
Epoch 836/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4084 - val_loss: 1.2902 - val_accuracy: 0.4135

Epoch 00836: val_loss did not improve from 1.28493
Epoch 837/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4081 - val_loss: 1.2908 - val_accuracy: 0.4024

Epoch 00837: val_loss did not improve from 1.28493
Epoch 838/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4128 - val_loss: 1.2864 - val_accuracy: 0.4096

Epoch 00838: val_loss did not improve from 1.28493
Epoch 839/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4077 - val_loss: 1.2894 - val_accuracy: 0.4104

Epoch 00839: val_loss did not improve from 1.28493
Epoch 840/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4079 - val_loss: 1.2855 - val_accuracy: 0.4096

Epoch 00840: val_loss did not improve from 1.28493
Epoch 841/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4066 - val_loss: 1.2875 - val_accuracy: 0.4056

Epoch 00841: val_loss did not improve from 1.28493
Epoch 842/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4106 - val_loss: 1.2865 - val_accuracy: 0.4032

Epoch 00842: val_loss did not improve from 1.28493
Epoch 843/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4106 - val_loss: 1.2844 - val_accuracy: 0.4080

Epoch 00843: val_loss improved from 1.28493 to 1.28436, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 844/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4081 - val_loss: 1.2865 - val_accuracy: 0.3960

Epoch 00844: val_loss did not improve from 1.28436
Epoch 845/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4069 - val_loss: 1.2849 - val_accuracy: 0.4056

Epoch 00845: val_loss did not improve from 1.28436
Epoch 846/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4098 - val_loss: 1.2841 - val_accuracy: 0.4088

Epoch 00846: val_loss improved from 1.28436 to 1.28414, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 847/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4087 - val_loss: 1.2889 - val_accuracy: 0.4056

Epoch 00847: val_loss did not improve from 1.28414
Epoch 848/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4065 - val_loss: 1.2877 - val_accuracy: 0.4143

Epoch 00848: val_loss did not improve from 1.28414
Epoch 849/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4093 - val_loss: 1.2865 - val_accuracy: 0.4080

Epoch 00849: val_loss did not improve from 1.28414
Epoch 850/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4124 - val_loss: 1.2930 - val_accuracy: 0.3984

Epoch 00850: val_loss did not improve from 1.28414
Epoch 851/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4112 - val_loss: 1.2850 - val_accuracy: 0.4056

Epoch 00851: val_loss did not improve from 1.28414
Epoch 852/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4105 - val_loss: 1.2898 - val_accuracy: 0.3992

Epoch 00852: val_loss did not improve from 1.28414
Epoch 853/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4077 - val_loss: 1.2899 - val_accuracy: 0.4159

Epoch 00853: val_loss did not improve from 1.28414
Epoch 854/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4104 - val_loss: 1.2844 - val_accuracy: 0.4056

Epoch 00854: val_loss did not improve from 1.28414
Epoch 855/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4091 - val_loss: 1.2853 - val_accuracy: 0.4120

Epoch 00855: val_loss did not improve from 1.28414
Epoch 856/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4083 - val_loss: 1.2880 - val_accuracy: 0.4008

Epoch 00856: val_loss did not improve from 1.28414
Epoch 857/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4121 - val_loss: 1.2867 - val_accuracy: 0.4032

Epoch 00857: val_loss did not improve from 1.28414
Epoch 858/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4106 - val_loss: 1.2942 - val_accuracy: 0.4056

Epoch 00858: val_loss did not improve from 1.28414
Epoch 859/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4100 - val_loss: 1.2887 - val_accuracy: 0.3968

Epoch 00859: val_loss did not improve from 1.28414
Epoch 860/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4124 - val_loss: 1.2878 - val_accuracy: 0.3968

Epoch 00860: val_loss did not improve from 1.28414
Epoch 861/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4047 - val_loss: 1.2937 - val_accuracy: 0.3960

Epoch 00861: val_loss did not improve from 1.28414
Epoch 862/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4084 - val_loss: 1.2868 - val_accuracy: 0.4000

Epoch 00862: val_loss did not improve from 1.28414
Epoch 863/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4045 - val_loss: 1.2876 - val_accuracy: 0.3976

Epoch 00863: val_loss did not improve from 1.28414
Epoch 864/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4101 - val_loss: 1.2873 - val_accuracy: 0.3992

Epoch 00864: val_loss did not improve from 1.28414
Epoch 865/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4119 - val_loss: 1.2920 - val_accuracy: 0.4088

Epoch 00865: val_loss did not improve from 1.28414
Epoch 866/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4089 - val_loss: 1.2844 - val_accuracy: 0.4104

Epoch 00866: val_loss did not improve from 1.28414
Epoch 867/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4104 - val_loss: 1.2899 - val_accuracy: 0.4008

Epoch 00867: val_loss did not improve from 1.28414
Epoch 868/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4144 - val_loss: 1.2870 - val_accuracy: 0.4175

Epoch 00868: val_loss did not improve from 1.28414
Epoch 869/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4097 - val_loss: 1.2890 - val_accuracy: 0.4072

Epoch 00869: val_loss did not improve from 1.28414
Epoch 870/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4093 - val_loss: 1.2856 - val_accuracy: 0.4008

Epoch 00870: val_loss did not improve from 1.28414
Epoch 871/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4101 - val_loss: 1.2882 - val_accuracy: 0.4120

Epoch 00871: val_loss did not improve from 1.28414
Epoch 872/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4105 - val_loss: 1.2856 - val_accuracy: 0.4064

Epoch 00872: val_loss did not improve from 1.28414
Epoch 873/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4140 - val_loss: 1.2865 - val_accuracy: 0.4032

Epoch 00873: val_loss did not improve from 1.28414
Epoch 874/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4142 - val_loss: 1.2841 - val_accuracy: 0.4120

Epoch 00874: val_loss improved from 1.28414 to 1.28411, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 875/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4102 - val_loss: 1.2874 - val_accuracy: 0.4040

Epoch 00875: val_loss did not improve from 1.28411
Epoch 876/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4078 - val_loss: 1.2846 - val_accuracy: 0.4056

Epoch 00876: val_loss did not improve from 1.28411
Epoch 877/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4108 - val_loss: 1.2844 - val_accuracy: 0.4072

Epoch 00877: val_loss did not improve from 1.28411
Epoch 878/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4090 - val_loss: 1.2863 - val_accuracy: 0.4096

Epoch 00878: val_loss did not improve from 1.28411
Epoch 879/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4112 - val_loss: 1.2904 - val_accuracy: 0.4088

Epoch 00879: val_loss did not improve from 1.28411
Epoch 880/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4107 - val_loss: 1.2847 - val_accuracy: 0.4056

Epoch 00880: val_loss did not improve from 1.28411
Epoch 881/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4115 - val_loss: 1.2855 - val_accuracy: 0.4032

Epoch 00881: val_loss did not improve from 1.28411
Epoch 882/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4120 - val_loss: 1.2847 - val_accuracy: 0.4112

Epoch 00882: val_loss did not improve from 1.28411
Epoch 883/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4111 - val_loss: 1.2859 - val_accuracy: 0.4080

Epoch 00883: val_loss did not improve from 1.28411
Epoch 884/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4109 - val_loss: 1.2846 - val_accuracy: 0.3992

Epoch 00884: val_loss did not improve from 1.28411
Epoch 885/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4117 - val_loss: 1.2836 - val_accuracy: 0.4096

Epoch 00885: val_loss improved from 1.28411 to 1.28364, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 886/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4107 - val_loss: 1.2879 - val_accuracy: 0.4088

Epoch 00886: val_loss did not improve from 1.28364
Epoch 887/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4089 - val_loss: 1.2878 - val_accuracy: 0.4088

Epoch 00887: val_loss did not improve from 1.28364
Epoch 888/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4084 - val_loss: 1.2836 - val_accuracy: 0.4056

Epoch 00888: val_loss improved from 1.28364 to 1.28358, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 889/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4097 - val_loss: 1.2838 - val_accuracy: 0.4000

Epoch 00889: val_loss did not improve from 1.28358
Epoch 890/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4087 - val_loss: 1.2871 - val_accuracy: 0.4016

Epoch 00890: val_loss did not improve from 1.28358
Epoch 891/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4091 - val_loss: 1.2890 - val_accuracy: 0.4112

Epoch 00891: val_loss did not improve from 1.28358
Epoch 892/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4149 - val_loss: 1.2850 - val_accuracy: 0.4032

Epoch 00892: val_loss did not improve from 1.28358
Epoch 893/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4126 - val_loss: 1.2902 - val_accuracy: 0.4032

Epoch 00893: val_loss did not improve from 1.28358
Epoch 894/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4102 - val_loss: 1.2875 - val_accuracy: 0.4135

Epoch 00894: val_loss did not improve from 1.28358
Epoch 895/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4072 - val_loss: 1.2854 - val_accuracy: 0.4064

Epoch 00895: val_loss did not improve from 1.28358
Epoch 896/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4105 - val_loss: 1.2855 - val_accuracy: 0.4135

Epoch 00896: val_loss did not improve from 1.28358
Epoch 897/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4117 - val_loss: 1.2835 - val_accuracy: 0.4040

Epoch 00897: val_loss improved from 1.28358 to 1.28346, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 898/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4106 - val_loss: 1.2890 - val_accuracy: 0.4048

Epoch 00898: val_loss did not improve from 1.28346
Epoch 899/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4116 - val_loss: 1.2852 - val_accuracy: 0.4040

Epoch 00899: val_loss did not improve from 1.28346
Epoch 900/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4101 - val_loss: 1.2901 - val_accuracy: 0.4135

Epoch 00900: val_loss did not improve from 1.28346
Epoch 901/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4095 - val_loss: 1.2857 - val_accuracy: 0.4056

Epoch 00901: val_loss did not improve from 1.28346
Epoch 902/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4108 - val_loss: 1.2831 - val_accuracy: 0.4016

Epoch 00902: val_loss improved from 1.28346 to 1.28307, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 903/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4093 - val_loss: 1.2889 - val_accuracy: 0.4024

Epoch 00903: val_loss did not improve from 1.28307
Epoch 904/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4065 - val_loss: 1.2846 - val_accuracy: 0.4048

Epoch 00904: val_loss did not improve from 1.28307
Epoch 905/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4155 - val_loss: 1.2867 - val_accuracy: 0.4048

Epoch 00905: val_loss did not improve from 1.28307
Epoch 906/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4041 - val_loss: 1.2898 - val_accuracy: 0.4112

Epoch 00906: val_loss did not improve from 1.28307
Epoch 907/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4087 - val_loss: 1.2865 - val_accuracy: 0.4096

Epoch 00907: val_loss did not improve from 1.28307
Epoch 908/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4130 - val_loss: 1.2853 - val_accuracy: 0.4120

Epoch 00908: val_loss did not improve from 1.28307
Epoch 909/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4089 - val_loss: 1.2863 - val_accuracy: 0.4056

Epoch 00909: val_loss did not improve from 1.28307
Epoch 910/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4136 - val_loss: 1.2838 - val_accuracy: 0.4096

Epoch 00910: val_loss did not improve from 1.28307
Epoch 911/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4126 - val_loss: 1.2844 - val_accuracy: 0.4096

Epoch 00911: val_loss did not improve from 1.28307
Epoch 912/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4134 - val_loss: 1.2855 - val_accuracy: 0.4096

Epoch 00912: val_loss did not improve from 1.28307
Epoch 913/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4077 - val_loss: 1.2896 - val_accuracy: 0.3992

Epoch 00913: val_loss did not improve from 1.28307
Epoch 914/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4102 - val_loss: 1.2820 - val_accuracy: 0.3992

Epoch 00914: val_loss improved from 1.28307 to 1.28195, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 915/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4111 - val_loss: 1.2824 - val_accuracy: 0.4032

Epoch 00915: val_loss did not improve from 1.28195
Epoch 916/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4119 - val_loss: 1.2855 - val_accuracy: 0.4064

Epoch 00916: val_loss did not improve from 1.28195
Epoch 917/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4118 - val_loss: 1.2850 - val_accuracy: 0.4024

Epoch 00917: val_loss did not improve from 1.28195
Epoch 918/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4104 - val_loss: 1.2882 - val_accuracy: 0.4056

Epoch 00918: val_loss did not improve from 1.28195
Epoch 919/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4106 - val_loss: 1.2858 - val_accuracy: 0.4048

Epoch 00919: val_loss did not improve from 1.28195
Epoch 920/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4136 - val_loss: 1.2839 - val_accuracy: 0.4120

Epoch 00920: val_loss did not improve from 1.28195
Epoch 921/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4055 - val_loss: 1.2883 - val_accuracy: 0.4064

Epoch 00921: val_loss did not improve from 1.28195
Epoch 922/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4066 - val_loss: 1.2836 - val_accuracy: 0.4024

Epoch 00922: val_loss did not improve from 1.28195
Epoch 923/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4105 - val_loss: 1.2822 - val_accuracy: 0.4048

Epoch 00923: val_loss did not improve from 1.28195
Epoch 924/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4133 - val_loss: 1.2856 - val_accuracy: 0.4127

Epoch 00924: val_loss did not improve from 1.28195
Epoch 925/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4151 - val_loss: 1.2843 - val_accuracy: 0.4024

Epoch 00925: val_loss did not improve from 1.28195
Epoch 926/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4125 - val_loss: 1.2852 - val_accuracy: 0.4040

Epoch 00926: val_loss did not improve from 1.28195
Epoch 927/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4082 - val_loss: 1.2863 - val_accuracy: 0.4040

Epoch 00927: val_loss did not improve from 1.28195
Epoch 928/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4137 - val_loss: 1.2835 - val_accuracy: 0.4048

Epoch 00928: val_loss did not improve from 1.28195
Epoch 929/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4120 - val_loss: 1.2867 - val_accuracy: 0.4056

Epoch 00929: val_loss did not improve from 1.28195
Epoch 930/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4111 - val_loss: 1.2834 - val_accuracy: 0.4120

Epoch 00930: val_loss did not improve from 1.28195
Epoch 931/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4138 - val_loss: 1.2896 - val_accuracy: 0.3992

Epoch 00931: val_loss did not improve from 1.28195
Epoch 932/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4089 - val_loss: 1.2838 - val_accuracy: 0.4072

Epoch 00932: val_loss did not improve from 1.28195
Epoch 933/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4136 - val_loss: 1.2894 - val_accuracy: 0.4120

Epoch 00933: val_loss did not improve from 1.28195
Epoch 934/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4081 - val_loss: 1.2858 - val_accuracy: 0.4048

Epoch 00934: val_loss did not improve from 1.28195
Epoch 935/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4108 - val_loss: 1.2845 - val_accuracy: 0.4056

Epoch 00935: val_loss did not improve from 1.28195
Epoch 936/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4118 - val_loss: 1.2862 - val_accuracy: 0.4056

Epoch 00936: val_loss did not improve from 1.28195
Epoch 937/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4138 - val_loss: 1.2850 - val_accuracy: 0.4024

Epoch 00937: val_loss did not improve from 1.28195
Epoch 938/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4095 - val_loss: 1.2866 - val_accuracy: 0.4088

Epoch 00938: val_loss did not improve from 1.28195
Epoch 939/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4105 - val_loss: 1.2863 - val_accuracy: 0.4032

Epoch 00939: val_loss did not improve from 1.28195
Epoch 940/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4113 - val_loss: 1.2830 - val_accuracy: 0.3920

Epoch 00940: val_loss did not improve from 1.28195
Epoch 941/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4128 - val_loss: 1.2903 - val_accuracy: 0.4167

Epoch 00941: val_loss did not improve from 1.28195
Epoch 942/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4088 - val_loss: 1.2883 - val_accuracy: 0.4143

Epoch 00942: val_loss did not improve from 1.28195
Epoch 943/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4094 - val_loss: 1.2863 - val_accuracy: 0.4024

Epoch 00943: val_loss did not improve from 1.28195
Epoch 944/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4133 - val_loss: 1.2828 - val_accuracy: 0.4008

Epoch 00944: val_loss did not improve from 1.28195
Epoch 945/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4119 - val_loss: 1.2829 - val_accuracy: 0.4024

Epoch 00945: val_loss did not improve from 1.28195
Epoch 946/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4129 - val_loss: 1.2813 - val_accuracy: 0.4032

Epoch 00946: val_loss improved from 1.28195 to 1.28126, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 947/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4115 - val_loss: 1.2855 - val_accuracy: 0.4175

Epoch 00947: val_loss did not improve from 1.28126
Epoch 948/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4087 - val_loss: 1.2823 - val_accuracy: 0.4032

Epoch 00948: val_loss did not improve from 1.28126
Epoch 949/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4119 - val_loss: 1.2843 - val_accuracy: 0.4064

Epoch 00949: val_loss did not improve from 1.28126
Epoch 950/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4108 - val_loss: 1.2870 - val_accuracy: 0.4024

Epoch 00950: val_loss did not improve from 1.28126
Epoch 951/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4081 - val_loss: 1.2851 - val_accuracy: 0.4008

Epoch 00951: val_loss did not improve from 1.28126
Epoch 952/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4112 - val_loss: 1.2838 - val_accuracy: 0.4008

Epoch 00952: val_loss did not improve from 1.28126
Epoch 953/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4129 - val_loss: 1.2829 - val_accuracy: 0.4104

Epoch 00953: val_loss did not improve from 1.28126
Epoch 954/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4086 - val_loss: 1.2834 - val_accuracy: 0.4016

Epoch 00954: val_loss did not improve from 1.28126
Epoch 955/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4083 - val_loss: 1.2857 - val_accuracy: 0.4143

Epoch 00955: val_loss did not improve from 1.28126
Epoch 956/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4089 - val_loss: 1.2839 - val_accuracy: 0.4024

Epoch 00956: val_loss did not improve from 1.28126
Epoch 957/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4111 - val_loss: 1.2837 - val_accuracy: 0.4088

Epoch 00957: val_loss did not improve from 1.28126
Epoch 958/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4112 - val_loss: 1.2855 - val_accuracy: 0.4088

Epoch 00958: val_loss did not improve from 1.28126
Epoch 959/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4125 - val_loss: 1.2825 - val_accuracy: 0.3984

Epoch 00959: val_loss did not improve from 1.28126
Epoch 960/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4116 - val_loss: 1.2869 - val_accuracy: 0.4088

Epoch 00960: val_loss did not improve from 1.28126
Epoch 961/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4133 - val_loss: 1.2863 - val_accuracy: 0.4048

Epoch 00961: val_loss did not improve from 1.28126
Epoch 962/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4144 - val_loss: 1.2817 - val_accuracy: 0.4080

Epoch 00962: val_loss did not improve from 1.28126
Epoch 963/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4070 - val_loss: 1.2861 - val_accuracy: 0.4120

Epoch 00963: val_loss did not improve from 1.28126
Epoch 964/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4105 - val_loss: 1.2840 - val_accuracy: 0.4127

Epoch 00964: val_loss did not improve from 1.28126
Epoch 965/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4123 - val_loss: 1.2820 - val_accuracy: 0.4024

Epoch 00965: val_loss did not improve from 1.28126
Epoch 966/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4143 - val_loss: 1.2809 - val_accuracy: 0.4120

Epoch 00966: val_loss improved from 1.28126 to 1.28088, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 967/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4102 - val_loss: 1.2840 - val_accuracy: 0.4032

Epoch 00967: val_loss did not improve from 1.28088
Epoch 968/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4130 - val_loss: 1.2817 - val_accuracy: 0.4096

Epoch 00968: val_loss did not improve from 1.28088
Epoch 969/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4139 - val_loss: 1.2826 - val_accuracy: 0.4096

Epoch 00969: val_loss did not improve from 1.28088
Epoch 970/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4116 - val_loss: 1.2835 - val_accuracy: 0.4088

Epoch 00970: val_loss did not improve from 1.28088
Epoch 971/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4089 - val_loss: 1.2823 - val_accuracy: 0.4024

Epoch 00971: val_loss did not improve from 1.28088
Epoch 972/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4117 - val_loss: 1.2827 - val_accuracy: 0.4072

Epoch 00972: val_loss did not improve from 1.28088
Epoch 973/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4121 - val_loss: 1.2896 - val_accuracy: 0.4096

Epoch 00973: val_loss did not improve from 1.28088
Epoch 974/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4117 - val_loss: 1.2853 - val_accuracy: 0.4056

Epoch 00974: val_loss did not improve from 1.28088
Epoch 975/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4136 - val_loss: 1.2837 - val_accuracy: 0.4040

Epoch 00975: val_loss did not improve from 1.28088
Epoch 976/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4112 - val_loss: 1.2859 - val_accuracy: 0.4008

Epoch 00976: val_loss did not improve from 1.28088
Epoch 977/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4115 - val_loss: 1.2808 - val_accuracy: 0.4016

Epoch 00977: val_loss improved from 1.28088 to 1.28084, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 978/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4090 - val_loss: 1.2832 - val_accuracy: 0.4072

Epoch 00978: val_loss did not improve from 1.28084
Epoch 979/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4132 - val_loss: 1.2839 - val_accuracy: 0.4080

Epoch 00979: val_loss did not improve from 1.28084
Epoch 980/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4142 - val_loss: 1.2834 - val_accuracy: 0.4072

Epoch 00980: val_loss did not improve from 1.28084
Epoch 981/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4118 - val_loss: 1.2838 - val_accuracy: 0.4104

Epoch 00981: val_loss did not improve from 1.28084
Epoch 982/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4182 - val_loss: 1.2869 - val_accuracy: 0.4135

Epoch 00982: val_loss did not improve from 1.28084
Epoch 983/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4131 - val_loss: 1.2850 - val_accuracy: 0.3960

Epoch 00983: val_loss did not improve from 1.28084
Epoch 984/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4099 - val_loss: 1.2840 - val_accuracy: 0.4016

Epoch 00984: val_loss did not improve from 1.28084
Epoch 985/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4149 - val_loss: 1.2846 - val_accuracy: 0.4032

Epoch 00985: val_loss did not improve from 1.28084
Epoch 986/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4137 - val_loss: 1.2861 - val_accuracy: 0.4112

Epoch 00986: val_loss did not improve from 1.28084
Epoch 987/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4119 - val_loss: 1.2827 - val_accuracy: 0.4088

Epoch 00987: val_loss did not improve from 1.28084
Epoch 988/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4141 - val_loss: 1.2823 - val_accuracy: 0.4056

Epoch 00988: val_loss did not improve from 1.28084
Epoch 989/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4064 - val_loss: 1.2902 - val_accuracy: 0.4239

Epoch 00989: val_loss did not improve from 1.28084
Epoch 990/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4100 - val_loss: 1.2823 - val_accuracy: 0.4120

Epoch 00990: val_loss did not improve from 1.28084
Epoch 991/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4102 - val_loss: 1.2837 - val_accuracy: 0.4104

Epoch 00991: val_loss did not improve from 1.28084
Epoch 992/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4159 - val_loss: 1.2836 - val_accuracy: 0.4127

Epoch 00992: val_loss did not improve from 1.28084
Epoch 993/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4100 - val_loss: 1.2854 - val_accuracy: 0.4048

Epoch 00993: val_loss did not improve from 1.28084
Epoch 994/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4066 - val_loss: 1.2925 - val_accuracy: 0.4271

Epoch 00994: val_loss did not improve from 1.28084
Epoch 995/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4091 - val_loss: 1.2837 - val_accuracy: 0.4112

Epoch 00995: val_loss did not improve from 1.28084
Epoch 996/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4130 - val_loss: 1.2896 - val_accuracy: 0.4088

Epoch 00996: val_loss did not improve from 1.28084
Epoch 997/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4128 - val_loss: 1.2813 - val_accuracy: 0.4104

Epoch 00997: val_loss did not improve from 1.28084
Epoch 998/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4098 - val_loss: 1.2803 - val_accuracy: 0.4104

Epoch 00998: val_loss improved from 1.28084 to 1.28032, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 999/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4158 - val_loss: 1.2817 - val_accuracy: 0.4000

Epoch 00999: val_loss did not improve from 1.28032
Epoch 1000/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4137 - val_loss: 1.2849 - val_accuracy: 0.4048

Epoch 01000: val_loss did not improve from 1.28032
Epoch 1001/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4138 - val_loss: 1.2816 - val_accuracy: 0.4040

Epoch 01001: val_loss did not improve from 1.28032
Epoch 1002/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4097 - val_loss: 1.2825 - val_accuracy: 0.4056

Epoch 01002: val_loss did not improve from 1.28032
Epoch 1003/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4177 - val_loss: 1.2794 - val_accuracy: 0.4104

Epoch 01003: val_loss improved from 1.28032 to 1.27935, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1004/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4160 - val_loss: 1.2813 - val_accuracy: 0.4104

Epoch 01004: val_loss did not improve from 1.27935
Epoch 1005/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4143 - val_loss: 1.2822 - val_accuracy: 0.4088

Epoch 01005: val_loss did not improve from 1.27935
Epoch 1006/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4127 - val_loss: 1.2842 - val_accuracy: 0.4112

Epoch 01006: val_loss did not improve from 1.27935
Epoch 1007/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4106 - val_loss: 1.2865 - val_accuracy: 0.4088

Epoch 01007: val_loss did not improve from 1.27935
Epoch 1008/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4101 - val_loss: 1.2864 - val_accuracy: 0.4048

Epoch 01008: val_loss did not improve from 1.27935
Epoch 1009/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4136 - val_loss: 1.2807 - val_accuracy: 0.4096

Epoch 01009: val_loss did not improve from 1.27935
Epoch 1010/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4153 - val_loss: 1.2810 - val_accuracy: 0.4127

Epoch 01010: val_loss did not improve from 1.27935
Epoch 1011/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4120 - val_loss: 1.2827 - val_accuracy: 0.4088

Epoch 01011: val_loss did not improve from 1.27935
Epoch 1012/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4132 - val_loss: 1.2856 - val_accuracy: 0.4143

Epoch 01012: val_loss did not improve from 1.27935
Epoch 1013/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4119 - val_loss: 1.2829 - val_accuracy: 0.4064

Epoch 01013: val_loss did not improve from 1.27935
Epoch 1014/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4128 - val_loss: 1.2828 - val_accuracy: 0.4072

Epoch 01014: val_loss did not improve from 1.27935
Epoch 1015/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4137 - val_loss: 1.2869 - val_accuracy: 0.4112

Epoch 01015: val_loss did not improve from 1.27935
Epoch 1016/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4112 - val_loss: 1.2857 - val_accuracy: 0.4096

Epoch 01016: val_loss did not improve from 1.27935
Epoch 1017/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4139 - val_loss: 1.2804 - val_accuracy: 0.4048

Epoch 01017: val_loss did not improve from 1.27935
Epoch 1018/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4155 - val_loss: 1.2839 - val_accuracy: 0.4088

Epoch 01018: val_loss did not improve from 1.27935
Epoch 1019/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4121 - val_loss: 1.2813 - val_accuracy: 0.4088

Epoch 01019: val_loss did not improve from 1.27935
Epoch 1020/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4128 - val_loss: 1.2821 - val_accuracy: 0.4072

Epoch 01020: val_loss did not improve from 1.27935
Epoch 1021/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4143 - val_loss: 1.2831 - val_accuracy: 0.3984

Epoch 01021: val_loss did not improve from 1.27935
Epoch 1022/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4137 - val_loss: 1.2803 - val_accuracy: 0.3992

Epoch 01022: val_loss did not improve from 1.27935
Epoch 1023/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4134 - val_loss: 1.2827 - val_accuracy: 0.4112

Epoch 01023: val_loss did not improve from 1.27935
Epoch 1024/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4144 - val_loss: 1.2862 - val_accuracy: 0.4032

Epoch 01024: val_loss did not improve from 1.27935
Epoch 1025/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4128 - val_loss: 1.2821 - val_accuracy: 0.4048

Epoch 01025: val_loss did not improve from 1.27935
Epoch 1026/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4123 - val_loss: 1.2844 - val_accuracy: 0.4072

Epoch 01026: val_loss did not improve from 1.27935
Epoch 1027/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4118 - val_loss: 1.2828 - val_accuracy: 0.4064

Epoch 01027: val_loss did not improve from 1.27935
Epoch 1028/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4124 - val_loss: 1.2838 - val_accuracy: 0.4064

Epoch 01028: val_loss did not improve from 1.27935
Epoch 1029/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4126 - val_loss: 1.2847 - val_accuracy: 0.4016

Epoch 01029: val_loss did not improve from 1.27935
Epoch 1030/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4166 - val_loss: 1.2838 - val_accuracy: 0.4024

Epoch 01030: val_loss did not improve from 1.27935
Epoch 1031/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4122 - val_loss: 1.2833 - val_accuracy: 0.4056

Epoch 01031: val_loss did not improve from 1.27935
Epoch 1032/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4089 - val_loss: 1.2811 - val_accuracy: 0.4000

Epoch 01032: val_loss did not improve from 1.27935
Epoch 1033/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4146 - val_loss: 1.2802 - val_accuracy: 0.4183

Epoch 01033: val_loss did not improve from 1.27935
Epoch 1034/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4149 - val_loss: 1.2812 - val_accuracy: 0.4048

Epoch 01034: val_loss did not improve from 1.27935
Epoch 1035/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4122 - val_loss: 1.2833 - val_accuracy: 0.4104

Epoch 01035: val_loss did not improve from 1.27935
Epoch 1036/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4127 - val_loss: 1.2843 - val_accuracy: 0.4040

Epoch 01036: val_loss did not improve from 1.27935
Epoch 1037/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4146 - val_loss: 1.2839 - val_accuracy: 0.4127

Epoch 01037: val_loss did not improve from 1.27935
Epoch 1038/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4119 - val_loss: 1.2826 - val_accuracy: 0.4080

Epoch 01038: val_loss did not improve from 1.27935
Epoch 1039/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4124 - val_loss: 1.2837 - val_accuracy: 0.4080

Epoch 01039: val_loss did not improve from 1.27935
Epoch 1040/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4160 - val_loss: 1.2844 - val_accuracy: 0.4096

Epoch 01040: val_loss did not improve from 1.27935
Epoch 1041/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4136 - val_loss: 1.2825 - val_accuracy: 0.4159

Epoch 01041: val_loss did not improve from 1.27935
Epoch 1042/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4106 - val_loss: 1.2826 - val_accuracy: 0.4088

Epoch 01042: val_loss did not improve from 1.27935
Epoch 1043/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4119 - val_loss: 1.2830 - val_accuracy: 0.4040

Epoch 01043: val_loss did not improve from 1.27935
Epoch 1044/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4167 - val_loss: 1.2812 - val_accuracy: 0.4008

Epoch 01044: val_loss did not improve from 1.27935
Epoch 1045/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4163 - val_loss: 1.2826 - val_accuracy: 0.4096

Epoch 01045: val_loss did not improve from 1.27935
Epoch 1046/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4156 - val_loss: 1.2828 - val_accuracy: 0.3992

Epoch 01046: val_loss did not improve from 1.27935
Epoch 1047/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4131 - val_loss: 1.2839 - val_accuracy: 0.4016

Epoch 01047: val_loss did not improve from 1.27935
Epoch 1048/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4107 - val_loss: 1.2834 - val_accuracy: 0.4056

Epoch 01048: val_loss did not improve from 1.27935
Epoch 1049/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4095 - val_loss: 1.2804 - val_accuracy: 0.4096

Epoch 01049: val_loss did not improve from 1.27935
Epoch 1050/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4153 - val_loss: 1.2830 - val_accuracy: 0.4207

Epoch 01050: val_loss did not improve from 1.27935
Epoch 1051/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4122 - val_loss: 1.2857 - val_accuracy: 0.4080

Epoch 01051: val_loss did not improve from 1.27935
Epoch 1052/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4131 - val_loss: 1.2825 - val_accuracy: 0.4143

Epoch 01052: val_loss did not improve from 1.27935
Epoch 1053/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4150 - val_loss: 1.2826 - val_accuracy: 0.4104

Epoch 01053: val_loss did not improve from 1.27935
Epoch 1054/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4129 - val_loss: 1.2828 - val_accuracy: 0.4008

Epoch 01054: val_loss did not improve from 1.27935
Epoch 1055/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4174 - val_loss: 1.2811 - val_accuracy: 0.4016

Epoch 01055: val_loss did not improve from 1.27935
Epoch 1056/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4127 - val_loss: 1.2798 - val_accuracy: 0.4000

Epoch 01056: val_loss did not improve from 1.27935
Epoch 1057/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4124 - val_loss: 1.2837 - val_accuracy: 0.4143

Epoch 01057: val_loss did not improve from 1.27935
Epoch 1058/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4136 - val_loss: 1.2833 - val_accuracy: 0.4040

Epoch 01058: val_loss did not improve from 1.27935
Epoch 1059/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4090 - val_loss: 1.2822 - val_accuracy: 0.4104

Epoch 01059: val_loss did not improve from 1.27935
Epoch 1060/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4125 - val_loss: 1.2821 - val_accuracy: 0.4040

Epoch 01060: val_loss did not improve from 1.27935
Epoch 1061/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4143 - val_loss: 1.2862 - val_accuracy: 0.4127

Epoch 01061: val_loss did not improve from 1.27935
Epoch 1062/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4111 - val_loss: 1.2936 - val_accuracy: 0.4040

Epoch 01062: val_loss did not improve from 1.27935
Epoch 1063/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4093 - val_loss: 1.2814 - val_accuracy: 0.4016

Epoch 01063: val_loss did not improve from 1.27935
Epoch 1064/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4124 - val_loss: 1.2839 - val_accuracy: 0.4088

Epoch 01064: val_loss did not improve from 1.27935
Epoch 1065/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4155 - val_loss: 1.2822 - val_accuracy: 0.4120

Epoch 01065: val_loss did not improve from 1.27935
Epoch 1066/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4174 - val_loss: 1.2833 - val_accuracy: 0.3968

Epoch 01066: val_loss did not improve from 1.27935
Epoch 1067/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4155 - val_loss: 1.2817 - val_accuracy: 0.4024

Epoch 01067: val_loss did not improve from 1.27935
Epoch 1068/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4102 - val_loss: 1.2827 - val_accuracy: 0.4104

Epoch 01068: val_loss did not improve from 1.27935
Epoch 1069/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4153 - val_loss: 1.2836 - val_accuracy: 0.3992

Epoch 01069: val_loss did not improve from 1.27935
Epoch 1070/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4135 - val_loss: 1.2817 - val_accuracy: 0.4088

Epoch 01070: val_loss did not improve from 1.27935
Epoch 1071/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4107 - val_loss: 1.2818 - val_accuracy: 0.4143

Epoch 01071: val_loss did not improve from 1.27935
Epoch 1072/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4121 - val_loss: 1.2803 - val_accuracy: 0.4064

Epoch 01072: val_loss did not improve from 1.27935
Epoch 1073/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4122 - val_loss: 1.2803 - val_accuracy: 0.4104

Epoch 01073: val_loss did not improve from 1.27935
Epoch 1074/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4131 - val_loss: 1.2783 - val_accuracy: 0.4080

Epoch 01074: val_loss improved from 1.27935 to 1.27834, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1075/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4146 - val_loss: 1.2802 - val_accuracy: 0.4127

Epoch 01075: val_loss did not improve from 1.27834
Epoch 1076/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4148 - val_loss: 1.2794 - val_accuracy: 0.4088

Epoch 01076: val_loss did not improve from 1.27834
Epoch 1077/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4126 - val_loss: 1.2835 - val_accuracy: 0.4040

Epoch 01077: val_loss did not improve from 1.27834
Epoch 1078/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4173 - val_loss: 1.2816 - val_accuracy: 0.4104

Epoch 01078: val_loss did not improve from 1.27834
Epoch 1079/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4123 - val_loss: 1.2802 - val_accuracy: 0.4040

Epoch 01079: val_loss did not improve from 1.27834
Epoch 1080/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4145 - val_loss: 1.2838 - val_accuracy: 0.4040

Epoch 01080: val_loss did not improve from 1.27834
Epoch 1081/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4109 - val_loss: 1.2907 - val_accuracy: 0.4096

Epoch 01081: val_loss did not improve from 1.27834
Epoch 1082/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4119 - val_loss: 1.2816 - val_accuracy: 0.4080

Epoch 01082: val_loss did not improve from 1.27834
Epoch 1083/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4152 - val_loss: 1.2801 - val_accuracy: 0.4088

Epoch 01083: val_loss did not improve from 1.27834
Epoch 1084/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4144 - val_loss: 1.2805 - val_accuracy: 0.3984

Epoch 01084: val_loss did not improve from 1.27834
Epoch 1085/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4125 - val_loss: 1.2806 - val_accuracy: 0.4064

Epoch 01085: val_loss did not improve from 1.27834
Epoch 1086/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4097 - val_loss: 1.2818 - val_accuracy: 0.4167

Epoch 01086: val_loss did not improve from 1.27834
Epoch 1087/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4136 - val_loss: 1.2837 - val_accuracy: 0.4048

Epoch 01087: val_loss did not improve from 1.27834
Epoch 1088/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4122 - val_loss: 1.2852 - val_accuracy: 0.3952

Epoch 01088: val_loss did not improve from 1.27834
Epoch 1089/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4136 - val_loss: 1.2817 - val_accuracy: 0.4016

Epoch 01089: val_loss did not improve from 1.27834
Epoch 1090/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4143 - val_loss: 1.2862 - val_accuracy: 0.3960

Epoch 01090: val_loss did not improve from 1.27834
Epoch 1091/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4126 - val_loss: 1.2797 - val_accuracy: 0.4064

Epoch 01091: val_loss did not improve from 1.27834
Epoch 1092/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4154 - val_loss: 1.2797 - val_accuracy: 0.4127

Epoch 01092: val_loss did not improve from 1.27834
Epoch 1093/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4122 - val_loss: 1.2848 - val_accuracy: 0.4120

Epoch 01093: val_loss did not improve from 1.27834
Epoch 1094/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4174 - val_loss: 1.2816 - val_accuracy: 0.4112

Epoch 01094: val_loss did not improve from 1.27834
Epoch 1095/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4142 - val_loss: 1.2880 - val_accuracy: 0.4088

Epoch 01095: val_loss did not improve from 1.27834
Epoch 1096/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4120 - val_loss: 1.2969 - val_accuracy: 0.4016

Epoch 01096: val_loss did not improve from 1.27834
Epoch 1097/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4120 - val_loss: 1.2861 - val_accuracy: 0.4159

Epoch 01097: val_loss did not improve from 1.27834
Epoch 1098/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4112 - val_loss: 1.2876 - val_accuracy: 0.4143

Epoch 01098: val_loss did not improve from 1.27834
Epoch 1099/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4090 - val_loss: 1.2889 - val_accuracy: 0.4008

Epoch 01099: val_loss did not improve from 1.27834
Epoch 1100/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4112 - val_loss: 1.2857 - val_accuracy: 0.3992

Epoch 01100: val_loss did not improve from 1.27834
Epoch 1101/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4129 - val_loss: 1.2819 - val_accuracy: 0.4032

Epoch 01101: val_loss did not improve from 1.27834
Epoch 1102/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4146 - val_loss: 1.2828 - val_accuracy: 0.4104

Epoch 01102: val_loss did not improve from 1.27834
Epoch 1103/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4113 - val_loss: 1.2853 - val_accuracy: 0.4143

Epoch 01103: val_loss did not improve from 1.27834
Epoch 1104/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4128 - val_loss: 1.2837 - val_accuracy: 0.4016

Epoch 01104: val_loss did not improve from 1.27834
Epoch 1105/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4185 - val_loss: 1.2837 - val_accuracy: 0.4056

Epoch 01105: val_loss did not improve from 1.27834
Epoch 1106/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4115 - val_loss: 1.2880 - val_accuracy: 0.4191

Epoch 01106: val_loss did not improve from 1.27834
Epoch 1107/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4167 - val_loss: 1.2842 - val_accuracy: 0.4024

Epoch 01107: val_loss did not improve from 1.27834
Epoch 1108/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4136 - val_loss: 1.2813 - val_accuracy: 0.4056

Epoch 01108: val_loss did not improve from 1.27834
Epoch 1109/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4128 - val_loss: 1.2800 - val_accuracy: 0.4112

Epoch 01109: val_loss did not improve from 1.27834
Epoch 1110/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4128 - val_loss: 1.2794 - val_accuracy: 0.4048

Epoch 01110: val_loss did not improve from 1.27834
Epoch 1111/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4117 - val_loss: 1.2862 - val_accuracy: 0.3992

Epoch 01111: val_loss did not improve from 1.27834
Epoch 1112/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4142 - val_loss: 1.2810 - val_accuracy: 0.4056

Epoch 01112: val_loss did not improve from 1.27834
Epoch 1113/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4138 - val_loss: 1.2822 - val_accuracy: 0.4120

Epoch 01113: val_loss did not improve from 1.27834
Epoch 1114/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4164 - val_loss: 1.2804 - val_accuracy: 0.4072

Epoch 01114: val_loss did not improve from 1.27834
Epoch 1115/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4139 - val_loss: 1.2833 - val_accuracy: 0.4064

Epoch 01115: val_loss did not improve from 1.27834
Epoch 1116/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4159 - val_loss: 1.2792 - val_accuracy: 0.4072

Epoch 01116: val_loss did not improve from 1.27834
Epoch 1117/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4143 - val_loss: 1.2805 - val_accuracy: 0.4000

Epoch 01117: val_loss did not improve from 1.27834
Epoch 1118/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4144 - val_loss: 1.2857 - val_accuracy: 0.4143

Epoch 01118: val_loss did not improve from 1.27834
Epoch 1119/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4123 - val_loss: 1.2862 - val_accuracy: 0.4056

Epoch 01119: val_loss did not improve from 1.27834
Epoch 1120/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4115 - val_loss: 1.2830 - val_accuracy: 0.4120

Epoch 01120: val_loss did not improve from 1.27834
Epoch 1121/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4136 - val_loss: 1.2853 - val_accuracy: 0.4223

Epoch 01121: val_loss did not improve from 1.27834
Epoch 1122/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4135 - val_loss: 1.2813 - val_accuracy: 0.4032

Epoch 01122: val_loss did not improve from 1.27834
Epoch 1123/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4103 - val_loss: 1.2834 - val_accuracy: 0.4048

Epoch 01123: val_loss did not improve from 1.27834
Epoch 1124/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4135 - val_loss: 1.2821 - val_accuracy: 0.4080

Epoch 01124: val_loss did not improve from 1.27834
Epoch 1125/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4135 - val_loss: 1.2819 - val_accuracy: 0.4088

Epoch 01125: val_loss did not improve from 1.27834
Epoch 1126/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4146 - val_loss: 1.2827 - val_accuracy: 0.4112

Epoch 01126: val_loss did not improve from 1.27834
Epoch 1127/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4124 - val_loss: 1.2818 - val_accuracy: 0.4120

Epoch 01127: val_loss did not improve from 1.27834
Epoch 1128/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4157 - val_loss: 1.2811 - val_accuracy: 0.4127

Epoch 01128: val_loss did not improve from 1.27834
Epoch 1129/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4156 - val_loss: 1.2807 - val_accuracy: 0.4143

Epoch 01129: val_loss did not improve from 1.27834
Epoch 1130/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4144 - val_loss: 1.2831 - val_accuracy: 0.4207

Epoch 01130: val_loss did not improve from 1.27834
Epoch 1131/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4115 - val_loss: 1.2860 - val_accuracy: 0.4048

Epoch 01131: val_loss did not improve from 1.27834
Epoch 1132/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4097 - val_loss: 1.2823 - val_accuracy: 0.4120

Epoch 01132: val_loss did not improve from 1.27834
Epoch 1133/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4151 - val_loss: 1.2785 - val_accuracy: 0.4096

Epoch 01133: val_loss did not improve from 1.27834
Epoch 1134/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4173 - val_loss: 1.2795 - val_accuracy: 0.4056

Epoch 01134: val_loss did not improve from 1.27834
Epoch 1135/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4096 - val_loss: 1.2808 - val_accuracy: 0.4151

Epoch 01135: val_loss did not improve from 1.27834
Epoch 1136/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4128 - val_loss: 1.2833 - val_accuracy: 0.4048

Epoch 01136: val_loss did not improve from 1.27834
Epoch 1137/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4172 - val_loss: 1.2843 - val_accuracy: 0.4080

Epoch 01137: val_loss did not improve from 1.27834
Epoch 1138/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4104 - val_loss: 1.2844 - val_accuracy: 0.4096

Epoch 01138: val_loss did not improve from 1.27834
Epoch 1139/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4150 - val_loss: 1.2804 - val_accuracy: 0.4096

Epoch 01139: val_loss did not improve from 1.27834
Epoch 1140/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4126 - val_loss: 1.2812 - val_accuracy: 0.4064

Epoch 01140: val_loss did not improve from 1.27834
Epoch 1141/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4136 - val_loss: 1.2846 - val_accuracy: 0.4096

Epoch 01141: val_loss did not improve from 1.27834
Epoch 1142/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4143 - val_loss: 1.2813 - val_accuracy: 0.4143

Epoch 01142: val_loss did not improve from 1.27834
Epoch 1143/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4144 - val_loss: 1.2821 - val_accuracy: 0.4088

Epoch 01143: val_loss did not improve from 1.27834
Epoch 1144/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4153 - val_loss: 1.2798 - val_accuracy: 0.4135

Epoch 01144: val_loss did not improve from 1.27834
Epoch 1145/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4132 - val_loss: 1.2852 - val_accuracy: 0.4151

Epoch 01145: val_loss did not improve from 1.27834
Epoch 1146/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4131 - val_loss: 1.2794 - val_accuracy: 0.4032

Epoch 01146: val_loss did not improve from 1.27834
Epoch 1147/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4202 - val_loss: 1.2806 - val_accuracy: 0.4104

Epoch 01147: val_loss did not improve from 1.27834
Epoch 1148/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4110 - val_loss: 1.2832 - val_accuracy: 0.4127

Epoch 01148: val_loss did not improve from 1.27834
Epoch 1149/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4101 - val_loss: 1.2903 - val_accuracy: 0.4127

Epoch 01149: val_loss did not improve from 1.27834
Epoch 1150/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4151 - val_loss: 1.2823 - val_accuracy: 0.4104

Epoch 01150: val_loss did not improve from 1.27834
Epoch 1151/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4153 - val_loss: 1.2823 - val_accuracy: 0.4135

Epoch 01151: val_loss did not improve from 1.27834
Epoch 1152/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4154 - val_loss: 1.2790 - val_accuracy: 0.4072

Epoch 01152: val_loss did not improve from 1.27834
Epoch 1153/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4118 - val_loss: 1.2815 - val_accuracy: 0.3968

Epoch 01153: val_loss did not improve from 1.27834
Epoch 1154/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4157 - val_loss: 1.2819 - val_accuracy: 0.4048

Epoch 01154: val_loss did not improve from 1.27834
Epoch 1155/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4151 - val_loss: 1.2808 - val_accuracy: 0.4056

Epoch 01155: val_loss did not improve from 1.27834
Epoch 1156/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4129 - val_loss: 1.2803 - val_accuracy: 0.4056

Epoch 01156: val_loss did not improve from 1.27834
Epoch 1157/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4147 - val_loss: 1.2808 - val_accuracy: 0.4159

Epoch 01157: val_loss did not improve from 1.27834
Epoch 1158/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4141 - val_loss: 1.2777 - val_accuracy: 0.4048

Epoch 01158: val_loss improved from 1.27834 to 1.27773, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1159/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4102 - val_loss: 1.2785 - val_accuracy: 0.4048

Epoch 01159: val_loss did not improve from 1.27773
Epoch 1160/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4163 - val_loss: 1.2769 - val_accuracy: 0.4104

Epoch 01160: val_loss improved from 1.27773 to 1.27691, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1161/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4141 - val_loss: 1.2771 - val_accuracy: 0.4080

Epoch 01161: val_loss did not improve from 1.27691
Epoch 1162/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4164 - val_loss: 1.2796 - val_accuracy: 0.3968

Epoch 01162: val_loss did not improve from 1.27691
Epoch 1163/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4154 - val_loss: 1.2812 - val_accuracy: 0.4167

Epoch 01163: val_loss did not improve from 1.27691
Epoch 1164/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4128 - val_loss: 1.2774 - val_accuracy: 0.4008

Epoch 01164: val_loss did not improve from 1.27691
Epoch 1165/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4136 - val_loss: 1.2818 - val_accuracy: 0.4056

Epoch 01165: val_loss did not improve from 1.27691
Epoch 1166/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4137 - val_loss: 1.2808 - val_accuracy: 0.4143

Epoch 01166: val_loss did not improve from 1.27691
Epoch 1167/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4170 - val_loss: 1.2774 - val_accuracy: 0.4080

Epoch 01167: val_loss did not improve from 1.27691
Epoch 1168/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4135 - val_loss: 1.2791 - val_accuracy: 0.4088

Epoch 01168: val_loss did not improve from 1.27691
Epoch 1169/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4160 - val_loss: 1.2781 - val_accuracy: 0.4135

Epoch 01169: val_loss did not improve from 1.27691
Epoch 1170/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4165 - val_loss: 1.2769 - val_accuracy: 0.4032

Epoch 01170: val_loss improved from 1.27691 to 1.27687, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1171/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4171 - val_loss: 1.2801 - val_accuracy: 0.4096

Epoch 01171: val_loss did not improve from 1.27687
Epoch 1172/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4161 - val_loss: 1.2785 - val_accuracy: 0.4008

Epoch 01172: val_loss did not improve from 1.27687
Epoch 1173/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4184 - val_loss: 1.2798 - val_accuracy: 0.4080

Epoch 01173: val_loss did not improve from 1.27687
Epoch 1174/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4145 - val_loss: 1.2787 - val_accuracy: 0.4064

Epoch 01174: val_loss did not improve from 1.27687
Epoch 1175/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4175 - val_loss: 1.2815 - val_accuracy: 0.4143

Epoch 01175: val_loss did not improve from 1.27687
Epoch 1176/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4197 - val_loss: 1.2799 - val_accuracy: 0.4072

Epoch 01176: val_loss did not improve from 1.27687
Epoch 1177/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4124 - val_loss: 1.2808 - val_accuracy: 0.4072

Epoch 01177: val_loss did not improve from 1.27687
Epoch 1178/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4136 - val_loss: 1.2825 - val_accuracy: 0.4096

Epoch 01178: val_loss did not improve from 1.27687
Epoch 1179/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4166 - val_loss: 1.2800 - val_accuracy: 0.3976

Epoch 01179: val_loss did not improve from 1.27687
Epoch 1180/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4137 - val_loss: 1.2785 - val_accuracy: 0.4120

Epoch 01180: val_loss did not improve from 1.27687
Epoch 1181/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4128 - val_loss: 1.2835 - val_accuracy: 0.4056

Epoch 01181: val_loss did not improve from 1.27687
Epoch 1182/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4127 - val_loss: 1.2801 - val_accuracy: 0.4175

Epoch 01182: val_loss did not improve from 1.27687
Epoch 1183/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4201 - val_loss: 1.2804 - val_accuracy: 0.4167

Epoch 01183: val_loss did not improve from 1.27687
Epoch 1184/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4148 - val_loss: 1.2781 - val_accuracy: 0.4127

Epoch 01184: val_loss did not improve from 1.27687
Epoch 1185/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4137 - val_loss: 1.2848 - val_accuracy: 0.4064

Epoch 01185: val_loss did not improve from 1.27687
Epoch 1186/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4124 - val_loss: 1.2831 - val_accuracy: 0.4135

Epoch 01186: val_loss did not improve from 1.27687
Epoch 1187/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4141 - val_loss: 1.2821 - val_accuracy: 0.4127

Epoch 01187: val_loss did not improve from 1.27687
Epoch 1188/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4153 - val_loss: 1.2831 - val_accuracy: 0.4127

Epoch 01188: val_loss did not improve from 1.27687
Epoch 1189/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4183 - val_loss: 1.2815 - val_accuracy: 0.4183

Epoch 01189: val_loss did not improve from 1.27687
Epoch 1190/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4182 - val_loss: 1.2823 - val_accuracy: 0.4127

Epoch 01190: val_loss did not improve from 1.27687
Epoch 1191/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4168 - val_loss: 1.2840 - val_accuracy: 0.4112

Epoch 01191: val_loss did not improve from 1.27687
Epoch 1192/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4159 - val_loss: 1.2805 - val_accuracy: 0.4032

Epoch 01192: val_loss did not improve from 1.27687
Epoch 1193/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4199 - val_loss: 1.2784 - val_accuracy: 0.4127

Epoch 01193: val_loss did not improve from 1.27687
Epoch 1194/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4169 - val_loss: 1.2785 - val_accuracy: 0.4127

Epoch 01194: val_loss did not improve from 1.27687
Epoch 1195/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4194 - val_loss: 1.2789 - val_accuracy: 0.4191

Epoch 01195: val_loss did not improve from 1.27687
Epoch 1196/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4183 - val_loss: 1.2788 - val_accuracy: 0.4207

Epoch 01196: val_loss did not improve from 1.27687
Epoch 1197/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4187 - val_loss: 1.2793 - val_accuracy: 0.4127

Epoch 01197: val_loss did not improve from 1.27687
Epoch 1198/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4159 - val_loss: 1.2777 - val_accuracy: 0.4112

Epoch 01198: val_loss did not improve from 1.27687
Epoch 1199/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4136 - val_loss: 1.2795 - val_accuracy: 0.4151

Epoch 01199: val_loss did not improve from 1.27687
Epoch 1200/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4153 - val_loss: 1.2801 - val_accuracy: 0.4080

Epoch 01200: val_loss did not improve from 1.27687
Epoch 1201/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4136 - val_loss: 1.2844 - val_accuracy: 0.4112

Epoch 01201: val_loss did not improve from 1.27687
Epoch 1202/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4153 - val_loss: 1.2808 - val_accuracy: 0.4104

Epoch 01202: val_loss did not improve from 1.27687
Epoch 1203/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4182 - val_loss: 1.2785 - val_accuracy: 0.4072

Epoch 01203: val_loss did not improve from 1.27687
Epoch 1204/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4156 - val_loss: 1.2826 - val_accuracy: 0.4024

Epoch 01204: val_loss did not improve from 1.27687
Epoch 1205/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4145 - val_loss: 1.2837 - val_accuracy: 0.4064

Epoch 01205: val_loss did not improve from 1.27687
Epoch 1206/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4209 - val_loss: 1.2791 - val_accuracy: 0.4223

Epoch 01206: val_loss did not improve from 1.27687
Epoch 1207/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4194 - val_loss: 1.2772 - val_accuracy: 0.4104

Epoch 01207: val_loss did not improve from 1.27687
Epoch 1208/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4139 - val_loss: 1.2828 - val_accuracy: 0.4088

Epoch 01208: val_loss did not improve from 1.27687
Epoch 1209/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4178 - val_loss: 1.2834 - val_accuracy: 0.4088

Epoch 01209: val_loss did not improve from 1.27687
Epoch 1210/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4182 - val_loss: 1.2775 - val_accuracy: 0.4072

Epoch 01210: val_loss did not improve from 1.27687
Epoch 1211/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4150 - val_loss: 1.2802 - val_accuracy: 0.4040

Epoch 01211: val_loss did not improve from 1.27687
Epoch 1212/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4141 - val_loss: 1.2804 - val_accuracy: 0.4120

Epoch 01212: val_loss did not improve from 1.27687
Epoch 1213/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4179 - val_loss: 1.2808 - val_accuracy: 0.4215

Epoch 01213: val_loss did not improve from 1.27687
Epoch 1214/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4134 - val_loss: 1.2859 - val_accuracy: 0.4048

Epoch 01214: val_loss did not improve from 1.27687
Epoch 1215/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4121 - val_loss: 1.2835 - val_accuracy: 0.4127

Epoch 01215: val_loss did not improve from 1.27687
Epoch 1216/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4208 - val_loss: 1.2780 - val_accuracy: 0.4064

Epoch 01216: val_loss did not improve from 1.27687
Epoch 1217/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4163 - val_loss: 1.2804 - val_accuracy: 0.3992

Epoch 01217: val_loss did not improve from 1.27687
Epoch 1218/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4135 - val_loss: 1.2791 - val_accuracy: 0.4104

Epoch 01218: val_loss did not improve from 1.27687
Epoch 1219/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4200 - val_loss: 1.2820 - val_accuracy: 0.4112

Epoch 01219: val_loss did not improve from 1.27687
Epoch 1220/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4198 - val_loss: 1.2812 - val_accuracy: 0.4088

Epoch 01220: val_loss did not improve from 1.27687
Epoch 1221/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4195 - val_loss: 1.2794 - val_accuracy: 0.4104

Epoch 01221: val_loss did not improve from 1.27687
Epoch 1222/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4181 - val_loss: 1.2772 - val_accuracy: 0.4072

Epoch 01222: val_loss did not improve from 1.27687
Epoch 1223/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4167 - val_loss: 1.2769 - val_accuracy: 0.4207

Epoch 01223: val_loss improved from 1.27687 to 1.27686, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1224/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4135 - val_loss: 1.2788 - val_accuracy: 0.4191

Epoch 01224: val_loss did not improve from 1.27686
Epoch 1225/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4179 - val_loss: 1.2779 - val_accuracy: 0.4088

Epoch 01225: val_loss did not improve from 1.27686
Epoch 1226/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4184 - val_loss: 1.2805 - val_accuracy: 0.4088

Epoch 01226: val_loss did not improve from 1.27686
Epoch 1227/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4128 - val_loss: 1.2823 - val_accuracy: 0.4080

Epoch 01227: val_loss did not improve from 1.27686
Epoch 1228/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4150 - val_loss: 1.2847 - val_accuracy: 0.4127

Epoch 01228: val_loss did not improve from 1.27686
Epoch 1229/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4195 - val_loss: 1.2778 - val_accuracy: 0.4104

Epoch 01229: val_loss did not improve from 1.27686
Epoch 1230/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4197 - val_loss: 1.2765 - val_accuracy: 0.4072

Epoch 01230: val_loss improved from 1.27686 to 1.27650, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1231/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4192 - val_loss: 1.2780 - val_accuracy: 0.4088

Epoch 01231: val_loss did not improve from 1.27650
Epoch 1232/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4182 - val_loss: 1.2788 - val_accuracy: 0.4032

Epoch 01232: val_loss did not improve from 1.27650
Epoch 1233/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4193 - val_loss: 1.2780 - val_accuracy: 0.4064

Epoch 01233: val_loss did not improve from 1.27650
Epoch 1234/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4178 - val_loss: 1.2806 - val_accuracy: 0.4143

Epoch 01234: val_loss did not improve from 1.27650
Epoch 1235/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4173 - val_loss: 1.2786 - val_accuracy: 0.4159

Epoch 01235: val_loss did not improve from 1.27650
Epoch 1236/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4152 - val_loss: 1.2801 - val_accuracy: 0.4231

Epoch 01236: val_loss did not improve from 1.27650
Epoch 1237/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4158 - val_loss: 1.2811 - val_accuracy: 0.4112

Epoch 01237: val_loss did not improve from 1.27650
Epoch 1238/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4205 - val_loss: 1.2834 - val_accuracy: 0.4064

Epoch 01238: val_loss did not improve from 1.27650
Epoch 1239/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4125 - val_loss: 1.2826 - val_accuracy: 0.4143

Epoch 01239: val_loss did not improve from 1.27650
Epoch 1240/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4171 - val_loss: 1.2775 - val_accuracy: 0.4127

Epoch 01240: val_loss did not improve from 1.27650
Epoch 1241/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4195 - val_loss: 1.2782 - val_accuracy: 0.4135

Epoch 01241: val_loss did not improve from 1.27650
Epoch 1242/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4204 - val_loss: 1.2796 - val_accuracy: 0.4032

Epoch 01242: val_loss did not improve from 1.27650
Epoch 1243/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4158 - val_loss: 1.2823 - val_accuracy: 0.4183

Epoch 01243: val_loss did not improve from 1.27650
Epoch 1244/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4194 - val_loss: 1.2794 - val_accuracy: 0.4135

Epoch 01244: val_loss did not improve from 1.27650
Epoch 1245/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4180 - val_loss: 1.2795 - val_accuracy: 0.4247

Epoch 01245: val_loss did not improve from 1.27650
Epoch 1246/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4169 - val_loss: 1.2809 - val_accuracy: 0.4112

Epoch 01246: val_loss did not improve from 1.27650
Epoch 1247/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4182 - val_loss: 1.2805 - val_accuracy: 0.4207

Epoch 01247: val_loss did not improve from 1.27650
Epoch 1248/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4175 - val_loss: 1.2825 - val_accuracy: 0.4215

Epoch 01248: val_loss did not improve from 1.27650
Epoch 1249/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4155 - val_loss: 1.2884 - val_accuracy: 0.4048

Epoch 01249: val_loss did not improve from 1.27650
Epoch 1250/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4168 - val_loss: 1.2828 - val_accuracy: 0.4080

Epoch 01250: val_loss did not improve from 1.27650
Epoch 1251/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4190 - val_loss: 1.2823 - val_accuracy: 0.4135

Epoch 01251: val_loss did not improve from 1.27650
Epoch 1252/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4172 - val_loss: 1.2852 - val_accuracy: 0.4127

Epoch 01252: val_loss did not improve from 1.27650
Epoch 1253/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4179 - val_loss: 1.2840 - val_accuracy: 0.4088

Epoch 01253: val_loss did not improve from 1.27650
Epoch 1254/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4137 - val_loss: 1.2850 - val_accuracy: 0.4032

Epoch 01254: val_loss did not improve from 1.27650
Epoch 1255/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4156 - val_loss: 1.2818 - val_accuracy: 0.4151

Epoch 01255: val_loss did not improve from 1.27650
Epoch 1256/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4182 - val_loss: 1.2820 - val_accuracy: 0.4080

Epoch 01256: val_loss did not improve from 1.27650
Epoch 1257/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4236 - val_loss: 1.2802 - val_accuracy: 0.4183

Epoch 01257: val_loss did not improve from 1.27650
Epoch 1258/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4141 - val_loss: 1.2831 - val_accuracy: 0.4127

Epoch 01258: val_loss did not improve from 1.27650
Epoch 1259/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4195 - val_loss: 1.2792 - val_accuracy: 0.4135

Epoch 01259: val_loss did not improve from 1.27650
Epoch 1260/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4178 - val_loss: 1.2789 - val_accuracy: 0.4112

Epoch 01260: val_loss did not improve from 1.27650
Epoch 1261/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4176 - val_loss: 1.2794 - val_accuracy: 0.4112

Epoch 01261: val_loss did not improve from 1.27650
Epoch 1262/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4162 - val_loss: 1.2806 - val_accuracy: 0.4096

Epoch 01262: val_loss did not improve from 1.27650
Epoch 1263/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4159 - val_loss: 1.2799 - val_accuracy: 0.4127

Epoch 01263: val_loss did not improve from 1.27650
Epoch 1264/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4221 - val_loss: 1.2794 - val_accuracy: 0.4199

Epoch 01264: val_loss did not improve from 1.27650
Epoch 1265/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4192 - val_loss: 1.2793 - val_accuracy: 0.4215

Epoch 01265: val_loss did not improve from 1.27650
Epoch 1266/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4173 - val_loss: 1.2790 - val_accuracy: 0.4096

Epoch 01266: val_loss did not improve from 1.27650
Epoch 1267/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4166 - val_loss: 1.2817 - val_accuracy: 0.4135

Epoch 01267: val_loss did not improve from 1.27650
Epoch 1268/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4190 - val_loss: 1.2799 - val_accuracy: 0.4135

Epoch 01268: val_loss did not improve from 1.27650
Epoch 1269/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4205 - val_loss: 1.2877 - val_accuracy: 0.4056

Epoch 01269: val_loss did not improve from 1.27650
Epoch 1270/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4173 - val_loss: 1.2765 - val_accuracy: 0.4231

Epoch 01270: val_loss did not improve from 1.27650
Epoch 1271/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4193 - val_loss: 1.2783 - val_accuracy: 0.4112

Epoch 01271: val_loss did not improve from 1.27650
Epoch 1272/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4169 - val_loss: 1.2837 - val_accuracy: 0.4127

Epoch 01272: val_loss did not improve from 1.27650
Epoch 1273/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4186 - val_loss: 1.2817 - val_accuracy: 0.4088

Epoch 01273: val_loss did not improve from 1.27650
Epoch 1274/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4159 - val_loss: 1.2788 - val_accuracy: 0.4088

Epoch 01274: val_loss did not improve from 1.27650
Epoch 1275/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4182 - val_loss: 1.2747 - val_accuracy: 0.4120

Epoch 01275: val_loss improved from 1.27650 to 1.27470, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1276/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4176 - val_loss: 1.2787 - val_accuracy: 0.4104

Epoch 01276: val_loss did not improve from 1.27470
Epoch 1277/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4195 - val_loss: 1.2807 - val_accuracy: 0.4191

Epoch 01277: val_loss did not improve from 1.27470
Epoch 1278/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4202 - val_loss: 1.2802 - val_accuracy: 0.4127

Epoch 01278: val_loss did not improve from 1.27470
Epoch 1279/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4205 - val_loss: 1.2798 - val_accuracy: 0.4127

Epoch 01279: val_loss did not improve from 1.27470
Epoch 1280/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4153 - val_loss: 1.2803 - val_accuracy: 0.4183

Epoch 01280: val_loss did not improve from 1.27470
Epoch 1281/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4174 - val_loss: 1.2784 - val_accuracy: 0.4143

Epoch 01281: val_loss did not improve from 1.27470
Epoch 1282/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4166 - val_loss: 1.2791 - val_accuracy: 0.4120

Epoch 01282: val_loss did not improve from 1.27470
Epoch 1283/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4230 - val_loss: 1.2798 - val_accuracy: 0.4231

Epoch 01283: val_loss did not improve from 1.27470
Epoch 1284/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4197 - val_loss: 1.2849 - val_accuracy: 0.4135

Epoch 01284: val_loss did not improve from 1.27470
Epoch 1285/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4205 - val_loss: 1.2806 - val_accuracy: 0.4064

Epoch 01285: val_loss did not improve from 1.27470
Epoch 1286/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4236 - val_loss: 1.2823 - val_accuracy: 0.4120

Epoch 01286: val_loss did not improve from 1.27470
Epoch 1287/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4205 - val_loss: 1.2795 - val_accuracy: 0.4096

Epoch 01287: val_loss did not improve from 1.27470
Epoch 1288/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4160 - val_loss: 1.2797 - val_accuracy: 0.4096

Epoch 01288: val_loss did not improve from 1.27470
Epoch 1289/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4204 - val_loss: 1.2790 - val_accuracy: 0.4104

Epoch 01289: val_loss did not improve from 1.27470
Epoch 1290/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4175 - val_loss: 1.2815 - val_accuracy: 0.4159

Epoch 01290: val_loss did not improve from 1.27470
Epoch 1291/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4201 - val_loss: 1.2777 - val_accuracy: 0.4104

Epoch 01291: val_loss did not improve from 1.27470
Epoch 1292/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4213 - val_loss: 1.2810 - val_accuracy: 0.4151

Epoch 01292: val_loss did not improve from 1.27470
Epoch 1293/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4216 - val_loss: 1.2780 - val_accuracy: 0.4151

Epoch 01293: val_loss did not improve from 1.27470
Epoch 1294/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4211 - val_loss: 1.2841 - val_accuracy: 0.4135

Epoch 01294: val_loss did not improve from 1.27470
Epoch 1295/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4160 - val_loss: 1.2844 - val_accuracy: 0.4088

Epoch 01295: val_loss did not improve from 1.27470
Epoch 1296/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4186 - val_loss: 1.2770 - val_accuracy: 0.4048

Epoch 01296: val_loss did not improve from 1.27470
Epoch 1297/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4163 - val_loss: 1.2815 - val_accuracy: 0.4048

Epoch 01297: val_loss did not improve from 1.27470
Epoch 1298/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4168 - val_loss: 1.2804 - val_accuracy: 0.4223

Epoch 01298: val_loss did not improve from 1.27470
Epoch 1299/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4187 - val_loss: 1.2805 - val_accuracy: 0.4120

Epoch 01299: val_loss did not improve from 1.27470
Epoch 1300/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4147 - val_loss: 1.2781 - val_accuracy: 0.4135

Epoch 01300: val_loss did not improve from 1.27470
Epoch 1301/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4236 - val_loss: 1.2783 - val_accuracy: 0.4183

Epoch 01301: val_loss did not improve from 1.27470
Epoch 1302/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4196 - val_loss: 1.2773 - val_accuracy: 0.4159

Epoch 01302: val_loss did not improve from 1.27470
Epoch 1303/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4193 - val_loss: 1.2788 - val_accuracy: 0.4088

Epoch 01303: val_loss did not improve from 1.27470
Epoch 1304/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4210 - val_loss: 1.2810 - val_accuracy: 0.4088

Epoch 01304: val_loss did not improve from 1.27470
Epoch 1305/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4197 - val_loss: 1.2801 - val_accuracy: 0.4199

Epoch 01305: val_loss did not improve from 1.27470
Epoch 1306/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4159 - val_loss: 1.2854 - val_accuracy: 0.4024

Epoch 01306: val_loss did not improve from 1.27470
Epoch 1307/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4166 - val_loss: 1.2807 - val_accuracy: 0.4120

Epoch 01307: val_loss did not improve from 1.27470
Epoch 1308/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4212 - val_loss: 1.2779 - val_accuracy: 0.4096

Epoch 01308: val_loss did not improve from 1.27470
Epoch 1309/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4129 - val_loss: 1.2780 - val_accuracy: 0.4024

Epoch 01309: val_loss did not improve from 1.27470
Epoch 1310/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4180 - val_loss: 1.2780 - val_accuracy: 0.4112

Epoch 01310: val_loss did not improve from 1.27470
Epoch 1311/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4138 - val_loss: 1.2771 - val_accuracy: 0.4120

Epoch 01311: val_loss did not improve from 1.27470
Epoch 1312/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4211 - val_loss: 1.2773 - val_accuracy: 0.4096

Epoch 01312: val_loss did not improve from 1.27470
Epoch 1313/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4267 - val_loss: 1.2774 - val_accuracy: 0.4215

Epoch 01313: val_loss did not improve from 1.27470
Epoch 1314/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4190 - val_loss: 1.2759 - val_accuracy: 0.4151

Epoch 01314: val_loss did not improve from 1.27470
Epoch 1315/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4208 - val_loss: 1.2785 - val_accuracy: 0.4167

Epoch 01315: val_loss did not improve from 1.27470
Epoch 1316/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4191 - val_loss: 1.2795 - val_accuracy: 0.4207

Epoch 01316: val_loss did not improve from 1.27470
Epoch 1317/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4260 - val_loss: 1.2804 - val_accuracy: 0.4159

Epoch 01317: val_loss did not improve from 1.27470
Epoch 1318/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4213 - val_loss: 1.2789 - val_accuracy: 0.4096

Epoch 01318: val_loss did not improve from 1.27470
Epoch 1319/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4210 - val_loss: 1.2809 - val_accuracy: 0.4239

Epoch 01319: val_loss did not improve from 1.27470
Epoch 1320/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4219 - val_loss: 1.2749 - val_accuracy: 0.4191

Epoch 01320: val_loss did not improve from 1.27470
Epoch 1321/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4222 - val_loss: 1.2859 - val_accuracy: 0.4167

Epoch 01321: val_loss did not improve from 1.27470
Epoch 1322/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4151 - val_loss: 1.2772 - val_accuracy: 0.4143

Epoch 01322: val_loss did not improve from 1.27470
Epoch 1323/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4205 - val_loss: 1.2821 - val_accuracy: 0.4175

Epoch 01323: val_loss did not improve from 1.27470
Epoch 1324/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4200 - val_loss: 1.2808 - val_accuracy: 0.4159

Epoch 01324: val_loss did not improve from 1.27470
Epoch 1325/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4167 - val_loss: 1.2774 - val_accuracy: 0.4151

Epoch 01325: val_loss did not improve from 1.27470
Epoch 1326/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4211 - val_loss: 1.2803 - val_accuracy: 0.4127

Epoch 01326: val_loss did not improve from 1.27470
Epoch 1327/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4185 - val_loss: 1.2837 - val_accuracy: 0.4096

Epoch 01327: val_loss did not improve from 1.27470
Epoch 1328/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4168 - val_loss: 1.2784 - val_accuracy: 0.4143

Epoch 01328: val_loss did not improve from 1.27470
Epoch 1329/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4215 - val_loss: 1.2751 - val_accuracy: 0.4255

Epoch 01329: val_loss did not improve from 1.27470
Epoch 1330/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4231 - val_loss: 1.2750 - val_accuracy: 0.4191

Epoch 01330: val_loss did not improve from 1.27470
Epoch 1331/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4217 - val_loss: 1.2770 - val_accuracy: 0.4215

Epoch 01331: val_loss did not improve from 1.27470
Epoch 1332/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4189 - val_loss: 1.2794 - val_accuracy: 0.4207

Epoch 01332: val_loss did not improve from 1.27470
Epoch 1333/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4203 - val_loss: 1.2835 - val_accuracy: 0.4048

Epoch 01333: val_loss did not improve from 1.27470
Epoch 1334/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4145 - val_loss: 1.2828 - val_accuracy: 0.4135

Epoch 01334: val_loss did not improve from 1.27470
Epoch 1335/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4205 - val_loss: 1.2781 - val_accuracy: 0.4159

Epoch 01335: val_loss did not improve from 1.27470
Epoch 1336/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4200 - val_loss: 1.2758 - val_accuracy: 0.4096

Epoch 01336: val_loss did not improve from 1.27470
Epoch 1337/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4185 - val_loss: 1.2798 - val_accuracy: 0.4231

Epoch 01337: val_loss did not improve from 1.27470
Epoch 1338/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4184 - val_loss: 1.2779 - val_accuracy: 0.4151

Epoch 01338: val_loss did not improve from 1.27470
Epoch 1339/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4213 - val_loss: 1.2804 - val_accuracy: 0.4127

Epoch 01339: val_loss did not improve from 1.27470
Epoch 1340/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4174 - val_loss: 1.2763 - val_accuracy: 0.4135

Epoch 01340: val_loss did not improve from 1.27470
Epoch 1341/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4206 - val_loss: 1.2777 - val_accuracy: 0.4135

Epoch 01341: val_loss did not improve from 1.27470
Epoch 1342/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4216 - val_loss: 1.2809 - val_accuracy: 0.4183

Epoch 01342: val_loss did not improve from 1.27470
Epoch 1343/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4143 - val_loss: 1.2824 - val_accuracy: 0.4112

Epoch 01343: val_loss did not improve from 1.27470
Epoch 1344/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4180 - val_loss: 1.2833 - val_accuracy: 0.4104

Epoch 01344: val_loss did not improve from 1.27470
Epoch 1345/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4174 - val_loss: 1.2810 - val_accuracy: 0.4096

Epoch 01345: val_loss did not improve from 1.27470
Epoch 1346/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4160 - val_loss: 1.2832 - val_accuracy: 0.4143

Epoch 01346: val_loss did not improve from 1.27470
Epoch 1347/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4179 - val_loss: 1.2839 - val_accuracy: 0.4104

Epoch 01347: val_loss did not improve from 1.27470
Epoch 1348/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4188 - val_loss: 1.2792 - val_accuracy: 0.4120

Epoch 01348: val_loss did not improve from 1.27470
Epoch 1349/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4217 - val_loss: 1.2869 - val_accuracy: 0.4088

Epoch 01349: val_loss did not improve from 1.27470
Epoch 1350/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4223 - val_loss: 1.2806 - val_accuracy: 0.4135

Epoch 01350: val_loss did not improve from 1.27470
Epoch 1351/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4185 - val_loss: 1.2789 - val_accuracy: 0.4135

Epoch 01351: val_loss did not improve from 1.27470
Epoch 1352/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4201 - val_loss: 1.2792 - val_accuracy: 0.4191

Epoch 01352: val_loss did not improve from 1.27470
Epoch 1353/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4196 - val_loss: 1.2769 - val_accuracy: 0.4159

Epoch 01353: val_loss did not improve from 1.27470
Epoch 1354/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4162 - val_loss: 1.2768 - val_accuracy: 0.4143

Epoch 01354: val_loss did not improve from 1.27470
Epoch 1355/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4245 - val_loss: 1.2767 - val_accuracy: 0.4199

Epoch 01355: val_loss did not improve from 1.27470
Epoch 1356/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4179 - val_loss: 1.2783 - val_accuracy: 0.4135

Epoch 01356: val_loss did not improve from 1.27470
Epoch 1357/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4190 - val_loss: 1.2814 - val_accuracy: 0.4231

Epoch 01357: val_loss did not improve from 1.27470
Epoch 1358/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4218 - val_loss: 1.2762 - val_accuracy: 0.4191

Epoch 01358: val_loss did not improve from 1.27470
Epoch 1359/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4229 - val_loss: 1.2758 - val_accuracy: 0.4159

Epoch 01359: val_loss did not improve from 1.27470
Epoch 1360/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4228 - val_loss: 1.2749 - val_accuracy: 0.4215

Epoch 01360: val_loss did not improve from 1.27470
Epoch 1361/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4188 - val_loss: 1.2751 - val_accuracy: 0.4183

Epoch 01361: val_loss did not improve from 1.27470
Epoch 1362/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4173 - val_loss: 1.2762 - val_accuracy: 0.4191

Epoch 01362: val_loss did not improve from 1.27470
Epoch 1363/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4154 - val_loss: 1.2799 - val_accuracy: 0.4127

Epoch 01363: val_loss did not improve from 1.27470
Epoch 1364/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4176 - val_loss: 1.2774 - val_accuracy: 0.4255

Epoch 01364: val_loss did not improve from 1.27470
Epoch 1365/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4190 - val_loss: 1.2786 - val_accuracy: 0.4127

Epoch 01365: val_loss did not improve from 1.27470
Epoch 1366/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4165 - val_loss: 1.2868 - val_accuracy: 0.4127

Epoch 01366: val_loss did not improve from 1.27470
Epoch 1367/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4186 - val_loss: 1.2765 - val_accuracy: 0.4191

Epoch 01367: val_loss did not improve from 1.27470
Epoch 1368/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4209 - val_loss: 1.2781 - val_accuracy: 0.4207

Epoch 01368: val_loss did not improve from 1.27470
Epoch 1369/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4209 - val_loss: 1.2790 - val_accuracy: 0.4295

Epoch 01369: val_loss did not improve from 1.27470
Epoch 1370/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4214 - val_loss: 1.2783 - val_accuracy: 0.4175

Epoch 01370: val_loss did not improve from 1.27470
Epoch 1371/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4180 - val_loss: 1.2784 - val_accuracy: 0.4207

Epoch 01371: val_loss did not improve from 1.27470
Epoch 1372/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4178 - val_loss: 1.2798 - val_accuracy: 0.4167

Epoch 01372: val_loss did not improve from 1.27470
Epoch 1373/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4207 - val_loss: 1.2796 - val_accuracy: 0.4239

Epoch 01373: val_loss did not improve from 1.27470
Epoch 1374/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4207 - val_loss: 1.2788 - val_accuracy: 0.4151

Epoch 01374: val_loss did not improve from 1.27470
Epoch 1375/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4229 - val_loss: 1.2763 - val_accuracy: 0.4183

Epoch 01375: val_loss did not improve from 1.27470
Epoch 1376/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4216 - val_loss: 1.2794 - val_accuracy: 0.4080

Epoch 01376: val_loss did not improve from 1.27470
Epoch 1377/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4181 - val_loss: 1.2805 - val_accuracy: 0.4215

Epoch 01377: val_loss did not improve from 1.27470
Epoch 1378/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4182 - val_loss: 1.2800 - val_accuracy: 0.4223

Epoch 01378: val_loss did not improve from 1.27470
Epoch 1379/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4190 - val_loss: 1.2808 - val_accuracy: 0.4135

Epoch 01379: val_loss did not improve from 1.27470
Epoch 1380/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4182 - val_loss: 1.2770 - val_accuracy: 0.4120

Epoch 01380: val_loss did not improve from 1.27470
Epoch 1381/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4234 - val_loss: 1.2819 - val_accuracy: 0.4159

Epoch 01381: val_loss did not improve from 1.27470
Epoch 1382/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4208 - val_loss: 1.2782 - val_accuracy: 0.4167

Epoch 01382: val_loss did not improve from 1.27470
Epoch 1383/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4226 - val_loss: 1.2759 - val_accuracy: 0.4183

Epoch 01383: val_loss did not improve from 1.27470
Epoch 1384/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4174 - val_loss: 1.2756 - val_accuracy: 0.4191

Epoch 01384: val_loss did not improve from 1.27470
Epoch 1385/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4241 - val_loss: 1.2760 - val_accuracy: 0.4287

Epoch 01385: val_loss did not improve from 1.27470
Epoch 1386/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4190 - val_loss: 1.2770 - val_accuracy: 0.4159

Epoch 01386: val_loss did not improve from 1.27470
Epoch 1387/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4170 - val_loss: 1.2760 - val_accuracy: 0.4183

Epoch 01387: val_loss did not improve from 1.27470
Epoch 1388/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4171 - val_loss: 1.2763 - val_accuracy: 0.4167

Epoch 01388: val_loss did not improve from 1.27470
Epoch 1389/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4209 - val_loss: 1.2772 - val_accuracy: 0.4223

Epoch 01389: val_loss did not improve from 1.27470
Epoch 1390/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4200 - val_loss: 1.2744 - val_accuracy: 0.4159

Epoch 01390: val_loss improved from 1.27470 to 1.27439, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1391/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4263 - val_loss: 1.2759 - val_accuracy: 0.4151

Epoch 01391: val_loss did not improve from 1.27439
Epoch 1392/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4236 - val_loss: 1.2815 - val_accuracy: 0.4127

Epoch 01392: val_loss did not improve from 1.27439
Epoch 1393/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4194 - val_loss: 1.2771 - val_accuracy: 0.4335

Epoch 01393: val_loss did not improve from 1.27439
Epoch 1394/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4247 - val_loss: 1.2747 - val_accuracy: 0.4072

Epoch 01394: val_loss did not improve from 1.27439
Epoch 1395/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4266 - val_loss: 1.2752 - val_accuracy: 0.4191

Epoch 01395: val_loss did not improve from 1.27439
Epoch 1396/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4229 - val_loss: 1.2812 - val_accuracy: 0.4127

Epoch 01396: val_loss did not improve from 1.27439
Epoch 1397/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4210 - val_loss: 1.2804 - val_accuracy: 0.4112

Epoch 01397: val_loss did not improve from 1.27439
Epoch 1398/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4161 - val_loss: 1.2782 - val_accuracy: 0.4175

Epoch 01398: val_loss did not improve from 1.27439
Epoch 1399/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4195 - val_loss: 1.2751 - val_accuracy: 0.4215

Epoch 01399: val_loss did not improve from 1.27439
Epoch 1400/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4241 - val_loss: 1.2747 - val_accuracy: 0.4247

Epoch 01400: val_loss did not improve from 1.27439
Epoch 1401/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4275 - val_loss: 1.2756 - val_accuracy: 0.4287

Epoch 01401: val_loss did not improve from 1.27439
Epoch 1402/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4252 - val_loss: 1.2795 - val_accuracy: 0.4096

Epoch 01402: val_loss did not improve from 1.27439
Epoch 1403/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4209 - val_loss: 1.2786 - val_accuracy: 0.4175

Epoch 01403: val_loss did not improve from 1.27439
Epoch 1404/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4221 - val_loss: 1.2784 - val_accuracy: 0.4096

Epoch 01404: val_loss did not improve from 1.27439
Epoch 1405/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4182 - val_loss: 1.2772 - val_accuracy: 0.4088

Epoch 01405: val_loss did not improve from 1.27439
Epoch 1406/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4219 - val_loss: 1.2799 - val_accuracy: 0.4167

Epoch 01406: val_loss did not improve from 1.27439
Epoch 1407/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4205 - val_loss: 1.2768 - val_accuracy: 0.4263

Epoch 01407: val_loss did not improve from 1.27439
Epoch 1408/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4229 - val_loss: 1.2782 - val_accuracy: 0.4255

Epoch 01408: val_loss did not improve from 1.27439
Epoch 1409/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4185 - val_loss: 1.2769 - val_accuracy: 0.4143

Epoch 01409: val_loss did not improve from 1.27439
Epoch 1410/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4242 - val_loss: 1.2765 - val_accuracy: 0.4175

Epoch 01410: val_loss did not improve from 1.27439
Epoch 1411/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4228 - val_loss: 1.2789 - val_accuracy: 0.4183

Epoch 01411: val_loss did not improve from 1.27439
Epoch 1412/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4243 - val_loss: 1.2770 - val_accuracy: 0.4191

Epoch 01412: val_loss did not improve from 1.27439
Epoch 1413/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4198 - val_loss: 1.2802 - val_accuracy: 0.4072

Epoch 01413: val_loss did not improve from 1.27439
Epoch 1414/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4175 - val_loss: 1.2814 - val_accuracy: 0.4096

Epoch 01414: val_loss did not improve from 1.27439
Epoch 1415/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4217 - val_loss: 1.2798 - val_accuracy: 0.4135

Epoch 01415: val_loss did not improve from 1.27439
Epoch 1416/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4177 - val_loss: 1.2783 - val_accuracy: 0.4175

Epoch 01416: val_loss did not improve from 1.27439
Epoch 1417/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4224 - val_loss: 1.2761 - val_accuracy: 0.4207

Epoch 01417: val_loss did not improve from 1.27439
Epoch 1418/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4214 - val_loss: 1.2809 - val_accuracy: 0.4088

Epoch 01418: val_loss did not improve from 1.27439
Epoch 1419/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4239 - val_loss: 1.2799 - val_accuracy: 0.4223

Epoch 01419: val_loss did not improve from 1.27439
Epoch 1420/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4221 - val_loss: 1.2776 - val_accuracy: 0.4191

Epoch 01420: val_loss did not improve from 1.27439
Epoch 1421/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4219 - val_loss: 1.2732 - val_accuracy: 0.4279

Epoch 01421: val_loss improved from 1.27439 to 1.27317, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1422/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4189 - val_loss: 1.2745 - val_accuracy: 0.4159

Epoch 01422: val_loss did not improve from 1.27317
Epoch 1423/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4188 - val_loss: 1.2752 - val_accuracy: 0.4279

Epoch 01423: val_loss did not improve from 1.27317
Epoch 1424/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4223 - val_loss: 1.2755 - val_accuracy: 0.4183

Epoch 01424: val_loss did not improve from 1.27317
Epoch 1425/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4230 - val_loss: 1.2762 - val_accuracy: 0.4207

Epoch 01425: val_loss did not improve from 1.27317
Epoch 1426/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4225 - val_loss: 1.2786 - val_accuracy: 0.4199

Epoch 01426: val_loss did not improve from 1.27317
Epoch 1427/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4244 - val_loss: 1.2868 - val_accuracy: 0.4167

Epoch 01427: val_loss did not improve from 1.27317
Epoch 1428/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4187 - val_loss: 1.2780 - val_accuracy: 0.4072

Epoch 01428: val_loss did not improve from 1.27317
Epoch 1429/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4251 - val_loss: 1.2746 - val_accuracy: 0.4167

Epoch 01429: val_loss did not improve from 1.27317
Epoch 1430/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4252 - val_loss: 1.2783 - val_accuracy: 0.4223

Epoch 01430: val_loss did not improve from 1.27317
Epoch 1431/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4219 - val_loss: 1.2796 - val_accuracy: 0.4207

Epoch 01431: val_loss did not improve from 1.27317
Epoch 1432/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4209 - val_loss: 1.2756 - val_accuracy: 0.4199

Epoch 01432: val_loss did not improve from 1.27317
Epoch 1433/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4245 - val_loss: 1.2758 - val_accuracy: 0.4247

Epoch 01433: val_loss did not improve from 1.27317
Epoch 1434/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4236 - val_loss: 1.2777 - val_accuracy: 0.4231

Epoch 01434: val_loss did not improve from 1.27317
Epoch 1435/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4241 - val_loss: 1.2807 - val_accuracy: 0.4175

Epoch 01435: val_loss did not improve from 1.27317
Epoch 1436/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4215 - val_loss: 1.2751 - val_accuracy: 0.4191

Epoch 01436: val_loss did not improve from 1.27317
Epoch 1437/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4282 - val_loss: 1.2765 - val_accuracy: 0.4199

Epoch 01437: val_loss did not improve from 1.27317
Epoch 1438/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4216 - val_loss: 1.2760 - val_accuracy: 0.4143

Epoch 01438: val_loss did not improve from 1.27317
Epoch 1439/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4234 - val_loss: 1.2757 - val_accuracy: 0.4183

Epoch 01439: val_loss did not improve from 1.27317
Epoch 1440/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4253 - val_loss: 1.2751 - val_accuracy: 0.4199

Epoch 01440: val_loss did not improve from 1.27317
Epoch 1441/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4177 - val_loss: 1.2799 - val_accuracy: 0.4072

Epoch 01441: val_loss did not improve from 1.27317
Epoch 1442/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4163 - val_loss: 1.2746 - val_accuracy: 0.4311

Epoch 01442: val_loss did not improve from 1.27317
Epoch 1443/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4221 - val_loss: 1.2764 - val_accuracy: 0.4303

Epoch 01443: val_loss did not improve from 1.27317
Epoch 1444/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4217 - val_loss: 1.2788 - val_accuracy: 0.4135

Epoch 01444: val_loss did not improve from 1.27317
Epoch 1445/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4246 - val_loss: 1.2762 - val_accuracy: 0.4239

Epoch 01445: val_loss did not improve from 1.27317
Epoch 1446/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4187 - val_loss: 1.2783 - val_accuracy: 0.4159

Epoch 01446: val_loss did not improve from 1.27317
Epoch 1447/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4202 - val_loss: 1.2774 - val_accuracy: 0.4223

Epoch 01447: val_loss did not improve from 1.27317
Epoch 1448/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4221 - val_loss: 1.2756 - val_accuracy: 0.4223

Epoch 01448: val_loss did not improve from 1.27317
Epoch 1449/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4224 - val_loss: 1.2796 - val_accuracy: 0.4072

Epoch 01449: val_loss did not improve from 1.27317
Epoch 1450/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4210 - val_loss: 1.2792 - val_accuracy: 0.4064

Epoch 01450: val_loss did not improve from 1.27317
Epoch 1451/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4205 - val_loss: 1.2872 - val_accuracy: 0.4215

Epoch 01451: val_loss did not improve from 1.27317
Epoch 1452/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4205 - val_loss: 1.2830 - val_accuracy: 0.4048

Epoch 01452: val_loss did not improve from 1.27317
Epoch 1453/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4260 - val_loss: 1.2802 - val_accuracy: 0.4151

Epoch 01453: val_loss did not improve from 1.27317
Epoch 1454/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4232 - val_loss: 1.2808 - val_accuracy: 0.4183

Epoch 01454: val_loss did not improve from 1.27317
Epoch 1455/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4216 - val_loss: 1.2787 - val_accuracy: 0.4104

Epoch 01455: val_loss did not improve from 1.27317
Epoch 1456/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4227 - val_loss: 1.2804 - val_accuracy: 0.4223

Epoch 01456: val_loss did not improve from 1.27317
Epoch 1457/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4235 - val_loss: 1.2811 - val_accuracy: 0.4127

Epoch 01457: val_loss did not improve from 1.27317
Epoch 1458/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4231 - val_loss: 1.2786 - val_accuracy: 0.4175

Epoch 01458: val_loss did not improve from 1.27317
Epoch 1459/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4196 - val_loss: 1.2799 - val_accuracy: 0.4191

Epoch 01459: val_loss did not improve from 1.27317
Epoch 1460/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4236 - val_loss: 1.2787 - val_accuracy: 0.4183

Epoch 01460: val_loss did not improve from 1.27317
Epoch 1461/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4217 - val_loss: 1.2763 - val_accuracy: 0.4207

Epoch 01461: val_loss did not improve from 1.27317
Epoch 1462/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4255 - val_loss: 1.2762 - val_accuracy: 0.4207

Epoch 01462: val_loss did not improve from 1.27317
Epoch 1463/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4207 - val_loss: 1.2767 - val_accuracy: 0.4223

Epoch 01463: val_loss did not improve from 1.27317
Epoch 1464/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4199 - val_loss: 1.2786 - val_accuracy: 0.4151

Epoch 01464: val_loss did not improve from 1.27317
Epoch 1465/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4172 - val_loss: 1.2750 - val_accuracy: 0.4199

Epoch 01465: val_loss did not improve from 1.27317
Epoch 1466/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4262 - val_loss: 1.2775 - val_accuracy: 0.4239

Epoch 01466: val_loss did not improve from 1.27317
Epoch 1467/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4212 - val_loss: 1.2746 - val_accuracy: 0.4199

Epoch 01467: val_loss did not improve from 1.27317
Epoch 1468/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4225 - val_loss: 1.2777 - val_accuracy: 0.4191

Epoch 01468: val_loss did not improve from 1.27317
Epoch 1469/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4267 - val_loss: 1.2792 - val_accuracy: 0.4175

Epoch 01469: val_loss did not improve from 1.27317
Epoch 1470/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4258 - val_loss: 1.2770 - val_accuracy: 0.4255

Epoch 01470: val_loss did not improve from 1.27317
Epoch 1471/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4231 - val_loss: 1.2749 - val_accuracy: 0.4255

Epoch 01471: val_loss did not improve from 1.27317
Epoch 1472/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4252 - val_loss: 1.2823 - val_accuracy: 0.4159

Epoch 01472: val_loss did not improve from 1.27317
Epoch 1473/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4266 - val_loss: 1.2804 - val_accuracy: 0.4183

Epoch 01473: val_loss did not improve from 1.27317
Epoch 1474/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4234 - val_loss: 1.2755 - val_accuracy: 0.4247

Epoch 01474: val_loss did not improve from 1.27317
Epoch 1475/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4229 - val_loss: 1.2801 - val_accuracy: 0.4215

Epoch 01475: val_loss did not improve from 1.27317
Epoch 1476/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4206 - val_loss: 1.2799 - val_accuracy: 0.4263

Epoch 01476: val_loss did not improve from 1.27317
Epoch 1477/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4265 - val_loss: 1.2728 - val_accuracy: 0.4191

Epoch 01477: val_loss improved from 1.27317 to 1.27279, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1478/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4206 - val_loss: 1.2768 - val_accuracy: 0.4183

Epoch 01478: val_loss did not improve from 1.27279
Epoch 1479/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4200 - val_loss: 1.2752 - val_accuracy: 0.4175

Epoch 01479: val_loss did not improve from 1.27279
Epoch 1480/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4252 - val_loss: 1.2848 - val_accuracy: 0.4088

Epoch 01480: val_loss did not improve from 1.27279
Epoch 1481/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4228 - val_loss: 1.2834 - val_accuracy: 0.4120

Epoch 01481: val_loss did not improve from 1.27279
Epoch 1482/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4170 - val_loss: 1.2796 - val_accuracy: 0.4183

Epoch 01482: val_loss did not improve from 1.27279
Epoch 1483/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4191 - val_loss: 1.2811 - val_accuracy: 0.4159

Epoch 01483: val_loss did not improve from 1.27279
Epoch 1484/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4204 - val_loss: 1.2877 - val_accuracy: 0.4072

Epoch 01484: val_loss did not improve from 1.27279
Epoch 1485/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4203 - val_loss: 1.2778 - val_accuracy: 0.4191

Epoch 01485: val_loss did not improve from 1.27279
Epoch 1486/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4246 - val_loss: 1.2771 - val_accuracy: 0.4279

Epoch 01486: val_loss did not improve from 1.27279
Epoch 1487/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4203 - val_loss: 1.2787 - val_accuracy: 0.4135

Epoch 01487: val_loss did not improve from 1.27279
Epoch 1488/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4237 - val_loss: 1.2783 - val_accuracy: 0.4127

Epoch 01488: val_loss did not improve from 1.27279
Epoch 1489/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4212 - val_loss: 1.2769 - val_accuracy: 0.4127

Epoch 01489: val_loss did not improve from 1.27279
Epoch 1490/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4231 - val_loss: 1.2785 - val_accuracy: 0.4239

Epoch 01490: val_loss did not improve from 1.27279
Epoch 1491/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4259 - val_loss: 1.2777 - val_accuracy: 0.4215

Epoch 01491: val_loss did not improve from 1.27279
Epoch 1492/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4267 - val_loss: 1.2753 - val_accuracy: 0.4271

Epoch 01492: val_loss did not improve from 1.27279
Epoch 1493/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4238 - val_loss: 1.2786 - val_accuracy: 0.4215

Epoch 01493: val_loss did not improve from 1.27279
Epoch 1494/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4257 - val_loss: 1.2768 - val_accuracy: 0.4175

Epoch 01494: val_loss did not improve from 1.27279
Epoch 1495/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4240 - val_loss: 1.2795 - val_accuracy: 0.4167

Epoch 01495: val_loss did not improve from 1.27279
Epoch 1496/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4251 - val_loss: 1.2756 - val_accuracy: 0.4183

Epoch 01496: val_loss did not improve from 1.27279
Epoch 1497/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4197 - val_loss: 1.2753 - val_accuracy: 0.4231

Epoch 01497: val_loss did not improve from 1.27279
Epoch 1498/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4229 - val_loss: 1.2803 - val_accuracy: 0.4215

Epoch 01498: val_loss did not improve from 1.27279
Epoch 1499/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4234 - val_loss: 1.2820 - val_accuracy: 0.4143

Epoch 01499: val_loss did not improve from 1.27279
Epoch 1500/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4214 - val_loss: 1.2758 - val_accuracy: 0.4279

Epoch 01500: val_loss did not improve from 1.27279
Epoch 1501/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4283 - val_loss: 1.2776 - val_accuracy: 0.4215

Epoch 01501: val_loss did not improve from 1.27279
Epoch 1502/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4215 - val_loss: 1.2773 - val_accuracy: 0.4223

Epoch 01502: val_loss did not improve from 1.27279
Epoch 1503/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4175 - val_loss: 1.2838 - val_accuracy: 0.4143

Epoch 01503: val_loss did not improve from 1.27279
Epoch 1504/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4208 - val_loss: 1.2778 - val_accuracy: 0.4135

Epoch 01504: val_loss did not improve from 1.27279
Epoch 1505/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4213 - val_loss: 1.2781 - val_accuracy: 0.4215

Epoch 01505: val_loss did not improve from 1.27279
Epoch 1506/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4259 - val_loss: 1.2750 - val_accuracy: 0.4247

Epoch 01506: val_loss did not improve from 1.27279
Epoch 1507/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4255 - val_loss: 1.2790 - val_accuracy: 0.4143

Epoch 01507: val_loss did not improve from 1.27279
Epoch 1508/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4275 - val_loss: 1.2772 - val_accuracy: 0.4223

Epoch 01508: val_loss did not improve from 1.27279
Epoch 1509/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4242 - val_loss: 1.2755 - val_accuracy: 0.4247

Epoch 01509: val_loss did not improve from 1.27279
Epoch 1510/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4235 - val_loss: 1.2748 - val_accuracy: 0.4207

Epoch 01510: val_loss did not improve from 1.27279
Epoch 1511/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4244 - val_loss: 1.2763 - val_accuracy: 0.4191

Epoch 01511: val_loss did not improve from 1.27279
Epoch 1512/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4306 - val_loss: 1.2766 - val_accuracy: 0.4183

Epoch 01512: val_loss did not improve from 1.27279
Epoch 1513/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4263 - val_loss: 1.2765 - val_accuracy: 0.4295

Epoch 01513: val_loss did not improve from 1.27279
Epoch 1514/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4259 - val_loss: 1.2758 - val_accuracy: 0.4183

Epoch 01514: val_loss did not improve from 1.27279
Epoch 1515/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4241 - val_loss: 1.2774 - val_accuracy: 0.4327

Epoch 01515: val_loss did not improve from 1.27279
Epoch 1516/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4256 - val_loss: 1.2811 - val_accuracy: 0.4135

Epoch 01516: val_loss did not improve from 1.27279
Epoch 1517/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4222 - val_loss: 1.2775 - val_accuracy: 0.4199

Epoch 01517: val_loss did not improve from 1.27279
Epoch 1518/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4231 - val_loss: 1.2771 - val_accuracy: 0.4351

Epoch 01518: val_loss did not improve from 1.27279
Epoch 1519/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4310 - val_loss: 1.2758 - val_accuracy: 0.4319

Epoch 01519: val_loss did not improve from 1.27279
Epoch 1520/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4206 - val_loss: 1.2787 - val_accuracy: 0.4247

Epoch 01520: val_loss did not improve from 1.27279
Epoch 1521/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4217 - val_loss: 1.2771 - val_accuracy: 0.4271

Epoch 01521: val_loss did not improve from 1.27279
Epoch 1522/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4205 - val_loss: 1.2770 - val_accuracy: 0.4231

Epoch 01522: val_loss did not improve from 1.27279
Epoch 1523/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4252 - val_loss: 1.2800 - val_accuracy: 0.4223

Epoch 01523: val_loss did not improve from 1.27279
Epoch 1524/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4197 - val_loss: 1.2784 - val_accuracy: 0.4263

Epoch 01524: val_loss did not improve from 1.27279
Epoch 1525/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4218 - val_loss: 1.2758 - val_accuracy: 0.4351

Epoch 01525: val_loss did not improve from 1.27279
Epoch 1526/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4208 - val_loss: 1.2748 - val_accuracy: 0.4319

Epoch 01526: val_loss did not improve from 1.27279
Epoch 1527/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4261 - val_loss: 1.2786 - val_accuracy: 0.4183

Epoch 01527: val_loss did not improve from 1.27279
Epoch 1528/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4242 - val_loss: 1.2760 - val_accuracy: 0.4191

Epoch 01528: val_loss did not improve from 1.27279
Epoch 1529/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4191 - val_loss: 1.2740 - val_accuracy: 0.4223

Epoch 01529: val_loss did not improve from 1.27279
Epoch 1530/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4170 - val_loss: 1.2860 - val_accuracy: 0.4247

Epoch 01530: val_loss did not improve from 1.27279
Epoch 1531/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4230 - val_loss: 1.2814 - val_accuracy: 0.4215

Epoch 01531: val_loss did not improve from 1.27279
Epoch 1532/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4205 - val_loss: 1.2757 - val_accuracy: 0.4255

Epoch 01532: val_loss did not improve from 1.27279
Epoch 1533/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4245 - val_loss: 1.2744 - val_accuracy: 0.4199

Epoch 01533: val_loss did not improve from 1.27279
Epoch 1534/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4249 - val_loss: 1.2776 - val_accuracy: 0.4167

Epoch 01534: val_loss did not improve from 1.27279
Epoch 1535/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4209 - val_loss: 1.2769 - val_accuracy: 0.4279

Epoch 01535: val_loss did not improve from 1.27279
Epoch 1536/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4258 - val_loss: 1.2764 - val_accuracy: 0.4287

Epoch 01536: val_loss did not improve from 1.27279
Epoch 1537/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4229 - val_loss: 1.2783 - val_accuracy: 0.4183

Epoch 01537: val_loss did not improve from 1.27279
Epoch 1538/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4235 - val_loss: 1.2755 - val_accuracy: 0.4159

Epoch 01538: val_loss did not improve from 1.27279
Epoch 1539/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4255 - val_loss: 1.2777 - val_accuracy: 0.4151

Epoch 01539: val_loss did not improve from 1.27279
Epoch 1540/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4234 - val_loss: 1.2811 - val_accuracy: 0.4135

Epoch 01540: val_loss did not improve from 1.27279
Epoch 1541/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4241 - val_loss: 1.2760 - val_accuracy: 0.4279

Epoch 01541: val_loss did not improve from 1.27279
Epoch 1542/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4215 - val_loss: 1.2790 - val_accuracy: 0.4319

Epoch 01542: val_loss did not improve from 1.27279
Epoch 1543/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4245 - val_loss: 1.2798 - val_accuracy: 0.4120

Epoch 01543: val_loss did not improve from 1.27279
Epoch 1544/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4236 - val_loss: 1.2750 - val_accuracy: 0.4271

Epoch 01544: val_loss did not improve from 1.27279
Epoch 1545/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4257 - val_loss: 1.2734 - val_accuracy: 0.4343

Epoch 01545: val_loss did not improve from 1.27279
Epoch 1546/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4210 - val_loss: 1.2767 - val_accuracy: 0.4207

Epoch 01546: val_loss did not improve from 1.27279
Epoch 1547/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4223 - val_loss: 1.2762 - val_accuracy: 0.4183

Epoch 01547: val_loss did not improve from 1.27279
Epoch 1548/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4235 - val_loss: 1.2739 - val_accuracy: 0.4271

Epoch 01548: val_loss did not improve from 1.27279
Epoch 1549/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4238 - val_loss: 1.2775 - val_accuracy: 0.4303

Epoch 01549: val_loss did not improve from 1.27279
Epoch 1550/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4249 - val_loss: 1.2755 - val_accuracy: 0.4175

Epoch 01550: val_loss did not improve from 1.27279
Epoch 1551/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4204 - val_loss: 1.2743 - val_accuracy: 0.4223

Epoch 01551: val_loss did not improve from 1.27279
Epoch 1552/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4252 - val_loss: 1.2766 - val_accuracy: 0.4143

Epoch 01552: val_loss did not improve from 1.27279
Epoch 1553/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4273 - val_loss: 1.2757 - val_accuracy: 0.4231

Epoch 01553: val_loss did not improve from 1.27279
Epoch 1554/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4234 - val_loss: 1.2757 - val_accuracy: 0.4175

Epoch 01554: val_loss did not improve from 1.27279
Epoch 1555/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4244 - val_loss: 1.2765 - val_accuracy: 0.4215

Epoch 01555: val_loss did not improve from 1.27279
Epoch 1556/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4237 - val_loss: 1.2798 - val_accuracy: 0.4327

Epoch 01556: val_loss did not improve from 1.27279
Epoch 1557/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4252 - val_loss: 1.2781 - val_accuracy: 0.4191

Epoch 01557: val_loss did not improve from 1.27279
Epoch 1558/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4233 - val_loss: 1.2847 - val_accuracy: 0.4096

Epoch 01558: val_loss did not improve from 1.27279
Epoch 1559/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4229 - val_loss: 1.2816 - val_accuracy: 0.4088

Epoch 01559: val_loss did not improve from 1.27279
Epoch 1560/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4202 - val_loss: 1.2906 - val_accuracy: 0.4183

Epoch 01560: val_loss did not improve from 1.27279
Epoch 1561/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4223 - val_loss: 1.2797 - val_accuracy: 0.4191

Epoch 01561: val_loss did not improve from 1.27279
Epoch 1562/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4250 - val_loss: 1.2787 - val_accuracy: 0.4303

Epoch 01562: val_loss did not improve from 1.27279
Epoch 1563/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4234 - val_loss: 1.2850 - val_accuracy: 0.4199

Epoch 01563: val_loss did not improve from 1.27279
Epoch 1564/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4239 - val_loss: 1.2786 - val_accuracy: 0.4215

Epoch 01564: val_loss did not improve from 1.27279
Epoch 1565/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4260 - val_loss: 1.2758 - val_accuracy: 0.4271

Epoch 01565: val_loss did not improve from 1.27279
Epoch 1566/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4267 - val_loss: 1.2751 - val_accuracy: 0.4207

Epoch 01566: val_loss did not improve from 1.27279
Epoch 1567/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4238 - val_loss: 1.2779 - val_accuracy: 0.4279

Epoch 01567: val_loss did not improve from 1.27279
Epoch 1568/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4267 - val_loss: 1.2778 - val_accuracy: 0.4239

Epoch 01568: val_loss did not improve from 1.27279
Epoch 1569/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4234 - val_loss: 1.2759 - val_accuracy: 0.4239

Epoch 01569: val_loss did not improve from 1.27279
Epoch 1570/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4235 - val_loss: 1.2748 - val_accuracy: 0.4223

Epoch 01570: val_loss did not improve from 1.27279
Epoch 1571/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4283 - val_loss: 1.2771 - val_accuracy: 0.4223

Epoch 01571: val_loss did not improve from 1.27279
Epoch 1572/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4201 - val_loss: 1.2753 - val_accuracy: 0.4199

Epoch 01572: val_loss did not improve from 1.27279
Epoch 1573/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4246 - val_loss: 1.2747 - val_accuracy: 0.4231

Epoch 01573: val_loss did not improve from 1.27279
Epoch 1574/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4258 - val_loss: 1.2778 - val_accuracy: 0.4223

Epoch 01574: val_loss did not improve from 1.27279
Epoch 1575/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4238 - val_loss: 1.2781 - val_accuracy: 0.4151

Epoch 01575: val_loss did not improve from 1.27279
Epoch 1576/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4233 - val_loss: 1.2771 - val_accuracy: 0.4199

Epoch 01576: val_loss did not improve from 1.27279
Epoch 1577/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4277 - val_loss: 1.2776 - val_accuracy: 0.4271

Epoch 01577: val_loss did not improve from 1.27279
Epoch 1578/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4205 - val_loss: 1.2845 - val_accuracy: 0.4167

Epoch 01578: val_loss did not improve from 1.27279
Epoch 1579/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4224 - val_loss: 1.2810 - val_accuracy: 0.4135

Epoch 01579: val_loss did not improve from 1.27279
Epoch 1580/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4214 - val_loss: 1.2793 - val_accuracy: 0.4271

Epoch 01580: val_loss did not improve from 1.27279
Epoch 1581/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4260 - val_loss: 1.2763 - val_accuracy: 0.4287

Epoch 01581: val_loss did not improve from 1.27279
Epoch 1582/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4223 - val_loss: 1.2781 - val_accuracy: 0.4120

Epoch 01582: val_loss did not improve from 1.27279
Epoch 1583/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4206 - val_loss: 1.2759 - val_accuracy: 0.4175

Epoch 01583: val_loss did not improve from 1.27279
Epoch 1584/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4264 - val_loss: 1.2789 - val_accuracy: 0.4183

Epoch 01584: val_loss did not improve from 1.27279
Epoch 1585/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4179 - val_loss: 1.2742 - val_accuracy: 0.4271

Epoch 01585: val_loss did not improve from 1.27279
Epoch 1586/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4209 - val_loss: 1.2778 - val_accuracy: 0.4199

Epoch 01586: val_loss did not improve from 1.27279
Epoch 1587/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4236 - val_loss: 1.2766 - val_accuracy: 0.4199

Epoch 01587: val_loss did not improve from 1.27279
Epoch 1588/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4271 - val_loss: 1.2766 - val_accuracy: 0.4135

Epoch 01588: val_loss did not improve from 1.27279
Epoch 1589/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4251 - val_loss: 1.2749 - val_accuracy: 0.4311

Epoch 01589: val_loss did not improve from 1.27279
Epoch 1590/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4238 - val_loss: 1.2738 - val_accuracy: 0.4231

Epoch 01590: val_loss did not improve from 1.27279
Epoch 1591/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4301 - val_loss: 1.2847 - val_accuracy: 0.4112

Epoch 01591: val_loss did not improve from 1.27279
Epoch 1592/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4221 - val_loss: 1.2816 - val_accuracy: 0.4167

Epoch 01592: val_loss did not improve from 1.27279
Epoch 1593/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4251 - val_loss: 1.2754 - val_accuracy: 0.4295

Epoch 01593: val_loss did not improve from 1.27279
Epoch 1594/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4201 - val_loss: 1.2742 - val_accuracy: 0.4327

Epoch 01594: val_loss did not improve from 1.27279
Epoch 1595/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4267 - val_loss: 1.2792 - val_accuracy: 0.4287

Epoch 01595: val_loss did not improve from 1.27279
Epoch 1596/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4222 - val_loss: 1.2752 - val_accuracy: 0.4239

Epoch 01596: val_loss did not improve from 1.27279
Epoch 1597/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4259 - val_loss: 1.2735 - val_accuracy: 0.4279

Epoch 01597: val_loss did not improve from 1.27279
Epoch 1598/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4199 - val_loss: 1.2800 - val_accuracy: 0.4143

Epoch 01598: val_loss did not improve from 1.27279
Epoch 1599/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4225 - val_loss: 1.2760 - val_accuracy: 0.4159

Epoch 01599: val_loss did not improve from 1.27279
Epoch 1600/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4221 - val_loss: 1.2727 - val_accuracy: 0.4367

Epoch 01600: val_loss improved from 1.27279 to 1.27268, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1601/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4218 - val_loss: 1.2754 - val_accuracy: 0.4335

Epoch 01601: val_loss did not improve from 1.27268
Epoch 1602/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4314 - val_loss: 1.2756 - val_accuracy: 0.4311

Epoch 01602: val_loss did not improve from 1.27268
Epoch 1603/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4222 - val_loss: 1.2741 - val_accuracy: 0.4303

Epoch 01603: val_loss did not improve from 1.27268
Epoch 1604/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4269 - val_loss: 1.2728 - val_accuracy: 0.4263

Epoch 01604: val_loss did not improve from 1.27268
Epoch 1605/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4167 - val_loss: 1.2767 - val_accuracy: 0.4231

Epoch 01605: val_loss did not improve from 1.27268
Epoch 1606/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4230 - val_loss: 1.2740 - val_accuracy: 0.4223

Epoch 01606: val_loss did not improve from 1.27268
Epoch 1607/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4246 - val_loss: 1.2727 - val_accuracy: 0.4279

Epoch 01607: val_loss improved from 1.27268 to 1.27266, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1608/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4260 - val_loss: 1.2711 - val_accuracy: 0.4414

Epoch 01608: val_loss improved from 1.27266 to 1.27106, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1609/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4257 - val_loss: 1.2727 - val_accuracy: 0.4223

Epoch 01609: val_loss did not improve from 1.27106
Epoch 1610/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4241 - val_loss: 1.2776 - val_accuracy: 0.4263

Epoch 01610: val_loss did not improve from 1.27106
Epoch 1611/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4227 - val_loss: 1.2768 - val_accuracy: 0.4247

Epoch 01611: val_loss did not improve from 1.27106
Epoch 1612/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4271 - val_loss: 1.2749 - val_accuracy: 0.4247

Epoch 01612: val_loss did not improve from 1.27106
Epoch 1613/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4211 - val_loss: 1.2754 - val_accuracy: 0.4255

Epoch 01613: val_loss did not improve from 1.27106
Epoch 1614/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4226 - val_loss: 1.2772 - val_accuracy: 0.4167

Epoch 01614: val_loss did not improve from 1.27106
Epoch 1615/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4271 - val_loss: 1.2758 - val_accuracy: 0.4199

Epoch 01615: val_loss did not improve from 1.27106
Epoch 1616/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4260 - val_loss: 1.2731 - val_accuracy: 0.4303

Epoch 01616: val_loss did not improve from 1.27106
Epoch 1617/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4267 - val_loss: 1.2733 - val_accuracy: 0.4382

Epoch 01617: val_loss did not improve from 1.27106
Epoch 1618/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4257 - val_loss: 1.2736 - val_accuracy: 0.4343

Epoch 01618: val_loss did not improve from 1.27106
Epoch 1619/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4241 - val_loss: 1.2712 - val_accuracy: 0.4398

Epoch 01619: val_loss did not improve from 1.27106
Epoch 1620/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4245 - val_loss: 1.2754 - val_accuracy: 0.4215

Epoch 01620: val_loss did not improve from 1.27106
Epoch 1621/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4258 - val_loss: 1.2743 - val_accuracy: 0.4255

Epoch 01621: val_loss did not improve from 1.27106
Epoch 1622/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4274 - val_loss: 1.2737 - val_accuracy: 0.4207

Epoch 01622: val_loss did not improve from 1.27106
Epoch 1623/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4242 - val_loss: 1.2714 - val_accuracy: 0.4279

Epoch 01623: val_loss did not improve from 1.27106
Epoch 1624/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4237 - val_loss: 1.2735 - val_accuracy: 0.4335

Epoch 01624: val_loss did not improve from 1.27106
Epoch 1625/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4226 - val_loss: 1.2761 - val_accuracy: 0.4279

Epoch 01625: val_loss did not improve from 1.27106
Epoch 1626/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4252 - val_loss: 1.2817 - val_accuracy: 0.4127

Epoch 01626: val_loss did not improve from 1.27106
Epoch 1627/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4268 - val_loss: 1.2742 - val_accuracy: 0.4223

Epoch 01627: val_loss did not improve from 1.27106
Epoch 1628/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4270 - val_loss: 1.2712 - val_accuracy: 0.4239

Epoch 01628: val_loss did not improve from 1.27106
Epoch 1629/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4264 - val_loss: 1.2721 - val_accuracy: 0.4319

Epoch 01629: val_loss did not improve from 1.27106
Epoch 1630/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4294 - val_loss: 1.2726 - val_accuracy: 0.4207

Epoch 01630: val_loss did not improve from 1.27106
Epoch 1631/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4254 - val_loss: 1.2736 - val_accuracy: 0.4271

Epoch 01631: val_loss did not improve from 1.27106
Epoch 1632/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4278 - val_loss: 1.2725 - val_accuracy: 0.4343

Epoch 01632: val_loss did not improve from 1.27106
Epoch 1633/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4182 - val_loss: 1.2742 - val_accuracy: 0.4271

Epoch 01633: val_loss did not improve from 1.27106
Epoch 1634/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4274 - val_loss: 1.2762 - val_accuracy: 0.4223

Epoch 01634: val_loss did not improve from 1.27106
Epoch 1635/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4250 - val_loss: 1.2780 - val_accuracy: 0.4151

Epoch 01635: val_loss did not improve from 1.27106
Epoch 1636/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4255 - val_loss: 1.2766 - val_accuracy: 0.4199

Epoch 01636: val_loss did not improve from 1.27106
Epoch 1637/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4239 - val_loss: 1.2749 - val_accuracy: 0.4255

Epoch 01637: val_loss did not improve from 1.27106
Epoch 1638/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4266 - val_loss: 1.2728 - val_accuracy: 0.4279

Epoch 01638: val_loss did not improve from 1.27106
Epoch 1639/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4266 - val_loss: 1.2735 - val_accuracy: 0.4319

Epoch 01639: val_loss did not improve from 1.27106
Epoch 1640/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4271 - val_loss: 1.2738 - val_accuracy: 0.4255

Epoch 01640: val_loss did not improve from 1.27106
Epoch 1641/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4231 - val_loss: 1.2713 - val_accuracy: 0.4207

Epoch 01641: val_loss did not improve from 1.27106
Epoch 1642/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4237 - val_loss: 1.2756 - val_accuracy: 0.4327

Epoch 01642: val_loss did not improve from 1.27106
Epoch 1643/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4259 - val_loss: 1.2743 - val_accuracy: 0.4207

Epoch 01643: val_loss did not improve from 1.27106
Epoch 1644/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4230 - val_loss: 1.2728 - val_accuracy: 0.4247

Epoch 01644: val_loss did not improve from 1.27106
Epoch 1645/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4209 - val_loss: 1.2739 - val_accuracy: 0.4223

Epoch 01645: val_loss did not improve from 1.27106
Epoch 1646/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4278 - val_loss: 1.2762 - val_accuracy: 0.4215

Epoch 01646: val_loss did not improve from 1.27106
Epoch 1647/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4254 - val_loss: 1.2741 - val_accuracy: 0.4247

Epoch 01647: val_loss did not improve from 1.27106
Epoch 1648/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4259 - val_loss: 1.2737 - val_accuracy: 0.4191

Epoch 01648: val_loss did not improve from 1.27106
Epoch 1649/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4265 - val_loss: 1.2765 - val_accuracy: 0.4263

Epoch 01649: val_loss did not improve from 1.27106
Epoch 1650/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4275 - val_loss: 1.2786 - val_accuracy: 0.4263

Epoch 01650: val_loss did not improve from 1.27106
Epoch 1651/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4237 - val_loss: 1.2804 - val_accuracy: 0.4088

Epoch 01651: val_loss did not improve from 1.27106
Epoch 1652/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4209 - val_loss: 1.2729 - val_accuracy: 0.4247

Epoch 01652: val_loss did not improve from 1.27106
Epoch 1653/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4271 - val_loss: 1.2745 - val_accuracy: 0.4223

Epoch 01653: val_loss did not improve from 1.27106
Epoch 1654/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4260 - val_loss: 1.2764 - val_accuracy: 0.4215

Epoch 01654: val_loss did not improve from 1.27106
Epoch 1655/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4224 - val_loss: 1.2788 - val_accuracy: 0.4175

Epoch 01655: val_loss did not improve from 1.27106
Epoch 1656/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4290 - val_loss: 1.2790 - val_accuracy: 0.4255

Epoch 01656: val_loss did not improve from 1.27106
Epoch 1657/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4263 - val_loss: 1.2780 - val_accuracy: 0.4167

Epoch 01657: val_loss did not improve from 1.27106
Epoch 1658/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4254 - val_loss: 1.2742 - val_accuracy: 0.4223

Epoch 01658: val_loss did not improve from 1.27106
Epoch 1659/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4290 - val_loss: 1.2830 - val_accuracy: 0.4183

Epoch 01659: val_loss did not improve from 1.27106
Epoch 1660/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4167 - val_loss: 1.2787 - val_accuracy: 0.4295

Epoch 01660: val_loss did not improve from 1.27106
Epoch 1661/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4283 - val_loss: 1.2792 - val_accuracy: 0.4120

Epoch 01661: val_loss did not improve from 1.27106
Epoch 1662/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4270 - val_loss: 1.2751 - val_accuracy: 0.4359

Epoch 01662: val_loss did not improve from 1.27106
Epoch 1663/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4279 - val_loss: 1.2762 - val_accuracy: 0.4167

Epoch 01663: val_loss did not improve from 1.27106
Epoch 1664/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4255 - val_loss: 1.2746 - val_accuracy: 0.4295

Epoch 01664: val_loss did not improve from 1.27106
Epoch 1665/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4244 - val_loss: 1.2730 - val_accuracy: 0.4247

Epoch 01665: val_loss did not improve from 1.27106
Epoch 1666/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4265 - val_loss: 1.2723 - val_accuracy: 0.4303

Epoch 01666: val_loss did not improve from 1.27106
Epoch 1667/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4256 - val_loss: 1.2769 - val_accuracy: 0.4295

Epoch 01667: val_loss did not improve from 1.27106
Epoch 1668/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4261 - val_loss: 1.2747 - val_accuracy: 0.4271

Epoch 01668: val_loss did not improve from 1.27106
Epoch 1669/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4252 - val_loss: 1.2782 - val_accuracy: 0.4135

Epoch 01669: val_loss did not improve from 1.27106
Epoch 1670/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4258 - val_loss: 1.2716 - val_accuracy: 0.4367

Epoch 01670: val_loss did not improve from 1.27106
Epoch 1671/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4261 - val_loss: 1.2729 - val_accuracy: 0.4303

Epoch 01671: val_loss did not improve from 1.27106
Epoch 1672/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4244 - val_loss: 1.2729 - val_accuracy: 0.4263

Epoch 01672: val_loss did not improve from 1.27106
Epoch 1673/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4243 - val_loss: 1.2778 - val_accuracy: 0.4231

Epoch 01673: val_loss did not improve from 1.27106
Epoch 1674/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4254 - val_loss: 1.2738 - val_accuracy: 0.4311

Epoch 01674: val_loss did not improve from 1.27106
Epoch 1675/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4283 - val_loss: 1.2746 - val_accuracy: 0.4207

Epoch 01675: val_loss did not improve from 1.27106
Epoch 1676/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4244 - val_loss: 1.2704 - val_accuracy: 0.4406

Epoch 01676: val_loss improved from 1.27106 to 1.27044, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1677/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4242 - val_loss: 1.2726 - val_accuracy: 0.4351

Epoch 01677: val_loss did not improve from 1.27044
Epoch 1678/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4241 - val_loss: 1.2769 - val_accuracy: 0.4215

Epoch 01678: val_loss did not improve from 1.27044
Epoch 1679/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4257 - val_loss: 1.2787 - val_accuracy: 0.4199

Epoch 01679: val_loss did not improve from 1.27044
Epoch 1680/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4213 - val_loss: 1.2752 - val_accuracy: 0.4263

Epoch 01680: val_loss did not improve from 1.27044
Epoch 1681/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4208 - val_loss: 1.2744 - val_accuracy: 0.4351

Epoch 01681: val_loss did not improve from 1.27044
Epoch 1682/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4239 - val_loss: 1.2766 - val_accuracy: 0.4239

Epoch 01682: val_loss did not improve from 1.27044
Epoch 1683/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4241 - val_loss: 1.2850 - val_accuracy: 0.4112

Epoch 01683: val_loss did not improve from 1.27044
Epoch 1684/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4228 - val_loss: 1.2763 - val_accuracy: 0.4223

Epoch 01684: val_loss did not improve from 1.27044
Epoch 1685/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4225 - val_loss: 1.2799 - val_accuracy: 0.4247

Epoch 01685: val_loss did not improve from 1.27044
Epoch 1686/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4256 - val_loss: 1.2785 - val_accuracy: 0.4080

Epoch 01686: val_loss did not improve from 1.27044
Epoch 1687/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4237 - val_loss: 1.2833 - val_accuracy: 0.4088

Epoch 01687: val_loss did not improve from 1.27044
Epoch 1688/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4230 - val_loss: 1.2782 - val_accuracy: 0.4215

Epoch 01688: val_loss did not improve from 1.27044
Epoch 1689/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4232 - val_loss: 1.2762 - val_accuracy: 0.4263

Epoch 01689: val_loss did not improve from 1.27044
Epoch 1690/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4257 - val_loss: 1.2776 - val_accuracy: 0.4263

Epoch 01690: val_loss did not improve from 1.27044
Epoch 1691/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4265 - val_loss: 1.2767 - val_accuracy: 0.4207

Epoch 01691: val_loss did not improve from 1.27044
Epoch 1692/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4236 - val_loss: 1.2750 - val_accuracy: 0.4335

Epoch 01692: val_loss did not improve from 1.27044
Epoch 1693/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4252 - val_loss: 1.2751 - val_accuracy: 0.4303

Epoch 01693: val_loss did not improve from 1.27044
Epoch 1694/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4263 - val_loss: 1.2746 - val_accuracy: 0.4215

Epoch 01694: val_loss did not improve from 1.27044
Epoch 1695/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4209 - val_loss: 1.2770 - val_accuracy: 0.4239

Epoch 01695: val_loss did not improve from 1.27044
Epoch 1696/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4253 - val_loss: 1.2741 - val_accuracy: 0.4319

Epoch 01696: val_loss did not improve from 1.27044
Epoch 1697/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4256 - val_loss: 1.2748 - val_accuracy: 0.4247

Epoch 01697: val_loss did not improve from 1.27044
Epoch 1698/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4250 - val_loss: 1.2726 - val_accuracy: 0.4263

Epoch 01698: val_loss did not improve from 1.27044
Epoch 1699/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4252 - val_loss: 1.2753 - val_accuracy: 0.4287

Epoch 01699: val_loss did not improve from 1.27044
Epoch 1700/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4261 - val_loss: 1.2712 - val_accuracy: 0.4223

Epoch 01700: val_loss did not improve from 1.27044
Epoch 1701/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4251 - val_loss: 1.2731 - val_accuracy: 0.4319

Epoch 01701: val_loss did not improve from 1.27044
Epoch 1702/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4206 - val_loss: 1.2767 - val_accuracy: 0.4279

Epoch 01702: val_loss did not improve from 1.27044
Epoch 1703/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4283 - val_loss: 1.2749 - val_accuracy: 0.4311

Epoch 01703: val_loss did not improve from 1.27044
Epoch 1704/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4267 - val_loss: 1.2712 - val_accuracy: 0.4303

Epoch 01704: val_loss did not improve from 1.27044
Epoch 1705/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4245 - val_loss: 1.2713 - val_accuracy: 0.4375

Epoch 01705: val_loss did not improve from 1.27044
Epoch 1706/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4239 - val_loss: 1.2741 - val_accuracy: 0.4255

Epoch 01706: val_loss did not improve from 1.27044
Epoch 1707/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4230 - val_loss: 1.2750 - val_accuracy: 0.4247

Epoch 01707: val_loss did not improve from 1.27044
Epoch 1708/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4278 - val_loss: 1.2722 - val_accuracy: 0.4430

Epoch 01708: val_loss did not improve from 1.27044
Epoch 1709/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4216 - val_loss: 1.2750 - val_accuracy: 0.4151

Epoch 01709: val_loss did not improve from 1.27044
Epoch 1710/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4248 - val_loss: 1.2713 - val_accuracy: 0.4303

Epoch 01710: val_loss did not improve from 1.27044
Epoch 1711/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4267 - val_loss: 1.2706 - val_accuracy: 0.4271

Epoch 01711: val_loss did not improve from 1.27044
Epoch 1712/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4270 - val_loss: 1.2731 - val_accuracy: 0.4287

Epoch 01712: val_loss did not improve from 1.27044
Epoch 1713/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4198 - val_loss: 1.2763 - val_accuracy: 0.4199

Epoch 01713: val_loss did not improve from 1.27044
Epoch 1714/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4239 - val_loss: 1.2732 - val_accuracy: 0.4311

Epoch 01714: val_loss did not improve from 1.27044
Epoch 1715/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4269 - val_loss: 1.2726 - val_accuracy: 0.4303

Epoch 01715: val_loss did not improve from 1.27044
Epoch 1716/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4246 - val_loss: 1.2745 - val_accuracy: 0.4215

Epoch 01716: val_loss did not improve from 1.27044
Epoch 1717/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4259 - val_loss: 1.2764 - val_accuracy: 0.4183

Epoch 01717: val_loss did not improve from 1.27044
Epoch 1718/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4295 - val_loss: 1.2744 - val_accuracy: 0.4239

Epoch 01718: val_loss did not improve from 1.27044
Epoch 1719/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4268 - val_loss: 1.2746 - val_accuracy: 0.4351

Epoch 01719: val_loss did not improve from 1.27044
Epoch 1720/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4277 - val_loss: 1.2794 - val_accuracy: 0.4151

Epoch 01720: val_loss did not improve from 1.27044
Epoch 1721/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4242 - val_loss: 1.2764 - val_accuracy: 0.4191

Epoch 01721: val_loss did not improve from 1.27044
Epoch 1722/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4244 - val_loss: 1.2724 - val_accuracy: 0.4215

Epoch 01722: val_loss did not improve from 1.27044
Epoch 1723/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4291 - val_loss: 1.2724 - val_accuracy: 0.4287

Epoch 01723: val_loss did not improve from 1.27044
Epoch 1724/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4221 - val_loss: 1.2741 - val_accuracy: 0.4287

Epoch 01724: val_loss did not improve from 1.27044
Epoch 1725/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4240 - val_loss: 1.2746 - val_accuracy: 0.4303

Epoch 01725: val_loss did not improve from 1.27044
Epoch 1726/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4263 - val_loss: 1.2698 - val_accuracy: 0.4287

Epoch 01726: val_loss improved from 1.27044 to 1.26980, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1727/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4286 - val_loss: 1.2702 - val_accuracy: 0.4311

Epoch 01727: val_loss did not improve from 1.26980
Epoch 1728/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4212 - val_loss: 1.2762 - val_accuracy: 0.4191

Epoch 01728: val_loss did not improve from 1.26980
Epoch 1729/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4286 - val_loss: 1.2760 - val_accuracy: 0.4343

Epoch 01729: val_loss did not improve from 1.26980
Epoch 1730/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4226 - val_loss: 1.2751 - val_accuracy: 0.4143

Epoch 01730: val_loss did not improve from 1.26980
Epoch 1731/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4262 - val_loss: 1.2768 - val_accuracy: 0.4151

Epoch 01731: val_loss did not improve from 1.26980
Epoch 1732/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4191 - val_loss: 1.2746 - val_accuracy: 0.4223

Epoch 01732: val_loss did not improve from 1.26980
Epoch 1733/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4245 - val_loss: 1.2753 - val_accuracy: 0.4223

Epoch 01733: val_loss did not improve from 1.26980
Epoch 1734/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4211 - val_loss: 1.2768 - val_accuracy: 0.4167

Epoch 01734: val_loss did not improve from 1.26980
Epoch 1735/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4233 - val_loss: 1.2721 - val_accuracy: 0.4271

Epoch 01735: val_loss did not improve from 1.26980
Epoch 1736/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4186 - val_loss: 1.2812 - val_accuracy: 0.4040

Epoch 01736: val_loss did not improve from 1.26980
Epoch 1737/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4208 - val_loss: 1.2740 - val_accuracy: 0.4231

Epoch 01737: val_loss did not improve from 1.26980
Epoch 1738/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4243 - val_loss: 1.2736 - val_accuracy: 0.4343

Epoch 01738: val_loss did not improve from 1.26980
Epoch 1739/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4256 - val_loss: 1.2744 - val_accuracy: 0.4335

Epoch 01739: val_loss did not improve from 1.26980
Epoch 1740/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4247 - val_loss: 1.2746 - val_accuracy: 0.4287

Epoch 01740: val_loss did not improve from 1.26980
Epoch 1741/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4272 - val_loss: 1.2745 - val_accuracy: 0.4287

Epoch 01741: val_loss did not improve from 1.26980
Epoch 1742/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4233 - val_loss: 1.2715 - val_accuracy: 0.4295

Epoch 01742: val_loss did not improve from 1.26980
Epoch 1743/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4277 - val_loss: 1.2717 - val_accuracy: 0.4375

Epoch 01743: val_loss did not improve from 1.26980
Epoch 1744/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4196 - val_loss: 1.2831 - val_accuracy: 0.4120

Epoch 01744: val_loss did not improve from 1.26980
Epoch 1745/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4260 - val_loss: 1.2777 - val_accuracy: 0.4255

Epoch 01745: val_loss did not improve from 1.26980
Epoch 1746/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4268 - val_loss: 1.2767 - val_accuracy: 0.4311

Epoch 01746: val_loss did not improve from 1.26980
Epoch 1747/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4244 - val_loss: 1.2757 - val_accuracy: 0.4207

Epoch 01747: val_loss did not improve from 1.26980
Epoch 1748/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4287 - val_loss: 1.2739 - val_accuracy: 0.4215

Epoch 01748: val_loss did not improve from 1.26980
Epoch 1749/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4246 - val_loss: 1.2730 - val_accuracy: 0.4311

Epoch 01749: val_loss did not improve from 1.26980
Epoch 1750/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4275 - val_loss: 1.2740 - val_accuracy: 0.4247

Epoch 01750: val_loss did not improve from 1.26980
Epoch 1751/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4261 - val_loss: 1.2787 - val_accuracy: 0.4287

Epoch 01751: val_loss did not improve from 1.26980
Epoch 1752/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4244 - val_loss: 1.2752 - val_accuracy: 0.4191

Epoch 01752: val_loss did not improve from 1.26980
Epoch 1753/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4270 - val_loss: 1.2762 - val_accuracy: 0.4231

Epoch 01753: val_loss did not improve from 1.26980
Epoch 1754/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4248 - val_loss: 1.2752 - val_accuracy: 0.4175

Epoch 01754: val_loss did not improve from 1.26980
Epoch 1755/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4305 - val_loss: 1.2734 - val_accuracy: 0.4335

Epoch 01755: val_loss did not improve from 1.26980
Epoch 1756/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4272 - val_loss: 1.2757 - val_accuracy: 0.4303

Epoch 01756: val_loss did not improve from 1.26980
Epoch 1757/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4264 - val_loss: 1.2713 - val_accuracy: 0.4398

Epoch 01757: val_loss did not improve from 1.26980
Epoch 1758/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4275 - val_loss: 1.2724 - val_accuracy: 0.4367

Epoch 01758: val_loss did not improve from 1.26980
Epoch 1759/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4252 - val_loss: 1.2788 - val_accuracy: 0.4135

Epoch 01759: val_loss did not improve from 1.26980
Epoch 1760/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4230 - val_loss: 1.2741 - val_accuracy: 0.4247

Epoch 01760: val_loss did not improve from 1.26980
Epoch 1761/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4245 - val_loss: 1.2723 - val_accuracy: 0.4199

Epoch 01761: val_loss did not improve from 1.26980
Epoch 1762/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4275 - val_loss: 1.2739 - val_accuracy: 0.4231

Epoch 01762: val_loss did not improve from 1.26980
Epoch 1763/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4265 - val_loss: 1.2747 - val_accuracy: 0.4191

Epoch 01763: val_loss did not improve from 1.26980
Epoch 1764/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4257 - val_loss: 1.2740 - val_accuracy: 0.4311

Epoch 01764: val_loss did not improve from 1.26980
Epoch 1765/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4286 - val_loss: 1.2790 - val_accuracy: 0.4159

Epoch 01765: val_loss did not improve from 1.26980
Epoch 1766/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4239 - val_loss: 1.2788 - val_accuracy: 0.4263

Epoch 01766: val_loss did not improve from 1.26980
Epoch 1767/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4210 - val_loss: 1.2748 - val_accuracy: 0.4311

Epoch 01767: val_loss did not improve from 1.26980
Epoch 1768/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4275 - val_loss: 1.2772 - val_accuracy: 0.4215

Epoch 01768: val_loss did not improve from 1.26980
Epoch 1769/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4253 - val_loss: 1.2754 - val_accuracy: 0.4255

Epoch 01769: val_loss did not improve from 1.26980
Epoch 1770/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4268 - val_loss: 1.2742 - val_accuracy: 0.4335

Epoch 01770: val_loss did not improve from 1.26980
Epoch 1771/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4238 - val_loss: 1.2741 - val_accuracy: 0.4335

Epoch 01771: val_loss did not improve from 1.26980
Epoch 1772/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4253 - val_loss: 1.2757 - val_accuracy: 0.4215

Epoch 01772: val_loss did not improve from 1.26980
Epoch 1773/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4242 - val_loss: 1.2797 - val_accuracy: 0.4175

Epoch 01773: val_loss did not improve from 1.26980
Epoch 1774/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4208 - val_loss: 1.2789 - val_accuracy: 0.4239

Epoch 01774: val_loss did not improve from 1.26980
Epoch 1775/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4258 - val_loss: 1.2743 - val_accuracy: 0.4287

Epoch 01775: val_loss did not improve from 1.26980
Epoch 1776/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4306 - val_loss: 1.2723 - val_accuracy: 0.4295

Epoch 01776: val_loss did not improve from 1.26980
Epoch 1777/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4273 - val_loss: 1.2771 - val_accuracy: 0.4167

Epoch 01777: val_loss did not improve from 1.26980
Epoch 1778/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4252 - val_loss: 1.2754 - val_accuracy: 0.4319

Epoch 01778: val_loss did not improve from 1.26980
Epoch 1779/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4252 - val_loss: 1.2748 - val_accuracy: 0.4247

Epoch 01779: val_loss did not improve from 1.26980
Epoch 1780/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4251 - val_loss: 1.2735 - val_accuracy: 0.4207

Epoch 01780: val_loss did not improve from 1.26980
Epoch 1781/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4284 - val_loss: 1.2740 - val_accuracy: 0.4199

Epoch 01781: val_loss did not improve from 1.26980
Epoch 1782/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4243 - val_loss: 1.2746 - val_accuracy: 0.4231

Epoch 01782: val_loss did not improve from 1.26980
Epoch 1783/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4250 - val_loss: 1.2709 - val_accuracy: 0.4303

Epoch 01783: val_loss did not improve from 1.26980
Epoch 1784/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4275 - val_loss: 1.2742 - val_accuracy: 0.4223

Epoch 01784: val_loss did not improve from 1.26980
Epoch 1785/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4276 - val_loss: 1.2800 - val_accuracy: 0.4135

Epoch 01785: val_loss did not improve from 1.26980
Epoch 1786/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4211 - val_loss: 1.2739 - val_accuracy: 0.4231

Epoch 01786: val_loss did not improve from 1.26980
Epoch 1787/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4218 - val_loss: 1.2765 - val_accuracy: 0.4175

Epoch 01787: val_loss did not improve from 1.26980
Epoch 1788/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4265 - val_loss: 1.2755 - val_accuracy: 0.4247

Epoch 01788: val_loss did not improve from 1.26980
Epoch 1789/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4274 - val_loss: 1.2757 - val_accuracy: 0.4223

Epoch 01789: val_loss did not improve from 1.26980
Epoch 1790/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4224 - val_loss: 1.2740 - val_accuracy: 0.4215

Epoch 01790: val_loss did not improve from 1.26980
Epoch 1791/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4256 - val_loss: 1.2726 - val_accuracy: 0.4311

Epoch 01791: val_loss did not improve from 1.26980
Epoch 1792/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4232 - val_loss: 1.2734 - val_accuracy: 0.4247

Epoch 01792: val_loss did not improve from 1.26980
Epoch 1793/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4208 - val_loss: 1.2725 - val_accuracy: 0.4303

Epoch 01793: val_loss did not improve from 1.26980
Epoch 1794/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4243 - val_loss: 1.2711 - val_accuracy: 0.4247

Epoch 01794: val_loss did not improve from 1.26980
Epoch 1795/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4299 - val_loss: 1.2726 - val_accuracy: 0.4239

Epoch 01795: val_loss did not improve from 1.26980
Epoch 1796/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4253 - val_loss: 1.2721 - val_accuracy: 0.4295

Epoch 01796: val_loss did not improve from 1.26980
Epoch 1797/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4243 - val_loss: 1.2798 - val_accuracy: 0.4207

Epoch 01797: val_loss did not improve from 1.26980
Epoch 1798/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4233 - val_loss: 1.2774 - val_accuracy: 0.4271

Epoch 01798: val_loss did not improve from 1.26980
Epoch 1799/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4237 - val_loss: 1.2783 - val_accuracy: 0.4271

Epoch 01799: val_loss did not improve from 1.26980
Epoch 1800/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4243 - val_loss: 1.2735 - val_accuracy: 0.4263

Epoch 01800: val_loss did not improve from 1.26980
Epoch 1801/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4217 - val_loss: 1.2735 - val_accuracy: 0.4199

Epoch 01801: val_loss did not improve from 1.26980
Epoch 1802/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4253 - val_loss: 1.2719 - val_accuracy: 0.4199

Epoch 01802: val_loss did not improve from 1.26980
Epoch 1803/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4273 - val_loss: 1.2731 - val_accuracy: 0.4279

Epoch 01803: val_loss did not improve from 1.26980
Epoch 1804/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4249 - val_loss: 1.2775 - val_accuracy: 0.4271

Epoch 01804: val_loss did not improve from 1.26980
Epoch 1805/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4255 - val_loss: 1.2723 - val_accuracy: 0.4295

Epoch 01805: val_loss did not improve from 1.26980
Epoch 1806/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4266 - val_loss: 1.2728 - val_accuracy: 0.4263

Epoch 01806: val_loss did not improve from 1.26980
Epoch 1807/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4255 - val_loss: 1.2731 - val_accuracy: 0.4303

Epoch 01807: val_loss did not improve from 1.26980
Epoch 1808/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4236 - val_loss: 1.2751 - val_accuracy: 0.4191

Epoch 01808: val_loss did not improve from 1.26980
Epoch 1809/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4263 - val_loss: 1.2715 - val_accuracy: 0.4367

Epoch 01809: val_loss did not improve from 1.26980
Epoch 1810/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4260 - val_loss: 1.2742 - val_accuracy: 0.4311

Epoch 01810: val_loss did not improve from 1.26980
Epoch 1811/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4284 - val_loss: 1.2740 - val_accuracy: 0.4319

Epoch 01811: val_loss did not improve from 1.26980
Epoch 1812/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4289 - val_loss: 1.2722 - val_accuracy: 0.4247

Epoch 01812: val_loss did not improve from 1.26980
Epoch 1813/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4266 - val_loss: 1.2712 - val_accuracy: 0.4311

Epoch 01813: val_loss did not improve from 1.26980
Epoch 1814/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4242 - val_loss: 1.2747 - val_accuracy: 0.4486

Epoch 01814: val_loss did not improve from 1.26980
Epoch 1815/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4267 - val_loss: 1.2727 - val_accuracy: 0.4311

Epoch 01815: val_loss did not improve from 1.26980
Epoch 1816/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4252 - val_loss: 1.2751 - val_accuracy: 0.4303

Epoch 01816: val_loss did not improve from 1.26980
Epoch 1817/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4220 - val_loss: 1.2740 - val_accuracy: 0.4454

Epoch 01817: val_loss did not improve from 1.26980
Epoch 1818/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4193 - val_loss: 1.2763 - val_accuracy: 0.4127

Epoch 01818: val_loss did not improve from 1.26980
Epoch 1819/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4257 - val_loss: 1.2704 - val_accuracy: 0.4359

Epoch 01819: val_loss did not improve from 1.26980
Epoch 1820/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4257 - val_loss: 1.2723 - val_accuracy: 0.4351

Epoch 01820: val_loss did not improve from 1.26980
Epoch 1821/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4268 - val_loss: 1.2776 - val_accuracy: 0.4191

Epoch 01821: val_loss did not improve from 1.26980
Epoch 1822/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4228 - val_loss: 1.2716 - val_accuracy: 0.4311

Epoch 01822: val_loss did not improve from 1.26980
Epoch 1823/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4298 - val_loss: 1.2737 - val_accuracy: 0.4311

Epoch 01823: val_loss did not improve from 1.26980
Epoch 1824/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4230 - val_loss: 1.2798 - val_accuracy: 0.4072

Epoch 01824: val_loss did not improve from 1.26980
Epoch 1825/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4253 - val_loss: 1.2778 - val_accuracy: 0.4112

Epoch 01825: val_loss did not improve from 1.26980
Epoch 1826/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4263 - val_loss: 1.2749 - val_accuracy: 0.4231

Epoch 01826: val_loss did not improve from 1.26980
Epoch 1827/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4240 - val_loss: 1.2737 - val_accuracy: 0.4255

Epoch 01827: val_loss did not improve from 1.26980
Epoch 1828/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4293 - val_loss: 1.2724 - val_accuracy: 0.4239

Epoch 01828: val_loss did not improve from 1.26980
Epoch 1829/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4244 - val_loss: 1.2741 - val_accuracy: 0.4303

Epoch 01829: val_loss did not improve from 1.26980
Epoch 1830/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4274 - val_loss: 1.2755 - val_accuracy: 0.4239

Epoch 01830: val_loss did not improve from 1.26980
Epoch 1831/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4260 - val_loss: 1.2747 - val_accuracy: 0.4287

Epoch 01831: val_loss did not improve from 1.26980
Epoch 1832/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4212 - val_loss: 1.2783 - val_accuracy: 0.4239

Epoch 01832: val_loss did not improve from 1.26980
Epoch 1833/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4223 - val_loss: 1.2754 - val_accuracy: 0.4215

Epoch 01833: val_loss did not improve from 1.26980
Epoch 1834/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4206 - val_loss: 1.2726 - val_accuracy: 0.4263

Epoch 01834: val_loss did not improve from 1.26980
Epoch 1835/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4248 - val_loss: 1.2745 - val_accuracy: 0.4263

Epoch 01835: val_loss did not improve from 1.26980
Epoch 1836/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4267 - val_loss: 1.2710 - val_accuracy: 0.4319

Epoch 01836: val_loss did not improve from 1.26980
Epoch 1837/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4239 - val_loss: 1.2716 - val_accuracy: 0.4327

Epoch 01837: val_loss did not improve from 1.26980
Epoch 1838/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4304 - val_loss: 1.2713 - val_accuracy: 0.4327

Epoch 01838: val_loss did not improve from 1.26980
Epoch 1839/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4303 - val_loss: 1.2740 - val_accuracy: 0.4239

Epoch 01839: val_loss did not improve from 1.26980
Epoch 1840/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4259 - val_loss: 1.2737 - val_accuracy: 0.4255

Epoch 01840: val_loss did not improve from 1.26980
Epoch 1841/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4268 - val_loss: 1.2701 - val_accuracy: 0.4367

Epoch 01841: val_loss did not improve from 1.26980
Epoch 1842/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4243 - val_loss: 1.2730 - val_accuracy: 0.4295

Epoch 01842: val_loss did not improve from 1.26980
Epoch 1843/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4264 - val_loss: 1.2736 - val_accuracy: 0.4343

Epoch 01843: val_loss did not improve from 1.26980
Epoch 1844/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4275 - val_loss: 1.2726 - val_accuracy: 0.4279

Epoch 01844: val_loss did not improve from 1.26980
Epoch 1845/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4312 - val_loss: 1.2732 - val_accuracy: 0.4335

Epoch 01845: val_loss did not improve from 1.26980
Epoch 1846/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4291 - val_loss: 1.2704 - val_accuracy: 0.4390

Epoch 01846: val_loss did not improve from 1.26980
Epoch 1847/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4233 - val_loss: 1.2762 - val_accuracy: 0.4064

Epoch 01847: val_loss did not improve from 1.26980
Epoch 1848/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4255 - val_loss: 1.2745 - val_accuracy: 0.4215

Epoch 01848: val_loss did not improve from 1.26980
Epoch 1849/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4259 - val_loss: 1.2712 - val_accuracy: 0.4422

Epoch 01849: val_loss did not improve from 1.26980
Epoch 1850/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4267 - val_loss: 1.2708 - val_accuracy: 0.4287

Epoch 01850: val_loss did not improve from 1.26980
Epoch 1851/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4305 - val_loss: 1.2740 - val_accuracy: 0.4199

Epoch 01851: val_loss did not improve from 1.26980
Epoch 1852/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4273 - val_loss: 1.2737 - val_accuracy: 0.4231

Epoch 01852: val_loss did not improve from 1.26980
Epoch 1853/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4284 - val_loss: 1.2708 - val_accuracy: 0.4295

Epoch 01853: val_loss did not improve from 1.26980
Epoch 1854/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4252 - val_loss: 1.2708 - val_accuracy: 0.4319

Epoch 01854: val_loss did not improve from 1.26980
Epoch 1855/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4251 - val_loss: 1.2702 - val_accuracy: 0.4279

Epoch 01855: val_loss did not improve from 1.26980
Epoch 1856/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4282 - val_loss: 1.2743 - val_accuracy: 0.4255

Epoch 01856: val_loss did not improve from 1.26980
Epoch 1857/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4248 - val_loss: 1.2724 - val_accuracy: 0.4359

Epoch 01857: val_loss did not improve from 1.26980
Epoch 1858/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4252 - val_loss: 1.2698 - val_accuracy: 0.4406

Epoch 01858: val_loss improved from 1.26980 to 1.26976, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1859/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4248 - val_loss: 1.2725 - val_accuracy: 0.4422

Epoch 01859: val_loss did not improve from 1.26976
Epoch 1860/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4265 - val_loss: 1.2747 - val_accuracy: 0.4303

Epoch 01860: val_loss did not improve from 1.26976
Epoch 1861/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4296 - val_loss: 1.2710 - val_accuracy: 0.4303

Epoch 01861: val_loss did not improve from 1.26976
Epoch 1862/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4245 - val_loss: 1.2705 - val_accuracy: 0.4311

Epoch 01862: val_loss did not improve from 1.26976
Epoch 1863/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4291 - val_loss: 1.2705 - val_accuracy: 0.4335

Epoch 01863: val_loss did not improve from 1.26976
Epoch 1864/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4227 - val_loss: 1.2765 - val_accuracy: 0.4231

Epoch 01864: val_loss did not improve from 1.26976
Epoch 1865/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4226 - val_loss: 1.2766 - val_accuracy: 0.4135

Epoch 01865: val_loss did not improve from 1.26976
Epoch 1866/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4267 - val_loss: 1.2729 - val_accuracy: 0.4295

Epoch 01866: val_loss did not improve from 1.26976
Epoch 1867/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4224 - val_loss: 1.2701 - val_accuracy: 0.4335

Epoch 01867: val_loss did not improve from 1.26976
Epoch 1868/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4291 - val_loss: 1.2716 - val_accuracy: 0.4351

Epoch 01868: val_loss did not improve from 1.26976
Epoch 1869/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4265 - val_loss: 1.2737 - val_accuracy: 0.4303

Epoch 01869: val_loss did not improve from 1.26976
Epoch 1870/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4290 - val_loss: 1.2731 - val_accuracy: 0.4303

Epoch 01870: val_loss did not improve from 1.26976
Epoch 1871/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4259 - val_loss: 1.2727 - val_accuracy: 0.4255

Epoch 01871: val_loss did not improve from 1.26976
Epoch 1872/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4258 - val_loss: 1.2831 - val_accuracy: 0.4231

Epoch 01872: val_loss did not improve from 1.26976
Epoch 1873/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4209 - val_loss: 1.2753 - val_accuracy: 0.4311

Epoch 01873: val_loss did not improve from 1.26976
Epoch 1874/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4261 - val_loss: 1.2733 - val_accuracy: 0.4327

Epoch 01874: val_loss did not improve from 1.26976
Epoch 1875/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4258 - val_loss: 1.2732 - val_accuracy: 0.4335

Epoch 01875: val_loss did not improve from 1.26976
Epoch 1876/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4305 - val_loss: 1.2718 - val_accuracy: 0.4398

Epoch 01876: val_loss did not improve from 1.26976
Epoch 1877/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4277 - val_loss: 1.2717 - val_accuracy: 0.4263

Epoch 01877: val_loss did not improve from 1.26976
Epoch 1878/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4273 - val_loss: 1.2768 - val_accuracy: 0.4271

Epoch 01878: val_loss did not improve from 1.26976
Epoch 1879/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4241 - val_loss: 1.2747 - val_accuracy: 0.4398

Epoch 01879: val_loss did not improve from 1.26976
Epoch 1880/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4298 - val_loss: 1.2734 - val_accuracy: 0.4271

Epoch 01880: val_loss did not improve from 1.26976
Epoch 1881/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4291 - val_loss: 1.2716 - val_accuracy: 0.4327

Epoch 01881: val_loss did not improve from 1.26976
Epoch 1882/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4280 - val_loss: 1.2732 - val_accuracy: 0.4311

Epoch 01882: val_loss did not improve from 1.26976
Epoch 1883/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4237 - val_loss: 1.2741 - val_accuracy: 0.4191

Epoch 01883: val_loss did not improve from 1.26976
Epoch 1884/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4274 - val_loss: 1.2730 - val_accuracy: 0.4279

Epoch 01884: val_loss did not improve from 1.26976
Epoch 1885/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4304 - val_loss: 1.2705 - val_accuracy: 0.4279

Epoch 01885: val_loss did not improve from 1.26976
Epoch 1886/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4256 - val_loss: 1.2736 - val_accuracy: 0.4279

Epoch 01886: val_loss did not improve from 1.26976
Epoch 1887/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4260 - val_loss: 1.2705 - val_accuracy: 0.4327

Epoch 01887: val_loss did not improve from 1.26976
Epoch 1888/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4261 - val_loss: 1.2830 - val_accuracy: 0.4231

Epoch 01888: val_loss did not improve from 1.26976
Epoch 1889/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4243 - val_loss: 1.2707 - val_accuracy: 0.4414

Epoch 01889: val_loss did not improve from 1.26976
Epoch 1890/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4247 - val_loss: 1.2728 - val_accuracy: 0.4351

Epoch 01890: val_loss did not improve from 1.26976
Epoch 1891/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4252 - val_loss: 1.2729 - val_accuracy: 0.4231

Epoch 01891: val_loss did not improve from 1.26976
Epoch 1892/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4256 - val_loss: 1.2732 - val_accuracy: 0.4247

Epoch 01892: val_loss did not improve from 1.26976
Epoch 1893/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4266 - val_loss: 1.2709 - val_accuracy: 0.4335

Epoch 01893: val_loss did not improve from 1.26976
Epoch 1894/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4280 - val_loss: 1.2758 - val_accuracy: 0.4247

Epoch 01894: val_loss did not improve from 1.26976
Epoch 1895/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4213 - val_loss: 1.2747 - val_accuracy: 0.4311

Epoch 01895: val_loss did not improve from 1.26976
Epoch 1896/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4264 - val_loss: 1.2733 - val_accuracy: 0.4199

Epoch 01896: val_loss did not improve from 1.26976
Epoch 1897/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4244 - val_loss: 1.2716 - val_accuracy: 0.4335

Epoch 01897: val_loss did not improve from 1.26976
Epoch 1898/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4307 - val_loss: 1.2727 - val_accuracy: 0.4175

Epoch 01898: val_loss did not improve from 1.26976
Epoch 1899/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4267 - val_loss: 1.2898 - val_accuracy: 0.4040

Epoch 01899: val_loss did not improve from 1.26976
Epoch 1900/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4221 - val_loss: 1.2750 - val_accuracy: 0.4295

Epoch 01900: val_loss did not improve from 1.26976
Epoch 1901/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4317 - val_loss: 1.2694 - val_accuracy: 0.4343

Epoch 01901: val_loss improved from 1.26976 to 1.26941, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1902/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4300 - val_loss: 1.2733 - val_accuracy: 0.4207

Epoch 01902: val_loss did not improve from 1.26941
Epoch 1903/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4252 - val_loss: 1.2751 - val_accuracy: 0.4255

Epoch 01903: val_loss did not improve from 1.26941
Epoch 1904/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4303 - val_loss: 1.2690 - val_accuracy: 0.4319

Epoch 01904: val_loss improved from 1.26941 to 1.26901, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1905/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4261 - val_loss: 1.2682 - val_accuracy: 0.4470

Epoch 01905: val_loss improved from 1.26901 to 1.26819, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1906/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4265 - val_loss: 1.2713 - val_accuracy: 0.4271

Epoch 01906: val_loss did not improve from 1.26819
Epoch 1907/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4271 - val_loss: 1.2705 - val_accuracy: 0.4319

Epoch 01907: val_loss did not improve from 1.26819
Epoch 1908/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4269 - val_loss: 1.2703 - val_accuracy: 0.4454

Epoch 01908: val_loss did not improve from 1.26819
Epoch 1909/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4277 - val_loss: 1.2799 - val_accuracy: 0.4175

Epoch 01909: val_loss did not improve from 1.26819
Epoch 1910/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4199 - val_loss: 1.2791 - val_accuracy: 0.4183

Epoch 01910: val_loss did not improve from 1.26819
Epoch 1911/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4235 - val_loss: 1.2727 - val_accuracy: 0.4199

Epoch 01911: val_loss did not improve from 1.26819
Epoch 1912/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4265 - val_loss: 1.2721 - val_accuracy: 0.4319

Epoch 01912: val_loss did not improve from 1.26819
Epoch 1913/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4252 - val_loss: 1.2757 - val_accuracy: 0.4239

Epoch 01913: val_loss did not improve from 1.26819
Epoch 1914/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4260 - val_loss: 1.2722 - val_accuracy: 0.4311

Epoch 01914: val_loss did not improve from 1.26819
Epoch 1915/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4289 - val_loss: 1.2693 - val_accuracy: 0.4398

Epoch 01915: val_loss did not improve from 1.26819
Epoch 1916/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4297 - val_loss: 1.2721 - val_accuracy: 0.4343

Epoch 01916: val_loss did not improve from 1.26819
Epoch 1917/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4264 - val_loss: 1.2768 - val_accuracy: 0.4255

Epoch 01917: val_loss did not improve from 1.26819
Epoch 1918/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4283 - val_loss: 1.2718 - val_accuracy: 0.4303

Epoch 01918: val_loss did not improve from 1.26819
Epoch 1919/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4263 - val_loss: 1.2707 - val_accuracy: 0.4271

Epoch 01919: val_loss did not improve from 1.26819
Epoch 1920/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4244 - val_loss: 1.2713 - val_accuracy: 0.4351

Epoch 01920: val_loss did not improve from 1.26819
Epoch 1921/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4256 - val_loss: 1.2746 - val_accuracy: 0.4215

Epoch 01921: val_loss did not improve from 1.26819
Epoch 1922/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4285 - val_loss: 1.2689 - val_accuracy: 0.4335

Epoch 01922: val_loss did not improve from 1.26819
Epoch 1923/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4313 - val_loss: 1.2706 - val_accuracy: 0.4303

Epoch 01923: val_loss did not improve from 1.26819
Epoch 1924/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4271 - val_loss: 1.2723 - val_accuracy: 0.4303

Epoch 01924: val_loss did not improve from 1.26819
Epoch 1925/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4286 - val_loss: 1.2730 - val_accuracy: 0.4255

Epoch 01925: val_loss did not improve from 1.26819
Epoch 1926/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4193 - val_loss: 1.2715 - val_accuracy: 0.4430

Epoch 01926: val_loss did not improve from 1.26819
Epoch 1927/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4297 - val_loss: 1.2685 - val_accuracy: 0.4398

Epoch 01927: val_loss did not improve from 1.26819
Epoch 1928/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4253 - val_loss: 1.2713 - val_accuracy: 0.4343

Epoch 01928: val_loss did not improve from 1.26819
Epoch 1929/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4265 - val_loss: 1.2715 - val_accuracy: 0.4263

Epoch 01929: val_loss did not improve from 1.26819
Epoch 1930/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4257 - val_loss: 1.2736 - val_accuracy: 0.4183

Epoch 01930: val_loss did not improve from 1.26819
Epoch 1931/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4219 - val_loss: 1.2744 - val_accuracy: 0.4223

Epoch 01931: val_loss did not improve from 1.26819
Epoch 1932/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4250 - val_loss: 1.2759 - val_accuracy: 0.4207

Epoch 01932: val_loss did not improve from 1.26819
Epoch 1933/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4248 - val_loss: 1.2734 - val_accuracy: 0.4351

Epoch 01933: val_loss did not improve from 1.26819
Epoch 1934/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4260 - val_loss: 1.2733 - val_accuracy: 0.4367

Epoch 01934: val_loss did not improve from 1.26819
Epoch 1935/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4297 - val_loss: 1.2707 - val_accuracy: 0.4295

Epoch 01935: val_loss did not improve from 1.26819
Epoch 1936/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4254 - val_loss: 1.2694 - val_accuracy: 0.4430

Epoch 01936: val_loss did not improve from 1.26819
Epoch 1937/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4260 - val_loss: 1.2747 - val_accuracy: 0.4223

Epoch 01937: val_loss did not improve from 1.26819
Epoch 1938/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4277 - val_loss: 1.2755 - val_accuracy: 0.4223

Epoch 01938: val_loss did not improve from 1.26819
Epoch 1939/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4284 - val_loss: 1.2718 - val_accuracy: 0.4351

Epoch 01939: val_loss did not improve from 1.26819
Epoch 1940/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4280 - val_loss: 1.2712 - val_accuracy: 0.4414

Epoch 01940: val_loss did not improve from 1.26819
Epoch 1941/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4260 - val_loss: 1.2705 - val_accuracy: 0.4327

Epoch 01941: val_loss did not improve from 1.26819
Epoch 1942/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4260 - val_loss: 1.2702 - val_accuracy: 0.4303

Epoch 01942: val_loss did not improve from 1.26819
Epoch 1943/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4277 - val_loss: 1.2729 - val_accuracy: 0.4335

Epoch 01943: val_loss did not improve from 1.26819
Epoch 1944/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4290 - val_loss: 1.2734 - val_accuracy: 0.4335

Epoch 01944: val_loss did not improve from 1.26819
Epoch 1945/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4258 - val_loss: 1.2675 - val_accuracy: 0.4367

Epoch 01945: val_loss improved from 1.26819 to 1.26749, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1946/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4239 - val_loss: 1.2741 - val_accuracy: 0.4279

Epoch 01946: val_loss did not improve from 1.26749
Epoch 1947/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4254 - val_loss: 1.2725 - val_accuracy: 0.4319

Epoch 01947: val_loss did not improve from 1.26749
Epoch 1948/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4306 - val_loss: 1.2707 - val_accuracy: 0.4279

Epoch 01948: val_loss did not improve from 1.26749
Epoch 1949/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4225 - val_loss: 1.2730 - val_accuracy: 0.4303

Epoch 01949: val_loss did not improve from 1.26749
Epoch 1950/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4267 - val_loss: 1.2704 - val_accuracy: 0.4335

Epoch 01950: val_loss did not improve from 1.26749
Epoch 1951/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4260 - val_loss: 1.2717 - val_accuracy: 0.4263

Epoch 01951: val_loss did not improve from 1.26749
Epoch 1952/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4271 - val_loss: 1.2725 - val_accuracy: 0.4231

Epoch 01952: val_loss did not improve from 1.26749
Epoch 1953/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4292 - val_loss: 1.2743 - val_accuracy: 0.4183

Epoch 01953: val_loss did not improve from 1.26749
Epoch 1954/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4229 - val_loss: 1.2731 - val_accuracy: 0.4263

Epoch 01954: val_loss did not improve from 1.26749
Epoch 1955/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4286 - val_loss: 1.2752 - val_accuracy: 0.4247

Epoch 01955: val_loss did not improve from 1.26749
Epoch 1956/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4212 - val_loss: 1.2730 - val_accuracy: 0.4303

Epoch 01956: val_loss did not improve from 1.26749
Epoch 1957/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4294 - val_loss: 1.2747 - val_accuracy: 0.4247

Epoch 01957: val_loss did not improve from 1.26749
Epoch 1958/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4263 - val_loss: 1.2766 - val_accuracy: 0.4199

Epoch 01958: val_loss did not improve from 1.26749
Epoch 1959/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4306 - val_loss: 1.2707 - val_accuracy: 0.4311

Epoch 01959: val_loss did not improve from 1.26749
Epoch 1960/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4275 - val_loss: 1.2724 - val_accuracy: 0.4327

Epoch 01960: val_loss did not improve from 1.26749
Epoch 1961/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4325 - val_loss: 1.2697 - val_accuracy: 0.4295

Epoch 01961: val_loss did not improve from 1.26749
Epoch 1962/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4275 - val_loss: 1.2721 - val_accuracy: 0.4375

Epoch 01962: val_loss did not improve from 1.26749
Epoch 1963/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4270 - val_loss: 1.2757 - val_accuracy: 0.4255

Epoch 01963: val_loss did not improve from 1.26749
Epoch 1964/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4269 - val_loss: 1.2717 - val_accuracy: 0.4303

Epoch 01964: val_loss did not improve from 1.26749
Epoch 1965/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4226 - val_loss: 1.2711 - val_accuracy: 0.4295

Epoch 01965: val_loss did not improve from 1.26749
Epoch 1966/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4282 - val_loss: 1.2709 - val_accuracy: 0.4335

Epoch 01966: val_loss did not improve from 1.26749
Epoch 1967/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4256 - val_loss: 1.2698 - val_accuracy: 0.4406

Epoch 01967: val_loss did not improve from 1.26749
Epoch 1968/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4233 - val_loss: 1.2733 - val_accuracy: 0.4295

Epoch 01968: val_loss did not improve from 1.26749
Epoch 1969/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4231 - val_loss: 1.2730 - val_accuracy: 0.4303

Epoch 01969: val_loss did not improve from 1.26749
Epoch 1970/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4263 - val_loss: 1.2698 - val_accuracy: 0.4359

Epoch 01970: val_loss did not improve from 1.26749
Epoch 1971/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4272 - val_loss: 1.2671 - val_accuracy: 0.4351

Epoch 01971: val_loss improved from 1.26749 to 1.26707, saving model to ./results/NN_thk_class/aggr_theta/ckpt_3
Epoch 1972/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4285 - val_loss: 1.2749 - val_accuracy: 0.4255

Epoch 01972: val_loss did not improve from 1.26707
Epoch 1973/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4213 - val_loss: 1.2722 - val_accuracy: 0.4351

Epoch 01973: val_loss did not improve from 1.26707
Epoch 1974/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4265 - val_loss: 1.2763 - val_accuracy: 0.4223

Epoch 01974: val_loss did not improve from 1.26707
Epoch 1975/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4276 - val_loss: 1.2681 - val_accuracy: 0.4367

Epoch 01975: val_loss did not improve from 1.26707
Epoch 1976/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4306 - val_loss: 1.2698 - val_accuracy: 0.4367

Epoch 01976: val_loss did not improve from 1.26707
Epoch 1977/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4255 - val_loss: 1.2723 - val_accuracy: 0.4279

Epoch 01977: val_loss did not improve from 1.26707
Epoch 1978/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4276 - val_loss: 1.2712 - val_accuracy: 0.4303

Epoch 01978: val_loss did not improve from 1.26707
Epoch 1979/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4227 - val_loss: 1.2718 - val_accuracy: 0.4247

Epoch 01979: val_loss did not improve from 1.26707
Epoch 1980/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4292 - val_loss: 1.2719 - val_accuracy: 0.4231

Epoch 01980: val_loss did not improve from 1.26707
Epoch 1981/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4260 - val_loss: 1.2749 - val_accuracy: 0.4327

Epoch 01981: val_loss did not improve from 1.26707
Epoch 1982/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4241 - val_loss: 1.2699 - val_accuracy: 0.4311

Epoch 01982: val_loss did not improve from 1.26707
Epoch 1983/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4283 - val_loss: 1.2732 - val_accuracy: 0.4287

Epoch 01983: val_loss did not improve from 1.26707
Epoch 1984/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4260 - val_loss: 1.2759 - val_accuracy: 0.4247

Epoch 01984: val_loss did not improve from 1.26707
Epoch 1985/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4254 - val_loss: 1.2818 - val_accuracy: 0.4191

Epoch 01985: val_loss did not improve from 1.26707
Epoch 1986/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4232 - val_loss: 1.2709 - val_accuracy: 0.4151

Epoch 01986: val_loss did not improve from 1.26707
Epoch 1987/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4298 - val_loss: 1.2705 - val_accuracy: 0.4311

Epoch 01987: val_loss did not improve from 1.26707
Epoch 1988/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4284 - val_loss: 1.2823 - val_accuracy: 0.4287

Epoch 01988: val_loss did not improve from 1.26707
Epoch 1989/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4216 - val_loss: 1.2857 - val_accuracy: 0.4135

Epoch 01989: val_loss did not improve from 1.26707
Epoch 1990/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4223 - val_loss: 1.2775 - val_accuracy: 0.4159

Epoch 01990: val_loss did not improve from 1.26707
Epoch 1991/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4221 - val_loss: 1.2714 - val_accuracy: 0.4510

Epoch 01991: val_loss did not improve from 1.26707
Epoch 1992/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4309 - val_loss: 1.2745 - val_accuracy: 0.4279

Epoch 01992: val_loss did not improve from 1.26707
Epoch 1993/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4214 - val_loss: 1.2748 - val_accuracy: 0.4271

Epoch 01993: val_loss did not improve from 1.26707
Epoch 1994/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4236 - val_loss: 1.2739 - val_accuracy: 0.4327

Epoch 01994: val_loss did not improve from 1.26707
Epoch 1995/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4238 - val_loss: 1.2703 - val_accuracy: 0.4446

Epoch 01995: val_loss did not improve from 1.26707
Epoch 1996/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4269 - val_loss: 1.2698 - val_accuracy: 0.4319

Epoch 01996: val_loss did not improve from 1.26707
Epoch 1997/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4288 - val_loss: 1.2754 - val_accuracy: 0.4271

Epoch 01997: val_loss did not improve from 1.26707
Epoch 1998/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4228 - val_loss: 1.2709 - val_accuracy: 0.4303

Epoch 01998: val_loss did not improve from 1.26707
Epoch 1999/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4295 - val_loss: 1.2711 - val_accuracy: 0.4247

Epoch 01999: val_loss did not improve from 1.26707
Epoch 2000/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4254 - val_loss: 1.2797 - val_accuracy: 0.4239

Epoch 02000: val_loss did not improve from 1.26707
Epoch 2001/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4262 - val_loss: 1.2731 - val_accuracy: 0.4295

Epoch 02001: val_loss did not improve from 1.26707
Epoch 2002/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4270 - val_loss: 1.2757 - val_accuracy: 0.4239

Epoch 02002: val_loss did not improve from 1.26707
Epoch 2003/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4269 - val_loss: 1.2795 - val_accuracy: 0.4199

Epoch 02003: val_loss did not improve from 1.26707
Epoch 2004/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4235 - val_loss: 1.2727 - val_accuracy: 0.4311

Epoch 02004: val_loss did not improve from 1.26707
Epoch 2005/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4236 - val_loss: 1.2778 - val_accuracy: 0.4271

Epoch 02005: val_loss did not improve from 1.26707
Epoch 2006/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4277 - val_loss: 1.2841 - val_accuracy: 0.4120

Epoch 02006: val_loss did not improve from 1.26707
Epoch 2007/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4269 - val_loss: 1.2813 - val_accuracy: 0.4120

Epoch 02007: val_loss did not improve from 1.26707
Epoch 2008/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4222 - val_loss: 1.2748 - val_accuracy: 0.4255

Epoch 02008: val_loss did not improve from 1.26707
Epoch 2009/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4289 - val_loss: 1.2707 - val_accuracy: 0.4359

Epoch 02009: val_loss did not improve from 1.26707
Epoch 2010/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4264 - val_loss: 1.2775 - val_accuracy: 0.4191

Epoch 02010: val_loss did not improve from 1.26707
Epoch 2011/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4267 - val_loss: 1.2728 - val_accuracy: 0.4295

Epoch 02011: val_loss did not improve from 1.26707
Epoch 2012/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4306 - val_loss: 1.2744 - val_accuracy: 0.4255

Epoch 02012: val_loss did not improve from 1.26707
Epoch 2013/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4277 - val_loss: 1.2733 - val_accuracy: 0.4311

Epoch 02013: val_loss did not improve from 1.26707
Epoch 2014/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4283 - val_loss: 1.2728 - val_accuracy: 0.4327

Epoch 02014: val_loss did not improve from 1.26707
Epoch 2015/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4307 - val_loss: 1.2724 - val_accuracy: 0.4406

Epoch 02015: val_loss did not improve from 1.26707
Epoch 2016/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4281 - val_loss: 1.2706 - val_accuracy: 0.4382

Epoch 02016: val_loss did not improve from 1.26707
Epoch 2017/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4303 - val_loss: 1.2733 - val_accuracy: 0.4375

Epoch 02017: val_loss did not improve from 1.26707
Epoch 2018/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4256 - val_loss: 1.2770 - val_accuracy: 0.4335

Epoch 02018: val_loss did not improve from 1.26707
Epoch 2019/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4279 - val_loss: 1.2804 - val_accuracy: 0.4215

Epoch 02019: val_loss did not improve from 1.26707
Epoch 2020/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4258 - val_loss: 1.2721 - val_accuracy: 0.4351

Epoch 02020: val_loss did not improve from 1.26707
Epoch 2021/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4282 - val_loss: 1.2754 - val_accuracy: 0.4375

Epoch 02021: val_loss did not improve from 1.26707
Epoch 2022/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4295 - val_loss: 1.2701 - val_accuracy: 0.4398

Epoch 02022: val_loss did not improve from 1.26707
Epoch 2023/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4269 - val_loss: 1.2697 - val_accuracy: 0.4367

Epoch 02023: val_loss did not improve from 1.26707
Epoch 2024/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4289 - val_loss: 1.2751 - val_accuracy: 0.4231

Epoch 02024: val_loss did not improve from 1.26707
Epoch 2025/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4280 - val_loss: 1.2715 - val_accuracy: 0.4207

Epoch 02025: val_loss did not improve from 1.26707
Epoch 2026/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4296 - val_loss: 1.2707 - val_accuracy: 0.4319

Epoch 02026: val_loss did not improve from 1.26707
Epoch 2027/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4273 - val_loss: 1.2707 - val_accuracy: 0.4398

Epoch 02027: val_loss did not improve from 1.26707
Epoch 2028/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4283 - val_loss: 1.2723 - val_accuracy: 0.4271

Epoch 02028: val_loss did not improve from 1.26707
Epoch 2029/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4253 - val_loss: 1.2757 - val_accuracy: 0.4375

Epoch 02029: val_loss did not improve from 1.26707
Epoch 2030/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4236 - val_loss: 1.2693 - val_accuracy: 0.4422

Epoch 02030: val_loss did not improve from 1.26707
Epoch 2031/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4290 - val_loss: 1.2742 - val_accuracy: 0.4375

Epoch 02031: val_loss did not improve from 1.26707
Epoch 2032/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4266 - val_loss: 1.2733 - val_accuracy: 0.4247

Epoch 02032: val_loss did not improve from 1.26707
Epoch 2033/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4290 - val_loss: 1.2695 - val_accuracy: 0.4351

Epoch 02033: val_loss did not improve from 1.26707
Epoch 2034/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4284 - val_loss: 1.2714 - val_accuracy: 0.4303

Epoch 02034: val_loss did not improve from 1.26707
Epoch 2035/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4261 - val_loss: 1.2722 - val_accuracy: 0.4271

Epoch 02035: val_loss did not improve from 1.26707
Epoch 2036/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4290 - val_loss: 1.2737 - val_accuracy: 0.4183

Epoch 02036: val_loss did not improve from 1.26707
Epoch 2037/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4267 - val_loss: 1.2764 - val_accuracy: 0.4215

Epoch 02037: val_loss did not improve from 1.26707
Epoch 2038/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4274 - val_loss: 1.2710 - val_accuracy: 0.4335

Epoch 02038: val_loss did not improve from 1.26707
Epoch 2039/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4291 - val_loss: 1.2689 - val_accuracy: 0.4542

Epoch 02039: val_loss did not improve from 1.26707
Epoch 2040/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4256 - val_loss: 1.2746 - val_accuracy: 0.4351

Epoch 02040: val_loss did not improve from 1.26707
Epoch 2041/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4241 - val_loss: 1.2727 - val_accuracy: 0.4271

Epoch 02041: val_loss did not improve from 1.26707
Epoch 2042/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4294 - val_loss: 1.2761 - val_accuracy: 0.4231

Epoch 02042: val_loss did not improve from 1.26707
Epoch 2043/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4221 - val_loss: 1.2712 - val_accuracy: 0.4335

Epoch 02043: val_loss did not improve from 1.26707
Epoch 2044/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4241 - val_loss: 1.2806 - val_accuracy: 0.4135

Epoch 02044: val_loss did not improve from 1.26707
Epoch 2045/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4229 - val_loss: 1.2766 - val_accuracy: 0.4255

Epoch 02045: val_loss did not improve from 1.26707
Epoch 2046/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4280 - val_loss: 1.2722 - val_accuracy: 0.4335

Epoch 02046: val_loss did not improve from 1.26707
Epoch 2047/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4257 - val_loss: 1.2745 - val_accuracy: 0.4319

Epoch 02047: val_loss did not improve from 1.26707
Epoch 2048/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4276 - val_loss: 1.2694 - val_accuracy: 0.4367

Epoch 02048: val_loss did not improve from 1.26707
Epoch 2049/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4301 - val_loss: 1.2727 - val_accuracy: 0.4367

Epoch 02049: val_loss did not improve from 1.26707
Epoch 2050/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4267 - val_loss: 1.2754 - val_accuracy: 0.4359

Epoch 02050: val_loss did not improve from 1.26707
Epoch 2051/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4245 - val_loss: 1.2739 - val_accuracy: 0.4295

Epoch 02051: val_loss did not improve from 1.26707
Epoch 2052/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4253 - val_loss: 1.2727 - val_accuracy: 0.4343

Epoch 02052: val_loss did not improve from 1.26707
Epoch 2053/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4277 - val_loss: 1.2737 - val_accuracy: 0.4351

Epoch 02053: val_loss did not improve from 1.26707
Epoch 2054/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4271 - val_loss: 1.2794 - val_accuracy: 0.4255

Epoch 02054: val_loss did not improve from 1.26707
Epoch 2055/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4253 - val_loss: 1.2721 - val_accuracy: 0.4303

Epoch 02055: val_loss did not improve from 1.26707
Epoch 2056/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4310 - val_loss: 1.2737 - val_accuracy: 0.4335

Epoch 02056: val_loss did not improve from 1.26707
Epoch 2057/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4268 - val_loss: 1.2702 - val_accuracy: 0.4335

Epoch 02057: val_loss did not improve from 1.26707
Epoch 2058/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4272 - val_loss: 1.2750 - val_accuracy: 0.4191

Epoch 02058: val_loss did not improve from 1.26707
Epoch 2059/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4270 - val_loss: 1.2729 - val_accuracy: 0.4247

Epoch 02059: val_loss did not improve from 1.26707
Epoch 2060/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4283 - val_loss: 1.2740 - val_accuracy: 0.4287

Epoch 02060: val_loss did not improve from 1.26707
Epoch 2061/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4254 - val_loss: 1.2739 - val_accuracy: 0.4223

Epoch 02061: val_loss did not improve from 1.26707
Epoch 2062/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4295 - val_loss: 1.2749 - val_accuracy: 0.4255

Epoch 02062: val_loss did not improve from 1.26707
Epoch 2063/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4279 - val_loss: 1.2729 - val_accuracy: 0.4287

Epoch 02063: val_loss did not improve from 1.26707
Epoch 2064/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4265 - val_loss: 1.2711 - val_accuracy: 0.4414

Epoch 02064: val_loss did not improve from 1.26707
Epoch 2065/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4275 - val_loss: 1.2790 - val_accuracy: 0.4231

Epoch 02065: val_loss did not improve from 1.26707
Epoch 2066/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4298 - val_loss: 1.2716 - val_accuracy: 0.4279

Epoch 02066: val_loss did not improve from 1.26707
Epoch 2067/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4321 - val_loss: 1.2720 - val_accuracy: 0.4375

Epoch 02067: val_loss did not improve from 1.26707
Epoch 2068/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4248 - val_loss: 1.2740 - val_accuracy: 0.4382

Epoch 02068: val_loss did not improve from 1.26707
Epoch 2069/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4271 - val_loss: 1.2703 - val_accuracy: 0.4359

Epoch 02069: val_loss did not improve from 1.26707
Epoch 2070/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4253 - val_loss: 1.2824 - val_accuracy: 0.4207

Epoch 02070: val_loss did not improve from 1.26707
Epoch 2071/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4218 - val_loss: 1.2800 - val_accuracy: 0.4191

Epoch 02071: val_loss did not improve from 1.26707
Epoch 2072/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4264 - val_loss: 1.2741 - val_accuracy: 0.4287

Epoch 02072: val_loss did not improve from 1.26707
Epoch 2073/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4232 - val_loss: 1.2680 - val_accuracy: 0.4446

Epoch 02073: val_loss did not improve from 1.26707
Epoch 2074/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4260 - val_loss: 1.2671 - val_accuracy: 0.4494

Epoch 02074: val_loss did not improve from 1.26707
Epoch 2075/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4278 - val_loss: 1.2693 - val_accuracy: 0.4287

Epoch 02075: val_loss did not improve from 1.26707
Epoch 2076/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4283 - val_loss: 1.2678 - val_accuracy: 0.4406

Epoch 02076: val_loss did not improve from 1.26707
Epoch 2077/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4236 - val_loss: 1.2729 - val_accuracy: 0.4287

Epoch 02077: val_loss did not improve from 1.26707
Epoch 2078/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4289 - val_loss: 1.2767 - val_accuracy: 0.4311

Epoch 02078: val_loss did not improve from 1.26707
Epoch 2079/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4282 - val_loss: 1.2691 - val_accuracy: 0.4382

Epoch 02079: val_loss did not improve from 1.26707
Epoch 2080/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4217 - val_loss: 1.2725 - val_accuracy: 0.4430

Epoch 02080: val_loss did not improve from 1.26707
Epoch 2081/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4253 - val_loss: 1.2720 - val_accuracy: 0.4311

Epoch 02081: val_loss did not improve from 1.26707
Epoch 2082/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4256 - val_loss: 1.2723 - val_accuracy: 0.4327

Epoch 02082: val_loss did not improve from 1.26707
Epoch 2083/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4273 - val_loss: 1.2712 - val_accuracy: 0.4263

Epoch 02083: val_loss did not improve from 1.26707
Epoch 2084/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4279 - val_loss: 1.2747 - val_accuracy: 0.4175

Epoch 02084: val_loss did not improve from 1.26707
Epoch 2085/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4198 - val_loss: 1.2719 - val_accuracy: 0.4263

Epoch 02085: val_loss did not improve from 1.26707
Epoch 2086/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4250 - val_loss: 1.2736 - val_accuracy: 0.4287

Epoch 02086: val_loss did not improve from 1.26707
Epoch 2087/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4284 - val_loss: 1.2749 - val_accuracy: 0.4279

Epoch 02087: val_loss did not improve from 1.26707
Epoch 2088/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4295 - val_loss: 1.2688 - val_accuracy: 0.4375

Epoch 02088: val_loss did not improve from 1.26707
Epoch 2089/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4302 - val_loss: 1.2705 - val_accuracy: 0.4406

Epoch 02089: val_loss did not improve from 1.26707
Epoch 2090/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4265 - val_loss: 1.2718 - val_accuracy: 0.4367

Epoch 02090: val_loss did not improve from 1.26707
Epoch 2091/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4296 - val_loss: 1.2727 - val_accuracy: 0.4303

Epoch 02091: val_loss did not improve from 1.26707
Epoch 2092/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4260 - val_loss: 1.2793 - val_accuracy: 0.4335

Epoch 02092: val_loss did not improve from 1.26707
Epoch 2093/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4246 - val_loss: 1.2714 - val_accuracy: 0.4335

Epoch 02093: val_loss did not improve from 1.26707
Epoch 2094/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4299 - val_loss: 1.2805 - val_accuracy: 0.4151

Epoch 02094: val_loss did not improve from 1.26707
Epoch 2095/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4271 - val_loss: 1.2738 - val_accuracy: 0.4247

Epoch 02095: val_loss did not improve from 1.26707
Epoch 2096/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4243 - val_loss: 1.2704 - val_accuracy: 0.4287

Epoch 02096: val_loss did not improve from 1.26707
Epoch 2097/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4261 - val_loss: 1.2690 - val_accuracy: 0.4382

Epoch 02097: val_loss did not improve from 1.26707
Epoch 2098/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4267 - val_loss: 1.2684 - val_accuracy: 0.4343

Epoch 02098: val_loss did not improve from 1.26707
Epoch 2099/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4282 - val_loss: 1.2713 - val_accuracy: 0.4327

Epoch 02099: val_loss did not improve from 1.26707
Epoch 2100/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4255 - val_loss: 1.2700 - val_accuracy: 0.4462

Epoch 02100: val_loss did not improve from 1.26707
Epoch 2101/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4283 - val_loss: 1.2702 - val_accuracy: 0.4438

Epoch 02101: val_loss did not improve from 1.26707
Epoch 2102/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4275 - val_loss: 1.2742 - val_accuracy: 0.4382

Epoch 02102: val_loss did not improve from 1.26707
Epoch 2103/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4284 - val_loss: 1.2749 - val_accuracy: 0.4359

Epoch 02103: val_loss did not improve from 1.26707
Epoch 2104/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4263 - val_loss: 1.2727 - val_accuracy: 0.4406

Epoch 02104: val_loss did not improve from 1.26707
Epoch 2105/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4298 - val_loss: 1.2693 - val_accuracy: 0.4359

Epoch 02105: val_loss did not improve from 1.26707
Epoch 2106/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4265 - val_loss: 1.2760 - val_accuracy: 0.4287

Epoch 02106: val_loss did not improve from 1.26707
Epoch 2107/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4283 - val_loss: 1.2708 - val_accuracy: 0.4470

Epoch 02107: val_loss did not improve from 1.26707
Epoch 2108/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4247 - val_loss: 1.2735 - val_accuracy: 0.4351

Epoch 02108: val_loss did not improve from 1.26707
Epoch 2109/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4273 - val_loss: 1.2754 - val_accuracy: 0.4223

Epoch 02109: val_loss did not improve from 1.26707
Epoch 2110/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4272 - val_loss: 1.2708 - val_accuracy: 0.4279

Epoch 02110: val_loss did not improve from 1.26707
Epoch 2111/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4261 - val_loss: 1.2735 - val_accuracy: 0.4319

Epoch 02111: val_loss did not improve from 1.26707
Epoch 2112/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4348 - val_loss: 1.2705 - val_accuracy: 0.4359

Epoch 02112: val_loss did not improve from 1.26707
Epoch 2113/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4267 - val_loss: 1.2719 - val_accuracy: 0.4438

Epoch 02113: val_loss did not improve from 1.26707
Epoch 2114/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4271 - val_loss: 1.2722 - val_accuracy: 0.4351

Epoch 02114: val_loss did not improve from 1.26707
Epoch 2115/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4267 - val_loss: 1.2738 - val_accuracy: 0.4271

Epoch 02115: val_loss did not improve from 1.26707
Epoch 2116/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4284 - val_loss: 1.2760 - val_accuracy: 0.4215

Epoch 02116: val_loss did not improve from 1.26707
Epoch 2117/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4266 - val_loss: 1.2721 - val_accuracy: 0.4191

Epoch 02117: val_loss did not improve from 1.26707
Epoch 2118/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4266 - val_loss: 1.2707 - val_accuracy: 0.4406

Epoch 02118: val_loss did not improve from 1.26707
Epoch 2119/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4288 - val_loss: 1.2767 - val_accuracy: 0.4207

Epoch 02119: val_loss did not improve from 1.26707
Epoch 2120/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4281 - val_loss: 1.2752 - val_accuracy: 0.4287

Epoch 02120: val_loss did not improve from 1.26707
Epoch 2121/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4285 - val_loss: 1.2722 - val_accuracy: 0.4390

Epoch 02121: val_loss did not improve from 1.26707
Epoch 2122/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4289 - val_loss: 1.2716 - val_accuracy: 0.4279

Epoch 02122: val_loss did not improve from 1.26707
Epoch 2123/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4282 - val_loss: 1.2718 - val_accuracy: 0.4414

Epoch 02123: val_loss did not improve from 1.26707
Epoch 2124/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4283 - val_loss: 1.2713 - val_accuracy: 0.4398

Epoch 02124: val_loss did not improve from 1.26707
Epoch 2125/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4295 - val_loss: 1.2735 - val_accuracy: 0.4367

Epoch 02125: val_loss did not improve from 1.26707
Epoch 2126/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4318 - val_loss: 1.2720 - val_accuracy: 0.4351

Epoch 02126: val_loss did not improve from 1.26707
Epoch 2127/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4276 - val_loss: 1.2745 - val_accuracy: 0.4303

Epoch 02127: val_loss did not improve from 1.26707
Epoch 2128/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4297 - val_loss: 1.2720 - val_accuracy: 0.4271

Epoch 02128: val_loss did not improve from 1.26707
Epoch 2129/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4270 - val_loss: 1.2733 - val_accuracy: 0.4414

Epoch 02129: val_loss did not improve from 1.26707
Epoch 2130/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4287 - val_loss: 1.2719 - val_accuracy: 0.4359

Epoch 02130: val_loss did not improve from 1.26707
Epoch 2131/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4315 - val_loss: 1.2703 - val_accuracy: 0.4327

Epoch 02131: val_loss did not improve from 1.26707
Epoch 2132/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4268 - val_loss: 1.2728 - val_accuracy: 0.4390

Epoch 02132: val_loss did not improve from 1.26707
Epoch 2133/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4262 - val_loss: 1.2767 - val_accuracy: 0.4279

Epoch 02133: val_loss did not improve from 1.26707
Epoch 2134/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4315 - val_loss: 1.2739 - val_accuracy: 0.4382

Epoch 02134: val_loss did not improve from 1.26707
Epoch 2135/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4290 - val_loss: 1.2732 - val_accuracy: 0.4303

Epoch 02135: val_loss did not improve from 1.26707
Epoch 2136/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4311 - val_loss: 1.2704 - val_accuracy: 0.4359

Epoch 02136: val_loss did not improve from 1.26707
Epoch 2137/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4335 - val_loss: 1.2731 - val_accuracy: 0.4287

Epoch 02137: val_loss did not improve from 1.26707
Epoch 2138/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4265 - val_loss: 1.2736 - val_accuracy: 0.4406

Epoch 02138: val_loss did not improve from 1.26707
Epoch 2139/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4284 - val_loss: 1.2728 - val_accuracy: 0.4375

Epoch 02139: val_loss did not improve from 1.26707
Epoch 2140/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4309 - val_loss: 1.2738 - val_accuracy: 0.4359

Epoch 02140: val_loss did not improve from 1.26707
Epoch 2141/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4283 - val_loss: 1.2711 - val_accuracy: 0.4311

Epoch 02141: val_loss did not improve from 1.26707
Epoch 2142/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4264 - val_loss: 1.2731 - val_accuracy: 0.4398

Epoch 02142: val_loss did not improve from 1.26707
Epoch 2143/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4265 - val_loss: 1.2706 - val_accuracy: 0.4311

Epoch 02143: val_loss did not improve from 1.26707
Epoch 2144/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4284 - val_loss: 1.2730 - val_accuracy: 0.4414

Epoch 02144: val_loss did not improve from 1.26707
Epoch 2145/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4280 - val_loss: 1.2719 - val_accuracy: 0.4367

Epoch 02145: val_loss did not improve from 1.26707
Epoch 2146/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4263 - val_loss: 1.2706 - val_accuracy: 0.4359

Epoch 02146: val_loss did not improve from 1.26707
Epoch 2147/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4280 - val_loss: 1.2688 - val_accuracy: 0.4398

Epoch 02147: val_loss did not improve from 1.26707
Epoch 2148/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4291 - val_loss: 1.2693 - val_accuracy: 0.4414

Epoch 02148: val_loss did not improve from 1.26707
Epoch 2149/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4296 - val_loss: 1.2757 - val_accuracy: 0.4263

Epoch 02149: val_loss did not improve from 1.26707
Epoch 2150/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4296 - val_loss: 1.2771 - val_accuracy: 0.4343

Epoch 02150: val_loss did not improve from 1.26707
Epoch 2151/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4313 - val_loss: 1.2706 - val_accuracy: 0.4351

Epoch 02151: val_loss did not improve from 1.26707
Epoch 2152/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4290 - val_loss: 1.2721 - val_accuracy: 0.4319

Epoch 02152: val_loss did not improve from 1.26707
Epoch 2153/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4280 - val_loss: 1.2710 - val_accuracy: 0.4462

Epoch 02153: val_loss did not improve from 1.26707
Epoch 2154/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4292 - val_loss: 1.2730 - val_accuracy: 0.4414

Epoch 02154: val_loss did not improve from 1.26707
Epoch 2155/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4252 - val_loss: 1.2694 - val_accuracy: 0.4271

Epoch 02155: val_loss did not improve from 1.26707
Epoch 2156/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4280 - val_loss: 1.2716 - val_accuracy: 0.4271

Epoch 02156: val_loss did not improve from 1.26707
Epoch 2157/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4257 - val_loss: 1.2722 - val_accuracy: 0.4279

Epoch 02157: val_loss did not improve from 1.26707
Epoch 2158/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4302 - val_loss: 1.2690 - val_accuracy: 0.4263

Epoch 02158: val_loss did not improve from 1.26707
Epoch 2159/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4260 - val_loss: 1.2721 - val_accuracy: 0.4287

Epoch 02159: val_loss did not improve from 1.26707
Epoch 2160/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4262 - val_loss: 1.2706 - val_accuracy: 0.4279

Epoch 02160: val_loss did not improve from 1.26707
Epoch 2161/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4309 - val_loss: 1.2720 - val_accuracy: 0.4319

Epoch 02161: val_loss did not improve from 1.26707
Epoch 2162/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4289 - val_loss: 1.2739 - val_accuracy: 0.4231

Epoch 02162: val_loss did not improve from 1.26707
Epoch 2163/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4314 - val_loss: 1.2726 - val_accuracy: 0.4295

Epoch 02163: val_loss did not improve from 1.26707
Epoch 2164/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4252 - val_loss: 1.2722 - val_accuracy: 0.4207

Epoch 02164: val_loss did not improve from 1.26707
Epoch 2165/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4289 - val_loss: 1.2710 - val_accuracy: 0.4382

Epoch 02165: val_loss did not improve from 1.26707
Epoch 2166/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4295 - val_loss: 1.2741 - val_accuracy: 0.4295

Epoch 02166: val_loss did not improve from 1.26707
Epoch 2167/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4327 - val_loss: 1.2721 - val_accuracy: 0.4343

Epoch 02167: val_loss did not improve from 1.26707
Epoch 2168/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4270 - val_loss: 1.2746 - val_accuracy: 0.4303

Epoch 02168: val_loss did not improve from 1.26707
Epoch 2169/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4284 - val_loss: 1.2697 - val_accuracy: 0.4335

Epoch 02169: val_loss did not improve from 1.26707
Epoch 2170/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4296 - val_loss: 1.2747 - val_accuracy: 0.4199

Epoch 02170: val_loss did not improve from 1.26707
Epoch 2171/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4233 - val_loss: 1.2699 - val_accuracy: 0.4359

Epoch 02171: val_loss did not improve from 1.26707
Epoch 02171: early stopping
*************************** Fold #: 4 ***************************
Model: "sequential_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_252 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_253 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_254 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_255 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6069 - accuracy: 0.2396 - val_loss: 1.6019 - val_accuracy: 0.2876

Epoch 00001: val_loss improved from inf to 1.60190, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 2/10000
12/12 - 0s - loss: 1.5996 - accuracy: 0.3060 - val_loss: 1.5945 - val_accuracy: 0.3187

Epoch 00002: val_loss improved from 1.60190 to 1.59448, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 3/10000
12/12 - 0s - loss: 1.5913 - accuracy: 0.3327 - val_loss: 1.5829 - val_accuracy: 0.3339

Epoch 00003: val_loss improved from 1.59448 to 1.58286, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 4/10000
12/12 - 0s - loss: 1.5794 - accuracy: 0.3345 - val_loss: 1.5663 - val_accuracy: 0.3386

Epoch 00004: val_loss improved from 1.58286 to 1.56634, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 5/10000
12/12 - 0s - loss: 1.5624 - accuracy: 0.3283 - val_loss: 1.5421 - val_accuracy: 0.3641

Epoch 00005: val_loss improved from 1.56634 to 1.54212, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 6/10000
12/12 - 0s - loss: 1.5379 - accuracy: 0.3537 - val_loss: 1.5115 - val_accuracy: 0.3625

Epoch 00006: val_loss improved from 1.54212 to 1.51149, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 7/10000
12/12 - 0s - loss: 1.5063 - accuracy: 0.3476 - val_loss: 1.4692 - val_accuracy: 0.3649

Epoch 00007: val_loss improved from 1.51149 to 1.46919, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 8/10000
12/12 - 0s - loss: 1.4668 - accuracy: 0.3557 - val_loss: 1.4244 - val_accuracy: 0.3817

Epoch 00008: val_loss improved from 1.46919 to 1.42437, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 9/10000
12/12 - 0s - loss: 1.4268 - accuracy: 0.3623 - val_loss: 1.3815 - val_accuracy: 0.3976

Epoch 00009: val_loss improved from 1.42437 to 1.38153, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 10/10000
12/12 - 0s - loss: 1.3935 - accuracy: 0.3852 - val_loss: 1.3533 - val_accuracy: 0.4000

Epoch 00010: val_loss improved from 1.38153 to 1.35331, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 11/10000
12/12 - 0s - loss: 1.3702 - accuracy: 0.3742 - val_loss: 1.3391 - val_accuracy: 0.3825

Epoch 00011: val_loss improved from 1.35331 to 1.33912, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 12/10000
12/12 - 0s - loss: 1.3554 - accuracy: 0.3813 - val_loss: 1.3206 - val_accuracy: 0.3976

Epoch 00012: val_loss improved from 1.33912 to 1.32058, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 13/10000
12/12 - 0s - loss: 1.3472 - accuracy: 0.3869 - val_loss: 1.3260 - val_accuracy: 0.3793

Epoch 00013: val_loss did not improve from 1.32058
Epoch 14/10000
12/12 - 0s - loss: 1.3439 - accuracy: 0.3849 - val_loss: 1.3130 - val_accuracy: 0.3865

Epoch 00014: val_loss improved from 1.32058 to 1.31297, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 15/10000
12/12 - 0s - loss: 1.3403 - accuracy: 0.3901 - val_loss: 1.3110 - val_accuracy: 0.3952

Epoch 00015: val_loss improved from 1.31297 to 1.31104, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 16/10000
12/12 - 0s - loss: 1.3380 - accuracy: 0.3904 - val_loss: 1.3127 - val_accuracy: 0.3920

Epoch 00016: val_loss did not improve from 1.31104
Epoch 17/10000
12/12 - 0s - loss: 1.3371 - accuracy: 0.3906 - val_loss: 1.3099 - val_accuracy: 0.3944

Epoch 00017: val_loss improved from 1.31104 to 1.30995, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 18/10000
12/12 - 0s - loss: 1.3370 - accuracy: 0.3850 - val_loss: 1.3112 - val_accuracy: 0.3936

Epoch 00018: val_loss did not improve from 1.30995
Epoch 19/10000
12/12 - 0s - loss: 1.3355 - accuracy: 0.3865 - val_loss: 1.3099 - val_accuracy: 0.3880

Epoch 00019: val_loss improved from 1.30995 to 1.30993, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 20/10000
12/12 - 0s - loss: 1.3383 - accuracy: 0.3853 - val_loss: 1.3216 - val_accuracy: 0.3849

Epoch 00020: val_loss did not improve from 1.30993
Epoch 21/10000
12/12 - 0s - loss: 1.3374 - accuracy: 0.3869 - val_loss: 1.3138 - val_accuracy: 0.3896

Epoch 00021: val_loss did not improve from 1.30993
Epoch 22/10000
12/12 - 0s - loss: 1.3418 - accuracy: 0.3845 - val_loss: 1.3124 - val_accuracy: 0.4032

Epoch 00022: val_loss did not improve from 1.30993
Epoch 23/10000
12/12 - 0s - loss: 1.3357 - accuracy: 0.3925 - val_loss: 1.3124 - val_accuracy: 0.3849

Epoch 00023: val_loss did not improve from 1.30993
Epoch 24/10000
12/12 - 0s - loss: 1.3338 - accuracy: 0.3939 - val_loss: 1.3075 - val_accuracy: 0.4032

Epoch 00024: val_loss improved from 1.30993 to 1.30752, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 25/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3889 - val_loss: 1.3170 - val_accuracy: 0.3841

Epoch 00025: val_loss did not improve from 1.30752
Epoch 26/10000
12/12 - 0s - loss: 1.3359 - accuracy: 0.3866 - val_loss: 1.3114 - val_accuracy: 0.3904

Epoch 00026: val_loss did not improve from 1.30752
Epoch 27/10000
12/12 - 0s - loss: 1.3345 - accuracy: 0.3850 - val_loss: 1.3080 - val_accuracy: 0.4000

Epoch 00027: val_loss did not improve from 1.30752
Epoch 28/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3922 - val_loss: 1.3119 - val_accuracy: 0.3849

Epoch 00028: val_loss did not improve from 1.30752
Epoch 29/10000
12/12 - 0s - loss: 1.3339 - accuracy: 0.3976 - val_loss: 1.3089 - val_accuracy: 0.3968

Epoch 00029: val_loss did not improve from 1.30752
Epoch 30/10000
12/12 - 0s - loss: 1.3328 - accuracy: 0.3980 - val_loss: 1.3108 - val_accuracy: 0.3888

Epoch 00030: val_loss did not improve from 1.30752
Epoch 31/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3882 - val_loss: 1.3077 - val_accuracy: 0.3912

Epoch 00031: val_loss did not improve from 1.30752
Epoch 32/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3879 - val_loss: 1.3092 - val_accuracy: 0.4000

Epoch 00032: val_loss did not improve from 1.30752
Epoch 33/10000
12/12 - 0s - loss: 1.3321 - accuracy: 0.3957 - val_loss: 1.3121 - val_accuracy: 0.3825

Epoch 00033: val_loss did not improve from 1.30752
Epoch 34/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3867 - val_loss: 1.3079 - val_accuracy: 0.3944

Epoch 00034: val_loss did not improve from 1.30752
Epoch 35/10000
12/12 - 0s - loss: 1.3333 - accuracy: 0.3897 - val_loss: 1.3083 - val_accuracy: 0.4008

Epoch 00035: val_loss did not improve from 1.30752
Epoch 36/10000
12/12 - 0s - loss: 1.3322 - accuracy: 0.3940 - val_loss: 1.3063 - val_accuracy: 0.3888

Epoch 00036: val_loss improved from 1.30752 to 1.30628, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 37/10000
12/12 - 0s - loss: 1.3318 - accuracy: 0.3881 - val_loss: 1.3117 - val_accuracy: 0.3888

Epoch 00037: val_loss did not improve from 1.30628
Epoch 38/10000
12/12 - 0s - loss: 1.3327 - accuracy: 0.3929 - val_loss: 1.3101 - val_accuracy: 0.3880

Epoch 00038: val_loss did not improve from 1.30628
Epoch 39/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.3911 - val_loss: 1.3102 - val_accuracy: 0.3944

Epoch 00039: val_loss did not improve from 1.30628
Epoch 40/10000
12/12 - 0s - loss: 1.3310 - accuracy: 0.3915 - val_loss: 1.3128 - val_accuracy: 0.3857

Epoch 00040: val_loss did not improve from 1.30628
Epoch 41/10000
12/12 - 0s - loss: 1.3339 - accuracy: 0.3887 - val_loss: 1.3074 - val_accuracy: 0.4088

Epoch 00041: val_loss did not improve from 1.30628
Epoch 42/10000
12/12 - 0s - loss: 1.3314 - accuracy: 0.3943 - val_loss: 1.3103 - val_accuracy: 0.3785

Epoch 00042: val_loss did not improve from 1.30628
Epoch 43/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3912 - val_loss: 1.3074 - val_accuracy: 0.3880

Epoch 00043: val_loss did not improve from 1.30628
Epoch 44/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3924 - val_loss: 1.3122 - val_accuracy: 0.3833

Epoch 00044: val_loss did not improve from 1.30628
Epoch 45/10000
12/12 - 0s - loss: 1.3314 - accuracy: 0.3942 - val_loss: 1.3097 - val_accuracy: 0.3976

Epoch 00045: val_loss did not improve from 1.30628
Epoch 46/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3945 - val_loss: 1.3072 - val_accuracy: 0.3880

Epoch 00046: val_loss did not improve from 1.30628
Epoch 47/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3888 - val_loss: 1.3080 - val_accuracy: 0.3801

Epoch 00047: val_loss did not improve from 1.30628
Epoch 48/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3981 - val_loss: 1.3064 - val_accuracy: 0.3976

Epoch 00048: val_loss did not improve from 1.30628
Epoch 49/10000
12/12 - 0s - loss: 1.3307 - accuracy: 0.4016 - val_loss: 1.3127 - val_accuracy: 0.3849

Epoch 00049: val_loss did not improve from 1.30628
Epoch 50/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3958 - val_loss: 1.3052 - val_accuracy: 0.4080

Epoch 00050: val_loss improved from 1.30628 to 1.30523, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 51/10000
12/12 - 0s - loss: 1.3301 - accuracy: 0.3942 - val_loss: 1.3067 - val_accuracy: 0.3936

Epoch 00051: val_loss did not improve from 1.30523
Epoch 52/10000
12/12 - 0s - loss: 1.3311 - accuracy: 0.3911 - val_loss: 1.3110 - val_accuracy: 0.3952

Epoch 00052: val_loss did not improve from 1.30523
Epoch 53/10000
12/12 - 0s - loss: 1.3300 - accuracy: 0.3955 - val_loss: 1.3083 - val_accuracy: 0.3904

Epoch 00053: val_loss did not improve from 1.30523
Epoch 54/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3872 - val_loss: 1.3081 - val_accuracy: 0.3920

Epoch 00054: val_loss did not improve from 1.30523
Epoch 55/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3911 - val_loss: 1.3123 - val_accuracy: 0.3801

Epoch 00055: val_loss did not improve from 1.30523
Epoch 56/10000
12/12 - 0s - loss: 1.3311 - accuracy: 0.3975 - val_loss: 1.3178 - val_accuracy: 0.3777

Epoch 00056: val_loss did not improve from 1.30523
Epoch 57/10000
12/12 - 0s - loss: 1.3402 - accuracy: 0.3853 - val_loss: 1.3084 - val_accuracy: 0.4096

Epoch 00057: val_loss did not improve from 1.30523
Epoch 58/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3892 - val_loss: 1.3094 - val_accuracy: 0.3904

Epoch 00058: val_loss did not improve from 1.30523
Epoch 59/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3981 - val_loss: 1.3129 - val_accuracy: 0.3865

Epoch 00059: val_loss did not improve from 1.30523
Epoch 60/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3888 - val_loss: 1.3092 - val_accuracy: 0.4000

Epoch 00060: val_loss did not improve from 1.30523
Epoch 61/10000
12/12 - 0s - loss: 1.3307 - accuracy: 0.4002 - val_loss: 1.3113 - val_accuracy: 0.3912

Epoch 00061: val_loss did not improve from 1.30523
Epoch 62/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3949 - val_loss: 1.3063 - val_accuracy: 0.3968

Epoch 00062: val_loss did not improve from 1.30523
Epoch 63/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3938 - val_loss: 1.3068 - val_accuracy: 0.3976

Epoch 00063: val_loss did not improve from 1.30523
Epoch 64/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3942 - val_loss: 1.3053 - val_accuracy: 0.3952

Epoch 00064: val_loss did not improve from 1.30523
Epoch 65/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3973 - val_loss: 1.3178 - val_accuracy: 0.3825

Epoch 00065: val_loss did not improve from 1.30523
Epoch 66/10000
12/12 - 0s - loss: 1.3339 - accuracy: 0.3907 - val_loss: 1.3067 - val_accuracy: 0.4040

Epoch 00066: val_loss did not improve from 1.30523
Epoch 67/10000
12/12 - 0s - loss: 1.3309 - accuracy: 0.3935 - val_loss: 1.3062 - val_accuracy: 0.3896

Epoch 00067: val_loss did not improve from 1.30523
Epoch 68/10000
12/12 - 0s - loss: 1.3282 - accuracy: 0.3964 - val_loss: 1.3068 - val_accuracy: 0.3984

Epoch 00068: val_loss did not improve from 1.30523
Epoch 69/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3993 - val_loss: 1.3057 - val_accuracy: 0.3984

Epoch 00069: val_loss did not improve from 1.30523
Epoch 70/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3997 - val_loss: 1.3047 - val_accuracy: 0.3936

Epoch 00070: val_loss improved from 1.30523 to 1.30470, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 71/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3884 - val_loss: 1.3066 - val_accuracy: 0.3936

Epoch 00071: val_loss did not improve from 1.30470
Epoch 72/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3822 - val_loss: 1.3053 - val_accuracy: 0.3888

Epoch 00072: val_loss did not improve from 1.30470
Epoch 73/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.4006 - val_loss: 1.3066 - val_accuracy: 0.3936

Epoch 00073: val_loss did not improve from 1.30470
Epoch 74/10000
12/12 - 0s - loss: 1.3284 - accuracy: 0.4000 - val_loss: 1.3082 - val_accuracy: 0.3849

Epoch 00074: val_loss did not improve from 1.30470
Epoch 75/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3878 - val_loss: 1.3053 - val_accuracy: 0.3920

Epoch 00075: val_loss did not improve from 1.30470
Epoch 76/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3977 - val_loss: 1.3093 - val_accuracy: 0.3952

Epoch 00076: val_loss did not improve from 1.30470
Epoch 77/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3976 - val_loss: 1.3032 - val_accuracy: 0.3968

Epoch 00077: val_loss improved from 1.30470 to 1.30315, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 78/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3967 - val_loss: 1.3027 - val_accuracy: 0.4016

Epoch 00078: val_loss improved from 1.30315 to 1.30271, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 79/10000
12/12 - 0s - loss: 1.3276 - accuracy: 0.3957 - val_loss: 1.3053 - val_accuracy: 0.3984

Epoch 00079: val_loss did not improve from 1.30271
Epoch 80/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3975 - val_loss: 1.3076 - val_accuracy: 0.3857

Epoch 00080: val_loss did not improve from 1.30271
Epoch 81/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3861 - val_loss: 1.3067 - val_accuracy: 0.3920

Epoch 00081: val_loss did not improve from 1.30271
Epoch 82/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3875 - val_loss: 1.3038 - val_accuracy: 0.4024

Epoch 00082: val_loss did not improve from 1.30271
Epoch 83/10000
12/12 - 0s - loss: 1.3299 - accuracy: 0.3974 - val_loss: 1.3044 - val_accuracy: 0.4000

Epoch 00083: val_loss did not improve from 1.30271
Epoch 84/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.4019 - val_loss: 1.3081 - val_accuracy: 0.3888

Epoch 00084: val_loss did not improve from 1.30271
Epoch 85/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3965 - val_loss: 1.3038 - val_accuracy: 0.4008

Epoch 00085: val_loss did not improve from 1.30271
Epoch 86/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.4002 - val_loss: 1.3030 - val_accuracy: 0.3960

Epoch 00086: val_loss did not improve from 1.30271
Epoch 87/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.4035 - val_loss: 1.3080 - val_accuracy: 0.3952

Epoch 00087: val_loss did not improve from 1.30271
Epoch 88/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3964 - val_loss: 1.3035 - val_accuracy: 0.3841

Epoch 00088: val_loss did not improve from 1.30271
Epoch 89/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3996 - val_loss: 1.3032 - val_accuracy: 0.4024

Epoch 00089: val_loss did not improve from 1.30271
Epoch 90/10000
12/12 - 0s - loss: 1.3284 - accuracy: 0.4027 - val_loss: 1.3104 - val_accuracy: 0.3865

Epoch 00090: val_loss did not improve from 1.30271
Epoch 91/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.4025 - val_loss: 1.3066 - val_accuracy: 0.3928

Epoch 00091: val_loss did not improve from 1.30271
Epoch 92/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3876 - val_loss: 1.3053 - val_accuracy: 0.3944

Epoch 00092: val_loss did not improve from 1.30271
Epoch 93/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3941 - val_loss: 1.3150 - val_accuracy: 0.3880

Epoch 00093: val_loss did not improve from 1.30271
Epoch 94/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3962 - val_loss: 1.3034 - val_accuracy: 0.3936

Epoch 00094: val_loss did not improve from 1.30271
Epoch 95/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3979 - val_loss: 1.3028 - val_accuracy: 0.4008

Epoch 00095: val_loss did not improve from 1.30271
Epoch 96/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.4011 - val_loss: 1.3085 - val_accuracy: 0.3865

Epoch 00096: val_loss did not improve from 1.30271
Epoch 97/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3950 - val_loss: 1.3033 - val_accuracy: 0.3912

Epoch 00097: val_loss did not improve from 1.30271
Epoch 98/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3960 - val_loss: 1.3040 - val_accuracy: 0.3857

Epoch 00098: val_loss did not improve from 1.30271
Epoch 99/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3970 - val_loss: 1.3067 - val_accuracy: 0.3849

Epoch 00099: val_loss did not improve from 1.30271
Epoch 100/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3942 - val_loss: 1.3026 - val_accuracy: 0.4000

Epoch 00100: val_loss improved from 1.30271 to 1.30258, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 101/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3986 - val_loss: 1.3025 - val_accuracy: 0.3904

Epoch 00101: val_loss improved from 1.30258 to 1.30253, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 102/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3948 - val_loss: 1.3055 - val_accuracy: 0.3857

Epoch 00102: val_loss did not improve from 1.30253
Epoch 103/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3942 - val_loss: 1.3063 - val_accuracy: 0.3865

Epoch 00103: val_loss did not improve from 1.30253
Epoch 104/10000
12/12 - 0s - loss: 1.3257 - accuracy: 0.4027 - val_loss: 1.3028 - val_accuracy: 0.3833

Epoch 00104: val_loss did not improve from 1.30253
Epoch 105/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3949 - val_loss: 1.3055 - val_accuracy: 0.3920

Epoch 00105: val_loss did not improve from 1.30253
Epoch 106/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3963 - val_loss: 1.3075 - val_accuracy: 0.3833

Epoch 00106: val_loss did not improve from 1.30253
Epoch 107/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3918 - val_loss: 1.3021 - val_accuracy: 0.3960

Epoch 00107: val_loss improved from 1.30253 to 1.30215, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 108/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3973 - val_loss: 1.3025 - val_accuracy: 0.4048

Epoch 00108: val_loss did not improve from 1.30215
Epoch 109/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3953 - val_loss: 1.3042 - val_accuracy: 0.3968

Epoch 00109: val_loss did not improve from 1.30215
Epoch 110/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3970 - val_loss: 1.3035 - val_accuracy: 0.3904

Epoch 00110: val_loss did not improve from 1.30215
Epoch 111/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3934 - val_loss: 1.3047 - val_accuracy: 0.3880

Epoch 00111: val_loss did not improve from 1.30215
Epoch 112/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3910 - val_loss: 1.3030 - val_accuracy: 0.3904

Epoch 00112: val_loss did not improve from 1.30215
Epoch 113/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3982 - val_loss: 1.3033 - val_accuracy: 0.4000

Epoch 00113: val_loss did not improve from 1.30215
Epoch 114/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.4024 - val_loss: 1.3050 - val_accuracy: 0.3833

Epoch 00114: val_loss did not improve from 1.30215
Epoch 115/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3946 - val_loss: 1.3001 - val_accuracy: 0.4008

Epoch 00115: val_loss improved from 1.30215 to 1.30012, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 116/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3977 - val_loss: 1.3049 - val_accuracy: 0.3928

Epoch 00116: val_loss did not improve from 1.30012
Epoch 117/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.4030 - val_loss: 1.3035 - val_accuracy: 0.3984

Epoch 00117: val_loss did not improve from 1.30012
Epoch 118/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3960 - val_loss: 1.3044 - val_accuracy: 0.3920

Epoch 00118: val_loss did not improve from 1.30012
Epoch 119/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.4002 - val_loss: 1.3032 - val_accuracy: 0.3952

Epoch 00119: val_loss did not improve from 1.30012
Epoch 120/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3985 - val_loss: 1.3062 - val_accuracy: 0.3888

Epoch 00120: val_loss did not improve from 1.30012
Epoch 121/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3981 - val_loss: 1.3001 - val_accuracy: 0.4000

Epoch 00121: val_loss improved from 1.30012 to 1.30006, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 122/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.4009 - val_loss: 1.3026 - val_accuracy: 0.3992

Epoch 00122: val_loss did not improve from 1.30006
Epoch 123/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.4012 - val_loss: 1.3037 - val_accuracy: 0.3904

Epoch 00123: val_loss did not improve from 1.30006
Epoch 124/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3928 - val_loss: 1.3107 - val_accuracy: 0.3825

Epoch 00124: val_loss did not improve from 1.30006
Epoch 125/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3905 - val_loss: 1.3018 - val_accuracy: 0.4000

Epoch 00125: val_loss did not improve from 1.30006
Epoch 126/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3982 - val_loss: 1.3075 - val_accuracy: 0.3960

Epoch 00126: val_loss did not improve from 1.30006
Epoch 127/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3998 - val_loss: 1.3025 - val_accuracy: 0.3960

Epoch 00127: val_loss did not improve from 1.30006
Epoch 128/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3961 - val_loss: 1.3002 - val_accuracy: 0.3984

Epoch 00128: val_loss did not improve from 1.30006
Epoch 129/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.4053 - val_loss: 1.3064 - val_accuracy: 0.3880

Epoch 00129: val_loss did not improve from 1.30006
Epoch 130/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3986 - val_loss: 1.3045 - val_accuracy: 0.3952

Epoch 00130: val_loss did not improve from 1.30006
Epoch 131/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3867 - val_loss: 1.3022 - val_accuracy: 0.3960

Epoch 00131: val_loss did not improve from 1.30006
Epoch 132/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3971 - val_loss: 1.3037 - val_accuracy: 0.3904

Epoch 00132: val_loss did not improve from 1.30006
Epoch 133/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.4000 - val_loss: 1.3067 - val_accuracy: 0.3865

Epoch 00133: val_loss did not improve from 1.30006
Epoch 134/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3958 - val_loss: 1.3037 - val_accuracy: 0.3857

Epoch 00134: val_loss did not improve from 1.30006
Epoch 135/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3967 - val_loss: 1.3016 - val_accuracy: 0.4040

Epoch 00135: val_loss did not improve from 1.30006
Epoch 136/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.4021 - val_loss: 1.3010 - val_accuracy: 0.4000

Epoch 00136: val_loss did not improve from 1.30006
Epoch 137/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3982 - val_loss: 1.3119 - val_accuracy: 0.3880

Epoch 00137: val_loss did not improve from 1.30006
Epoch 138/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3966 - val_loss: 1.3018 - val_accuracy: 0.3976

Epoch 00138: val_loss did not improve from 1.30006
Epoch 139/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3975 - val_loss: 1.3014 - val_accuracy: 0.3873

Epoch 00139: val_loss did not improve from 1.30006
Epoch 140/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.4004 - val_loss: 1.3029 - val_accuracy: 0.3880

Epoch 00140: val_loss did not improve from 1.30006
Epoch 141/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.4023 - val_loss: 1.3032 - val_accuracy: 0.3920

Epoch 00141: val_loss did not improve from 1.30006
Epoch 142/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.4015 - val_loss: 1.3029 - val_accuracy: 0.3896

Epoch 00142: val_loss did not improve from 1.30006
Epoch 143/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3977 - val_loss: 1.3021 - val_accuracy: 0.3873

Epoch 00143: val_loss did not improve from 1.30006
Epoch 144/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3934 - val_loss: 1.3019 - val_accuracy: 0.3920

Epoch 00144: val_loss did not improve from 1.30006
Epoch 145/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3996 - val_loss: 1.3056 - val_accuracy: 0.3880

Epoch 00145: val_loss did not improve from 1.30006
Epoch 146/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.4013 - val_loss: 1.3011 - val_accuracy: 0.3984

Epoch 00146: val_loss did not improve from 1.30006
Epoch 147/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.4023 - val_loss: 1.3044 - val_accuracy: 0.3825

Epoch 00147: val_loss did not improve from 1.30006
Epoch 148/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3951 - val_loss: 1.3007 - val_accuracy: 0.3976

Epoch 00148: val_loss did not improve from 1.30006
Epoch 149/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3971 - val_loss: 1.3055 - val_accuracy: 0.3833

Epoch 00149: val_loss did not improve from 1.30006
Epoch 150/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3978 - val_loss: 1.3016 - val_accuracy: 0.3960

Epoch 00150: val_loss did not improve from 1.30006
Epoch 151/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3966 - val_loss: 1.2993 - val_accuracy: 0.4024

Epoch 00151: val_loss improved from 1.30006 to 1.29928, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 152/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.4018 - val_loss: 1.3070 - val_accuracy: 0.3873

Epoch 00152: val_loss did not improve from 1.29928
Epoch 153/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3965 - val_loss: 1.3025 - val_accuracy: 0.4072

Epoch 00153: val_loss did not improve from 1.29928
Epoch 154/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.4000 - val_loss: 1.3024 - val_accuracy: 0.4032

Epoch 00154: val_loss did not improve from 1.29928
Epoch 155/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.4001 - val_loss: 1.3031 - val_accuracy: 0.3984

Epoch 00155: val_loss did not improve from 1.29928
Epoch 156/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3915 - val_loss: 1.3006 - val_accuracy: 0.3920

Epoch 00156: val_loss did not improve from 1.29928
Epoch 157/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.4024 - val_loss: 1.3015 - val_accuracy: 0.3976

Epoch 00157: val_loss did not improve from 1.29928
Epoch 158/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.4014 - val_loss: 1.3024 - val_accuracy: 0.4016

Epoch 00158: val_loss did not improve from 1.29928
Epoch 159/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3989 - val_loss: 1.3040 - val_accuracy: 0.3817

Epoch 00159: val_loss did not improve from 1.29928
Epoch 160/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.4027 - val_loss: 1.3043 - val_accuracy: 0.3888

Epoch 00160: val_loss did not improve from 1.29928
Epoch 161/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3984 - val_loss: 1.3039 - val_accuracy: 0.3833

Epoch 00161: val_loss did not improve from 1.29928
Epoch 162/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3946 - val_loss: 1.3015 - val_accuracy: 0.4024

Epoch 00162: val_loss did not improve from 1.29928
Epoch 163/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3988 - val_loss: 1.3043 - val_accuracy: 0.3888

Epoch 00163: val_loss did not improve from 1.29928
Epoch 164/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3945 - val_loss: 1.3003 - val_accuracy: 0.3968

Epoch 00164: val_loss did not improve from 1.29928
Epoch 165/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.4008 - val_loss: 1.3038 - val_accuracy: 0.3809

Epoch 00165: val_loss did not improve from 1.29928
Epoch 166/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3986 - val_loss: 1.3037 - val_accuracy: 0.3793

Epoch 00166: val_loss did not improve from 1.29928
Epoch 167/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3922 - val_loss: 1.3033 - val_accuracy: 0.3888

Epoch 00167: val_loss did not improve from 1.29928
Epoch 168/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.4000 - val_loss: 1.3043 - val_accuracy: 0.3928

Epoch 00168: val_loss did not improve from 1.29928
Epoch 169/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.4001 - val_loss: 1.2992 - val_accuracy: 0.3968

Epoch 00169: val_loss improved from 1.29928 to 1.29918, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 170/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.4028 - val_loss: 1.3013 - val_accuracy: 0.3912

Epoch 00170: val_loss did not improve from 1.29918
Epoch 171/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.4024 - val_loss: 1.3049 - val_accuracy: 0.3952

Epoch 00171: val_loss did not improve from 1.29918
Epoch 172/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3984 - val_loss: 1.3028 - val_accuracy: 0.3833

Epoch 00172: val_loss did not improve from 1.29918
Epoch 173/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.4010 - val_loss: 1.3011 - val_accuracy: 0.3896

Epoch 00173: val_loss did not improve from 1.29918
Epoch 174/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.4023 - val_loss: 1.3016 - val_accuracy: 0.3952

Epoch 00174: val_loss did not improve from 1.29918
Epoch 175/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.4042 - val_loss: 1.3001 - val_accuracy: 0.3920

Epoch 00175: val_loss did not improve from 1.29918
Epoch 176/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.4012 - val_loss: 1.3050 - val_accuracy: 0.3888

Epoch 00176: val_loss did not improve from 1.29918
Epoch 177/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.4030 - val_loss: 1.3034 - val_accuracy: 0.3809

Epoch 00177: val_loss did not improve from 1.29918
Epoch 178/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.4023 - val_loss: 1.2992 - val_accuracy: 0.3952

Epoch 00178: val_loss did not improve from 1.29918
Epoch 179/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3981 - val_loss: 1.3012 - val_accuracy: 0.3857

Epoch 00179: val_loss did not improve from 1.29918
Epoch 180/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.4024 - val_loss: 1.3022 - val_accuracy: 0.3896

Epoch 00180: val_loss did not improve from 1.29918
Epoch 181/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.4018 - val_loss: 1.3040 - val_accuracy: 0.3888

Epoch 00181: val_loss did not improve from 1.29918
Epoch 182/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3964 - val_loss: 1.2984 - val_accuracy: 0.4032

Epoch 00182: val_loss improved from 1.29918 to 1.29837, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 183/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.4013 - val_loss: 1.2993 - val_accuracy: 0.3968

Epoch 00183: val_loss did not improve from 1.29837
Epoch 184/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3981 - val_loss: 1.3035 - val_accuracy: 0.3769

Epoch 00184: val_loss did not improve from 1.29837
Epoch 185/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.4027 - val_loss: 1.3000 - val_accuracy: 0.4000

Epoch 00185: val_loss did not improve from 1.29837
Epoch 186/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.4023 - val_loss: 1.3014 - val_accuracy: 0.3944

Epoch 00186: val_loss did not improve from 1.29837
Epoch 187/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3991 - val_loss: 1.3016 - val_accuracy: 0.4000

Epoch 00187: val_loss did not improve from 1.29837
Epoch 188/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3994 - val_loss: 1.3037 - val_accuracy: 0.3841

Epoch 00188: val_loss did not improve from 1.29837
Epoch 189/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.4015 - val_loss: 1.3011 - val_accuracy: 0.3849

Epoch 00189: val_loss did not improve from 1.29837
Epoch 190/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.4028 - val_loss: 1.2986 - val_accuracy: 0.4000

Epoch 00190: val_loss did not improve from 1.29837
Epoch 191/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.4034 - val_loss: 1.3013 - val_accuracy: 0.3984

Epoch 00191: val_loss did not improve from 1.29837
Epoch 192/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3989 - val_loss: 1.3024 - val_accuracy: 0.3817

Epoch 00192: val_loss did not improve from 1.29837
Epoch 193/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3904 - val_loss: 1.2979 - val_accuracy: 0.3912

Epoch 00193: val_loss improved from 1.29837 to 1.29789, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 194/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3985 - val_loss: 1.3020 - val_accuracy: 0.3912

Epoch 00194: val_loss did not improve from 1.29789
Epoch 195/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.4015 - val_loss: 1.3006 - val_accuracy: 0.3920

Epoch 00195: val_loss did not improve from 1.29789
Epoch 196/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3954 - val_loss: 1.3009 - val_accuracy: 0.3888

Epoch 00196: val_loss did not improve from 1.29789
Epoch 197/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3951 - val_loss: 1.3002 - val_accuracy: 0.3873

Epoch 00197: val_loss did not improve from 1.29789
Epoch 198/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3976 - val_loss: 1.3001 - val_accuracy: 0.3952

Epoch 00198: val_loss did not improve from 1.29789
Epoch 199/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.4027 - val_loss: 1.3003 - val_accuracy: 0.3936

Epoch 00199: val_loss did not improve from 1.29789
Epoch 200/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.4003 - val_loss: 1.3004 - val_accuracy: 0.3880

Epoch 00200: val_loss did not improve from 1.29789
Epoch 201/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.4043 - val_loss: 1.2994 - val_accuracy: 0.4000

Epoch 00201: val_loss did not improve from 1.29789
Epoch 202/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.4003 - val_loss: 1.2984 - val_accuracy: 0.4032

Epoch 00202: val_loss did not improve from 1.29789
Epoch 203/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.4015 - val_loss: 1.3043 - val_accuracy: 0.3817

Epoch 00203: val_loss did not improve from 1.29789
Epoch 204/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.4010 - val_loss: 1.3015 - val_accuracy: 0.3817

Epoch 00204: val_loss did not improve from 1.29789
Epoch 205/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3975 - val_loss: 1.2993 - val_accuracy: 0.3992

Epoch 00205: val_loss did not improve from 1.29789
Epoch 206/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.4008 - val_loss: 1.3009 - val_accuracy: 0.3984

Epoch 00206: val_loss did not improve from 1.29789
Epoch 207/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.4010 - val_loss: 1.3005 - val_accuracy: 0.3857

Epoch 00207: val_loss did not improve from 1.29789
Epoch 208/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.4033 - val_loss: 1.3009 - val_accuracy: 0.3880

Epoch 00208: val_loss did not improve from 1.29789
Epoch 209/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.4036 - val_loss: 1.3051 - val_accuracy: 0.3809

Epoch 00209: val_loss did not improve from 1.29789
Epoch 210/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3932 - val_loss: 1.2992 - val_accuracy: 0.3904

Epoch 00210: val_loss did not improve from 1.29789
Epoch 211/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4022 - val_loss: 1.3008 - val_accuracy: 0.3920

Epoch 00211: val_loss did not improve from 1.29789
Epoch 212/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.4012 - val_loss: 1.3005 - val_accuracy: 0.3865

Epoch 00212: val_loss did not improve from 1.29789
Epoch 213/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.4022 - val_loss: 1.3003 - val_accuracy: 0.3793

Epoch 00213: val_loss did not improve from 1.29789
Epoch 214/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.4044 - val_loss: 1.2990 - val_accuracy: 0.3865

Epoch 00214: val_loss did not improve from 1.29789
Epoch 215/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4050 - val_loss: 1.3004 - val_accuracy: 0.3857

Epoch 00215: val_loss did not improve from 1.29789
Epoch 216/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.4002 - val_loss: 1.3020 - val_accuracy: 0.3777

Epoch 00216: val_loss did not improve from 1.29789
Epoch 217/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.4026 - val_loss: 1.2999 - val_accuracy: 0.3992

Epoch 00217: val_loss did not improve from 1.29789
Epoch 218/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.4087 - val_loss: 1.2987 - val_accuracy: 0.3920

Epoch 00218: val_loss did not improve from 1.29789
Epoch 219/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.4040 - val_loss: 1.3039 - val_accuracy: 0.3912

Epoch 00219: val_loss did not improve from 1.29789
Epoch 220/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4035 - val_loss: 1.2996 - val_accuracy: 0.3801

Epoch 00220: val_loss did not improve from 1.29789
Epoch 221/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.4017 - val_loss: 1.2995 - val_accuracy: 0.4024

Epoch 00221: val_loss did not improve from 1.29789
Epoch 222/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.4007 - val_loss: 1.3018 - val_accuracy: 0.3968

Epoch 00222: val_loss did not improve from 1.29789
Epoch 223/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.4035 - val_loss: 1.3022 - val_accuracy: 0.3873

Epoch 00223: val_loss did not improve from 1.29789
Epoch 224/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4035 - val_loss: 1.2995 - val_accuracy: 0.3936

Epoch 00224: val_loss did not improve from 1.29789
Epoch 225/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.4046 - val_loss: 1.2994 - val_accuracy: 0.3841

Epoch 00225: val_loss did not improve from 1.29789
Epoch 226/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4016 - val_loss: 1.2999 - val_accuracy: 0.4000

Epoch 00226: val_loss did not improve from 1.29789
Epoch 227/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.4018 - val_loss: 1.3068 - val_accuracy: 0.3896

Epoch 00227: val_loss did not improve from 1.29789
Epoch 228/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4005 - val_loss: 1.2995 - val_accuracy: 0.3849

Epoch 00228: val_loss did not improve from 1.29789
Epoch 229/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3987 - val_loss: 1.2981 - val_accuracy: 0.4000

Epoch 00229: val_loss did not improve from 1.29789
Epoch 230/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4004 - val_loss: 1.2987 - val_accuracy: 0.3936

Epoch 00230: val_loss did not improve from 1.29789
Epoch 231/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4027 - val_loss: 1.2995 - val_accuracy: 0.3896

Epoch 00231: val_loss did not improve from 1.29789
Epoch 232/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.4003 - val_loss: 1.2984 - val_accuracy: 0.3992

Epoch 00232: val_loss did not improve from 1.29789
Epoch 233/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.4007 - val_loss: 1.2980 - val_accuracy: 0.4040

Epoch 00233: val_loss did not improve from 1.29789
Epoch 234/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.4023 - val_loss: 1.3069 - val_accuracy: 0.3936

Epoch 00234: val_loss did not improve from 1.29789
Epoch 235/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3993 - val_loss: 1.2986 - val_accuracy: 0.3944

Epoch 00235: val_loss did not improve from 1.29789
Epoch 236/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3925 - val_loss: 1.3044 - val_accuracy: 0.3857

Epoch 00236: val_loss did not improve from 1.29789
Epoch 237/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4014 - val_loss: 1.3018 - val_accuracy: 0.3912

Epoch 00237: val_loss did not improve from 1.29789
Epoch 238/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.4050 - val_loss: 1.2983 - val_accuracy: 0.3880

Epoch 00238: val_loss did not improve from 1.29789
Epoch 239/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.4045 - val_loss: 1.2980 - val_accuracy: 0.3920

Epoch 00239: val_loss did not improve from 1.29789
Epoch 240/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.4043 - val_loss: 1.3001 - val_accuracy: 0.4000

Epoch 00240: val_loss did not improve from 1.29789
Epoch 241/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3996 - val_loss: 1.2994 - val_accuracy: 0.3857

Epoch 00241: val_loss did not improve from 1.29789
Epoch 242/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3940 - val_loss: 1.3003 - val_accuracy: 0.3904

Epoch 00242: val_loss did not improve from 1.29789
Epoch 243/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4010 - val_loss: 1.2979 - val_accuracy: 0.3928

Epoch 00243: val_loss improved from 1.29789 to 1.29788, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 244/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.4047 - val_loss: 1.2999 - val_accuracy: 0.3833

Epoch 00244: val_loss did not improve from 1.29788
Epoch 245/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3993 - val_loss: 1.3008 - val_accuracy: 0.3825

Epoch 00245: val_loss did not improve from 1.29788
Epoch 246/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4035 - val_loss: 1.3002 - val_accuracy: 0.3952

Epoch 00246: val_loss did not improve from 1.29788
Epoch 247/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4036 - val_loss: 1.3009 - val_accuracy: 0.3880

Epoch 00247: val_loss did not improve from 1.29788
Epoch 248/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3994 - val_loss: 1.2974 - val_accuracy: 0.4008

Epoch 00248: val_loss improved from 1.29788 to 1.29741, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 249/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3960 - val_loss: 1.3016 - val_accuracy: 0.3920

Epoch 00249: val_loss did not improve from 1.29741
Epoch 250/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4022 - val_loss: 1.2987 - val_accuracy: 0.3904

Epoch 00250: val_loss did not improve from 1.29741
Epoch 251/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4058 - val_loss: 1.3027 - val_accuracy: 0.3857

Epoch 00251: val_loss did not improve from 1.29741
Epoch 252/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.4019 - val_loss: 1.3007 - val_accuracy: 0.3904

Epoch 00252: val_loss did not improve from 1.29741
Epoch 253/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.4053 - val_loss: 1.3014 - val_accuracy: 0.3865

Epoch 00253: val_loss did not improve from 1.29741
Epoch 254/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.4025 - val_loss: 1.2994 - val_accuracy: 0.4048

Epoch 00254: val_loss did not improve from 1.29741
Epoch 255/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4027 - val_loss: 1.3021 - val_accuracy: 0.3833

Epoch 00255: val_loss did not improve from 1.29741
Epoch 256/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.4007 - val_loss: 1.3008 - val_accuracy: 0.4016

Epoch 00256: val_loss did not improve from 1.29741
Epoch 257/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.4001 - val_loss: 1.2994 - val_accuracy: 0.3817

Epoch 00257: val_loss did not improve from 1.29741
Epoch 258/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.4038 - val_loss: 1.3011 - val_accuracy: 0.3849

Epoch 00258: val_loss did not improve from 1.29741
Epoch 259/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.4037 - val_loss: 1.2990 - val_accuracy: 0.3920

Epoch 00259: val_loss did not improve from 1.29741
Epoch 260/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3996 - val_loss: 1.2985 - val_accuracy: 0.3888

Epoch 00260: val_loss did not improve from 1.29741
Epoch 261/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.4034 - val_loss: 1.3027 - val_accuracy: 0.3912

Epoch 00261: val_loss did not improve from 1.29741
Epoch 262/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.4002 - val_loss: 1.3026 - val_accuracy: 0.3928

Epoch 00262: val_loss did not improve from 1.29741
Epoch 263/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3973 - val_loss: 1.2987 - val_accuracy: 0.3936

Epoch 00263: val_loss did not improve from 1.29741
Epoch 264/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4041 - val_loss: 1.2989 - val_accuracy: 0.3960

Epoch 00264: val_loss did not improve from 1.29741
Epoch 265/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4050 - val_loss: 1.3043 - val_accuracy: 0.3825

Epoch 00265: val_loss did not improve from 1.29741
Epoch 266/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4027 - val_loss: 1.2996 - val_accuracy: 0.3928

Epoch 00266: val_loss did not improve from 1.29741
Epoch 267/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4019 - val_loss: 1.2986 - val_accuracy: 0.3968

Epoch 00267: val_loss did not improve from 1.29741
Epoch 268/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4033 - val_loss: 1.3019 - val_accuracy: 0.3928

Epoch 00268: val_loss did not improve from 1.29741
Epoch 269/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4050 - val_loss: 1.2991 - val_accuracy: 0.3920

Epoch 00269: val_loss did not improve from 1.29741
Epoch 270/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3989 - val_loss: 1.3000 - val_accuracy: 0.4056

Epoch 00270: val_loss did not improve from 1.29741
Epoch 271/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4023 - val_loss: 1.2997 - val_accuracy: 0.3880

Epoch 00271: val_loss did not improve from 1.29741
Epoch 272/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4060 - val_loss: 1.3013 - val_accuracy: 0.3841

Epoch 00272: val_loss did not improve from 1.29741
Epoch 273/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4044 - val_loss: 1.3014 - val_accuracy: 0.3873

Epoch 00273: val_loss did not improve from 1.29741
Epoch 274/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4026 - val_loss: 1.2979 - val_accuracy: 0.4000

Epoch 00274: val_loss did not improve from 1.29741
Epoch 275/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.4061 - val_loss: 1.3016 - val_accuracy: 0.4000

Epoch 00275: val_loss did not improve from 1.29741
Epoch 276/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4009 - val_loss: 1.2982 - val_accuracy: 0.3944

Epoch 00276: val_loss did not improve from 1.29741
Epoch 277/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4038 - val_loss: 1.3009 - val_accuracy: 0.3952

Epoch 00277: val_loss did not improve from 1.29741
Epoch 278/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.4057 - val_loss: 1.2978 - val_accuracy: 0.3880

Epoch 00278: val_loss did not improve from 1.29741
Epoch 279/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4035 - val_loss: 1.3025 - val_accuracy: 0.3817

Epoch 00279: val_loss did not improve from 1.29741
Epoch 280/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4047 - val_loss: 1.2997 - val_accuracy: 0.3968

Epoch 00280: val_loss did not improve from 1.29741
Epoch 281/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.4019 - val_loss: 1.3002 - val_accuracy: 0.4096

Epoch 00281: val_loss did not improve from 1.29741
Epoch 282/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.4004 - val_loss: 1.3070 - val_accuracy: 0.3960

Epoch 00282: val_loss did not improve from 1.29741
Epoch 283/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3997 - val_loss: 1.3022 - val_accuracy: 0.3888

Epoch 00283: val_loss did not improve from 1.29741
Epoch 284/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4011 - val_loss: 1.2996 - val_accuracy: 0.3857

Epoch 00284: val_loss did not improve from 1.29741
Epoch 285/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3979 - val_loss: 1.2985 - val_accuracy: 0.4024

Epoch 00285: val_loss did not improve from 1.29741
Epoch 286/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.4058 - val_loss: 1.3016 - val_accuracy: 0.3888

Epoch 00286: val_loss did not improve from 1.29741
Epoch 287/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4059 - val_loss: 1.2993 - val_accuracy: 0.3880

Epoch 00287: val_loss did not improve from 1.29741
Epoch 288/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3977 - val_loss: 1.2999 - val_accuracy: 0.3809

Epoch 00288: val_loss did not improve from 1.29741
Epoch 289/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4016 - val_loss: 1.2995 - val_accuracy: 0.4016

Epoch 00289: val_loss did not improve from 1.29741
Epoch 290/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4059 - val_loss: 1.3055 - val_accuracy: 0.3873

Epoch 00290: val_loss did not improve from 1.29741
Epoch 291/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.4015 - val_loss: 1.2977 - val_accuracy: 0.3904

Epoch 00291: val_loss did not improve from 1.29741
Epoch 292/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4035 - val_loss: 1.3009 - val_accuracy: 0.4000

Epoch 00292: val_loss did not improve from 1.29741
Epoch 293/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4006 - val_loss: 1.2998 - val_accuracy: 0.3888

Epoch 00293: val_loss did not improve from 1.29741
Epoch 294/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4024 - val_loss: 1.2997 - val_accuracy: 0.3944

Epoch 00294: val_loss did not improve from 1.29741
Epoch 295/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4003 - val_loss: 1.3019 - val_accuracy: 0.3833

Epoch 00295: val_loss did not improve from 1.29741
Epoch 296/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.4024 - val_loss: 1.2982 - val_accuracy: 0.3880

Epoch 00296: val_loss did not improve from 1.29741
Epoch 297/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4024 - val_loss: 1.2972 - val_accuracy: 0.4056

Epoch 00297: val_loss improved from 1.29741 to 1.29720, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 298/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4045 - val_loss: 1.2995 - val_accuracy: 0.3904

Epoch 00298: val_loss did not improve from 1.29720
Epoch 299/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4007 - val_loss: 1.3007 - val_accuracy: 0.3928

Epoch 00299: val_loss did not improve from 1.29720
Epoch 300/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4001 - val_loss: 1.2981 - val_accuracy: 0.4016

Epoch 00300: val_loss did not improve from 1.29720
Epoch 301/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4006 - val_loss: 1.2983 - val_accuracy: 0.4048

Epoch 00301: val_loss did not improve from 1.29720
Epoch 302/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4022 - val_loss: 1.3035 - val_accuracy: 0.3896

Epoch 00302: val_loss did not improve from 1.29720
Epoch 303/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4025 - val_loss: 1.3008 - val_accuracy: 0.3920

Epoch 00303: val_loss did not improve from 1.29720
Epoch 304/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3965 - val_loss: 1.2970 - val_accuracy: 0.4000

Epoch 00304: val_loss improved from 1.29720 to 1.29696, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 305/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4066 - val_loss: 1.3065 - val_accuracy: 0.3944

Epoch 00305: val_loss did not improve from 1.29696
Epoch 306/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.4035 - val_loss: 1.2984 - val_accuracy: 0.3904

Epoch 00306: val_loss did not improve from 1.29696
Epoch 307/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4051 - val_loss: 1.2992 - val_accuracy: 0.3888

Epoch 00307: val_loss did not improve from 1.29696
Epoch 308/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4024 - val_loss: 1.2997 - val_accuracy: 0.3944

Epoch 00308: val_loss did not improve from 1.29696
Epoch 309/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3996 - val_loss: 1.3026 - val_accuracy: 0.3880

Epoch 00309: val_loss did not improve from 1.29696
Epoch 310/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4021 - val_loss: 1.2984 - val_accuracy: 0.3944

Epoch 00310: val_loss did not improve from 1.29696
Epoch 311/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4059 - val_loss: 1.2993 - val_accuracy: 0.3904

Epoch 00311: val_loss did not improve from 1.29696
Epoch 312/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4028 - val_loss: 1.2986 - val_accuracy: 0.3960

Epoch 00312: val_loss did not improve from 1.29696
Epoch 313/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4033 - val_loss: 1.2999 - val_accuracy: 0.3817

Epoch 00313: val_loss did not improve from 1.29696
Epoch 314/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3975 - val_loss: 1.2998 - val_accuracy: 0.3817

Epoch 00314: val_loss did not improve from 1.29696
Epoch 315/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4006 - val_loss: 1.3030 - val_accuracy: 0.3857

Epoch 00315: val_loss did not improve from 1.29696
Epoch 316/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4019 - val_loss: 1.3002 - val_accuracy: 0.3880

Epoch 00316: val_loss did not improve from 1.29696
Epoch 317/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3973 - val_loss: 1.3003 - val_accuracy: 0.3992

Epoch 00317: val_loss did not improve from 1.29696
Epoch 318/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.4039 - val_loss: 1.3003 - val_accuracy: 0.3976

Epoch 00318: val_loss did not improve from 1.29696
Epoch 319/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4028 - val_loss: 1.3023 - val_accuracy: 0.3809

Epoch 00319: val_loss did not improve from 1.29696
Epoch 320/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4046 - val_loss: 1.3022 - val_accuracy: 0.3761

Epoch 00320: val_loss did not improve from 1.29696
Epoch 321/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3957 - val_loss: 1.2965 - val_accuracy: 0.4048

Epoch 00321: val_loss improved from 1.29696 to 1.29646, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 322/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.4046 - val_loss: 1.2981 - val_accuracy: 0.3992

Epoch 00322: val_loss did not improve from 1.29646
Epoch 323/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4044 - val_loss: 1.3021 - val_accuracy: 0.3793

Epoch 00323: val_loss did not improve from 1.29646
Epoch 324/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.4008 - val_loss: 1.3013 - val_accuracy: 0.3928

Epoch 00324: val_loss did not improve from 1.29646
Epoch 325/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3970 - val_loss: 1.2997 - val_accuracy: 0.3936

Epoch 00325: val_loss did not improve from 1.29646
Epoch 326/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4035 - val_loss: 1.3001 - val_accuracy: 0.3825

Epoch 00326: val_loss did not improve from 1.29646
Epoch 327/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4033 - val_loss: 1.3031 - val_accuracy: 0.3793

Epoch 00327: val_loss did not improve from 1.29646
Epoch 328/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4017 - val_loss: 1.2984 - val_accuracy: 0.3952

Epoch 00328: val_loss did not improve from 1.29646
Epoch 329/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.4020 - val_loss: 1.2997 - val_accuracy: 0.3968

Epoch 00329: val_loss did not improve from 1.29646
Epoch 330/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4027 - val_loss: 1.2971 - val_accuracy: 0.3944

Epoch 00330: val_loss did not improve from 1.29646
Epoch 331/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4052 - val_loss: 1.3003 - val_accuracy: 0.3912

Epoch 00331: val_loss did not improve from 1.29646
Epoch 332/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4026 - val_loss: 1.2982 - val_accuracy: 0.3904

Epoch 00332: val_loss did not improve from 1.29646
Epoch 333/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4044 - val_loss: 1.2968 - val_accuracy: 0.3984

Epoch 00333: val_loss did not improve from 1.29646
Epoch 334/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4036 - val_loss: 1.3016 - val_accuracy: 0.3849

Epoch 00334: val_loss did not improve from 1.29646
Epoch 335/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4044 - val_loss: 1.2985 - val_accuracy: 0.3841

Epoch 00335: val_loss did not improve from 1.29646
Epoch 336/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4044 - val_loss: 1.2978 - val_accuracy: 0.3896

Epoch 00336: val_loss did not improve from 1.29646
Epoch 337/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4037 - val_loss: 1.2978 - val_accuracy: 0.3992

Epoch 00337: val_loss did not improve from 1.29646
Epoch 338/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4029 - val_loss: 1.2981 - val_accuracy: 0.3992

Epoch 00338: val_loss did not improve from 1.29646
Epoch 339/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4040 - val_loss: 1.2973 - val_accuracy: 0.3968

Epoch 00339: val_loss did not improve from 1.29646
Epoch 340/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4044 - val_loss: 1.3010 - val_accuracy: 0.3920

Epoch 00340: val_loss did not improve from 1.29646
Epoch 341/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4042 - val_loss: 1.3038 - val_accuracy: 0.3857

Epoch 00341: val_loss did not improve from 1.29646
Epoch 342/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3994 - val_loss: 1.2959 - val_accuracy: 0.3960

Epoch 00342: val_loss improved from 1.29646 to 1.29593, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 343/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.4067 - val_loss: 1.3024 - val_accuracy: 0.3833

Epoch 00343: val_loss did not improve from 1.29593
Epoch 344/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3988 - val_loss: 1.3008 - val_accuracy: 0.3873

Epoch 00344: val_loss did not improve from 1.29593
Epoch 345/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4024 - val_loss: 1.2993 - val_accuracy: 0.4040

Epoch 00345: val_loss did not improve from 1.29593
Epoch 346/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4014 - val_loss: 1.3069 - val_accuracy: 0.3904

Epoch 00346: val_loss did not improve from 1.29593
Epoch 347/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.4021 - val_loss: 1.2981 - val_accuracy: 0.3880

Epoch 00347: val_loss did not improve from 1.29593
Epoch 348/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3992 - val_loss: 1.2974 - val_accuracy: 0.4000

Epoch 00348: val_loss did not improve from 1.29593
Epoch 349/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4066 - val_loss: 1.3020 - val_accuracy: 0.3865

Epoch 00349: val_loss did not improve from 1.29593
Epoch 350/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4037 - val_loss: 1.2960 - val_accuracy: 0.4016

Epoch 00350: val_loss did not improve from 1.29593
Epoch 351/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4019 - val_loss: 1.3000 - val_accuracy: 0.4040

Epoch 00351: val_loss did not improve from 1.29593
Epoch 352/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4013 - val_loss: 1.3026 - val_accuracy: 0.3920

Epoch 00352: val_loss did not improve from 1.29593
Epoch 353/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3996 - val_loss: 1.2984 - val_accuracy: 0.4016

Epoch 00353: val_loss did not improve from 1.29593
Epoch 354/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4026 - val_loss: 1.2968 - val_accuracy: 0.3888

Epoch 00354: val_loss did not improve from 1.29593
Epoch 355/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4025 - val_loss: 1.3026 - val_accuracy: 0.3809

Epoch 00355: val_loss did not improve from 1.29593
Epoch 356/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4016 - val_loss: 1.2967 - val_accuracy: 0.3952

Epoch 00356: val_loss did not improve from 1.29593
Epoch 357/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4041 - val_loss: 1.2989 - val_accuracy: 0.3992

Epoch 00357: val_loss did not improve from 1.29593
Epoch 358/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4029 - val_loss: 1.3020 - val_accuracy: 0.3873

Epoch 00358: val_loss did not improve from 1.29593
Epoch 359/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4033 - val_loss: 1.2997 - val_accuracy: 0.3944

Epoch 00359: val_loss did not improve from 1.29593
Epoch 360/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4070 - val_loss: 1.2972 - val_accuracy: 0.3944

Epoch 00360: val_loss did not improve from 1.29593
Epoch 361/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4003 - val_loss: 1.2995 - val_accuracy: 0.3873

Epoch 00361: val_loss did not improve from 1.29593
Epoch 362/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4037 - val_loss: 1.2986 - val_accuracy: 0.3928

Epoch 00362: val_loss did not improve from 1.29593
Epoch 363/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4046 - val_loss: 1.3003 - val_accuracy: 0.3904

Epoch 00363: val_loss did not improve from 1.29593
Epoch 364/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4017 - val_loss: 1.2988 - val_accuracy: 0.3968

Epoch 00364: val_loss did not improve from 1.29593
Epoch 365/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4056 - val_loss: 1.3009 - val_accuracy: 0.3865

Epoch 00365: val_loss did not improve from 1.29593
Epoch 366/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4050 - val_loss: 1.3003 - val_accuracy: 0.3920

Epoch 00366: val_loss did not improve from 1.29593
Epoch 367/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4075 - val_loss: 1.2991 - val_accuracy: 0.3952

Epoch 00367: val_loss did not improve from 1.29593
Epoch 368/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4013 - val_loss: 1.3002 - val_accuracy: 0.3896

Epoch 00368: val_loss did not improve from 1.29593
Epoch 369/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4022 - val_loss: 1.2994 - val_accuracy: 0.3880

Epoch 00369: val_loss did not improve from 1.29593
Epoch 370/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4042 - val_loss: 1.3018 - val_accuracy: 0.3865

Epoch 00370: val_loss did not improve from 1.29593
Epoch 371/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4069 - val_loss: 1.2982 - val_accuracy: 0.3936

Epoch 00371: val_loss did not improve from 1.29593
Epoch 372/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4013 - val_loss: 1.2992 - val_accuracy: 0.4016

Epoch 00372: val_loss did not improve from 1.29593
Epoch 373/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4038 - val_loss: 1.3034 - val_accuracy: 0.3936

Epoch 00373: val_loss did not improve from 1.29593
Epoch 374/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4060 - val_loss: 1.2971 - val_accuracy: 0.3944

Epoch 00374: val_loss did not improve from 1.29593
Epoch 375/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4035 - val_loss: 1.2984 - val_accuracy: 0.3912

Epoch 00375: val_loss did not improve from 1.29593
Epoch 376/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4035 - val_loss: 1.3062 - val_accuracy: 0.3912

Epoch 00376: val_loss did not improve from 1.29593
Epoch 377/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4003 - val_loss: 1.2984 - val_accuracy: 0.3920

Epoch 00377: val_loss did not improve from 1.29593
Epoch 378/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4043 - val_loss: 1.2988 - val_accuracy: 0.3936

Epoch 00378: val_loss did not improve from 1.29593
Epoch 379/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4016 - val_loss: 1.3031 - val_accuracy: 0.3857

Epoch 00379: val_loss did not improve from 1.29593
Epoch 380/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4047 - val_loss: 1.2983 - val_accuracy: 0.3880

Epoch 00380: val_loss did not improve from 1.29593
Epoch 381/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4008 - val_loss: 1.2982 - val_accuracy: 0.3944

Epoch 00381: val_loss did not improve from 1.29593
Epoch 382/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4048 - val_loss: 1.3016 - val_accuracy: 0.3912

Epoch 00382: val_loss did not improve from 1.29593
Epoch 383/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4027 - val_loss: 1.3028 - val_accuracy: 0.3896

Epoch 00383: val_loss did not improve from 1.29593
Epoch 384/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4030 - val_loss: 1.2984 - val_accuracy: 0.3984

Epoch 00384: val_loss did not improve from 1.29593
Epoch 385/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4048 - val_loss: 1.2994 - val_accuracy: 0.3849

Epoch 00385: val_loss did not improve from 1.29593
Epoch 386/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4043 - val_loss: 1.3009 - val_accuracy: 0.3817

Epoch 00386: val_loss did not improve from 1.29593
Epoch 387/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3983 - val_loss: 1.2979 - val_accuracy: 0.3888

Epoch 00387: val_loss did not improve from 1.29593
Epoch 388/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4069 - val_loss: 1.3051 - val_accuracy: 0.3896

Epoch 00388: val_loss did not improve from 1.29593
Epoch 389/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4033 - val_loss: 1.2999 - val_accuracy: 0.3952

Epoch 00389: val_loss did not improve from 1.29593
Epoch 390/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4071 - val_loss: 1.3026 - val_accuracy: 0.3833

Epoch 00390: val_loss did not improve from 1.29593
Epoch 391/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4075 - val_loss: 1.3002 - val_accuracy: 0.3873

Epoch 00391: val_loss did not improve from 1.29593
Epoch 392/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4019 - val_loss: 1.2999 - val_accuracy: 0.3920

Epoch 00392: val_loss did not improve from 1.29593
Epoch 393/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4044 - val_loss: 1.2961 - val_accuracy: 0.3968

Epoch 00393: val_loss did not improve from 1.29593
Epoch 394/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4040 - val_loss: 1.2983 - val_accuracy: 0.3912

Epoch 00394: val_loss did not improve from 1.29593
Epoch 395/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4034 - val_loss: 1.3054 - val_accuracy: 0.3833

Epoch 00395: val_loss did not improve from 1.29593
Epoch 396/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4004 - val_loss: 1.2991 - val_accuracy: 0.3888

Epoch 00396: val_loss did not improve from 1.29593
Epoch 397/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3999 - val_loss: 1.2972 - val_accuracy: 0.3992

Epoch 00397: val_loss did not improve from 1.29593
Epoch 398/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4035 - val_loss: 1.3036 - val_accuracy: 0.3912

Epoch 00398: val_loss did not improve from 1.29593
Epoch 399/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4059 - val_loss: 1.2988 - val_accuracy: 0.3849

Epoch 00399: val_loss did not improve from 1.29593
Epoch 400/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4019 - val_loss: 1.3006 - val_accuracy: 0.3952

Epoch 00400: val_loss did not improve from 1.29593
Epoch 401/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4063 - val_loss: 1.3017 - val_accuracy: 0.3952

Epoch 00401: val_loss did not improve from 1.29593
Epoch 402/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4067 - val_loss: 1.3070 - val_accuracy: 0.3753

Epoch 00402: val_loss did not improve from 1.29593
Epoch 403/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3990 - val_loss: 1.3005 - val_accuracy: 0.3984

Epoch 00403: val_loss did not improve from 1.29593
Epoch 404/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4029 - val_loss: 1.3063 - val_accuracy: 0.3809

Epoch 00404: val_loss did not improve from 1.29593
Epoch 405/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4057 - val_loss: 1.2986 - val_accuracy: 0.3912

Epoch 00405: val_loss did not improve from 1.29593
Epoch 406/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4004 - val_loss: 1.3002 - val_accuracy: 0.4032

Epoch 00406: val_loss did not improve from 1.29593
Epoch 407/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.4040 - val_loss: 1.3035 - val_accuracy: 0.3896

Epoch 00407: val_loss did not improve from 1.29593
Epoch 408/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4030 - val_loss: 1.2993 - val_accuracy: 0.3920

Epoch 00408: val_loss did not improve from 1.29593
Epoch 409/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4030 - val_loss: 1.2972 - val_accuracy: 0.3912

Epoch 00409: val_loss did not improve from 1.29593
Epoch 410/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4048 - val_loss: 1.2978 - val_accuracy: 0.3992

Epoch 00410: val_loss did not improve from 1.29593
Epoch 411/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4046 - val_loss: 1.3102 - val_accuracy: 0.3841

Epoch 00411: val_loss did not improve from 1.29593
Epoch 412/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4009 - val_loss: 1.2996 - val_accuracy: 0.4040

Epoch 00412: val_loss did not improve from 1.29593
Epoch 413/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4071 - val_loss: 1.2983 - val_accuracy: 0.3857

Epoch 00413: val_loss did not improve from 1.29593
Epoch 414/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4068 - val_loss: 1.3042 - val_accuracy: 0.3984

Epoch 00414: val_loss did not improve from 1.29593
Epoch 415/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4036 - val_loss: 1.2985 - val_accuracy: 0.4000

Epoch 00415: val_loss did not improve from 1.29593
Epoch 416/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4051 - val_loss: 1.2967 - val_accuracy: 0.3928

Epoch 00416: val_loss did not improve from 1.29593
Epoch 417/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4043 - val_loss: 1.3031 - val_accuracy: 0.3825

Epoch 00417: val_loss did not improve from 1.29593
Epoch 418/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4066 - val_loss: 1.2976 - val_accuracy: 0.3928

Epoch 00418: val_loss did not improve from 1.29593
Epoch 419/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4043 - val_loss: 1.2971 - val_accuracy: 0.3873

Epoch 00419: val_loss did not improve from 1.29593
Epoch 420/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4033 - val_loss: 1.2991 - val_accuracy: 0.3873

Epoch 00420: val_loss did not improve from 1.29593
Epoch 421/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4077 - val_loss: 1.3015 - val_accuracy: 0.3960

Epoch 00421: val_loss did not improve from 1.29593
Epoch 422/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4074 - val_loss: 1.3025 - val_accuracy: 0.3873

Epoch 00422: val_loss did not improve from 1.29593
Epoch 423/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4058 - val_loss: 1.2984 - val_accuracy: 0.3888

Epoch 00423: val_loss did not improve from 1.29593
Epoch 424/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4039 - val_loss: 1.2972 - val_accuracy: 0.3952

Epoch 00424: val_loss did not improve from 1.29593
Epoch 425/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4074 - val_loss: 1.3133 - val_accuracy: 0.3761

Epoch 00425: val_loss did not improve from 1.29593
Epoch 426/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3967 - val_loss: 1.2976 - val_accuracy: 0.3944

Epoch 00426: val_loss did not improve from 1.29593
Epoch 427/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4035 - val_loss: 1.2984 - val_accuracy: 0.3880

Epoch 00427: val_loss did not improve from 1.29593
Epoch 428/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4017 - val_loss: 1.3021 - val_accuracy: 0.3817

Epoch 00428: val_loss did not improve from 1.29593
Epoch 429/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4066 - val_loss: 1.2977 - val_accuracy: 0.3960

Epoch 00429: val_loss did not improve from 1.29593
Epoch 430/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4043 - val_loss: 1.2987 - val_accuracy: 0.3880

Epoch 00430: val_loss did not improve from 1.29593
Epoch 431/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4025 - val_loss: 1.2999 - val_accuracy: 0.3857

Epoch 00431: val_loss did not improve from 1.29593
Epoch 432/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4025 - val_loss: 1.2988 - val_accuracy: 0.3873

Epoch 00432: val_loss did not improve from 1.29593
Epoch 433/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4058 - val_loss: 1.3023 - val_accuracy: 0.3841

Epoch 00433: val_loss did not improve from 1.29593
Epoch 434/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4047 - val_loss: 1.2976 - val_accuracy: 0.3920

Epoch 00434: val_loss did not improve from 1.29593
Epoch 435/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4019 - val_loss: 1.3012 - val_accuracy: 0.3928

Epoch 00435: val_loss did not improve from 1.29593
Epoch 436/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4023 - val_loss: 1.2997 - val_accuracy: 0.3952

Epoch 00436: val_loss did not improve from 1.29593
Epoch 437/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4062 - val_loss: 1.2973 - val_accuracy: 0.3928

Epoch 00437: val_loss did not improve from 1.29593
Epoch 438/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4043 - val_loss: 1.3000 - val_accuracy: 0.3825

Epoch 00438: val_loss did not improve from 1.29593
Epoch 439/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4053 - val_loss: 1.3001 - val_accuracy: 0.3841

Epoch 00439: val_loss did not improve from 1.29593
Epoch 440/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4039 - val_loss: 1.2992 - val_accuracy: 0.3920

Epoch 00440: val_loss did not improve from 1.29593
Epoch 441/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4032 - val_loss: 1.2962 - val_accuracy: 0.3849

Epoch 00441: val_loss did not improve from 1.29593
Epoch 442/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4074 - val_loss: 1.3072 - val_accuracy: 0.3880

Epoch 00442: val_loss did not improve from 1.29593
Epoch 443/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4078 - val_loss: 1.2962 - val_accuracy: 0.3944

Epoch 00443: val_loss did not improve from 1.29593
Epoch 444/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4027 - val_loss: 1.2961 - val_accuracy: 0.3880

Epoch 00444: val_loss did not improve from 1.29593
Epoch 445/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4008 - val_loss: 1.3006 - val_accuracy: 0.3857

Epoch 00445: val_loss did not improve from 1.29593
Epoch 446/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4004 - val_loss: 1.3007 - val_accuracy: 0.3952

Epoch 00446: val_loss did not improve from 1.29593
Epoch 447/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4042 - val_loss: 1.3030 - val_accuracy: 0.3896

Epoch 00447: val_loss did not improve from 1.29593
Epoch 448/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4054 - val_loss: 1.2979 - val_accuracy: 0.3912

Epoch 00448: val_loss did not improve from 1.29593
Epoch 449/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4060 - val_loss: 1.3041 - val_accuracy: 0.3825

Epoch 00449: val_loss did not improve from 1.29593
Epoch 450/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4058 - val_loss: 1.2976 - val_accuracy: 0.3936

Epoch 00450: val_loss did not improve from 1.29593
Epoch 451/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4046 - val_loss: 1.2978 - val_accuracy: 0.3880

Epoch 00451: val_loss did not improve from 1.29593
Epoch 452/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4024 - val_loss: 1.3005 - val_accuracy: 0.3865

Epoch 00452: val_loss did not improve from 1.29593
Epoch 453/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4070 - val_loss: 1.3001 - val_accuracy: 0.3888

Epoch 00453: val_loss did not improve from 1.29593
Epoch 454/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4066 - val_loss: 1.3002 - val_accuracy: 0.3865

Epoch 00454: val_loss did not improve from 1.29593
Epoch 455/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4062 - val_loss: 1.3004 - val_accuracy: 0.3841

Epoch 00455: val_loss did not improve from 1.29593
Epoch 456/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4051 - val_loss: 1.2980 - val_accuracy: 0.3888

Epoch 00456: val_loss did not improve from 1.29593
Epoch 457/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4062 - val_loss: 1.3033 - val_accuracy: 0.3960

Epoch 00457: val_loss did not improve from 1.29593
Epoch 458/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4019 - val_loss: 1.2977 - val_accuracy: 0.3944

Epoch 00458: val_loss did not improve from 1.29593
Epoch 459/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4063 - val_loss: 1.2979 - val_accuracy: 0.3873

Epoch 00459: val_loss did not improve from 1.29593
Epoch 460/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4026 - val_loss: 1.2997 - val_accuracy: 0.3865

Epoch 00460: val_loss did not improve from 1.29593
Epoch 461/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4028 - val_loss: 1.2985 - val_accuracy: 0.3952

Epoch 00461: val_loss did not improve from 1.29593
Epoch 462/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4068 - val_loss: 1.2969 - val_accuracy: 0.3880

Epoch 00462: val_loss did not improve from 1.29593
Epoch 463/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4079 - val_loss: 1.3007 - val_accuracy: 0.3825

Epoch 00463: val_loss did not improve from 1.29593
Epoch 464/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4062 - val_loss: 1.3002 - val_accuracy: 0.3896

Epoch 00464: val_loss did not improve from 1.29593
Epoch 465/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4075 - val_loss: 1.2990 - val_accuracy: 0.3976

Epoch 00465: val_loss did not improve from 1.29593
Epoch 466/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4032 - val_loss: 1.2994 - val_accuracy: 0.3817

Epoch 00466: val_loss did not improve from 1.29593
Epoch 467/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4061 - val_loss: 1.2999 - val_accuracy: 0.3833

Epoch 00467: val_loss did not improve from 1.29593
Epoch 468/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4051 - val_loss: 1.2966 - val_accuracy: 0.3904

Epoch 00468: val_loss did not improve from 1.29593
Epoch 469/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4035 - val_loss: 1.2991 - val_accuracy: 0.3865

Epoch 00469: val_loss did not improve from 1.29593
Epoch 470/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4044 - val_loss: 1.2975 - val_accuracy: 0.3904

Epoch 00470: val_loss did not improve from 1.29593
Epoch 471/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4024 - val_loss: 1.3017 - val_accuracy: 0.3801

Epoch 00471: val_loss did not improve from 1.29593
Epoch 472/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4046 - val_loss: 1.2975 - val_accuracy: 0.3952

Epoch 00472: val_loss did not improve from 1.29593
Epoch 473/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4040 - val_loss: 1.3047 - val_accuracy: 0.3928

Epoch 00473: val_loss did not improve from 1.29593
Epoch 474/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4039 - val_loss: 1.2981 - val_accuracy: 0.3960

Epoch 00474: val_loss did not improve from 1.29593
Epoch 475/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4021 - val_loss: 1.2976 - val_accuracy: 0.3904

Epoch 00475: val_loss did not improve from 1.29593
Epoch 476/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4052 - val_loss: 1.3055 - val_accuracy: 0.3865

Epoch 00476: val_loss did not improve from 1.29593
Epoch 477/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4029 - val_loss: 1.2999 - val_accuracy: 0.4032

Epoch 00477: val_loss did not improve from 1.29593
Epoch 478/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4075 - val_loss: 1.2992 - val_accuracy: 0.3888

Epoch 00478: val_loss did not improve from 1.29593
Epoch 479/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4034 - val_loss: 1.2985 - val_accuracy: 0.3849

Epoch 00479: val_loss did not improve from 1.29593
Epoch 480/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4059 - val_loss: 1.3010 - val_accuracy: 0.3841

Epoch 00480: val_loss did not improve from 1.29593
Epoch 481/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4045 - val_loss: 1.3001 - val_accuracy: 0.3865

Epoch 00481: val_loss did not improve from 1.29593
Epoch 482/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4030 - val_loss: 1.2991 - val_accuracy: 0.3936

Epoch 00482: val_loss did not improve from 1.29593
Epoch 483/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4066 - val_loss: 1.3035 - val_accuracy: 0.3873

Epoch 00483: val_loss did not improve from 1.29593
Epoch 484/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4052 - val_loss: 1.2973 - val_accuracy: 0.3912

Epoch 00484: val_loss did not improve from 1.29593
Epoch 485/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4066 - val_loss: 1.2966 - val_accuracy: 0.3904

Epoch 00485: val_loss did not improve from 1.29593
Epoch 486/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4055 - val_loss: 1.2988 - val_accuracy: 0.3896

Epoch 00486: val_loss did not improve from 1.29593
Epoch 487/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4048 - val_loss: 1.2974 - val_accuracy: 0.3880

Epoch 00487: val_loss did not improve from 1.29593
Epoch 488/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4068 - val_loss: 1.2974 - val_accuracy: 0.3857

Epoch 00488: val_loss did not improve from 1.29593
Epoch 489/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4016 - val_loss: 1.2979 - val_accuracy: 0.3857

Epoch 00489: val_loss did not improve from 1.29593
Epoch 490/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4031 - val_loss: 1.2978 - val_accuracy: 0.3896

Epoch 00490: val_loss did not improve from 1.29593
Epoch 491/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4008 - val_loss: 1.2995 - val_accuracy: 0.3928

Epoch 00491: val_loss did not improve from 1.29593
Epoch 492/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4027 - val_loss: 1.3047 - val_accuracy: 0.3880

Epoch 00492: val_loss did not improve from 1.29593
Epoch 493/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4056 - val_loss: 1.2967 - val_accuracy: 0.3857

Epoch 00493: val_loss did not improve from 1.29593
Epoch 494/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4053 - val_loss: 1.2968 - val_accuracy: 0.3888

Epoch 00494: val_loss did not improve from 1.29593
Epoch 495/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4043 - val_loss: 1.2958 - val_accuracy: 0.3912

Epoch 00495: val_loss improved from 1.29593 to 1.29584, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 496/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4039 - val_loss: 1.2963 - val_accuracy: 0.3936

Epoch 00496: val_loss did not improve from 1.29584
Epoch 497/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4032 - val_loss: 1.3043 - val_accuracy: 0.3777

Epoch 00497: val_loss did not improve from 1.29584
Epoch 498/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4022 - val_loss: 1.3003 - val_accuracy: 0.3968

Epoch 00498: val_loss did not improve from 1.29584
Epoch 499/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4053 - val_loss: 1.3006 - val_accuracy: 0.3825

Epoch 00499: val_loss did not improve from 1.29584
Epoch 500/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4028 - val_loss: 1.2984 - val_accuracy: 0.3865

Epoch 00500: val_loss did not improve from 1.29584
Epoch 501/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4050 - val_loss: 1.3027 - val_accuracy: 0.3888

Epoch 00501: val_loss did not improve from 1.29584
Epoch 502/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4052 - val_loss: 1.2970 - val_accuracy: 0.3944

Epoch 00502: val_loss did not improve from 1.29584
Epoch 503/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4045 - val_loss: 1.2977 - val_accuracy: 0.3896

Epoch 00503: val_loss did not improve from 1.29584
Epoch 504/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4027 - val_loss: 1.2986 - val_accuracy: 0.3880

Epoch 00504: val_loss did not improve from 1.29584
Epoch 505/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4077 - val_loss: 1.2984 - val_accuracy: 0.4008

Epoch 00505: val_loss did not improve from 1.29584
Epoch 506/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4064 - val_loss: 1.3002 - val_accuracy: 0.3880

Epoch 00506: val_loss did not improve from 1.29584
Epoch 507/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4044 - val_loss: 1.3005 - val_accuracy: 0.3849

Epoch 00507: val_loss did not improve from 1.29584
Epoch 508/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4037 - val_loss: 1.2945 - val_accuracy: 0.3952

Epoch 00508: val_loss improved from 1.29584 to 1.29449, saving model to ./results/NN_thk_class/aggr_theta/ckpt_4
Epoch 509/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4063 - val_loss: 1.2966 - val_accuracy: 0.3928

Epoch 00509: val_loss did not improve from 1.29449
Epoch 510/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4058 - val_loss: 1.2979 - val_accuracy: 0.3865

Epoch 00510: val_loss did not improve from 1.29449
Epoch 511/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4081 - val_loss: 1.2985 - val_accuracy: 0.3873

Epoch 00511: val_loss did not improve from 1.29449
Epoch 512/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4077 - val_loss: 1.2968 - val_accuracy: 0.3888

Epoch 00512: val_loss did not improve from 1.29449
Epoch 513/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4071 - val_loss: 1.3071 - val_accuracy: 0.3825

Epoch 00513: val_loss did not improve from 1.29449
Epoch 514/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4054 - val_loss: 1.3004 - val_accuracy: 0.4016

Epoch 00514: val_loss did not improve from 1.29449
Epoch 515/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4025 - val_loss: 1.2980 - val_accuracy: 0.3896

Epoch 00515: val_loss did not improve from 1.29449
Epoch 516/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4066 - val_loss: 1.2982 - val_accuracy: 0.3825

Epoch 00516: val_loss did not improve from 1.29449
Epoch 517/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4019 - val_loss: 1.2979 - val_accuracy: 0.3880

Epoch 00517: val_loss did not improve from 1.29449
Epoch 518/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4039 - val_loss: 1.3013 - val_accuracy: 0.3841

Epoch 00518: val_loss did not improve from 1.29449
Epoch 519/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4027 - val_loss: 1.2984 - val_accuracy: 0.3928

Epoch 00519: val_loss did not improve from 1.29449
Epoch 520/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4029 - val_loss: 1.3003 - val_accuracy: 0.3849

Epoch 00520: val_loss did not improve from 1.29449
Epoch 521/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4057 - val_loss: 1.2961 - val_accuracy: 0.3849

Epoch 00521: val_loss did not improve from 1.29449
Epoch 522/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4024 - val_loss: 1.2972 - val_accuracy: 0.3865

Epoch 00522: val_loss did not improve from 1.29449
Epoch 523/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4058 - val_loss: 1.2980 - val_accuracy: 0.4000

Epoch 00523: val_loss did not improve from 1.29449
Epoch 524/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4071 - val_loss: 1.3046 - val_accuracy: 0.3825

Epoch 00524: val_loss did not improve from 1.29449
Epoch 525/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4041 - val_loss: 1.2972 - val_accuracy: 0.3880

Epoch 00525: val_loss did not improve from 1.29449
Epoch 526/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4034 - val_loss: 1.2966 - val_accuracy: 0.3912

Epoch 00526: val_loss did not improve from 1.29449
Epoch 527/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4070 - val_loss: 1.3008 - val_accuracy: 0.3809

Epoch 00527: val_loss did not improve from 1.29449
Epoch 528/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4025 - val_loss: 1.2992 - val_accuracy: 0.3976

Epoch 00528: val_loss did not improve from 1.29449
Epoch 529/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4058 - val_loss: 1.3008 - val_accuracy: 0.3888

Epoch 00529: val_loss did not improve from 1.29449
Epoch 530/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4055 - val_loss: 1.2976 - val_accuracy: 0.3857

Epoch 00530: val_loss did not improve from 1.29449
Epoch 531/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4042 - val_loss: 1.2967 - val_accuracy: 0.3896

Epoch 00531: val_loss did not improve from 1.29449
Epoch 532/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4045 - val_loss: 1.3015 - val_accuracy: 0.3817

Epoch 00532: val_loss did not improve from 1.29449
Epoch 533/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4021 - val_loss: 1.2976 - val_accuracy: 0.4072

Epoch 00533: val_loss did not improve from 1.29449
Epoch 534/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4046 - val_loss: 1.2980 - val_accuracy: 0.3920

Epoch 00534: val_loss did not improve from 1.29449
Epoch 535/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4075 - val_loss: 1.2978 - val_accuracy: 0.3936

Epoch 00535: val_loss did not improve from 1.29449
Epoch 536/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4071 - val_loss: 1.3001 - val_accuracy: 0.3896

Epoch 00536: val_loss did not improve from 1.29449
Epoch 537/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4063 - val_loss: 1.2986 - val_accuracy: 0.3849

Epoch 00537: val_loss did not improve from 1.29449
Epoch 538/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4039 - val_loss: 1.2996 - val_accuracy: 0.3841

Epoch 00538: val_loss did not improve from 1.29449
Epoch 539/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4030 - val_loss: 1.3055 - val_accuracy: 0.3841

Epoch 00539: val_loss did not improve from 1.29449
Epoch 540/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4046 - val_loss: 1.3001 - val_accuracy: 0.3984

Epoch 00540: val_loss did not improve from 1.29449
Epoch 541/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4054 - val_loss: 1.3042 - val_accuracy: 0.3857

Epoch 00541: val_loss did not improve from 1.29449
Epoch 542/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4085 - val_loss: 1.3014 - val_accuracy: 0.3944

Epoch 00542: val_loss did not improve from 1.29449
Epoch 543/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4030 - val_loss: 1.2961 - val_accuracy: 0.4040

Epoch 00543: val_loss did not improve from 1.29449
Epoch 544/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4055 - val_loss: 1.3024 - val_accuracy: 0.3833

Epoch 00544: val_loss did not improve from 1.29449
Epoch 545/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4066 - val_loss: 1.2984 - val_accuracy: 0.3936

Epoch 00545: val_loss did not improve from 1.29449
Epoch 546/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4041 - val_loss: 1.2999 - val_accuracy: 0.3865

Epoch 00546: val_loss did not improve from 1.29449
Epoch 547/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4053 - val_loss: 1.3003 - val_accuracy: 0.3849

Epoch 00547: val_loss did not improve from 1.29449
Epoch 548/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4050 - val_loss: 1.2961 - val_accuracy: 0.3888

Epoch 00548: val_loss did not improve from 1.29449
Epoch 549/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4054 - val_loss: 1.2980 - val_accuracy: 0.3873

Epoch 00549: val_loss did not improve from 1.29449
Epoch 550/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4050 - val_loss: 1.2994 - val_accuracy: 0.3865

Epoch 00550: val_loss did not improve from 1.29449
Epoch 551/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4049 - val_loss: 1.2995 - val_accuracy: 0.3849

Epoch 00551: val_loss did not improve from 1.29449
Epoch 552/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4043 - val_loss: 1.2983 - val_accuracy: 0.3992

Epoch 00552: val_loss did not improve from 1.29449
Epoch 553/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4058 - val_loss: 1.3023 - val_accuracy: 0.3841

Epoch 00553: val_loss did not improve from 1.29449
Epoch 554/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4063 - val_loss: 1.2962 - val_accuracy: 0.3912

Epoch 00554: val_loss did not improve from 1.29449
Epoch 555/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4043 - val_loss: 1.3012 - val_accuracy: 0.3825

Epoch 00555: val_loss did not improve from 1.29449
Epoch 556/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4065 - val_loss: 1.3003 - val_accuracy: 0.3976

Epoch 00556: val_loss did not improve from 1.29449
Epoch 557/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4067 - val_loss: 1.3024 - val_accuracy: 0.3880

Epoch 00557: val_loss did not improve from 1.29449
Epoch 558/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4069 - val_loss: 1.2966 - val_accuracy: 0.3865

Epoch 00558: val_loss did not improve from 1.29449
Epoch 559/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4072 - val_loss: 1.2975 - val_accuracy: 0.3888

Epoch 00559: val_loss did not improve from 1.29449
Epoch 560/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4054 - val_loss: 1.2963 - val_accuracy: 0.3896

Epoch 00560: val_loss did not improve from 1.29449
Epoch 561/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4079 - val_loss: 1.2989 - val_accuracy: 0.3896

Epoch 00561: val_loss did not improve from 1.29449
Epoch 562/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4098 - val_loss: 1.2990 - val_accuracy: 0.3928

Epoch 00562: val_loss did not improve from 1.29449
Epoch 563/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4058 - val_loss: 1.2990 - val_accuracy: 0.3880

Epoch 00563: val_loss did not improve from 1.29449
Epoch 564/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4045 - val_loss: 1.2990 - val_accuracy: 0.3817

Epoch 00564: val_loss did not improve from 1.29449
Epoch 565/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4052 - val_loss: 1.2984 - val_accuracy: 0.3936

Epoch 00565: val_loss did not improve from 1.29449
Epoch 566/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4055 - val_loss: 1.3021 - val_accuracy: 0.3904

Epoch 00566: val_loss did not improve from 1.29449
Epoch 567/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4066 - val_loss: 1.3020 - val_accuracy: 0.3801

Epoch 00567: val_loss did not improve from 1.29449
Epoch 568/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4052 - val_loss: 1.2969 - val_accuracy: 0.3936

Epoch 00568: val_loss did not improve from 1.29449
Epoch 569/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4036 - val_loss: 1.3050 - val_accuracy: 0.3873

Epoch 00569: val_loss did not improve from 1.29449
Epoch 570/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4040 - val_loss: 1.3003 - val_accuracy: 0.3920

Epoch 00570: val_loss did not improve from 1.29449
Epoch 571/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4044 - val_loss: 1.2996 - val_accuracy: 0.3841

Epoch 00571: val_loss did not improve from 1.29449
Epoch 572/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4027 - val_loss: 1.2967 - val_accuracy: 0.3896

Epoch 00572: val_loss did not improve from 1.29449
Epoch 573/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4041 - val_loss: 1.2990 - val_accuracy: 0.3880

Epoch 00573: val_loss did not improve from 1.29449
Epoch 574/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4086 - val_loss: 1.2967 - val_accuracy: 0.3857

Epoch 00574: val_loss did not improve from 1.29449
Epoch 575/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4021 - val_loss: 1.2971 - val_accuracy: 0.3873

Epoch 00575: val_loss did not improve from 1.29449
Epoch 576/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4043 - val_loss: 1.2987 - val_accuracy: 0.3801

Epoch 00576: val_loss did not improve from 1.29449
Epoch 577/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4040 - val_loss: 1.2948 - val_accuracy: 0.3928

Epoch 00577: val_loss did not improve from 1.29449
Epoch 578/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4071 - val_loss: 1.2992 - val_accuracy: 0.3841

Epoch 00578: val_loss did not improve from 1.29449
Epoch 579/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4032 - val_loss: 1.2987 - val_accuracy: 0.3880

Epoch 00579: val_loss did not improve from 1.29449
Epoch 580/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4042 - val_loss: 1.2972 - val_accuracy: 0.3857

Epoch 00580: val_loss did not improve from 1.29449
Epoch 581/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4058 - val_loss: 1.2995 - val_accuracy: 0.3825

Epoch 00581: val_loss did not improve from 1.29449
Epoch 582/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4056 - val_loss: 1.2991 - val_accuracy: 0.4008

Epoch 00582: val_loss did not improve from 1.29449
Epoch 583/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4053 - val_loss: 1.3000 - val_accuracy: 0.3833

Epoch 00583: val_loss did not improve from 1.29449
Epoch 584/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4050 - val_loss: 1.2999 - val_accuracy: 0.3857

Epoch 00584: val_loss did not improve from 1.29449
Epoch 585/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4064 - val_loss: 1.3020 - val_accuracy: 0.3904

Epoch 00585: val_loss did not improve from 1.29449
Epoch 586/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4040 - val_loss: 1.2964 - val_accuracy: 0.3960

Epoch 00586: val_loss did not improve from 1.29449
Epoch 587/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4051 - val_loss: 1.3013 - val_accuracy: 0.3904

Epoch 00587: val_loss did not improve from 1.29449
Epoch 588/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4059 - val_loss: 1.2972 - val_accuracy: 0.3880

Epoch 00588: val_loss did not improve from 1.29449
Epoch 589/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4052 - val_loss: 1.3016 - val_accuracy: 0.3817

Epoch 00589: val_loss did not improve from 1.29449
Epoch 590/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3988 - val_loss: 1.3013 - val_accuracy: 0.3785

Epoch 00590: val_loss did not improve from 1.29449
Epoch 591/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4043 - val_loss: 1.3027 - val_accuracy: 0.3849

Epoch 00591: val_loss did not improve from 1.29449
Epoch 592/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4032 - val_loss: 1.2996 - val_accuracy: 0.3873

Epoch 00592: val_loss did not improve from 1.29449
Epoch 593/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4040 - val_loss: 1.2990 - val_accuracy: 0.3896

Epoch 00593: val_loss did not improve from 1.29449
Epoch 594/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4057 - val_loss: 1.3009 - val_accuracy: 0.3809

Epoch 00594: val_loss did not improve from 1.29449
Epoch 595/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4078 - val_loss: 1.2974 - val_accuracy: 0.3841

Epoch 00595: val_loss did not improve from 1.29449
Epoch 596/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4058 - val_loss: 1.3010 - val_accuracy: 0.3761

Epoch 00596: val_loss did not improve from 1.29449
Epoch 597/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4035 - val_loss: 1.2982 - val_accuracy: 0.3825

Epoch 00597: val_loss did not improve from 1.29449
Epoch 598/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4035 - val_loss: 1.3003 - val_accuracy: 0.3880

Epoch 00598: val_loss did not improve from 1.29449
Epoch 599/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4036 - val_loss: 1.2977 - val_accuracy: 0.3849

Epoch 00599: val_loss did not improve from 1.29449
Epoch 600/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4066 - val_loss: 1.2979 - val_accuracy: 0.3904

Epoch 00600: val_loss did not improve from 1.29449
Epoch 601/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4041 - val_loss: 1.2997 - val_accuracy: 0.3873

Epoch 00601: val_loss did not improve from 1.29449
Epoch 602/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4072 - val_loss: 1.3027 - val_accuracy: 0.3904

Epoch 00602: val_loss did not improve from 1.29449
Epoch 603/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4019 - val_loss: 1.2990 - val_accuracy: 0.3904

Epoch 00603: val_loss did not improve from 1.29449
Epoch 604/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4042 - val_loss: 1.2967 - val_accuracy: 0.3865

Epoch 00604: val_loss did not improve from 1.29449
Epoch 605/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4027 - val_loss: 1.3019 - val_accuracy: 0.3777

Epoch 00605: val_loss did not improve from 1.29449
Epoch 606/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4049 - val_loss: 1.2994 - val_accuracy: 0.3896

Epoch 00606: val_loss did not improve from 1.29449
Epoch 607/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4037 - val_loss: 1.3001 - val_accuracy: 0.3904

Epoch 00607: val_loss did not improve from 1.29449
Epoch 608/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4053 - val_loss: 1.3024 - val_accuracy: 0.3857

Epoch 00608: val_loss did not improve from 1.29449
Epoch 609/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4065 - val_loss: 1.2979 - val_accuracy: 0.3904

Epoch 00609: val_loss did not improve from 1.29449
Epoch 610/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4089 - val_loss: 1.2983 - val_accuracy: 0.3976

Epoch 00610: val_loss did not improve from 1.29449
Epoch 611/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4058 - val_loss: 1.3012 - val_accuracy: 0.3769

Epoch 00611: val_loss did not improve from 1.29449
Epoch 612/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4050 - val_loss: 1.3026 - val_accuracy: 0.3896

Epoch 00612: val_loss did not improve from 1.29449
Epoch 613/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4069 - val_loss: 1.3008 - val_accuracy: 0.4000

Epoch 00613: val_loss did not improve from 1.29449
Epoch 614/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4060 - val_loss: 1.2976 - val_accuracy: 0.3880

Epoch 00614: val_loss did not improve from 1.29449
Epoch 615/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4026 - val_loss: 1.3003 - val_accuracy: 0.3841

Epoch 00615: val_loss did not improve from 1.29449
Epoch 616/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4034 - val_loss: 1.2961 - val_accuracy: 0.3936

Epoch 00616: val_loss did not improve from 1.29449
Epoch 617/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4052 - val_loss: 1.2961 - val_accuracy: 0.3912

Epoch 00617: val_loss did not improve from 1.29449
Epoch 618/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4055 - val_loss: 1.2995 - val_accuracy: 0.3928

Epoch 00618: val_loss did not improve from 1.29449
Epoch 619/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4052 - val_loss: 1.2974 - val_accuracy: 0.3912

Epoch 00619: val_loss did not improve from 1.29449
Epoch 620/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4052 - val_loss: 1.2968 - val_accuracy: 0.3896

Epoch 00620: val_loss did not improve from 1.29449
Epoch 621/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4027 - val_loss: 1.3015 - val_accuracy: 0.3865

Epoch 00621: val_loss did not improve from 1.29449
Epoch 622/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4050 - val_loss: 1.3008 - val_accuracy: 0.3841

Epoch 00622: val_loss did not improve from 1.29449
Epoch 623/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4066 - val_loss: 1.3023 - val_accuracy: 0.3944

Epoch 00623: val_loss did not improve from 1.29449
Epoch 624/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4066 - val_loss: 1.3007 - val_accuracy: 0.3841

Epoch 00624: val_loss did not improve from 1.29449
Epoch 625/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4038 - val_loss: 1.3004 - val_accuracy: 0.3817

Epoch 00625: val_loss did not improve from 1.29449
Epoch 626/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4089 - val_loss: 1.2965 - val_accuracy: 0.3992

Epoch 00626: val_loss did not improve from 1.29449
Epoch 627/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4066 - val_loss: 1.2993 - val_accuracy: 0.3849

Epoch 00627: val_loss did not improve from 1.29449
Epoch 628/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4069 - val_loss: 1.3016 - val_accuracy: 0.3809

Epoch 00628: val_loss did not improve from 1.29449
Epoch 629/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4058 - val_loss: 1.2986 - val_accuracy: 0.3896

Epoch 00629: val_loss did not improve from 1.29449
Epoch 630/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4049 - val_loss: 1.2967 - val_accuracy: 0.3857

Epoch 00630: val_loss did not improve from 1.29449
Epoch 631/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4056 - val_loss: 1.2991 - val_accuracy: 0.3873

Epoch 00631: val_loss did not improve from 1.29449
Epoch 632/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4081 - val_loss: 1.3005 - val_accuracy: 0.3849

Epoch 00632: val_loss did not improve from 1.29449
Epoch 633/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4072 - val_loss: 1.2995 - val_accuracy: 0.3849

Epoch 00633: val_loss did not improve from 1.29449
Epoch 634/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4066 - val_loss: 1.2981 - val_accuracy: 0.4024

Epoch 00634: val_loss did not improve from 1.29449
Epoch 635/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4067 - val_loss: 1.3023 - val_accuracy: 0.3873

Epoch 00635: val_loss did not improve from 1.29449
Epoch 636/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4046 - val_loss: 1.2983 - val_accuracy: 0.3928

Epoch 00636: val_loss did not improve from 1.29449
Epoch 637/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4089 - val_loss: 1.3026 - val_accuracy: 0.3785

Epoch 00637: val_loss did not improve from 1.29449
Epoch 638/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4059 - val_loss: 1.3002 - val_accuracy: 0.3952

Epoch 00638: val_loss did not improve from 1.29449
Epoch 639/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4039 - val_loss: 1.3089 - val_accuracy: 0.3817

Epoch 00639: val_loss did not improve from 1.29449
Epoch 640/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4026 - val_loss: 1.2976 - val_accuracy: 0.4000

Epoch 00640: val_loss did not improve from 1.29449
Epoch 641/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4046 - val_loss: 1.2986 - val_accuracy: 0.3912

Epoch 00641: val_loss did not improve from 1.29449
Epoch 642/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4050 - val_loss: 1.2960 - val_accuracy: 0.3912

Epoch 00642: val_loss did not improve from 1.29449
Epoch 643/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4043 - val_loss: 1.2976 - val_accuracy: 0.3873

Epoch 00643: val_loss did not improve from 1.29449
Epoch 644/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4063 - val_loss: 1.3015 - val_accuracy: 0.3984

Epoch 00644: val_loss did not improve from 1.29449
Epoch 645/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4081 - val_loss: 1.3011 - val_accuracy: 0.3904

Epoch 00645: val_loss did not improve from 1.29449
Epoch 646/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4091 - val_loss: 1.2982 - val_accuracy: 0.3841

Epoch 00646: val_loss did not improve from 1.29449
Epoch 647/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4085 - val_loss: 1.2998 - val_accuracy: 0.3904

Epoch 00647: val_loss did not improve from 1.29449
Epoch 648/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4047 - val_loss: 1.2973 - val_accuracy: 0.3880

Epoch 00648: val_loss did not improve from 1.29449
Epoch 649/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4074 - val_loss: 1.2976 - val_accuracy: 0.3865

Epoch 00649: val_loss did not improve from 1.29449
Epoch 650/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4050 - val_loss: 1.2997 - val_accuracy: 0.3817

Epoch 00650: val_loss did not improve from 1.29449
Epoch 651/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4036 - val_loss: 1.2996 - val_accuracy: 0.3769

Epoch 00651: val_loss did not improve from 1.29449
Epoch 652/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4040 - val_loss: 1.2982 - val_accuracy: 0.3920

Epoch 00652: val_loss did not improve from 1.29449
Epoch 653/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4085 - val_loss: 1.2982 - val_accuracy: 0.3849

Epoch 00653: val_loss did not improve from 1.29449
Epoch 654/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4087 - val_loss: 1.3001 - val_accuracy: 0.3865

Epoch 00654: val_loss did not improve from 1.29449
Epoch 655/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4059 - val_loss: 1.2991 - val_accuracy: 0.3888

Epoch 00655: val_loss did not improve from 1.29449
Epoch 656/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4070 - val_loss: 1.2970 - val_accuracy: 0.3968

Epoch 00656: val_loss did not improve from 1.29449
Epoch 657/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4043 - val_loss: 1.3000 - val_accuracy: 0.3833

Epoch 00657: val_loss did not improve from 1.29449
Epoch 658/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4091 - val_loss: 1.2995 - val_accuracy: 0.3857

Epoch 00658: val_loss did not improve from 1.29449
Epoch 659/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4042 - val_loss: 1.2982 - val_accuracy: 0.3896

Epoch 00659: val_loss did not improve from 1.29449
Epoch 660/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4034 - val_loss: 1.3077 - val_accuracy: 0.3904

Epoch 00660: val_loss did not improve from 1.29449
Epoch 661/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4035 - val_loss: 1.3008 - val_accuracy: 0.3873

Epoch 00661: val_loss did not improve from 1.29449
Epoch 662/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4058 - val_loss: 1.3025 - val_accuracy: 0.3801

Epoch 00662: val_loss did not improve from 1.29449
Epoch 663/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4097 - val_loss: 1.2998 - val_accuracy: 0.3920

Epoch 00663: val_loss did not improve from 1.29449
Epoch 664/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4097 - val_loss: 1.3004 - val_accuracy: 0.4008

Epoch 00664: val_loss did not improve from 1.29449
Epoch 665/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4066 - val_loss: 1.3019 - val_accuracy: 0.3865

Epoch 00665: val_loss did not improve from 1.29449
Epoch 666/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4041 - val_loss: 1.2987 - val_accuracy: 0.3936

Epoch 00666: val_loss did not improve from 1.29449
Epoch 667/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4042 - val_loss: 1.2975 - val_accuracy: 0.3976

Epoch 00667: val_loss did not improve from 1.29449
Epoch 668/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4049 - val_loss: 1.3070 - val_accuracy: 0.3873

Epoch 00668: val_loss did not improve from 1.29449
Epoch 669/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4060 - val_loss: 1.3038 - val_accuracy: 0.3777

Epoch 00669: val_loss did not improve from 1.29449
Epoch 670/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4013 - val_loss: 1.2984 - val_accuracy: 0.3873

Epoch 00670: val_loss did not improve from 1.29449
Epoch 671/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4020 - val_loss: 1.2973 - val_accuracy: 0.3992

Epoch 00671: val_loss did not improve from 1.29449
Epoch 672/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4079 - val_loss: 1.3061 - val_accuracy: 0.3944

Epoch 00672: val_loss did not improve from 1.29449
Epoch 673/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4059 - val_loss: 1.2974 - val_accuracy: 0.3960

Epoch 00673: val_loss did not improve from 1.29449
Epoch 674/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4053 - val_loss: 1.3046 - val_accuracy: 0.3793

Epoch 00674: val_loss did not improve from 1.29449
Epoch 675/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4047 - val_loss: 1.2978 - val_accuracy: 0.3912

Epoch 00675: val_loss did not improve from 1.29449
Epoch 676/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4087 - val_loss: 1.3020 - val_accuracy: 0.3888

Epoch 00676: val_loss did not improve from 1.29449
Epoch 677/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4056 - val_loss: 1.2977 - val_accuracy: 0.3952

Epoch 00677: val_loss did not improve from 1.29449
Epoch 678/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4066 - val_loss: 1.2978 - val_accuracy: 0.3880

Epoch 00678: val_loss did not improve from 1.29449
Epoch 679/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4052 - val_loss: 1.2971 - val_accuracy: 0.3825

Epoch 00679: val_loss did not improve from 1.29449
Epoch 680/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4047 - val_loss: 1.2987 - val_accuracy: 0.3960

Epoch 00680: val_loss did not improve from 1.29449
Epoch 681/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4061 - val_loss: 1.3017 - val_accuracy: 0.3777

Epoch 00681: val_loss did not improve from 1.29449
Epoch 682/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4077 - val_loss: 1.2984 - val_accuracy: 0.3976

Epoch 00682: val_loss did not improve from 1.29449
Epoch 683/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4085 - val_loss: 1.2989 - val_accuracy: 0.3936

Epoch 00683: val_loss did not improve from 1.29449
Epoch 684/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4099 - val_loss: 1.2978 - val_accuracy: 0.3841

Epoch 00684: val_loss did not improve from 1.29449
Epoch 685/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4055 - val_loss: 1.2992 - val_accuracy: 0.3817

Epoch 00685: val_loss did not improve from 1.29449
Epoch 686/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4058 - val_loss: 1.2989 - val_accuracy: 0.3896

Epoch 00686: val_loss did not improve from 1.29449
Epoch 687/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4076 - val_loss: 1.3034 - val_accuracy: 0.3825

Epoch 00687: val_loss did not improve from 1.29449
Epoch 688/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4065 - val_loss: 1.2995 - val_accuracy: 0.3912

Epoch 00688: val_loss did not improve from 1.29449
Epoch 689/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4043 - val_loss: 1.2983 - val_accuracy: 0.3912

Epoch 00689: val_loss did not improve from 1.29449
Epoch 690/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4055 - val_loss: 1.2983 - val_accuracy: 0.3865

Epoch 00690: val_loss did not improve from 1.29449
Epoch 691/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4066 - val_loss: 1.2994 - val_accuracy: 0.3857

Epoch 00691: val_loss did not improve from 1.29449
Epoch 692/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4061 - val_loss: 1.2986 - val_accuracy: 0.3920

Epoch 00692: val_loss did not improve from 1.29449
Epoch 693/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4070 - val_loss: 1.2998 - val_accuracy: 0.3920

Epoch 00693: val_loss did not improve from 1.29449
Epoch 694/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4093 - val_loss: 1.3040 - val_accuracy: 0.3960

Epoch 00694: val_loss did not improve from 1.29449
Epoch 695/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4074 - val_loss: 1.3014 - val_accuracy: 0.3896

Epoch 00695: val_loss did not improve from 1.29449
Epoch 696/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4055 - val_loss: 1.2980 - val_accuracy: 0.3904

Epoch 00696: val_loss did not improve from 1.29449
Epoch 697/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4092 - val_loss: 1.2988 - val_accuracy: 0.3888

Epoch 00697: val_loss did not improve from 1.29449
Epoch 698/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4050 - val_loss: 1.2996 - val_accuracy: 0.3880

Epoch 00698: val_loss did not improve from 1.29449
Epoch 699/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4076 - val_loss: 1.3033 - val_accuracy: 0.3785

Epoch 00699: val_loss did not improve from 1.29449
Epoch 700/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4061 - val_loss: 1.2972 - val_accuracy: 0.3920

Epoch 00700: val_loss did not improve from 1.29449
Epoch 701/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4080 - val_loss: 1.3021 - val_accuracy: 0.3833

Epoch 00701: val_loss did not improve from 1.29449
Epoch 702/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4066 - val_loss: 1.2977 - val_accuracy: 0.3912

Epoch 00702: val_loss did not improve from 1.29449
Epoch 703/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4043 - val_loss: 1.2992 - val_accuracy: 0.3873

Epoch 00703: val_loss did not improve from 1.29449
Epoch 704/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4023 - val_loss: 1.3011 - val_accuracy: 0.3904

Epoch 00704: val_loss did not improve from 1.29449
Epoch 705/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4077 - val_loss: 1.3042 - val_accuracy: 0.3952

Epoch 00705: val_loss did not improve from 1.29449
Epoch 706/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4074 - val_loss: 1.3005 - val_accuracy: 0.3833

Epoch 00706: val_loss did not improve from 1.29449
Epoch 707/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4070 - val_loss: 1.3022 - val_accuracy: 0.3888

Epoch 00707: val_loss did not improve from 1.29449
Epoch 708/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4068 - val_loss: 1.2977 - val_accuracy: 0.3960

Epoch 00708: val_loss did not improve from 1.29449
Epoch 00708: early stopping
*************************** Fold #: 5 ***************************
Model: "sequential_64"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_256 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_257 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_258 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_259 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6062 - accuracy: 0.2153 - val_loss: 1.6009 - val_accuracy: 0.2382

Epoch 00001: val_loss improved from inf to 1.60095, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 2/10000
12/12 - 0s - loss: 1.5985 - accuracy: 0.2454 - val_loss: 1.5932 - val_accuracy: 0.2789

Epoch 00002: val_loss improved from 1.60095 to 1.59320, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 3/10000
12/12 - 0s - loss: 1.5896 - accuracy: 0.2872 - val_loss: 1.5832 - val_accuracy: 0.2932

Epoch 00003: val_loss improved from 1.59320 to 1.58320, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 4/10000
12/12 - 0s - loss: 1.5773 - accuracy: 0.3072 - val_loss: 1.5683 - val_accuracy: 0.3084

Epoch 00004: val_loss improved from 1.58320 to 1.56833, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 5/10000
12/12 - 0s - loss: 1.5582 - accuracy: 0.3282 - val_loss: 1.5464 - val_accuracy: 0.3259

Epoch 00005: val_loss improved from 1.56833 to 1.54642, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 6/10000
12/12 - 0s - loss: 1.5336 - accuracy: 0.3340 - val_loss: 1.5190 - val_accuracy: 0.3219

Epoch 00006: val_loss improved from 1.54642 to 1.51899, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 7/10000
12/12 - 0s - loss: 1.5005 - accuracy: 0.3427 - val_loss: 1.4843 - val_accuracy: 0.3402

Epoch 00007: val_loss improved from 1.51899 to 1.48435, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 8/10000
12/12 - 0s - loss: 1.4637 - accuracy: 0.3604 - val_loss: 1.4498 - val_accuracy: 0.3410

Epoch 00008: val_loss improved from 1.48435 to 1.44983, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 9/10000
12/12 - 0s - loss: 1.4287 - accuracy: 0.3561 - val_loss: 1.4200 - val_accuracy: 0.3410

Epoch 00009: val_loss improved from 1.44983 to 1.42003, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 10/10000
12/12 - 0s - loss: 1.3972 - accuracy: 0.3659 - val_loss: 1.3960 - val_accuracy: 0.3594

Epoch 00010: val_loss improved from 1.42003 to 1.39603, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 11/10000
12/12 - 0s - loss: 1.3733 - accuracy: 0.3826 - val_loss: 1.3775 - val_accuracy: 0.3490

Epoch 00011: val_loss improved from 1.39603 to 1.37749, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 12/10000
12/12 - 0s - loss: 1.3563 - accuracy: 0.3917 - val_loss: 1.3675 - val_accuracy: 0.3602

Epoch 00012: val_loss improved from 1.37749 to 1.36752, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 13/10000
12/12 - 0s - loss: 1.3516 - accuracy: 0.3902 - val_loss: 1.3638 - val_accuracy: 0.3769

Epoch 00013: val_loss improved from 1.36752 to 1.36375, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 14/10000
12/12 - 0s - loss: 1.3429 - accuracy: 0.3888 - val_loss: 1.3650 - val_accuracy: 0.3873

Epoch 00014: val_loss did not improve from 1.36375
Epoch 15/10000
12/12 - 0s - loss: 1.3490 - accuracy: 0.3910 - val_loss: 1.3619 - val_accuracy: 0.3681

Epoch 00015: val_loss improved from 1.36375 to 1.36186, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 16/10000
12/12 - 0s - loss: 1.3388 - accuracy: 0.3919 - val_loss: 1.3526 - val_accuracy: 0.3681

Epoch 00016: val_loss improved from 1.36186 to 1.35263, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 17/10000
12/12 - 0s - loss: 1.3356 - accuracy: 0.3841 - val_loss: 1.3556 - val_accuracy: 0.3713

Epoch 00017: val_loss did not improve from 1.35263
Epoch 18/10000
12/12 - 0s - loss: 1.3376 - accuracy: 0.4012 - val_loss: 1.3573 - val_accuracy: 0.3785

Epoch 00018: val_loss did not improve from 1.35263
Epoch 19/10000
12/12 - 0s - loss: 1.3368 - accuracy: 0.3978 - val_loss: 1.3516 - val_accuracy: 0.3769

Epoch 00019: val_loss improved from 1.35263 to 1.35162, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 20/10000
12/12 - 0s - loss: 1.3340 - accuracy: 0.3862 - val_loss: 1.3547 - val_accuracy: 0.3713

Epoch 00020: val_loss did not improve from 1.35162
Epoch 21/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3911 - val_loss: 1.3526 - val_accuracy: 0.3673

Epoch 00021: val_loss did not improve from 1.35162
Epoch 22/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3886 - val_loss: 1.3518 - val_accuracy: 0.3705

Epoch 00022: val_loss did not improve from 1.35162
Epoch 23/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3876 - val_loss: 1.3512 - val_accuracy: 0.3681

Epoch 00023: val_loss improved from 1.35162 to 1.35122, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 24/10000
12/12 - 0s - loss: 1.3319 - accuracy: 0.3921 - val_loss: 1.3489 - val_accuracy: 0.3769

Epoch 00024: val_loss improved from 1.35122 to 1.34887, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 25/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3885 - val_loss: 1.3517 - val_accuracy: 0.3761

Epoch 00025: val_loss did not improve from 1.34887
Epoch 26/10000
12/12 - 0s - loss: 1.3343 - accuracy: 0.3932 - val_loss: 1.3543 - val_accuracy: 0.3681

Epoch 00026: val_loss did not improve from 1.34887
Epoch 27/10000
12/12 - 0s - loss: 1.3354 - accuracy: 0.3919 - val_loss: 1.3528 - val_accuracy: 0.3785

Epoch 00027: val_loss did not improve from 1.34887
Epoch 28/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3953 - val_loss: 1.3493 - val_accuracy: 0.3697

Epoch 00028: val_loss did not improve from 1.34887
Epoch 29/10000
12/12 - 0s - loss: 1.3299 - accuracy: 0.3876 - val_loss: 1.3488 - val_accuracy: 0.3753

Epoch 00029: val_loss improved from 1.34887 to 1.34885, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 30/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3925 - val_loss: 1.3491 - val_accuracy: 0.3841

Epoch 00030: val_loss did not improve from 1.34885
Epoch 31/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3964 - val_loss: 1.3490 - val_accuracy: 0.3793

Epoch 00031: val_loss did not improve from 1.34885
Epoch 32/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3929 - val_loss: 1.3500 - val_accuracy: 0.3737

Epoch 00032: val_loss did not improve from 1.34885
Epoch 33/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.3871 - val_loss: 1.3502 - val_accuracy: 0.3833

Epoch 00033: val_loss did not improve from 1.34885
Epoch 34/10000
12/12 - 0s - loss: 1.3322 - accuracy: 0.3864 - val_loss: 1.3469 - val_accuracy: 0.3841

Epoch 00034: val_loss improved from 1.34885 to 1.34686, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 35/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3928 - val_loss: 1.3460 - val_accuracy: 0.3769

Epoch 00035: val_loss improved from 1.34686 to 1.34603, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 36/10000
12/12 - 0s - loss: 1.3309 - accuracy: 0.3933 - val_loss: 1.3478 - val_accuracy: 0.3753

Epoch 00036: val_loss did not improve from 1.34603
Epoch 37/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3944 - val_loss: 1.3460 - val_accuracy: 0.3873

Epoch 00037: val_loss did not improve from 1.34603
Epoch 38/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3942 - val_loss: 1.3465 - val_accuracy: 0.3737

Epoch 00038: val_loss did not improve from 1.34603
Epoch 39/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3910 - val_loss: 1.3469 - val_accuracy: 0.3761

Epoch 00039: val_loss did not improve from 1.34603
Epoch 40/10000
12/12 - 0s - loss: 1.3284 - accuracy: 0.3944 - val_loss: 1.3472 - val_accuracy: 0.3745

Epoch 00040: val_loss did not improve from 1.34603
Epoch 41/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3895 - val_loss: 1.3485 - val_accuracy: 0.3673

Epoch 00041: val_loss did not improve from 1.34603
Epoch 42/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3941 - val_loss: 1.3485 - val_accuracy: 0.3873

Epoch 00042: val_loss did not improve from 1.34603
Epoch 43/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3995 - val_loss: 1.3493 - val_accuracy: 0.3777

Epoch 00043: val_loss did not improve from 1.34603
Epoch 44/10000
12/12 - 0s - loss: 1.3284 - accuracy: 0.3973 - val_loss: 1.3558 - val_accuracy: 0.3825

Epoch 00044: val_loss did not improve from 1.34603
Epoch 45/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3972 - val_loss: 1.3532 - val_accuracy: 0.3745

Epoch 00045: val_loss did not improve from 1.34603
Epoch 46/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3949 - val_loss: 1.3451 - val_accuracy: 0.3880

Epoch 00046: val_loss improved from 1.34603 to 1.34514, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 47/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3880 - val_loss: 1.3465 - val_accuracy: 0.3713

Epoch 00047: val_loss did not improve from 1.34514
Epoch 48/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3888 - val_loss: 1.3461 - val_accuracy: 0.3737

Epoch 00048: val_loss did not improve from 1.34514
Epoch 49/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3873 - val_loss: 1.3463 - val_accuracy: 0.3745

Epoch 00049: val_loss did not improve from 1.34514
Epoch 50/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3931 - val_loss: 1.3502 - val_accuracy: 0.3825

Epoch 00050: val_loss did not improve from 1.34514
Epoch 51/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.4010 - val_loss: 1.3498 - val_accuracy: 0.3665

Epoch 00051: val_loss did not improve from 1.34514
Epoch 52/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3911 - val_loss: 1.3471 - val_accuracy: 0.3777

Epoch 00052: val_loss did not improve from 1.34514
Epoch 53/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.3900 - val_loss: 1.3464 - val_accuracy: 0.3721

Epoch 00053: val_loss did not improve from 1.34514
Epoch 54/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.3889 - val_loss: 1.3478 - val_accuracy: 0.3665

Epoch 00054: val_loss did not improve from 1.34514
Epoch 55/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3867 - val_loss: 1.3468 - val_accuracy: 0.3793

Epoch 00055: val_loss did not improve from 1.34514
Epoch 56/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3942 - val_loss: 1.3470 - val_accuracy: 0.3777

Epoch 00056: val_loss did not improve from 1.34514
Epoch 57/10000
12/12 - 0s - loss: 1.3276 - accuracy: 0.3940 - val_loss: 1.3475 - val_accuracy: 0.3841

Epoch 00057: val_loss did not improve from 1.34514
Epoch 58/10000
12/12 - 0s - loss: 1.3276 - accuracy: 0.3989 - val_loss: 1.3457 - val_accuracy: 0.3833

Epoch 00058: val_loss did not improve from 1.34514
Epoch 59/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3975 - val_loss: 1.3466 - val_accuracy: 0.3753

Epoch 00059: val_loss did not improve from 1.34514
Epoch 60/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3872 - val_loss: 1.3529 - val_accuracy: 0.3769

Epoch 00060: val_loss did not improve from 1.34514
Epoch 61/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3948 - val_loss: 1.3472 - val_accuracy: 0.3896

Epoch 00061: val_loss did not improve from 1.34514
Epoch 62/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3995 - val_loss: 1.3458 - val_accuracy: 0.3896

Epoch 00062: val_loss did not improve from 1.34514
Epoch 63/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.4008 - val_loss: 1.3438 - val_accuracy: 0.3896

Epoch 00063: val_loss improved from 1.34514 to 1.34376, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 64/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3981 - val_loss: 1.3444 - val_accuracy: 0.3849

Epoch 00064: val_loss did not improve from 1.34376
Epoch 65/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.4008 - val_loss: 1.3495 - val_accuracy: 0.3713

Epoch 00065: val_loss did not improve from 1.34376
Epoch 66/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3888 - val_loss: 1.3468 - val_accuracy: 0.3753

Epoch 00066: val_loss did not improve from 1.34376
Epoch 67/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3970 - val_loss: 1.3445 - val_accuracy: 0.3888

Epoch 00067: val_loss did not improve from 1.34376
Epoch 68/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3932 - val_loss: 1.3480 - val_accuracy: 0.3697

Epoch 00068: val_loss did not improve from 1.34376
Epoch 69/10000
12/12 - 0s - loss: 1.3282 - accuracy: 0.3863 - val_loss: 1.3489 - val_accuracy: 0.3936

Epoch 00069: val_loss did not improve from 1.34376
Epoch 70/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3953 - val_loss: 1.3454 - val_accuracy: 0.3825

Epoch 00070: val_loss did not improve from 1.34376
Epoch 71/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3962 - val_loss: 1.3440 - val_accuracy: 0.3793

Epoch 00071: val_loss did not improve from 1.34376
Epoch 72/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3948 - val_loss: 1.3435 - val_accuracy: 0.3793

Epoch 00072: val_loss improved from 1.34376 to 1.34348, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 73/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3929 - val_loss: 1.3441 - val_accuracy: 0.3817

Epoch 00073: val_loss did not improve from 1.34348
Epoch 74/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3925 - val_loss: 1.3432 - val_accuracy: 0.3809

Epoch 00074: val_loss improved from 1.34348 to 1.34321, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 75/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.4002 - val_loss: 1.3448 - val_accuracy: 0.3849

Epoch 00075: val_loss did not improve from 1.34321
Epoch 76/10000
12/12 - 0s - loss: 1.3298 - accuracy: 0.3974 - val_loss: 1.3484 - val_accuracy: 0.3936

Epoch 00076: val_loss did not improve from 1.34321
Epoch 77/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3943 - val_loss: 1.3476 - val_accuracy: 0.3657

Epoch 00077: val_loss did not improve from 1.34321
Epoch 78/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3939 - val_loss: 1.3478 - val_accuracy: 0.3761

Epoch 00078: val_loss did not improve from 1.34321
Epoch 79/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3942 - val_loss: 1.3443 - val_accuracy: 0.3912

Epoch 00079: val_loss did not improve from 1.34321
Epoch 80/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.4002 - val_loss: 1.3419 - val_accuracy: 0.4064

Epoch 00080: val_loss improved from 1.34321 to 1.34195, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 81/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.4015 - val_loss: 1.3435 - val_accuracy: 0.3912

Epoch 00081: val_loss did not improve from 1.34195
Epoch 82/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3934 - val_loss: 1.3436 - val_accuracy: 0.3761

Epoch 00082: val_loss did not improve from 1.34195
Epoch 83/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3935 - val_loss: 1.3440 - val_accuracy: 0.3793

Epoch 00083: val_loss did not improve from 1.34195
Epoch 84/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3967 - val_loss: 1.3438 - val_accuracy: 0.3841

Epoch 00084: val_loss did not improve from 1.34195
Epoch 85/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3953 - val_loss: 1.3458 - val_accuracy: 0.3817

Epoch 00085: val_loss did not improve from 1.34195
Epoch 86/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.4002 - val_loss: 1.3414 - val_accuracy: 0.3936

Epoch 00086: val_loss improved from 1.34195 to 1.34137, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 87/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.4008 - val_loss: 1.3424 - val_accuracy: 0.3928

Epoch 00087: val_loss did not improve from 1.34137
Epoch 88/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.4018 - val_loss: 1.3416 - val_accuracy: 0.3825

Epoch 00088: val_loss did not improve from 1.34137
Epoch 89/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.4012 - val_loss: 1.3408 - val_accuracy: 0.3968

Epoch 00089: val_loss improved from 1.34137 to 1.34084, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 90/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3976 - val_loss: 1.3449 - val_accuracy: 0.3873

Epoch 00090: val_loss did not improve from 1.34084
Epoch 91/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3973 - val_loss: 1.3419 - val_accuracy: 0.3960

Epoch 00091: val_loss did not improve from 1.34084
Epoch 92/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.4006 - val_loss: 1.3407 - val_accuracy: 0.3976

Epoch 00092: val_loss improved from 1.34084 to 1.34067, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 93/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3990 - val_loss: 1.3437 - val_accuracy: 0.3785

Epoch 00093: val_loss did not improve from 1.34067
Epoch 94/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3936 - val_loss: 1.3431 - val_accuracy: 0.3833

Epoch 00094: val_loss did not improve from 1.34067
Epoch 95/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3966 - val_loss: 1.3437 - val_accuracy: 0.3968

Epoch 00095: val_loss did not improve from 1.34067
Epoch 96/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3970 - val_loss: 1.3470 - val_accuracy: 0.3904

Epoch 00096: val_loss did not improve from 1.34067
Epoch 97/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3988 - val_loss: 1.3433 - val_accuracy: 0.3968

Epoch 00097: val_loss did not improve from 1.34067
Epoch 98/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.4020 - val_loss: 1.3418 - val_accuracy: 0.3896

Epoch 00098: val_loss did not improve from 1.34067
Epoch 99/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3992 - val_loss: 1.3422 - val_accuracy: 0.3801

Epoch 00099: val_loss did not improve from 1.34067
Epoch 100/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3934 - val_loss: 1.3443 - val_accuracy: 0.3713

Epoch 00100: val_loss did not improve from 1.34067
Epoch 101/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3911 - val_loss: 1.3439 - val_accuracy: 0.3976

Epoch 00101: val_loss did not improve from 1.34067
Epoch 102/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.4015 - val_loss: 1.3429 - val_accuracy: 0.3976

Epoch 00102: val_loss did not improve from 1.34067
Epoch 103/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3973 - val_loss: 1.3402 - val_accuracy: 0.3825

Epoch 00103: val_loss improved from 1.34067 to 1.34023, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 104/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3966 - val_loss: 1.3395 - val_accuracy: 0.3928

Epoch 00104: val_loss improved from 1.34023 to 1.33949, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 105/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.4002 - val_loss: 1.3422 - val_accuracy: 0.3896

Epoch 00105: val_loss did not improve from 1.33949
Epoch 106/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.4022 - val_loss: 1.3386 - val_accuracy: 0.4000

Epoch 00106: val_loss improved from 1.33949 to 1.33858, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 107/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3988 - val_loss: 1.3409 - val_accuracy: 0.3833

Epoch 00107: val_loss did not improve from 1.33858
Epoch 108/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3963 - val_loss: 1.3428 - val_accuracy: 0.3944

Epoch 00108: val_loss did not improve from 1.33858
Epoch 109/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3999 - val_loss: 1.3405 - val_accuracy: 0.3920

Epoch 00109: val_loss did not improve from 1.33858
Epoch 110/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.4011 - val_loss: 1.3416 - val_accuracy: 0.4032

Epoch 00110: val_loss did not improve from 1.33858
Epoch 111/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.4015 - val_loss: 1.3408 - val_accuracy: 0.3944

Epoch 00111: val_loss did not improve from 1.33858
Epoch 112/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.4016 - val_loss: 1.3397 - val_accuracy: 0.3857

Epoch 00112: val_loss did not improve from 1.33858
Epoch 113/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.4000 - val_loss: 1.3416 - val_accuracy: 0.4032

Epoch 00113: val_loss did not improve from 1.33858
Epoch 114/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.4020 - val_loss: 1.3454 - val_accuracy: 0.3896

Epoch 00114: val_loss did not improve from 1.33858
Epoch 115/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.4020 - val_loss: 1.3393 - val_accuracy: 0.3896

Epoch 00115: val_loss did not improve from 1.33858
Epoch 116/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.4017 - val_loss: 1.3429 - val_accuracy: 0.3896

Epoch 00116: val_loss did not improve from 1.33858
Epoch 117/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.4017 - val_loss: 1.3393 - val_accuracy: 0.4008

Epoch 00117: val_loss did not improve from 1.33858
Epoch 118/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3988 - val_loss: 1.3386 - val_accuracy: 0.3992

Epoch 00118: val_loss did not improve from 1.33858
Epoch 119/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.4018 - val_loss: 1.3407 - val_accuracy: 0.3936

Epoch 00119: val_loss did not improve from 1.33858
Epoch 120/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.4012 - val_loss: 1.3389 - val_accuracy: 0.3936

Epoch 00120: val_loss did not improve from 1.33858
Epoch 121/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3999 - val_loss: 1.3422 - val_accuracy: 0.4016

Epoch 00121: val_loss did not improve from 1.33858
Epoch 122/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3993 - val_loss: 1.3392 - val_accuracy: 0.3920

Epoch 00122: val_loss did not improve from 1.33858
Epoch 123/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4020 - val_loss: 1.3393 - val_accuracy: 0.3952

Epoch 00123: val_loss did not improve from 1.33858
Epoch 124/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4012 - val_loss: 1.3413 - val_accuracy: 0.3904

Epoch 00124: val_loss did not improve from 1.33858
Epoch 125/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3942 - val_loss: 1.3385 - val_accuracy: 0.3960

Epoch 00125: val_loss improved from 1.33858 to 1.33854, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 126/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.4012 - val_loss: 1.3378 - val_accuracy: 0.3920

Epoch 00126: val_loss improved from 1.33854 to 1.33778, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 127/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.4003 - val_loss: 1.3380 - val_accuracy: 0.3968

Epoch 00127: val_loss did not improve from 1.33778
Epoch 128/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.4029 - val_loss: 1.3379 - val_accuracy: 0.3936

Epoch 00128: val_loss did not improve from 1.33778
Epoch 129/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.4026 - val_loss: 1.3419 - val_accuracy: 0.3912

Epoch 00129: val_loss did not improve from 1.33778
Epoch 130/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.4015 - val_loss: 1.3377 - val_accuracy: 0.3992

Epoch 00130: val_loss improved from 1.33778 to 1.33766, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 131/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.4019 - val_loss: 1.3404 - val_accuracy: 0.3817

Epoch 00131: val_loss did not improve from 1.33766
Epoch 132/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3993 - val_loss: 1.3385 - val_accuracy: 0.4032

Epoch 00132: val_loss did not improve from 1.33766
Epoch 133/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3973 - val_loss: 1.3389 - val_accuracy: 0.3952

Epoch 00133: val_loss did not improve from 1.33766
Epoch 134/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3985 - val_loss: 1.3375 - val_accuracy: 0.3912

Epoch 00134: val_loss improved from 1.33766 to 1.33751, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 135/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4000 - val_loss: 1.3389 - val_accuracy: 0.3928

Epoch 00135: val_loss did not improve from 1.33751
Epoch 136/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4040 - val_loss: 1.3408 - val_accuracy: 0.4024

Epoch 00136: val_loss did not improve from 1.33751
Epoch 137/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3978 - val_loss: 1.3427 - val_accuracy: 0.3857

Epoch 00137: val_loss did not improve from 1.33751
Epoch 138/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3983 - val_loss: 1.3392 - val_accuracy: 0.3825

Epoch 00138: val_loss did not improve from 1.33751
Epoch 139/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.4020 - val_loss: 1.3391 - val_accuracy: 0.3984

Epoch 00139: val_loss did not improve from 1.33751
Epoch 140/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.4035 - val_loss: 1.3402 - val_accuracy: 0.3888

Epoch 00140: val_loss did not improve from 1.33751
Epoch 141/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.4063 - val_loss: 1.3377 - val_accuracy: 0.3928

Epoch 00141: val_loss did not improve from 1.33751
Epoch 142/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.4028 - val_loss: 1.3393 - val_accuracy: 0.3809

Epoch 00142: val_loss did not improve from 1.33751
Epoch 143/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3950 - val_loss: 1.3414 - val_accuracy: 0.3960

Epoch 00143: val_loss did not improve from 1.33751
Epoch 144/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.4008 - val_loss: 1.3390 - val_accuracy: 0.3928

Epoch 00144: val_loss did not improve from 1.33751
Epoch 145/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3998 - val_loss: 1.3413 - val_accuracy: 0.3857

Epoch 00145: val_loss did not improve from 1.33751
Epoch 146/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3965 - val_loss: 1.3378 - val_accuracy: 0.3896

Epoch 00146: val_loss did not improve from 1.33751
Epoch 147/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3931 - val_loss: 1.3374 - val_accuracy: 0.3825

Epoch 00147: val_loss improved from 1.33751 to 1.33738, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 148/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3990 - val_loss: 1.3383 - val_accuracy: 0.3968

Epoch 00148: val_loss did not improve from 1.33738
Epoch 149/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.4033 - val_loss: 1.3337 - val_accuracy: 0.4032

Epoch 00149: val_loss improved from 1.33738 to 1.33369, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 150/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3983 - val_loss: 1.3348 - val_accuracy: 0.3793

Epoch 00150: val_loss did not improve from 1.33369
Epoch 151/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.4012 - val_loss: 1.3359 - val_accuracy: 0.3984

Epoch 00151: val_loss did not improve from 1.33369
Epoch 152/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3996 - val_loss: 1.3390 - val_accuracy: 0.4024

Epoch 00152: val_loss did not improve from 1.33369
Epoch 153/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4041 - val_loss: 1.3370 - val_accuracy: 0.3849

Epoch 00153: val_loss did not improve from 1.33369
Epoch 154/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4050 - val_loss: 1.3374 - val_accuracy: 0.3896

Epoch 00154: val_loss did not improve from 1.33369
Epoch 155/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4045 - val_loss: 1.3377 - val_accuracy: 0.4008

Epoch 00155: val_loss did not improve from 1.33369
Epoch 156/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.4019 - val_loss: 1.3375 - val_accuracy: 0.3880

Epoch 00156: val_loss did not improve from 1.33369
Epoch 157/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.4061 - val_loss: 1.3356 - val_accuracy: 0.3992

Epoch 00157: val_loss did not improve from 1.33369
Epoch 158/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4045 - val_loss: 1.3408 - val_accuracy: 0.4112

Epoch 00158: val_loss did not improve from 1.33369
Epoch 159/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3996 - val_loss: 1.3400 - val_accuracy: 0.3785

Epoch 00159: val_loss did not improve from 1.33369
Epoch 160/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4058 - val_loss: 1.3359 - val_accuracy: 0.3928

Epoch 00160: val_loss did not improve from 1.33369
Epoch 161/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4033 - val_loss: 1.3346 - val_accuracy: 0.3912

Epoch 00161: val_loss did not improve from 1.33369
Epoch 162/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4027 - val_loss: 1.3330 - val_accuracy: 0.3952

Epoch 00162: val_loss improved from 1.33369 to 1.33295, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 163/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.4005 - val_loss: 1.3364 - val_accuracy: 0.4096

Epoch 00163: val_loss did not improve from 1.33295
Epoch 164/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.4006 - val_loss: 1.3380 - val_accuracy: 0.3849

Epoch 00164: val_loss did not improve from 1.33295
Epoch 165/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3988 - val_loss: 1.3345 - val_accuracy: 0.3920

Epoch 00165: val_loss did not improve from 1.33295
Epoch 166/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4022 - val_loss: 1.3346 - val_accuracy: 0.4000

Epoch 00166: val_loss did not improve from 1.33295
Epoch 167/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4020 - val_loss: 1.3339 - val_accuracy: 0.3960

Epoch 00167: val_loss did not improve from 1.33295
Epoch 168/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4046 - val_loss: 1.3353 - val_accuracy: 0.3928

Epoch 00168: val_loss did not improve from 1.33295
Epoch 169/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4028 - val_loss: 1.3375 - val_accuracy: 0.3976

Epoch 00169: val_loss did not improve from 1.33295
Epoch 170/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4046 - val_loss: 1.3342 - val_accuracy: 0.4008

Epoch 00170: val_loss did not improve from 1.33295
Epoch 171/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.4036 - val_loss: 1.3351 - val_accuracy: 0.3896

Epoch 00171: val_loss did not improve from 1.33295
Epoch 172/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4031 - val_loss: 1.3377 - val_accuracy: 0.4040

Epoch 00172: val_loss did not improve from 1.33295
Epoch 173/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4028 - val_loss: 1.3369 - val_accuracy: 0.3936

Epoch 00173: val_loss did not improve from 1.33295
Epoch 174/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4039 - val_loss: 1.3333 - val_accuracy: 0.3984

Epoch 00174: val_loss did not improve from 1.33295
Epoch 175/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.4027 - val_loss: 1.3338 - val_accuracy: 0.3880

Epoch 00175: val_loss did not improve from 1.33295
Epoch 176/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4024 - val_loss: 1.3348 - val_accuracy: 0.3952

Epoch 00176: val_loss did not improve from 1.33295
Epoch 177/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.4027 - val_loss: 1.3388 - val_accuracy: 0.3960

Epoch 00177: val_loss did not improve from 1.33295
Epoch 178/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4020 - val_loss: 1.3323 - val_accuracy: 0.3896

Epoch 00178: val_loss improved from 1.33295 to 1.33233, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 179/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4047 - val_loss: 1.3349 - val_accuracy: 0.4056

Epoch 00179: val_loss did not improve from 1.33233
Epoch 180/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4025 - val_loss: 1.3376 - val_accuracy: 0.4032

Epoch 00180: val_loss did not improve from 1.33233
Epoch 181/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4027 - val_loss: 1.3344 - val_accuracy: 0.3960

Epoch 00181: val_loss did not improve from 1.33233
Epoch 182/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4025 - val_loss: 1.3353 - val_accuracy: 0.3849

Epoch 00182: val_loss did not improve from 1.33233
Epoch 183/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.4008 - val_loss: 1.3378 - val_accuracy: 0.3801

Epoch 00183: val_loss did not improve from 1.33233
Epoch 184/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3970 - val_loss: 1.3333 - val_accuracy: 0.3936

Epoch 00184: val_loss did not improve from 1.33233
Epoch 185/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4043 - val_loss: 1.3329 - val_accuracy: 0.3984

Epoch 00185: val_loss did not improve from 1.33233
Epoch 186/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4017 - val_loss: 1.3325 - val_accuracy: 0.3952

Epoch 00186: val_loss did not improve from 1.33233
Epoch 187/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.4058 - val_loss: 1.3338 - val_accuracy: 0.3952

Epoch 00187: val_loss did not improve from 1.33233
Epoch 188/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4017 - val_loss: 1.3383 - val_accuracy: 0.3960

Epoch 00188: val_loss did not improve from 1.33233
Epoch 189/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4043 - val_loss: 1.3335 - val_accuracy: 0.3920

Epoch 00189: val_loss did not improve from 1.33233
Epoch 190/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4004 - val_loss: 1.3354 - val_accuracy: 0.4032

Epoch 00190: val_loss did not improve from 1.33233
Epoch 191/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4056 - val_loss: 1.3332 - val_accuracy: 0.4008

Epoch 00191: val_loss did not improve from 1.33233
Epoch 192/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4058 - val_loss: 1.3351 - val_accuracy: 0.3976

Epoch 00192: val_loss did not improve from 1.33233
Epoch 193/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4056 - val_loss: 1.3343 - val_accuracy: 0.3944

Epoch 00193: val_loss did not improve from 1.33233
Epoch 194/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4043 - val_loss: 1.3330 - val_accuracy: 0.3976

Epoch 00194: val_loss did not improve from 1.33233
Epoch 195/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4046 - val_loss: 1.3345 - val_accuracy: 0.3968

Epoch 00195: val_loss did not improve from 1.33233
Epoch 196/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4032 - val_loss: 1.3370 - val_accuracy: 0.4024

Epoch 00196: val_loss did not improve from 1.33233
Epoch 197/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4035 - val_loss: 1.3343 - val_accuracy: 0.3992

Epoch 00197: val_loss did not improve from 1.33233
Epoch 198/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4075 - val_loss: 1.3366 - val_accuracy: 0.3928

Epoch 00198: val_loss did not improve from 1.33233
Epoch 199/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.4035 - val_loss: 1.3335 - val_accuracy: 0.4048

Epoch 00199: val_loss did not improve from 1.33233
Epoch 200/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4049 - val_loss: 1.3343 - val_accuracy: 0.3952

Epoch 00200: val_loss did not improve from 1.33233
Epoch 201/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4066 - val_loss: 1.3355 - val_accuracy: 0.3928

Epoch 00201: val_loss did not improve from 1.33233
Epoch 202/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4042 - val_loss: 1.3327 - val_accuracy: 0.4008

Epoch 00202: val_loss did not improve from 1.33233
Epoch 203/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4037 - val_loss: 1.3341 - val_accuracy: 0.3984

Epoch 00203: val_loss did not improve from 1.33233
Epoch 204/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4039 - val_loss: 1.3348 - val_accuracy: 0.3928

Epoch 00204: val_loss did not improve from 1.33233
Epoch 205/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4011 - val_loss: 1.3390 - val_accuracy: 0.4048

Epoch 00205: val_loss did not improve from 1.33233
Epoch 206/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4077 - val_loss: 1.3375 - val_accuracy: 0.3793

Epoch 00206: val_loss did not improve from 1.33233
Epoch 207/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4053 - val_loss: 1.3335 - val_accuracy: 0.3976

Epoch 00207: val_loss did not improve from 1.33233
Epoch 208/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4043 - val_loss: 1.3314 - val_accuracy: 0.4008

Epoch 00208: val_loss improved from 1.33233 to 1.33138, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 209/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4057 - val_loss: 1.3356 - val_accuracy: 0.4000

Epoch 00209: val_loss did not improve from 1.33138
Epoch 210/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4051 - val_loss: 1.3332 - val_accuracy: 0.4000

Epoch 00210: val_loss did not improve from 1.33138
Epoch 211/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4076 - val_loss: 1.3303 - val_accuracy: 0.3873

Epoch 00211: val_loss improved from 1.33138 to 1.33026, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 212/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4079 - val_loss: 1.3338 - val_accuracy: 0.3896

Epoch 00212: val_loss did not improve from 1.33026
Epoch 213/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4024 - val_loss: 1.3320 - val_accuracy: 0.3976

Epoch 00213: val_loss did not improve from 1.33026
Epoch 214/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4073 - val_loss: 1.3314 - val_accuracy: 0.3944

Epoch 00214: val_loss did not improve from 1.33026
Epoch 215/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4074 - val_loss: 1.3312 - val_accuracy: 0.3936

Epoch 00215: val_loss did not improve from 1.33026
Epoch 216/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4035 - val_loss: 1.3321 - val_accuracy: 0.3936

Epoch 00216: val_loss did not improve from 1.33026
Epoch 217/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4037 - val_loss: 1.3297 - val_accuracy: 0.3976

Epoch 00217: val_loss improved from 1.33026 to 1.32969, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 218/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4053 - val_loss: 1.3293 - val_accuracy: 0.3984

Epoch 00218: val_loss improved from 1.32969 to 1.32927, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 219/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4038 - val_loss: 1.3319 - val_accuracy: 0.4008

Epoch 00219: val_loss did not improve from 1.32927
Epoch 220/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.4005 - val_loss: 1.3289 - val_accuracy: 0.3976

Epoch 00220: val_loss improved from 1.32927 to 1.32892, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 221/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4006 - val_loss: 1.3348 - val_accuracy: 0.4104

Epoch 00221: val_loss did not improve from 1.32892
Epoch 222/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4074 - val_loss: 1.3382 - val_accuracy: 0.3928

Epoch 00222: val_loss did not improve from 1.32892
Epoch 223/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4036 - val_loss: 1.3320 - val_accuracy: 0.3992

Epoch 00223: val_loss did not improve from 1.32892
Epoch 224/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4043 - val_loss: 1.3299 - val_accuracy: 0.3984

Epoch 00224: val_loss did not improve from 1.32892
Epoch 225/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4056 - val_loss: 1.3315 - val_accuracy: 0.3984

Epoch 00225: val_loss did not improve from 1.32892
Epoch 226/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4066 - val_loss: 1.3313 - val_accuracy: 0.3968

Epoch 00226: val_loss did not improve from 1.32892
Epoch 227/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4081 - val_loss: 1.3303 - val_accuracy: 0.3984

Epoch 00227: val_loss did not improve from 1.32892
Epoch 228/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4072 - val_loss: 1.3308 - val_accuracy: 0.4000

Epoch 00228: val_loss did not improve from 1.32892
Epoch 229/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4050 - val_loss: 1.3303 - val_accuracy: 0.3920

Epoch 00229: val_loss did not improve from 1.32892
Epoch 230/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4055 - val_loss: 1.3309 - val_accuracy: 0.4016

Epoch 00230: val_loss did not improve from 1.32892
Epoch 231/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4055 - val_loss: 1.3297 - val_accuracy: 0.4032

Epoch 00231: val_loss did not improve from 1.32892
Epoch 232/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4048 - val_loss: 1.3307 - val_accuracy: 0.4104

Epoch 00232: val_loss did not improve from 1.32892
Epoch 233/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4081 - val_loss: 1.3321 - val_accuracy: 0.3984

Epoch 00233: val_loss did not improve from 1.32892
Epoch 234/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4070 - val_loss: 1.3312 - val_accuracy: 0.3936

Epoch 00234: val_loss did not improve from 1.32892
Epoch 235/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4019 - val_loss: 1.3297 - val_accuracy: 0.4000

Epoch 00235: val_loss did not improve from 1.32892
Epoch 236/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4045 - val_loss: 1.3303 - val_accuracy: 0.3880

Epoch 00236: val_loss did not improve from 1.32892
Epoch 237/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4030 - val_loss: 1.3299 - val_accuracy: 0.3944

Epoch 00237: val_loss did not improve from 1.32892
Epoch 238/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4091 - val_loss: 1.3303 - val_accuracy: 0.3968

Epoch 00238: val_loss did not improve from 1.32892
Epoch 239/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4050 - val_loss: 1.3300 - val_accuracy: 0.3984

Epoch 00239: val_loss did not improve from 1.32892
Epoch 240/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4065 - val_loss: 1.3334 - val_accuracy: 0.3737

Epoch 00240: val_loss did not improve from 1.32892
Epoch 241/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4043 - val_loss: 1.3307 - val_accuracy: 0.3992

Epoch 00241: val_loss did not improve from 1.32892
Epoch 242/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4046 - val_loss: 1.3314 - val_accuracy: 0.4008

Epoch 00242: val_loss did not improve from 1.32892
Epoch 243/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4068 - val_loss: 1.3328 - val_accuracy: 0.4032

Epoch 00243: val_loss did not improve from 1.32892
Epoch 244/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4046 - val_loss: 1.3330 - val_accuracy: 0.3968

Epoch 00244: val_loss did not improve from 1.32892
Epoch 245/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4086 - val_loss: 1.3282 - val_accuracy: 0.3936

Epoch 00245: val_loss improved from 1.32892 to 1.32818, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 246/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4035 - val_loss: 1.3306 - val_accuracy: 0.4040

Epoch 00246: val_loss did not improve from 1.32818
Epoch 247/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4078 - val_loss: 1.3338 - val_accuracy: 0.3857

Epoch 00247: val_loss did not improve from 1.32818
Epoch 248/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4021 - val_loss: 1.3317 - val_accuracy: 0.3904

Epoch 00248: val_loss did not improve from 1.32818
Epoch 249/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4058 - val_loss: 1.3284 - val_accuracy: 0.3968

Epoch 00249: val_loss did not improve from 1.32818
Epoch 250/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4097 - val_loss: 1.3332 - val_accuracy: 0.3920

Epoch 00250: val_loss did not improve from 1.32818
Epoch 251/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.4054 - val_loss: 1.3328 - val_accuracy: 0.4104

Epoch 00251: val_loss did not improve from 1.32818
Epoch 252/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4082 - val_loss: 1.3290 - val_accuracy: 0.3984

Epoch 00252: val_loss did not improve from 1.32818
Epoch 253/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4075 - val_loss: 1.3322 - val_accuracy: 0.3833

Epoch 00253: val_loss did not improve from 1.32818
Epoch 254/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3965 - val_loss: 1.3293 - val_accuracy: 0.3992

Epoch 00254: val_loss did not improve from 1.32818
Epoch 255/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4072 - val_loss: 1.3285 - val_accuracy: 0.4000

Epoch 00255: val_loss did not improve from 1.32818
Epoch 256/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4068 - val_loss: 1.3296 - val_accuracy: 0.4016

Epoch 00256: val_loss did not improve from 1.32818
Epoch 257/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4059 - val_loss: 1.3282 - val_accuracy: 0.3976

Epoch 00257: val_loss improved from 1.32818 to 1.32816, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 258/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4072 - val_loss: 1.3291 - val_accuracy: 0.4096

Epoch 00258: val_loss did not improve from 1.32816
Epoch 259/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4071 - val_loss: 1.3381 - val_accuracy: 0.3944

Epoch 00259: val_loss did not improve from 1.32816
Epoch 260/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4068 - val_loss: 1.3287 - val_accuracy: 0.4032

Epoch 00260: val_loss did not improve from 1.32816
Epoch 261/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4097 - val_loss: 1.3278 - val_accuracy: 0.3992

Epoch 00261: val_loss improved from 1.32816 to 1.32784, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 262/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4079 - val_loss: 1.3307 - val_accuracy: 0.3984

Epoch 00262: val_loss did not improve from 1.32784
Epoch 263/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4081 - val_loss: 1.3271 - val_accuracy: 0.4032

Epoch 00263: val_loss improved from 1.32784 to 1.32709, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 264/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4059 - val_loss: 1.3289 - val_accuracy: 0.4016

Epoch 00264: val_loss did not improve from 1.32709
Epoch 265/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4072 - val_loss: 1.3319 - val_accuracy: 0.3928

Epoch 00265: val_loss did not improve from 1.32709
Epoch 266/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4029 - val_loss: 1.3291 - val_accuracy: 0.4040

Epoch 00266: val_loss did not improve from 1.32709
Epoch 267/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4066 - val_loss: 1.3285 - val_accuracy: 0.4032

Epoch 00267: val_loss did not improve from 1.32709
Epoch 268/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4088 - val_loss: 1.3286 - val_accuracy: 0.4040

Epoch 00268: val_loss did not improve from 1.32709
Epoch 269/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4066 - val_loss: 1.3287 - val_accuracy: 0.3992

Epoch 00269: val_loss did not improve from 1.32709
Epoch 270/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4061 - val_loss: 1.3290 - val_accuracy: 0.4048

Epoch 00270: val_loss did not improve from 1.32709
Epoch 271/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4082 - val_loss: 1.3325 - val_accuracy: 0.3944

Epoch 00271: val_loss did not improve from 1.32709
Epoch 272/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4058 - val_loss: 1.3274 - val_accuracy: 0.4000

Epoch 00272: val_loss did not improve from 1.32709
Epoch 273/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4079 - val_loss: 1.3287 - val_accuracy: 0.3984

Epoch 00273: val_loss did not improve from 1.32709
Epoch 274/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4104 - val_loss: 1.3281 - val_accuracy: 0.4064

Epoch 00274: val_loss did not improve from 1.32709
Epoch 275/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4081 - val_loss: 1.3341 - val_accuracy: 0.3865

Epoch 00275: val_loss did not improve from 1.32709
Epoch 276/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4081 - val_loss: 1.3273 - val_accuracy: 0.4016

Epoch 00276: val_loss did not improve from 1.32709
Epoch 277/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4010 - val_loss: 1.3271 - val_accuracy: 0.3968

Epoch 00277: val_loss improved from 1.32709 to 1.32708, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 278/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4118 - val_loss: 1.3253 - val_accuracy: 0.3984

Epoch 00278: val_loss improved from 1.32708 to 1.32527, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 279/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4113 - val_loss: 1.3266 - val_accuracy: 0.3960

Epoch 00279: val_loss did not improve from 1.32527
Epoch 280/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4096 - val_loss: 1.3257 - val_accuracy: 0.4016

Epoch 00280: val_loss did not improve from 1.32527
Epoch 281/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4074 - val_loss: 1.3301 - val_accuracy: 0.3960

Epoch 00281: val_loss did not improve from 1.32527
Epoch 282/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4088 - val_loss: 1.3268 - val_accuracy: 0.4024

Epoch 00282: val_loss did not improve from 1.32527
Epoch 283/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4072 - val_loss: 1.3278 - val_accuracy: 0.3952

Epoch 00283: val_loss did not improve from 1.32527
Epoch 284/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4078 - val_loss: 1.3255 - val_accuracy: 0.3968

Epoch 00284: val_loss did not improve from 1.32527
Epoch 285/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4100 - val_loss: 1.3287 - val_accuracy: 0.3896

Epoch 00285: val_loss did not improve from 1.32527
Epoch 286/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4057 - val_loss: 1.3299 - val_accuracy: 0.3928

Epoch 00286: val_loss did not improve from 1.32527
Epoch 287/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4030 - val_loss: 1.3257 - val_accuracy: 0.4000

Epoch 00287: val_loss did not improve from 1.32527
Epoch 288/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4050 - val_loss: 1.3257 - val_accuracy: 0.4000

Epoch 00288: val_loss did not improve from 1.32527
Epoch 289/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4096 - val_loss: 1.3290 - val_accuracy: 0.3912

Epoch 00289: val_loss did not improve from 1.32527
Epoch 290/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4076 - val_loss: 1.3270 - val_accuracy: 0.4064

Epoch 00290: val_loss did not improve from 1.32527
Epoch 291/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4097 - val_loss: 1.3268 - val_accuracy: 0.4040

Epoch 00291: val_loss did not improve from 1.32527
Epoch 292/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4090 - val_loss: 1.3277 - val_accuracy: 0.4024

Epoch 00292: val_loss did not improve from 1.32527
Epoch 293/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4074 - val_loss: 1.3268 - val_accuracy: 0.4040

Epoch 00293: val_loss did not improve from 1.32527
Epoch 294/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4096 - val_loss: 1.3274 - val_accuracy: 0.3984

Epoch 00294: val_loss did not improve from 1.32527
Epoch 295/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4059 - val_loss: 1.3271 - val_accuracy: 0.3952

Epoch 00295: val_loss did not improve from 1.32527
Epoch 296/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4078 - val_loss: 1.3266 - val_accuracy: 0.4016

Epoch 00296: val_loss did not improve from 1.32527
Epoch 297/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4078 - val_loss: 1.3267 - val_accuracy: 0.4064

Epoch 00297: val_loss did not improve from 1.32527
Epoch 298/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4058 - val_loss: 1.3263 - val_accuracy: 0.4000

Epoch 00298: val_loss did not improve from 1.32527
Epoch 299/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4094 - val_loss: 1.3262 - val_accuracy: 0.4080

Epoch 00299: val_loss did not improve from 1.32527
Epoch 300/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4081 - val_loss: 1.3251 - val_accuracy: 0.4088

Epoch 00300: val_loss improved from 1.32527 to 1.32514, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 301/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4111 - val_loss: 1.3254 - val_accuracy: 0.3984

Epoch 00301: val_loss did not improve from 1.32514
Epoch 302/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4097 - val_loss: 1.3326 - val_accuracy: 0.3857

Epoch 00302: val_loss did not improve from 1.32514
Epoch 303/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4103 - val_loss: 1.3266 - val_accuracy: 0.4008

Epoch 00303: val_loss did not improve from 1.32514
Epoch 304/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4056 - val_loss: 1.3263 - val_accuracy: 0.4064

Epoch 00304: val_loss did not improve from 1.32514
Epoch 305/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4107 - val_loss: 1.3304 - val_accuracy: 0.3992

Epoch 00305: val_loss did not improve from 1.32514
Epoch 306/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4080 - val_loss: 1.3261 - val_accuracy: 0.4096

Epoch 00306: val_loss did not improve from 1.32514
Epoch 307/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4087 - val_loss: 1.3276 - val_accuracy: 0.4016

Epoch 00307: val_loss did not improve from 1.32514
Epoch 308/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4053 - val_loss: 1.3364 - val_accuracy: 0.3976

Epoch 00308: val_loss did not improve from 1.32514
Epoch 309/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4119 - val_loss: 1.3253 - val_accuracy: 0.4064

Epoch 00309: val_loss did not improve from 1.32514
Epoch 310/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4079 - val_loss: 1.3239 - val_accuracy: 0.4096

Epoch 00310: val_loss improved from 1.32514 to 1.32389, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 311/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4135 - val_loss: 1.3258 - val_accuracy: 0.3984

Epoch 00311: val_loss did not improve from 1.32389
Epoch 312/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4072 - val_loss: 1.3288 - val_accuracy: 0.3968

Epoch 00312: val_loss did not improve from 1.32389
Epoch 313/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4087 - val_loss: 1.3242 - val_accuracy: 0.3976

Epoch 00313: val_loss did not improve from 1.32389
Epoch 314/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4055 - val_loss: 1.3269 - val_accuracy: 0.4088

Epoch 00314: val_loss did not improve from 1.32389
Epoch 315/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4090 - val_loss: 1.3280 - val_accuracy: 0.3976

Epoch 00315: val_loss did not improve from 1.32389
Epoch 316/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4148 - val_loss: 1.3260 - val_accuracy: 0.4016

Epoch 00316: val_loss did not improve from 1.32389
Epoch 317/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4096 - val_loss: 1.3276 - val_accuracy: 0.4096

Epoch 00317: val_loss did not improve from 1.32389
Epoch 318/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4066 - val_loss: 1.3266 - val_accuracy: 0.3976

Epoch 00318: val_loss did not improve from 1.32389
Epoch 319/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4101 - val_loss: 1.3276 - val_accuracy: 0.4024

Epoch 00319: val_loss did not improve from 1.32389
Epoch 320/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4066 - val_loss: 1.3317 - val_accuracy: 0.3968

Epoch 00320: val_loss did not improve from 1.32389
Epoch 321/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4085 - val_loss: 1.3255 - val_accuracy: 0.4112

Epoch 00321: val_loss did not improve from 1.32389
Epoch 322/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4095 - val_loss: 1.3258 - val_accuracy: 0.3960

Epoch 00322: val_loss did not improve from 1.32389
Epoch 323/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4079 - val_loss: 1.3238 - val_accuracy: 0.4032

Epoch 00323: val_loss improved from 1.32389 to 1.32384, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 324/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4133 - val_loss: 1.3237 - val_accuracy: 0.4040

Epoch 00324: val_loss improved from 1.32384 to 1.32366, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 325/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4112 - val_loss: 1.3234 - val_accuracy: 0.4032

Epoch 00325: val_loss improved from 1.32366 to 1.32341, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 326/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4067 - val_loss: 1.3259 - val_accuracy: 0.3968

Epoch 00326: val_loss did not improve from 1.32341
Epoch 327/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4053 - val_loss: 1.3254 - val_accuracy: 0.4088

Epoch 00327: val_loss did not improve from 1.32341
Epoch 328/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4100 - val_loss: 1.3241 - val_accuracy: 0.3992

Epoch 00328: val_loss did not improve from 1.32341
Epoch 329/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4087 - val_loss: 1.3245 - val_accuracy: 0.3976

Epoch 00329: val_loss did not improve from 1.32341
Epoch 330/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4128 - val_loss: 1.3259 - val_accuracy: 0.4032

Epoch 00330: val_loss did not improve from 1.32341
Epoch 331/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4076 - val_loss: 1.3263 - val_accuracy: 0.4072

Epoch 00331: val_loss did not improve from 1.32341
Epoch 332/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4108 - val_loss: 1.3259 - val_accuracy: 0.4056

Epoch 00332: val_loss did not improve from 1.32341
Epoch 333/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4115 - val_loss: 1.3248 - val_accuracy: 0.4000

Epoch 00333: val_loss did not improve from 1.32341
Epoch 334/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4103 - val_loss: 1.3232 - val_accuracy: 0.4040

Epoch 00334: val_loss improved from 1.32341 to 1.32322, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 335/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4115 - val_loss: 1.3228 - val_accuracy: 0.4048

Epoch 00335: val_loss improved from 1.32322 to 1.32279, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 336/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4084 - val_loss: 1.3240 - val_accuracy: 0.4016

Epoch 00336: val_loss did not improve from 1.32279
Epoch 337/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4119 - val_loss: 1.3238 - val_accuracy: 0.4096

Epoch 00337: val_loss did not improve from 1.32279
Epoch 338/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4032 - val_loss: 1.3244 - val_accuracy: 0.4048

Epoch 00338: val_loss did not improve from 1.32279
Epoch 339/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4085 - val_loss: 1.3285 - val_accuracy: 0.3857

Epoch 00339: val_loss did not improve from 1.32279
Epoch 340/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4074 - val_loss: 1.3254 - val_accuracy: 0.3936

Epoch 00340: val_loss did not improve from 1.32279
Epoch 341/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4067 - val_loss: 1.3219 - val_accuracy: 0.4032

Epoch 00341: val_loss improved from 1.32279 to 1.32194, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 342/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.3982 - val_loss: 1.3271 - val_accuracy: 0.4024

Epoch 00342: val_loss did not improve from 1.32194
Epoch 343/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4073 - val_loss: 1.3306 - val_accuracy: 0.3952

Epoch 00343: val_loss did not improve from 1.32194
Epoch 344/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4104 - val_loss: 1.3240 - val_accuracy: 0.4056

Epoch 00344: val_loss did not improve from 1.32194
Epoch 345/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4077 - val_loss: 1.3235 - val_accuracy: 0.4143

Epoch 00345: val_loss did not improve from 1.32194
Epoch 346/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4088 - val_loss: 1.3279 - val_accuracy: 0.4000

Epoch 00346: val_loss did not improve from 1.32194
Epoch 347/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4064 - val_loss: 1.3247 - val_accuracy: 0.4048

Epoch 00347: val_loss did not improve from 1.32194
Epoch 348/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4111 - val_loss: 1.3242 - val_accuracy: 0.4016

Epoch 00348: val_loss did not improve from 1.32194
Epoch 349/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4112 - val_loss: 1.3242 - val_accuracy: 0.4032

Epoch 00349: val_loss did not improve from 1.32194
Epoch 350/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4074 - val_loss: 1.3241 - val_accuracy: 0.4040

Epoch 00350: val_loss did not improve from 1.32194
Epoch 351/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4060 - val_loss: 1.3228 - val_accuracy: 0.4088

Epoch 00351: val_loss did not improve from 1.32194
Epoch 352/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4101 - val_loss: 1.3251 - val_accuracy: 0.3968

Epoch 00352: val_loss did not improve from 1.32194
Epoch 353/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4084 - val_loss: 1.3227 - val_accuracy: 0.4024

Epoch 00353: val_loss did not improve from 1.32194
Epoch 354/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4081 - val_loss: 1.3249 - val_accuracy: 0.4072

Epoch 00354: val_loss did not improve from 1.32194
Epoch 355/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4083 - val_loss: 1.3270 - val_accuracy: 0.3920

Epoch 00355: val_loss did not improve from 1.32194
Epoch 356/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4131 - val_loss: 1.3242 - val_accuracy: 0.3944

Epoch 00356: val_loss did not improve from 1.32194
Epoch 357/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4075 - val_loss: 1.3232 - val_accuracy: 0.4048

Epoch 00357: val_loss did not improve from 1.32194
Epoch 358/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4127 - val_loss: 1.3248 - val_accuracy: 0.4016

Epoch 00358: val_loss did not improve from 1.32194
Epoch 359/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4073 - val_loss: 1.3334 - val_accuracy: 0.3857

Epoch 00359: val_loss did not improve from 1.32194
Epoch 360/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4046 - val_loss: 1.3219 - val_accuracy: 0.4008

Epoch 00360: val_loss improved from 1.32194 to 1.32192, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 361/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4151 - val_loss: 1.3226 - val_accuracy: 0.4008

Epoch 00361: val_loss did not improve from 1.32192
Epoch 362/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4092 - val_loss: 1.3220 - val_accuracy: 0.4120

Epoch 00362: val_loss did not improve from 1.32192
Epoch 363/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4123 - val_loss: 1.3250 - val_accuracy: 0.3952

Epoch 00363: val_loss did not improve from 1.32192
Epoch 364/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4087 - val_loss: 1.3262 - val_accuracy: 0.3936

Epoch 00364: val_loss did not improve from 1.32192
Epoch 365/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4072 - val_loss: 1.3218 - val_accuracy: 0.4064

Epoch 00365: val_loss improved from 1.32192 to 1.32180, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 366/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4111 - val_loss: 1.3224 - val_accuracy: 0.4072

Epoch 00366: val_loss did not improve from 1.32180
Epoch 367/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4062 - val_loss: 1.3281 - val_accuracy: 0.3880

Epoch 00367: val_loss did not improve from 1.32180
Epoch 368/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4097 - val_loss: 1.3227 - val_accuracy: 0.4072

Epoch 00368: val_loss did not improve from 1.32180
Epoch 369/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4126 - val_loss: 1.3246 - val_accuracy: 0.3928

Epoch 00369: val_loss did not improve from 1.32180
Epoch 370/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4068 - val_loss: 1.3232 - val_accuracy: 0.4072

Epoch 00370: val_loss did not improve from 1.32180
Epoch 371/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4122 - val_loss: 1.3235 - val_accuracy: 0.4024

Epoch 00371: val_loss did not improve from 1.32180
Epoch 372/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4097 - val_loss: 1.3236 - val_accuracy: 0.4008

Epoch 00372: val_loss did not improve from 1.32180
Epoch 373/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4101 - val_loss: 1.3226 - val_accuracy: 0.4056

Epoch 00373: val_loss did not improve from 1.32180
Epoch 374/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4097 - val_loss: 1.3216 - val_accuracy: 0.4000

Epoch 00374: val_loss improved from 1.32180 to 1.32160, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 375/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4106 - val_loss: 1.3215 - val_accuracy: 0.4048

Epoch 00375: val_loss improved from 1.32160 to 1.32155, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 376/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4060 - val_loss: 1.3219 - val_accuracy: 0.4135

Epoch 00376: val_loss did not improve from 1.32155
Epoch 377/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4118 - val_loss: 1.3267 - val_accuracy: 0.3952

Epoch 00377: val_loss did not improve from 1.32155
Epoch 378/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4047 - val_loss: 1.3232 - val_accuracy: 0.3968

Epoch 00378: val_loss did not improve from 1.32155
Epoch 379/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4066 - val_loss: 1.3234 - val_accuracy: 0.4135

Epoch 00379: val_loss did not improve from 1.32155
Epoch 380/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4125 - val_loss: 1.3211 - val_accuracy: 0.4040

Epoch 00380: val_loss improved from 1.32155 to 1.32113, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 381/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4075 - val_loss: 1.3322 - val_accuracy: 0.3841

Epoch 00381: val_loss did not improve from 1.32113
Epoch 382/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4081 - val_loss: 1.3228 - val_accuracy: 0.4143

Epoch 00382: val_loss did not improve from 1.32113
Epoch 383/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4086 - val_loss: 1.3224 - val_accuracy: 0.4135

Epoch 00383: val_loss did not improve from 1.32113
Epoch 384/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4104 - val_loss: 1.3294 - val_accuracy: 0.3944

Epoch 00384: val_loss did not improve from 1.32113
Epoch 385/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4074 - val_loss: 1.3215 - val_accuracy: 0.4048

Epoch 00385: val_loss did not improve from 1.32113
Epoch 386/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4106 - val_loss: 1.3207 - val_accuracy: 0.4064

Epoch 00386: val_loss improved from 1.32113 to 1.32070, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 387/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4084 - val_loss: 1.3251 - val_accuracy: 0.3944

Epoch 00387: val_loss did not improve from 1.32070
Epoch 388/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4050 - val_loss: 1.3229 - val_accuracy: 0.4080

Epoch 00388: val_loss did not improve from 1.32070
Epoch 389/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4069 - val_loss: 1.3210 - val_accuracy: 0.4096

Epoch 00389: val_loss did not improve from 1.32070
Epoch 390/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4119 - val_loss: 1.3200 - val_accuracy: 0.4088

Epoch 00390: val_loss improved from 1.32070 to 1.32002, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 391/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4115 - val_loss: 1.3237 - val_accuracy: 0.4072

Epoch 00391: val_loss did not improve from 1.32002
Epoch 392/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4105 - val_loss: 1.3224 - val_accuracy: 0.4016

Epoch 00392: val_loss did not improve from 1.32002
Epoch 393/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4097 - val_loss: 1.3218 - val_accuracy: 0.3992

Epoch 00393: val_loss did not improve from 1.32002
Epoch 394/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4082 - val_loss: 1.3215 - val_accuracy: 0.4032

Epoch 00394: val_loss did not improve from 1.32002
Epoch 395/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4136 - val_loss: 1.3191 - val_accuracy: 0.4112

Epoch 00395: val_loss improved from 1.32002 to 1.31909, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 396/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4051 - val_loss: 1.3234 - val_accuracy: 0.4040

Epoch 00396: val_loss did not improve from 1.31909
Epoch 397/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4096 - val_loss: 1.3250 - val_accuracy: 0.3968

Epoch 00397: val_loss did not improve from 1.31909
Epoch 398/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4062 - val_loss: 1.3208 - val_accuracy: 0.4088

Epoch 00398: val_loss did not improve from 1.31909
Epoch 399/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4112 - val_loss: 1.3206 - val_accuracy: 0.4072

Epoch 00399: val_loss did not improve from 1.31909
Epoch 400/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4095 - val_loss: 1.3237 - val_accuracy: 0.4024

Epoch 00400: val_loss did not improve from 1.31909
Epoch 401/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4125 - val_loss: 1.3226 - val_accuracy: 0.3992

Epoch 00401: val_loss did not improve from 1.31909
Epoch 402/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4129 - val_loss: 1.3212 - val_accuracy: 0.4056

Epoch 00402: val_loss did not improve from 1.31909
Epoch 403/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4120 - val_loss: 1.3248 - val_accuracy: 0.4008

Epoch 00403: val_loss did not improve from 1.31909
Epoch 404/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4098 - val_loss: 1.3209 - val_accuracy: 0.4064

Epoch 00404: val_loss did not improve from 1.31909
Epoch 405/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4087 - val_loss: 1.3225 - val_accuracy: 0.3968

Epoch 00405: val_loss did not improve from 1.31909
Epoch 406/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4100 - val_loss: 1.3271 - val_accuracy: 0.3896

Epoch 00406: val_loss did not improve from 1.31909
Epoch 407/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4129 - val_loss: 1.3188 - val_accuracy: 0.4112

Epoch 00407: val_loss improved from 1.31909 to 1.31883, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 408/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4137 - val_loss: 1.3236 - val_accuracy: 0.3936

Epoch 00408: val_loss did not improve from 1.31883
Epoch 409/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4070 - val_loss: 1.3208 - val_accuracy: 0.4112

Epoch 00409: val_loss did not improve from 1.31883
Epoch 410/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4104 - val_loss: 1.3249 - val_accuracy: 0.3880

Epoch 00410: val_loss did not improve from 1.31883
Epoch 411/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4094 - val_loss: 1.3238 - val_accuracy: 0.3984

Epoch 00411: val_loss did not improve from 1.31883
Epoch 412/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4121 - val_loss: 1.3186 - val_accuracy: 0.4096

Epoch 00412: val_loss improved from 1.31883 to 1.31859, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 413/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4152 - val_loss: 1.3206 - val_accuracy: 0.4048

Epoch 00413: val_loss did not improve from 1.31859
Epoch 414/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4151 - val_loss: 1.3254 - val_accuracy: 0.3936

Epoch 00414: val_loss did not improve from 1.31859
Epoch 415/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4066 - val_loss: 1.3209 - val_accuracy: 0.4040

Epoch 00415: val_loss did not improve from 1.31859
Epoch 416/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4094 - val_loss: 1.3194 - val_accuracy: 0.4096

Epoch 00416: val_loss did not improve from 1.31859
Epoch 417/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4076 - val_loss: 1.3209 - val_accuracy: 0.4032

Epoch 00417: val_loss did not improve from 1.31859
Epoch 418/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4109 - val_loss: 1.3208 - val_accuracy: 0.4024

Epoch 00418: val_loss did not improve from 1.31859
Epoch 419/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4135 - val_loss: 1.3206 - val_accuracy: 0.4040

Epoch 00419: val_loss did not improve from 1.31859
Epoch 420/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4068 - val_loss: 1.3188 - val_accuracy: 0.4151

Epoch 00420: val_loss did not improve from 1.31859
Epoch 421/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4082 - val_loss: 1.3199 - val_accuracy: 0.4072

Epoch 00421: val_loss did not improve from 1.31859
Epoch 422/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4114 - val_loss: 1.3219 - val_accuracy: 0.3960

Epoch 00422: val_loss did not improve from 1.31859
Epoch 423/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4115 - val_loss: 1.3219 - val_accuracy: 0.3912

Epoch 00423: val_loss did not improve from 1.31859
Epoch 424/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4097 - val_loss: 1.3203 - val_accuracy: 0.4096

Epoch 00424: val_loss did not improve from 1.31859
Epoch 425/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4075 - val_loss: 1.3215 - val_accuracy: 0.4112

Epoch 00425: val_loss did not improve from 1.31859
Epoch 426/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4106 - val_loss: 1.3210 - val_accuracy: 0.3896

Epoch 00426: val_loss did not improve from 1.31859
Epoch 427/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4165 - val_loss: 1.3176 - val_accuracy: 0.4064

Epoch 00427: val_loss improved from 1.31859 to 1.31760, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 428/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4118 - val_loss: 1.3202 - val_accuracy: 0.3976

Epoch 00428: val_loss did not improve from 1.31760
Epoch 429/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4088 - val_loss: 1.3182 - val_accuracy: 0.4016

Epoch 00429: val_loss did not improve from 1.31760
Epoch 430/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4117 - val_loss: 1.3182 - val_accuracy: 0.4135

Epoch 00430: val_loss did not improve from 1.31760
Epoch 431/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4095 - val_loss: 1.3192 - val_accuracy: 0.4104

Epoch 00431: val_loss did not improve from 1.31760
Epoch 432/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4137 - val_loss: 1.3248 - val_accuracy: 0.4056

Epoch 00432: val_loss did not improve from 1.31760
Epoch 433/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4075 - val_loss: 1.3193 - val_accuracy: 0.4096

Epoch 00433: val_loss did not improve from 1.31760
Epoch 434/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4095 - val_loss: 1.3164 - val_accuracy: 0.4072

Epoch 00434: val_loss improved from 1.31760 to 1.31636, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 435/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4116 - val_loss: 1.3233 - val_accuracy: 0.3833

Epoch 00435: val_loss did not improve from 1.31636
Epoch 436/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4084 - val_loss: 1.3176 - val_accuracy: 0.4048

Epoch 00436: val_loss did not improve from 1.31636
Epoch 437/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4088 - val_loss: 1.3193 - val_accuracy: 0.4000

Epoch 00437: val_loss did not improve from 1.31636
Epoch 438/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4114 - val_loss: 1.3162 - val_accuracy: 0.4080

Epoch 00438: val_loss improved from 1.31636 to 1.31624, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 439/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4081 - val_loss: 1.3173 - val_accuracy: 0.4127

Epoch 00439: val_loss did not improve from 1.31624
Epoch 440/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4102 - val_loss: 1.3235 - val_accuracy: 0.3912

Epoch 00440: val_loss did not improve from 1.31624
Epoch 441/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4104 - val_loss: 1.3178 - val_accuracy: 0.4040

Epoch 00441: val_loss did not improve from 1.31624
Epoch 442/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4149 - val_loss: 1.3163 - val_accuracy: 0.4112

Epoch 00442: val_loss did not improve from 1.31624
Epoch 443/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4107 - val_loss: 1.3169 - val_accuracy: 0.4072

Epoch 00443: val_loss did not improve from 1.31624
Epoch 444/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4175 - val_loss: 1.3231 - val_accuracy: 0.3880

Epoch 00444: val_loss did not improve from 1.31624
Epoch 445/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4085 - val_loss: 1.3169 - val_accuracy: 0.4096

Epoch 00445: val_loss did not improve from 1.31624
Epoch 446/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4112 - val_loss: 1.3179 - val_accuracy: 0.4143

Epoch 00446: val_loss did not improve from 1.31624
Epoch 447/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4137 - val_loss: 1.3308 - val_accuracy: 0.3912

Epoch 00447: val_loss did not improve from 1.31624
Epoch 448/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4117 - val_loss: 1.3183 - val_accuracy: 0.4048

Epoch 00448: val_loss did not improve from 1.31624
Epoch 449/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4088 - val_loss: 1.3231 - val_accuracy: 0.4104

Epoch 00449: val_loss did not improve from 1.31624
Epoch 450/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4110 - val_loss: 1.3230 - val_accuracy: 0.3952

Epoch 00450: val_loss did not improve from 1.31624
Epoch 451/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4110 - val_loss: 1.3272 - val_accuracy: 0.3904

Epoch 00451: val_loss did not improve from 1.31624
Epoch 452/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4081 - val_loss: 1.3264 - val_accuracy: 0.4072

Epoch 00452: val_loss did not improve from 1.31624
Epoch 453/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4109 - val_loss: 1.3281 - val_accuracy: 0.3888

Epoch 00453: val_loss did not improve from 1.31624
Epoch 454/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4148 - val_loss: 1.3207 - val_accuracy: 0.4016

Epoch 00454: val_loss did not improve from 1.31624
Epoch 455/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4106 - val_loss: 1.3171 - val_accuracy: 0.4135

Epoch 00455: val_loss did not improve from 1.31624
Epoch 456/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4077 - val_loss: 1.3151 - val_accuracy: 0.4072

Epoch 00456: val_loss improved from 1.31624 to 1.31508, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 457/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4149 - val_loss: 1.3157 - val_accuracy: 0.4088

Epoch 00457: val_loss did not improve from 1.31508
Epoch 458/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4159 - val_loss: 1.3230 - val_accuracy: 0.3928

Epoch 00458: val_loss did not improve from 1.31508
Epoch 459/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4112 - val_loss: 1.3170 - val_accuracy: 0.4135

Epoch 00459: val_loss did not improve from 1.31508
Epoch 460/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4104 - val_loss: 1.3187 - val_accuracy: 0.4088

Epoch 00460: val_loss did not improve from 1.31508
Epoch 461/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4097 - val_loss: 1.3279 - val_accuracy: 0.3865

Epoch 00461: val_loss did not improve from 1.31508
Epoch 462/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4128 - val_loss: 1.3189 - val_accuracy: 0.4191

Epoch 00462: val_loss did not improve from 1.31508
Epoch 463/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4136 - val_loss: 1.3236 - val_accuracy: 0.3904

Epoch 00463: val_loss did not improve from 1.31508
Epoch 464/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4116 - val_loss: 1.3167 - val_accuracy: 0.4151

Epoch 00464: val_loss did not improve from 1.31508
Epoch 465/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4128 - val_loss: 1.3205 - val_accuracy: 0.3944

Epoch 00465: val_loss did not improve from 1.31508
Epoch 466/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4129 - val_loss: 1.3213 - val_accuracy: 0.3976

Epoch 00466: val_loss did not improve from 1.31508
Epoch 467/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4113 - val_loss: 1.3172 - val_accuracy: 0.4072

Epoch 00467: val_loss did not improve from 1.31508
Epoch 468/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4102 - val_loss: 1.3175 - val_accuracy: 0.4096

Epoch 00468: val_loss did not improve from 1.31508
Epoch 469/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4128 - val_loss: 1.3220 - val_accuracy: 0.3888

Epoch 00469: val_loss did not improve from 1.31508
Epoch 470/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4111 - val_loss: 1.3174 - val_accuracy: 0.4064

Epoch 00470: val_loss did not improve from 1.31508
Epoch 471/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4134 - val_loss: 1.3232 - val_accuracy: 0.3904

Epoch 00471: val_loss did not improve from 1.31508
Epoch 472/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4121 - val_loss: 1.3185 - val_accuracy: 0.4048

Epoch 00472: val_loss did not improve from 1.31508
Epoch 473/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4097 - val_loss: 1.3175 - val_accuracy: 0.4096

Epoch 00473: val_loss did not improve from 1.31508
Epoch 474/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4106 - val_loss: 1.3183 - val_accuracy: 0.4048

Epoch 00474: val_loss did not improve from 1.31508
Epoch 475/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4114 - val_loss: 1.3192 - val_accuracy: 0.4008

Epoch 00475: val_loss did not improve from 1.31508
Epoch 476/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4110 - val_loss: 1.3159 - val_accuracy: 0.4080

Epoch 00476: val_loss did not improve from 1.31508
Epoch 477/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4142 - val_loss: 1.3186 - val_accuracy: 0.4008

Epoch 00477: val_loss did not improve from 1.31508
Epoch 478/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4089 - val_loss: 1.3218 - val_accuracy: 0.3888

Epoch 00478: val_loss did not improve from 1.31508
Epoch 479/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4097 - val_loss: 1.3158 - val_accuracy: 0.4104

Epoch 00479: val_loss did not improve from 1.31508
Epoch 480/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4110 - val_loss: 1.3160 - val_accuracy: 0.4120

Epoch 00480: val_loss did not improve from 1.31508
Epoch 481/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4133 - val_loss: 1.3132 - val_accuracy: 0.4064

Epoch 00481: val_loss improved from 1.31508 to 1.31322, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 482/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4159 - val_loss: 1.3217 - val_accuracy: 0.3833

Epoch 00482: val_loss did not improve from 1.31322
Epoch 483/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4087 - val_loss: 1.3177 - val_accuracy: 0.4024

Epoch 00483: val_loss did not improve from 1.31322
Epoch 484/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4083 - val_loss: 1.3176 - val_accuracy: 0.4135

Epoch 00484: val_loss did not improve from 1.31322
Epoch 485/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4120 - val_loss: 1.3173 - val_accuracy: 0.4048

Epoch 00485: val_loss did not improve from 1.31322
Epoch 486/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4113 - val_loss: 1.3169 - val_accuracy: 0.3984

Epoch 00486: val_loss did not improve from 1.31322
Epoch 487/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4153 - val_loss: 1.3168 - val_accuracy: 0.4000

Epoch 00487: val_loss did not improve from 1.31322
Epoch 488/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4118 - val_loss: 1.3160 - val_accuracy: 0.4096

Epoch 00488: val_loss did not improve from 1.31322
Epoch 489/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4124 - val_loss: 1.3215 - val_accuracy: 0.4048

Epoch 00489: val_loss did not improve from 1.31322
Epoch 490/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4159 - val_loss: 1.3169 - val_accuracy: 0.4000

Epoch 00490: val_loss did not improve from 1.31322
Epoch 491/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4094 - val_loss: 1.3140 - val_accuracy: 0.4072

Epoch 00491: val_loss did not improve from 1.31322
Epoch 492/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4151 - val_loss: 1.3151 - val_accuracy: 0.4120

Epoch 00492: val_loss did not improve from 1.31322
Epoch 493/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4169 - val_loss: 1.3180 - val_accuracy: 0.4056

Epoch 00493: val_loss did not improve from 1.31322
Epoch 494/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4116 - val_loss: 1.3183 - val_accuracy: 0.4064

Epoch 00494: val_loss did not improve from 1.31322
Epoch 495/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4114 - val_loss: 1.3177 - val_accuracy: 0.3992

Epoch 00495: val_loss did not improve from 1.31322
Epoch 496/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4107 - val_loss: 1.3157 - val_accuracy: 0.4127

Epoch 00496: val_loss did not improve from 1.31322
Epoch 497/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4108 - val_loss: 1.3159 - val_accuracy: 0.4056

Epoch 00497: val_loss did not improve from 1.31322
Epoch 498/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4157 - val_loss: 1.3151 - val_accuracy: 0.4056

Epoch 00498: val_loss did not improve from 1.31322
Epoch 499/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4103 - val_loss: 1.3138 - val_accuracy: 0.4088

Epoch 00499: val_loss did not improve from 1.31322
Epoch 500/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4103 - val_loss: 1.3168 - val_accuracy: 0.4024

Epoch 00500: val_loss did not improve from 1.31322
Epoch 501/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4117 - val_loss: 1.3236 - val_accuracy: 0.3849

Epoch 00501: val_loss did not improve from 1.31322
Epoch 502/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4103 - val_loss: 1.3137 - val_accuracy: 0.4088

Epoch 00502: val_loss did not improve from 1.31322
Epoch 503/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4124 - val_loss: 1.3120 - val_accuracy: 0.4104

Epoch 00503: val_loss improved from 1.31322 to 1.31201, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 504/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4157 - val_loss: 1.3166 - val_accuracy: 0.3992

Epoch 00504: val_loss did not improve from 1.31201
Epoch 505/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4079 - val_loss: 1.3189 - val_accuracy: 0.3912

Epoch 00505: val_loss did not improve from 1.31201
Epoch 506/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4147 - val_loss: 1.3151 - val_accuracy: 0.4072

Epoch 00506: val_loss did not improve from 1.31201
Epoch 507/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4140 - val_loss: 1.3129 - val_accuracy: 0.4008

Epoch 00507: val_loss did not improve from 1.31201
Epoch 508/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4112 - val_loss: 1.3178 - val_accuracy: 0.3944

Epoch 00508: val_loss did not improve from 1.31201
Epoch 509/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4148 - val_loss: 1.3147 - val_accuracy: 0.3984

Epoch 00509: val_loss did not improve from 1.31201
Epoch 510/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4117 - val_loss: 1.3156 - val_accuracy: 0.4040

Epoch 00510: val_loss did not improve from 1.31201
Epoch 511/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4146 - val_loss: 1.3156 - val_accuracy: 0.4016

Epoch 00511: val_loss did not improve from 1.31201
Epoch 512/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4167 - val_loss: 1.3147 - val_accuracy: 0.4096

Epoch 00512: val_loss did not improve from 1.31201
Epoch 513/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4163 - val_loss: 1.3230 - val_accuracy: 0.3936

Epoch 00513: val_loss did not improve from 1.31201
Epoch 514/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4105 - val_loss: 1.3144 - val_accuracy: 0.4080

Epoch 00514: val_loss did not improve from 1.31201
Epoch 515/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4126 - val_loss: 1.3140 - val_accuracy: 0.4032

Epoch 00515: val_loss did not improve from 1.31201
Epoch 516/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4150 - val_loss: 1.3164 - val_accuracy: 0.3992

Epoch 00516: val_loss did not improve from 1.31201
Epoch 517/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4092 - val_loss: 1.3175 - val_accuracy: 0.3976

Epoch 00517: val_loss did not improve from 1.31201
Epoch 518/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4136 - val_loss: 1.3157 - val_accuracy: 0.3960

Epoch 00518: val_loss did not improve from 1.31201
Epoch 519/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4080 - val_loss: 1.3153 - val_accuracy: 0.4088

Epoch 00519: val_loss did not improve from 1.31201
Epoch 520/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4140 - val_loss: 1.3148 - val_accuracy: 0.4024

Epoch 00520: val_loss did not improve from 1.31201
Epoch 521/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4167 - val_loss: 1.3141 - val_accuracy: 0.4040

Epoch 00521: val_loss did not improve from 1.31201
Epoch 522/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4154 - val_loss: 1.3146 - val_accuracy: 0.4048

Epoch 00522: val_loss did not improve from 1.31201
Epoch 523/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4133 - val_loss: 1.3182 - val_accuracy: 0.3976

Epoch 00523: val_loss did not improve from 1.31201
Epoch 524/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4103 - val_loss: 1.3146 - val_accuracy: 0.4064

Epoch 00524: val_loss did not improve from 1.31201
Epoch 525/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4135 - val_loss: 1.3143 - val_accuracy: 0.4048

Epoch 00525: val_loss did not improve from 1.31201
Epoch 526/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4185 - val_loss: 1.3229 - val_accuracy: 0.3928

Epoch 00526: val_loss did not improve from 1.31201
Epoch 527/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4136 - val_loss: 1.3134 - val_accuracy: 0.4175

Epoch 00527: val_loss did not improve from 1.31201
Epoch 528/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4149 - val_loss: 1.3162 - val_accuracy: 0.4056

Epoch 00528: val_loss did not improve from 1.31201
Epoch 529/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4178 - val_loss: 1.3146 - val_accuracy: 0.4040

Epoch 00529: val_loss did not improve from 1.31201
Epoch 530/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4128 - val_loss: 1.3174 - val_accuracy: 0.4024

Epoch 00530: val_loss did not improve from 1.31201
Epoch 531/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4159 - val_loss: 1.3143 - val_accuracy: 0.4072

Epoch 00531: val_loss did not improve from 1.31201
Epoch 532/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4157 - val_loss: 1.3139 - val_accuracy: 0.4064

Epoch 00532: val_loss did not improve from 1.31201
Epoch 533/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4151 - val_loss: 1.3143 - val_accuracy: 0.4056

Epoch 00533: val_loss did not improve from 1.31201
Epoch 534/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4159 - val_loss: 1.3123 - val_accuracy: 0.4056

Epoch 00534: val_loss did not improve from 1.31201
Epoch 535/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4161 - val_loss: 1.3154 - val_accuracy: 0.4032

Epoch 00535: val_loss did not improve from 1.31201
Epoch 536/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4151 - val_loss: 1.3174 - val_accuracy: 0.4032

Epoch 00536: val_loss did not improve from 1.31201
Epoch 537/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4090 - val_loss: 1.3146 - val_accuracy: 0.3960

Epoch 00537: val_loss did not improve from 1.31201
Epoch 538/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4126 - val_loss: 1.3149 - val_accuracy: 0.4064

Epoch 00538: val_loss did not improve from 1.31201
Epoch 539/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4169 - val_loss: 1.3153 - val_accuracy: 0.4064

Epoch 00539: val_loss did not improve from 1.31201
Epoch 540/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4160 - val_loss: 1.3133 - val_accuracy: 0.4064

Epoch 00540: val_loss did not improve from 1.31201
Epoch 541/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4152 - val_loss: 1.3135 - val_accuracy: 0.4056

Epoch 00541: val_loss did not improve from 1.31201
Epoch 542/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4159 - val_loss: 1.3123 - val_accuracy: 0.4080

Epoch 00542: val_loss did not improve from 1.31201
Epoch 543/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4140 - val_loss: 1.3132 - val_accuracy: 0.4056

Epoch 00543: val_loss did not improve from 1.31201
Epoch 544/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4150 - val_loss: 1.3210 - val_accuracy: 0.3952

Epoch 00544: val_loss did not improve from 1.31201
Epoch 545/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4151 - val_loss: 1.3159 - val_accuracy: 0.4127

Epoch 00545: val_loss did not improve from 1.31201
Epoch 546/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4067 - val_loss: 1.3122 - val_accuracy: 0.4080

Epoch 00546: val_loss did not improve from 1.31201
Epoch 547/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4143 - val_loss: 1.3162 - val_accuracy: 0.4008

Epoch 00547: val_loss did not improve from 1.31201
Epoch 548/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4129 - val_loss: 1.3121 - val_accuracy: 0.4175

Epoch 00548: val_loss did not improve from 1.31201
Epoch 549/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4144 - val_loss: 1.3205 - val_accuracy: 0.3880

Epoch 00549: val_loss did not improve from 1.31201
Epoch 550/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4079 - val_loss: 1.3135 - val_accuracy: 0.4048

Epoch 00550: val_loss did not improve from 1.31201
Epoch 551/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4163 - val_loss: 1.3116 - val_accuracy: 0.4080

Epoch 00551: val_loss improved from 1.31201 to 1.31160, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 552/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4146 - val_loss: 1.3172 - val_accuracy: 0.3928

Epoch 00552: val_loss did not improve from 1.31160
Epoch 553/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4138 - val_loss: 1.3137 - val_accuracy: 0.4032

Epoch 00553: val_loss did not improve from 1.31160
Epoch 554/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4132 - val_loss: 1.3117 - val_accuracy: 0.4088

Epoch 00554: val_loss did not improve from 1.31160
Epoch 555/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4150 - val_loss: 1.3130 - val_accuracy: 0.4064

Epoch 00555: val_loss did not improve from 1.31160
Epoch 556/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4149 - val_loss: 1.3105 - val_accuracy: 0.4024

Epoch 00556: val_loss improved from 1.31160 to 1.31054, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 557/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4156 - val_loss: 1.3161 - val_accuracy: 0.3952

Epoch 00557: val_loss did not improve from 1.31054
Epoch 558/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4163 - val_loss: 1.3122 - val_accuracy: 0.4088

Epoch 00558: val_loss did not improve from 1.31054
Epoch 559/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4159 - val_loss: 1.3167 - val_accuracy: 0.4008

Epoch 00559: val_loss did not improve from 1.31054
Epoch 560/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4101 - val_loss: 1.3119 - val_accuracy: 0.4120

Epoch 00560: val_loss did not improve from 1.31054
Epoch 561/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4201 - val_loss: 1.3137 - val_accuracy: 0.4040

Epoch 00561: val_loss did not improve from 1.31054
Epoch 562/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4138 - val_loss: 1.3117 - val_accuracy: 0.4032

Epoch 00562: val_loss did not improve from 1.31054
Epoch 563/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4170 - val_loss: 1.3126 - val_accuracy: 0.4048

Epoch 00563: val_loss did not improve from 1.31054
Epoch 564/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4148 - val_loss: 1.3126 - val_accuracy: 0.4072

Epoch 00564: val_loss did not improve from 1.31054
Epoch 565/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4165 - val_loss: 1.3131 - val_accuracy: 0.4104

Epoch 00565: val_loss did not improve from 1.31054
Epoch 566/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4177 - val_loss: 1.3142 - val_accuracy: 0.4088

Epoch 00566: val_loss did not improve from 1.31054
Epoch 567/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4167 - val_loss: 1.3142 - val_accuracy: 0.4135

Epoch 00567: val_loss did not improve from 1.31054
Epoch 568/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4156 - val_loss: 1.3140 - val_accuracy: 0.4032

Epoch 00568: val_loss did not improve from 1.31054
Epoch 569/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4116 - val_loss: 1.3106 - val_accuracy: 0.4088

Epoch 00569: val_loss did not improve from 1.31054
Epoch 570/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4149 - val_loss: 1.3121 - val_accuracy: 0.4088

Epoch 00570: val_loss did not improve from 1.31054
Epoch 571/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4142 - val_loss: 1.3133 - val_accuracy: 0.4008

Epoch 00571: val_loss did not improve from 1.31054
Epoch 572/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4126 - val_loss: 1.3090 - val_accuracy: 0.4072

Epoch 00572: val_loss improved from 1.31054 to 1.30899, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 573/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4136 - val_loss: 1.3122 - val_accuracy: 0.4151

Epoch 00573: val_loss did not improve from 1.30899
Epoch 574/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4164 - val_loss: 1.3182 - val_accuracy: 0.3984

Epoch 00574: val_loss did not improve from 1.30899
Epoch 575/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4157 - val_loss: 1.3109 - val_accuracy: 0.4064

Epoch 00575: val_loss did not improve from 1.30899
Epoch 576/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4128 - val_loss: 1.3095 - val_accuracy: 0.4112

Epoch 00576: val_loss did not improve from 1.30899
Epoch 577/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4159 - val_loss: 1.3087 - val_accuracy: 0.4135

Epoch 00577: val_loss improved from 1.30899 to 1.30872, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 578/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4174 - val_loss: 1.3178 - val_accuracy: 0.3960

Epoch 00578: val_loss did not improve from 1.30872
Epoch 579/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4115 - val_loss: 1.3108 - val_accuracy: 0.4120

Epoch 00579: val_loss did not improve from 1.30872
Epoch 580/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4164 - val_loss: 1.3091 - val_accuracy: 0.4104

Epoch 00580: val_loss did not improve from 1.30872
Epoch 581/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4169 - val_loss: 1.3163 - val_accuracy: 0.4000

Epoch 00581: val_loss did not improve from 1.30872
Epoch 582/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4136 - val_loss: 1.3117 - val_accuracy: 0.4032

Epoch 00582: val_loss did not improve from 1.30872
Epoch 583/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4167 - val_loss: 1.3119 - val_accuracy: 0.3992

Epoch 00583: val_loss did not improve from 1.30872
Epoch 584/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4147 - val_loss: 1.3162 - val_accuracy: 0.3952

Epoch 00584: val_loss did not improve from 1.30872
Epoch 585/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4113 - val_loss: 1.3113 - val_accuracy: 0.4088

Epoch 00585: val_loss did not improve from 1.30872
Epoch 586/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4156 - val_loss: 1.3116 - val_accuracy: 0.4080

Epoch 00586: val_loss did not improve from 1.30872
Epoch 587/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4157 - val_loss: 1.3100 - val_accuracy: 0.4104

Epoch 00587: val_loss did not improve from 1.30872
Epoch 588/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4156 - val_loss: 1.3092 - val_accuracy: 0.4072

Epoch 00588: val_loss did not improve from 1.30872
Epoch 589/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4182 - val_loss: 1.3081 - val_accuracy: 0.4024

Epoch 00589: val_loss improved from 1.30872 to 1.30812, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 590/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4143 - val_loss: 1.3122 - val_accuracy: 0.4016

Epoch 00590: val_loss did not improve from 1.30812
Epoch 591/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4126 - val_loss: 1.3093 - val_accuracy: 0.4120

Epoch 00591: val_loss did not improve from 1.30812
Epoch 592/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4151 - val_loss: 1.3119 - val_accuracy: 0.4056

Epoch 00592: val_loss did not improve from 1.30812
Epoch 593/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4164 - val_loss: 1.3099 - val_accuracy: 0.4112

Epoch 00593: val_loss did not improve from 1.30812
Epoch 594/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4132 - val_loss: 1.3077 - val_accuracy: 0.4120

Epoch 00594: val_loss improved from 1.30812 to 1.30767, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 595/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4157 - val_loss: 1.3114 - val_accuracy: 0.4032

Epoch 00595: val_loss did not improve from 1.30767
Epoch 596/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4157 - val_loss: 1.3117 - val_accuracy: 0.3968

Epoch 00596: val_loss did not improve from 1.30767
Epoch 597/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4168 - val_loss: 1.3181 - val_accuracy: 0.4024

Epoch 00597: val_loss did not improve from 1.30767
Epoch 598/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4120 - val_loss: 1.3131 - val_accuracy: 0.4040

Epoch 00598: val_loss did not improve from 1.30767
Epoch 599/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4162 - val_loss: 1.3131 - val_accuracy: 0.4056

Epoch 00599: val_loss did not improve from 1.30767
Epoch 600/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4138 - val_loss: 1.3077 - val_accuracy: 0.4072

Epoch 00600: val_loss did not improve from 1.30767
Epoch 601/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4174 - val_loss: 1.3103 - val_accuracy: 0.4056

Epoch 00601: val_loss did not improve from 1.30767
Epoch 602/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4142 - val_loss: 1.3085 - val_accuracy: 0.4159

Epoch 00602: val_loss did not improve from 1.30767
Epoch 603/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4172 - val_loss: 1.3066 - val_accuracy: 0.4032

Epoch 00603: val_loss improved from 1.30767 to 1.30663, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 604/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4154 - val_loss: 1.3088 - val_accuracy: 0.4072

Epoch 00604: val_loss did not improve from 1.30663
Epoch 605/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4156 - val_loss: 1.3098 - val_accuracy: 0.4024

Epoch 00605: val_loss did not improve from 1.30663
Epoch 606/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4159 - val_loss: 1.3122 - val_accuracy: 0.4096

Epoch 00606: val_loss did not improve from 1.30663
Epoch 607/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4189 - val_loss: 1.3105 - val_accuracy: 0.4175

Epoch 00607: val_loss did not improve from 1.30663
Epoch 608/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4171 - val_loss: 1.3097 - val_accuracy: 0.4032

Epoch 00608: val_loss did not improve from 1.30663
Epoch 609/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4193 - val_loss: 1.3123 - val_accuracy: 0.4032

Epoch 00609: val_loss did not improve from 1.30663
Epoch 610/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4181 - val_loss: 1.3098 - val_accuracy: 0.4127

Epoch 00610: val_loss did not improve from 1.30663
Epoch 611/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4161 - val_loss: 1.3174 - val_accuracy: 0.3880

Epoch 00611: val_loss did not improve from 1.30663
Epoch 612/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4140 - val_loss: 1.3084 - val_accuracy: 0.4048

Epoch 00612: val_loss did not improve from 1.30663
Epoch 613/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4138 - val_loss: 1.3103 - val_accuracy: 0.3968

Epoch 00613: val_loss did not improve from 1.30663
Epoch 614/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4151 - val_loss: 1.3107 - val_accuracy: 0.4040

Epoch 00614: val_loss did not improve from 1.30663
Epoch 615/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4190 - val_loss: 1.3096 - val_accuracy: 0.4032

Epoch 00615: val_loss did not improve from 1.30663
Epoch 616/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4178 - val_loss: 1.3110 - val_accuracy: 0.4048

Epoch 00616: val_loss did not improve from 1.30663
Epoch 617/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4135 - val_loss: 1.3096 - val_accuracy: 0.4040

Epoch 00617: val_loss did not improve from 1.30663
Epoch 618/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4156 - val_loss: 1.3098 - val_accuracy: 0.4080

Epoch 00618: val_loss did not improve from 1.30663
Epoch 619/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4161 - val_loss: 1.3176 - val_accuracy: 0.3960

Epoch 00619: val_loss did not improve from 1.30663
Epoch 620/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4163 - val_loss: 1.3131 - val_accuracy: 0.3952

Epoch 00620: val_loss did not improve from 1.30663
Epoch 621/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4154 - val_loss: 1.3066 - val_accuracy: 0.4104

Epoch 00621: val_loss improved from 1.30663 to 1.30658, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 622/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4167 - val_loss: 1.3095 - val_accuracy: 0.4175

Epoch 00622: val_loss did not improve from 1.30658
Epoch 623/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4148 - val_loss: 1.3158 - val_accuracy: 0.3968

Epoch 00623: val_loss did not improve from 1.30658
Epoch 624/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4179 - val_loss: 1.3076 - val_accuracy: 0.3952

Epoch 00624: val_loss did not improve from 1.30658
Epoch 625/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4134 - val_loss: 1.3095 - val_accuracy: 0.4032

Epoch 00625: val_loss did not improve from 1.30658
Epoch 626/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4161 - val_loss: 1.3083 - val_accuracy: 0.4080

Epoch 00626: val_loss did not improve from 1.30658
Epoch 627/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4147 - val_loss: 1.3071 - val_accuracy: 0.4120

Epoch 00627: val_loss did not improve from 1.30658
Epoch 628/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4167 - val_loss: 1.3128 - val_accuracy: 0.3992

Epoch 00628: val_loss did not improve from 1.30658
Epoch 629/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4146 - val_loss: 1.3081 - val_accuracy: 0.4032

Epoch 00629: val_loss did not improve from 1.30658
Epoch 630/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4172 - val_loss: 1.3105 - val_accuracy: 0.4048

Epoch 00630: val_loss did not improve from 1.30658
Epoch 631/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4196 - val_loss: 1.3116 - val_accuracy: 0.3992

Epoch 00631: val_loss did not improve from 1.30658
Epoch 632/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4198 - val_loss: 1.3085 - val_accuracy: 0.4016

Epoch 00632: val_loss did not improve from 1.30658
Epoch 633/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4113 - val_loss: 1.3147 - val_accuracy: 0.4048

Epoch 00633: val_loss did not improve from 1.30658
Epoch 634/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4137 - val_loss: 1.3093 - val_accuracy: 0.4032

Epoch 00634: val_loss did not improve from 1.30658
Epoch 635/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4142 - val_loss: 1.3092 - val_accuracy: 0.4064

Epoch 00635: val_loss did not improve from 1.30658
Epoch 636/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4142 - val_loss: 1.3084 - val_accuracy: 0.4104

Epoch 00636: val_loss did not improve from 1.30658
Epoch 637/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4152 - val_loss: 1.3094 - val_accuracy: 0.4024

Epoch 00637: val_loss did not improve from 1.30658
Epoch 638/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4145 - val_loss: 1.3069 - val_accuracy: 0.4080

Epoch 00638: val_loss did not improve from 1.30658
Epoch 639/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4150 - val_loss: 1.3150 - val_accuracy: 0.3960

Epoch 00639: val_loss did not improve from 1.30658
Epoch 640/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4145 - val_loss: 1.3082 - val_accuracy: 0.4048

Epoch 00640: val_loss did not improve from 1.30658
Epoch 641/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4145 - val_loss: 1.3082 - val_accuracy: 0.4080

Epoch 00641: val_loss did not improve from 1.30658
Epoch 642/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4141 - val_loss: 1.3073 - val_accuracy: 0.3992

Epoch 00642: val_loss did not improve from 1.30658
Epoch 643/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4156 - val_loss: 1.3072 - val_accuracy: 0.4056

Epoch 00643: val_loss did not improve from 1.30658
Epoch 644/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4141 - val_loss: 1.3108 - val_accuracy: 0.4016

Epoch 00644: val_loss did not improve from 1.30658
Epoch 645/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4158 - val_loss: 1.3098 - val_accuracy: 0.4048

Epoch 00645: val_loss did not improve from 1.30658
Epoch 646/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4167 - val_loss: 1.3068 - val_accuracy: 0.4080

Epoch 00646: val_loss did not improve from 1.30658
Epoch 647/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4195 - val_loss: 1.3063 - val_accuracy: 0.4104

Epoch 00647: val_loss improved from 1.30658 to 1.30631, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 648/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4164 - val_loss: 1.3102 - val_accuracy: 0.4040

Epoch 00648: val_loss did not improve from 1.30631
Epoch 649/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4195 - val_loss: 1.3071 - val_accuracy: 0.4120

Epoch 00649: val_loss did not improve from 1.30631
Epoch 650/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4175 - val_loss: 1.3146 - val_accuracy: 0.3976

Epoch 00650: val_loss did not improve from 1.30631
Epoch 651/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4197 - val_loss: 1.3091 - val_accuracy: 0.4112

Epoch 00651: val_loss did not improve from 1.30631
Epoch 652/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4168 - val_loss: 1.3124 - val_accuracy: 0.3992

Epoch 00652: val_loss did not improve from 1.30631
Epoch 653/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4176 - val_loss: 1.3103 - val_accuracy: 0.4072

Epoch 00653: val_loss did not improve from 1.30631
Epoch 654/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4162 - val_loss: 1.3055 - val_accuracy: 0.4088

Epoch 00654: val_loss improved from 1.30631 to 1.30545, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 655/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4159 - val_loss: 1.3074 - val_accuracy: 0.4056

Epoch 00655: val_loss did not improve from 1.30545
Epoch 656/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4169 - val_loss: 1.3074 - val_accuracy: 0.4056

Epoch 00656: val_loss did not improve from 1.30545
Epoch 657/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4156 - val_loss: 1.3074 - val_accuracy: 0.4024

Epoch 00657: val_loss did not improve from 1.30545
Epoch 658/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4165 - val_loss: 1.3054 - val_accuracy: 0.4120

Epoch 00658: val_loss improved from 1.30545 to 1.30537, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 659/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4174 - val_loss: 1.3053 - val_accuracy: 0.4167

Epoch 00659: val_loss improved from 1.30537 to 1.30528, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 660/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4149 - val_loss: 1.3151 - val_accuracy: 0.3984

Epoch 00660: val_loss did not improve from 1.30528
Epoch 661/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4152 - val_loss: 1.3094 - val_accuracy: 0.4127

Epoch 00661: val_loss did not improve from 1.30528
Epoch 662/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4162 - val_loss: 1.3042 - val_accuracy: 0.4191

Epoch 00662: val_loss improved from 1.30528 to 1.30423, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 663/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4160 - val_loss: 1.3052 - val_accuracy: 0.4199

Epoch 00663: val_loss did not improve from 1.30423
Epoch 664/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4161 - val_loss: 1.3079 - val_accuracy: 0.4072

Epoch 00664: val_loss did not improve from 1.30423
Epoch 665/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4146 - val_loss: 1.3171 - val_accuracy: 0.4064

Epoch 00665: val_loss did not improve from 1.30423
Epoch 666/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4168 - val_loss: 1.3064 - val_accuracy: 0.4056

Epoch 00666: val_loss did not improve from 1.30423
Epoch 667/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4165 - val_loss: 1.3064 - val_accuracy: 0.4032

Epoch 00667: val_loss did not improve from 1.30423
Epoch 668/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4173 - val_loss: 1.3094 - val_accuracy: 0.4048

Epoch 00668: val_loss did not improve from 1.30423
Epoch 669/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4179 - val_loss: 1.3078 - val_accuracy: 0.4040

Epoch 00669: val_loss did not improve from 1.30423
Epoch 670/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4169 - val_loss: 1.3052 - val_accuracy: 0.4072

Epoch 00670: val_loss did not improve from 1.30423
Epoch 671/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4098 - val_loss: 1.3101 - val_accuracy: 0.4096

Epoch 00671: val_loss did not improve from 1.30423
Epoch 672/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4142 - val_loss: 1.3120 - val_accuracy: 0.3984

Epoch 00672: val_loss did not improve from 1.30423
Epoch 673/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4174 - val_loss: 1.3136 - val_accuracy: 0.3960

Epoch 00673: val_loss did not improve from 1.30423
Epoch 674/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4167 - val_loss: 1.3085 - val_accuracy: 0.4088

Epoch 00674: val_loss did not improve from 1.30423
Epoch 675/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4142 - val_loss: 1.3109 - val_accuracy: 0.3984

Epoch 00675: val_loss did not improve from 1.30423
Epoch 676/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4130 - val_loss: 1.3086 - val_accuracy: 0.4120

Epoch 00676: val_loss did not improve from 1.30423
Epoch 677/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4182 - val_loss: 1.3081 - val_accuracy: 0.4112

Epoch 00677: val_loss did not improve from 1.30423
Epoch 678/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4170 - val_loss: 1.3100 - val_accuracy: 0.4000

Epoch 00678: val_loss did not improve from 1.30423
Epoch 679/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4192 - val_loss: 1.3105 - val_accuracy: 0.4088

Epoch 00679: val_loss did not improve from 1.30423
Epoch 680/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4149 - val_loss: 1.3105 - val_accuracy: 0.4088

Epoch 00680: val_loss did not improve from 1.30423
Epoch 681/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4123 - val_loss: 1.3125 - val_accuracy: 0.4000

Epoch 00681: val_loss did not improve from 1.30423
Epoch 682/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4169 - val_loss: 1.3090 - val_accuracy: 0.4048

Epoch 00682: val_loss did not improve from 1.30423
Epoch 683/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4173 - val_loss: 1.3049 - val_accuracy: 0.4088

Epoch 00683: val_loss did not improve from 1.30423
Epoch 684/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4175 - val_loss: 1.3058 - val_accuracy: 0.4096

Epoch 00684: val_loss did not improve from 1.30423
Epoch 685/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4184 - val_loss: 1.3053 - val_accuracy: 0.4072

Epoch 00685: val_loss did not improve from 1.30423
Epoch 686/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4194 - val_loss: 1.3094 - val_accuracy: 0.4072

Epoch 00686: val_loss did not improve from 1.30423
Epoch 687/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4174 - val_loss: 1.3057 - val_accuracy: 0.4112

Epoch 00687: val_loss did not improve from 1.30423
Epoch 688/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4213 - val_loss: 1.3122 - val_accuracy: 0.3984

Epoch 00688: val_loss did not improve from 1.30423
Epoch 689/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4191 - val_loss: 1.3086 - val_accuracy: 0.4064

Epoch 00689: val_loss did not improve from 1.30423
Epoch 690/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4191 - val_loss: 1.3061 - val_accuracy: 0.4096

Epoch 00690: val_loss did not improve from 1.30423
Epoch 691/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4187 - val_loss: 1.3075 - val_accuracy: 0.4064

Epoch 00691: val_loss did not improve from 1.30423
Epoch 692/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4177 - val_loss: 1.3022 - val_accuracy: 0.4143

Epoch 00692: val_loss improved from 1.30423 to 1.30215, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 693/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4164 - val_loss: 1.3061 - val_accuracy: 0.4080

Epoch 00693: val_loss did not improve from 1.30215
Epoch 694/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4189 - val_loss: 1.3050 - val_accuracy: 0.4120

Epoch 00694: val_loss did not improve from 1.30215
Epoch 695/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4208 - val_loss: 1.3070 - val_accuracy: 0.4040

Epoch 00695: val_loss did not improve from 1.30215
Epoch 696/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4190 - val_loss: 1.3050 - val_accuracy: 0.4104

Epoch 00696: val_loss did not improve from 1.30215
Epoch 697/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4203 - val_loss: 1.3055 - val_accuracy: 0.4127

Epoch 00697: val_loss did not improve from 1.30215
Epoch 698/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4187 - val_loss: 1.3054 - val_accuracy: 0.4127

Epoch 00698: val_loss did not improve from 1.30215
Epoch 699/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4169 - val_loss: 1.3062 - val_accuracy: 0.4135

Epoch 00699: val_loss did not improve from 1.30215
Epoch 700/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4198 - val_loss: 1.3037 - val_accuracy: 0.4167

Epoch 00700: val_loss did not improve from 1.30215
Epoch 701/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4138 - val_loss: 1.3144 - val_accuracy: 0.3992

Epoch 00701: val_loss did not improve from 1.30215
Epoch 702/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4156 - val_loss: 1.3149 - val_accuracy: 0.3912

Epoch 00702: val_loss did not improve from 1.30215
Epoch 703/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4161 - val_loss: 1.3051 - val_accuracy: 0.4143

Epoch 00703: val_loss did not improve from 1.30215
Epoch 704/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4185 - val_loss: 1.3077 - val_accuracy: 0.4096

Epoch 00704: val_loss did not improve from 1.30215
Epoch 705/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4160 - val_loss: 1.3090 - val_accuracy: 0.4040

Epoch 00705: val_loss did not improve from 1.30215
Epoch 706/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4213 - val_loss: 1.3038 - val_accuracy: 0.4167

Epoch 00706: val_loss did not improve from 1.30215
Epoch 707/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4187 - val_loss: 1.3052 - val_accuracy: 0.4096

Epoch 00707: val_loss did not improve from 1.30215
Epoch 708/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4181 - val_loss: 1.3082 - val_accuracy: 0.3920

Epoch 00708: val_loss did not improve from 1.30215
Epoch 709/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4190 - val_loss: 1.3043 - val_accuracy: 0.4096

Epoch 00709: val_loss did not improve from 1.30215
Epoch 710/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4193 - val_loss: 1.3029 - val_accuracy: 0.4159

Epoch 00710: val_loss did not improve from 1.30215
Epoch 711/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4194 - val_loss: 1.3075 - val_accuracy: 0.4016

Epoch 00711: val_loss did not improve from 1.30215
Epoch 712/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4187 - val_loss: 1.3037 - val_accuracy: 0.4056

Epoch 00712: val_loss did not improve from 1.30215
Epoch 713/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4190 - val_loss: 1.3030 - val_accuracy: 0.4112

Epoch 00713: val_loss did not improve from 1.30215
Epoch 714/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4187 - val_loss: 1.3035 - val_accuracy: 0.4072

Epoch 00714: val_loss did not improve from 1.30215
Epoch 715/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4186 - val_loss: 1.3053 - val_accuracy: 0.4096

Epoch 00715: val_loss did not improve from 1.30215
Epoch 716/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4198 - val_loss: 1.3042 - val_accuracy: 0.4064

Epoch 00716: val_loss did not improve from 1.30215
Epoch 717/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4157 - val_loss: 1.3036 - val_accuracy: 0.4112

Epoch 00717: val_loss did not improve from 1.30215
Epoch 718/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4184 - val_loss: 1.3018 - val_accuracy: 0.4127

Epoch 00718: val_loss improved from 1.30215 to 1.30184, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 719/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4164 - val_loss: 1.3055 - val_accuracy: 0.4135

Epoch 00719: val_loss did not improve from 1.30184
Epoch 720/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4180 - val_loss: 1.3019 - val_accuracy: 0.4127

Epoch 00720: val_loss did not improve from 1.30184
Epoch 721/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4179 - val_loss: 1.3038 - val_accuracy: 0.4080

Epoch 00721: val_loss did not improve from 1.30184
Epoch 722/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4203 - val_loss: 1.3035 - val_accuracy: 0.4143

Epoch 00722: val_loss did not improve from 1.30184
Epoch 723/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4193 - val_loss: 1.3070 - val_accuracy: 0.4080

Epoch 00723: val_loss did not improve from 1.30184
Epoch 724/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4192 - val_loss: 1.3017 - val_accuracy: 0.4151

Epoch 00724: val_loss improved from 1.30184 to 1.30170, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 725/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4173 - val_loss: 1.3029 - val_accuracy: 0.4135

Epoch 00725: val_loss did not improve from 1.30170
Epoch 726/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4176 - val_loss: 1.3046 - val_accuracy: 0.4064

Epoch 00726: val_loss did not improve from 1.30170
Epoch 727/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4172 - val_loss: 1.3109 - val_accuracy: 0.4080

Epoch 00727: val_loss did not improve from 1.30170
Epoch 728/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4178 - val_loss: 1.3104 - val_accuracy: 0.3984

Epoch 00728: val_loss did not improve from 1.30170
Epoch 729/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4195 - val_loss: 1.3031 - val_accuracy: 0.4112

Epoch 00729: val_loss did not improve from 1.30170
Epoch 730/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4198 - val_loss: 1.3056 - val_accuracy: 0.4080

Epoch 00730: val_loss did not improve from 1.30170
Epoch 731/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4190 - val_loss: 1.3035 - val_accuracy: 0.4096

Epoch 00731: val_loss did not improve from 1.30170
Epoch 732/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4160 - val_loss: 1.3078 - val_accuracy: 0.4080

Epoch 00732: val_loss did not improve from 1.30170
Epoch 733/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4169 - val_loss: 1.3083 - val_accuracy: 0.4056

Epoch 00733: val_loss did not improve from 1.30170
Epoch 734/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4139 - val_loss: 1.3036 - val_accuracy: 0.4167

Epoch 00734: val_loss did not improve from 1.30170
Epoch 735/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4214 - val_loss: 1.3027 - val_accuracy: 0.4199

Epoch 00735: val_loss did not improve from 1.30170
Epoch 736/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4189 - val_loss: 1.3056 - val_accuracy: 0.4080

Epoch 00736: val_loss did not improve from 1.30170
Epoch 737/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4213 - val_loss: 1.3002 - val_accuracy: 0.4167

Epoch 00737: val_loss improved from 1.30170 to 1.30023, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 738/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4188 - val_loss: 1.3012 - val_accuracy: 0.4183

Epoch 00738: val_loss did not improve from 1.30023
Epoch 739/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4187 - val_loss: 1.3025 - val_accuracy: 0.4112

Epoch 00739: val_loss did not improve from 1.30023
Epoch 740/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4204 - val_loss: 1.3061 - val_accuracy: 0.4032

Epoch 00740: val_loss did not improve from 1.30023
Epoch 741/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4191 - val_loss: 1.3029 - val_accuracy: 0.4064

Epoch 00741: val_loss did not improve from 1.30023
Epoch 742/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4186 - val_loss: 1.3101 - val_accuracy: 0.4064

Epoch 00742: val_loss did not improve from 1.30023
Epoch 743/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4159 - val_loss: 1.3052 - val_accuracy: 0.4088

Epoch 00743: val_loss did not improve from 1.30023
Epoch 744/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4190 - val_loss: 1.3016 - val_accuracy: 0.4120

Epoch 00744: val_loss did not improve from 1.30023
Epoch 745/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4185 - val_loss: 1.3063 - val_accuracy: 0.4072

Epoch 00745: val_loss did not improve from 1.30023
Epoch 746/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4187 - val_loss: 1.3037 - val_accuracy: 0.4120

Epoch 00746: val_loss did not improve from 1.30023
Epoch 747/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4190 - val_loss: 1.3031 - val_accuracy: 0.4120

Epoch 00747: val_loss did not improve from 1.30023
Epoch 748/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4167 - val_loss: 1.3024 - val_accuracy: 0.3992

Epoch 00748: val_loss did not improve from 1.30023
Epoch 749/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4195 - val_loss: 1.3025 - val_accuracy: 0.4056

Epoch 00749: val_loss did not improve from 1.30023
Epoch 750/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4218 - val_loss: 1.3132 - val_accuracy: 0.3912

Epoch 00750: val_loss did not improve from 1.30023
Epoch 751/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4142 - val_loss: 1.2999 - val_accuracy: 0.4104

Epoch 00751: val_loss improved from 1.30023 to 1.29993, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 752/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4212 - val_loss: 1.3025 - val_accuracy: 0.4127

Epoch 00752: val_loss did not improve from 1.29993
Epoch 753/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4159 - val_loss: 1.3054 - val_accuracy: 0.3976

Epoch 00753: val_loss did not improve from 1.29993
Epoch 754/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4202 - val_loss: 1.3085 - val_accuracy: 0.4088

Epoch 00754: val_loss did not improve from 1.29993
Epoch 755/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4195 - val_loss: 1.3021 - val_accuracy: 0.4135

Epoch 00755: val_loss did not improve from 1.29993
Epoch 756/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4201 - val_loss: 1.3022 - val_accuracy: 0.4135

Epoch 00756: val_loss did not improve from 1.29993
Epoch 757/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4163 - val_loss: 1.3042 - val_accuracy: 0.4096

Epoch 00757: val_loss did not improve from 1.29993
Epoch 758/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4196 - val_loss: 1.3081 - val_accuracy: 0.3896

Epoch 00758: val_loss did not improve from 1.29993
Epoch 759/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4198 - val_loss: 1.3030 - val_accuracy: 0.4088

Epoch 00759: val_loss did not improve from 1.29993
Epoch 760/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4222 - val_loss: 1.3016 - val_accuracy: 0.4135

Epoch 00760: val_loss did not improve from 1.29993
Epoch 761/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4191 - val_loss: 1.3104 - val_accuracy: 0.4008

Epoch 00761: val_loss did not improve from 1.29993
Epoch 762/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4175 - val_loss: 1.3047 - val_accuracy: 0.4096

Epoch 00762: val_loss did not improve from 1.29993
Epoch 763/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4167 - val_loss: 1.3039 - val_accuracy: 0.4088

Epoch 00763: val_loss did not improve from 1.29993
Epoch 764/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4176 - val_loss: 1.3044 - val_accuracy: 0.4080

Epoch 00764: val_loss did not improve from 1.29993
Epoch 765/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4221 - val_loss: 1.3003 - val_accuracy: 0.4223

Epoch 00765: val_loss did not improve from 1.29993
Epoch 766/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4200 - val_loss: 1.3066 - val_accuracy: 0.3928

Epoch 00766: val_loss did not improve from 1.29993
Epoch 767/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4211 - val_loss: 1.3022 - val_accuracy: 0.4104

Epoch 00767: val_loss did not improve from 1.29993
Epoch 768/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4203 - val_loss: 1.3001 - val_accuracy: 0.4120

Epoch 00768: val_loss did not improve from 1.29993
Epoch 769/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4204 - val_loss: 1.3042 - val_accuracy: 0.4080

Epoch 00769: val_loss did not improve from 1.29993
Epoch 770/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4201 - val_loss: 1.3009 - val_accuracy: 0.4120

Epoch 00770: val_loss did not improve from 1.29993
Epoch 771/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4194 - val_loss: 1.3012 - val_accuracy: 0.4120

Epoch 00771: val_loss did not improve from 1.29993
Epoch 772/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4218 - val_loss: 1.3011 - val_accuracy: 0.4151

Epoch 00772: val_loss did not improve from 1.29993
Epoch 773/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4183 - val_loss: 1.3049 - val_accuracy: 0.4008

Epoch 00773: val_loss did not improve from 1.29993
Epoch 774/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4235 - val_loss: 1.3041 - val_accuracy: 0.4008

Epoch 00774: val_loss did not improve from 1.29993
Epoch 775/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4186 - val_loss: 1.3030 - val_accuracy: 0.4016

Epoch 00775: val_loss did not improve from 1.29993
Epoch 776/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4145 - val_loss: 1.3040 - val_accuracy: 0.4072

Epoch 00776: val_loss did not improve from 1.29993
Epoch 777/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4189 - val_loss: 1.3013 - val_accuracy: 0.4135

Epoch 00777: val_loss did not improve from 1.29993
Epoch 778/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4155 - val_loss: 1.3058 - val_accuracy: 0.3968

Epoch 00778: val_loss did not improve from 1.29993
Epoch 779/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4190 - val_loss: 1.3009 - val_accuracy: 0.4080

Epoch 00779: val_loss did not improve from 1.29993
Epoch 780/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4180 - val_loss: 1.3043 - val_accuracy: 0.4127

Epoch 00780: val_loss did not improve from 1.29993
Epoch 781/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4206 - val_loss: 1.3036 - val_accuracy: 0.4159

Epoch 00781: val_loss did not improve from 1.29993
Epoch 782/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4212 - val_loss: 1.2984 - val_accuracy: 0.4175

Epoch 00782: val_loss improved from 1.29993 to 1.29841, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 783/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4178 - val_loss: 1.2999 - val_accuracy: 0.4088

Epoch 00783: val_loss did not improve from 1.29841
Epoch 784/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4185 - val_loss: 1.3019 - val_accuracy: 0.4127

Epoch 00784: val_loss did not improve from 1.29841
Epoch 785/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4179 - val_loss: 1.3006 - val_accuracy: 0.4135

Epoch 00785: val_loss did not improve from 1.29841
Epoch 786/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4184 - val_loss: 1.3023 - val_accuracy: 0.4080

Epoch 00786: val_loss did not improve from 1.29841
Epoch 787/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4179 - val_loss: 1.3007 - val_accuracy: 0.4072

Epoch 00787: val_loss did not improve from 1.29841
Epoch 788/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4221 - val_loss: 1.3009 - val_accuracy: 0.4104

Epoch 00788: val_loss did not improve from 1.29841
Epoch 789/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4204 - val_loss: 1.3018 - val_accuracy: 0.4143

Epoch 00789: val_loss did not improve from 1.29841
Epoch 790/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4162 - val_loss: 1.3052 - val_accuracy: 0.4008

Epoch 00790: val_loss did not improve from 1.29841
Epoch 791/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4186 - val_loss: 1.3087 - val_accuracy: 0.4032

Epoch 00791: val_loss did not improve from 1.29841
Epoch 792/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4209 - val_loss: 1.3029 - val_accuracy: 0.4080

Epoch 00792: val_loss did not improve from 1.29841
Epoch 793/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4194 - val_loss: 1.3028 - val_accuracy: 0.4151

Epoch 00793: val_loss did not improve from 1.29841
Epoch 794/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4212 - val_loss: 1.3014 - val_accuracy: 0.4151

Epoch 00794: val_loss did not improve from 1.29841
Epoch 795/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4164 - val_loss: 1.3124 - val_accuracy: 0.4000

Epoch 00795: val_loss did not improve from 1.29841
Epoch 796/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4217 - val_loss: 1.3033 - val_accuracy: 0.4135

Epoch 00796: val_loss did not improve from 1.29841
Epoch 797/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4197 - val_loss: 1.3032 - val_accuracy: 0.4135

Epoch 00797: val_loss did not improve from 1.29841
Epoch 798/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4221 - val_loss: 1.3053 - val_accuracy: 0.4135

Epoch 00798: val_loss did not improve from 1.29841
Epoch 799/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4172 - val_loss: 1.3014 - val_accuracy: 0.4175

Epoch 00799: val_loss did not improve from 1.29841
Epoch 800/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4198 - val_loss: 1.2990 - val_accuracy: 0.4175

Epoch 00800: val_loss did not improve from 1.29841
Epoch 801/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4189 - val_loss: 1.3015 - val_accuracy: 0.4127

Epoch 00801: val_loss did not improve from 1.29841
Epoch 802/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4205 - val_loss: 1.3038 - val_accuracy: 0.4120

Epoch 00802: val_loss did not improve from 1.29841
Epoch 803/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4200 - val_loss: 1.3106 - val_accuracy: 0.4072

Epoch 00803: val_loss did not improve from 1.29841
Epoch 804/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4154 - val_loss: 1.2975 - val_accuracy: 0.4175

Epoch 00804: val_loss improved from 1.29841 to 1.29752, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 805/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4158 - val_loss: 1.2996 - val_accuracy: 0.4096

Epoch 00805: val_loss did not improve from 1.29752
Epoch 806/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4220 - val_loss: 1.3032 - val_accuracy: 0.4048

Epoch 00806: val_loss did not improve from 1.29752
Epoch 807/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4183 - val_loss: 1.3053 - val_accuracy: 0.4080

Epoch 00807: val_loss did not improve from 1.29752
Epoch 808/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4211 - val_loss: 1.3077 - val_accuracy: 0.4000

Epoch 00808: val_loss did not improve from 1.29752
Epoch 809/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4146 - val_loss: 1.3028 - val_accuracy: 0.4127

Epoch 00809: val_loss did not improve from 1.29752
Epoch 810/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4170 - val_loss: 1.3029 - val_accuracy: 0.4088

Epoch 00810: val_loss did not improve from 1.29752
Epoch 811/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4203 - val_loss: 1.2992 - val_accuracy: 0.4112

Epoch 00811: val_loss did not improve from 1.29752
Epoch 812/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4159 - val_loss: 1.3019 - val_accuracy: 0.4151

Epoch 00812: val_loss did not improve from 1.29752
Epoch 813/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4174 - val_loss: 1.3088 - val_accuracy: 0.4024

Epoch 00813: val_loss did not improve from 1.29752
Epoch 814/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4223 - val_loss: 1.3042 - val_accuracy: 0.4008

Epoch 00814: val_loss did not improve from 1.29752
Epoch 815/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4195 - val_loss: 1.3039 - val_accuracy: 0.4008

Epoch 00815: val_loss did not improve from 1.29752
Epoch 816/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4184 - val_loss: 1.3003 - val_accuracy: 0.4112

Epoch 00816: val_loss did not improve from 1.29752
Epoch 817/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4205 - val_loss: 1.3044 - val_accuracy: 0.4024

Epoch 00817: val_loss did not improve from 1.29752
Epoch 818/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4174 - val_loss: 1.3016 - val_accuracy: 0.4080

Epoch 00818: val_loss did not improve from 1.29752
Epoch 819/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4197 - val_loss: 1.3010 - val_accuracy: 0.4088

Epoch 00819: val_loss did not improve from 1.29752
Epoch 820/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4213 - val_loss: 1.2982 - val_accuracy: 0.4048

Epoch 00820: val_loss did not improve from 1.29752
Epoch 821/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4221 - val_loss: 1.2981 - val_accuracy: 0.4080

Epoch 00821: val_loss did not improve from 1.29752
Epoch 822/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4227 - val_loss: 1.2991 - val_accuracy: 0.4112

Epoch 00822: val_loss did not improve from 1.29752
Epoch 823/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4213 - val_loss: 1.3011 - val_accuracy: 0.4056

Epoch 00823: val_loss did not improve from 1.29752
Epoch 824/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4174 - val_loss: 1.3073 - val_accuracy: 0.4000

Epoch 00824: val_loss did not improve from 1.29752
Epoch 825/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4208 - val_loss: 1.2973 - val_accuracy: 0.4199

Epoch 00825: val_loss improved from 1.29752 to 1.29730, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 826/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4207 - val_loss: 1.2992 - val_accuracy: 0.4135

Epoch 00826: val_loss did not improve from 1.29730
Epoch 827/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4190 - val_loss: 1.2998 - val_accuracy: 0.4151

Epoch 00827: val_loss did not improve from 1.29730
Epoch 828/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4258 - val_loss: 1.2997 - val_accuracy: 0.4088

Epoch 00828: val_loss did not improve from 1.29730
Epoch 829/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4177 - val_loss: 1.2983 - val_accuracy: 0.4159

Epoch 00829: val_loss did not improve from 1.29730
Epoch 830/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4182 - val_loss: 1.3102 - val_accuracy: 0.4088

Epoch 00830: val_loss did not improve from 1.29730
Epoch 831/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4244 - val_loss: 1.2951 - val_accuracy: 0.4183

Epoch 00831: val_loss improved from 1.29730 to 1.29514, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 832/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4242 - val_loss: 1.3000 - val_accuracy: 0.4183

Epoch 00832: val_loss did not improve from 1.29514
Epoch 833/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4220 - val_loss: 1.3031 - val_accuracy: 0.4056

Epoch 00833: val_loss did not improve from 1.29514
Epoch 834/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4196 - val_loss: 1.2985 - val_accuracy: 0.4143

Epoch 00834: val_loss did not improve from 1.29514
Epoch 835/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4207 - val_loss: 1.2974 - val_accuracy: 0.4183

Epoch 00835: val_loss did not improve from 1.29514
Epoch 836/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4213 - val_loss: 1.2981 - val_accuracy: 0.4135

Epoch 00836: val_loss did not improve from 1.29514
Epoch 837/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4182 - val_loss: 1.3001 - val_accuracy: 0.4112

Epoch 00837: val_loss did not improve from 1.29514
Epoch 838/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4251 - val_loss: 1.2986 - val_accuracy: 0.4112

Epoch 00838: val_loss did not improve from 1.29514
Epoch 839/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4193 - val_loss: 1.3069 - val_accuracy: 0.3984

Epoch 00839: val_loss did not improve from 1.29514
Epoch 840/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4194 - val_loss: 1.2986 - val_accuracy: 0.4112

Epoch 00840: val_loss did not improve from 1.29514
Epoch 841/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4240 - val_loss: 1.2998 - val_accuracy: 0.4056

Epoch 00841: val_loss did not improve from 1.29514
Epoch 842/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4196 - val_loss: 1.2998 - val_accuracy: 0.4032

Epoch 00842: val_loss did not improve from 1.29514
Epoch 843/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4223 - val_loss: 1.2983 - val_accuracy: 0.4135

Epoch 00843: val_loss did not improve from 1.29514
Epoch 844/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4186 - val_loss: 1.2997 - val_accuracy: 0.4064

Epoch 00844: val_loss did not improve from 1.29514
Epoch 845/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4174 - val_loss: 1.3023 - val_accuracy: 0.4056

Epoch 00845: val_loss did not improve from 1.29514
Epoch 846/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4207 - val_loss: 1.2963 - val_accuracy: 0.4104

Epoch 00846: val_loss did not improve from 1.29514
Epoch 847/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4209 - val_loss: 1.2976 - val_accuracy: 0.4151

Epoch 00847: val_loss did not improve from 1.29514
Epoch 848/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4227 - val_loss: 1.2990 - val_accuracy: 0.4104

Epoch 00848: val_loss did not improve from 1.29514
Epoch 849/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4200 - val_loss: 1.3001 - val_accuracy: 0.4048

Epoch 00849: val_loss did not improve from 1.29514
Epoch 850/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4221 - val_loss: 1.2981 - val_accuracy: 0.4127

Epoch 00850: val_loss did not improve from 1.29514
Epoch 851/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4196 - val_loss: 1.2991 - val_accuracy: 0.4127

Epoch 00851: val_loss did not improve from 1.29514
Epoch 852/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4219 - val_loss: 1.2963 - val_accuracy: 0.4080

Epoch 00852: val_loss did not improve from 1.29514
Epoch 853/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4203 - val_loss: 1.3013 - val_accuracy: 0.4032

Epoch 00853: val_loss did not improve from 1.29514
Epoch 854/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4198 - val_loss: 1.2999 - val_accuracy: 0.4127

Epoch 00854: val_loss did not improve from 1.29514
Epoch 855/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4183 - val_loss: 1.3089 - val_accuracy: 0.4016

Epoch 00855: val_loss did not improve from 1.29514
Epoch 856/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4209 - val_loss: 1.3041 - val_accuracy: 0.4024

Epoch 00856: val_loss did not improve from 1.29514
Epoch 857/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4216 - val_loss: 1.2965 - val_accuracy: 0.4120

Epoch 00857: val_loss did not improve from 1.29514
Epoch 858/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4223 - val_loss: 1.2961 - val_accuracy: 0.4199

Epoch 00858: val_loss did not improve from 1.29514
Epoch 859/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4210 - val_loss: 1.2978 - val_accuracy: 0.4143

Epoch 00859: val_loss did not improve from 1.29514
Epoch 860/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4212 - val_loss: 1.3089 - val_accuracy: 0.3920

Epoch 00860: val_loss did not improve from 1.29514
Epoch 861/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4207 - val_loss: 1.2986 - val_accuracy: 0.4088

Epoch 00861: val_loss did not improve from 1.29514
Epoch 862/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4211 - val_loss: 1.2997 - val_accuracy: 0.4127

Epoch 00862: val_loss did not improve from 1.29514
Epoch 863/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4223 - val_loss: 1.2984 - val_accuracy: 0.4151

Epoch 00863: val_loss did not improve from 1.29514
Epoch 864/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4186 - val_loss: 1.3019 - val_accuracy: 0.4088

Epoch 00864: val_loss did not improve from 1.29514
Epoch 865/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4220 - val_loss: 1.3016 - val_accuracy: 0.4096

Epoch 00865: val_loss did not improve from 1.29514
Epoch 866/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4181 - val_loss: 1.3010 - val_accuracy: 0.4135

Epoch 00866: val_loss did not improve from 1.29514
Epoch 867/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4245 - val_loss: 1.2992 - val_accuracy: 0.4223

Epoch 00867: val_loss did not improve from 1.29514
Epoch 868/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4168 - val_loss: 1.2993 - val_accuracy: 0.4223

Epoch 00868: val_loss did not improve from 1.29514
Epoch 869/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4222 - val_loss: 1.2961 - val_accuracy: 0.4159

Epoch 00869: val_loss did not improve from 1.29514
Epoch 870/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4196 - val_loss: 1.2991 - val_accuracy: 0.4088

Epoch 00870: val_loss did not improve from 1.29514
Epoch 871/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4183 - val_loss: 1.3010 - val_accuracy: 0.4056

Epoch 00871: val_loss did not improve from 1.29514
Epoch 872/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4176 - val_loss: 1.2980 - val_accuracy: 0.4183

Epoch 00872: val_loss did not improve from 1.29514
Epoch 873/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4184 - val_loss: 1.3015 - val_accuracy: 0.4080

Epoch 00873: val_loss did not improve from 1.29514
Epoch 874/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4236 - val_loss: 1.3011 - val_accuracy: 0.4040

Epoch 00874: val_loss did not improve from 1.29514
Epoch 875/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4263 - val_loss: 1.2964 - val_accuracy: 0.4064

Epoch 00875: val_loss did not improve from 1.29514
Epoch 876/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4230 - val_loss: 1.3006 - val_accuracy: 0.4096

Epoch 00876: val_loss did not improve from 1.29514
Epoch 877/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4229 - val_loss: 1.3054 - val_accuracy: 0.4096

Epoch 00877: val_loss did not improve from 1.29514
Epoch 878/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4227 - val_loss: 1.2969 - val_accuracy: 0.4207

Epoch 00878: val_loss did not improve from 1.29514
Epoch 879/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4198 - val_loss: 1.2978 - val_accuracy: 0.4215

Epoch 00879: val_loss did not improve from 1.29514
Epoch 880/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4229 - val_loss: 1.3052 - val_accuracy: 0.4016

Epoch 00880: val_loss did not improve from 1.29514
Epoch 881/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4201 - val_loss: 1.3018 - val_accuracy: 0.4096

Epoch 00881: val_loss did not improve from 1.29514
Epoch 882/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4238 - val_loss: 1.3017 - val_accuracy: 0.4112

Epoch 00882: val_loss did not improve from 1.29514
Epoch 883/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4200 - val_loss: 1.2978 - val_accuracy: 0.4199

Epoch 00883: val_loss did not improve from 1.29514
Epoch 884/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4227 - val_loss: 1.2980 - val_accuracy: 0.4127

Epoch 00884: val_loss did not improve from 1.29514
Epoch 885/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4227 - val_loss: 1.3018 - val_accuracy: 0.4104

Epoch 00885: val_loss did not improve from 1.29514
Epoch 886/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4242 - val_loss: 1.3008 - val_accuracy: 0.4112

Epoch 00886: val_loss did not improve from 1.29514
Epoch 887/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4240 - val_loss: 1.3017 - val_accuracy: 0.4048

Epoch 00887: val_loss did not improve from 1.29514
Epoch 888/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4235 - val_loss: 1.2961 - val_accuracy: 0.4135

Epoch 00888: val_loss did not improve from 1.29514
Epoch 889/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4193 - val_loss: 1.2999 - val_accuracy: 0.4135

Epoch 00889: val_loss did not improve from 1.29514
Epoch 890/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4231 - val_loss: 1.2997 - val_accuracy: 0.4199

Epoch 00890: val_loss did not improve from 1.29514
Epoch 891/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4241 - val_loss: 1.2954 - val_accuracy: 0.4207

Epoch 00891: val_loss did not improve from 1.29514
Epoch 892/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4237 - val_loss: 1.2977 - val_accuracy: 0.4167

Epoch 00892: val_loss did not improve from 1.29514
Epoch 893/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4204 - val_loss: 1.3035 - val_accuracy: 0.4024

Epoch 00893: val_loss did not improve from 1.29514
Epoch 894/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4225 - val_loss: 1.3095 - val_accuracy: 0.3936

Epoch 00894: val_loss did not improve from 1.29514
Epoch 895/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4242 - val_loss: 1.2969 - val_accuracy: 0.4080

Epoch 00895: val_loss did not improve from 1.29514
Epoch 896/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4240 - val_loss: 1.3011 - val_accuracy: 0.4032

Epoch 00896: val_loss did not improve from 1.29514
Epoch 897/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4235 - val_loss: 1.3014 - val_accuracy: 0.4064

Epoch 00897: val_loss did not improve from 1.29514
Epoch 898/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4198 - val_loss: 1.2960 - val_accuracy: 0.4072

Epoch 00898: val_loss did not improve from 1.29514
Epoch 899/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4251 - val_loss: 1.3010 - val_accuracy: 0.4024

Epoch 00899: val_loss did not improve from 1.29514
Epoch 900/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4229 - val_loss: 1.2981 - val_accuracy: 0.4104

Epoch 00900: val_loss did not improve from 1.29514
Epoch 901/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4221 - val_loss: 1.3033 - val_accuracy: 0.3984

Epoch 00901: val_loss did not improve from 1.29514
Epoch 902/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4205 - val_loss: 1.2999 - val_accuracy: 0.4175

Epoch 00902: val_loss did not improve from 1.29514
Epoch 903/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4250 - val_loss: 1.2977 - val_accuracy: 0.4183

Epoch 00903: val_loss did not improve from 1.29514
Epoch 904/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4181 - val_loss: 1.2994 - val_accuracy: 0.4104

Epoch 00904: val_loss did not improve from 1.29514
Epoch 905/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4207 - val_loss: 1.3004 - val_accuracy: 0.4127

Epoch 00905: val_loss did not improve from 1.29514
Epoch 906/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4212 - val_loss: 1.3041 - val_accuracy: 0.3992

Epoch 00906: val_loss did not improve from 1.29514
Epoch 907/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4250 - val_loss: 1.2968 - val_accuracy: 0.4167

Epoch 00907: val_loss did not improve from 1.29514
Epoch 908/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4178 - val_loss: 1.2963 - val_accuracy: 0.4088

Epoch 00908: val_loss did not improve from 1.29514
Epoch 909/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4213 - val_loss: 1.2992 - val_accuracy: 0.4104

Epoch 00909: val_loss did not improve from 1.29514
Epoch 910/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4222 - val_loss: 1.3041 - val_accuracy: 0.4024

Epoch 00910: val_loss did not improve from 1.29514
Epoch 911/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4221 - val_loss: 1.3047 - val_accuracy: 0.4072

Epoch 00911: val_loss did not improve from 1.29514
Epoch 912/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4200 - val_loss: 1.3021 - val_accuracy: 0.4104

Epoch 00912: val_loss did not improve from 1.29514
Epoch 913/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4253 - val_loss: 1.2979 - val_accuracy: 0.4135

Epoch 00913: val_loss did not improve from 1.29514
Epoch 914/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4227 - val_loss: 1.3060 - val_accuracy: 0.4080

Epoch 00914: val_loss did not improve from 1.29514
Epoch 915/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4200 - val_loss: 1.2989 - val_accuracy: 0.4143

Epoch 00915: val_loss did not improve from 1.29514
Epoch 916/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4209 - val_loss: 1.2991 - val_accuracy: 0.4104

Epoch 00916: val_loss did not improve from 1.29514
Epoch 917/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4223 - val_loss: 1.3012 - val_accuracy: 0.4143

Epoch 00917: val_loss did not improve from 1.29514
Epoch 918/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4238 - val_loss: 1.3056 - val_accuracy: 0.4064

Epoch 00918: val_loss did not improve from 1.29514
Epoch 919/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4223 - val_loss: 1.2988 - val_accuracy: 0.4143

Epoch 00919: val_loss did not improve from 1.29514
Epoch 920/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4244 - val_loss: 1.3023 - val_accuracy: 0.4048

Epoch 00920: val_loss did not improve from 1.29514
Epoch 921/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4277 - val_loss: 1.2961 - val_accuracy: 0.4159

Epoch 00921: val_loss did not improve from 1.29514
Epoch 922/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4236 - val_loss: 1.2995 - val_accuracy: 0.4008

Epoch 00922: val_loss did not improve from 1.29514
Epoch 923/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4232 - val_loss: 1.3013 - val_accuracy: 0.4127

Epoch 00923: val_loss did not improve from 1.29514
Epoch 924/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4229 - val_loss: 1.2980 - val_accuracy: 0.4120

Epoch 00924: val_loss did not improve from 1.29514
Epoch 925/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4223 - val_loss: 1.2974 - val_accuracy: 0.4112

Epoch 00925: val_loss did not improve from 1.29514
Epoch 926/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4211 - val_loss: 1.2987 - val_accuracy: 0.4104

Epoch 00926: val_loss did not improve from 1.29514
Epoch 927/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4245 - val_loss: 1.2995 - val_accuracy: 0.4175

Epoch 00927: val_loss did not improve from 1.29514
Epoch 928/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4188 - val_loss: 1.2950 - val_accuracy: 0.4191

Epoch 00928: val_loss improved from 1.29514 to 1.29497, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 929/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4198 - val_loss: 1.3066 - val_accuracy: 0.4024

Epoch 00929: val_loss did not improve from 1.29497
Epoch 930/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4185 - val_loss: 1.2966 - val_accuracy: 0.4231

Epoch 00930: val_loss did not improve from 1.29497
Epoch 931/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4213 - val_loss: 1.3074 - val_accuracy: 0.4199

Epoch 00931: val_loss did not improve from 1.29497
Epoch 932/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4165 - val_loss: 1.3010 - val_accuracy: 0.4127

Epoch 00932: val_loss did not improve from 1.29497
Epoch 933/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4262 - val_loss: 1.3109 - val_accuracy: 0.3984

Epoch 00933: val_loss did not improve from 1.29497
Epoch 934/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4214 - val_loss: 1.2990 - val_accuracy: 0.3992

Epoch 00934: val_loss did not improve from 1.29497
Epoch 935/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4198 - val_loss: 1.2950 - val_accuracy: 0.4207

Epoch 00935: val_loss did not improve from 1.29497
Epoch 936/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4184 - val_loss: 1.2981 - val_accuracy: 0.4000

Epoch 00936: val_loss did not improve from 1.29497
Epoch 937/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4202 - val_loss: 1.3020 - val_accuracy: 0.4135

Epoch 00937: val_loss did not improve from 1.29497
Epoch 938/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4230 - val_loss: 1.2979 - val_accuracy: 0.4159

Epoch 00938: val_loss did not improve from 1.29497
Epoch 939/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4222 - val_loss: 1.2964 - val_accuracy: 0.4159

Epoch 00939: val_loss did not improve from 1.29497
Epoch 940/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4245 - val_loss: 1.2971 - val_accuracy: 0.4167

Epoch 00940: val_loss did not improve from 1.29497
Epoch 941/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4240 - val_loss: 1.3011 - val_accuracy: 0.4135

Epoch 00941: val_loss did not improve from 1.29497
Epoch 942/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4214 - val_loss: 1.2973 - val_accuracy: 0.4072

Epoch 00942: val_loss did not improve from 1.29497
Epoch 943/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4205 - val_loss: 1.2946 - val_accuracy: 0.4143

Epoch 00943: val_loss improved from 1.29497 to 1.29458, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 944/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4216 - val_loss: 1.2961 - val_accuracy: 0.4159

Epoch 00944: val_loss did not improve from 1.29458
Epoch 945/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4236 - val_loss: 1.2974 - val_accuracy: 0.4088

Epoch 00945: val_loss did not improve from 1.29458
Epoch 946/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4227 - val_loss: 1.2979 - val_accuracy: 0.4167

Epoch 00946: val_loss did not improve from 1.29458
Epoch 947/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4221 - val_loss: 1.2943 - val_accuracy: 0.4247

Epoch 00947: val_loss improved from 1.29458 to 1.29426, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 948/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4223 - val_loss: 1.2977 - val_accuracy: 0.4024

Epoch 00948: val_loss did not improve from 1.29426
Epoch 949/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4251 - val_loss: 1.2952 - val_accuracy: 0.4088

Epoch 00949: val_loss did not improve from 1.29426
Epoch 950/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4187 - val_loss: 1.3007 - val_accuracy: 0.4120

Epoch 00950: val_loss did not improve from 1.29426
Epoch 951/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4258 - val_loss: 1.2968 - val_accuracy: 0.4096

Epoch 00951: val_loss did not improve from 1.29426
Epoch 952/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4205 - val_loss: 1.2942 - val_accuracy: 0.4175

Epoch 00952: val_loss improved from 1.29426 to 1.29418, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 953/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4244 - val_loss: 1.2992 - val_accuracy: 0.4127

Epoch 00953: val_loss did not improve from 1.29418
Epoch 954/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4195 - val_loss: 1.3023 - val_accuracy: 0.4016

Epoch 00954: val_loss did not improve from 1.29418
Epoch 955/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4226 - val_loss: 1.2977 - val_accuracy: 0.4112

Epoch 00955: val_loss did not improve from 1.29418
Epoch 956/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4236 - val_loss: 1.2969 - val_accuracy: 0.4112

Epoch 00956: val_loss did not improve from 1.29418
Epoch 957/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4253 - val_loss: 1.2964 - val_accuracy: 0.4167

Epoch 00957: val_loss did not improve from 1.29418
Epoch 958/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4241 - val_loss: 1.2960 - val_accuracy: 0.4175

Epoch 00958: val_loss did not improve from 1.29418
Epoch 959/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4259 - val_loss: 1.2956 - val_accuracy: 0.4159

Epoch 00959: val_loss did not improve from 1.29418
Epoch 960/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4245 - val_loss: 1.2972 - val_accuracy: 0.4159

Epoch 00960: val_loss did not improve from 1.29418
Epoch 961/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4224 - val_loss: 1.2959 - val_accuracy: 0.4191

Epoch 00961: val_loss did not improve from 1.29418
Epoch 962/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4211 - val_loss: 1.2961 - val_accuracy: 0.4120

Epoch 00962: val_loss did not improve from 1.29418
Epoch 963/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4254 - val_loss: 1.2959 - val_accuracy: 0.4135

Epoch 00963: val_loss did not improve from 1.29418
Epoch 964/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4244 - val_loss: 1.2954 - val_accuracy: 0.4175

Epoch 00964: val_loss did not improve from 1.29418
Epoch 965/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4236 - val_loss: 1.2992 - val_accuracy: 0.4120

Epoch 00965: val_loss did not improve from 1.29418
Epoch 966/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4244 - val_loss: 1.2948 - val_accuracy: 0.4120

Epoch 00966: val_loss did not improve from 1.29418
Epoch 967/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4245 - val_loss: 1.3017 - val_accuracy: 0.4080

Epoch 00967: val_loss did not improve from 1.29418
Epoch 968/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4221 - val_loss: 1.2986 - val_accuracy: 0.4048

Epoch 00968: val_loss did not improve from 1.29418
Epoch 969/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4227 - val_loss: 1.2940 - val_accuracy: 0.4135

Epoch 00969: val_loss improved from 1.29418 to 1.29404, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 970/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4217 - val_loss: 1.2985 - val_accuracy: 0.4096

Epoch 00970: val_loss did not improve from 1.29404
Epoch 971/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4254 - val_loss: 1.2935 - val_accuracy: 0.4135

Epoch 00971: val_loss improved from 1.29404 to 1.29355, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 972/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4219 - val_loss: 1.2997 - val_accuracy: 0.4032

Epoch 00972: val_loss did not improve from 1.29355
Epoch 973/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4245 - val_loss: 1.2985 - val_accuracy: 0.4040

Epoch 00973: val_loss did not improve from 1.29355
Epoch 974/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4239 - val_loss: 1.3003 - val_accuracy: 0.4008

Epoch 00974: val_loss did not improve from 1.29355
Epoch 975/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4248 - val_loss: 1.2980 - val_accuracy: 0.4112

Epoch 00975: val_loss did not improve from 1.29355
Epoch 976/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4261 - val_loss: 1.3018 - val_accuracy: 0.4151

Epoch 00976: val_loss did not improve from 1.29355
Epoch 977/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4238 - val_loss: 1.3154 - val_accuracy: 0.3992

Epoch 00977: val_loss did not improve from 1.29355
Epoch 978/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4181 - val_loss: 1.2947 - val_accuracy: 0.4088

Epoch 00978: val_loss did not improve from 1.29355
Epoch 979/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4280 - val_loss: 1.2947 - val_accuracy: 0.4159

Epoch 00979: val_loss did not improve from 1.29355
Epoch 980/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4252 - val_loss: 1.2982 - val_accuracy: 0.4120

Epoch 00980: val_loss did not improve from 1.29355
Epoch 981/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4256 - val_loss: 1.2951 - val_accuracy: 0.4199

Epoch 00981: val_loss did not improve from 1.29355
Epoch 982/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4231 - val_loss: 1.3042 - val_accuracy: 0.4223

Epoch 00982: val_loss did not improve from 1.29355
Epoch 983/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4230 - val_loss: 1.2961 - val_accuracy: 0.4135

Epoch 00983: val_loss did not improve from 1.29355
Epoch 984/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4264 - val_loss: 1.2991 - val_accuracy: 0.4104

Epoch 00984: val_loss did not improve from 1.29355
Epoch 985/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4233 - val_loss: 1.2993 - val_accuracy: 0.4127

Epoch 00985: val_loss did not improve from 1.29355
Epoch 986/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4198 - val_loss: 1.3049 - val_accuracy: 0.4032

Epoch 00986: val_loss did not improve from 1.29355
Epoch 987/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4229 - val_loss: 1.2950 - val_accuracy: 0.4199

Epoch 00987: val_loss did not improve from 1.29355
Epoch 988/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4270 - val_loss: 1.2958 - val_accuracy: 0.4072

Epoch 00988: val_loss did not improve from 1.29355
Epoch 989/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4276 - val_loss: 1.2967 - val_accuracy: 0.4072

Epoch 00989: val_loss did not improve from 1.29355
Epoch 990/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4257 - val_loss: 1.3006 - val_accuracy: 0.4072

Epoch 00990: val_loss did not improve from 1.29355
Epoch 991/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4256 - val_loss: 1.2960 - val_accuracy: 0.4120

Epoch 00991: val_loss did not improve from 1.29355
Epoch 992/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4229 - val_loss: 1.2976 - val_accuracy: 0.3976

Epoch 00992: val_loss did not improve from 1.29355
Epoch 993/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4226 - val_loss: 1.3033 - val_accuracy: 0.3984

Epoch 00993: val_loss did not improve from 1.29355
Epoch 994/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4264 - val_loss: 1.2952 - val_accuracy: 0.4167

Epoch 00994: val_loss did not improve from 1.29355
Epoch 995/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4225 - val_loss: 1.2976 - val_accuracy: 0.4072

Epoch 00995: val_loss did not improve from 1.29355
Epoch 996/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4242 - val_loss: 1.2940 - val_accuracy: 0.4088

Epoch 00996: val_loss did not improve from 1.29355
Epoch 997/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4291 - val_loss: 1.2946 - val_accuracy: 0.4080

Epoch 00997: val_loss did not improve from 1.29355
Epoch 998/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4249 - val_loss: 1.2972 - val_accuracy: 0.4120

Epoch 00998: val_loss did not improve from 1.29355
Epoch 999/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4238 - val_loss: 1.2968 - val_accuracy: 0.4072

Epoch 00999: val_loss did not improve from 1.29355
Epoch 1000/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4235 - val_loss: 1.2952 - val_accuracy: 0.4120

Epoch 01000: val_loss did not improve from 1.29355
Epoch 1001/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4239 - val_loss: 1.2952 - val_accuracy: 0.4080

Epoch 01001: val_loss did not improve from 1.29355
Epoch 1002/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4253 - val_loss: 1.2956 - val_accuracy: 0.4159

Epoch 01002: val_loss did not improve from 1.29355
Epoch 1003/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4221 - val_loss: 1.2934 - val_accuracy: 0.4295

Epoch 01003: val_loss improved from 1.29355 to 1.29341, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1004/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4207 - val_loss: 1.2934 - val_accuracy: 0.4191

Epoch 01004: val_loss improved from 1.29341 to 1.29340, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1005/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4205 - val_loss: 1.2958 - val_accuracy: 0.4135

Epoch 01005: val_loss did not improve from 1.29340
Epoch 1006/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4245 - val_loss: 1.2966 - val_accuracy: 0.4104

Epoch 01006: val_loss did not improve from 1.29340
Epoch 1007/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4288 - val_loss: 1.3031 - val_accuracy: 0.4064

Epoch 01007: val_loss did not improve from 1.29340
Epoch 1008/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4232 - val_loss: 1.2944 - val_accuracy: 0.4151

Epoch 01008: val_loss did not improve from 1.29340
Epoch 1009/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4221 - val_loss: 1.2916 - val_accuracy: 0.4159

Epoch 01009: val_loss improved from 1.29340 to 1.29161, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1010/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4249 - val_loss: 1.2972 - val_accuracy: 0.4104

Epoch 01010: val_loss did not improve from 1.29161
Epoch 1011/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4275 - val_loss: 1.2959 - val_accuracy: 0.4072

Epoch 01011: val_loss did not improve from 1.29161
Epoch 1012/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4226 - val_loss: 1.2967 - val_accuracy: 0.4151

Epoch 01012: val_loss did not improve from 1.29161
Epoch 1013/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4243 - val_loss: 1.2963 - val_accuracy: 0.4159

Epoch 01013: val_loss did not improve from 1.29161
Epoch 1014/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4228 - val_loss: 1.2990 - val_accuracy: 0.4064

Epoch 01014: val_loss did not improve from 1.29161
Epoch 1015/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4236 - val_loss: 1.2943 - val_accuracy: 0.4120

Epoch 01015: val_loss did not improve from 1.29161
Epoch 1016/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4218 - val_loss: 1.3050 - val_accuracy: 0.4008

Epoch 01016: val_loss did not improve from 1.29161
Epoch 1017/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4205 - val_loss: 1.3076 - val_accuracy: 0.4008

Epoch 01017: val_loss did not improve from 1.29161
Epoch 1018/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4193 - val_loss: 1.2938 - val_accuracy: 0.4199

Epoch 01018: val_loss did not improve from 1.29161
Epoch 1019/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4255 - val_loss: 1.3004 - val_accuracy: 0.4159

Epoch 01019: val_loss did not improve from 1.29161
Epoch 1020/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4271 - val_loss: 1.2931 - val_accuracy: 0.4223

Epoch 01020: val_loss did not improve from 1.29161
Epoch 1021/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4241 - val_loss: 1.2966 - val_accuracy: 0.4159

Epoch 01021: val_loss did not improve from 1.29161
Epoch 1022/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4237 - val_loss: 1.2940 - val_accuracy: 0.4143

Epoch 01022: val_loss did not improve from 1.29161
Epoch 1023/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4209 - val_loss: 1.3047 - val_accuracy: 0.4072

Epoch 01023: val_loss did not improve from 1.29161
Epoch 1024/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4259 - val_loss: 1.2944 - val_accuracy: 0.4127

Epoch 01024: val_loss did not improve from 1.29161
Epoch 1025/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4228 - val_loss: 1.2958 - val_accuracy: 0.4183

Epoch 01025: val_loss did not improve from 1.29161
Epoch 1026/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4220 - val_loss: 1.3027 - val_accuracy: 0.4072

Epoch 01026: val_loss did not improve from 1.29161
Epoch 1027/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4234 - val_loss: 1.2986 - val_accuracy: 0.4016

Epoch 01027: val_loss did not improve from 1.29161
Epoch 1028/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4234 - val_loss: 1.2997 - val_accuracy: 0.4112

Epoch 01028: val_loss did not improve from 1.29161
Epoch 1029/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4226 - val_loss: 1.2923 - val_accuracy: 0.4151

Epoch 01029: val_loss did not improve from 1.29161
Epoch 1030/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4237 - val_loss: 1.2966 - val_accuracy: 0.4143

Epoch 01030: val_loss did not improve from 1.29161
Epoch 1031/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4250 - val_loss: 1.2954 - val_accuracy: 0.4167

Epoch 01031: val_loss did not improve from 1.29161
Epoch 1032/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4220 - val_loss: 1.2938 - val_accuracy: 0.4223

Epoch 01032: val_loss did not improve from 1.29161
Epoch 1033/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4217 - val_loss: 1.2933 - val_accuracy: 0.4183

Epoch 01033: val_loss did not improve from 1.29161
Epoch 1034/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4244 - val_loss: 1.2920 - val_accuracy: 0.4215

Epoch 01034: val_loss did not improve from 1.29161
Epoch 1035/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4239 - val_loss: 1.2957 - val_accuracy: 0.4127

Epoch 01035: val_loss did not improve from 1.29161
Epoch 1036/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4241 - val_loss: 1.2956 - val_accuracy: 0.4143

Epoch 01036: val_loss did not improve from 1.29161
Epoch 1037/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4231 - val_loss: 1.2935 - val_accuracy: 0.4223

Epoch 01037: val_loss did not improve from 1.29161
Epoch 1038/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4233 - val_loss: 1.2928 - val_accuracy: 0.4215

Epoch 01038: val_loss did not improve from 1.29161
Epoch 1039/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4235 - val_loss: 1.2923 - val_accuracy: 0.4215

Epoch 01039: val_loss did not improve from 1.29161
Epoch 1040/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4236 - val_loss: 1.2939 - val_accuracy: 0.4143

Epoch 01040: val_loss did not improve from 1.29161
Epoch 1041/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4267 - val_loss: 1.2967 - val_accuracy: 0.4112

Epoch 01041: val_loss did not improve from 1.29161
Epoch 1042/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4215 - val_loss: 1.2949 - val_accuracy: 0.4215

Epoch 01042: val_loss did not improve from 1.29161
Epoch 1043/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4247 - val_loss: 1.2889 - val_accuracy: 0.4247

Epoch 01043: val_loss improved from 1.29161 to 1.28888, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1044/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4210 - val_loss: 1.2972 - val_accuracy: 0.4104

Epoch 01044: val_loss did not improve from 1.28888
Epoch 1045/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4272 - val_loss: 1.2929 - val_accuracy: 0.4191

Epoch 01045: val_loss did not improve from 1.28888
Epoch 1046/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4230 - val_loss: 1.2953 - val_accuracy: 0.4183

Epoch 01046: val_loss did not improve from 1.28888
Epoch 1047/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4223 - val_loss: 1.2945 - val_accuracy: 0.4143

Epoch 01047: val_loss did not improve from 1.28888
Epoch 1048/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4235 - val_loss: 1.2910 - val_accuracy: 0.4239

Epoch 01048: val_loss did not improve from 1.28888
Epoch 1049/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4253 - val_loss: 1.3002 - val_accuracy: 0.4016

Epoch 01049: val_loss did not improve from 1.28888
Epoch 1050/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4200 - val_loss: 1.2927 - val_accuracy: 0.4223

Epoch 01050: val_loss did not improve from 1.28888
Epoch 1051/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4224 - val_loss: 1.2917 - val_accuracy: 0.4207

Epoch 01051: val_loss did not improve from 1.28888
Epoch 1052/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4224 - val_loss: 1.2936 - val_accuracy: 0.4135

Epoch 01052: val_loss did not improve from 1.28888
Epoch 1053/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4202 - val_loss: 1.2938 - val_accuracy: 0.4167

Epoch 01053: val_loss did not improve from 1.28888
Epoch 1054/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4255 - val_loss: 1.2953 - val_accuracy: 0.4167

Epoch 01054: val_loss did not improve from 1.28888
Epoch 1055/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4254 - val_loss: 1.2941 - val_accuracy: 0.4080

Epoch 01055: val_loss did not improve from 1.28888
Epoch 1056/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4243 - val_loss: 1.2904 - val_accuracy: 0.4215

Epoch 01056: val_loss did not improve from 1.28888
Epoch 1057/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4210 - val_loss: 1.2916 - val_accuracy: 0.4311

Epoch 01057: val_loss did not improve from 1.28888
Epoch 1058/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4236 - val_loss: 1.2946 - val_accuracy: 0.4104

Epoch 01058: val_loss did not improve from 1.28888
Epoch 1059/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4226 - val_loss: 1.2940 - val_accuracy: 0.4048

Epoch 01059: val_loss did not improve from 1.28888
Epoch 1060/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4246 - val_loss: 1.2929 - val_accuracy: 0.4159

Epoch 01060: val_loss did not improve from 1.28888
Epoch 1061/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4243 - val_loss: 1.2945 - val_accuracy: 0.4135

Epoch 01061: val_loss did not improve from 1.28888
Epoch 1062/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4252 - val_loss: 1.2938 - val_accuracy: 0.4104

Epoch 01062: val_loss did not improve from 1.28888
Epoch 1063/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4263 - val_loss: 1.2932 - val_accuracy: 0.4151

Epoch 01063: val_loss did not improve from 1.28888
Epoch 1064/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4251 - val_loss: 1.3009 - val_accuracy: 0.4040

Epoch 01064: val_loss did not improve from 1.28888
Epoch 1065/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4229 - val_loss: 1.2960 - val_accuracy: 0.4032

Epoch 01065: val_loss did not improve from 1.28888
Epoch 1066/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4252 - val_loss: 1.2911 - val_accuracy: 0.4143

Epoch 01066: val_loss did not improve from 1.28888
Epoch 1067/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4239 - val_loss: 1.2909 - val_accuracy: 0.4207

Epoch 01067: val_loss did not improve from 1.28888
Epoch 1068/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4244 - val_loss: 1.2926 - val_accuracy: 0.4167

Epoch 01068: val_loss did not improve from 1.28888
Epoch 1069/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4246 - val_loss: 1.2911 - val_accuracy: 0.4167

Epoch 01069: val_loss did not improve from 1.28888
Epoch 1070/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4240 - val_loss: 1.2902 - val_accuracy: 0.4135

Epoch 01070: val_loss did not improve from 1.28888
Epoch 1071/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4244 - val_loss: 1.2934 - val_accuracy: 0.4175

Epoch 01071: val_loss did not improve from 1.28888
Epoch 1072/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4251 - val_loss: 1.3022 - val_accuracy: 0.4040

Epoch 01072: val_loss did not improve from 1.28888
Epoch 1073/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4252 - val_loss: 1.2926 - val_accuracy: 0.4223

Epoch 01073: val_loss did not improve from 1.28888
Epoch 1074/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4275 - val_loss: 1.2994 - val_accuracy: 0.3992

Epoch 01074: val_loss did not improve from 1.28888
Epoch 1075/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4218 - val_loss: 1.2905 - val_accuracy: 0.4143

Epoch 01075: val_loss did not improve from 1.28888
Epoch 1076/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4236 - val_loss: 1.2926 - val_accuracy: 0.4183

Epoch 01076: val_loss did not improve from 1.28888
Epoch 1077/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4240 - val_loss: 1.2983 - val_accuracy: 0.4127

Epoch 01077: val_loss did not improve from 1.28888
Epoch 1078/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4205 - val_loss: 1.3021 - val_accuracy: 0.4056

Epoch 01078: val_loss did not improve from 1.28888
Epoch 1079/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4232 - val_loss: 1.3003 - val_accuracy: 0.4120

Epoch 01079: val_loss did not improve from 1.28888
Epoch 1080/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4230 - val_loss: 1.2898 - val_accuracy: 0.4183

Epoch 01080: val_loss did not improve from 1.28888
Epoch 1081/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4258 - val_loss: 1.2944 - val_accuracy: 0.4183

Epoch 01081: val_loss did not improve from 1.28888
Epoch 1082/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4257 - val_loss: 1.2913 - val_accuracy: 0.4183

Epoch 01082: val_loss did not improve from 1.28888
Epoch 1083/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4239 - val_loss: 1.2932 - val_accuracy: 0.4135

Epoch 01083: val_loss did not improve from 1.28888
Epoch 1084/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4276 - val_loss: 1.2954 - val_accuracy: 0.4096

Epoch 01084: val_loss did not improve from 1.28888
Epoch 1085/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4259 - val_loss: 1.2944 - val_accuracy: 0.4207

Epoch 01085: val_loss did not improve from 1.28888
Epoch 1086/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4239 - val_loss: 1.3008 - val_accuracy: 0.4120

Epoch 01086: val_loss did not improve from 1.28888
Epoch 1087/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4283 - val_loss: 1.2997 - val_accuracy: 0.4088

Epoch 01087: val_loss did not improve from 1.28888
Epoch 1088/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4272 - val_loss: 1.2911 - val_accuracy: 0.4120

Epoch 01088: val_loss did not improve from 1.28888
Epoch 1089/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4275 - val_loss: 1.2901 - val_accuracy: 0.4303

Epoch 01089: val_loss did not improve from 1.28888
Epoch 1090/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4221 - val_loss: 1.2954 - val_accuracy: 0.4151

Epoch 01090: val_loss did not improve from 1.28888
Epoch 1091/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4262 - val_loss: 1.2952 - val_accuracy: 0.4064

Epoch 01091: val_loss did not improve from 1.28888
Epoch 1092/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4260 - val_loss: 1.2994 - val_accuracy: 0.4048

Epoch 01092: val_loss did not improve from 1.28888
Epoch 1093/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4186 - val_loss: 1.2895 - val_accuracy: 0.4120

Epoch 01093: val_loss did not improve from 1.28888
Epoch 1094/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4244 - val_loss: 1.2963 - val_accuracy: 0.4175

Epoch 01094: val_loss did not improve from 1.28888
Epoch 1095/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4225 - val_loss: 1.2939 - val_accuracy: 0.4120

Epoch 01095: val_loss did not improve from 1.28888
Epoch 1096/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4260 - val_loss: 1.2929 - val_accuracy: 0.4064

Epoch 01096: val_loss did not improve from 1.28888
Epoch 1097/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4264 - val_loss: 1.3032 - val_accuracy: 0.3984

Epoch 01097: val_loss did not improve from 1.28888
Epoch 1098/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4283 - val_loss: 1.2932 - val_accuracy: 0.4135

Epoch 01098: val_loss did not improve from 1.28888
Epoch 1099/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4259 - val_loss: 1.2923 - val_accuracy: 0.4191

Epoch 01099: val_loss did not improve from 1.28888
Epoch 1100/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4228 - val_loss: 1.3000 - val_accuracy: 0.4032

Epoch 01100: val_loss did not improve from 1.28888
Epoch 1101/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4215 - val_loss: 1.2914 - val_accuracy: 0.4159

Epoch 01101: val_loss did not improve from 1.28888
Epoch 1102/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4244 - val_loss: 1.2990 - val_accuracy: 0.4040

Epoch 01102: val_loss did not improve from 1.28888
Epoch 1103/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4233 - val_loss: 1.2950 - val_accuracy: 0.4127

Epoch 01103: val_loss did not improve from 1.28888
Epoch 1104/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4229 - val_loss: 1.2910 - val_accuracy: 0.4175

Epoch 01104: val_loss did not improve from 1.28888
Epoch 1105/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4236 - val_loss: 1.2931 - val_accuracy: 0.4127

Epoch 01105: val_loss did not improve from 1.28888
Epoch 1106/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4232 - val_loss: 1.2957 - val_accuracy: 0.4112

Epoch 01106: val_loss did not improve from 1.28888
Epoch 1107/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4251 - val_loss: 1.2970 - val_accuracy: 0.4143

Epoch 01107: val_loss did not improve from 1.28888
Epoch 1108/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4257 - val_loss: 1.2919 - val_accuracy: 0.4096

Epoch 01108: val_loss did not improve from 1.28888
Epoch 1109/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4220 - val_loss: 1.2914 - val_accuracy: 0.4167

Epoch 01109: val_loss did not improve from 1.28888
Epoch 1110/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4251 - val_loss: 1.2972 - val_accuracy: 0.4056

Epoch 01110: val_loss did not improve from 1.28888
Epoch 1111/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4249 - val_loss: 1.2960 - val_accuracy: 0.4215

Epoch 01111: val_loss did not improve from 1.28888
Epoch 1112/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4228 - val_loss: 1.2924 - val_accuracy: 0.4199

Epoch 01112: val_loss did not improve from 1.28888
Epoch 1113/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4275 - val_loss: 1.2894 - val_accuracy: 0.4207

Epoch 01113: val_loss did not improve from 1.28888
Epoch 1114/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4179 - val_loss: 1.2945 - val_accuracy: 0.4143

Epoch 01114: val_loss did not improve from 1.28888
Epoch 1115/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4229 - val_loss: 1.2932 - val_accuracy: 0.4056

Epoch 01115: val_loss did not improve from 1.28888
Epoch 1116/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4249 - val_loss: 1.3044 - val_accuracy: 0.4048

Epoch 01116: val_loss did not improve from 1.28888
Epoch 1117/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4149 - val_loss: 1.2966 - val_accuracy: 0.4072

Epoch 01117: val_loss did not improve from 1.28888
Epoch 1118/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4260 - val_loss: 1.2905 - val_accuracy: 0.4151

Epoch 01118: val_loss did not improve from 1.28888
Epoch 1119/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4276 - val_loss: 1.2977 - val_accuracy: 0.4056

Epoch 01119: val_loss did not improve from 1.28888
Epoch 1120/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4242 - val_loss: 1.2906 - val_accuracy: 0.4127

Epoch 01120: val_loss did not improve from 1.28888
Epoch 1121/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4218 - val_loss: 1.2907 - val_accuracy: 0.4143

Epoch 01121: val_loss did not improve from 1.28888
Epoch 1122/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4275 - val_loss: 1.2961 - val_accuracy: 0.4048

Epoch 01122: val_loss did not improve from 1.28888
Epoch 1123/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4249 - val_loss: 1.2950 - val_accuracy: 0.4096

Epoch 01123: val_loss did not improve from 1.28888
Epoch 1124/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4255 - val_loss: 1.2933 - val_accuracy: 0.4120

Epoch 01124: val_loss did not improve from 1.28888
Epoch 1125/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4290 - val_loss: 1.2921 - val_accuracy: 0.4120

Epoch 01125: val_loss did not improve from 1.28888
Epoch 1126/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4243 - val_loss: 1.2929 - val_accuracy: 0.4088

Epoch 01126: val_loss did not improve from 1.28888
Epoch 1127/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4240 - val_loss: 1.2916 - val_accuracy: 0.4143

Epoch 01127: val_loss did not improve from 1.28888
Epoch 1128/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4205 - val_loss: 1.2939 - val_accuracy: 0.4223

Epoch 01128: val_loss did not improve from 1.28888
Epoch 1129/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4258 - val_loss: 1.2898 - val_accuracy: 0.4183

Epoch 01129: val_loss did not improve from 1.28888
Epoch 1130/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4272 - val_loss: 1.2900 - val_accuracy: 0.4207

Epoch 01130: val_loss did not improve from 1.28888
Epoch 1131/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4256 - val_loss: 1.2894 - val_accuracy: 0.4199

Epoch 01131: val_loss did not improve from 1.28888
Epoch 1132/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4247 - val_loss: 1.2925 - val_accuracy: 0.4167

Epoch 01132: val_loss did not improve from 1.28888
Epoch 1133/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4213 - val_loss: 1.2904 - val_accuracy: 0.4199

Epoch 01133: val_loss did not improve from 1.28888
Epoch 1134/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4274 - val_loss: 1.2913 - val_accuracy: 0.4159

Epoch 01134: val_loss did not improve from 1.28888
Epoch 1135/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4251 - val_loss: 1.2914 - val_accuracy: 0.4104

Epoch 01135: val_loss did not improve from 1.28888
Epoch 1136/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4229 - val_loss: 1.2908 - val_accuracy: 0.4159

Epoch 01136: val_loss did not improve from 1.28888
Epoch 1137/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4250 - val_loss: 1.2885 - val_accuracy: 0.4271

Epoch 01137: val_loss improved from 1.28888 to 1.28850, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1138/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4251 - val_loss: 1.2912 - val_accuracy: 0.4215

Epoch 01138: val_loss did not improve from 1.28850
Epoch 1139/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4231 - val_loss: 1.2917 - val_accuracy: 0.4159

Epoch 01139: val_loss did not improve from 1.28850
Epoch 1140/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4252 - val_loss: 1.2933 - val_accuracy: 0.4151

Epoch 01140: val_loss did not improve from 1.28850
Epoch 1141/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4269 - val_loss: 1.2892 - val_accuracy: 0.4151

Epoch 01141: val_loss did not improve from 1.28850
Epoch 1142/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4276 - val_loss: 1.2944 - val_accuracy: 0.4104

Epoch 01142: val_loss did not improve from 1.28850
Epoch 1143/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4257 - val_loss: 1.2909 - val_accuracy: 0.4159

Epoch 01143: val_loss did not improve from 1.28850
Epoch 1144/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4254 - val_loss: 1.2911 - val_accuracy: 0.4151

Epoch 01144: val_loss did not improve from 1.28850
Epoch 1145/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4264 - val_loss: 1.2931 - val_accuracy: 0.4175

Epoch 01145: val_loss did not improve from 1.28850
Epoch 1146/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4264 - val_loss: 1.2941 - val_accuracy: 0.4215

Epoch 01146: val_loss did not improve from 1.28850
Epoch 1147/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4284 - val_loss: 1.2902 - val_accuracy: 0.4159

Epoch 01147: val_loss did not improve from 1.28850
Epoch 1148/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4313 - val_loss: 1.2868 - val_accuracy: 0.4223

Epoch 01148: val_loss improved from 1.28850 to 1.28677, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1149/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4253 - val_loss: 1.2912 - val_accuracy: 0.4120

Epoch 01149: val_loss did not improve from 1.28677
Epoch 1150/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4236 - val_loss: 1.2916 - val_accuracy: 0.4120

Epoch 01150: val_loss did not improve from 1.28677
Epoch 1151/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4273 - val_loss: 1.2917 - val_accuracy: 0.4175

Epoch 01151: val_loss did not improve from 1.28677
Epoch 1152/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4247 - val_loss: 1.2942 - val_accuracy: 0.4175

Epoch 01152: val_loss did not improve from 1.28677
Epoch 1153/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4283 - val_loss: 1.2896 - val_accuracy: 0.4112

Epoch 01153: val_loss did not improve from 1.28677
Epoch 1154/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4274 - val_loss: 1.2928 - val_accuracy: 0.4175

Epoch 01154: val_loss did not improve from 1.28677
Epoch 1155/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4246 - val_loss: 1.2887 - val_accuracy: 0.4215

Epoch 01155: val_loss did not improve from 1.28677
Epoch 1156/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4241 - val_loss: 1.2905 - val_accuracy: 0.4159

Epoch 01156: val_loss did not improve from 1.28677
Epoch 1157/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4223 - val_loss: 1.2900 - val_accuracy: 0.4127

Epoch 01157: val_loss did not improve from 1.28677
Epoch 1158/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4223 - val_loss: 1.3091 - val_accuracy: 0.4008

Epoch 01158: val_loss did not improve from 1.28677
Epoch 1159/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4258 - val_loss: 1.2887 - val_accuracy: 0.4191

Epoch 01159: val_loss did not improve from 1.28677
Epoch 1160/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4262 - val_loss: 1.2909 - val_accuracy: 0.4183

Epoch 01160: val_loss did not improve from 1.28677
Epoch 1161/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4272 - val_loss: 1.2917 - val_accuracy: 0.4143

Epoch 01161: val_loss did not improve from 1.28677
Epoch 1162/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4216 - val_loss: 1.2918 - val_accuracy: 0.4088

Epoch 01162: val_loss did not improve from 1.28677
Epoch 1163/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4267 - val_loss: 1.2920 - val_accuracy: 0.4096

Epoch 01163: val_loss did not improve from 1.28677
Epoch 1164/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4291 - val_loss: 1.2893 - val_accuracy: 0.4167

Epoch 01164: val_loss did not improve from 1.28677
Epoch 1165/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4293 - val_loss: 1.2929 - val_accuracy: 0.4135

Epoch 01165: val_loss did not improve from 1.28677
Epoch 1166/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4260 - val_loss: 1.2915 - val_accuracy: 0.4135

Epoch 01166: val_loss did not improve from 1.28677
Epoch 1167/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4265 - val_loss: 1.2879 - val_accuracy: 0.4120

Epoch 01167: val_loss did not improve from 1.28677
Epoch 1168/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4236 - val_loss: 1.3005 - val_accuracy: 0.4008

Epoch 01168: val_loss did not improve from 1.28677
Epoch 1169/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4228 - val_loss: 1.2919 - val_accuracy: 0.4199

Epoch 01169: val_loss did not improve from 1.28677
Epoch 1170/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4279 - val_loss: 1.2867 - val_accuracy: 0.4159

Epoch 01170: val_loss improved from 1.28677 to 1.28668, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1171/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4252 - val_loss: 1.2900 - val_accuracy: 0.4159

Epoch 01171: val_loss did not improve from 1.28668
Epoch 1172/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4271 - val_loss: 1.2914 - val_accuracy: 0.4167

Epoch 01172: val_loss did not improve from 1.28668
Epoch 1173/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4251 - val_loss: 1.2891 - val_accuracy: 0.4167

Epoch 01173: val_loss did not improve from 1.28668
Epoch 1174/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4220 - val_loss: 1.2877 - val_accuracy: 0.4207

Epoch 01174: val_loss did not improve from 1.28668
Epoch 1175/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4260 - val_loss: 1.2954 - val_accuracy: 0.4151

Epoch 01175: val_loss did not improve from 1.28668
Epoch 1176/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4258 - val_loss: 1.2934 - val_accuracy: 0.4120

Epoch 01176: val_loss did not improve from 1.28668
Epoch 1177/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4287 - val_loss: 1.2931 - val_accuracy: 0.4088

Epoch 01177: val_loss did not improve from 1.28668
Epoch 1178/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4278 - val_loss: 1.2878 - val_accuracy: 0.4143

Epoch 01178: val_loss did not improve from 1.28668
Epoch 1179/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4284 - val_loss: 1.2902 - val_accuracy: 0.4215

Epoch 01179: val_loss did not improve from 1.28668
Epoch 1180/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4268 - val_loss: 1.2908 - val_accuracy: 0.4135

Epoch 01180: val_loss did not improve from 1.28668
Epoch 1181/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4275 - val_loss: 1.2949 - val_accuracy: 0.4072

Epoch 01181: val_loss did not improve from 1.28668
Epoch 1182/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4260 - val_loss: 1.2878 - val_accuracy: 0.4207

Epoch 01182: val_loss did not improve from 1.28668
Epoch 1183/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4209 - val_loss: 1.2938 - val_accuracy: 0.4151

Epoch 01183: val_loss did not improve from 1.28668
Epoch 1184/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4270 - val_loss: 1.2905 - val_accuracy: 0.4143

Epoch 01184: val_loss did not improve from 1.28668
Epoch 1185/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4241 - val_loss: 1.2937 - val_accuracy: 0.4135

Epoch 01185: val_loss did not improve from 1.28668
Epoch 1186/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4284 - val_loss: 1.2925 - val_accuracy: 0.4231

Epoch 01186: val_loss did not improve from 1.28668
Epoch 1187/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4229 - val_loss: 1.2905 - val_accuracy: 0.4127

Epoch 01187: val_loss did not improve from 1.28668
Epoch 1188/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4294 - val_loss: 1.2889 - val_accuracy: 0.4159

Epoch 01188: val_loss did not improve from 1.28668
Epoch 1189/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4238 - val_loss: 1.2935 - val_accuracy: 0.4104

Epoch 01189: val_loss did not improve from 1.28668
Epoch 1190/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4210 - val_loss: 1.2920 - val_accuracy: 0.4151

Epoch 01190: val_loss did not improve from 1.28668
Epoch 1191/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4187 - val_loss: 1.2891 - val_accuracy: 0.4175

Epoch 01191: val_loss did not improve from 1.28668
Epoch 1192/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4244 - val_loss: 1.2945 - val_accuracy: 0.4151

Epoch 01192: val_loss did not improve from 1.28668
Epoch 1193/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4205 - val_loss: 1.2913 - val_accuracy: 0.4167

Epoch 01193: val_loss did not improve from 1.28668
Epoch 1194/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4240 - val_loss: 1.2959 - val_accuracy: 0.4104

Epoch 01194: val_loss did not improve from 1.28668
Epoch 1195/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4248 - val_loss: 1.2947 - val_accuracy: 0.4159

Epoch 01195: val_loss did not improve from 1.28668
Epoch 1196/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4265 - val_loss: 1.2889 - val_accuracy: 0.4191

Epoch 01196: val_loss did not improve from 1.28668
Epoch 1197/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4275 - val_loss: 1.2916 - val_accuracy: 0.4135

Epoch 01197: val_loss did not improve from 1.28668
Epoch 1198/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4272 - val_loss: 1.2869 - val_accuracy: 0.4247

Epoch 01198: val_loss did not improve from 1.28668
Epoch 1199/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4260 - val_loss: 1.2901 - val_accuracy: 0.4175

Epoch 01199: val_loss did not improve from 1.28668
Epoch 1200/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4271 - val_loss: 1.2946 - val_accuracy: 0.4159

Epoch 01200: val_loss did not improve from 1.28668
Epoch 1201/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4284 - val_loss: 1.2922 - val_accuracy: 0.4159

Epoch 01201: val_loss did not improve from 1.28668
Epoch 1202/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4247 - val_loss: 1.2888 - val_accuracy: 0.4199

Epoch 01202: val_loss did not improve from 1.28668
Epoch 1203/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4289 - val_loss: 1.2903 - val_accuracy: 0.4175

Epoch 01203: val_loss did not improve from 1.28668
Epoch 1204/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4250 - val_loss: 1.2911 - val_accuracy: 0.4215

Epoch 01204: val_loss did not improve from 1.28668
Epoch 1205/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4216 - val_loss: 1.2894 - val_accuracy: 0.4175

Epoch 01205: val_loss did not improve from 1.28668
Epoch 1206/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4272 - val_loss: 1.2954 - val_accuracy: 0.4120

Epoch 01206: val_loss did not improve from 1.28668
Epoch 1207/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4277 - val_loss: 1.2875 - val_accuracy: 0.4151

Epoch 01207: val_loss did not improve from 1.28668
Epoch 1208/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4260 - val_loss: 1.2845 - val_accuracy: 0.4127

Epoch 01208: val_loss improved from 1.28668 to 1.28447, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1209/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4260 - val_loss: 1.2939 - val_accuracy: 0.4048

Epoch 01209: val_loss did not improve from 1.28447
Epoch 1210/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4225 - val_loss: 1.2917 - val_accuracy: 0.4151

Epoch 01210: val_loss did not improve from 1.28447
Epoch 1211/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4234 - val_loss: 1.2913 - val_accuracy: 0.4048

Epoch 01211: val_loss did not improve from 1.28447
Epoch 1212/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4257 - val_loss: 1.2928 - val_accuracy: 0.4064

Epoch 01212: val_loss did not improve from 1.28447
Epoch 1213/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4220 - val_loss: 1.2902 - val_accuracy: 0.4175

Epoch 01213: val_loss did not improve from 1.28447
Epoch 1214/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4248 - val_loss: 1.2916 - val_accuracy: 0.4064

Epoch 01214: val_loss did not improve from 1.28447
Epoch 1215/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4269 - val_loss: 1.2880 - val_accuracy: 0.4143

Epoch 01215: val_loss did not improve from 1.28447
Epoch 1216/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4255 - val_loss: 1.2853 - val_accuracy: 0.4207

Epoch 01216: val_loss did not improve from 1.28447
Epoch 1217/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4289 - val_loss: 1.2894 - val_accuracy: 0.4135

Epoch 01217: val_loss did not improve from 1.28447
Epoch 1218/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4261 - val_loss: 1.2880 - val_accuracy: 0.4175

Epoch 01218: val_loss did not improve from 1.28447
Epoch 1219/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4267 - val_loss: 1.2871 - val_accuracy: 0.4207

Epoch 01219: val_loss did not improve from 1.28447
Epoch 1220/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4289 - val_loss: 1.2905 - val_accuracy: 0.4127

Epoch 01220: val_loss did not improve from 1.28447
Epoch 1221/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4241 - val_loss: 1.2899 - val_accuracy: 0.4143

Epoch 01221: val_loss did not improve from 1.28447
Epoch 1222/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4253 - val_loss: 1.2883 - val_accuracy: 0.4175

Epoch 01222: val_loss did not improve from 1.28447
Epoch 1223/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4236 - val_loss: 1.2859 - val_accuracy: 0.4127

Epoch 01223: val_loss did not improve from 1.28447
Epoch 1224/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4258 - val_loss: 1.2914 - val_accuracy: 0.4120

Epoch 01224: val_loss did not improve from 1.28447
Epoch 1225/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4278 - val_loss: 1.2861 - val_accuracy: 0.4255

Epoch 01225: val_loss did not improve from 1.28447
Epoch 1226/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4304 - val_loss: 1.2877 - val_accuracy: 0.4207

Epoch 01226: val_loss did not improve from 1.28447
Epoch 1227/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4277 - val_loss: 1.2881 - val_accuracy: 0.4191

Epoch 01227: val_loss did not improve from 1.28447
Epoch 1228/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4267 - val_loss: 1.2914 - val_accuracy: 0.4239

Epoch 01228: val_loss did not improve from 1.28447
Epoch 1229/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4252 - val_loss: 1.2891 - val_accuracy: 0.4175

Epoch 01229: val_loss did not improve from 1.28447
Epoch 1230/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4313 - val_loss: 1.2851 - val_accuracy: 0.4215

Epoch 01230: val_loss did not improve from 1.28447
Epoch 1231/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4252 - val_loss: 1.2971 - val_accuracy: 0.4167

Epoch 01231: val_loss did not improve from 1.28447
Epoch 1232/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4167 - val_loss: 1.2999 - val_accuracy: 0.4064

Epoch 01232: val_loss did not improve from 1.28447
Epoch 1233/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4263 - val_loss: 1.2882 - val_accuracy: 0.4104

Epoch 01233: val_loss did not improve from 1.28447
Epoch 1234/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4244 - val_loss: 1.2867 - val_accuracy: 0.4159

Epoch 01234: val_loss did not improve from 1.28447
Epoch 1235/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4322 - val_loss: 1.2886 - val_accuracy: 0.4112

Epoch 01235: val_loss did not improve from 1.28447
Epoch 1236/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4291 - val_loss: 1.2902 - val_accuracy: 0.4143

Epoch 01236: val_loss did not improve from 1.28447
Epoch 1237/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4253 - val_loss: 1.2873 - val_accuracy: 0.4159

Epoch 01237: val_loss did not improve from 1.28447
Epoch 1238/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4266 - val_loss: 1.2876 - val_accuracy: 0.4127

Epoch 01238: val_loss did not improve from 1.28447
Epoch 1239/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4284 - val_loss: 1.2885 - val_accuracy: 0.4159

Epoch 01239: val_loss did not improve from 1.28447
Epoch 1240/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4280 - val_loss: 1.2862 - val_accuracy: 0.4183

Epoch 01240: val_loss did not improve from 1.28447
Epoch 1241/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4245 - val_loss: 1.2857 - val_accuracy: 0.4167

Epoch 01241: val_loss did not improve from 1.28447
Epoch 1242/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4268 - val_loss: 1.2883 - val_accuracy: 0.4223

Epoch 01242: val_loss did not improve from 1.28447
Epoch 1243/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4235 - val_loss: 1.2928 - val_accuracy: 0.4167

Epoch 01243: val_loss did not improve from 1.28447
Epoch 1244/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4275 - val_loss: 1.2892 - val_accuracy: 0.4175

Epoch 01244: val_loss did not improve from 1.28447
Epoch 1245/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4275 - val_loss: 1.2987 - val_accuracy: 0.4040

Epoch 01245: val_loss did not improve from 1.28447
Epoch 1246/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4258 - val_loss: 1.2847 - val_accuracy: 0.4159

Epoch 01246: val_loss did not improve from 1.28447
Epoch 1247/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4300 - val_loss: 1.2890 - val_accuracy: 0.4167

Epoch 01247: val_loss did not improve from 1.28447
Epoch 1248/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4292 - val_loss: 1.2867 - val_accuracy: 0.4120

Epoch 01248: val_loss did not improve from 1.28447
Epoch 1249/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4285 - val_loss: 1.2863 - val_accuracy: 0.4271

Epoch 01249: val_loss did not improve from 1.28447
Epoch 1250/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4247 - val_loss: 1.2913 - val_accuracy: 0.4120

Epoch 01250: val_loss did not improve from 1.28447
Epoch 1251/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4220 - val_loss: 1.2876 - val_accuracy: 0.4231

Epoch 01251: val_loss did not improve from 1.28447
Epoch 1252/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4217 - val_loss: 1.2828 - val_accuracy: 0.4143

Epoch 01252: val_loss improved from 1.28447 to 1.28282, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1253/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4245 - val_loss: 1.2860 - val_accuracy: 0.4207

Epoch 01253: val_loss did not improve from 1.28282
Epoch 1254/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4300 - val_loss: 1.2929 - val_accuracy: 0.4175

Epoch 01254: val_loss did not improve from 1.28282
Epoch 1255/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4308 - val_loss: 1.2885 - val_accuracy: 0.4183

Epoch 01255: val_loss did not improve from 1.28282
Epoch 1256/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4264 - val_loss: 1.2864 - val_accuracy: 0.4151

Epoch 01256: val_loss did not improve from 1.28282
Epoch 1257/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4224 - val_loss: 1.2860 - val_accuracy: 0.4215

Epoch 01257: val_loss did not improve from 1.28282
Epoch 1258/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4249 - val_loss: 1.2928 - val_accuracy: 0.4127

Epoch 01258: val_loss did not improve from 1.28282
Epoch 1259/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4295 - val_loss: 1.2864 - val_accuracy: 0.4183

Epoch 01259: val_loss did not improve from 1.28282
Epoch 1260/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4285 - val_loss: 1.2857 - val_accuracy: 0.4223

Epoch 01260: val_loss did not improve from 1.28282
Epoch 1261/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4285 - val_loss: 1.2880 - val_accuracy: 0.4199

Epoch 01261: val_loss did not improve from 1.28282
Epoch 1262/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4293 - val_loss: 1.2879 - val_accuracy: 0.4112

Epoch 01262: val_loss did not improve from 1.28282
Epoch 1263/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4266 - val_loss: 1.2883 - val_accuracy: 0.4223

Epoch 01263: val_loss did not improve from 1.28282
Epoch 1264/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4226 - val_loss: 1.2840 - val_accuracy: 0.4175

Epoch 01264: val_loss did not improve from 1.28282
Epoch 1265/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4284 - val_loss: 1.2879 - val_accuracy: 0.4088

Epoch 01265: val_loss did not improve from 1.28282
Epoch 1266/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4234 - val_loss: 1.2827 - val_accuracy: 0.4143

Epoch 01266: val_loss improved from 1.28282 to 1.28268, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1267/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4278 - val_loss: 1.2875 - val_accuracy: 0.4151

Epoch 01267: val_loss did not improve from 1.28268
Epoch 1268/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4266 - val_loss: 1.2873 - val_accuracy: 0.4191

Epoch 01268: val_loss did not improve from 1.28268
Epoch 1269/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4276 - val_loss: 1.2864 - val_accuracy: 0.4120

Epoch 01269: val_loss did not improve from 1.28268
Epoch 1270/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4267 - val_loss: 1.2869 - val_accuracy: 0.4120

Epoch 01270: val_loss did not improve from 1.28268
Epoch 1271/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4300 - val_loss: 1.2891 - val_accuracy: 0.4143

Epoch 01271: val_loss did not improve from 1.28268
Epoch 1272/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4261 - val_loss: 1.2870 - val_accuracy: 0.4247

Epoch 01272: val_loss did not improve from 1.28268
Epoch 1273/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4255 - val_loss: 1.2886 - val_accuracy: 0.4159

Epoch 01273: val_loss did not improve from 1.28268
Epoch 1274/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4219 - val_loss: 1.2912 - val_accuracy: 0.4175

Epoch 01274: val_loss did not improve from 1.28268
Epoch 1275/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4265 - val_loss: 1.2911 - val_accuracy: 0.4191

Epoch 01275: val_loss did not improve from 1.28268
Epoch 1276/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4254 - val_loss: 1.2866 - val_accuracy: 0.4135

Epoch 01276: val_loss did not improve from 1.28268
Epoch 1277/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4267 - val_loss: 1.2845 - val_accuracy: 0.4127

Epoch 01277: val_loss did not improve from 1.28268
Epoch 1278/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4265 - val_loss: 1.2867 - val_accuracy: 0.4159

Epoch 01278: val_loss did not improve from 1.28268
Epoch 1279/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4251 - val_loss: 1.2919 - val_accuracy: 0.4080

Epoch 01279: val_loss did not improve from 1.28268
Epoch 1280/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4275 - val_loss: 1.2851 - val_accuracy: 0.4151

Epoch 01280: val_loss did not improve from 1.28268
Epoch 1281/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4255 - val_loss: 1.2861 - val_accuracy: 0.4159

Epoch 01281: val_loss did not improve from 1.28268
Epoch 1282/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4264 - val_loss: 1.2885 - val_accuracy: 0.4143

Epoch 01282: val_loss did not improve from 1.28268
Epoch 1283/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4274 - val_loss: 1.2898 - val_accuracy: 0.4191

Epoch 01283: val_loss did not improve from 1.28268
Epoch 1284/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4280 - val_loss: 1.2861 - val_accuracy: 0.4175

Epoch 01284: val_loss did not improve from 1.28268
Epoch 1285/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4289 - val_loss: 1.2893 - val_accuracy: 0.4143

Epoch 01285: val_loss did not improve from 1.28268
Epoch 1286/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4255 - val_loss: 1.2908 - val_accuracy: 0.4104

Epoch 01286: val_loss did not improve from 1.28268
Epoch 1287/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4260 - val_loss: 1.2851 - val_accuracy: 0.4199

Epoch 01287: val_loss did not improve from 1.28268
Epoch 1288/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4277 - val_loss: 1.2872 - val_accuracy: 0.4104

Epoch 01288: val_loss did not improve from 1.28268
Epoch 1289/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4261 - val_loss: 1.2857 - val_accuracy: 0.4135

Epoch 01289: val_loss did not improve from 1.28268
Epoch 1290/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4201 - val_loss: 1.2926 - val_accuracy: 0.4120

Epoch 01290: val_loss did not improve from 1.28268
Epoch 1291/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4230 - val_loss: 1.2942 - val_accuracy: 0.4072

Epoch 01291: val_loss did not improve from 1.28268
Epoch 1292/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4211 - val_loss: 1.2869 - val_accuracy: 0.4175

Epoch 01292: val_loss did not improve from 1.28268
Epoch 1293/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4243 - val_loss: 1.2872 - val_accuracy: 0.4199

Epoch 01293: val_loss did not improve from 1.28268
Epoch 1294/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4231 - val_loss: 1.2872 - val_accuracy: 0.4167

Epoch 01294: val_loss did not improve from 1.28268
Epoch 1295/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4260 - val_loss: 1.2844 - val_accuracy: 0.4223

Epoch 01295: val_loss did not improve from 1.28268
Epoch 1296/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4270 - val_loss: 1.2860 - val_accuracy: 0.4127

Epoch 01296: val_loss did not improve from 1.28268
Epoch 1297/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4282 - val_loss: 1.2837 - val_accuracy: 0.4207

Epoch 01297: val_loss did not improve from 1.28268
Epoch 1298/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4259 - val_loss: 1.2871 - val_accuracy: 0.4207

Epoch 01298: val_loss did not improve from 1.28268
Epoch 1299/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4302 - val_loss: 1.2915 - val_accuracy: 0.4112

Epoch 01299: val_loss did not improve from 1.28268
Epoch 1300/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4234 - val_loss: 1.2883 - val_accuracy: 0.4143

Epoch 01300: val_loss did not improve from 1.28268
Epoch 1301/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4291 - val_loss: 1.2859 - val_accuracy: 0.4127

Epoch 01301: val_loss did not improve from 1.28268
Epoch 1302/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4243 - val_loss: 1.2928 - val_accuracy: 0.4112

Epoch 01302: val_loss did not improve from 1.28268
Epoch 1303/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4291 - val_loss: 1.2835 - val_accuracy: 0.4167

Epoch 01303: val_loss did not improve from 1.28268
Epoch 1304/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4232 - val_loss: 1.2948 - val_accuracy: 0.4127

Epoch 01304: val_loss did not improve from 1.28268
Epoch 1305/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4280 - val_loss: 1.2943 - val_accuracy: 0.4040

Epoch 01305: val_loss did not improve from 1.28268
Epoch 1306/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4265 - val_loss: 1.2867 - val_accuracy: 0.4143

Epoch 01306: val_loss did not improve from 1.28268
Epoch 1307/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4267 - val_loss: 1.2845 - val_accuracy: 0.4223

Epoch 01307: val_loss did not improve from 1.28268
Epoch 1308/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4220 - val_loss: 1.2882 - val_accuracy: 0.4183

Epoch 01308: val_loss did not improve from 1.28268
Epoch 1309/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4286 - val_loss: 1.2996 - val_accuracy: 0.4048

Epoch 01309: val_loss did not improve from 1.28268
Epoch 1310/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4233 - val_loss: 1.2858 - val_accuracy: 0.4159

Epoch 01310: val_loss did not improve from 1.28268
Epoch 1311/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4180 - val_loss: 1.2859 - val_accuracy: 0.4231

Epoch 01311: val_loss did not improve from 1.28268
Epoch 1312/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4253 - val_loss: 1.2919 - val_accuracy: 0.4064

Epoch 01312: val_loss did not improve from 1.28268
Epoch 1313/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4269 - val_loss: 1.2854 - val_accuracy: 0.4231

Epoch 01313: val_loss did not improve from 1.28268
Epoch 1314/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4295 - val_loss: 1.2851 - val_accuracy: 0.4151

Epoch 01314: val_loss did not improve from 1.28268
Epoch 1315/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4296 - val_loss: 1.2884 - val_accuracy: 0.4135

Epoch 01315: val_loss did not improve from 1.28268
Epoch 1316/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4292 - val_loss: 1.2861 - val_accuracy: 0.4143

Epoch 01316: val_loss did not improve from 1.28268
Epoch 1317/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4281 - val_loss: 1.2880 - val_accuracy: 0.4143

Epoch 01317: val_loss did not improve from 1.28268
Epoch 1318/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4247 - val_loss: 1.2924 - val_accuracy: 0.4088

Epoch 01318: val_loss did not improve from 1.28268
Epoch 1319/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4221 - val_loss: 1.2892 - val_accuracy: 0.4223

Epoch 01319: val_loss did not improve from 1.28268
Epoch 1320/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4233 - val_loss: 1.2860 - val_accuracy: 0.4127

Epoch 01320: val_loss did not improve from 1.28268
Epoch 1321/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4302 - val_loss: 1.2906 - val_accuracy: 0.4104

Epoch 01321: val_loss did not improve from 1.28268
Epoch 1322/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4252 - val_loss: 1.2868 - val_accuracy: 0.4159

Epoch 01322: val_loss did not improve from 1.28268
Epoch 1323/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4291 - val_loss: 1.2835 - val_accuracy: 0.4191

Epoch 01323: val_loss did not improve from 1.28268
Epoch 1324/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4202 - val_loss: 1.2933 - val_accuracy: 0.3992

Epoch 01324: val_loss did not improve from 1.28268
Epoch 1325/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4246 - val_loss: 1.2892 - val_accuracy: 0.4104

Epoch 01325: val_loss did not improve from 1.28268
Epoch 1326/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4297 - val_loss: 1.2886 - val_accuracy: 0.4151

Epoch 01326: val_loss did not improve from 1.28268
Epoch 1327/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4276 - val_loss: 1.2876 - val_accuracy: 0.4167

Epoch 01327: val_loss did not improve from 1.28268
Epoch 1328/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4279 - val_loss: 1.2867 - val_accuracy: 0.4135

Epoch 01328: val_loss did not improve from 1.28268
Epoch 1329/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4291 - val_loss: 1.2839 - val_accuracy: 0.4199

Epoch 01329: val_loss did not improve from 1.28268
Epoch 1330/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4225 - val_loss: 1.2849 - val_accuracy: 0.4104

Epoch 01330: val_loss did not improve from 1.28268
Epoch 1331/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4259 - val_loss: 1.2848 - val_accuracy: 0.4167

Epoch 01331: val_loss did not improve from 1.28268
Epoch 1332/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4260 - val_loss: 1.2914 - val_accuracy: 0.4112

Epoch 01332: val_loss did not improve from 1.28268
Epoch 1333/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4273 - val_loss: 1.2900 - val_accuracy: 0.4127

Epoch 01333: val_loss did not improve from 1.28268
Epoch 1334/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4283 - val_loss: 1.2848 - val_accuracy: 0.4199

Epoch 01334: val_loss did not improve from 1.28268
Epoch 1335/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4298 - val_loss: 1.2928 - val_accuracy: 0.4127

Epoch 01335: val_loss did not improve from 1.28268
Epoch 1336/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4311 - val_loss: 1.2907 - val_accuracy: 0.4088

Epoch 01336: val_loss did not improve from 1.28268
Epoch 1337/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4268 - val_loss: 1.2879 - val_accuracy: 0.4120

Epoch 01337: val_loss did not improve from 1.28268
Epoch 1338/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4253 - val_loss: 1.2883 - val_accuracy: 0.4127

Epoch 01338: val_loss did not improve from 1.28268
Epoch 1339/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4232 - val_loss: 1.2850 - val_accuracy: 0.4215

Epoch 01339: val_loss did not improve from 1.28268
Epoch 1340/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4241 - val_loss: 1.2939 - val_accuracy: 0.4127

Epoch 01340: val_loss did not improve from 1.28268
Epoch 1341/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4267 - val_loss: 1.2897 - val_accuracy: 0.4143

Epoch 01341: val_loss did not improve from 1.28268
Epoch 1342/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4298 - val_loss: 1.2852 - val_accuracy: 0.4143

Epoch 01342: val_loss did not improve from 1.28268
Epoch 1343/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4278 - val_loss: 1.2848 - val_accuracy: 0.4223

Epoch 01343: val_loss did not improve from 1.28268
Epoch 1344/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4257 - val_loss: 1.2840 - val_accuracy: 0.4159

Epoch 01344: val_loss did not improve from 1.28268
Epoch 1345/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4255 - val_loss: 1.2881 - val_accuracy: 0.4207

Epoch 01345: val_loss did not improve from 1.28268
Epoch 1346/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4294 - val_loss: 1.2897 - val_accuracy: 0.4151

Epoch 01346: val_loss did not improve from 1.28268
Epoch 1347/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4271 - val_loss: 1.2879 - val_accuracy: 0.4151

Epoch 01347: val_loss did not improve from 1.28268
Epoch 1348/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4260 - val_loss: 1.2873 - val_accuracy: 0.4183

Epoch 01348: val_loss did not improve from 1.28268
Epoch 1349/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4289 - val_loss: 1.2865 - val_accuracy: 0.4255

Epoch 01349: val_loss did not improve from 1.28268
Epoch 1350/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4320 - val_loss: 1.2876 - val_accuracy: 0.4271

Epoch 01350: val_loss did not improve from 1.28268
Epoch 1351/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4266 - val_loss: 1.2922 - val_accuracy: 0.4056

Epoch 01351: val_loss did not improve from 1.28268
Epoch 1352/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4259 - val_loss: 1.2860 - val_accuracy: 0.4199

Epoch 01352: val_loss did not improve from 1.28268
Epoch 1353/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4305 - val_loss: 1.2900 - val_accuracy: 0.4159

Epoch 01353: val_loss did not improve from 1.28268
Epoch 1354/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4269 - val_loss: 1.2834 - val_accuracy: 0.4223

Epoch 01354: val_loss did not improve from 1.28268
Epoch 1355/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4275 - val_loss: 1.2858 - val_accuracy: 0.4104

Epoch 01355: val_loss did not improve from 1.28268
Epoch 1356/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4253 - val_loss: 1.2859 - val_accuracy: 0.4223

Epoch 01356: val_loss did not improve from 1.28268
Epoch 1357/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4274 - val_loss: 1.2908 - val_accuracy: 0.4159

Epoch 01357: val_loss did not improve from 1.28268
Epoch 1358/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4273 - val_loss: 1.2854 - val_accuracy: 0.4096

Epoch 01358: val_loss did not improve from 1.28268
Epoch 1359/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4252 - val_loss: 1.2873 - val_accuracy: 0.4056

Epoch 01359: val_loss did not improve from 1.28268
Epoch 1360/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4272 - val_loss: 1.2820 - val_accuracy: 0.4151

Epoch 01360: val_loss improved from 1.28268 to 1.28198, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1361/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4254 - val_loss: 1.2918 - val_accuracy: 0.4151

Epoch 01361: val_loss did not improve from 1.28198
Epoch 1362/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4275 - val_loss: 1.2844 - val_accuracy: 0.4183

Epoch 01362: val_loss did not improve from 1.28198
Epoch 1363/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4278 - val_loss: 1.2875 - val_accuracy: 0.4223

Epoch 01363: val_loss did not improve from 1.28198
Epoch 1364/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4233 - val_loss: 1.2874 - val_accuracy: 0.4215

Epoch 01364: val_loss did not improve from 1.28198
Epoch 1365/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4258 - val_loss: 1.2916 - val_accuracy: 0.4104

Epoch 01365: val_loss did not improve from 1.28198
Epoch 1366/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4287 - val_loss: 1.2830 - val_accuracy: 0.4143

Epoch 01366: val_loss did not improve from 1.28198
Epoch 1367/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4252 - val_loss: 1.2888 - val_accuracy: 0.4048

Epoch 01367: val_loss did not improve from 1.28198
Epoch 1368/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4261 - val_loss: 1.2890 - val_accuracy: 0.4104

Epoch 01368: val_loss did not improve from 1.28198
Epoch 1369/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4236 - val_loss: 1.2837 - val_accuracy: 0.4143

Epoch 01369: val_loss did not improve from 1.28198
Epoch 1370/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4257 - val_loss: 1.2856 - val_accuracy: 0.4112

Epoch 01370: val_loss did not improve from 1.28198
Epoch 1371/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4298 - val_loss: 1.2829 - val_accuracy: 0.4183

Epoch 01371: val_loss did not improve from 1.28198
Epoch 1372/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4280 - val_loss: 1.2876 - val_accuracy: 0.4159

Epoch 01372: val_loss did not improve from 1.28198
Epoch 1373/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4271 - val_loss: 1.2832 - val_accuracy: 0.4215

Epoch 01373: val_loss did not improve from 1.28198
Epoch 1374/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4266 - val_loss: 1.2807 - val_accuracy: 0.4223

Epoch 01374: val_loss improved from 1.28198 to 1.28074, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1375/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4285 - val_loss: 1.2843 - val_accuracy: 0.4135

Epoch 01375: val_loss did not improve from 1.28074
Epoch 1376/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4270 - val_loss: 1.2890 - val_accuracy: 0.4088

Epoch 01376: val_loss did not improve from 1.28074
Epoch 1377/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4252 - val_loss: 1.2856 - val_accuracy: 0.4207

Epoch 01377: val_loss did not improve from 1.28074
Epoch 1378/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4221 - val_loss: 1.2883 - val_accuracy: 0.4024

Epoch 01378: val_loss did not improve from 1.28074
Epoch 1379/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4291 - val_loss: 1.2908 - val_accuracy: 0.4056

Epoch 01379: val_loss did not improve from 1.28074
Epoch 1380/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4236 - val_loss: 1.2841 - val_accuracy: 0.4143

Epoch 01380: val_loss did not improve from 1.28074
Epoch 1381/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4281 - val_loss: 1.2871 - val_accuracy: 0.4183

Epoch 01381: val_loss did not improve from 1.28074
Epoch 1382/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4278 - val_loss: 1.2838 - val_accuracy: 0.4120

Epoch 01382: val_loss did not improve from 1.28074
Epoch 1383/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4268 - val_loss: 1.2868 - val_accuracy: 0.4151

Epoch 01383: val_loss did not improve from 1.28074
Epoch 1384/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4301 - val_loss: 1.2856 - val_accuracy: 0.4183

Epoch 01384: val_loss did not improve from 1.28074
Epoch 1385/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4322 - val_loss: 1.2830 - val_accuracy: 0.4143

Epoch 01385: val_loss did not improve from 1.28074
Epoch 1386/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4291 - val_loss: 1.2828 - val_accuracy: 0.4143

Epoch 01386: val_loss did not improve from 1.28074
Epoch 1387/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4221 - val_loss: 1.2829 - val_accuracy: 0.4151

Epoch 01387: val_loss did not improve from 1.28074
Epoch 1388/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4210 - val_loss: 1.2917 - val_accuracy: 0.4088

Epoch 01388: val_loss did not improve from 1.28074
Epoch 1389/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4307 - val_loss: 1.2851 - val_accuracy: 0.4279

Epoch 01389: val_loss did not improve from 1.28074
Epoch 1390/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4296 - val_loss: 1.2945 - val_accuracy: 0.4096

Epoch 01390: val_loss did not improve from 1.28074
Epoch 1391/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4278 - val_loss: 1.2831 - val_accuracy: 0.4255

Epoch 01391: val_loss did not improve from 1.28074
Epoch 1392/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4282 - val_loss: 1.2824 - val_accuracy: 0.4215

Epoch 01392: val_loss did not improve from 1.28074
Epoch 1393/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4271 - val_loss: 1.2889 - val_accuracy: 0.4088

Epoch 01393: val_loss did not improve from 1.28074
Epoch 1394/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4282 - val_loss: 1.2822 - val_accuracy: 0.4175

Epoch 01394: val_loss did not improve from 1.28074
Epoch 1395/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4249 - val_loss: 1.2817 - val_accuracy: 0.4135

Epoch 01395: val_loss did not improve from 1.28074
Epoch 1396/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4311 - val_loss: 1.2814 - val_accuracy: 0.4127

Epoch 01396: val_loss did not improve from 1.28074
Epoch 1397/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4254 - val_loss: 1.2906 - val_accuracy: 0.4048

Epoch 01397: val_loss did not improve from 1.28074
Epoch 1398/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4267 - val_loss: 1.2826 - val_accuracy: 0.4183

Epoch 01398: val_loss did not improve from 1.28074
Epoch 1399/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4306 - val_loss: 1.2964 - val_accuracy: 0.3976

Epoch 01399: val_loss did not improve from 1.28074
Epoch 1400/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4205 - val_loss: 1.2883 - val_accuracy: 0.4104

Epoch 01400: val_loss did not improve from 1.28074
Epoch 1401/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4174 - val_loss: 1.2807 - val_accuracy: 0.4175

Epoch 01401: val_loss improved from 1.28074 to 1.28070, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1402/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4256 - val_loss: 1.2806 - val_accuracy: 0.4175

Epoch 01402: val_loss improved from 1.28070 to 1.28060, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1403/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4271 - val_loss: 1.2876 - val_accuracy: 0.4175

Epoch 01403: val_loss did not improve from 1.28060
Epoch 1404/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4236 - val_loss: 1.2939 - val_accuracy: 0.4048

Epoch 01404: val_loss did not improve from 1.28060
Epoch 1405/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4260 - val_loss: 1.2819 - val_accuracy: 0.4199

Epoch 01405: val_loss did not improve from 1.28060
Epoch 1406/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4247 - val_loss: 1.2844 - val_accuracy: 0.4239

Epoch 01406: val_loss did not improve from 1.28060
Epoch 1407/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4272 - val_loss: 1.2833 - val_accuracy: 0.4175

Epoch 01407: val_loss did not improve from 1.28060
Epoch 1408/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4294 - val_loss: 1.2875 - val_accuracy: 0.4247

Epoch 01408: val_loss did not improve from 1.28060
Epoch 1409/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4276 - val_loss: 1.2954 - val_accuracy: 0.4191

Epoch 01409: val_loss did not improve from 1.28060
Epoch 1410/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4266 - val_loss: 1.2827 - val_accuracy: 0.4207

Epoch 01410: val_loss did not improve from 1.28060
Epoch 1411/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4285 - val_loss: 1.2843 - val_accuracy: 0.4191

Epoch 01411: val_loss did not improve from 1.28060
Epoch 1412/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4275 - val_loss: 1.2878 - val_accuracy: 0.4175

Epoch 01412: val_loss did not improve from 1.28060
Epoch 1413/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4337 - val_loss: 1.2888 - val_accuracy: 0.4143

Epoch 01413: val_loss did not improve from 1.28060
Epoch 1414/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4287 - val_loss: 1.2857 - val_accuracy: 0.4191

Epoch 01414: val_loss did not improve from 1.28060
Epoch 1415/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4260 - val_loss: 1.2862 - val_accuracy: 0.4088

Epoch 01415: val_loss did not improve from 1.28060
Epoch 1416/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4283 - val_loss: 1.2843 - val_accuracy: 0.4143

Epoch 01416: val_loss did not improve from 1.28060
Epoch 1417/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4264 - val_loss: 1.2870 - val_accuracy: 0.4072

Epoch 01417: val_loss did not improve from 1.28060
Epoch 1418/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4274 - val_loss: 1.2829 - val_accuracy: 0.4143

Epoch 01418: val_loss did not improve from 1.28060
Epoch 1419/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4262 - val_loss: 1.2852 - val_accuracy: 0.4143

Epoch 01419: val_loss did not improve from 1.28060
Epoch 1420/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4287 - val_loss: 1.2829 - val_accuracy: 0.4175

Epoch 01420: val_loss did not improve from 1.28060
Epoch 1421/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4289 - val_loss: 1.2861 - val_accuracy: 0.4183

Epoch 01421: val_loss did not improve from 1.28060
Epoch 1422/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4297 - val_loss: 1.2841 - val_accuracy: 0.4159

Epoch 01422: val_loss did not improve from 1.28060
Epoch 1423/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4302 - val_loss: 1.2875 - val_accuracy: 0.4135

Epoch 01423: val_loss did not improve from 1.28060
Epoch 1424/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4280 - val_loss: 1.2847 - val_accuracy: 0.4167

Epoch 01424: val_loss did not improve from 1.28060
Epoch 1425/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4194 - val_loss: 1.2878 - val_accuracy: 0.4096

Epoch 01425: val_loss did not improve from 1.28060
Epoch 1426/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4225 - val_loss: 1.2899 - val_accuracy: 0.4135

Epoch 01426: val_loss did not improve from 1.28060
Epoch 1427/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4283 - val_loss: 1.2907 - val_accuracy: 0.4159

Epoch 01427: val_loss did not improve from 1.28060
Epoch 1428/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4246 - val_loss: 1.2894 - val_accuracy: 0.4135

Epoch 01428: val_loss did not improve from 1.28060
Epoch 1429/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4283 - val_loss: 1.2869 - val_accuracy: 0.4096

Epoch 01429: val_loss did not improve from 1.28060
Epoch 1430/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4251 - val_loss: 1.2865 - val_accuracy: 0.4096

Epoch 01430: val_loss did not improve from 1.28060
Epoch 1431/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4285 - val_loss: 1.2857 - val_accuracy: 0.4135

Epoch 01431: val_loss did not improve from 1.28060
Epoch 1432/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4278 - val_loss: 1.2847 - val_accuracy: 0.4127

Epoch 01432: val_loss did not improve from 1.28060
Epoch 1433/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4297 - val_loss: 1.2928 - val_accuracy: 0.4008

Epoch 01433: val_loss did not improve from 1.28060
Epoch 1434/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4291 - val_loss: 1.2821 - val_accuracy: 0.4167

Epoch 01434: val_loss did not improve from 1.28060
Epoch 1435/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4300 - val_loss: 1.2829 - val_accuracy: 0.4175

Epoch 01435: val_loss did not improve from 1.28060
Epoch 1436/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4252 - val_loss: 1.2844 - val_accuracy: 0.4088

Epoch 01436: val_loss did not improve from 1.28060
Epoch 1437/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4307 - val_loss: 1.2832 - val_accuracy: 0.4056

Epoch 01437: val_loss did not improve from 1.28060
Epoch 1438/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4239 - val_loss: 1.2851 - val_accuracy: 0.4151

Epoch 01438: val_loss did not improve from 1.28060
Epoch 1439/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4288 - val_loss: 1.2816 - val_accuracy: 0.4151

Epoch 01439: val_loss did not improve from 1.28060
Epoch 1440/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4276 - val_loss: 1.2845 - val_accuracy: 0.4191

Epoch 01440: val_loss did not improve from 1.28060
Epoch 1441/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4272 - val_loss: 1.2827 - val_accuracy: 0.4207

Epoch 01441: val_loss did not improve from 1.28060
Epoch 1442/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4296 - val_loss: 1.2831 - val_accuracy: 0.4112

Epoch 01442: val_loss did not improve from 1.28060
Epoch 1443/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4296 - val_loss: 1.2845 - val_accuracy: 0.4120

Epoch 01443: val_loss did not improve from 1.28060
Epoch 1444/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4267 - val_loss: 1.2882 - val_accuracy: 0.4056

Epoch 01444: val_loss did not improve from 1.28060
Epoch 1445/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4305 - val_loss: 1.2853 - val_accuracy: 0.4120

Epoch 01445: val_loss did not improve from 1.28060
Epoch 1446/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4273 - val_loss: 1.2852 - val_accuracy: 0.4080

Epoch 01446: val_loss did not improve from 1.28060
Epoch 1447/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4256 - val_loss: 1.2855 - val_accuracy: 0.4159

Epoch 01447: val_loss did not improve from 1.28060
Epoch 1448/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4282 - val_loss: 1.2859 - val_accuracy: 0.4191

Epoch 01448: val_loss did not improve from 1.28060
Epoch 1449/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4297 - val_loss: 1.2900 - val_accuracy: 0.4183

Epoch 01449: val_loss did not improve from 1.28060
Epoch 1450/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4242 - val_loss: 1.2819 - val_accuracy: 0.4080

Epoch 01450: val_loss did not improve from 1.28060
Epoch 1451/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4276 - val_loss: 1.2853 - val_accuracy: 0.4135

Epoch 01451: val_loss did not improve from 1.28060
Epoch 1452/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4252 - val_loss: 1.2838 - val_accuracy: 0.4151

Epoch 01452: val_loss did not improve from 1.28060
Epoch 1453/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4290 - val_loss: 1.2877 - val_accuracy: 0.4135

Epoch 01453: val_loss did not improve from 1.28060
Epoch 1454/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4299 - val_loss: 1.2896 - val_accuracy: 0.4143

Epoch 01454: val_loss did not improve from 1.28060
Epoch 1455/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4262 - val_loss: 1.2822 - val_accuracy: 0.4223

Epoch 01455: val_loss did not improve from 1.28060
Epoch 1456/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4203 - val_loss: 1.2846 - val_accuracy: 0.4112

Epoch 01456: val_loss did not improve from 1.28060
Epoch 1457/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4278 - val_loss: 1.2836 - val_accuracy: 0.4207

Epoch 01457: val_loss did not improve from 1.28060
Epoch 1458/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4275 - val_loss: 1.2842 - val_accuracy: 0.4191

Epoch 01458: val_loss did not improve from 1.28060
Epoch 1459/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4277 - val_loss: 1.2837 - val_accuracy: 0.4223

Epoch 01459: val_loss did not improve from 1.28060
Epoch 1460/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4312 - val_loss: 1.2826 - val_accuracy: 0.4175

Epoch 01460: val_loss did not improve from 1.28060
Epoch 1461/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4257 - val_loss: 1.2816 - val_accuracy: 0.4064

Epoch 01461: val_loss did not improve from 1.28060
Epoch 1462/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4259 - val_loss: 1.2846 - val_accuracy: 0.4127

Epoch 01462: val_loss did not improve from 1.28060
Epoch 1463/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4317 - val_loss: 1.2819 - val_accuracy: 0.4191

Epoch 01463: val_loss did not improve from 1.28060
Epoch 1464/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4293 - val_loss: 1.2912 - val_accuracy: 0.4112

Epoch 01464: val_loss did not improve from 1.28060
Epoch 1465/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4275 - val_loss: 1.2841 - val_accuracy: 0.4135

Epoch 01465: val_loss did not improve from 1.28060
Epoch 1466/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4282 - val_loss: 1.2806 - val_accuracy: 0.4191

Epoch 01466: val_loss did not improve from 1.28060
Epoch 1467/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4297 - val_loss: 1.2819 - val_accuracy: 0.4096

Epoch 01467: val_loss did not improve from 1.28060
Epoch 1468/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4228 - val_loss: 1.2836 - val_accuracy: 0.4159

Epoch 01468: val_loss did not improve from 1.28060
Epoch 1469/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4266 - val_loss: 1.2830 - val_accuracy: 0.4151

Epoch 01469: val_loss did not improve from 1.28060
Epoch 1470/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4292 - val_loss: 1.2869 - val_accuracy: 0.4127

Epoch 01470: val_loss did not improve from 1.28060
Epoch 1471/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4252 - val_loss: 1.2889 - val_accuracy: 0.4104

Epoch 01471: val_loss did not improve from 1.28060
Epoch 1472/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4292 - val_loss: 1.2806 - val_accuracy: 0.4199

Epoch 01472: val_loss did not improve from 1.28060
Epoch 1473/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4254 - val_loss: 1.2813 - val_accuracy: 0.4207

Epoch 01473: val_loss did not improve from 1.28060
Epoch 1474/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4294 - val_loss: 1.2819 - val_accuracy: 0.4143

Epoch 01474: val_loss did not improve from 1.28060
Epoch 1475/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4296 - val_loss: 1.2891 - val_accuracy: 0.4112

Epoch 01475: val_loss did not improve from 1.28060
Epoch 1476/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4302 - val_loss: 1.2834 - val_accuracy: 0.4191

Epoch 01476: val_loss did not improve from 1.28060
Epoch 1477/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4303 - val_loss: 1.2853 - val_accuracy: 0.4231

Epoch 01477: val_loss did not improve from 1.28060
Epoch 1478/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4254 - val_loss: 1.2796 - val_accuracy: 0.4231

Epoch 01478: val_loss improved from 1.28060 to 1.27958, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1479/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4278 - val_loss: 1.2817 - val_accuracy: 0.4207

Epoch 01479: val_loss did not improve from 1.27958
Epoch 1480/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4277 - val_loss: 1.2852 - val_accuracy: 0.4127

Epoch 01480: val_loss did not improve from 1.27958
Epoch 1481/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4325 - val_loss: 1.2845 - val_accuracy: 0.4159

Epoch 01481: val_loss did not improve from 1.27958
Epoch 1482/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4293 - val_loss: 1.2836 - val_accuracy: 0.4215

Epoch 01482: val_loss did not improve from 1.27958
Epoch 1483/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4274 - val_loss: 1.2822 - val_accuracy: 0.4215

Epoch 01483: val_loss did not improve from 1.27958
Epoch 1484/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4277 - val_loss: 1.2854 - val_accuracy: 0.4167

Epoch 01484: val_loss did not improve from 1.27958
Epoch 1485/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4236 - val_loss: 1.2884 - val_accuracy: 0.4127

Epoch 01485: val_loss did not improve from 1.27958
Epoch 1486/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4291 - val_loss: 1.2836 - val_accuracy: 0.4151

Epoch 01486: val_loss did not improve from 1.27958
Epoch 1487/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4316 - val_loss: 1.2841 - val_accuracy: 0.4175

Epoch 01487: val_loss did not improve from 1.27958
Epoch 1488/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4265 - val_loss: 1.2856 - val_accuracy: 0.4175

Epoch 01488: val_loss did not improve from 1.27958
Epoch 1489/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4314 - val_loss: 1.2896 - val_accuracy: 0.4072

Epoch 01489: val_loss did not improve from 1.27958
Epoch 1490/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4213 - val_loss: 1.2847 - val_accuracy: 0.4135

Epoch 01490: val_loss did not improve from 1.27958
Epoch 1491/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4295 - val_loss: 1.2850 - val_accuracy: 0.4127

Epoch 01491: val_loss did not improve from 1.27958
Epoch 1492/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4296 - val_loss: 1.2818 - val_accuracy: 0.4183

Epoch 01492: val_loss did not improve from 1.27958
Epoch 1493/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4270 - val_loss: 1.2857 - val_accuracy: 0.4127

Epoch 01493: val_loss did not improve from 1.27958
Epoch 1494/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4319 - val_loss: 1.2808 - val_accuracy: 0.4159

Epoch 01494: val_loss did not improve from 1.27958
Epoch 1495/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4260 - val_loss: 1.2844 - val_accuracy: 0.4088

Epoch 01495: val_loss did not improve from 1.27958
Epoch 1496/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4291 - val_loss: 1.2811 - val_accuracy: 0.4120

Epoch 01496: val_loss did not improve from 1.27958
Epoch 1497/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4284 - val_loss: 1.2837 - val_accuracy: 0.4191

Epoch 01497: val_loss did not improve from 1.27958
Epoch 1498/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4265 - val_loss: 1.2885 - val_accuracy: 0.4167

Epoch 01498: val_loss did not improve from 1.27958
Epoch 1499/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4282 - val_loss: 1.2947 - val_accuracy: 0.4008

Epoch 01499: val_loss did not improve from 1.27958
Epoch 1500/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4222 - val_loss: 1.2849 - val_accuracy: 0.4112

Epoch 01500: val_loss did not improve from 1.27958
Epoch 1501/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4244 - val_loss: 1.2830 - val_accuracy: 0.4191

Epoch 01501: val_loss did not improve from 1.27958
Epoch 1502/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4291 - val_loss: 1.2831 - val_accuracy: 0.4048

Epoch 01502: val_loss did not improve from 1.27958
Epoch 1503/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4297 - val_loss: 1.2856 - val_accuracy: 0.4080

Epoch 01503: val_loss did not improve from 1.27958
Epoch 1504/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4296 - val_loss: 1.2826 - val_accuracy: 0.4175

Epoch 01504: val_loss did not improve from 1.27958
Epoch 1505/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4291 - val_loss: 1.2798 - val_accuracy: 0.4127

Epoch 01505: val_loss did not improve from 1.27958
Epoch 1506/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4314 - val_loss: 1.2828 - val_accuracy: 0.4167

Epoch 01506: val_loss did not improve from 1.27958
Epoch 1507/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4304 - val_loss: 1.2864 - val_accuracy: 0.4096

Epoch 01507: val_loss did not improve from 1.27958
Epoch 1508/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4249 - val_loss: 1.2828 - val_accuracy: 0.4080

Epoch 01508: val_loss did not improve from 1.27958
Epoch 1509/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4297 - val_loss: 1.2918 - val_accuracy: 0.4040

Epoch 01509: val_loss did not improve from 1.27958
Epoch 1510/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4281 - val_loss: 1.2941 - val_accuracy: 0.4096

Epoch 01510: val_loss did not improve from 1.27958
Epoch 1511/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4269 - val_loss: 1.2844 - val_accuracy: 0.4120

Epoch 01511: val_loss did not improve from 1.27958
Epoch 1512/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4289 - val_loss: 1.2895 - val_accuracy: 0.4088

Epoch 01512: val_loss did not improve from 1.27958
Epoch 1513/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4273 - val_loss: 1.2844 - val_accuracy: 0.4223

Epoch 01513: val_loss did not improve from 1.27958
Epoch 1514/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4294 - val_loss: 1.2873 - val_accuracy: 0.4167

Epoch 01514: val_loss did not improve from 1.27958
Epoch 1515/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4326 - val_loss: 1.2872 - val_accuracy: 0.4151

Epoch 01515: val_loss did not improve from 1.27958
Epoch 1516/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4288 - val_loss: 1.2892 - val_accuracy: 0.4088

Epoch 01516: val_loss did not improve from 1.27958
Epoch 1517/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4313 - val_loss: 1.2865 - val_accuracy: 0.4175

Epoch 01517: val_loss did not improve from 1.27958
Epoch 1518/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4286 - val_loss: 1.2851 - val_accuracy: 0.4183

Epoch 01518: val_loss did not improve from 1.27958
Epoch 1519/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4258 - val_loss: 1.2824 - val_accuracy: 0.4127

Epoch 01519: val_loss did not improve from 1.27958
Epoch 1520/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4275 - val_loss: 1.2827 - val_accuracy: 0.4056

Epoch 01520: val_loss did not improve from 1.27958
Epoch 1521/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4306 - val_loss: 1.2872 - val_accuracy: 0.4151

Epoch 01521: val_loss did not improve from 1.27958
Epoch 1522/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4330 - val_loss: 1.2818 - val_accuracy: 0.4207

Epoch 01522: val_loss did not improve from 1.27958
Epoch 1523/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4300 - val_loss: 1.2840 - val_accuracy: 0.4159

Epoch 01523: val_loss did not improve from 1.27958
Epoch 1524/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4326 - val_loss: 1.2848 - val_accuracy: 0.4151

Epoch 01524: val_loss did not improve from 1.27958
Epoch 1525/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4288 - val_loss: 1.2865 - val_accuracy: 0.4207

Epoch 01525: val_loss did not improve from 1.27958
Epoch 1526/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4291 - val_loss: 1.2999 - val_accuracy: 0.4096

Epoch 01526: val_loss did not improve from 1.27958
Epoch 1527/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4249 - val_loss: 1.2846 - val_accuracy: 0.4135

Epoch 01527: val_loss did not improve from 1.27958
Epoch 1528/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4264 - val_loss: 1.2852 - val_accuracy: 0.4143

Epoch 01528: val_loss did not improve from 1.27958
Epoch 1529/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4254 - val_loss: 1.2845 - val_accuracy: 0.4167

Epoch 01529: val_loss did not improve from 1.27958
Epoch 1530/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4327 - val_loss: 1.2823 - val_accuracy: 0.4175

Epoch 01530: val_loss did not improve from 1.27958
Epoch 1531/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4298 - val_loss: 1.2833 - val_accuracy: 0.4096

Epoch 01531: val_loss did not improve from 1.27958
Epoch 1532/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4302 - val_loss: 1.2808 - val_accuracy: 0.4191

Epoch 01532: val_loss did not improve from 1.27958
Epoch 1533/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4261 - val_loss: 1.2834 - val_accuracy: 0.4104

Epoch 01533: val_loss did not improve from 1.27958
Epoch 1534/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4253 - val_loss: 1.2860 - val_accuracy: 0.4175

Epoch 01534: val_loss did not improve from 1.27958
Epoch 1535/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4287 - val_loss: 1.2854 - val_accuracy: 0.4175

Epoch 01535: val_loss did not improve from 1.27958
Epoch 1536/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4301 - val_loss: 1.2833 - val_accuracy: 0.4167

Epoch 01536: val_loss did not improve from 1.27958
Epoch 1537/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4274 - val_loss: 1.2817 - val_accuracy: 0.4072

Epoch 01537: val_loss did not improve from 1.27958
Epoch 1538/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4266 - val_loss: 1.2941 - val_accuracy: 0.3936

Epoch 01538: val_loss did not improve from 1.27958
Epoch 1539/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4219 - val_loss: 1.2872 - val_accuracy: 0.4080

Epoch 01539: val_loss did not improve from 1.27958
Epoch 1540/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4272 - val_loss: 1.2814 - val_accuracy: 0.4135

Epoch 01540: val_loss did not improve from 1.27958
Epoch 1541/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4298 - val_loss: 1.2841 - val_accuracy: 0.4207

Epoch 01541: val_loss did not improve from 1.27958
Epoch 1542/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4349 - val_loss: 1.2899 - val_accuracy: 0.4024

Epoch 01542: val_loss did not improve from 1.27958
Epoch 1543/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4274 - val_loss: 1.2837 - val_accuracy: 0.4040

Epoch 01543: val_loss did not improve from 1.27958
Epoch 1544/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4260 - val_loss: 1.2837 - val_accuracy: 0.4135

Epoch 01544: val_loss did not improve from 1.27958
Epoch 1545/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4266 - val_loss: 1.2848 - val_accuracy: 0.4120

Epoch 01545: val_loss did not improve from 1.27958
Epoch 1546/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4298 - val_loss: 1.2832 - val_accuracy: 0.4167

Epoch 01546: val_loss did not improve from 1.27958
Epoch 1547/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4295 - val_loss: 1.2875 - val_accuracy: 0.4127

Epoch 01547: val_loss did not improve from 1.27958
Epoch 1548/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4292 - val_loss: 1.2800 - val_accuracy: 0.4151

Epoch 01548: val_loss did not improve from 1.27958
Epoch 1549/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4311 - val_loss: 1.2820 - val_accuracy: 0.4215

Epoch 01549: val_loss did not improve from 1.27958
Epoch 1550/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4313 - val_loss: 1.2813 - val_accuracy: 0.4167

Epoch 01550: val_loss did not improve from 1.27958
Epoch 1551/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4314 - val_loss: 1.2842 - val_accuracy: 0.4199

Epoch 01551: val_loss did not improve from 1.27958
Epoch 1552/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4316 - val_loss: 1.2852 - val_accuracy: 0.4104

Epoch 01552: val_loss did not improve from 1.27958
Epoch 1553/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4273 - val_loss: 1.2827 - val_accuracy: 0.4120

Epoch 01553: val_loss did not improve from 1.27958
Epoch 1554/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4321 - val_loss: 1.2847 - val_accuracy: 0.4088

Epoch 01554: val_loss did not improve from 1.27958
Epoch 1555/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4318 - val_loss: 1.2869 - val_accuracy: 0.4064

Epoch 01555: val_loss did not improve from 1.27958
Epoch 1556/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4310 - val_loss: 1.2782 - val_accuracy: 0.4247

Epoch 01556: val_loss improved from 1.27958 to 1.27818, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1557/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4288 - val_loss: 1.2856 - val_accuracy: 0.4199

Epoch 01557: val_loss did not improve from 1.27818
Epoch 1558/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4293 - val_loss: 1.2818 - val_accuracy: 0.4175

Epoch 01558: val_loss did not improve from 1.27818
Epoch 1559/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4247 - val_loss: 1.2841 - val_accuracy: 0.4143

Epoch 01559: val_loss did not improve from 1.27818
Epoch 1560/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4213 - val_loss: 1.2813 - val_accuracy: 0.4127

Epoch 01560: val_loss did not improve from 1.27818
Epoch 1561/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4271 - val_loss: 1.2806 - val_accuracy: 0.4112

Epoch 01561: val_loss did not improve from 1.27818
Epoch 1562/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4314 - val_loss: 1.2820 - val_accuracy: 0.4191

Epoch 01562: val_loss did not improve from 1.27818
Epoch 1563/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4270 - val_loss: 1.2831 - val_accuracy: 0.4151

Epoch 01563: val_loss did not improve from 1.27818
Epoch 1564/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4268 - val_loss: 1.2833 - val_accuracy: 0.4072

Epoch 01564: val_loss did not improve from 1.27818
Epoch 1565/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4284 - val_loss: 1.2867 - val_accuracy: 0.4120

Epoch 01565: val_loss did not improve from 1.27818
Epoch 1566/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4265 - val_loss: 1.2826 - val_accuracy: 0.4112

Epoch 01566: val_loss did not improve from 1.27818
Epoch 1567/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4299 - val_loss: 1.2866 - val_accuracy: 0.4104

Epoch 01567: val_loss did not improve from 1.27818
Epoch 1568/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4290 - val_loss: 1.2897 - val_accuracy: 0.4143

Epoch 01568: val_loss did not improve from 1.27818
Epoch 1569/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4272 - val_loss: 1.2833 - val_accuracy: 0.4183

Epoch 01569: val_loss did not improve from 1.27818
Epoch 1570/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4296 - val_loss: 1.2784 - val_accuracy: 0.4207

Epoch 01570: val_loss did not improve from 1.27818
Epoch 1571/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4328 - val_loss: 1.2798 - val_accuracy: 0.4135

Epoch 01571: val_loss did not improve from 1.27818
Epoch 1572/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4257 - val_loss: 1.2879 - val_accuracy: 0.4183

Epoch 01572: val_loss did not improve from 1.27818
Epoch 1573/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4256 - val_loss: 1.2856 - val_accuracy: 0.4159

Epoch 01573: val_loss did not improve from 1.27818
Epoch 1574/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4300 - val_loss: 1.2817 - val_accuracy: 0.4207

Epoch 01574: val_loss did not improve from 1.27818
Epoch 1575/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4301 - val_loss: 1.2823 - val_accuracy: 0.4143

Epoch 01575: val_loss did not improve from 1.27818
Epoch 1576/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4250 - val_loss: 1.2849 - val_accuracy: 0.4151

Epoch 01576: val_loss did not improve from 1.27818
Epoch 1577/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4284 - val_loss: 1.2806 - val_accuracy: 0.4159

Epoch 01577: val_loss did not improve from 1.27818
Epoch 1578/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4281 - val_loss: 1.2862 - val_accuracy: 0.4096

Epoch 01578: val_loss did not improve from 1.27818
Epoch 1579/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4322 - val_loss: 1.2791 - val_accuracy: 0.4159

Epoch 01579: val_loss did not improve from 1.27818
Epoch 1580/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4306 - val_loss: 1.2891 - val_accuracy: 0.4104

Epoch 01580: val_loss did not improve from 1.27818
Epoch 1581/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4308 - val_loss: 1.2863 - val_accuracy: 0.4112

Epoch 01581: val_loss did not improve from 1.27818
Epoch 1582/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4260 - val_loss: 1.2821 - val_accuracy: 0.4112

Epoch 01582: val_loss did not improve from 1.27818
Epoch 1583/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4297 - val_loss: 1.2804 - val_accuracy: 0.4167

Epoch 01583: val_loss did not improve from 1.27818
Epoch 1584/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4253 - val_loss: 1.2828 - val_accuracy: 0.4104

Epoch 01584: val_loss did not improve from 1.27818
Epoch 1585/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4292 - val_loss: 1.2807 - val_accuracy: 0.4175

Epoch 01585: val_loss did not improve from 1.27818
Epoch 1586/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4276 - val_loss: 1.2845 - val_accuracy: 0.4104

Epoch 01586: val_loss did not improve from 1.27818
Epoch 1587/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4277 - val_loss: 1.2905 - val_accuracy: 0.4120

Epoch 01587: val_loss did not improve from 1.27818
Epoch 1588/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4290 - val_loss: 1.2839 - val_accuracy: 0.4167

Epoch 01588: val_loss did not improve from 1.27818
Epoch 1589/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4274 - val_loss: 1.2917 - val_accuracy: 0.4064

Epoch 01589: val_loss did not improve from 1.27818
Epoch 1590/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4296 - val_loss: 1.2831 - val_accuracy: 0.4120

Epoch 01590: val_loss did not improve from 1.27818
Epoch 1591/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4300 - val_loss: 1.2884 - val_accuracy: 0.4104

Epoch 01591: val_loss did not improve from 1.27818
Epoch 1592/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4277 - val_loss: 1.2789 - val_accuracy: 0.4072

Epoch 01592: val_loss did not improve from 1.27818
Epoch 1593/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4291 - val_loss: 1.2797 - val_accuracy: 0.4191

Epoch 01593: val_loss did not improve from 1.27818
Epoch 1594/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4283 - val_loss: 1.2869 - val_accuracy: 0.4175

Epoch 01594: val_loss did not improve from 1.27818
Epoch 1595/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4283 - val_loss: 1.2795 - val_accuracy: 0.4175

Epoch 01595: val_loss did not improve from 1.27818
Epoch 1596/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4282 - val_loss: 1.2804 - val_accuracy: 0.4191

Epoch 01596: val_loss did not improve from 1.27818
Epoch 1597/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4308 - val_loss: 1.2880 - val_accuracy: 0.4127

Epoch 01597: val_loss did not improve from 1.27818
Epoch 1598/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4270 - val_loss: 1.2817 - val_accuracy: 0.4199

Epoch 01598: val_loss did not improve from 1.27818
Epoch 1599/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4267 - val_loss: 1.2823 - val_accuracy: 0.4135

Epoch 01599: val_loss did not improve from 1.27818
Epoch 1600/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4298 - val_loss: 1.2816 - val_accuracy: 0.4151

Epoch 01600: val_loss did not improve from 1.27818
Epoch 1601/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4309 - val_loss: 1.2796 - val_accuracy: 0.4263

Epoch 01601: val_loss did not improve from 1.27818
Epoch 1602/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4313 - val_loss: 1.2817 - val_accuracy: 0.4159

Epoch 01602: val_loss did not improve from 1.27818
Epoch 1603/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4314 - val_loss: 1.2836 - val_accuracy: 0.4191

Epoch 01603: val_loss did not improve from 1.27818
Epoch 1604/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4315 - val_loss: 1.2843 - val_accuracy: 0.4151

Epoch 01604: val_loss did not improve from 1.27818
Epoch 1605/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4281 - val_loss: 1.2842 - val_accuracy: 0.4135

Epoch 01605: val_loss did not improve from 1.27818
Epoch 1606/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4322 - val_loss: 1.2846 - val_accuracy: 0.4175

Epoch 01606: val_loss did not improve from 1.27818
Epoch 1607/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4240 - val_loss: 1.2866 - val_accuracy: 0.4112

Epoch 01607: val_loss did not improve from 1.27818
Epoch 1608/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4307 - val_loss: 1.2832 - val_accuracy: 0.4215

Epoch 01608: val_loss did not improve from 1.27818
Epoch 1609/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4267 - val_loss: 1.2806 - val_accuracy: 0.4135

Epoch 01609: val_loss did not improve from 1.27818
Epoch 1610/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4295 - val_loss: 1.2819 - val_accuracy: 0.4151

Epoch 01610: val_loss did not improve from 1.27818
Epoch 1611/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4292 - val_loss: 1.2824 - val_accuracy: 0.4120

Epoch 01611: val_loss did not improve from 1.27818
Epoch 1612/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4350 - val_loss: 1.2835 - val_accuracy: 0.4127

Epoch 01612: val_loss did not improve from 1.27818
Epoch 1613/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4286 - val_loss: 1.2850 - val_accuracy: 0.4080

Epoch 01613: val_loss did not improve from 1.27818
Epoch 1614/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4252 - val_loss: 1.2813 - val_accuracy: 0.4104

Epoch 01614: val_loss did not improve from 1.27818
Epoch 1615/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4317 - val_loss: 1.2805 - val_accuracy: 0.4120

Epoch 01615: val_loss did not improve from 1.27818
Epoch 1616/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4298 - val_loss: 1.2865 - val_accuracy: 0.4104

Epoch 01616: val_loss did not improve from 1.27818
Epoch 1617/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4243 - val_loss: 1.2843 - val_accuracy: 0.4104

Epoch 01617: val_loss did not improve from 1.27818
Epoch 1618/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4299 - val_loss: 1.2821 - val_accuracy: 0.4104

Epoch 01618: val_loss did not improve from 1.27818
Epoch 1619/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4274 - val_loss: 1.2887 - val_accuracy: 0.4151

Epoch 01619: val_loss did not improve from 1.27818
Epoch 1620/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4329 - val_loss: 1.2779 - val_accuracy: 0.4207

Epoch 01620: val_loss improved from 1.27818 to 1.27792, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1621/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4238 - val_loss: 1.2840 - val_accuracy: 0.4112

Epoch 01621: val_loss did not improve from 1.27792
Epoch 1622/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4261 - val_loss: 1.2801 - val_accuracy: 0.4175

Epoch 01622: val_loss did not improve from 1.27792
Epoch 1623/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4334 - val_loss: 1.2883 - val_accuracy: 0.4088

Epoch 01623: val_loss did not improve from 1.27792
Epoch 1624/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4299 - val_loss: 1.2823 - val_accuracy: 0.4159

Epoch 01624: val_loss did not improve from 1.27792
Epoch 1625/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4283 - val_loss: 1.2805 - val_accuracy: 0.4183

Epoch 01625: val_loss did not improve from 1.27792
Epoch 1626/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4274 - val_loss: 1.2849 - val_accuracy: 0.4080

Epoch 01626: val_loss did not improve from 1.27792
Epoch 1627/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4308 - val_loss: 1.2917 - val_accuracy: 0.4191

Epoch 01627: val_loss did not improve from 1.27792
Epoch 1628/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4267 - val_loss: 1.2870 - val_accuracy: 0.4183

Epoch 01628: val_loss did not improve from 1.27792
Epoch 1629/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4284 - val_loss: 1.2817 - val_accuracy: 0.4120

Epoch 01629: val_loss did not improve from 1.27792
Epoch 1630/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4277 - val_loss: 1.2833 - val_accuracy: 0.4159

Epoch 01630: val_loss did not improve from 1.27792
Epoch 1631/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4313 - val_loss: 1.2848 - val_accuracy: 0.4159

Epoch 01631: val_loss did not improve from 1.27792
Epoch 1632/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4303 - val_loss: 1.2833 - val_accuracy: 0.4112

Epoch 01632: val_loss did not improve from 1.27792
Epoch 1633/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4250 - val_loss: 1.2810 - val_accuracy: 0.4191

Epoch 01633: val_loss did not improve from 1.27792
Epoch 1634/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4259 - val_loss: 1.2768 - val_accuracy: 0.4199

Epoch 01634: val_loss improved from 1.27792 to 1.27680, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1635/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4252 - val_loss: 1.2873 - val_accuracy: 0.4080

Epoch 01635: val_loss did not improve from 1.27680
Epoch 1636/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4325 - val_loss: 1.2817 - val_accuracy: 0.4112

Epoch 01636: val_loss did not improve from 1.27680
Epoch 1637/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4264 - val_loss: 1.2814 - val_accuracy: 0.4199

Epoch 01637: val_loss did not improve from 1.27680
Epoch 1638/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4262 - val_loss: 1.2871 - val_accuracy: 0.4104

Epoch 01638: val_loss did not improve from 1.27680
Epoch 1639/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4311 - val_loss: 1.2831 - val_accuracy: 0.4088

Epoch 01639: val_loss did not improve from 1.27680
Epoch 1640/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4273 - val_loss: 1.2832 - val_accuracy: 0.4096

Epoch 01640: val_loss did not improve from 1.27680
Epoch 1641/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4281 - val_loss: 1.2846 - val_accuracy: 0.4127

Epoch 01641: val_loss did not improve from 1.27680
Epoch 1642/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4321 - val_loss: 1.2829 - val_accuracy: 0.4143

Epoch 01642: val_loss did not improve from 1.27680
Epoch 1643/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4322 - val_loss: 1.2776 - val_accuracy: 0.4072

Epoch 01643: val_loss did not improve from 1.27680
Epoch 1644/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4273 - val_loss: 1.2796 - val_accuracy: 0.4167

Epoch 01644: val_loss did not improve from 1.27680
Epoch 1645/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4214 - val_loss: 1.2845 - val_accuracy: 0.4135

Epoch 01645: val_loss did not improve from 1.27680
Epoch 1646/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4306 - val_loss: 1.2872 - val_accuracy: 0.4064

Epoch 01646: val_loss did not improve from 1.27680
Epoch 1647/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4316 - val_loss: 1.2844 - val_accuracy: 0.4104

Epoch 01647: val_loss did not improve from 1.27680
Epoch 1648/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4329 - val_loss: 1.2832 - val_accuracy: 0.4151

Epoch 01648: val_loss did not improve from 1.27680
Epoch 1649/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4291 - val_loss: 1.2850 - val_accuracy: 0.4135

Epoch 01649: val_loss did not improve from 1.27680
Epoch 1650/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4287 - val_loss: 1.2832 - val_accuracy: 0.4151

Epoch 01650: val_loss did not improve from 1.27680
Epoch 1651/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4267 - val_loss: 1.2865 - val_accuracy: 0.4080

Epoch 01651: val_loss did not improve from 1.27680
Epoch 1652/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4287 - val_loss: 1.2931 - val_accuracy: 0.3976

Epoch 01652: val_loss did not improve from 1.27680
Epoch 1653/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4217 - val_loss: 1.2846 - val_accuracy: 0.4120

Epoch 01653: val_loss did not improve from 1.27680
Epoch 1654/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4252 - val_loss: 1.2811 - val_accuracy: 0.4112

Epoch 01654: val_loss did not improve from 1.27680
Epoch 1655/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4261 - val_loss: 1.2798 - val_accuracy: 0.4167

Epoch 01655: val_loss did not improve from 1.27680
Epoch 1656/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4314 - val_loss: 1.2823 - val_accuracy: 0.4096

Epoch 01656: val_loss did not improve from 1.27680
Epoch 1657/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4306 - val_loss: 1.2836 - val_accuracy: 0.4048

Epoch 01657: val_loss did not improve from 1.27680
Epoch 1658/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4267 - val_loss: 1.2815 - val_accuracy: 0.4080

Epoch 01658: val_loss did not improve from 1.27680
Epoch 1659/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4299 - val_loss: 1.2861 - val_accuracy: 0.4183

Epoch 01659: val_loss did not improve from 1.27680
Epoch 1660/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4307 - val_loss: 1.2817 - val_accuracy: 0.4151

Epoch 01660: val_loss did not improve from 1.27680
Epoch 1661/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4278 - val_loss: 1.2799 - val_accuracy: 0.4088

Epoch 01661: val_loss did not improve from 1.27680
Epoch 1662/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4307 - val_loss: 1.2818 - val_accuracy: 0.4151

Epoch 01662: val_loss did not improve from 1.27680
Epoch 1663/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4306 - val_loss: 1.2850 - val_accuracy: 0.4008

Epoch 01663: val_loss did not improve from 1.27680
Epoch 1664/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4272 - val_loss: 1.2835 - val_accuracy: 0.4096

Epoch 01664: val_loss did not improve from 1.27680
Epoch 1665/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4262 - val_loss: 1.2861 - val_accuracy: 0.4040

Epoch 01665: val_loss did not improve from 1.27680
Epoch 1666/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4253 - val_loss: 1.2830 - val_accuracy: 0.4112

Epoch 01666: val_loss did not improve from 1.27680
Epoch 1667/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4307 - val_loss: 1.2945 - val_accuracy: 0.4112

Epoch 01667: val_loss did not improve from 1.27680
Epoch 1668/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4326 - val_loss: 1.2816 - val_accuracy: 0.4135

Epoch 01668: val_loss did not improve from 1.27680
Epoch 1669/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4319 - val_loss: 1.2833 - val_accuracy: 0.4159

Epoch 01669: val_loss did not improve from 1.27680
Epoch 1670/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4260 - val_loss: 1.2951 - val_accuracy: 0.4064

Epoch 01670: val_loss did not improve from 1.27680
Epoch 1671/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4292 - val_loss: 1.2825 - val_accuracy: 0.4183

Epoch 01671: val_loss did not improve from 1.27680
Epoch 1672/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4285 - val_loss: 1.2809 - val_accuracy: 0.4159

Epoch 01672: val_loss did not improve from 1.27680
Epoch 1673/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4251 - val_loss: 1.2814 - val_accuracy: 0.4159

Epoch 01673: val_loss did not improve from 1.27680
Epoch 1674/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4269 - val_loss: 1.2854 - val_accuracy: 0.4096

Epoch 01674: val_loss did not improve from 1.27680
Epoch 1675/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4308 - val_loss: 1.2830 - val_accuracy: 0.4191

Epoch 01675: val_loss did not improve from 1.27680
Epoch 1676/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4304 - val_loss: 1.2820 - val_accuracy: 0.4135

Epoch 01676: val_loss did not improve from 1.27680
Epoch 1677/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4291 - val_loss: 1.2836 - val_accuracy: 0.4120

Epoch 01677: val_loss did not improve from 1.27680
Epoch 1678/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4330 - val_loss: 1.2858 - val_accuracy: 0.4143

Epoch 01678: val_loss did not improve from 1.27680
Epoch 1679/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4309 - val_loss: 1.2843 - val_accuracy: 0.4151

Epoch 01679: val_loss did not improve from 1.27680
Epoch 1680/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4314 - val_loss: 1.2770 - val_accuracy: 0.4199

Epoch 01680: val_loss did not improve from 1.27680
Epoch 1681/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4296 - val_loss: 1.2889 - val_accuracy: 0.4215

Epoch 01681: val_loss did not improve from 1.27680
Epoch 1682/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4273 - val_loss: 1.2870 - val_accuracy: 0.4040

Epoch 01682: val_loss did not improve from 1.27680
Epoch 1683/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4310 - val_loss: 1.2844 - val_accuracy: 0.4096

Epoch 01683: val_loss did not improve from 1.27680
Epoch 1684/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4298 - val_loss: 1.2823 - val_accuracy: 0.4096

Epoch 01684: val_loss did not improve from 1.27680
Epoch 1685/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4265 - val_loss: 1.2845 - val_accuracy: 0.4207

Epoch 01685: val_loss did not improve from 1.27680
Epoch 1686/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4303 - val_loss: 1.2912 - val_accuracy: 0.4056

Epoch 01686: val_loss did not improve from 1.27680
Epoch 1687/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4321 - val_loss: 1.2831 - val_accuracy: 0.4127

Epoch 01687: val_loss did not improve from 1.27680
Epoch 1688/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4345 - val_loss: 1.2799 - val_accuracy: 0.4207

Epoch 01688: val_loss did not improve from 1.27680
Epoch 1689/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4322 - val_loss: 1.2862 - val_accuracy: 0.4175

Epoch 01689: val_loss did not improve from 1.27680
Epoch 1690/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4307 - val_loss: 1.2839 - val_accuracy: 0.4120

Epoch 01690: val_loss did not improve from 1.27680
Epoch 1691/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4320 - val_loss: 1.2818 - val_accuracy: 0.4127

Epoch 01691: val_loss did not improve from 1.27680
Epoch 1692/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4289 - val_loss: 1.2822 - val_accuracy: 0.4056

Epoch 01692: val_loss did not improve from 1.27680
Epoch 1693/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4291 - val_loss: 1.2794 - val_accuracy: 0.4127

Epoch 01693: val_loss did not improve from 1.27680
Epoch 1694/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4303 - val_loss: 1.2784 - val_accuracy: 0.4175

Epoch 01694: val_loss did not improve from 1.27680
Epoch 1695/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4322 - val_loss: 1.2817 - val_accuracy: 0.4207

Epoch 01695: val_loss did not improve from 1.27680
Epoch 1696/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4344 - val_loss: 1.2813 - val_accuracy: 0.4239

Epoch 01696: val_loss did not improve from 1.27680
Epoch 1697/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4275 - val_loss: 1.2828 - val_accuracy: 0.4159

Epoch 01697: val_loss did not improve from 1.27680
Epoch 1698/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4325 - val_loss: 1.2839 - val_accuracy: 0.4167

Epoch 01698: val_loss did not improve from 1.27680
Epoch 1699/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4305 - val_loss: 1.2835 - val_accuracy: 0.4048

Epoch 01699: val_loss did not improve from 1.27680
Epoch 1700/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4305 - val_loss: 1.2810 - val_accuracy: 0.4135

Epoch 01700: val_loss did not improve from 1.27680
Epoch 1701/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4257 - val_loss: 1.2804 - val_accuracy: 0.4151

Epoch 01701: val_loss did not improve from 1.27680
Epoch 1702/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4284 - val_loss: 1.2811 - val_accuracy: 0.4151

Epoch 01702: val_loss did not improve from 1.27680
Epoch 1703/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4287 - val_loss: 1.2795 - val_accuracy: 0.4199

Epoch 01703: val_loss did not improve from 1.27680
Epoch 1704/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4273 - val_loss: 1.2785 - val_accuracy: 0.4191

Epoch 01704: val_loss did not improve from 1.27680
Epoch 1705/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4313 - val_loss: 1.2801 - val_accuracy: 0.4215

Epoch 01705: val_loss did not improve from 1.27680
Epoch 1706/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4315 - val_loss: 1.2871 - val_accuracy: 0.4032

Epoch 01706: val_loss did not improve from 1.27680
Epoch 1707/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4309 - val_loss: 1.2812 - val_accuracy: 0.4135

Epoch 01707: val_loss did not improve from 1.27680
Epoch 1708/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4263 - val_loss: 1.2860 - val_accuracy: 0.4135

Epoch 01708: val_loss did not improve from 1.27680
Epoch 1709/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4275 - val_loss: 1.2832 - val_accuracy: 0.4120

Epoch 01709: val_loss did not improve from 1.27680
Epoch 1710/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4331 - val_loss: 1.2844 - val_accuracy: 0.4112

Epoch 01710: val_loss did not improve from 1.27680
Epoch 1711/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4283 - val_loss: 1.2822 - val_accuracy: 0.4191

Epoch 01711: val_loss did not improve from 1.27680
Epoch 1712/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4321 - val_loss: 1.2809 - val_accuracy: 0.4151

Epoch 01712: val_loss did not improve from 1.27680
Epoch 1713/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4301 - val_loss: 1.2851 - val_accuracy: 0.4032

Epoch 01713: val_loss did not improve from 1.27680
Epoch 1714/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4314 - val_loss: 1.2795 - val_accuracy: 0.4207

Epoch 01714: val_loss did not improve from 1.27680
Epoch 1715/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4306 - val_loss: 1.2803 - val_accuracy: 0.4135

Epoch 01715: val_loss did not improve from 1.27680
Epoch 1716/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4262 - val_loss: 1.2809 - val_accuracy: 0.4096

Epoch 01716: val_loss did not improve from 1.27680
Epoch 1717/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4282 - val_loss: 1.2801 - val_accuracy: 0.4175

Epoch 01717: val_loss did not improve from 1.27680
Epoch 1718/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4334 - val_loss: 1.2818 - val_accuracy: 0.4159

Epoch 01718: val_loss did not improve from 1.27680
Epoch 1719/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4283 - val_loss: 1.2784 - val_accuracy: 0.4247

Epoch 01719: val_loss did not improve from 1.27680
Epoch 1720/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4291 - val_loss: 1.2839 - val_accuracy: 0.4143

Epoch 01720: val_loss did not improve from 1.27680
Epoch 1721/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4294 - val_loss: 1.2777 - val_accuracy: 0.4183

Epoch 01721: val_loss did not improve from 1.27680
Epoch 1722/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4267 - val_loss: 1.2819 - val_accuracy: 0.4120

Epoch 01722: val_loss did not improve from 1.27680
Epoch 1723/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4337 - val_loss: 1.2843 - val_accuracy: 0.4151

Epoch 01723: val_loss did not improve from 1.27680
Epoch 1724/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4298 - val_loss: 1.2797 - val_accuracy: 0.4231

Epoch 01724: val_loss did not improve from 1.27680
Epoch 1725/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4324 - val_loss: 1.2814 - val_accuracy: 0.4151

Epoch 01725: val_loss did not improve from 1.27680
Epoch 1726/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4291 - val_loss: 1.2819 - val_accuracy: 0.4008

Epoch 01726: val_loss did not improve from 1.27680
Epoch 1727/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4290 - val_loss: 1.2799 - val_accuracy: 0.4183

Epoch 01727: val_loss did not improve from 1.27680
Epoch 1728/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4310 - val_loss: 1.2857 - val_accuracy: 0.4096

Epoch 01728: val_loss did not improve from 1.27680
Epoch 1729/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4301 - val_loss: 1.2802 - val_accuracy: 0.4215

Epoch 01729: val_loss did not improve from 1.27680
Epoch 1730/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4298 - val_loss: 1.2891 - val_accuracy: 0.4024

Epoch 01730: val_loss did not improve from 1.27680
Epoch 1731/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4244 - val_loss: 1.2765 - val_accuracy: 0.4048

Epoch 01731: val_loss improved from 1.27680 to 1.27650, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1732/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4295 - val_loss: 1.2846 - val_accuracy: 0.4056

Epoch 01732: val_loss did not improve from 1.27650
Epoch 1733/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4322 - val_loss: 1.2835 - val_accuracy: 0.4167

Epoch 01733: val_loss did not improve from 1.27650
Epoch 1734/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4289 - val_loss: 1.2856 - val_accuracy: 0.4056

Epoch 01734: val_loss did not improve from 1.27650
Epoch 1735/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4319 - val_loss: 1.2839 - val_accuracy: 0.4175

Epoch 01735: val_loss did not improve from 1.27650
Epoch 1736/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4274 - val_loss: 1.2813 - val_accuracy: 0.4215

Epoch 01736: val_loss did not improve from 1.27650
Epoch 1737/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4339 - val_loss: 1.2847 - val_accuracy: 0.4151

Epoch 01737: val_loss did not improve from 1.27650
Epoch 1738/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4298 - val_loss: 1.2808 - val_accuracy: 0.4112

Epoch 01738: val_loss did not improve from 1.27650
Epoch 1739/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4294 - val_loss: 1.2806 - val_accuracy: 0.4120

Epoch 01739: val_loss did not improve from 1.27650
Epoch 1740/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4331 - val_loss: 1.2857 - val_accuracy: 0.4112

Epoch 01740: val_loss did not improve from 1.27650
Epoch 1741/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4268 - val_loss: 1.2840 - val_accuracy: 0.4223

Epoch 01741: val_loss did not improve from 1.27650
Epoch 1742/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4297 - val_loss: 1.2801 - val_accuracy: 0.4112

Epoch 01742: val_loss did not improve from 1.27650
Epoch 1743/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4300 - val_loss: 1.2822 - val_accuracy: 0.4127

Epoch 01743: val_loss did not improve from 1.27650
Epoch 1744/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4318 - val_loss: 1.2816 - val_accuracy: 0.4183

Epoch 01744: val_loss did not improve from 1.27650
Epoch 1745/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4318 - val_loss: 1.2822 - val_accuracy: 0.4167

Epoch 01745: val_loss did not improve from 1.27650
Epoch 1746/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4312 - val_loss: 1.2821 - val_accuracy: 0.4088

Epoch 01746: val_loss did not improve from 1.27650
Epoch 1747/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4291 - val_loss: 1.2830 - val_accuracy: 0.4191

Epoch 01747: val_loss did not improve from 1.27650
Epoch 1748/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4293 - val_loss: 1.2824 - val_accuracy: 0.4104

Epoch 01748: val_loss did not improve from 1.27650
Epoch 1749/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4291 - val_loss: 1.2784 - val_accuracy: 0.4175

Epoch 01749: val_loss did not improve from 1.27650
Epoch 1750/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4268 - val_loss: 1.2820 - val_accuracy: 0.4151

Epoch 01750: val_loss did not improve from 1.27650
Epoch 1751/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4300 - val_loss: 1.2805 - val_accuracy: 0.4143

Epoch 01751: val_loss did not improve from 1.27650
Epoch 1752/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4300 - val_loss: 1.2881 - val_accuracy: 0.4016

Epoch 01752: val_loss did not improve from 1.27650
Epoch 1753/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4285 - val_loss: 1.2806 - val_accuracy: 0.4175

Epoch 01753: val_loss did not improve from 1.27650
Epoch 1754/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4344 - val_loss: 1.2805 - val_accuracy: 0.4167

Epoch 01754: val_loss did not improve from 1.27650
Epoch 1755/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4331 - val_loss: 1.2811 - val_accuracy: 0.4215

Epoch 01755: val_loss did not improve from 1.27650
Epoch 1756/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4295 - val_loss: 1.2801 - val_accuracy: 0.4088

Epoch 01756: val_loss did not improve from 1.27650
Epoch 1757/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4299 - val_loss: 1.2837 - val_accuracy: 0.4143

Epoch 01757: val_loss did not improve from 1.27650
Epoch 1758/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4311 - val_loss: 1.2853 - val_accuracy: 0.4072

Epoch 01758: val_loss did not improve from 1.27650
Epoch 1759/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4316 - val_loss: 1.2782 - val_accuracy: 0.4207

Epoch 01759: val_loss did not improve from 1.27650
Epoch 1760/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4293 - val_loss: 1.2836 - val_accuracy: 0.4183

Epoch 01760: val_loss did not improve from 1.27650
Epoch 1761/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4307 - val_loss: 1.2780 - val_accuracy: 0.4215

Epoch 01761: val_loss did not improve from 1.27650
Epoch 1762/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4334 - val_loss: 1.2817 - val_accuracy: 0.4247

Epoch 01762: val_loss did not improve from 1.27650
Epoch 1763/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4294 - val_loss: 1.2770 - val_accuracy: 0.4127

Epoch 01763: val_loss did not improve from 1.27650
Epoch 1764/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4253 - val_loss: 1.2855 - val_accuracy: 0.4175

Epoch 01764: val_loss did not improve from 1.27650
Epoch 1765/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4304 - val_loss: 1.2869 - val_accuracy: 0.4088

Epoch 01765: val_loss did not improve from 1.27650
Epoch 1766/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4326 - val_loss: 1.2856 - val_accuracy: 0.4080

Epoch 01766: val_loss did not improve from 1.27650
Epoch 1767/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4293 - val_loss: 1.2912 - val_accuracy: 0.4104

Epoch 01767: val_loss did not improve from 1.27650
Epoch 1768/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4282 - val_loss: 1.2836 - val_accuracy: 0.4159

Epoch 01768: val_loss did not improve from 1.27650
Epoch 1769/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4302 - val_loss: 1.2808 - val_accuracy: 0.4199

Epoch 01769: val_loss did not improve from 1.27650
Epoch 1770/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4308 - val_loss: 1.2828 - val_accuracy: 0.4127

Epoch 01770: val_loss did not improve from 1.27650
Epoch 1771/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4305 - val_loss: 1.2813 - val_accuracy: 0.4175

Epoch 01771: val_loss did not improve from 1.27650
Epoch 1772/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4311 - val_loss: 1.2850 - val_accuracy: 0.4112

Epoch 01772: val_loss did not improve from 1.27650
Epoch 1773/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4353 - val_loss: 1.2865 - val_accuracy: 0.4088

Epoch 01773: val_loss did not improve from 1.27650
Epoch 1774/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4298 - val_loss: 1.2858 - val_accuracy: 0.4175

Epoch 01774: val_loss did not improve from 1.27650
Epoch 1775/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4281 - val_loss: 1.2772 - val_accuracy: 0.4255

Epoch 01775: val_loss did not improve from 1.27650
Epoch 1776/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4329 - val_loss: 1.2927 - val_accuracy: 0.4112

Epoch 01776: val_loss did not improve from 1.27650
Epoch 1777/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4286 - val_loss: 1.2818 - val_accuracy: 0.4175

Epoch 01777: val_loss did not improve from 1.27650
Epoch 1778/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4345 - val_loss: 1.2825 - val_accuracy: 0.4112

Epoch 01778: val_loss did not improve from 1.27650
Epoch 1779/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4332 - val_loss: 1.2792 - val_accuracy: 0.4088

Epoch 01779: val_loss did not improve from 1.27650
Epoch 1780/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4294 - val_loss: 1.2766 - val_accuracy: 0.4183

Epoch 01780: val_loss did not improve from 1.27650
Epoch 1781/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4306 - val_loss: 1.2779 - val_accuracy: 0.4143

Epoch 01781: val_loss did not improve from 1.27650
Epoch 1782/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4329 - val_loss: 1.2779 - val_accuracy: 0.4215

Epoch 01782: val_loss did not improve from 1.27650
Epoch 1783/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4351 - val_loss: 1.2794 - val_accuracy: 0.4080

Epoch 01783: val_loss did not improve from 1.27650
Epoch 1784/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4290 - val_loss: 1.2867 - val_accuracy: 0.4127

Epoch 01784: val_loss did not improve from 1.27650
Epoch 1785/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4339 - val_loss: 1.2827 - val_accuracy: 0.4143

Epoch 01785: val_loss did not improve from 1.27650
Epoch 1786/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4291 - val_loss: 1.2818 - val_accuracy: 0.4207

Epoch 01786: val_loss did not improve from 1.27650
Epoch 1787/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4306 - val_loss: 1.2832 - val_accuracy: 0.4112

Epoch 01787: val_loss did not improve from 1.27650
Epoch 1788/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4292 - val_loss: 1.2815 - val_accuracy: 0.4167

Epoch 01788: val_loss did not improve from 1.27650
Epoch 1789/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4298 - val_loss: 1.2847 - val_accuracy: 0.4167

Epoch 01789: val_loss did not improve from 1.27650
Epoch 1790/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4307 - val_loss: 1.2823 - val_accuracy: 0.4104

Epoch 01790: val_loss did not improve from 1.27650
Epoch 1791/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4288 - val_loss: 1.2787 - val_accuracy: 0.4167

Epoch 01791: val_loss did not improve from 1.27650
Epoch 1792/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4309 - val_loss: 1.2831 - val_accuracy: 0.4064

Epoch 01792: val_loss did not improve from 1.27650
Epoch 1793/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4321 - val_loss: 1.2807 - val_accuracy: 0.4104

Epoch 01793: val_loss did not improve from 1.27650
Epoch 1794/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4277 - val_loss: 1.2806 - val_accuracy: 0.4207

Epoch 01794: val_loss did not improve from 1.27650
Epoch 1795/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4312 - val_loss: 1.2819 - val_accuracy: 0.4135

Epoch 01795: val_loss did not improve from 1.27650
Epoch 1796/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4319 - val_loss: 1.2830 - val_accuracy: 0.4056

Epoch 01796: val_loss did not improve from 1.27650
Epoch 1797/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4311 - val_loss: 1.2781 - val_accuracy: 0.4191

Epoch 01797: val_loss did not improve from 1.27650
Epoch 1798/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4326 - val_loss: 1.2827 - val_accuracy: 0.4159

Epoch 01798: val_loss did not improve from 1.27650
Epoch 1799/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4322 - val_loss: 1.2791 - val_accuracy: 0.4271

Epoch 01799: val_loss did not improve from 1.27650
Epoch 1800/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4313 - val_loss: 1.2810 - val_accuracy: 0.4135

Epoch 01800: val_loss did not improve from 1.27650
Epoch 1801/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4254 - val_loss: 1.2831 - val_accuracy: 0.4151

Epoch 01801: val_loss did not improve from 1.27650
Epoch 1802/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4267 - val_loss: 1.2817 - val_accuracy: 0.4072

Epoch 01802: val_loss did not improve from 1.27650
Epoch 1803/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4313 - val_loss: 1.2877 - val_accuracy: 0.4127

Epoch 01803: val_loss did not improve from 1.27650
Epoch 1804/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4280 - val_loss: 1.2825 - val_accuracy: 0.4056

Epoch 01804: val_loss did not improve from 1.27650
Epoch 1805/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4264 - val_loss: 1.2818 - val_accuracy: 0.4215

Epoch 01805: val_loss did not improve from 1.27650
Epoch 1806/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4236 - val_loss: 1.2908 - val_accuracy: 0.4056

Epoch 01806: val_loss did not improve from 1.27650
Epoch 1807/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4245 - val_loss: 1.2846 - val_accuracy: 0.4104

Epoch 01807: val_loss did not improve from 1.27650
Epoch 1808/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4282 - val_loss: 1.2828 - val_accuracy: 0.4159

Epoch 01808: val_loss did not improve from 1.27650
Epoch 1809/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4292 - val_loss: 1.2812 - val_accuracy: 0.4120

Epoch 01809: val_loss did not improve from 1.27650
Epoch 1810/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4280 - val_loss: 1.2845 - val_accuracy: 0.4056

Epoch 01810: val_loss did not improve from 1.27650
Epoch 1811/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4335 - val_loss: 1.2865 - val_accuracy: 0.4096

Epoch 01811: val_loss did not improve from 1.27650
Epoch 1812/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4320 - val_loss: 1.2848 - val_accuracy: 0.4112

Epoch 01812: val_loss did not improve from 1.27650
Epoch 1813/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4278 - val_loss: 1.2830 - val_accuracy: 0.4143

Epoch 01813: val_loss did not improve from 1.27650
Epoch 1814/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4315 - val_loss: 1.2779 - val_accuracy: 0.4167

Epoch 01814: val_loss did not improve from 1.27650
Epoch 1815/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4318 - val_loss: 1.2788 - val_accuracy: 0.4271

Epoch 01815: val_loss did not improve from 1.27650
Epoch 1816/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4343 - val_loss: 1.2845 - val_accuracy: 0.4135

Epoch 01816: val_loss did not improve from 1.27650
Epoch 1817/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4341 - val_loss: 1.2800 - val_accuracy: 0.4175

Epoch 01817: val_loss did not improve from 1.27650
Epoch 1818/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4278 - val_loss: 1.2829 - val_accuracy: 0.4120

Epoch 01818: val_loss did not improve from 1.27650
Epoch 1819/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4278 - val_loss: 1.2805 - val_accuracy: 0.4135

Epoch 01819: val_loss did not improve from 1.27650
Epoch 1820/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4309 - val_loss: 1.2806 - val_accuracy: 0.4143

Epoch 01820: val_loss did not improve from 1.27650
Epoch 1821/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4291 - val_loss: 1.2815 - val_accuracy: 0.4072

Epoch 01821: val_loss did not improve from 1.27650
Epoch 1822/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4306 - val_loss: 1.2812 - val_accuracy: 0.4135

Epoch 01822: val_loss did not improve from 1.27650
Epoch 1823/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4291 - val_loss: 1.2830 - val_accuracy: 0.4135

Epoch 01823: val_loss did not improve from 1.27650
Epoch 1824/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4269 - val_loss: 1.2783 - val_accuracy: 0.4151

Epoch 01824: val_loss did not improve from 1.27650
Epoch 1825/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4290 - val_loss: 1.2800 - val_accuracy: 0.4151

Epoch 01825: val_loss did not improve from 1.27650
Epoch 1826/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4314 - val_loss: 1.2850 - val_accuracy: 0.4096

Epoch 01826: val_loss did not improve from 1.27650
Epoch 1827/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4333 - val_loss: 1.2768 - val_accuracy: 0.4207

Epoch 01827: val_loss did not improve from 1.27650
Epoch 1828/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4302 - val_loss: 1.2816 - val_accuracy: 0.4120

Epoch 01828: val_loss did not improve from 1.27650
Epoch 1829/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4308 - val_loss: 1.2837 - val_accuracy: 0.4207

Epoch 01829: val_loss did not improve from 1.27650
Epoch 1830/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4345 - val_loss: 1.2834 - val_accuracy: 0.4175

Epoch 01830: val_loss did not improve from 1.27650
Epoch 1831/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4381 - val_loss: 1.2804 - val_accuracy: 0.4223

Epoch 01831: val_loss did not improve from 1.27650
Epoch 1832/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4289 - val_loss: 1.2794 - val_accuracy: 0.4151

Epoch 01832: val_loss did not improve from 1.27650
Epoch 1833/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4322 - val_loss: 1.2850 - val_accuracy: 0.4080

Epoch 01833: val_loss did not improve from 1.27650
Epoch 1834/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4310 - val_loss: 1.2850 - val_accuracy: 0.4112

Epoch 01834: val_loss did not improve from 1.27650
Epoch 1835/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4292 - val_loss: 1.2787 - val_accuracy: 0.4135

Epoch 01835: val_loss did not improve from 1.27650
Epoch 1836/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4349 - val_loss: 1.2796 - val_accuracy: 0.4135

Epoch 01836: val_loss did not improve from 1.27650
Epoch 1837/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4304 - val_loss: 1.2824 - val_accuracy: 0.4135

Epoch 01837: val_loss did not improve from 1.27650
Epoch 1838/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4302 - val_loss: 1.2824 - val_accuracy: 0.4127

Epoch 01838: val_loss did not improve from 1.27650
Epoch 1839/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4303 - val_loss: 1.2813 - val_accuracy: 0.4127

Epoch 01839: val_loss did not improve from 1.27650
Epoch 1840/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4283 - val_loss: 1.2789 - val_accuracy: 0.4175

Epoch 01840: val_loss did not improve from 1.27650
Epoch 1841/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4283 - val_loss: 1.2839 - val_accuracy: 0.4096

Epoch 01841: val_loss did not improve from 1.27650
Epoch 1842/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4329 - val_loss: 1.2820 - val_accuracy: 0.4112

Epoch 01842: val_loss did not improve from 1.27650
Epoch 1843/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4279 - val_loss: 1.2827 - val_accuracy: 0.4151

Epoch 01843: val_loss did not improve from 1.27650
Epoch 1844/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4286 - val_loss: 1.2796 - val_accuracy: 0.4183

Epoch 01844: val_loss did not improve from 1.27650
Epoch 1845/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4309 - val_loss: 1.2848 - val_accuracy: 0.4191

Epoch 01845: val_loss did not improve from 1.27650
Epoch 1846/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4342 - val_loss: 1.2859 - val_accuracy: 0.4127

Epoch 01846: val_loss did not improve from 1.27650
Epoch 1847/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4286 - val_loss: 1.2839 - val_accuracy: 0.4159

Epoch 01847: val_loss did not improve from 1.27650
Epoch 1848/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4265 - val_loss: 1.2816 - val_accuracy: 0.4247

Epoch 01848: val_loss did not improve from 1.27650
Epoch 1849/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4320 - val_loss: 1.2808 - val_accuracy: 0.4088

Epoch 01849: val_loss did not improve from 1.27650
Epoch 1850/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4324 - val_loss: 1.2896 - val_accuracy: 0.4096

Epoch 01850: val_loss did not improve from 1.27650
Epoch 1851/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4314 - val_loss: 1.2883 - val_accuracy: 0.4080

Epoch 01851: val_loss did not improve from 1.27650
Epoch 1852/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4256 - val_loss: 1.2817 - val_accuracy: 0.4143

Epoch 01852: val_loss did not improve from 1.27650
Epoch 1853/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4319 - val_loss: 1.2825 - val_accuracy: 0.4215

Epoch 01853: val_loss did not improve from 1.27650
Epoch 1854/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4320 - val_loss: 1.2860 - val_accuracy: 0.4024

Epoch 01854: val_loss did not improve from 1.27650
Epoch 1855/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4303 - val_loss: 1.2793 - val_accuracy: 0.4088

Epoch 01855: val_loss did not improve from 1.27650
Epoch 1856/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4295 - val_loss: 1.2780 - val_accuracy: 0.4104

Epoch 01856: val_loss did not improve from 1.27650
Epoch 1857/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4257 - val_loss: 1.2808 - val_accuracy: 0.4120

Epoch 01857: val_loss did not improve from 1.27650
Epoch 1858/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4345 - val_loss: 1.2849 - val_accuracy: 0.4120

Epoch 01858: val_loss did not improve from 1.27650
Epoch 1859/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4368 - val_loss: 1.2782 - val_accuracy: 0.4080

Epoch 01859: val_loss did not improve from 1.27650
Epoch 1860/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4319 - val_loss: 1.2825 - val_accuracy: 0.4048

Epoch 01860: val_loss did not improve from 1.27650
Epoch 1861/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4317 - val_loss: 1.2783 - val_accuracy: 0.4175

Epoch 01861: val_loss did not improve from 1.27650
Epoch 1862/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4366 - val_loss: 1.2770 - val_accuracy: 0.4223

Epoch 01862: val_loss did not improve from 1.27650
Epoch 1863/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4351 - val_loss: 1.2799 - val_accuracy: 0.4088

Epoch 01863: val_loss did not improve from 1.27650
Epoch 1864/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4325 - val_loss: 1.2761 - val_accuracy: 0.4239

Epoch 01864: val_loss improved from 1.27650 to 1.27608, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1865/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4237 - val_loss: 1.2788 - val_accuracy: 0.4215

Epoch 01865: val_loss did not improve from 1.27608
Epoch 1866/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4306 - val_loss: 1.2841 - val_accuracy: 0.4159

Epoch 01866: val_loss did not improve from 1.27608
Epoch 1867/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4313 - val_loss: 1.2778 - val_accuracy: 0.4199

Epoch 01867: val_loss did not improve from 1.27608
Epoch 1868/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4268 - val_loss: 1.2794 - val_accuracy: 0.4048

Epoch 01868: val_loss did not improve from 1.27608
Epoch 1869/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4293 - val_loss: 1.2746 - val_accuracy: 0.4223

Epoch 01869: val_loss improved from 1.27608 to 1.27461, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1870/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4257 - val_loss: 1.2785 - val_accuracy: 0.4112

Epoch 01870: val_loss did not improve from 1.27461
Epoch 1871/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4302 - val_loss: 1.2831 - val_accuracy: 0.4127

Epoch 01871: val_loss did not improve from 1.27461
Epoch 1872/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4302 - val_loss: 1.2783 - val_accuracy: 0.4127

Epoch 01872: val_loss did not improve from 1.27461
Epoch 1873/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4313 - val_loss: 1.2830 - val_accuracy: 0.4088

Epoch 01873: val_loss did not improve from 1.27461
Epoch 1874/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4322 - val_loss: 1.2792 - val_accuracy: 0.4064

Epoch 01874: val_loss did not improve from 1.27461
Epoch 1875/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4308 - val_loss: 1.2788 - val_accuracy: 0.4151

Epoch 01875: val_loss did not improve from 1.27461
Epoch 1876/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4323 - val_loss: 1.2826 - val_accuracy: 0.4120

Epoch 01876: val_loss did not improve from 1.27461
Epoch 1877/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4348 - val_loss: 1.2743 - val_accuracy: 0.4167

Epoch 01877: val_loss improved from 1.27461 to 1.27429, saving model to ./results/NN_thk_class/aggr_theta/ckpt_5
Epoch 1878/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4317 - val_loss: 1.2819 - val_accuracy: 0.4088

Epoch 01878: val_loss did not improve from 1.27429
Epoch 1879/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4324 - val_loss: 1.2794 - val_accuracy: 0.4112

Epoch 01879: val_loss did not improve from 1.27429
Epoch 1880/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4312 - val_loss: 1.2825 - val_accuracy: 0.4072

Epoch 01880: val_loss did not improve from 1.27429
Epoch 1881/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4305 - val_loss: 1.2769 - val_accuracy: 0.4151

Epoch 01881: val_loss did not improve from 1.27429
Epoch 1882/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4275 - val_loss: 1.2794 - val_accuracy: 0.4104

Epoch 01882: val_loss did not improve from 1.27429
Epoch 1883/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4331 - val_loss: 1.2774 - val_accuracy: 0.4143

Epoch 01883: val_loss did not improve from 1.27429
Epoch 1884/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4293 - val_loss: 1.2802 - val_accuracy: 0.4159

Epoch 01884: val_loss did not improve from 1.27429
Epoch 1885/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4358 - val_loss: 1.2781 - val_accuracy: 0.4112

Epoch 01885: val_loss did not improve from 1.27429
Epoch 1886/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4275 - val_loss: 1.2828 - val_accuracy: 0.4167

Epoch 01886: val_loss did not improve from 1.27429
Epoch 1887/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4272 - val_loss: 1.2911 - val_accuracy: 0.4127

Epoch 01887: val_loss did not improve from 1.27429
Epoch 1888/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4313 - val_loss: 1.2937 - val_accuracy: 0.4088

Epoch 01888: val_loss did not improve from 1.27429
Epoch 1889/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4246 - val_loss: 1.2805 - val_accuracy: 0.4096

Epoch 01889: val_loss did not improve from 1.27429
Epoch 1890/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4302 - val_loss: 1.2792 - val_accuracy: 0.4151

Epoch 01890: val_loss did not improve from 1.27429
Epoch 1891/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4284 - val_loss: 1.2796 - val_accuracy: 0.4175

Epoch 01891: val_loss did not improve from 1.27429
Epoch 1892/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4315 - val_loss: 1.2796 - val_accuracy: 0.4151

Epoch 01892: val_loss did not improve from 1.27429
Epoch 1893/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4286 - val_loss: 1.2793 - val_accuracy: 0.4151

Epoch 01893: val_loss did not improve from 1.27429
Epoch 1894/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4295 - val_loss: 1.2810 - val_accuracy: 0.4175

Epoch 01894: val_loss did not improve from 1.27429
Epoch 1895/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4282 - val_loss: 1.2790 - val_accuracy: 0.4199

Epoch 01895: val_loss did not improve from 1.27429
Epoch 1896/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4351 - val_loss: 1.2825 - val_accuracy: 0.4088

Epoch 01896: val_loss did not improve from 1.27429
Epoch 1897/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4260 - val_loss: 1.2827 - val_accuracy: 0.4088

Epoch 01897: val_loss did not improve from 1.27429
Epoch 1898/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4343 - val_loss: 1.2820 - val_accuracy: 0.4096

Epoch 01898: val_loss did not improve from 1.27429
Epoch 1899/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4339 - val_loss: 1.2813 - val_accuracy: 0.4159

Epoch 01899: val_loss did not improve from 1.27429
Epoch 1900/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4314 - val_loss: 1.2869 - val_accuracy: 0.4064

Epoch 01900: val_loss did not improve from 1.27429
Epoch 1901/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4306 - val_loss: 1.2802 - val_accuracy: 0.4056

Epoch 01901: val_loss did not improve from 1.27429
Epoch 1902/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4314 - val_loss: 1.2774 - val_accuracy: 0.4096

Epoch 01902: val_loss did not improve from 1.27429
Epoch 1903/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4322 - val_loss: 1.2793 - val_accuracy: 0.4159

Epoch 01903: val_loss did not improve from 1.27429
Epoch 1904/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4305 - val_loss: 1.2824 - val_accuracy: 0.4167

Epoch 01904: val_loss did not improve from 1.27429
Epoch 1905/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4314 - val_loss: 1.2805 - val_accuracy: 0.4191

Epoch 01905: val_loss did not improve from 1.27429
Epoch 1906/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4257 - val_loss: 1.2822 - val_accuracy: 0.4112

Epoch 01906: val_loss did not improve from 1.27429
Epoch 1907/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4296 - val_loss: 1.2853 - val_accuracy: 0.4135

Epoch 01907: val_loss did not improve from 1.27429
Epoch 1908/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4286 - val_loss: 1.2815 - val_accuracy: 0.4151

Epoch 01908: val_loss did not improve from 1.27429
Epoch 1909/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4323 - val_loss: 1.2777 - val_accuracy: 0.4159

Epoch 01909: val_loss did not improve from 1.27429
Epoch 1910/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4313 - val_loss: 1.2815 - val_accuracy: 0.4112

Epoch 01910: val_loss did not improve from 1.27429
Epoch 1911/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4309 - val_loss: 1.2809 - val_accuracy: 0.4080

Epoch 01911: val_loss did not improve from 1.27429
Epoch 1912/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4301 - val_loss: 1.2788 - val_accuracy: 0.4175

Epoch 01912: val_loss did not improve from 1.27429
Epoch 1913/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4284 - val_loss: 1.2900 - val_accuracy: 0.4096

Epoch 01913: val_loss did not improve from 1.27429
Epoch 1914/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4287 - val_loss: 1.2883 - val_accuracy: 0.4064

Epoch 01914: val_loss did not improve from 1.27429
Epoch 1915/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4253 - val_loss: 1.2788 - val_accuracy: 0.4159

Epoch 01915: val_loss did not improve from 1.27429
Epoch 1916/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4357 - val_loss: 1.2769 - val_accuracy: 0.4239

Epoch 01916: val_loss did not improve from 1.27429
Epoch 1917/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4343 - val_loss: 1.2841 - val_accuracy: 0.4120

Epoch 01917: val_loss did not improve from 1.27429
Epoch 1918/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4296 - val_loss: 1.2777 - val_accuracy: 0.4151

Epoch 01918: val_loss did not improve from 1.27429
Epoch 1919/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4346 - val_loss: 1.2807 - val_accuracy: 0.4080

Epoch 01919: val_loss did not improve from 1.27429
Epoch 1920/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4323 - val_loss: 1.2853 - val_accuracy: 0.4008

Epoch 01920: val_loss did not improve from 1.27429
Epoch 1921/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4268 - val_loss: 1.2793 - val_accuracy: 0.4151

Epoch 01921: val_loss did not improve from 1.27429
Epoch 1922/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4320 - val_loss: 1.2785 - val_accuracy: 0.4175

Epoch 01922: val_loss did not improve from 1.27429
Epoch 1923/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4312 - val_loss: 1.2797 - val_accuracy: 0.4143

Epoch 01923: val_loss did not improve from 1.27429
Epoch 1924/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4310 - val_loss: 1.2785 - val_accuracy: 0.4143

Epoch 01924: val_loss did not improve from 1.27429
Epoch 1925/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4297 - val_loss: 1.2846 - val_accuracy: 0.4143

Epoch 01925: val_loss did not improve from 1.27429
Epoch 1926/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4288 - val_loss: 1.2837 - val_accuracy: 0.4191

Epoch 01926: val_loss did not improve from 1.27429
Epoch 1927/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4318 - val_loss: 1.2901 - val_accuracy: 0.4048

Epoch 01927: val_loss did not improve from 1.27429
Epoch 1928/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4263 - val_loss: 1.2829 - val_accuracy: 0.4143

Epoch 01928: val_loss did not improve from 1.27429
Epoch 1929/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4287 - val_loss: 1.2872 - val_accuracy: 0.4159

Epoch 01929: val_loss did not improve from 1.27429
Epoch 1930/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4340 - val_loss: 1.2910 - val_accuracy: 0.4072

Epoch 01930: val_loss did not improve from 1.27429
Epoch 1931/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4284 - val_loss: 1.2836 - val_accuracy: 0.4159

Epoch 01931: val_loss did not improve from 1.27429
Epoch 1932/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4310 - val_loss: 1.2801 - val_accuracy: 0.4159

Epoch 01932: val_loss did not improve from 1.27429
Epoch 1933/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4221 - val_loss: 1.2869 - val_accuracy: 0.4135

Epoch 01933: val_loss did not improve from 1.27429
Epoch 1934/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4277 - val_loss: 1.2833 - val_accuracy: 0.4072

Epoch 01934: val_loss did not improve from 1.27429
Epoch 1935/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4275 - val_loss: 1.2851 - val_accuracy: 0.4064

Epoch 01935: val_loss did not improve from 1.27429
Epoch 1936/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4285 - val_loss: 1.2812 - val_accuracy: 0.4151

Epoch 01936: val_loss did not improve from 1.27429
Epoch 1937/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4276 - val_loss: 1.2796 - val_accuracy: 0.4167

Epoch 01937: val_loss did not improve from 1.27429
Epoch 1938/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4329 - val_loss: 1.2786 - val_accuracy: 0.4167

Epoch 01938: val_loss did not improve from 1.27429
Epoch 1939/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4339 - val_loss: 1.2766 - val_accuracy: 0.4207

Epoch 01939: val_loss did not improve from 1.27429
Epoch 1940/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4276 - val_loss: 1.2820 - val_accuracy: 0.4159

Epoch 01940: val_loss did not improve from 1.27429
Epoch 1941/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4299 - val_loss: 1.2803 - val_accuracy: 0.4127

Epoch 01941: val_loss did not improve from 1.27429
Epoch 1942/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4297 - val_loss: 1.2800 - val_accuracy: 0.4255

Epoch 01942: val_loss did not improve from 1.27429
Epoch 1943/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4340 - val_loss: 1.2808 - val_accuracy: 0.4239

Epoch 01943: val_loss did not improve from 1.27429
Epoch 1944/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4319 - val_loss: 1.2772 - val_accuracy: 0.4183

Epoch 01944: val_loss did not improve from 1.27429
Epoch 1945/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4307 - val_loss: 1.2769 - val_accuracy: 0.4239

Epoch 01945: val_loss did not improve from 1.27429
Epoch 1946/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4305 - val_loss: 1.2795 - val_accuracy: 0.4263

Epoch 01946: val_loss did not improve from 1.27429
Epoch 1947/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4351 - val_loss: 1.2813 - val_accuracy: 0.4199

Epoch 01947: val_loss did not improve from 1.27429
Epoch 1948/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4294 - val_loss: 1.2820 - val_accuracy: 0.4120

Epoch 01948: val_loss did not improve from 1.27429
Epoch 1949/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4342 - val_loss: 1.2818 - val_accuracy: 0.4127

Epoch 01949: val_loss did not improve from 1.27429
Epoch 1950/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4314 - val_loss: 1.2801 - val_accuracy: 0.4104

Epoch 01950: val_loss did not improve from 1.27429
Epoch 1951/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4237 - val_loss: 1.2822 - val_accuracy: 0.4120

Epoch 01951: val_loss did not improve from 1.27429
Epoch 1952/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4246 - val_loss: 1.2908 - val_accuracy: 0.4104

Epoch 01952: val_loss did not improve from 1.27429
Epoch 1953/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4346 - val_loss: 1.2800 - val_accuracy: 0.4231

Epoch 01953: val_loss did not improve from 1.27429
Epoch 1954/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4345 - val_loss: 1.2798 - val_accuracy: 0.4183

Epoch 01954: val_loss did not improve from 1.27429
Epoch 1955/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4263 - val_loss: 1.2811 - val_accuracy: 0.4120

Epoch 01955: val_loss did not improve from 1.27429
Epoch 1956/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4291 - val_loss: 1.2805 - val_accuracy: 0.4151

Epoch 01956: val_loss did not improve from 1.27429
Epoch 1957/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4316 - val_loss: 1.2888 - val_accuracy: 0.4056

Epoch 01957: val_loss did not improve from 1.27429
Epoch 1958/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4358 - val_loss: 1.2804 - val_accuracy: 0.4143

Epoch 01958: val_loss did not improve from 1.27429
Epoch 1959/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4315 - val_loss: 1.2803 - val_accuracy: 0.4120

Epoch 01959: val_loss did not improve from 1.27429
Epoch 1960/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4329 - val_loss: 1.2825 - val_accuracy: 0.4135

Epoch 01960: val_loss did not improve from 1.27429
Epoch 1961/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4318 - val_loss: 1.2829 - val_accuracy: 0.4183

Epoch 01961: val_loss did not improve from 1.27429
Epoch 1962/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4324 - val_loss: 1.2841 - val_accuracy: 0.4048

Epoch 01962: val_loss did not improve from 1.27429
Epoch 1963/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4266 - val_loss: 1.2843 - val_accuracy: 0.4143

Epoch 01963: val_loss did not improve from 1.27429
Epoch 1964/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4303 - val_loss: 1.2792 - val_accuracy: 0.4143

Epoch 01964: val_loss did not improve from 1.27429
Epoch 1965/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4316 - val_loss: 1.2802 - val_accuracy: 0.4056

Epoch 01965: val_loss did not improve from 1.27429
Epoch 1966/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4314 - val_loss: 1.2791 - val_accuracy: 0.4215

Epoch 01966: val_loss did not improve from 1.27429
Epoch 1967/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4297 - val_loss: 1.2795 - val_accuracy: 0.4104

Epoch 01967: val_loss did not improve from 1.27429
Epoch 1968/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4296 - val_loss: 1.2812 - val_accuracy: 0.4191

Epoch 01968: val_loss did not improve from 1.27429
Epoch 1969/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4293 - val_loss: 1.2813 - val_accuracy: 0.4175

Epoch 01969: val_loss did not improve from 1.27429
Epoch 1970/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4308 - val_loss: 1.2777 - val_accuracy: 0.4120

Epoch 01970: val_loss did not improve from 1.27429
Epoch 1971/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4293 - val_loss: 1.2813 - val_accuracy: 0.4135

Epoch 01971: val_loss did not improve from 1.27429
Epoch 1972/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4290 - val_loss: 1.2781 - val_accuracy: 0.4175

Epoch 01972: val_loss did not improve from 1.27429
Epoch 1973/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4294 - val_loss: 1.2831 - val_accuracy: 0.4159

Epoch 01973: val_loss did not improve from 1.27429
Epoch 1974/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4306 - val_loss: 1.2839 - val_accuracy: 0.3992

Epoch 01974: val_loss did not improve from 1.27429
Epoch 1975/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4296 - val_loss: 1.2814 - val_accuracy: 0.4016

Epoch 01975: val_loss did not improve from 1.27429
Epoch 1976/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4301 - val_loss: 1.2757 - val_accuracy: 0.4247

Epoch 01976: val_loss did not improve from 1.27429
Epoch 1977/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4289 - val_loss: 1.2813 - val_accuracy: 0.4207

Epoch 01977: val_loss did not improve from 1.27429
Epoch 1978/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4345 - val_loss: 1.2782 - val_accuracy: 0.4207

Epoch 01978: val_loss did not improve from 1.27429
Epoch 1979/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4276 - val_loss: 1.2827 - val_accuracy: 0.4112

Epoch 01979: val_loss did not improve from 1.27429
Epoch 1980/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4304 - val_loss: 1.2843 - val_accuracy: 0.4151

Epoch 01980: val_loss did not improve from 1.27429
Epoch 1981/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4337 - val_loss: 1.2797 - val_accuracy: 0.4247

Epoch 01981: val_loss did not improve from 1.27429
Epoch 1982/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4313 - val_loss: 1.2842 - val_accuracy: 0.4088

Epoch 01982: val_loss did not improve from 1.27429
Epoch 1983/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4322 - val_loss: 1.2925 - val_accuracy: 0.4056

Epoch 01983: val_loss did not improve from 1.27429
Epoch 1984/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4298 - val_loss: 1.2838 - val_accuracy: 0.4159

Epoch 01984: val_loss did not improve from 1.27429
Epoch 1985/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4338 - val_loss: 1.2841 - val_accuracy: 0.4104

Epoch 01985: val_loss did not improve from 1.27429
Epoch 1986/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4351 - val_loss: 1.2762 - val_accuracy: 0.4239

Epoch 01986: val_loss did not improve from 1.27429
Epoch 1987/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4299 - val_loss: 1.2811 - val_accuracy: 0.4167

Epoch 01987: val_loss did not improve from 1.27429
Epoch 1988/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4339 - val_loss: 1.2788 - val_accuracy: 0.4247

Epoch 01988: val_loss did not improve from 1.27429
Epoch 1989/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4300 - val_loss: 1.2806 - val_accuracy: 0.4135

Epoch 01989: val_loss did not improve from 1.27429
Epoch 1990/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4297 - val_loss: 1.2786 - val_accuracy: 0.4143

Epoch 01990: val_loss did not improve from 1.27429
Epoch 1991/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4302 - val_loss: 1.2827 - val_accuracy: 0.4127

Epoch 01991: val_loss did not improve from 1.27429
Epoch 1992/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4305 - val_loss: 1.2765 - val_accuracy: 0.4175

Epoch 01992: val_loss did not improve from 1.27429
Epoch 1993/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4299 - val_loss: 1.2812 - val_accuracy: 0.4064

Epoch 01993: val_loss did not improve from 1.27429
Epoch 1994/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4338 - val_loss: 1.2803 - val_accuracy: 0.4191

Epoch 01994: val_loss did not improve from 1.27429
Epoch 1995/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4309 - val_loss: 1.2762 - val_accuracy: 0.4159

Epoch 01995: val_loss did not improve from 1.27429
Epoch 1996/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4260 - val_loss: 1.2802 - val_accuracy: 0.4080

Epoch 01996: val_loss did not improve from 1.27429
Epoch 1997/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4269 - val_loss: 1.2846 - val_accuracy: 0.4064

Epoch 01997: val_loss did not improve from 1.27429
Epoch 1998/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4244 - val_loss: 1.2794 - val_accuracy: 0.4096

Epoch 01998: val_loss did not improve from 1.27429
Epoch 1999/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4300 - val_loss: 1.2839 - val_accuracy: 0.4032

Epoch 01999: val_loss did not improve from 1.27429
Epoch 2000/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4316 - val_loss: 1.2951 - val_accuracy: 0.3992

Epoch 02000: val_loss did not improve from 1.27429
Epoch 2001/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4254 - val_loss: 1.2852 - val_accuracy: 0.4127

Epoch 02001: val_loss did not improve from 1.27429
Epoch 2002/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4275 - val_loss: 1.2824 - val_accuracy: 0.4088

Epoch 02002: val_loss did not improve from 1.27429
Epoch 2003/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4299 - val_loss: 1.2820 - val_accuracy: 0.4239

Epoch 02003: val_loss did not improve from 1.27429
Epoch 2004/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4280 - val_loss: 1.2778 - val_accuracy: 0.4215

Epoch 02004: val_loss did not improve from 1.27429
Epoch 2005/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4303 - val_loss: 1.2783 - val_accuracy: 0.4143

Epoch 02005: val_loss did not improve from 1.27429
Epoch 2006/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4322 - val_loss: 1.2873 - val_accuracy: 0.4112

Epoch 02006: val_loss did not improve from 1.27429
Epoch 2007/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4283 - val_loss: 1.2799 - val_accuracy: 0.4175

Epoch 02007: val_loss did not improve from 1.27429
Epoch 2008/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4299 - val_loss: 1.2794 - val_accuracy: 0.4191

Epoch 02008: val_loss did not improve from 1.27429
Epoch 2009/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4275 - val_loss: 1.2831 - val_accuracy: 0.4175

Epoch 02009: val_loss did not improve from 1.27429
Epoch 2010/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4331 - val_loss: 1.2814 - val_accuracy: 0.4231

Epoch 02010: val_loss did not improve from 1.27429
Epoch 2011/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4307 - val_loss: 1.2831 - val_accuracy: 0.4239

Epoch 02011: val_loss did not improve from 1.27429
Epoch 2012/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4309 - val_loss: 1.2813 - val_accuracy: 0.4167

Epoch 02012: val_loss did not improve from 1.27429
Epoch 2013/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4311 - val_loss: 1.2814 - val_accuracy: 0.4183

Epoch 02013: val_loss did not improve from 1.27429
Epoch 2014/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4309 - val_loss: 1.2773 - val_accuracy: 0.4159

Epoch 02014: val_loss did not improve from 1.27429
Epoch 2015/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4332 - val_loss: 1.2836 - val_accuracy: 0.4112

Epoch 02015: val_loss did not improve from 1.27429
Epoch 2016/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4283 - val_loss: 1.2780 - val_accuracy: 0.4088

Epoch 02016: val_loss did not improve from 1.27429
Epoch 2017/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4323 - val_loss: 1.2821 - val_accuracy: 0.4104

Epoch 02017: val_loss did not improve from 1.27429
Epoch 2018/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4336 - val_loss: 1.2781 - val_accuracy: 0.4080

Epoch 02018: val_loss did not improve from 1.27429
Epoch 2019/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4343 - val_loss: 1.2780 - val_accuracy: 0.4112

Epoch 02019: val_loss did not improve from 1.27429
Epoch 2020/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4322 - val_loss: 1.2785 - val_accuracy: 0.4080

Epoch 02020: val_loss did not improve from 1.27429
Epoch 2021/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4353 - val_loss: 1.2790 - val_accuracy: 0.4143

Epoch 02021: val_loss did not improve from 1.27429
Epoch 2022/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4333 - val_loss: 1.2821 - val_accuracy: 0.4104

Epoch 02022: val_loss did not improve from 1.27429
Epoch 2023/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4321 - val_loss: 1.2804 - val_accuracy: 0.4127

Epoch 02023: val_loss did not improve from 1.27429
Epoch 2024/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4311 - val_loss: 1.2815 - val_accuracy: 0.4104

Epoch 02024: val_loss did not improve from 1.27429
Epoch 2025/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4328 - val_loss: 1.2843 - val_accuracy: 0.4207

Epoch 02025: val_loss did not improve from 1.27429
Epoch 2026/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4349 - val_loss: 1.2829 - val_accuracy: 0.4191

Epoch 02026: val_loss did not improve from 1.27429
Epoch 2027/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4326 - val_loss: 1.2823 - val_accuracy: 0.4135

Epoch 02027: val_loss did not improve from 1.27429
Epoch 2028/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4339 - val_loss: 1.2791 - val_accuracy: 0.4183

Epoch 02028: val_loss did not improve from 1.27429
Epoch 2029/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4335 - val_loss: 1.2811 - val_accuracy: 0.4127

Epoch 02029: val_loss did not improve from 1.27429
Epoch 2030/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4269 - val_loss: 1.2773 - val_accuracy: 0.4151

Epoch 02030: val_loss did not improve from 1.27429
Epoch 2031/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4305 - val_loss: 1.2868 - val_accuracy: 0.4112

Epoch 02031: val_loss did not improve from 1.27429
Epoch 2032/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4267 - val_loss: 1.2776 - val_accuracy: 0.4080

Epoch 02032: val_loss did not improve from 1.27429
Epoch 2033/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4364 - val_loss: 1.2835 - val_accuracy: 0.4120

Epoch 02033: val_loss did not improve from 1.27429
Epoch 2034/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4358 - val_loss: 1.2856 - val_accuracy: 0.4143

Epoch 02034: val_loss did not improve from 1.27429
Epoch 2035/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4284 - val_loss: 1.2806 - val_accuracy: 0.4112

Epoch 02035: val_loss did not improve from 1.27429
Epoch 2036/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4317 - val_loss: 1.2767 - val_accuracy: 0.4191

Epoch 02036: val_loss did not improve from 1.27429
Epoch 2037/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4305 - val_loss: 1.2781 - val_accuracy: 0.4207

Epoch 02037: val_loss did not improve from 1.27429
Epoch 2038/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4345 - val_loss: 1.2789 - val_accuracy: 0.4135

Epoch 02038: val_loss did not improve from 1.27429
Epoch 2039/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4314 - val_loss: 1.2777 - val_accuracy: 0.4151

Epoch 02039: val_loss did not improve from 1.27429
Epoch 2040/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4344 - val_loss: 1.2788 - val_accuracy: 0.4104

Epoch 02040: val_loss did not improve from 1.27429
Epoch 2041/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4305 - val_loss: 1.2764 - val_accuracy: 0.4151

Epoch 02041: val_loss did not improve from 1.27429
Epoch 2042/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4336 - val_loss: 1.2822 - val_accuracy: 0.4143

Epoch 02042: val_loss did not improve from 1.27429
Epoch 2043/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4333 - val_loss: 1.2790 - val_accuracy: 0.4175

Epoch 02043: val_loss did not improve from 1.27429
Epoch 2044/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4298 - val_loss: 1.2823 - val_accuracy: 0.4159

Epoch 02044: val_loss did not improve from 1.27429
Epoch 2045/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4298 - val_loss: 1.2804 - val_accuracy: 0.4215

Epoch 02045: val_loss did not improve from 1.27429
Epoch 2046/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4345 - val_loss: 1.2791 - val_accuracy: 0.4191

Epoch 02046: val_loss did not improve from 1.27429
Epoch 2047/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4296 - val_loss: 1.2750 - val_accuracy: 0.4199

Epoch 02047: val_loss did not improve from 1.27429
Epoch 2048/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4266 - val_loss: 1.2777 - val_accuracy: 0.4247

Epoch 02048: val_loss did not improve from 1.27429
Epoch 2049/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4298 - val_loss: 1.2822 - val_accuracy: 0.4143

Epoch 02049: val_loss did not improve from 1.27429
Epoch 2050/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4313 - val_loss: 1.2818 - val_accuracy: 0.4104

Epoch 02050: val_loss did not improve from 1.27429
Epoch 2051/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4358 - val_loss: 1.2866 - val_accuracy: 0.4112

Epoch 02051: val_loss did not improve from 1.27429
Epoch 2052/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4322 - val_loss: 1.2871 - val_accuracy: 0.3984

Epoch 02052: val_loss did not improve from 1.27429
Epoch 2053/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4306 - val_loss: 1.2778 - val_accuracy: 0.4112

Epoch 02053: val_loss did not improve from 1.27429
Epoch 2054/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4271 - val_loss: 1.2808 - val_accuracy: 0.4088

Epoch 02054: val_loss did not improve from 1.27429
Epoch 2055/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4304 - val_loss: 1.2814 - val_accuracy: 0.4167

Epoch 02055: val_loss did not improve from 1.27429
Epoch 2056/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4325 - val_loss: 1.2780 - val_accuracy: 0.4135

Epoch 02056: val_loss did not improve from 1.27429
Epoch 2057/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4322 - val_loss: 1.2777 - val_accuracy: 0.4247

Epoch 02057: val_loss did not improve from 1.27429
Epoch 2058/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4360 - val_loss: 1.2806 - val_accuracy: 0.4255

Epoch 02058: val_loss did not improve from 1.27429
Epoch 2059/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4328 - val_loss: 1.2826 - val_accuracy: 0.4135

Epoch 02059: val_loss did not improve from 1.27429
Epoch 2060/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4302 - val_loss: 1.2776 - val_accuracy: 0.4207

Epoch 02060: val_loss did not improve from 1.27429
Epoch 2061/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4272 - val_loss: 1.2805 - val_accuracy: 0.4231

Epoch 02061: val_loss did not improve from 1.27429
Epoch 2062/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4294 - val_loss: 1.2831 - val_accuracy: 0.4127

Epoch 02062: val_loss did not improve from 1.27429
Epoch 2063/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4297 - val_loss: 1.2847 - val_accuracy: 0.4032

Epoch 02063: val_loss did not improve from 1.27429
Epoch 2064/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4339 - val_loss: 1.2816 - val_accuracy: 0.4120

Epoch 02064: val_loss did not improve from 1.27429
Epoch 2065/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4337 - val_loss: 1.2813 - val_accuracy: 0.4167

Epoch 02065: val_loss did not improve from 1.27429
Epoch 2066/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4337 - val_loss: 1.2798 - val_accuracy: 0.4112

Epoch 02066: val_loss did not improve from 1.27429
Epoch 2067/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4332 - val_loss: 1.2773 - val_accuracy: 0.4135

Epoch 02067: val_loss did not improve from 1.27429
Epoch 2068/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4339 - val_loss: 1.2782 - val_accuracy: 0.4167

Epoch 02068: val_loss did not improve from 1.27429
Epoch 2069/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4309 - val_loss: 1.2799 - val_accuracy: 0.4151

Epoch 02069: val_loss did not improve from 1.27429
Epoch 2070/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4315 - val_loss: 1.2820 - val_accuracy: 0.4120

Epoch 02070: val_loss did not improve from 1.27429
Epoch 2071/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4329 - val_loss: 1.2802 - val_accuracy: 0.4127

Epoch 02071: val_loss did not improve from 1.27429
Epoch 2072/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4311 - val_loss: 1.2821 - val_accuracy: 0.4151

Epoch 02072: val_loss did not improve from 1.27429
Epoch 2073/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4346 - val_loss: 1.2768 - val_accuracy: 0.4159

Epoch 02073: val_loss did not improve from 1.27429
Epoch 2074/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4335 - val_loss: 1.2771 - val_accuracy: 0.4175

Epoch 02074: val_loss did not improve from 1.27429
Epoch 2075/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4341 - val_loss: 1.2780 - val_accuracy: 0.4183

Epoch 02075: val_loss did not improve from 1.27429
Epoch 2076/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4350 - val_loss: 1.2789 - val_accuracy: 0.4135

Epoch 02076: val_loss did not improve from 1.27429
Epoch 2077/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4306 - val_loss: 1.2797 - val_accuracy: 0.4120

Epoch 02077: val_loss did not improve from 1.27429
Epoch 02077: early stopping
*************************** Fold #: 6 ***************************
Model: "sequential_65"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_260 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_261 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_262 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_263 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.5992 - accuracy: 0.2013 - val_loss: 1.5922 - val_accuracy: 0.2408

Epoch 00001: val_loss improved from inf to 1.59216, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2/10000
12/12 - 0s - loss: 1.5886 - accuracy: 0.2688 - val_loss: 1.5800 - val_accuracy: 0.3054

Epoch 00002: val_loss improved from 1.59216 to 1.58004, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 3/10000
12/12 - 0s - loss: 1.5753 - accuracy: 0.3078 - val_loss: 1.5653 - val_accuracy: 0.3094

Epoch 00003: val_loss improved from 1.58004 to 1.56535, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 4/10000
12/12 - 0s - loss: 1.5591 - accuracy: 0.3234 - val_loss: 1.5480 - val_accuracy: 0.3206

Epoch 00004: val_loss improved from 1.56535 to 1.54801, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 5/10000
12/12 - 0s - loss: 1.5392 - accuracy: 0.3385 - val_loss: 1.5253 - val_accuracy: 0.3325

Epoch 00005: val_loss improved from 1.54801 to 1.52533, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 6/10000
12/12 - 0s - loss: 1.5132 - accuracy: 0.3560 - val_loss: 1.4941 - val_accuracy: 0.3509

Epoch 00006: val_loss improved from 1.52533 to 1.49406, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 7/10000
12/12 - 0s - loss: 1.4815 - accuracy: 0.3400 - val_loss: 1.4602 - val_accuracy: 0.3573

Epoch 00007: val_loss improved from 1.49406 to 1.46015, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 8/10000
12/12 - 0s - loss: 1.4475 - accuracy: 0.3466 - val_loss: 1.4236 - val_accuracy: 0.3700

Epoch 00008: val_loss improved from 1.46015 to 1.42364, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 9/10000
12/12 - 0s - loss: 1.4154 - accuracy: 0.3596 - val_loss: 1.3934 - val_accuracy: 0.3716

Epoch 00009: val_loss improved from 1.42364 to 1.39342, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 10/10000
12/12 - 0s - loss: 1.3887 - accuracy: 0.3682 - val_loss: 1.3763 - val_accuracy: 0.3668

Epoch 00010: val_loss improved from 1.39342 to 1.37632, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 11/10000
12/12 - 0s - loss: 1.3715 - accuracy: 0.3742 - val_loss: 1.3566 - val_accuracy: 0.3652

Epoch 00011: val_loss improved from 1.37632 to 1.35658, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 12/10000
12/12 - 0s - loss: 1.3603 - accuracy: 0.3859 - val_loss: 1.3497 - val_accuracy: 0.3852

Epoch 00012: val_loss improved from 1.35658 to 1.34973, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 13/10000
12/12 - 0s - loss: 1.3554 - accuracy: 0.3890 - val_loss: 1.3433 - val_accuracy: 0.3724

Epoch 00013: val_loss improved from 1.34973 to 1.34332, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 14/10000
12/12 - 0s - loss: 1.3489 - accuracy: 0.3843 - val_loss: 1.3447 - val_accuracy: 0.3652

Epoch 00014: val_loss did not improve from 1.34332
Epoch 15/10000
12/12 - 0s - loss: 1.3464 - accuracy: 0.3858 - val_loss: 1.3383 - val_accuracy: 0.3900

Epoch 00015: val_loss improved from 1.34332 to 1.33832, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 16/10000
12/12 - 0s - loss: 1.3472 - accuracy: 0.3975 - val_loss: 1.3373 - val_accuracy: 0.3955

Epoch 00016: val_loss improved from 1.33832 to 1.33727, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 17/10000
12/12 - 0s - loss: 1.3439 - accuracy: 0.3951 - val_loss: 1.3402 - val_accuracy: 0.3947

Epoch 00017: val_loss did not improve from 1.33727
Epoch 18/10000
12/12 - 0s - loss: 1.3435 - accuracy: 0.3873 - val_loss: 1.3358 - val_accuracy: 0.3708

Epoch 00018: val_loss improved from 1.33727 to 1.33583, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 19/10000
12/12 - 0s - loss: 1.3415 - accuracy: 0.3895 - val_loss: 1.3329 - val_accuracy: 0.3780

Epoch 00019: val_loss improved from 1.33583 to 1.33295, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 20/10000
12/12 - 0s - loss: 1.3410 - accuracy: 0.3948 - val_loss: 1.3385 - val_accuracy: 0.4059

Epoch 00020: val_loss did not improve from 1.33295
Epoch 21/10000
12/12 - 0s - loss: 1.3408 - accuracy: 0.3949 - val_loss: 1.3380 - val_accuracy: 0.4051

Epoch 00021: val_loss did not improve from 1.33295
Epoch 22/10000
12/12 - 0s - loss: 1.3432 - accuracy: 0.3900 - val_loss: 1.3328 - val_accuracy: 0.3764

Epoch 00022: val_loss improved from 1.33295 to 1.33277, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 23/10000
12/12 - 0s - loss: 1.3408 - accuracy: 0.3915 - val_loss: 1.3342 - val_accuracy: 0.3907

Epoch 00023: val_loss did not improve from 1.33277
Epoch 24/10000
12/12 - 0s - loss: 1.3410 - accuracy: 0.3897 - val_loss: 1.3329 - val_accuracy: 0.3788

Epoch 00024: val_loss did not improve from 1.33277
Epoch 25/10000
12/12 - 0s - loss: 1.3385 - accuracy: 0.3885 - val_loss: 1.3347 - val_accuracy: 0.3900

Epoch 00025: val_loss did not improve from 1.33277
Epoch 26/10000
12/12 - 0s - loss: 1.3383 - accuracy: 0.3856 - val_loss: 1.3339 - val_accuracy: 0.3740

Epoch 00026: val_loss did not improve from 1.33277
Epoch 27/10000
12/12 - 0s - loss: 1.3379 - accuracy: 0.3852 - val_loss: 1.3325 - val_accuracy: 0.3828

Epoch 00027: val_loss improved from 1.33277 to 1.33253, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 28/10000
12/12 - 0s - loss: 1.3386 - accuracy: 0.3877 - val_loss: 1.3311 - val_accuracy: 0.3676

Epoch 00028: val_loss improved from 1.33253 to 1.33113, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 29/10000
12/12 - 0s - loss: 1.3374 - accuracy: 0.3847 - val_loss: 1.3339 - val_accuracy: 0.3732

Epoch 00029: val_loss did not improve from 1.33113
Epoch 30/10000
12/12 - 0s - loss: 1.3370 - accuracy: 0.3892 - val_loss: 1.3308 - val_accuracy: 0.3868

Epoch 00030: val_loss improved from 1.33113 to 1.33079, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 31/10000
12/12 - 0s - loss: 1.3367 - accuracy: 0.3942 - val_loss: 1.3295 - val_accuracy: 0.3860

Epoch 00031: val_loss improved from 1.33079 to 1.32945, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 32/10000
12/12 - 0s - loss: 1.3379 - accuracy: 0.3937 - val_loss: 1.3317 - val_accuracy: 0.3947

Epoch 00032: val_loss did not improve from 1.32945
Epoch 33/10000
12/12 - 0s - loss: 1.3365 - accuracy: 0.3896 - val_loss: 1.3323 - val_accuracy: 0.3724

Epoch 00033: val_loss did not improve from 1.32945
Epoch 34/10000
12/12 - 0s - loss: 1.3358 - accuracy: 0.3861 - val_loss: 1.3314 - val_accuracy: 0.3740

Epoch 00034: val_loss did not improve from 1.32945
Epoch 35/10000
12/12 - 0s - loss: 1.3355 - accuracy: 0.3846 - val_loss: 1.3305 - val_accuracy: 0.3716

Epoch 00035: val_loss did not improve from 1.32945
Epoch 36/10000
12/12 - 0s - loss: 1.3352 - accuracy: 0.3952 - val_loss: 1.3291 - val_accuracy: 0.3971

Epoch 00036: val_loss improved from 1.32945 to 1.32911, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 37/10000
12/12 - 0s - loss: 1.3355 - accuracy: 0.3847 - val_loss: 1.3303 - val_accuracy: 0.3660

Epoch 00037: val_loss did not improve from 1.32911
Epoch 38/10000
12/12 - 0s - loss: 1.3357 - accuracy: 0.3871 - val_loss: 1.3313 - val_accuracy: 0.3660

Epoch 00038: val_loss did not improve from 1.32911
Epoch 39/10000
12/12 - 0s - loss: 1.3398 - accuracy: 0.3858 - val_loss: 1.3327 - val_accuracy: 0.3780

Epoch 00039: val_loss did not improve from 1.32911
Epoch 40/10000
12/12 - 0s - loss: 1.3357 - accuracy: 0.3897 - val_loss: 1.3322 - val_accuracy: 0.3987

Epoch 00040: val_loss did not improve from 1.32911
Epoch 41/10000
12/12 - 0s - loss: 1.3355 - accuracy: 0.3883 - val_loss: 1.3307 - val_accuracy: 0.3732

Epoch 00041: val_loss did not improve from 1.32911
Epoch 42/10000
12/12 - 0s - loss: 1.3356 - accuracy: 0.3875 - val_loss: 1.3362 - val_accuracy: 0.3995

Epoch 00042: val_loss did not improve from 1.32911
Epoch 43/10000
12/12 - 0s - loss: 1.3354 - accuracy: 0.3909 - val_loss: 1.3286 - val_accuracy: 0.3820

Epoch 00043: val_loss improved from 1.32911 to 1.32861, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 44/10000
12/12 - 0s - loss: 1.3343 - accuracy: 0.3978 - val_loss: 1.3290 - val_accuracy: 0.3939

Epoch 00044: val_loss did not improve from 1.32861
Epoch 45/10000
12/12 - 0s - loss: 1.3345 - accuracy: 0.3915 - val_loss: 1.3292 - val_accuracy: 0.3716

Epoch 00045: val_loss did not improve from 1.32861
Epoch 46/10000
12/12 - 0s - loss: 1.3335 - accuracy: 0.3911 - val_loss: 1.3322 - val_accuracy: 0.3995

Epoch 00046: val_loss did not improve from 1.32861
Epoch 47/10000
12/12 - 0s - loss: 1.3350 - accuracy: 0.3950 - val_loss: 1.3272 - val_accuracy: 0.3820

Epoch 00047: val_loss improved from 1.32861 to 1.32715, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 48/10000
12/12 - 0s - loss: 1.3366 - accuracy: 0.3931 - val_loss: 1.3325 - val_accuracy: 0.3963

Epoch 00048: val_loss did not improve from 1.32715
Epoch 49/10000
12/12 - 0s - loss: 1.3340 - accuracy: 0.3993 - val_loss: 1.3278 - val_accuracy: 0.3979

Epoch 00049: val_loss did not improve from 1.32715
Epoch 50/10000
12/12 - 0s - loss: 1.3345 - accuracy: 0.3790 - val_loss: 1.3288 - val_accuracy: 0.3844

Epoch 00050: val_loss did not improve from 1.32715
Epoch 51/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3913 - val_loss: 1.3294 - val_accuracy: 0.3748

Epoch 00051: val_loss did not improve from 1.32715
Epoch 52/10000
12/12 - 0s - loss: 1.3337 - accuracy: 0.3893 - val_loss: 1.3308 - val_accuracy: 0.3748

Epoch 00052: val_loss did not improve from 1.32715
Epoch 53/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3926 - val_loss: 1.3287 - val_accuracy: 0.3939

Epoch 00053: val_loss did not improve from 1.32715
Epoch 54/10000
12/12 - 0s - loss: 1.3338 - accuracy: 0.3946 - val_loss: 1.3261 - val_accuracy: 0.3868

Epoch 00054: val_loss improved from 1.32715 to 1.32607, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 55/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3895 - val_loss: 1.3320 - val_accuracy: 0.3764

Epoch 00055: val_loss did not improve from 1.32607
Epoch 56/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3893 - val_loss: 1.3284 - val_accuracy: 0.3868

Epoch 00056: val_loss did not improve from 1.32607
Epoch 57/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.3962 - val_loss: 1.3276 - val_accuracy: 0.3939

Epoch 00057: val_loss did not improve from 1.32607
Epoch 58/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3965 - val_loss: 1.3283 - val_accuracy: 0.3852

Epoch 00058: val_loss did not improve from 1.32607
Epoch 59/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3876 - val_loss: 1.3259 - val_accuracy: 0.3692

Epoch 00059: val_loss improved from 1.32607 to 1.32595, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 60/10000
12/12 - 0s - loss: 1.3337 - accuracy: 0.3860 - val_loss: 1.3253 - val_accuracy: 0.3852

Epoch 00060: val_loss improved from 1.32595 to 1.32526, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 61/10000
12/12 - 0s - loss: 1.3333 - accuracy: 0.3947 - val_loss: 1.3293 - val_accuracy: 0.3947

Epoch 00061: val_loss did not improve from 1.32526
Epoch 62/10000
12/12 - 0s - loss: 1.3326 - accuracy: 0.3935 - val_loss: 1.3267 - val_accuracy: 0.3915

Epoch 00062: val_loss did not improve from 1.32526
Epoch 63/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3929 - val_loss: 1.3260 - val_accuracy: 0.3836

Epoch 00063: val_loss did not improve from 1.32526
Epoch 64/10000
12/12 - 0s - loss: 1.3332 - accuracy: 0.3870 - val_loss: 1.3277 - val_accuracy: 0.3644

Epoch 00064: val_loss did not improve from 1.32526
Epoch 65/10000
12/12 - 0s - loss: 1.3352 - accuracy: 0.3892 - val_loss: 1.3276 - val_accuracy: 0.3963

Epoch 00065: val_loss did not improve from 1.32526
Epoch 66/10000
12/12 - 0s - loss: 1.3309 - accuracy: 0.3974 - val_loss: 1.3240 - val_accuracy: 0.3788

Epoch 00066: val_loss improved from 1.32526 to 1.32403, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 67/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3890 - val_loss: 1.3289 - val_accuracy: 0.3828

Epoch 00067: val_loss did not improve from 1.32403
Epoch 68/10000
12/12 - 0s - loss: 1.3305 - accuracy: 0.3915 - val_loss: 1.3252 - val_accuracy: 0.3828

Epoch 00068: val_loss did not improve from 1.32403
Epoch 69/10000
12/12 - 0s - loss: 1.3304 - accuracy: 0.3953 - val_loss: 1.3239 - val_accuracy: 0.3892

Epoch 00069: val_loss improved from 1.32403 to 1.32393, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 70/10000
12/12 - 0s - loss: 1.3300 - accuracy: 0.3954 - val_loss: 1.3277 - val_accuracy: 0.3939

Epoch 00070: val_loss did not improve from 1.32393
Epoch 71/10000
12/12 - 0s - loss: 1.3307 - accuracy: 0.3943 - val_loss: 1.3280 - val_accuracy: 0.3979

Epoch 00071: val_loss did not improve from 1.32393
Epoch 72/10000
12/12 - 0s - loss: 1.3329 - accuracy: 0.3965 - val_loss: 1.3238 - val_accuracy: 0.3931

Epoch 00072: val_loss improved from 1.32393 to 1.32383, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 73/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3980 - val_loss: 1.3249 - val_accuracy: 0.3995

Epoch 00073: val_loss did not improve from 1.32383
Epoch 74/10000
12/12 - 0s - loss: 1.3301 - accuracy: 0.3896 - val_loss: 1.3290 - val_accuracy: 0.3772

Epoch 00074: val_loss did not improve from 1.32383
Epoch 75/10000
12/12 - 0s - loss: 1.3314 - accuracy: 0.3875 - val_loss: 1.3292 - val_accuracy: 0.3828

Epoch 00075: val_loss did not improve from 1.32383
Epoch 76/10000
12/12 - 0s - loss: 1.3340 - accuracy: 0.3953 - val_loss: 1.3281 - val_accuracy: 0.3676

Epoch 00076: val_loss did not improve from 1.32383
Epoch 77/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3937 - val_loss: 1.3253 - val_accuracy: 0.3915

Epoch 00077: val_loss did not improve from 1.32383
Epoch 78/10000
12/12 - 0s - loss: 1.3321 - accuracy: 0.3938 - val_loss: 1.3355 - val_accuracy: 0.3995

Epoch 00078: val_loss did not improve from 1.32383
Epoch 79/10000
12/12 - 0s - loss: 1.3346 - accuracy: 0.3966 - val_loss: 1.3269 - val_accuracy: 0.3628

Epoch 00079: val_loss did not improve from 1.32383
Epoch 80/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3930 - val_loss: 1.3277 - val_accuracy: 0.3772

Epoch 00080: val_loss did not improve from 1.32383
Epoch 81/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.3892 - val_loss: 1.3238 - val_accuracy: 0.3748

Epoch 00081: val_loss improved from 1.32383 to 1.32382, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 82/10000
12/12 - 0s - loss: 1.3300 - accuracy: 0.3923 - val_loss: 1.3266 - val_accuracy: 0.3884

Epoch 00082: val_loss did not improve from 1.32382
Epoch 83/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.3947 - val_loss: 1.3247 - val_accuracy: 0.3852

Epoch 00083: val_loss did not improve from 1.32382
Epoch 84/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3966 - val_loss: 1.3241 - val_accuracy: 0.3820

Epoch 00084: val_loss did not improve from 1.32382
Epoch 85/10000
12/12 - 0s - loss: 1.3307 - accuracy: 0.3944 - val_loss: 1.3342 - val_accuracy: 0.4011

Epoch 00085: val_loss did not improve from 1.32382
Epoch 86/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3966 - val_loss: 1.3233 - val_accuracy: 0.3836

Epoch 00086: val_loss improved from 1.32382 to 1.32335, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 87/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3976 - val_loss: 1.3236 - val_accuracy: 0.3844

Epoch 00087: val_loss did not improve from 1.32335
Epoch 88/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3912 - val_loss: 1.3237 - val_accuracy: 0.3804

Epoch 00088: val_loss did not improve from 1.32335
Epoch 89/10000
12/12 - 0s - loss: 1.3299 - accuracy: 0.3909 - val_loss: 1.3267 - val_accuracy: 0.3971

Epoch 00089: val_loss did not improve from 1.32335
Epoch 90/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3931 - val_loss: 1.3269 - val_accuracy: 0.3971

Epoch 00090: val_loss did not improve from 1.32335
Epoch 91/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3970 - val_loss: 1.3239 - val_accuracy: 0.3780

Epoch 00091: val_loss did not improve from 1.32335
Epoch 92/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3941 - val_loss: 1.3247 - val_accuracy: 0.3931

Epoch 00092: val_loss did not improve from 1.32335
Epoch 93/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3935 - val_loss: 1.3267 - val_accuracy: 0.3931

Epoch 00093: val_loss did not improve from 1.32335
Epoch 94/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3944 - val_loss: 1.3240 - val_accuracy: 0.3684

Epoch 00094: val_loss did not improve from 1.32335
Epoch 95/10000
12/12 - 0s - loss: 1.3309 - accuracy: 0.3960 - val_loss: 1.3229 - val_accuracy: 0.3772

Epoch 00095: val_loss improved from 1.32335 to 1.32285, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 96/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3958 - val_loss: 1.3223 - val_accuracy: 0.3812

Epoch 00096: val_loss improved from 1.32285 to 1.32230, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 97/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3905 - val_loss: 1.3388 - val_accuracy: 0.4075

Epoch 00097: val_loss did not improve from 1.32230
Epoch 98/10000
12/12 - 0s - loss: 1.3365 - accuracy: 0.3939 - val_loss: 1.3260 - val_accuracy: 0.3828

Epoch 00098: val_loss did not improve from 1.32230
Epoch 99/10000
12/12 - 0s - loss: 1.3301 - accuracy: 0.3972 - val_loss: 1.3247 - val_accuracy: 0.3732

Epoch 00099: val_loss did not improve from 1.32230
Epoch 100/10000
12/12 - 0s - loss: 1.3355 - accuracy: 0.3836 - val_loss: 1.3315 - val_accuracy: 0.4019

Epoch 00100: val_loss did not improve from 1.32230
Epoch 101/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3987 - val_loss: 1.3256 - val_accuracy: 0.3764

Epoch 00101: val_loss did not improve from 1.32230
Epoch 102/10000
12/12 - 0s - loss: 1.3342 - accuracy: 0.3929 - val_loss: 1.3283 - val_accuracy: 0.3947

Epoch 00102: val_loss did not improve from 1.32230
Epoch 103/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3908 - val_loss: 1.3225 - val_accuracy: 0.3636

Epoch 00103: val_loss did not improve from 1.32230
Epoch 104/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3872 - val_loss: 1.3247 - val_accuracy: 0.3652

Epoch 00104: val_loss did not improve from 1.32230
Epoch 105/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3888 - val_loss: 1.3226 - val_accuracy: 0.3692

Epoch 00105: val_loss did not improve from 1.32230
Epoch 106/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3939 - val_loss: 1.3219 - val_accuracy: 0.3836

Epoch 00106: val_loss improved from 1.32230 to 1.32187, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 107/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3854 - val_loss: 1.3258 - val_accuracy: 0.3923

Epoch 00107: val_loss did not improve from 1.32187
Epoch 108/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.3988 - val_loss: 1.3223 - val_accuracy: 0.3892

Epoch 00108: val_loss did not improve from 1.32187
Epoch 109/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3947 - val_loss: 1.3253 - val_accuracy: 0.4003

Epoch 00109: val_loss did not improve from 1.32187
Epoch 110/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3966 - val_loss: 1.3236 - val_accuracy: 0.3907

Epoch 00110: val_loss did not improve from 1.32187
Epoch 111/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3940 - val_loss: 1.3219 - val_accuracy: 0.3820

Epoch 00111: val_loss did not improve from 1.32187
Epoch 112/10000
12/12 - 0s - loss: 1.3299 - accuracy: 0.3925 - val_loss: 1.3291 - val_accuracy: 0.4059

Epoch 00112: val_loss did not improve from 1.32187
Epoch 113/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.4000 - val_loss: 1.3244 - val_accuracy: 0.3828

Epoch 00113: val_loss did not improve from 1.32187
Epoch 114/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3921 - val_loss: 1.3310 - val_accuracy: 0.4003

Epoch 00114: val_loss did not improve from 1.32187
Epoch 115/10000
12/12 - 0s - loss: 1.3292 - accuracy: 0.3967 - val_loss: 1.3213 - val_accuracy: 0.3820

Epoch 00115: val_loss improved from 1.32187 to 1.32126, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 116/10000
12/12 - 0s - loss: 1.3276 - accuracy: 0.3946 - val_loss: 1.3219 - val_accuracy: 0.3828

Epoch 00116: val_loss did not improve from 1.32126
Epoch 117/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3920 - val_loss: 1.3238 - val_accuracy: 0.3955

Epoch 00117: val_loss did not improve from 1.32126
Epoch 118/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3984 - val_loss: 1.3226 - val_accuracy: 0.3979

Epoch 00118: val_loss did not improve from 1.32126
Epoch 119/10000
12/12 - 0s - loss: 1.3282 - accuracy: 0.3960 - val_loss: 1.3229 - val_accuracy: 0.3788

Epoch 00119: val_loss did not improve from 1.32126
Epoch 120/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3914 - val_loss: 1.3234 - val_accuracy: 0.3923

Epoch 00120: val_loss did not improve from 1.32126
Epoch 121/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3959 - val_loss: 1.3226 - val_accuracy: 0.3915

Epoch 00121: val_loss did not improve from 1.32126
Epoch 122/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3939 - val_loss: 1.3226 - val_accuracy: 0.3907

Epoch 00122: val_loss did not improve from 1.32126
Epoch 123/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3955 - val_loss: 1.3215 - val_accuracy: 0.3844

Epoch 00123: val_loss did not improve from 1.32126
Epoch 124/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3962 - val_loss: 1.3239 - val_accuracy: 0.3684

Epoch 00124: val_loss did not improve from 1.32126
Epoch 125/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3926 - val_loss: 1.3215 - val_accuracy: 0.3884

Epoch 00125: val_loss did not improve from 1.32126
Epoch 126/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3958 - val_loss: 1.3218 - val_accuracy: 0.3836

Epoch 00126: val_loss did not improve from 1.32126
Epoch 127/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3954 - val_loss: 1.3210 - val_accuracy: 0.3907

Epoch 00127: val_loss improved from 1.32126 to 1.32101, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 128/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3978 - val_loss: 1.3206 - val_accuracy: 0.3939

Epoch 00128: val_loss improved from 1.32101 to 1.32060, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 129/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3939 - val_loss: 1.3245 - val_accuracy: 0.3923

Epoch 00129: val_loss did not improve from 1.32060
Epoch 130/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3939 - val_loss: 1.3196 - val_accuracy: 0.3852

Epoch 00130: val_loss improved from 1.32060 to 1.31964, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 131/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.3952 - val_loss: 1.3237 - val_accuracy: 0.3987

Epoch 00131: val_loss did not improve from 1.31964
Epoch 132/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3971 - val_loss: 1.3203 - val_accuracy: 0.3939

Epoch 00132: val_loss did not improve from 1.31964
Epoch 133/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3970 - val_loss: 1.3210 - val_accuracy: 0.3939

Epoch 00133: val_loss did not improve from 1.31964
Epoch 134/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3906 - val_loss: 1.3253 - val_accuracy: 0.3828

Epoch 00134: val_loss did not improve from 1.31964
Epoch 135/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3905 - val_loss: 1.3216 - val_accuracy: 0.3780

Epoch 00135: val_loss did not improve from 1.31964
Epoch 136/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3934 - val_loss: 1.3209 - val_accuracy: 0.3884

Epoch 00136: val_loss did not improve from 1.31964
Epoch 137/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3954 - val_loss: 1.3205 - val_accuracy: 0.3836

Epoch 00137: val_loss did not improve from 1.31964
Epoch 138/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3894 - val_loss: 1.3236 - val_accuracy: 0.3892

Epoch 00138: val_loss did not improve from 1.31964
Epoch 139/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3968 - val_loss: 1.3193 - val_accuracy: 0.3939

Epoch 00139: val_loss improved from 1.31964 to 1.31931, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 140/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3963 - val_loss: 1.3197 - val_accuracy: 0.3923

Epoch 00140: val_loss did not improve from 1.31931
Epoch 141/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3966 - val_loss: 1.3237 - val_accuracy: 0.3876

Epoch 00141: val_loss did not improve from 1.31931
Epoch 142/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3951 - val_loss: 1.3221 - val_accuracy: 0.3788

Epoch 00142: val_loss did not improve from 1.31931
Epoch 143/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3954 - val_loss: 1.3203 - val_accuracy: 0.3979

Epoch 00143: val_loss did not improve from 1.31931
Epoch 144/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3916 - val_loss: 1.3243 - val_accuracy: 0.3963

Epoch 00144: val_loss did not improve from 1.31931
Epoch 145/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3994 - val_loss: 1.3203 - val_accuracy: 0.3900

Epoch 00145: val_loss did not improve from 1.31931
Epoch 146/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3967 - val_loss: 1.3195 - val_accuracy: 0.3772

Epoch 00146: val_loss did not improve from 1.31931
Epoch 147/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3968 - val_loss: 1.3216 - val_accuracy: 0.3907

Epoch 00147: val_loss did not improve from 1.31931
Epoch 148/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3979 - val_loss: 1.3185 - val_accuracy: 0.3923

Epoch 00148: val_loss improved from 1.31931 to 1.31852, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 149/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3965 - val_loss: 1.3205 - val_accuracy: 0.3884

Epoch 00149: val_loss did not improve from 1.31852
Epoch 150/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3938 - val_loss: 1.3202 - val_accuracy: 0.3884

Epoch 00150: val_loss did not improve from 1.31852
Epoch 151/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3981 - val_loss: 1.3203 - val_accuracy: 0.3868

Epoch 00151: val_loss did not improve from 1.31852
Epoch 152/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3961 - val_loss: 1.3208 - val_accuracy: 0.3900

Epoch 00152: val_loss did not improve from 1.31852
Epoch 153/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3947 - val_loss: 1.3214 - val_accuracy: 0.3900

Epoch 00153: val_loss did not improve from 1.31852
Epoch 154/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3999 - val_loss: 1.3193 - val_accuracy: 0.3900

Epoch 00154: val_loss did not improve from 1.31852
Epoch 155/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3980 - val_loss: 1.3188 - val_accuracy: 0.3732

Epoch 00155: val_loss did not improve from 1.31852
Epoch 156/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3911 - val_loss: 1.3216 - val_accuracy: 0.3939

Epoch 00156: val_loss did not improve from 1.31852
Epoch 157/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3975 - val_loss: 1.3203 - val_accuracy: 0.3907

Epoch 00157: val_loss did not improve from 1.31852
Epoch 158/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3909 - val_loss: 1.3210 - val_accuracy: 0.3923

Epoch 00158: val_loss did not improve from 1.31852
Epoch 159/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3966 - val_loss: 1.3234 - val_accuracy: 0.3923

Epoch 00159: val_loss did not improve from 1.31852
Epoch 160/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3936 - val_loss: 1.3186 - val_accuracy: 0.3692

Epoch 00160: val_loss did not improve from 1.31852
Epoch 161/10000
12/12 - 0s - loss: 1.3273 - accuracy: 0.3939 - val_loss: 1.3190 - val_accuracy: 0.3860

Epoch 00161: val_loss did not improve from 1.31852
Epoch 162/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3993 - val_loss: 1.3191 - val_accuracy: 0.3931

Epoch 00162: val_loss did not improve from 1.31852
Epoch 163/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.4003 - val_loss: 1.3188 - val_accuracy: 0.3923

Epoch 00163: val_loss did not improve from 1.31852
Epoch 164/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3963 - val_loss: 1.3189 - val_accuracy: 0.3963

Epoch 00164: val_loss did not improve from 1.31852
Epoch 165/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3966 - val_loss: 1.3195 - val_accuracy: 0.3939

Epoch 00165: val_loss did not improve from 1.31852
Epoch 166/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.4000 - val_loss: 1.3182 - val_accuracy: 0.3907

Epoch 00166: val_loss improved from 1.31852 to 1.31818, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 167/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3999 - val_loss: 1.3195 - val_accuracy: 0.3971

Epoch 00167: val_loss did not improve from 1.31818
Epoch 168/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3971 - val_loss: 1.3190 - val_accuracy: 0.3923

Epoch 00168: val_loss did not improve from 1.31818
Epoch 169/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3976 - val_loss: 1.3174 - val_accuracy: 0.3772

Epoch 00169: val_loss improved from 1.31818 to 1.31742, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 170/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3907 - val_loss: 1.3221 - val_accuracy: 0.3740

Epoch 00170: val_loss did not improve from 1.31742
Epoch 171/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3987 - val_loss: 1.3180 - val_accuracy: 0.3900

Epoch 00171: val_loss did not improve from 1.31742
Epoch 172/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3934 - val_loss: 1.3209 - val_accuracy: 0.3923

Epoch 00172: val_loss did not improve from 1.31742
Epoch 173/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3963 - val_loss: 1.3169 - val_accuracy: 0.3900

Epoch 00173: val_loss improved from 1.31742 to 1.31692, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 174/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3984 - val_loss: 1.3173 - val_accuracy: 0.3884

Epoch 00174: val_loss did not improve from 1.31692
Epoch 175/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3933 - val_loss: 1.3226 - val_accuracy: 0.3987

Epoch 00175: val_loss did not improve from 1.31692
Epoch 176/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3982 - val_loss: 1.3193 - val_accuracy: 0.3876

Epoch 00176: val_loss did not improve from 1.31692
Epoch 177/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3904 - val_loss: 1.3185 - val_accuracy: 0.3700

Epoch 00177: val_loss did not improve from 1.31692
Epoch 178/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3866 - val_loss: 1.3209 - val_accuracy: 0.3812

Epoch 00178: val_loss did not improve from 1.31692
Epoch 179/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3962 - val_loss: 1.3170 - val_accuracy: 0.3931

Epoch 00179: val_loss did not improve from 1.31692
Epoch 180/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3970 - val_loss: 1.3179 - val_accuracy: 0.3884

Epoch 00180: val_loss did not improve from 1.31692
Epoch 181/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3963 - val_loss: 1.3198 - val_accuracy: 0.3907

Epoch 00181: val_loss did not improve from 1.31692
Epoch 182/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3930 - val_loss: 1.3183 - val_accuracy: 0.3828

Epoch 00182: val_loss did not improve from 1.31692
Epoch 183/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3904 - val_loss: 1.3191 - val_accuracy: 0.3772

Epoch 00183: val_loss did not improve from 1.31692
Epoch 184/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3900 - val_loss: 1.3249 - val_accuracy: 0.3939

Epoch 00184: val_loss did not improve from 1.31692
Epoch 185/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3983 - val_loss: 1.3184 - val_accuracy: 0.3876

Epoch 00185: val_loss did not improve from 1.31692
Epoch 186/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3991 - val_loss: 1.3170 - val_accuracy: 0.3939

Epoch 00186: val_loss did not improve from 1.31692
Epoch 187/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3968 - val_loss: 1.3183 - val_accuracy: 0.3876

Epoch 00187: val_loss did not improve from 1.31692
Epoch 188/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3957 - val_loss: 1.3167 - val_accuracy: 0.3876

Epoch 00188: val_loss improved from 1.31692 to 1.31674, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 189/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3937 - val_loss: 1.3191 - val_accuracy: 0.3836

Epoch 00189: val_loss did not improve from 1.31674
Epoch 190/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3980 - val_loss: 1.3205 - val_accuracy: 0.3900

Epoch 00190: val_loss did not improve from 1.31674
Epoch 191/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3961 - val_loss: 1.3198 - val_accuracy: 0.3915

Epoch 00191: val_loss did not improve from 1.31674
Epoch 192/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3946 - val_loss: 1.3189 - val_accuracy: 0.3907

Epoch 00192: val_loss did not improve from 1.31674
Epoch 193/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3935 - val_loss: 1.3182 - val_accuracy: 0.3788

Epoch 00193: val_loss did not improve from 1.31674
Epoch 194/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3900 - val_loss: 1.3200 - val_accuracy: 0.3900

Epoch 00194: val_loss did not improve from 1.31674
Epoch 195/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3955 - val_loss: 1.3178 - val_accuracy: 0.3724

Epoch 00195: val_loss did not improve from 1.31674
Epoch 196/10000
12/12 - 0s - loss: 1.3257 - accuracy: 0.3861 - val_loss: 1.3240 - val_accuracy: 0.3844

Epoch 00196: val_loss did not improve from 1.31674
Epoch 197/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3955 - val_loss: 1.3194 - val_accuracy: 0.3955

Epoch 00197: val_loss did not improve from 1.31674
Epoch 198/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3987 - val_loss: 1.3169 - val_accuracy: 0.3892

Epoch 00198: val_loss did not improve from 1.31674
Epoch 199/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3923 - val_loss: 1.3199 - val_accuracy: 0.3907

Epoch 00199: val_loss did not improve from 1.31674
Epoch 200/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3933 - val_loss: 1.3176 - val_accuracy: 0.3772

Epoch 00200: val_loss did not improve from 1.31674
Epoch 201/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3885 - val_loss: 1.3189 - val_accuracy: 0.3732

Epoch 00201: val_loss did not improve from 1.31674
Epoch 202/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3898 - val_loss: 1.3173 - val_accuracy: 0.3923

Epoch 00202: val_loss did not improve from 1.31674
Epoch 203/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3970 - val_loss: 1.3170 - val_accuracy: 0.3884

Epoch 00203: val_loss did not improve from 1.31674
Epoch 204/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3951 - val_loss: 1.3203 - val_accuracy: 0.3931

Epoch 00204: val_loss did not improve from 1.31674
Epoch 205/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3910 - val_loss: 1.3163 - val_accuracy: 0.3852

Epoch 00205: val_loss improved from 1.31674 to 1.31628, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 206/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3985 - val_loss: 1.3171 - val_accuracy: 0.3876

Epoch 00206: val_loss did not improve from 1.31628
Epoch 207/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3978 - val_loss: 1.3175 - val_accuracy: 0.3931

Epoch 00207: val_loss did not improve from 1.31628
Epoch 208/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3958 - val_loss: 1.3167 - val_accuracy: 0.3860

Epoch 00208: val_loss did not improve from 1.31628
Epoch 209/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3956 - val_loss: 1.3153 - val_accuracy: 0.3828

Epoch 00209: val_loss improved from 1.31628 to 1.31532, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 210/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3910 - val_loss: 1.3197 - val_accuracy: 0.3860

Epoch 00210: val_loss did not improve from 1.31532
Epoch 211/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3900 - val_loss: 1.3168 - val_accuracy: 0.3820

Epoch 00211: val_loss did not improve from 1.31532
Epoch 212/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3974 - val_loss: 1.3191 - val_accuracy: 0.3947

Epoch 00212: val_loss did not improve from 1.31532
Epoch 213/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3978 - val_loss: 1.3260 - val_accuracy: 0.3955

Epoch 00213: val_loss did not improve from 1.31532
Epoch 214/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3946 - val_loss: 1.3246 - val_accuracy: 0.3589

Epoch 00214: val_loss did not improve from 1.31532
Epoch 215/10000
12/12 - 0s - loss: 1.3305 - accuracy: 0.3921 - val_loss: 1.3272 - val_accuracy: 0.3923

Epoch 00215: val_loss did not improve from 1.31532
Epoch 216/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3899 - val_loss: 1.3167 - val_accuracy: 0.3931

Epoch 00216: val_loss did not improve from 1.31532
Epoch 217/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3991 - val_loss: 1.3150 - val_accuracy: 0.3955

Epoch 00217: val_loss improved from 1.31532 to 1.31501, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 218/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3951 - val_loss: 1.3190 - val_accuracy: 0.3939

Epoch 00218: val_loss did not improve from 1.31501
Epoch 219/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3967 - val_loss: 1.3182 - val_accuracy: 0.3971

Epoch 00219: val_loss did not improve from 1.31501
Epoch 220/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3954 - val_loss: 1.3159 - val_accuracy: 0.3804

Epoch 00220: val_loss did not improve from 1.31501
Epoch 221/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3933 - val_loss: 1.3190 - val_accuracy: 0.3900

Epoch 00221: val_loss did not improve from 1.31501
Epoch 222/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3958 - val_loss: 1.3163 - val_accuracy: 0.3884

Epoch 00222: val_loss did not improve from 1.31501
Epoch 223/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3980 - val_loss: 1.3179 - val_accuracy: 0.3876

Epoch 00223: val_loss did not improve from 1.31501
Epoch 224/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3995 - val_loss: 1.3184 - val_accuracy: 0.3900

Epoch 00224: val_loss did not improve from 1.31501
Epoch 225/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3986 - val_loss: 1.3161 - val_accuracy: 0.3788

Epoch 00225: val_loss did not improve from 1.31501
Epoch 226/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3882 - val_loss: 1.3183 - val_accuracy: 0.3836

Epoch 00226: val_loss did not improve from 1.31501
Epoch 227/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3912 - val_loss: 1.3166 - val_accuracy: 0.3931

Epoch 00227: val_loss did not improve from 1.31501
Epoch 228/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.4021 - val_loss: 1.3147 - val_accuracy: 0.3923

Epoch 00228: val_loss improved from 1.31501 to 1.31472, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 229/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3963 - val_loss: 1.3176 - val_accuracy: 0.3915

Epoch 00229: val_loss did not improve from 1.31472
Epoch 230/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3923 - val_loss: 1.3166 - val_accuracy: 0.3676

Epoch 00230: val_loss did not improve from 1.31472
Epoch 231/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3897 - val_loss: 1.3164 - val_accuracy: 0.3923

Epoch 00231: val_loss did not improve from 1.31472
Epoch 232/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3981 - val_loss: 1.3169 - val_accuracy: 0.3947

Epoch 00232: val_loss did not improve from 1.31472
Epoch 233/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3970 - val_loss: 1.3153 - val_accuracy: 0.3868

Epoch 00233: val_loss did not improve from 1.31472
Epoch 234/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3987 - val_loss: 1.3148 - val_accuracy: 0.3915

Epoch 00234: val_loss did not improve from 1.31472
Epoch 235/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3965 - val_loss: 1.3173 - val_accuracy: 0.3915

Epoch 00235: val_loss did not improve from 1.31472
Epoch 236/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3985 - val_loss: 1.3186 - val_accuracy: 0.3923

Epoch 00236: val_loss did not improve from 1.31472
Epoch 237/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.4009 - val_loss: 1.3170 - val_accuracy: 0.3963

Epoch 00237: val_loss did not improve from 1.31472
Epoch 238/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3976 - val_loss: 1.3153 - val_accuracy: 0.3931

Epoch 00238: val_loss did not improve from 1.31472
Epoch 239/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3978 - val_loss: 1.3180 - val_accuracy: 0.3876

Epoch 00239: val_loss did not improve from 1.31472
Epoch 240/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.4028 - val_loss: 1.3168 - val_accuracy: 0.3780

Epoch 00240: val_loss did not improve from 1.31472
Epoch 241/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3896 - val_loss: 1.3171 - val_accuracy: 0.3796

Epoch 00241: val_loss did not improve from 1.31472
Epoch 242/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3871 - val_loss: 1.3207 - val_accuracy: 0.3963

Epoch 00242: val_loss did not improve from 1.31472
Epoch 243/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3970 - val_loss: 1.3145 - val_accuracy: 0.3939

Epoch 00243: val_loss improved from 1.31472 to 1.31445, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 244/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3979 - val_loss: 1.3168 - val_accuracy: 0.3915

Epoch 00244: val_loss did not improve from 1.31445
Epoch 245/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3998 - val_loss: 1.3153 - val_accuracy: 0.3955

Epoch 00245: val_loss did not improve from 1.31445
Epoch 246/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3967 - val_loss: 1.3145 - val_accuracy: 0.3900

Epoch 00246: val_loss did not improve from 1.31445
Epoch 247/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3902 - val_loss: 1.3198 - val_accuracy: 0.3931

Epoch 00247: val_loss did not improve from 1.31445
Epoch 248/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3951 - val_loss: 1.3164 - val_accuracy: 0.3915

Epoch 00248: val_loss did not improve from 1.31445
Epoch 249/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3981 - val_loss: 1.3162 - val_accuracy: 0.3868

Epoch 00249: val_loss did not improve from 1.31445
Epoch 250/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3961 - val_loss: 1.3156 - val_accuracy: 0.3915

Epoch 00250: val_loss did not improve from 1.31445
Epoch 251/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3958 - val_loss: 1.3173 - val_accuracy: 0.3923

Epoch 00251: val_loss did not improve from 1.31445
Epoch 252/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3978 - val_loss: 1.3153 - val_accuracy: 0.3947

Epoch 00252: val_loss did not improve from 1.31445
Epoch 253/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3957 - val_loss: 1.3169 - val_accuracy: 0.3868

Epoch 00253: val_loss did not improve from 1.31445
Epoch 254/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3911 - val_loss: 1.3223 - val_accuracy: 0.3939

Epoch 00254: val_loss did not improve from 1.31445
Epoch 255/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3968 - val_loss: 1.3184 - val_accuracy: 0.3900

Epoch 00255: val_loss did not improve from 1.31445
Epoch 256/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3988 - val_loss: 1.3176 - val_accuracy: 0.3860

Epoch 00256: val_loss did not improve from 1.31445
Epoch 257/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3985 - val_loss: 1.3210 - val_accuracy: 0.3915

Epoch 00257: val_loss did not improve from 1.31445
Epoch 258/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3953 - val_loss: 1.3156 - val_accuracy: 0.3947

Epoch 00258: val_loss did not improve from 1.31445
Epoch 259/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3994 - val_loss: 1.3164 - val_accuracy: 0.3844

Epoch 00259: val_loss did not improve from 1.31445
Epoch 260/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3959 - val_loss: 1.3198 - val_accuracy: 0.3907

Epoch 00260: val_loss did not improve from 1.31445
Epoch 261/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3947 - val_loss: 1.3157 - val_accuracy: 0.3860

Epoch 00261: val_loss did not improve from 1.31445
Epoch 262/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3981 - val_loss: 1.3148 - val_accuracy: 0.3892

Epoch 00262: val_loss did not improve from 1.31445
Epoch 263/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3975 - val_loss: 1.3152 - val_accuracy: 0.3987

Epoch 00263: val_loss did not improve from 1.31445
Epoch 264/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3989 - val_loss: 1.3155 - val_accuracy: 0.3923

Epoch 00264: val_loss did not improve from 1.31445
Epoch 265/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3962 - val_loss: 1.3191 - val_accuracy: 0.3979

Epoch 00265: val_loss did not improve from 1.31445
Epoch 266/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.4019 - val_loss: 1.3166 - val_accuracy: 0.3836

Epoch 00266: val_loss did not improve from 1.31445
Epoch 267/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3981 - val_loss: 1.3153 - val_accuracy: 0.3884

Epoch 00267: val_loss did not improve from 1.31445
Epoch 268/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3978 - val_loss: 1.3142 - val_accuracy: 0.3907

Epoch 00268: val_loss improved from 1.31445 to 1.31422, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 269/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3927 - val_loss: 1.3149 - val_accuracy: 0.3708

Epoch 00269: val_loss did not improve from 1.31422
Epoch 270/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3900 - val_loss: 1.3286 - val_accuracy: 0.3868

Epoch 00270: val_loss did not improve from 1.31422
Epoch 271/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3983 - val_loss: 1.3175 - val_accuracy: 0.3907

Epoch 00271: val_loss did not improve from 1.31422
Epoch 272/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3978 - val_loss: 1.3161 - val_accuracy: 0.3892

Epoch 00272: val_loss did not improve from 1.31422
Epoch 273/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3970 - val_loss: 1.3143 - val_accuracy: 0.3931

Epoch 00273: val_loss did not improve from 1.31422
Epoch 274/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3935 - val_loss: 1.3170 - val_accuracy: 0.3892

Epoch 00274: val_loss did not improve from 1.31422
Epoch 275/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3994 - val_loss: 1.3142 - val_accuracy: 0.3852

Epoch 00275: val_loss did not improve from 1.31422
Epoch 276/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3985 - val_loss: 1.3149 - val_accuracy: 0.3915

Epoch 00276: val_loss did not improve from 1.31422
Epoch 277/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3959 - val_loss: 1.3144 - val_accuracy: 0.3836

Epoch 00277: val_loss did not improve from 1.31422
Epoch 278/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3990 - val_loss: 1.3157 - val_accuracy: 0.3892

Epoch 00278: val_loss did not improve from 1.31422
Epoch 279/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.4024 - val_loss: 1.3164 - val_accuracy: 0.3971

Epoch 00279: val_loss did not improve from 1.31422
Epoch 280/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3967 - val_loss: 1.3203 - val_accuracy: 0.4011

Epoch 00280: val_loss did not improve from 1.31422
Epoch 281/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3989 - val_loss: 1.3141 - val_accuracy: 0.3860

Epoch 00281: val_loss improved from 1.31422 to 1.31414, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 282/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3962 - val_loss: 1.3173 - val_accuracy: 0.3923

Epoch 00282: val_loss did not improve from 1.31414
Epoch 283/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3979 - val_loss: 1.3190 - val_accuracy: 0.4067

Epoch 00283: val_loss did not improve from 1.31414
Epoch 284/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3986 - val_loss: 1.3153 - val_accuracy: 0.3740

Epoch 00284: val_loss did not improve from 1.31414
Epoch 285/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3860 - val_loss: 1.3167 - val_accuracy: 0.3772

Epoch 00285: val_loss did not improve from 1.31414
Epoch 286/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3922 - val_loss: 1.3171 - val_accuracy: 0.3923

Epoch 00286: val_loss did not improve from 1.31414
Epoch 287/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.4011 - val_loss: 1.3170 - val_accuracy: 0.3828

Epoch 00287: val_loss did not improve from 1.31414
Epoch 288/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3958 - val_loss: 1.3167 - val_accuracy: 0.3963

Epoch 00288: val_loss did not improve from 1.31414
Epoch 289/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3948 - val_loss: 1.3146 - val_accuracy: 0.3915

Epoch 00289: val_loss did not improve from 1.31414
Epoch 290/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3974 - val_loss: 1.3147 - val_accuracy: 0.3892

Epoch 00290: val_loss did not improve from 1.31414
Epoch 291/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3966 - val_loss: 1.3139 - val_accuracy: 0.3915

Epoch 00291: val_loss improved from 1.31414 to 1.31393, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 292/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3981 - val_loss: 1.3164 - val_accuracy: 0.4019

Epoch 00292: val_loss did not improve from 1.31393
Epoch 293/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3976 - val_loss: 1.3170 - val_accuracy: 0.3907

Epoch 00293: val_loss did not improve from 1.31393
Epoch 294/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3975 - val_loss: 1.3143 - val_accuracy: 0.3820

Epoch 00294: val_loss did not improve from 1.31393
Epoch 295/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.4000 - val_loss: 1.3138 - val_accuracy: 0.3963

Epoch 00295: val_loss improved from 1.31393 to 1.31379, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 296/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3972 - val_loss: 1.3144 - val_accuracy: 0.3868

Epoch 00296: val_loss did not improve from 1.31379
Epoch 297/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3988 - val_loss: 1.3170 - val_accuracy: 0.3987

Epoch 00297: val_loss did not improve from 1.31379
Epoch 298/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3965 - val_loss: 1.3194 - val_accuracy: 0.3907

Epoch 00298: val_loss did not improve from 1.31379
Epoch 299/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3993 - val_loss: 1.3142 - val_accuracy: 0.3931

Epoch 00299: val_loss did not improve from 1.31379
Epoch 300/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3959 - val_loss: 1.3143 - val_accuracy: 0.3923

Epoch 00300: val_loss did not improve from 1.31379
Epoch 301/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3956 - val_loss: 1.3171 - val_accuracy: 0.3923

Epoch 00301: val_loss did not improve from 1.31379
Epoch 302/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3978 - val_loss: 1.3159 - val_accuracy: 0.3915

Epoch 00302: val_loss did not improve from 1.31379
Epoch 303/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3913 - val_loss: 1.3210 - val_accuracy: 0.3860

Epoch 00303: val_loss did not improve from 1.31379
Epoch 304/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3999 - val_loss: 1.3126 - val_accuracy: 0.3892

Epoch 00304: val_loss improved from 1.31379 to 1.31262, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 305/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3970 - val_loss: 1.3125 - val_accuracy: 0.3852

Epoch 00305: val_loss improved from 1.31262 to 1.31253, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 306/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3978 - val_loss: 1.3169 - val_accuracy: 0.3907

Epoch 00306: val_loss did not improve from 1.31253
Epoch 307/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3950 - val_loss: 1.3145 - val_accuracy: 0.3788

Epoch 00307: val_loss did not improve from 1.31253
Epoch 308/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3984 - val_loss: 1.3139 - val_accuracy: 0.4011

Epoch 00308: val_loss did not improve from 1.31253
Epoch 309/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3981 - val_loss: 1.3144 - val_accuracy: 0.3860

Epoch 00309: val_loss did not improve from 1.31253
Epoch 310/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3967 - val_loss: 1.3122 - val_accuracy: 0.3844

Epoch 00310: val_loss improved from 1.31253 to 1.31222, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 311/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3986 - val_loss: 1.3141 - val_accuracy: 0.3844

Epoch 00311: val_loss did not improve from 1.31222
Epoch 312/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3890 - val_loss: 1.3160 - val_accuracy: 0.3836

Epoch 00312: val_loss did not improve from 1.31222
Epoch 313/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3966 - val_loss: 1.3139 - val_accuracy: 0.3868

Epoch 00313: val_loss did not improve from 1.31222
Epoch 314/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3981 - val_loss: 1.3143 - val_accuracy: 0.3892

Epoch 00314: val_loss did not improve from 1.31222
Epoch 315/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3994 - val_loss: 1.3147 - val_accuracy: 0.3987

Epoch 00315: val_loss did not improve from 1.31222
Epoch 316/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3892 - val_loss: 1.3220 - val_accuracy: 0.3892

Epoch 00316: val_loss did not improve from 1.31222
Epoch 317/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3930 - val_loss: 1.3129 - val_accuracy: 0.3876

Epoch 00317: val_loss did not improve from 1.31222
Epoch 318/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3963 - val_loss: 1.3134 - val_accuracy: 0.3931

Epoch 00318: val_loss did not improve from 1.31222
Epoch 319/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3947 - val_loss: 1.3180 - val_accuracy: 0.3828

Epoch 00319: val_loss did not improve from 1.31222
Epoch 320/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3978 - val_loss: 1.3130 - val_accuracy: 0.3971

Epoch 00320: val_loss did not improve from 1.31222
Epoch 321/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3970 - val_loss: 1.3166 - val_accuracy: 0.3860

Epoch 00321: val_loss did not improve from 1.31222
Epoch 322/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3994 - val_loss: 1.3140 - val_accuracy: 0.3987

Epoch 00322: val_loss did not improve from 1.31222
Epoch 323/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3973 - val_loss: 1.3135 - val_accuracy: 0.3900

Epoch 00323: val_loss did not improve from 1.31222
Epoch 324/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3939 - val_loss: 1.3181 - val_accuracy: 0.3995

Epoch 00324: val_loss did not improve from 1.31222
Epoch 325/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.4008 - val_loss: 1.3176 - val_accuracy: 0.3804

Epoch 00325: val_loss did not improve from 1.31222
Epoch 326/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3967 - val_loss: 1.3174 - val_accuracy: 0.4035

Epoch 00326: val_loss did not improve from 1.31222
Epoch 327/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3917 - val_loss: 1.3198 - val_accuracy: 0.3979

Epoch 00327: val_loss did not improve from 1.31222
Epoch 328/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3962 - val_loss: 1.3133 - val_accuracy: 0.3860

Epoch 00328: val_loss did not improve from 1.31222
Epoch 329/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3928 - val_loss: 1.3221 - val_accuracy: 0.3844

Epoch 00329: val_loss did not improve from 1.31222
Epoch 330/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.4009 - val_loss: 1.3138 - val_accuracy: 0.3923

Epoch 00330: val_loss did not improve from 1.31222
Epoch 331/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3954 - val_loss: 1.3199 - val_accuracy: 0.3915

Epoch 00331: val_loss did not improve from 1.31222
Epoch 332/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3993 - val_loss: 1.3131 - val_accuracy: 0.3923

Epoch 00332: val_loss did not improve from 1.31222
Epoch 333/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.4030 - val_loss: 1.3125 - val_accuracy: 0.3907

Epoch 00333: val_loss did not improve from 1.31222
Epoch 334/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3973 - val_loss: 1.3123 - val_accuracy: 0.3939

Epoch 00334: val_loss did not improve from 1.31222
Epoch 335/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3978 - val_loss: 1.3157 - val_accuracy: 0.3884

Epoch 00335: val_loss did not improve from 1.31222
Epoch 336/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.4024 - val_loss: 1.3162 - val_accuracy: 0.3844

Epoch 00336: val_loss did not improve from 1.31222
Epoch 337/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3983 - val_loss: 1.3213 - val_accuracy: 0.3955

Epoch 00337: val_loss did not improve from 1.31222
Epoch 338/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3980 - val_loss: 1.3116 - val_accuracy: 0.3955

Epoch 00338: val_loss improved from 1.31222 to 1.31164, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 339/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3982 - val_loss: 1.3118 - val_accuracy: 0.3860

Epoch 00339: val_loss did not improve from 1.31164
Epoch 340/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3960 - val_loss: 1.3150 - val_accuracy: 0.3852

Epoch 00340: val_loss did not improve from 1.31164
Epoch 341/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3967 - val_loss: 1.3149 - val_accuracy: 0.4067

Epoch 00341: val_loss did not improve from 1.31164
Epoch 342/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3966 - val_loss: 1.3131 - val_accuracy: 0.3796

Epoch 00342: val_loss did not improve from 1.31164
Epoch 343/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3977 - val_loss: 1.3120 - val_accuracy: 0.3884

Epoch 00343: val_loss did not improve from 1.31164
Epoch 344/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3962 - val_loss: 1.3164 - val_accuracy: 0.4003

Epoch 00344: val_loss did not improve from 1.31164
Epoch 345/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3967 - val_loss: 1.3144 - val_accuracy: 0.3923

Epoch 00345: val_loss did not improve from 1.31164
Epoch 346/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.4002 - val_loss: 1.3140 - val_accuracy: 0.4011

Epoch 00346: val_loss did not improve from 1.31164
Epoch 347/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3961 - val_loss: 1.3174 - val_accuracy: 0.3931

Epoch 00347: val_loss did not improve from 1.31164
Epoch 348/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.4012 - val_loss: 1.3135 - val_accuracy: 0.3995

Epoch 00348: val_loss did not improve from 1.31164
Epoch 349/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.4016 - val_loss: 1.3148 - val_accuracy: 0.3772

Epoch 00349: val_loss did not improve from 1.31164
Epoch 350/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3960 - val_loss: 1.3182 - val_accuracy: 0.3931

Epoch 00350: val_loss did not improve from 1.31164
Epoch 351/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3974 - val_loss: 1.3151 - val_accuracy: 0.4043

Epoch 00351: val_loss did not improve from 1.31164
Epoch 352/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3988 - val_loss: 1.3124 - val_accuracy: 0.3868

Epoch 00352: val_loss did not improve from 1.31164
Epoch 353/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3991 - val_loss: 1.3125 - val_accuracy: 0.3955

Epoch 00353: val_loss did not improve from 1.31164
Epoch 354/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3955 - val_loss: 1.3168 - val_accuracy: 0.3971

Epoch 00354: val_loss did not improve from 1.31164
Epoch 355/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.4042 - val_loss: 1.3144 - val_accuracy: 0.3947

Epoch 00355: val_loss did not improve from 1.31164
Epoch 356/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3977 - val_loss: 1.3173 - val_accuracy: 0.3907

Epoch 00356: val_loss did not improve from 1.31164
Epoch 357/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3996 - val_loss: 1.3130 - val_accuracy: 0.3780

Epoch 00357: val_loss did not improve from 1.31164
Epoch 358/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3980 - val_loss: 1.3129 - val_accuracy: 0.3979

Epoch 00358: val_loss did not improve from 1.31164
Epoch 359/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.4001 - val_loss: 1.3145 - val_accuracy: 0.3947

Epoch 00359: val_loss did not improve from 1.31164
Epoch 360/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.4003 - val_loss: 1.3144 - val_accuracy: 0.3963

Epoch 00360: val_loss did not improve from 1.31164
Epoch 361/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3964 - val_loss: 1.3145 - val_accuracy: 0.4027

Epoch 00361: val_loss did not improve from 1.31164
Epoch 362/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3977 - val_loss: 1.3132 - val_accuracy: 0.3915

Epoch 00362: val_loss did not improve from 1.31164
Epoch 363/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.4016 - val_loss: 1.3115 - val_accuracy: 0.3963

Epoch 00363: val_loss improved from 1.31164 to 1.31153, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 364/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.4007 - val_loss: 1.3134 - val_accuracy: 0.3884

Epoch 00364: val_loss did not improve from 1.31153
Epoch 365/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3967 - val_loss: 1.3146 - val_accuracy: 0.3923

Epoch 00365: val_loss did not improve from 1.31153
Epoch 366/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.4000 - val_loss: 1.3126 - val_accuracy: 0.3947

Epoch 00366: val_loss did not improve from 1.31153
Epoch 367/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3985 - val_loss: 1.3122 - val_accuracy: 0.3868

Epoch 00367: val_loss did not improve from 1.31153
Epoch 368/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.4012 - val_loss: 1.3119 - val_accuracy: 0.3860

Epoch 00368: val_loss did not improve from 1.31153
Epoch 369/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4016 - val_loss: 1.3130 - val_accuracy: 0.3963

Epoch 00369: val_loss did not improve from 1.31153
Epoch 370/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.4011 - val_loss: 1.3121 - val_accuracy: 0.3947

Epoch 00370: val_loss did not improve from 1.31153
Epoch 371/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3986 - val_loss: 1.3145 - val_accuracy: 0.3931

Epoch 00371: val_loss did not improve from 1.31153
Epoch 372/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3904 - val_loss: 1.3124 - val_accuracy: 0.3947

Epoch 00372: val_loss did not improve from 1.31153
Epoch 373/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4017 - val_loss: 1.3122 - val_accuracy: 0.3963

Epoch 00373: val_loss did not improve from 1.31153
Epoch 374/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.4011 - val_loss: 1.3225 - val_accuracy: 0.3923

Epoch 00374: val_loss did not improve from 1.31153
Epoch 375/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3984 - val_loss: 1.3137 - val_accuracy: 0.3828

Epoch 00375: val_loss did not improve from 1.31153
Epoch 376/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3961 - val_loss: 1.3168 - val_accuracy: 0.3876

Epoch 00376: val_loss did not improve from 1.31153
Epoch 377/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3984 - val_loss: 1.3112 - val_accuracy: 0.3876

Epoch 00377: val_loss improved from 1.31153 to 1.31118, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 378/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4026 - val_loss: 1.3099 - val_accuracy: 0.3979

Epoch 00378: val_loss improved from 1.31118 to 1.30993, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 379/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3977 - val_loss: 1.3116 - val_accuracy: 0.3907

Epoch 00379: val_loss did not improve from 1.30993
Epoch 380/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3962 - val_loss: 1.3165 - val_accuracy: 0.3987

Epoch 00380: val_loss did not improve from 1.30993
Epoch 381/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3965 - val_loss: 1.3136 - val_accuracy: 0.3947

Epoch 00381: val_loss did not improve from 1.30993
Epoch 382/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3985 - val_loss: 1.3128 - val_accuracy: 0.3979

Epoch 00382: val_loss did not improve from 1.30993
Epoch 383/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3990 - val_loss: 1.3162 - val_accuracy: 0.3931

Epoch 00383: val_loss did not improve from 1.30993
Epoch 384/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4027 - val_loss: 1.3108 - val_accuracy: 0.3979

Epoch 00384: val_loss did not improve from 1.30993
Epoch 385/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.4032 - val_loss: 1.3137 - val_accuracy: 0.3987

Epoch 00385: val_loss did not improve from 1.30993
Epoch 386/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.4024 - val_loss: 1.3107 - val_accuracy: 0.3892

Epoch 00386: val_loss did not improve from 1.30993
Epoch 387/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3983 - val_loss: 1.3148 - val_accuracy: 0.3900

Epoch 00387: val_loss did not improve from 1.30993
Epoch 388/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3969 - val_loss: 1.3126 - val_accuracy: 0.3900

Epoch 00388: val_loss did not improve from 1.30993
Epoch 389/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3999 - val_loss: 1.3124 - val_accuracy: 0.3931

Epoch 00389: val_loss did not improve from 1.30993
Epoch 390/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3992 - val_loss: 1.3097 - val_accuracy: 0.3892

Epoch 00390: val_loss improved from 1.30993 to 1.30966, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 391/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3959 - val_loss: 1.3137 - val_accuracy: 0.4027

Epoch 00391: val_loss did not improve from 1.30966
Epoch 392/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.4017 - val_loss: 1.3112 - val_accuracy: 0.3955

Epoch 00392: val_loss did not improve from 1.30966
Epoch 393/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3967 - val_loss: 1.3122 - val_accuracy: 0.3939

Epoch 00393: val_loss did not improve from 1.30966
Epoch 394/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3877 - val_loss: 1.3151 - val_accuracy: 0.3860

Epoch 00394: val_loss did not improve from 1.30966
Epoch 395/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3982 - val_loss: 1.3110 - val_accuracy: 0.3844

Epoch 00395: val_loss did not improve from 1.30966
Epoch 396/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3927 - val_loss: 1.3296 - val_accuracy: 0.3884

Epoch 00396: val_loss did not improve from 1.30966
Epoch 397/10000
12/12 - 0s - loss: 1.3273 - accuracy: 0.3994 - val_loss: 1.3135 - val_accuracy: 0.3955

Epoch 00397: val_loss did not improve from 1.30966
Epoch 398/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3988 - val_loss: 1.3134 - val_accuracy: 0.3987

Epoch 00398: val_loss did not improve from 1.30966
Epoch 399/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3958 - val_loss: 1.3118 - val_accuracy: 0.4011

Epoch 00399: val_loss did not improve from 1.30966
Epoch 400/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.4009 - val_loss: 1.3107 - val_accuracy: 0.3892

Epoch 00400: val_loss did not improve from 1.30966
Epoch 401/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.4001 - val_loss: 1.3109 - val_accuracy: 0.3955

Epoch 00401: val_loss did not improve from 1.30966
Epoch 402/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3984 - val_loss: 1.3161 - val_accuracy: 0.3955

Epoch 00402: val_loss did not improve from 1.30966
Epoch 403/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.4008 - val_loss: 1.3129 - val_accuracy: 0.3963

Epoch 00403: val_loss did not improve from 1.30966
Epoch 404/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.4017 - val_loss: 1.3116 - val_accuracy: 0.3900

Epoch 00404: val_loss did not improve from 1.30966
Epoch 405/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.4003 - val_loss: 1.3092 - val_accuracy: 0.3939

Epoch 00405: val_loss improved from 1.30966 to 1.30923, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 406/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.4008 - val_loss: 1.3122 - val_accuracy: 0.3979

Epoch 00406: val_loss did not improve from 1.30923
Epoch 407/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.4004 - val_loss: 1.3166 - val_accuracy: 0.4011

Epoch 00407: val_loss did not improve from 1.30923
Epoch 408/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3968 - val_loss: 1.3117 - val_accuracy: 0.3892

Epoch 00408: val_loss did not improve from 1.30923
Epoch 409/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3972 - val_loss: 1.3119 - val_accuracy: 0.3931

Epoch 00409: val_loss did not improve from 1.30923
Epoch 410/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3966 - val_loss: 1.3104 - val_accuracy: 0.3907

Epoch 00410: val_loss did not improve from 1.30923
Epoch 411/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3994 - val_loss: 1.3159 - val_accuracy: 0.3915

Epoch 00411: val_loss did not improve from 1.30923
Epoch 412/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.4041 - val_loss: 1.3106 - val_accuracy: 0.3923

Epoch 00412: val_loss did not improve from 1.30923
Epoch 413/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.4023 - val_loss: 1.3144 - val_accuracy: 0.3995

Epoch 00413: val_loss did not improve from 1.30923
Epoch 414/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4018 - val_loss: 1.3104 - val_accuracy: 0.3812

Epoch 00414: val_loss did not improve from 1.30923
Epoch 415/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3966 - val_loss: 1.3123 - val_accuracy: 0.3900

Epoch 00415: val_loss did not improve from 1.30923
Epoch 416/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.4009 - val_loss: 1.3147 - val_accuracy: 0.3939

Epoch 00416: val_loss did not improve from 1.30923
Epoch 417/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4022 - val_loss: 1.3109 - val_accuracy: 0.3868

Epoch 00417: val_loss did not improve from 1.30923
Epoch 418/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3982 - val_loss: 1.3145 - val_accuracy: 0.3987

Epoch 00418: val_loss did not improve from 1.30923
Epoch 419/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.4033 - val_loss: 1.3108 - val_accuracy: 0.3931

Epoch 00419: val_loss did not improve from 1.30923
Epoch 420/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3996 - val_loss: 1.3111 - val_accuracy: 0.3995

Epoch 00420: val_loss did not improve from 1.30923
Epoch 421/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4030 - val_loss: 1.3113 - val_accuracy: 0.3995

Epoch 00421: val_loss did not improve from 1.30923
Epoch 422/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3983 - val_loss: 1.3122 - val_accuracy: 0.3844

Epoch 00422: val_loss did not improve from 1.30923
Epoch 423/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3994 - val_loss: 1.3103 - val_accuracy: 0.3852

Epoch 00423: val_loss did not improve from 1.30923
Epoch 424/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3981 - val_loss: 1.3104 - val_accuracy: 0.3860

Epoch 00424: val_loss did not improve from 1.30923
Epoch 425/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.4009 - val_loss: 1.3147 - val_accuracy: 0.3939

Epoch 00425: val_loss did not improve from 1.30923
Epoch 426/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4068 - val_loss: 1.3117 - val_accuracy: 0.4019

Epoch 00426: val_loss did not improve from 1.30923
Epoch 427/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4012 - val_loss: 1.3102 - val_accuracy: 0.3828

Epoch 00427: val_loss did not improve from 1.30923
Epoch 428/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3916 - val_loss: 1.3113 - val_accuracy: 0.3900

Epoch 00428: val_loss did not improve from 1.30923
Epoch 429/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3919 - val_loss: 1.3126 - val_accuracy: 0.3979

Epoch 00429: val_loss did not improve from 1.30923
Epoch 430/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3996 - val_loss: 1.3153 - val_accuracy: 0.3868

Epoch 00430: val_loss did not improve from 1.30923
Epoch 431/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.4017 - val_loss: 1.3104 - val_accuracy: 0.3955

Epoch 00431: val_loss did not improve from 1.30923
Epoch 432/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.4008 - val_loss: 1.3103 - val_accuracy: 0.3892

Epoch 00432: val_loss did not improve from 1.30923
Epoch 433/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3933 - val_loss: 1.3114 - val_accuracy: 0.4019

Epoch 00433: val_loss did not improve from 1.30923
Epoch 434/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3999 - val_loss: 1.3090 - val_accuracy: 0.3915

Epoch 00434: val_loss improved from 1.30923 to 1.30899, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 435/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3990 - val_loss: 1.3081 - val_accuracy: 0.3915

Epoch 00435: val_loss improved from 1.30899 to 1.30813, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 436/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3997 - val_loss: 1.3093 - val_accuracy: 0.4011

Epoch 00436: val_loss did not improve from 1.30813
Epoch 437/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3976 - val_loss: 1.3108 - val_accuracy: 0.4011

Epoch 00437: val_loss did not improve from 1.30813
Epoch 438/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3989 - val_loss: 1.3157 - val_accuracy: 0.3955

Epoch 00438: val_loss did not improve from 1.30813
Epoch 439/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.4017 - val_loss: 1.3113 - val_accuracy: 0.3828

Epoch 00439: val_loss did not improve from 1.30813
Epoch 440/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3961 - val_loss: 1.3139 - val_accuracy: 0.4011

Epoch 00440: val_loss did not improve from 1.30813
Epoch 441/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.4023 - val_loss: 1.3087 - val_accuracy: 0.3987

Epoch 00441: val_loss did not improve from 1.30813
Epoch 442/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4033 - val_loss: 1.3109 - val_accuracy: 0.4003

Epoch 00442: val_loss did not improve from 1.30813
Epoch 443/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3978 - val_loss: 1.3130 - val_accuracy: 0.3852

Epoch 00443: val_loss did not improve from 1.30813
Epoch 444/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3930 - val_loss: 1.3110 - val_accuracy: 0.3931

Epoch 00444: val_loss did not improve from 1.30813
Epoch 445/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3977 - val_loss: 1.3130 - val_accuracy: 0.3915

Epoch 00445: val_loss did not improve from 1.30813
Epoch 446/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4021 - val_loss: 1.3091 - val_accuracy: 0.3939

Epoch 00446: val_loss did not improve from 1.30813
Epoch 447/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4011 - val_loss: 1.3089 - val_accuracy: 0.3947

Epoch 00447: val_loss did not improve from 1.30813
Epoch 448/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3976 - val_loss: 1.3109 - val_accuracy: 0.3892

Epoch 00448: val_loss did not improve from 1.30813
Epoch 449/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.4013 - val_loss: 1.3102 - val_accuracy: 0.3987

Epoch 00449: val_loss did not improve from 1.30813
Epoch 450/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.4020 - val_loss: 1.3098 - val_accuracy: 0.4019

Epoch 00450: val_loss did not improve from 1.30813
Epoch 451/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3955 - val_loss: 1.3095 - val_accuracy: 0.3772

Epoch 00451: val_loss did not improve from 1.30813
Epoch 452/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3931 - val_loss: 1.3120 - val_accuracy: 0.4051

Epoch 00452: val_loss did not improve from 1.30813
Epoch 453/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4009 - val_loss: 1.3080 - val_accuracy: 0.3963

Epoch 00453: val_loss improved from 1.30813 to 1.30800, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 454/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3979 - val_loss: 1.3121 - val_accuracy: 0.4027

Epoch 00454: val_loss did not improve from 1.30800
Epoch 455/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4020 - val_loss: 1.3085 - val_accuracy: 0.3892

Epoch 00455: val_loss did not improve from 1.30800
Epoch 456/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3897 - val_loss: 1.3157 - val_accuracy: 0.4027

Epoch 00456: val_loss did not improve from 1.30800
Epoch 457/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4015 - val_loss: 1.3114 - val_accuracy: 0.3995

Epoch 00457: val_loss did not improve from 1.30800
Epoch 458/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3979 - val_loss: 1.3136 - val_accuracy: 0.3963

Epoch 00458: val_loss did not improve from 1.30800
Epoch 459/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3948 - val_loss: 1.3157 - val_accuracy: 0.3915

Epoch 00459: val_loss did not improve from 1.30800
Epoch 460/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3982 - val_loss: 1.3077 - val_accuracy: 0.3868

Epoch 00460: val_loss improved from 1.30800 to 1.30771, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 461/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3994 - val_loss: 1.3080 - val_accuracy: 0.3900

Epoch 00461: val_loss did not improve from 1.30771
Epoch 462/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3985 - val_loss: 1.3120 - val_accuracy: 0.3995

Epoch 00462: val_loss did not improve from 1.30771
Epoch 463/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4002 - val_loss: 1.3088 - val_accuracy: 0.4019

Epoch 00463: val_loss did not improve from 1.30771
Epoch 464/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3973 - val_loss: 1.3132 - val_accuracy: 0.3947

Epoch 00464: val_loss did not improve from 1.30771
Epoch 465/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.4008 - val_loss: 1.3073 - val_accuracy: 0.4011

Epoch 00465: val_loss improved from 1.30771 to 1.30735, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 466/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.4028 - val_loss: 1.3083 - val_accuracy: 0.3939

Epoch 00466: val_loss did not improve from 1.30735
Epoch 467/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3992 - val_loss: 1.3084 - val_accuracy: 0.3939

Epoch 00467: val_loss did not improve from 1.30735
Epoch 468/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3975 - val_loss: 1.3106 - val_accuracy: 0.4019

Epoch 00468: val_loss did not improve from 1.30735
Epoch 469/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.4019 - val_loss: 1.3113 - val_accuracy: 0.4011

Epoch 00469: val_loss did not improve from 1.30735
Epoch 470/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4048 - val_loss: 1.3087 - val_accuracy: 0.3979

Epoch 00470: val_loss did not improve from 1.30735
Epoch 471/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4027 - val_loss: 1.3102 - val_accuracy: 0.4019

Epoch 00471: val_loss did not improve from 1.30735
Epoch 472/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3956 - val_loss: 1.3097 - val_accuracy: 0.3764

Epoch 00472: val_loss did not improve from 1.30735
Epoch 473/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4015 - val_loss: 1.3111 - val_accuracy: 0.3923

Epoch 00473: val_loss did not improve from 1.30735
Epoch 474/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4018 - val_loss: 1.3081 - val_accuracy: 0.3868

Epoch 00474: val_loss did not improve from 1.30735
Epoch 475/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3940 - val_loss: 1.3132 - val_accuracy: 0.4011

Epoch 00475: val_loss did not improve from 1.30735
Epoch 476/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4007 - val_loss: 1.3082 - val_accuracy: 0.4011

Epoch 00476: val_loss did not improve from 1.30735
Epoch 477/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4016 - val_loss: 1.3084 - val_accuracy: 0.4027

Epoch 00477: val_loss did not improve from 1.30735
Epoch 478/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4003 - val_loss: 1.3108 - val_accuracy: 0.4003

Epoch 00478: val_loss did not improve from 1.30735
Epoch 479/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4048 - val_loss: 1.3088 - val_accuracy: 0.3971

Epoch 00479: val_loss did not improve from 1.30735
Epoch 480/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.4043 - val_loss: 1.3078 - val_accuracy: 0.3931

Epoch 00480: val_loss did not improve from 1.30735
Epoch 481/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3915 - val_loss: 1.3123 - val_accuracy: 0.3812

Epoch 00481: val_loss did not improve from 1.30735
Epoch 482/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3952 - val_loss: 1.3091 - val_accuracy: 0.4003

Epoch 00482: val_loss did not improve from 1.30735
Epoch 483/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4036 - val_loss: 1.3091 - val_accuracy: 0.3995

Epoch 00483: val_loss did not improve from 1.30735
Epoch 484/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3974 - val_loss: 1.3091 - val_accuracy: 0.3907

Epoch 00484: val_loss did not improve from 1.30735
Epoch 485/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3998 - val_loss: 1.3084 - val_accuracy: 0.4035

Epoch 00485: val_loss did not improve from 1.30735
Epoch 486/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.4017 - val_loss: 1.3076 - val_accuracy: 0.3971

Epoch 00486: val_loss did not improve from 1.30735
Epoch 487/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.4031 - val_loss: 1.3091 - val_accuracy: 0.3979

Epoch 00487: val_loss did not improve from 1.30735
Epoch 488/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4025 - val_loss: 1.3118 - val_accuracy: 0.4011

Epoch 00488: val_loss did not improve from 1.30735
Epoch 489/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4032 - val_loss: 1.3088 - val_accuracy: 0.4043

Epoch 00489: val_loss did not improve from 1.30735
Epoch 490/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4006 - val_loss: 1.3086 - val_accuracy: 0.3884

Epoch 00490: val_loss did not improve from 1.30735
Epoch 491/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3942 - val_loss: 1.3146 - val_accuracy: 0.3995

Epoch 00491: val_loss did not improve from 1.30735
Epoch 492/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4034 - val_loss: 1.3068 - val_accuracy: 0.3947

Epoch 00492: val_loss improved from 1.30735 to 1.30681, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 493/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.4038 - val_loss: 1.3069 - val_accuracy: 0.3884

Epoch 00493: val_loss did not improve from 1.30681
Epoch 494/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3978 - val_loss: 1.3096 - val_accuracy: 0.3939

Epoch 00494: val_loss did not improve from 1.30681
Epoch 495/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4017 - val_loss: 1.3070 - val_accuracy: 0.3987

Epoch 00495: val_loss did not improve from 1.30681
Epoch 496/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4045 - val_loss: 1.3079 - val_accuracy: 0.4011

Epoch 00496: val_loss did not improve from 1.30681
Epoch 497/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4021 - val_loss: 1.3073 - val_accuracy: 0.3884

Epoch 00497: val_loss did not improve from 1.30681
Epoch 498/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3989 - val_loss: 1.3111 - val_accuracy: 0.3915

Epoch 00498: val_loss did not improve from 1.30681
Epoch 499/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3985 - val_loss: 1.3084 - val_accuracy: 0.3780

Epoch 00499: val_loss did not improve from 1.30681
Epoch 500/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3982 - val_loss: 1.3113 - val_accuracy: 0.3987

Epoch 00500: val_loss did not improve from 1.30681
Epoch 501/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.4033 - val_loss: 1.3082 - val_accuracy: 0.3963

Epoch 00501: val_loss did not improve from 1.30681
Epoch 502/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.4028 - val_loss: 1.3086 - val_accuracy: 0.4027

Epoch 00502: val_loss did not improve from 1.30681
Epoch 503/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3973 - val_loss: 1.3087 - val_accuracy: 0.3915

Epoch 00503: val_loss did not improve from 1.30681
Epoch 504/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4026 - val_loss: 1.3085 - val_accuracy: 0.4035

Epoch 00504: val_loss did not improve from 1.30681
Epoch 505/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.4030 - val_loss: 1.3072 - val_accuracy: 0.3931

Epoch 00505: val_loss did not improve from 1.30681
Epoch 506/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3966 - val_loss: 1.3101 - val_accuracy: 0.4067

Epoch 00506: val_loss did not improve from 1.30681
Epoch 507/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.4025 - val_loss: 1.3061 - val_accuracy: 0.4011

Epoch 00507: val_loss improved from 1.30681 to 1.30611, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 508/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3986 - val_loss: 1.3081 - val_accuracy: 0.3995

Epoch 00508: val_loss did not improve from 1.30611
Epoch 509/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4021 - val_loss: 1.3068 - val_accuracy: 0.3931

Epoch 00509: val_loss did not improve from 1.30611
Epoch 510/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4016 - val_loss: 1.3087 - val_accuracy: 0.4027

Epoch 00510: val_loss did not improve from 1.30611
Epoch 511/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3999 - val_loss: 1.3074 - val_accuracy: 0.3947

Epoch 00511: val_loss did not improve from 1.30611
Epoch 512/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3990 - val_loss: 1.3118 - val_accuracy: 0.3963

Epoch 00512: val_loss did not improve from 1.30611
Epoch 513/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4016 - val_loss: 1.3073 - val_accuracy: 0.3995

Epoch 00513: val_loss did not improve from 1.30611
Epoch 514/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4012 - val_loss: 1.3070 - val_accuracy: 0.3995

Epoch 00514: val_loss did not improve from 1.30611
Epoch 515/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4001 - val_loss: 1.3119 - val_accuracy: 0.3947

Epoch 00515: val_loss did not improve from 1.30611
Epoch 516/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.4010 - val_loss: 1.3073 - val_accuracy: 0.3979

Epoch 00516: val_loss did not improve from 1.30611
Epoch 517/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4004 - val_loss: 1.3097 - val_accuracy: 0.4051

Epoch 00517: val_loss did not improve from 1.30611
Epoch 518/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4004 - val_loss: 1.3074 - val_accuracy: 0.4035

Epoch 00518: val_loss did not improve from 1.30611
Epoch 519/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3973 - val_loss: 1.3073 - val_accuracy: 0.4035

Epoch 00519: val_loss did not improve from 1.30611
Epoch 520/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4018 - val_loss: 1.3078 - val_accuracy: 0.3947

Epoch 00520: val_loss did not improve from 1.30611
Epoch 521/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4001 - val_loss: 1.3078 - val_accuracy: 0.3900

Epoch 00521: val_loss did not improve from 1.30611
Epoch 522/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3968 - val_loss: 1.3075 - val_accuracy: 0.3987

Epoch 00522: val_loss did not improve from 1.30611
Epoch 523/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4017 - val_loss: 1.3071 - val_accuracy: 0.4011

Epoch 00523: val_loss did not improve from 1.30611
Epoch 524/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3972 - val_loss: 1.3062 - val_accuracy: 0.3931

Epoch 00524: val_loss did not improve from 1.30611
Epoch 525/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4003 - val_loss: 1.3073 - val_accuracy: 0.3995

Epoch 00525: val_loss did not improve from 1.30611
Epoch 526/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4021 - val_loss: 1.3060 - val_accuracy: 0.3931

Epoch 00526: val_loss improved from 1.30611 to 1.30604, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 527/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3993 - val_loss: 1.3080 - val_accuracy: 0.4019

Epoch 00527: val_loss did not improve from 1.30604
Epoch 528/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4028 - val_loss: 1.3069 - val_accuracy: 0.3979

Epoch 00528: val_loss did not improve from 1.30604
Epoch 529/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4021 - val_loss: 1.3131 - val_accuracy: 0.3987

Epoch 00529: val_loss did not improve from 1.30604
Epoch 530/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.4032 - val_loss: 1.3055 - val_accuracy: 0.3931

Epoch 00530: val_loss improved from 1.30604 to 1.30545, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 531/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3984 - val_loss: 1.3074 - val_accuracy: 0.4003

Epoch 00531: val_loss did not improve from 1.30545
Epoch 532/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3992 - val_loss: 1.3076 - val_accuracy: 0.3995

Epoch 00532: val_loss did not improve from 1.30545
Epoch 533/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4028 - val_loss: 1.3072 - val_accuracy: 0.3947

Epoch 00533: val_loss did not improve from 1.30545
Epoch 534/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4003 - val_loss: 1.3146 - val_accuracy: 0.3979

Epoch 00534: val_loss did not improve from 1.30545
Epoch 535/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4042 - val_loss: 1.3054 - val_accuracy: 0.3971

Epoch 00535: val_loss improved from 1.30545 to 1.30541, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 536/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4039 - val_loss: 1.3077 - val_accuracy: 0.3979

Epoch 00536: val_loss did not improve from 1.30541
Epoch 537/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4031 - val_loss: 1.3092 - val_accuracy: 0.3963

Epoch 00537: val_loss did not improve from 1.30541
Epoch 538/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4019 - val_loss: 1.3065 - val_accuracy: 0.3915

Epoch 00538: val_loss did not improve from 1.30541
Epoch 539/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4033 - val_loss: 1.3090 - val_accuracy: 0.3979

Epoch 00539: val_loss did not improve from 1.30541
Epoch 540/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4041 - val_loss: 1.3053 - val_accuracy: 0.3900

Epoch 00540: val_loss improved from 1.30541 to 1.30530, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 541/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4019 - val_loss: 1.3066 - val_accuracy: 0.3939

Epoch 00541: val_loss did not improve from 1.30530
Epoch 542/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4040 - val_loss: 1.3070 - val_accuracy: 0.3995

Epoch 00542: val_loss did not improve from 1.30530
Epoch 543/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3988 - val_loss: 1.3056 - val_accuracy: 0.3995

Epoch 00543: val_loss did not improve from 1.30530
Epoch 544/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.4022 - val_loss: 1.3071 - val_accuracy: 0.3955

Epoch 00544: val_loss did not improve from 1.30530
Epoch 545/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3993 - val_loss: 1.3050 - val_accuracy: 0.3923

Epoch 00545: val_loss improved from 1.30530 to 1.30496, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 546/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3978 - val_loss: 1.3078 - val_accuracy: 0.3947

Epoch 00546: val_loss did not improve from 1.30496
Epoch 547/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4042 - val_loss: 1.3044 - val_accuracy: 0.4035

Epoch 00547: val_loss improved from 1.30496 to 1.30437, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 548/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4011 - val_loss: 1.3086 - val_accuracy: 0.3939

Epoch 00548: val_loss did not improve from 1.30437
Epoch 549/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4029 - val_loss: 1.3067 - val_accuracy: 0.3979

Epoch 00549: val_loss did not improve from 1.30437
Epoch 550/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.4043 - val_loss: 1.3045 - val_accuracy: 0.3979

Epoch 00550: val_loss did not improve from 1.30437
Epoch 551/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3989 - val_loss: 1.3053 - val_accuracy: 0.4027

Epoch 00551: val_loss did not improve from 1.30437
Epoch 552/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4008 - val_loss: 1.3118 - val_accuracy: 0.3931

Epoch 00552: val_loss did not improve from 1.30437
Epoch 553/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4007 - val_loss: 1.3055 - val_accuracy: 0.3931

Epoch 00553: val_loss did not improve from 1.30437
Epoch 554/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4021 - val_loss: 1.3078 - val_accuracy: 0.3955

Epoch 00554: val_loss did not improve from 1.30437
Epoch 555/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4029 - val_loss: 1.3058 - val_accuracy: 0.3892

Epoch 00555: val_loss did not improve from 1.30437
Epoch 556/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4001 - val_loss: 1.3088 - val_accuracy: 0.4043

Epoch 00556: val_loss did not improve from 1.30437
Epoch 557/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4052 - val_loss: 1.3067 - val_accuracy: 0.4003

Epoch 00557: val_loss did not improve from 1.30437
Epoch 558/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3975 - val_loss: 1.3054 - val_accuracy: 0.3892

Epoch 00558: val_loss did not improve from 1.30437
Epoch 559/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4014 - val_loss: 1.3091 - val_accuracy: 0.3939

Epoch 00559: val_loss did not improve from 1.30437
Epoch 560/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4028 - val_loss: 1.3054 - val_accuracy: 0.4043

Epoch 00560: val_loss did not improve from 1.30437
Epoch 561/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4049 - val_loss: 1.3066 - val_accuracy: 0.4003

Epoch 00561: val_loss did not improve from 1.30437
Epoch 562/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4026 - val_loss: 1.3062 - val_accuracy: 0.3995

Epoch 00562: val_loss did not improve from 1.30437
Epoch 563/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4001 - val_loss: 1.3094 - val_accuracy: 0.4059

Epoch 00563: val_loss did not improve from 1.30437
Epoch 564/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4029 - val_loss: 1.3064 - val_accuracy: 0.4043

Epoch 00564: val_loss did not improve from 1.30437
Epoch 565/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4013 - val_loss: 1.3065 - val_accuracy: 0.3915

Epoch 00565: val_loss did not improve from 1.30437
Epoch 566/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4014 - val_loss: 1.3080 - val_accuracy: 0.3939

Epoch 00566: val_loss did not improve from 1.30437
Epoch 567/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4017 - val_loss: 1.3069 - val_accuracy: 0.3963

Epoch 00567: val_loss did not improve from 1.30437
Epoch 568/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4029 - val_loss: 1.3044 - val_accuracy: 0.4003

Epoch 00568: val_loss did not improve from 1.30437
Epoch 569/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4017 - val_loss: 1.3070 - val_accuracy: 0.4011

Epoch 00569: val_loss did not improve from 1.30437
Epoch 570/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4035 - val_loss: 1.3072 - val_accuracy: 0.4003

Epoch 00570: val_loss did not improve from 1.30437
Epoch 571/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4033 - val_loss: 1.3062 - val_accuracy: 0.4003

Epoch 00571: val_loss did not improve from 1.30437
Epoch 572/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4037 - val_loss: 1.3063 - val_accuracy: 0.4027

Epoch 00572: val_loss did not improve from 1.30437
Epoch 573/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4038 - val_loss: 1.3055 - val_accuracy: 0.4027

Epoch 00573: val_loss did not improve from 1.30437
Epoch 574/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4047 - val_loss: 1.3049 - val_accuracy: 0.3907

Epoch 00574: val_loss did not improve from 1.30437
Epoch 575/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4010 - val_loss: 1.3097 - val_accuracy: 0.4035

Epoch 00575: val_loss did not improve from 1.30437
Epoch 576/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4017 - val_loss: 1.3036 - val_accuracy: 0.3963

Epoch 00576: val_loss improved from 1.30437 to 1.30357, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 577/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4030 - val_loss: 1.3083 - val_accuracy: 0.3995

Epoch 00577: val_loss did not improve from 1.30357
Epoch 578/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4016 - val_loss: 1.3048 - val_accuracy: 0.3860

Epoch 00578: val_loss did not improve from 1.30357
Epoch 579/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3962 - val_loss: 1.3050 - val_accuracy: 0.4027

Epoch 00579: val_loss did not improve from 1.30357
Epoch 580/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4041 - val_loss: 1.3039 - val_accuracy: 0.3923

Epoch 00580: val_loss did not improve from 1.30357
Epoch 581/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4031 - val_loss: 1.3061 - val_accuracy: 0.4043

Epoch 00581: val_loss did not improve from 1.30357
Epoch 582/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4017 - val_loss: 1.3039 - val_accuracy: 0.4011

Epoch 00582: val_loss did not improve from 1.30357
Epoch 583/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4001 - val_loss: 1.3057 - val_accuracy: 0.4011

Epoch 00583: val_loss did not improve from 1.30357
Epoch 584/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4032 - val_loss: 1.3056 - val_accuracy: 0.4019

Epoch 00584: val_loss did not improve from 1.30357
Epoch 585/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4043 - val_loss: 1.3046 - val_accuracy: 0.3979

Epoch 00585: val_loss did not improve from 1.30357
Epoch 586/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4022 - val_loss: 1.3080 - val_accuracy: 0.3987

Epoch 00586: val_loss did not improve from 1.30357
Epoch 587/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4036 - val_loss: 1.3078 - val_accuracy: 0.4051

Epoch 00587: val_loss did not improve from 1.30357
Epoch 588/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3997 - val_loss: 1.3043 - val_accuracy: 0.3995

Epoch 00588: val_loss did not improve from 1.30357
Epoch 589/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4027 - val_loss: 1.3050 - val_accuracy: 0.3955

Epoch 00589: val_loss did not improve from 1.30357
Epoch 590/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4024 - val_loss: 1.3063 - val_accuracy: 0.4003

Epoch 00590: val_loss did not improve from 1.30357
Epoch 591/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4037 - val_loss: 1.3061 - val_accuracy: 0.3979

Epoch 00591: val_loss did not improve from 1.30357
Epoch 592/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4037 - val_loss: 1.3043 - val_accuracy: 0.4027

Epoch 00592: val_loss did not improve from 1.30357
Epoch 593/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4042 - val_loss: 1.3042 - val_accuracy: 0.4011

Epoch 00593: val_loss did not improve from 1.30357
Epoch 594/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4018 - val_loss: 1.3070 - val_accuracy: 0.4051

Epoch 00594: val_loss did not improve from 1.30357
Epoch 595/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4012 - val_loss: 1.3081 - val_accuracy: 0.4051

Epoch 00595: val_loss did not improve from 1.30357
Epoch 596/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3994 - val_loss: 1.3061 - val_accuracy: 0.3884

Epoch 00596: val_loss did not improve from 1.30357
Epoch 597/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3984 - val_loss: 1.3068 - val_accuracy: 0.3939

Epoch 00597: val_loss did not improve from 1.30357
Epoch 598/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4027 - val_loss: 1.3053 - val_accuracy: 0.3963

Epoch 00598: val_loss did not improve from 1.30357
Epoch 599/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4030 - val_loss: 1.3049 - val_accuracy: 0.3947

Epoch 00599: val_loss did not improve from 1.30357
Epoch 600/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4021 - val_loss: 1.3039 - val_accuracy: 0.4011

Epoch 00600: val_loss did not improve from 1.30357
Epoch 601/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4005 - val_loss: 1.3053 - val_accuracy: 0.4059

Epoch 00601: val_loss did not improve from 1.30357
Epoch 602/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3965 - val_loss: 1.3080 - val_accuracy: 0.4027

Epoch 00602: val_loss did not improve from 1.30357
Epoch 603/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4032 - val_loss: 1.3046 - val_accuracy: 0.4035

Epoch 00603: val_loss did not improve from 1.30357
Epoch 604/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4041 - val_loss: 1.3061 - val_accuracy: 0.3955

Epoch 00604: val_loss did not improve from 1.30357
Epoch 605/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4024 - val_loss: 1.3044 - val_accuracy: 0.3907

Epoch 00605: val_loss did not improve from 1.30357
Epoch 606/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4013 - val_loss: 1.3056 - val_accuracy: 0.4027

Epoch 00606: val_loss did not improve from 1.30357
Epoch 607/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4035 - val_loss: 1.3063 - val_accuracy: 0.4011

Epoch 00607: val_loss did not improve from 1.30357
Epoch 608/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4022 - val_loss: 1.3043 - val_accuracy: 0.3971

Epoch 00608: val_loss did not improve from 1.30357
Epoch 609/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4029 - val_loss: 1.3053 - val_accuracy: 0.4035

Epoch 00609: val_loss did not improve from 1.30357
Epoch 610/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4031 - val_loss: 1.3058 - val_accuracy: 0.3923

Epoch 00610: val_loss did not improve from 1.30357
Epoch 611/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4016 - val_loss: 1.3071 - val_accuracy: 0.4043

Epoch 00611: val_loss did not improve from 1.30357
Epoch 612/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3996 - val_loss: 1.3090 - val_accuracy: 0.4035

Epoch 00612: val_loss did not improve from 1.30357
Epoch 613/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4010 - val_loss: 1.3041 - val_accuracy: 0.3947

Epoch 00613: val_loss did not improve from 1.30357
Epoch 614/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4043 - val_loss: 1.3037 - val_accuracy: 0.4019

Epoch 00614: val_loss did not improve from 1.30357
Epoch 615/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4021 - val_loss: 1.3048 - val_accuracy: 0.4067

Epoch 00615: val_loss did not improve from 1.30357
Epoch 616/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4024 - val_loss: 1.3095 - val_accuracy: 0.4083

Epoch 00616: val_loss did not improve from 1.30357
Epoch 617/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3983 - val_loss: 1.3038 - val_accuracy: 0.3955

Epoch 00617: val_loss did not improve from 1.30357
Epoch 618/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4001 - val_loss: 1.3062 - val_accuracy: 0.4027

Epoch 00618: val_loss did not improve from 1.30357
Epoch 619/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4021 - val_loss: 1.3059 - val_accuracy: 0.4011

Epoch 00619: val_loss did not improve from 1.30357
Epoch 620/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4038 - val_loss: 1.3034 - val_accuracy: 0.4019

Epoch 00620: val_loss improved from 1.30357 to 1.30339, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 621/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4042 - val_loss: 1.3030 - val_accuracy: 0.4035

Epoch 00621: val_loss improved from 1.30339 to 1.30296, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 622/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4027 - val_loss: 1.3045 - val_accuracy: 0.3995

Epoch 00622: val_loss did not improve from 1.30296
Epoch 623/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4032 - val_loss: 1.3040 - val_accuracy: 0.4059

Epoch 00623: val_loss did not improve from 1.30296
Epoch 624/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4040 - val_loss: 1.3055 - val_accuracy: 0.4043

Epoch 00624: val_loss did not improve from 1.30296
Epoch 625/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4002 - val_loss: 1.3092 - val_accuracy: 0.4011

Epoch 00625: val_loss did not improve from 1.30296
Epoch 626/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4020 - val_loss: 1.3042 - val_accuracy: 0.3939

Epoch 00626: val_loss did not improve from 1.30296
Epoch 627/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3963 - val_loss: 1.3108 - val_accuracy: 0.4011

Epoch 00627: val_loss did not improve from 1.30296
Epoch 628/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3986 - val_loss: 1.3055 - val_accuracy: 0.3876

Epoch 00628: val_loss did not improve from 1.30296
Epoch 629/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3993 - val_loss: 1.3056 - val_accuracy: 0.3971

Epoch 00629: val_loss did not improve from 1.30296
Epoch 630/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4030 - val_loss: 1.3053 - val_accuracy: 0.3876

Epoch 00630: val_loss did not improve from 1.30296
Epoch 631/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3989 - val_loss: 1.3059 - val_accuracy: 0.3979

Epoch 00631: val_loss did not improve from 1.30296
Epoch 632/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4017 - val_loss: 1.3011 - val_accuracy: 0.3979

Epoch 00632: val_loss improved from 1.30296 to 1.30109, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 633/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4016 - val_loss: 1.3047 - val_accuracy: 0.4027

Epoch 00633: val_loss did not improve from 1.30109
Epoch 634/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4012 - val_loss: 1.3029 - val_accuracy: 0.4011

Epoch 00634: val_loss did not improve from 1.30109
Epoch 635/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4034 - val_loss: 1.3069 - val_accuracy: 0.4011

Epoch 00635: val_loss did not improve from 1.30109
Epoch 636/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4028 - val_loss: 1.3033 - val_accuracy: 0.3987

Epoch 00636: val_loss did not improve from 1.30109
Epoch 637/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4009 - val_loss: 1.3029 - val_accuracy: 0.3876

Epoch 00637: val_loss did not improve from 1.30109
Epoch 638/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4006 - val_loss: 1.3081 - val_accuracy: 0.3939

Epoch 00638: val_loss did not improve from 1.30109
Epoch 639/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4038 - val_loss: 1.3027 - val_accuracy: 0.3892

Epoch 00639: val_loss did not improve from 1.30109
Epoch 640/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4005 - val_loss: 1.3085 - val_accuracy: 0.4011

Epoch 00640: val_loss did not improve from 1.30109
Epoch 641/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4048 - val_loss: 1.3023 - val_accuracy: 0.4091

Epoch 00641: val_loss did not improve from 1.30109
Epoch 642/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4057 - val_loss: 1.3044 - val_accuracy: 0.3979

Epoch 00642: val_loss did not improve from 1.30109
Epoch 643/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4053 - val_loss: 1.3041 - val_accuracy: 0.4011

Epoch 00643: val_loss did not improve from 1.30109
Epoch 644/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4064 - val_loss: 1.3031 - val_accuracy: 0.4035

Epoch 00644: val_loss did not improve from 1.30109
Epoch 645/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4049 - val_loss: 1.3078 - val_accuracy: 0.3979

Epoch 00645: val_loss did not improve from 1.30109
Epoch 646/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4056 - val_loss: 1.3051 - val_accuracy: 0.3995

Epoch 00646: val_loss did not improve from 1.30109
Epoch 647/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4027 - val_loss: 1.3045 - val_accuracy: 0.4035

Epoch 00647: val_loss did not improve from 1.30109
Epoch 648/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4013 - val_loss: 1.3057 - val_accuracy: 0.3987

Epoch 00648: val_loss did not improve from 1.30109
Epoch 649/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4039 - val_loss: 1.3030 - val_accuracy: 0.3987

Epoch 00649: val_loss did not improve from 1.30109
Epoch 650/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4039 - val_loss: 1.3041 - val_accuracy: 0.4067

Epoch 00650: val_loss did not improve from 1.30109
Epoch 651/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4015 - val_loss: 1.3058 - val_accuracy: 0.3971

Epoch 00651: val_loss did not improve from 1.30109
Epoch 652/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4061 - val_loss: 1.3046 - val_accuracy: 0.4059

Epoch 00652: val_loss did not improve from 1.30109
Epoch 653/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4024 - val_loss: 1.3040 - val_accuracy: 0.4003

Epoch 00653: val_loss did not improve from 1.30109
Epoch 654/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4012 - val_loss: 1.3038 - val_accuracy: 0.4003

Epoch 00654: val_loss did not improve from 1.30109
Epoch 655/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4028 - val_loss: 1.3032 - val_accuracy: 0.4011

Epoch 00655: val_loss did not improve from 1.30109
Epoch 656/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4059 - val_loss: 1.3020 - val_accuracy: 0.3900

Epoch 00656: val_loss did not improve from 1.30109
Epoch 657/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3989 - val_loss: 1.3058 - val_accuracy: 0.4043

Epoch 00657: val_loss did not improve from 1.30109
Epoch 658/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4062 - val_loss: 1.3035 - val_accuracy: 0.4043

Epoch 00658: val_loss did not improve from 1.30109
Epoch 659/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4068 - val_loss: 1.3042 - val_accuracy: 0.4043

Epoch 00659: val_loss did not improve from 1.30109
Epoch 660/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4063 - val_loss: 1.3029 - val_accuracy: 0.3955

Epoch 00660: val_loss did not improve from 1.30109
Epoch 661/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3962 - val_loss: 1.3058 - val_accuracy: 0.4067

Epoch 00661: val_loss did not improve from 1.30109
Epoch 662/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4044 - val_loss: 1.3070 - val_accuracy: 0.4011

Epoch 00662: val_loss did not improve from 1.30109
Epoch 663/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4039 - val_loss: 1.3035 - val_accuracy: 0.3939

Epoch 00663: val_loss did not improve from 1.30109
Epoch 664/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4017 - val_loss: 1.3031 - val_accuracy: 0.3868

Epoch 00664: val_loss did not improve from 1.30109
Epoch 665/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4002 - val_loss: 1.3067 - val_accuracy: 0.3987

Epoch 00665: val_loss did not improve from 1.30109
Epoch 666/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4046 - val_loss: 1.3039 - val_accuracy: 0.3900

Epoch 00666: val_loss did not improve from 1.30109
Epoch 667/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4013 - val_loss: 1.3038 - val_accuracy: 0.3939

Epoch 00667: val_loss did not improve from 1.30109
Epoch 668/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4001 - val_loss: 1.3028 - val_accuracy: 0.4003

Epoch 00668: val_loss did not improve from 1.30109
Epoch 669/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.3973 - val_loss: 1.3057 - val_accuracy: 0.4011

Epoch 00669: val_loss did not improve from 1.30109
Epoch 670/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4003 - val_loss: 1.3000 - val_accuracy: 0.4027

Epoch 00670: val_loss improved from 1.30109 to 1.29998, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 671/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4023 - val_loss: 1.3009 - val_accuracy: 0.3995

Epoch 00671: val_loss did not improve from 1.29998
Epoch 672/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4017 - val_loss: 1.3038 - val_accuracy: 0.4027

Epoch 00672: val_loss did not improve from 1.29998
Epoch 673/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4054 - val_loss: 1.3030 - val_accuracy: 0.3931

Epoch 00673: val_loss did not improve from 1.29998
Epoch 674/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4014 - val_loss: 1.3108 - val_accuracy: 0.4035

Epoch 00674: val_loss did not improve from 1.29998
Epoch 675/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4011 - val_loss: 1.3021 - val_accuracy: 0.3915

Epoch 00675: val_loss did not improve from 1.29998
Epoch 676/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4011 - val_loss: 1.3034 - val_accuracy: 0.3995

Epoch 00676: val_loss did not improve from 1.29998
Epoch 677/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4029 - val_loss: 1.3052 - val_accuracy: 0.3995

Epoch 00677: val_loss did not improve from 1.29998
Epoch 678/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4009 - val_loss: 1.3020 - val_accuracy: 0.3955

Epoch 00678: val_loss did not improve from 1.29998
Epoch 679/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4035 - val_loss: 1.3035 - val_accuracy: 0.3995

Epoch 00679: val_loss did not improve from 1.29998
Epoch 680/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4035 - val_loss: 1.3036 - val_accuracy: 0.4035

Epoch 00680: val_loss did not improve from 1.29998
Epoch 681/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4045 - val_loss: 1.3024 - val_accuracy: 0.3947

Epoch 00681: val_loss did not improve from 1.29998
Epoch 682/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4041 - val_loss: 1.3038 - val_accuracy: 0.4019

Epoch 00682: val_loss did not improve from 1.29998
Epoch 683/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4045 - val_loss: 1.3035 - val_accuracy: 0.4003

Epoch 00683: val_loss did not improve from 1.29998
Epoch 684/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4057 - val_loss: 1.3018 - val_accuracy: 0.4035

Epoch 00684: val_loss did not improve from 1.29998
Epoch 685/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4015 - val_loss: 1.3005 - val_accuracy: 0.4043

Epoch 00685: val_loss did not improve from 1.29998
Epoch 686/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4032 - val_loss: 1.3029 - val_accuracy: 0.3971

Epoch 00686: val_loss did not improve from 1.29998
Epoch 687/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4031 - val_loss: 1.2996 - val_accuracy: 0.4019

Epoch 00687: val_loss improved from 1.29998 to 1.29964, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 688/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3988 - val_loss: 1.3015 - val_accuracy: 0.4003

Epoch 00688: val_loss did not improve from 1.29964
Epoch 689/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3984 - val_loss: 1.3054 - val_accuracy: 0.3971

Epoch 00689: val_loss did not improve from 1.29964
Epoch 690/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4062 - val_loss: 1.3035 - val_accuracy: 0.4019

Epoch 00690: val_loss did not improve from 1.29964
Epoch 691/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4007 - val_loss: 1.3030 - val_accuracy: 0.3971

Epoch 00691: val_loss did not improve from 1.29964
Epoch 692/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4016 - val_loss: 1.3013 - val_accuracy: 0.4019

Epoch 00692: val_loss did not improve from 1.29964
Epoch 693/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4006 - val_loss: 1.3086 - val_accuracy: 0.3995

Epoch 00693: val_loss did not improve from 1.29964
Epoch 694/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4074 - val_loss: 1.3007 - val_accuracy: 0.4003

Epoch 00694: val_loss did not improve from 1.29964
Epoch 695/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4030 - val_loss: 1.3012 - val_accuracy: 0.3987

Epoch 00695: val_loss did not improve from 1.29964
Epoch 696/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4016 - val_loss: 1.3028 - val_accuracy: 0.3987

Epoch 00696: val_loss did not improve from 1.29964
Epoch 697/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4023 - val_loss: 1.3002 - val_accuracy: 0.3963

Epoch 00697: val_loss did not improve from 1.29964
Epoch 698/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4064 - val_loss: 1.2995 - val_accuracy: 0.4003

Epoch 00698: val_loss improved from 1.29964 to 1.29952, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 699/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4025 - val_loss: 1.3018 - val_accuracy: 0.3987

Epoch 00699: val_loss did not improve from 1.29952
Epoch 700/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4018 - val_loss: 1.2986 - val_accuracy: 0.3979

Epoch 00700: val_loss improved from 1.29952 to 1.29863, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 701/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4040 - val_loss: 1.3021 - val_accuracy: 0.4011

Epoch 00701: val_loss did not improve from 1.29863
Epoch 702/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4049 - val_loss: 1.3010 - val_accuracy: 0.3987

Epoch 00702: val_loss did not improve from 1.29863
Epoch 703/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4072 - val_loss: 1.3020 - val_accuracy: 0.4019

Epoch 00703: val_loss did not improve from 1.29863
Epoch 704/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4029 - val_loss: 1.3034 - val_accuracy: 0.3987

Epoch 00704: val_loss did not improve from 1.29863
Epoch 705/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4043 - val_loss: 1.3017 - val_accuracy: 0.3971

Epoch 00705: val_loss did not improve from 1.29863
Epoch 706/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4009 - val_loss: 1.3031 - val_accuracy: 0.4011

Epoch 00706: val_loss did not improve from 1.29863
Epoch 707/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4005 - val_loss: 1.3025 - val_accuracy: 0.4051

Epoch 00707: val_loss did not improve from 1.29863
Epoch 708/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4012 - val_loss: 1.3015 - val_accuracy: 0.4043

Epoch 00708: val_loss did not improve from 1.29863
Epoch 709/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4026 - val_loss: 1.3040 - val_accuracy: 0.4011

Epoch 00709: val_loss did not improve from 1.29863
Epoch 710/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4038 - val_loss: 1.3016 - val_accuracy: 0.4019

Epoch 00710: val_loss did not improve from 1.29863
Epoch 711/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4042 - val_loss: 1.3022 - val_accuracy: 0.4011

Epoch 00711: val_loss did not improve from 1.29863
Epoch 712/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4046 - val_loss: 1.3001 - val_accuracy: 0.3979

Epoch 00712: val_loss did not improve from 1.29863
Epoch 713/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4001 - val_loss: 1.3015 - val_accuracy: 0.4003

Epoch 00713: val_loss did not improve from 1.29863
Epoch 714/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4055 - val_loss: 1.3013 - val_accuracy: 0.3979

Epoch 00714: val_loss did not improve from 1.29863
Epoch 715/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4062 - val_loss: 1.3044 - val_accuracy: 0.3947

Epoch 00715: val_loss did not improve from 1.29863
Epoch 716/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4036 - val_loss: 1.2999 - val_accuracy: 0.4075

Epoch 00716: val_loss did not improve from 1.29863
Epoch 717/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4055 - val_loss: 1.3008 - val_accuracy: 0.4035

Epoch 00717: val_loss did not improve from 1.29863
Epoch 718/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4029 - val_loss: 1.3012 - val_accuracy: 0.3995

Epoch 00718: val_loss did not improve from 1.29863
Epoch 719/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4022 - val_loss: 1.3024 - val_accuracy: 0.4043

Epoch 00719: val_loss did not improve from 1.29863
Epoch 720/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4001 - val_loss: 1.3021 - val_accuracy: 0.4011

Epoch 00720: val_loss did not improve from 1.29863
Epoch 721/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4048 - val_loss: 1.3020 - val_accuracy: 0.4059

Epoch 00721: val_loss did not improve from 1.29863
Epoch 722/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4064 - val_loss: 1.3023 - val_accuracy: 0.4027

Epoch 00722: val_loss did not improve from 1.29863
Epoch 723/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4064 - val_loss: 1.2999 - val_accuracy: 0.4011

Epoch 00723: val_loss did not improve from 1.29863
Epoch 724/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4039 - val_loss: 1.2998 - val_accuracy: 0.4043

Epoch 00724: val_loss did not improve from 1.29863
Epoch 725/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4017 - val_loss: 1.3016 - val_accuracy: 0.4067

Epoch 00725: val_loss did not improve from 1.29863
Epoch 726/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4027 - val_loss: 1.3004 - val_accuracy: 0.4027

Epoch 00726: val_loss did not improve from 1.29863
Epoch 727/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4008 - val_loss: 1.3062 - val_accuracy: 0.3963

Epoch 00727: val_loss did not improve from 1.29863
Epoch 728/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4055 - val_loss: 1.3011 - val_accuracy: 0.4067

Epoch 00728: val_loss did not improve from 1.29863
Epoch 729/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4074 - val_loss: 1.3004 - val_accuracy: 0.4083

Epoch 00729: val_loss did not improve from 1.29863
Epoch 730/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4036 - val_loss: 1.2997 - val_accuracy: 0.4059

Epoch 00730: val_loss did not improve from 1.29863
Epoch 731/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4047 - val_loss: 1.2992 - val_accuracy: 0.4027

Epoch 00731: val_loss did not improve from 1.29863
Epoch 732/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4031 - val_loss: 1.3040 - val_accuracy: 0.4019

Epoch 00732: val_loss did not improve from 1.29863
Epoch 733/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4060 - val_loss: 1.2988 - val_accuracy: 0.3987

Epoch 00733: val_loss did not improve from 1.29863
Epoch 734/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4060 - val_loss: 1.3004 - val_accuracy: 0.3963

Epoch 00734: val_loss did not improve from 1.29863
Epoch 735/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4054 - val_loss: 1.2997 - val_accuracy: 0.3987

Epoch 00735: val_loss did not improve from 1.29863
Epoch 736/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4032 - val_loss: 1.3011 - val_accuracy: 0.3987

Epoch 00736: val_loss did not improve from 1.29863
Epoch 737/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4049 - val_loss: 1.2999 - val_accuracy: 0.4035

Epoch 00737: val_loss did not improve from 1.29863
Epoch 738/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4015 - val_loss: 1.3020 - val_accuracy: 0.4019

Epoch 00738: val_loss did not improve from 1.29863
Epoch 739/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4055 - val_loss: 1.3004 - val_accuracy: 0.4019

Epoch 00739: val_loss did not improve from 1.29863
Epoch 740/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4046 - val_loss: 1.3039 - val_accuracy: 0.4019

Epoch 00740: val_loss did not improve from 1.29863
Epoch 741/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4049 - val_loss: 1.3001 - val_accuracy: 0.4019

Epoch 00741: val_loss did not improve from 1.29863
Epoch 742/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4047 - val_loss: 1.2983 - val_accuracy: 0.4011

Epoch 00742: val_loss improved from 1.29863 to 1.29830, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 743/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4034 - val_loss: 1.2988 - val_accuracy: 0.4059

Epoch 00743: val_loss did not improve from 1.29830
Epoch 744/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4031 - val_loss: 1.3009 - val_accuracy: 0.3987

Epoch 00744: val_loss did not improve from 1.29830
Epoch 745/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4060 - val_loss: 1.3014 - val_accuracy: 0.3979

Epoch 00745: val_loss did not improve from 1.29830
Epoch 746/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4037 - val_loss: 1.3009 - val_accuracy: 0.4011

Epoch 00746: val_loss did not improve from 1.29830
Epoch 747/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4018 - val_loss: 1.3002 - val_accuracy: 0.4075

Epoch 00747: val_loss did not improve from 1.29830
Epoch 748/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4032 - val_loss: 1.2996 - val_accuracy: 0.4059

Epoch 00748: val_loss did not improve from 1.29830
Epoch 749/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4008 - val_loss: 1.3069 - val_accuracy: 0.4099

Epoch 00749: val_loss did not improve from 1.29830
Epoch 750/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4053 - val_loss: 1.3019 - val_accuracy: 0.4011

Epoch 00750: val_loss did not improve from 1.29830
Epoch 751/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4040 - val_loss: 1.2999 - val_accuracy: 0.4027

Epoch 00751: val_loss did not improve from 1.29830
Epoch 752/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3965 - val_loss: 1.3055 - val_accuracy: 0.4059

Epoch 00752: val_loss did not improve from 1.29830
Epoch 753/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4037 - val_loss: 1.3015 - val_accuracy: 0.4091

Epoch 00753: val_loss did not improve from 1.29830
Epoch 754/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4009 - val_loss: 1.3095 - val_accuracy: 0.4019

Epoch 00754: val_loss did not improve from 1.29830
Epoch 755/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4024 - val_loss: 1.3005 - val_accuracy: 0.4003

Epoch 00755: val_loss did not improve from 1.29830
Epoch 756/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4051 - val_loss: 1.3013 - val_accuracy: 0.4019

Epoch 00756: val_loss did not improve from 1.29830
Epoch 757/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4066 - val_loss: 1.3016 - val_accuracy: 0.4027

Epoch 00757: val_loss did not improve from 1.29830
Epoch 758/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4070 - val_loss: 1.3000 - val_accuracy: 0.4067

Epoch 00758: val_loss did not improve from 1.29830
Epoch 759/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4032 - val_loss: 1.3034 - val_accuracy: 0.4043

Epoch 00759: val_loss did not improve from 1.29830
Epoch 760/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4030 - val_loss: 1.2993 - val_accuracy: 0.4043

Epoch 00760: val_loss did not improve from 1.29830
Epoch 761/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4015 - val_loss: 1.3002 - val_accuracy: 0.3947

Epoch 00761: val_loss did not improve from 1.29830
Epoch 762/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4026 - val_loss: 1.3014 - val_accuracy: 0.4003

Epoch 00762: val_loss did not improve from 1.29830
Epoch 763/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4040 - val_loss: 1.2986 - val_accuracy: 0.4051

Epoch 00763: val_loss did not improve from 1.29830
Epoch 764/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4032 - val_loss: 1.3003 - val_accuracy: 0.3923

Epoch 00764: val_loss did not improve from 1.29830
Epoch 765/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3980 - val_loss: 1.2994 - val_accuracy: 0.4043

Epoch 00765: val_loss did not improve from 1.29830
Epoch 766/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4039 - val_loss: 1.3018 - val_accuracy: 0.3979

Epoch 00766: val_loss did not improve from 1.29830
Epoch 767/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4048 - val_loss: 1.2983 - val_accuracy: 0.4019

Epoch 00767: val_loss did not improve from 1.29830
Epoch 768/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4001 - val_loss: 1.3039 - val_accuracy: 0.4027

Epoch 00768: val_loss did not improve from 1.29830
Epoch 769/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4037 - val_loss: 1.2994 - val_accuracy: 0.3995

Epoch 00769: val_loss did not improve from 1.29830
Epoch 770/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4059 - val_loss: 1.3025 - val_accuracy: 0.4019

Epoch 00770: val_loss did not improve from 1.29830
Epoch 771/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4061 - val_loss: 1.3014 - val_accuracy: 0.4035

Epoch 00771: val_loss did not improve from 1.29830
Epoch 772/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4024 - val_loss: 1.3028 - val_accuracy: 0.4043

Epoch 00772: val_loss did not improve from 1.29830
Epoch 773/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4032 - val_loss: 1.3052 - val_accuracy: 0.3931

Epoch 00773: val_loss did not improve from 1.29830
Epoch 774/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4079 - val_loss: 1.2998 - val_accuracy: 0.4035

Epoch 00774: val_loss did not improve from 1.29830
Epoch 775/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4028 - val_loss: 1.3006 - val_accuracy: 0.4075

Epoch 00775: val_loss did not improve from 1.29830
Epoch 776/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4038 - val_loss: 1.3000 - val_accuracy: 0.4003

Epoch 00776: val_loss did not improve from 1.29830
Epoch 777/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4043 - val_loss: 1.3026 - val_accuracy: 0.4123

Epoch 00777: val_loss did not improve from 1.29830
Epoch 778/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4050 - val_loss: 1.3048 - val_accuracy: 0.4099

Epoch 00778: val_loss did not improve from 1.29830
Epoch 779/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4064 - val_loss: 1.2993 - val_accuracy: 0.3971

Epoch 00779: val_loss did not improve from 1.29830
Epoch 780/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4003 - val_loss: 1.2995 - val_accuracy: 0.4051

Epoch 00780: val_loss did not improve from 1.29830
Epoch 781/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4025 - val_loss: 1.3001 - val_accuracy: 0.3979

Epoch 00781: val_loss did not improve from 1.29830
Epoch 782/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4058 - val_loss: 1.2979 - val_accuracy: 0.3979

Epoch 00782: val_loss improved from 1.29830 to 1.29793, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 783/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4048 - val_loss: 1.2986 - val_accuracy: 0.4019

Epoch 00783: val_loss did not improve from 1.29793
Epoch 784/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4027 - val_loss: 1.2992 - val_accuracy: 0.3931

Epoch 00784: val_loss did not improve from 1.29793
Epoch 785/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.3992 - val_loss: 1.3015 - val_accuracy: 0.4019

Epoch 00785: val_loss did not improve from 1.29793
Epoch 786/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4040 - val_loss: 1.2986 - val_accuracy: 0.4003

Epoch 00786: val_loss did not improve from 1.29793
Epoch 787/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4050 - val_loss: 1.2976 - val_accuracy: 0.4027

Epoch 00787: val_loss improved from 1.29793 to 1.29759, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 788/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4009 - val_loss: 1.3000 - val_accuracy: 0.3963

Epoch 00788: val_loss did not improve from 1.29759
Epoch 789/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4032 - val_loss: 1.3010 - val_accuracy: 0.3971

Epoch 00789: val_loss did not improve from 1.29759
Epoch 790/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4074 - val_loss: 1.2996 - val_accuracy: 0.3979

Epoch 00790: val_loss did not improve from 1.29759
Epoch 791/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4029 - val_loss: 1.3017 - val_accuracy: 0.3995

Epoch 00791: val_loss did not improve from 1.29759
Epoch 792/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4063 - val_loss: 1.2991 - val_accuracy: 0.4027

Epoch 00792: val_loss did not improve from 1.29759
Epoch 793/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4085 - val_loss: 1.3004 - val_accuracy: 0.4051

Epoch 00793: val_loss did not improve from 1.29759
Epoch 794/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4050 - val_loss: 1.3002 - val_accuracy: 0.4075

Epoch 00794: val_loss did not improve from 1.29759
Epoch 795/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4060 - val_loss: 1.2984 - val_accuracy: 0.3979

Epoch 00795: val_loss did not improve from 1.29759
Epoch 796/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4046 - val_loss: 1.2998 - val_accuracy: 0.4027

Epoch 00796: val_loss did not improve from 1.29759
Epoch 797/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4055 - val_loss: 1.2982 - val_accuracy: 0.3995

Epoch 00797: val_loss did not improve from 1.29759
Epoch 798/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4047 - val_loss: 1.2984 - val_accuracy: 0.4003

Epoch 00798: val_loss did not improve from 1.29759
Epoch 799/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4082 - val_loss: 1.2975 - val_accuracy: 0.4067

Epoch 00799: val_loss improved from 1.29759 to 1.29753, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 800/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4094 - val_loss: 1.2987 - val_accuracy: 0.4027

Epoch 00800: val_loss did not improve from 1.29753
Epoch 801/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4063 - val_loss: 1.2967 - val_accuracy: 0.4035

Epoch 00801: val_loss improved from 1.29753 to 1.29670, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 802/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4037 - val_loss: 1.2984 - val_accuracy: 0.4003

Epoch 00802: val_loss did not improve from 1.29670
Epoch 803/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4036 - val_loss: 1.2986 - val_accuracy: 0.4019

Epoch 00803: val_loss did not improve from 1.29670
Epoch 804/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4061 - val_loss: 1.2980 - val_accuracy: 0.3939

Epoch 00804: val_loss did not improve from 1.29670
Epoch 805/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4013 - val_loss: 1.3039 - val_accuracy: 0.4035

Epoch 00805: val_loss did not improve from 1.29670
Epoch 806/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4066 - val_loss: 1.2985 - val_accuracy: 0.4043

Epoch 00806: val_loss did not improve from 1.29670
Epoch 807/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4059 - val_loss: 1.3000 - val_accuracy: 0.3987

Epoch 00807: val_loss did not improve from 1.29670
Epoch 808/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4063 - val_loss: 1.2975 - val_accuracy: 0.4059

Epoch 00808: val_loss did not improve from 1.29670
Epoch 809/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4068 - val_loss: 1.2989 - val_accuracy: 0.4059

Epoch 00809: val_loss did not improve from 1.29670
Epoch 810/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4066 - val_loss: 1.3011 - val_accuracy: 0.3995

Epoch 00810: val_loss did not improve from 1.29670
Epoch 811/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4024 - val_loss: 1.2997 - val_accuracy: 0.3995

Epoch 00811: val_loss did not improve from 1.29670
Epoch 812/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4050 - val_loss: 1.2981 - val_accuracy: 0.3995

Epoch 00812: val_loss did not improve from 1.29670
Epoch 813/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4044 - val_loss: 1.2992 - val_accuracy: 0.4075

Epoch 00813: val_loss did not improve from 1.29670
Epoch 814/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4060 - val_loss: 1.2991 - val_accuracy: 0.4043

Epoch 00814: val_loss did not improve from 1.29670
Epoch 815/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4059 - val_loss: 1.2983 - val_accuracy: 0.4027

Epoch 00815: val_loss did not improve from 1.29670
Epoch 816/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4051 - val_loss: 1.2971 - val_accuracy: 0.4019

Epoch 00816: val_loss did not improve from 1.29670
Epoch 817/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4019 - val_loss: 1.2969 - val_accuracy: 0.4051

Epoch 00817: val_loss did not improve from 1.29670
Epoch 818/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.3995 - val_loss: 1.3071 - val_accuracy: 0.4003

Epoch 00818: val_loss did not improve from 1.29670
Epoch 819/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4063 - val_loss: 1.2991 - val_accuracy: 0.4043

Epoch 00819: val_loss did not improve from 1.29670
Epoch 820/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4060 - val_loss: 1.2978 - val_accuracy: 0.4043

Epoch 00820: val_loss did not improve from 1.29670
Epoch 821/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.3954 - val_loss: 1.3007 - val_accuracy: 0.4131

Epoch 00821: val_loss did not improve from 1.29670
Epoch 822/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4057 - val_loss: 1.2986 - val_accuracy: 0.4051

Epoch 00822: val_loss did not improve from 1.29670
Epoch 823/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4040 - val_loss: 1.2960 - val_accuracy: 0.4059

Epoch 00823: val_loss improved from 1.29670 to 1.29597, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 824/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4056 - val_loss: 1.2995 - val_accuracy: 0.3995

Epoch 00824: val_loss did not improve from 1.29597
Epoch 825/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4036 - val_loss: 1.2989 - val_accuracy: 0.4011

Epoch 00825: val_loss did not improve from 1.29597
Epoch 826/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4044 - val_loss: 1.2980 - val_accuracy: 0.4067

Epoch 00826: val_loss did not improve from 1.29597
Epoch 827/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4048 - val_loss: 1.2968 - val_accuracy: 0.4019

Epoch 00827: val_loss did not improve from 1.29597
Epoch 828/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4056 - val_loss: 1.2990 - val_accuracy: 0.4075

Epoch 00828: val_loss did not improve from 1.29597
Epoch 829/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4060 - val_loss: 1.2968 - val_accuracy: 0.4035

Epoch 00829: val_loss did not improve from 1.29597
Epoch 830/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4024 - val_loss: 1.2998 - val_accuracy: 0.4067

Epoch 00830: val_loss did not improve from 1.29597
Epoch 831/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4080 - val_loss: 1.2983 - val_accuracy: 0.4035

Epoch 00831: val_loss did not improve from 1.29597
Epoch 832/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4041 - val_loss: 1.2974 - val_accuracy: 0.3995

Epoch 00832: val_loss did not improve from 1.29597
Epoch 833/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4026 - val_loss: 1.3019 - val_accuracy: 0.3995

Epoch 00833: val_loss did not improve from 1.29597
Epoch 834/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4058 - val_loss: 1.2981 - val_accuracy: 0.4091

Epoch 00834: val_loss did not improve from 1.29597
Epoch 835/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4066 - val_loss: 1.3001 - val_accuracy: 0.4003

Epoch 00835: val_loss did not improve from 1.29597
Epoch 836/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4037 - val_loss: 1.2975 - val_accuracy: 0.4043

Epoch 00836: val_loss did not improve from 1.29597
Epoch 837/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4062 - val_loss: 1.2993 - val_accuracy: 0.4075

Epoch 00837: val_loss did not improve from 1.29597
Epoch 838/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4043 - val_loss: 1.2989 - val_accuracy: 0.4051

Epoch 00838: val_loss did not improve from 1.29597
Epoch 839/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4055 - val_loss: 1.3003 - val_accuracy: 0.4011

Epoch 00839: val_loss did not improve from 1.29597
Epoch 840/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4072 - val_loss: 1.2958 - val_accuracy: 0.3987

Epoch 00840: val_loss improved from 1.29597 to 1.29580, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 841/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4055 - val_loss: 1.2985 - val_accuracy: 0.3931

Epoch 00841: val_loss did not improve from 1.29580
Epoch 842/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4042 - val_loss: 1.2980 - val_accuracy: 0.4019

Epoch 00842: val_loss did not improve from 1.29580
Epoch 843/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4044 - val_loss: 1.3014 - val_accuracy: 0.3995

Epoch 00843: val_loss did not improve from 1.29580
Epoch 844/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3990 - val_loss: 1.2981 - val_accuracy: 0.4043

Epoch 00844: val_loss did not improve from 1.29580
Epoch 845/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4032 - val_loss: 1.2987 - val_accuracy: 0.4043

Epoch 00845: val_loss did not improve from 1.29580
Epoch 846/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4071 - val_loss: 1.2988 - val_accuracy: 0.4051

Epoch 00846: val_loss did not improve from 1.29580
Epoch 847/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4081 - val_loss: 1.2970 - val_accuracy: 0.4027

Epoch 00847: val_loss did not improve from 1.29580
Epoch 848/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.3992 - val_loss: 1.3010 - val_accuracy: 0.4011

Epoch 00848: val_loss did not improve from 1.29580
Epoch 849/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4095 - val_loss: 1.2971 - val_accuracy: 0.4003

Epoch 00849: val_loss did not improve from 1.29580
Epoch 850/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4085 - val_loss: 1.2973 - val_accuracy: 0.4011

Epoch 00850: val_loss did not improve from 1.29580
Epoch 851/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4031 - val_loss: 1.2982 - val_accuracy: 0.4011

Epoch 00851: val_loss did not improve from 1.29580
Epoch 852/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4052 - val_loss: 1.2966 - val_accuracy: 0.3987

Epoch 00852: val_loss did not improve from 1.29580
Epoch 853/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4027 - val_loss: 1.2969 - val_accuracy: 0.3987

Epoch 00853: val_loss did not improve from 1.29580
Epoch 854/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4057 - val_loss: 1.2961 - val_accuracy: 0.4035

Epoch 00854: val_loss did not improve from 1.29580
Epoch 855/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4071 - val_loss: 1.2975 - val_accuracy: 0.4051

Epoch 00855: val_loss did not improve from 1.29580
Epoch 856/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4073 - val_loss: 1.2959 - val_accuracy: 0.3987

Epoch 00856: val_loss did not improve from 1.29580
Epoch 857/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4078 - val_loss: 1.2997 - val_accuracy: 0.3979

Epoch 00857: val_loss did not improve from 1.29580
Epoch 858/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4081 - val_loss: 1.2958 - val_accuracy: 0.4011

Epoch 00858: val_loss did not improve from 1.29580
Epoch 859/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4033 - val_loss: 1.2958 - val_accuracy: 0.4011

Epoch 00859: val_loss improved from 1.29580 to 1.29579, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 860/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4022 - val_loss: 1.3027 - val_accuracy: 0.3987

Epoch 00860: val_loss did not improve from 1.29579
Epoch 861/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4053 - val_loss: 1.2956 - val_accuracy: 0.4067

Epoch 00861: val_loss improved from 1.29579 to 1.29556, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 862/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4054 - val_loss: 1.2952 - val_accuracy: 0.4059

Epoch 00862: val_loss improved from 1.29556 to 1.29523, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 863/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.3998 - val_loss: 1.2983 - val_accuracy: 0.4083

Epoch 00863: val_loss did not improve from 1.29523
Epoch 864/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4060 - val_loss: 1.2950 - val_accuracy: 0.4027

Epoch 00864: val_loss improved from 1.29523 to 1.29504, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 865/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4058 - val_loss: 1.2958 - val_accuracy: 0.4075

Epoch 00865: val_loss did not improve from 1.29504
Epoch 866/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4058 - val_loss: 1.2970 - val_accuracy: 0.3995

Epoch 00866: val_loss did not improve from 1.29504
Epoch 867/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4061 - val_loss: 1.2961 - val_accuracy: 0.4067

Epoch 00867: val_loss did not improve from 1.29504
Epoch 868/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4042 - val_loss: 1.2984 - val_accuracy: 0.3995

Epoch 00868: val_loss did not improve from 1.29504
Epoch 869/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4004 - val_loss: 1.2992 - val_accuracy: 0.4099

Epoch 00869: val_loss did not improve from 1.29504
Epoch 870/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4039 - val_loss: 1.3016 - val_accuracy: 0.4043

Epoch 00870: val_loss did not improve from 1.29504
Epoch 871/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4057 - val_loss: 1.2950 - val_accuracy: 0.4003

Epoch 00871: val_loss improved from 1.29504 to 1.29503, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 872/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4040 - val_loss: 1.2945 - val_accuracy: 0.4035

Epoch 00872: val_loss improved from 1.29503 to 1.29446, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 873/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4023 - val_loss: 1.2987 - val_accuracy: 0.4083

Epoch 00873: val_loss did not improve from 1.29446
Epoch 874/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4049 - val_loss: 1.2965 - val_accuracy: 0.4131

Epoch 00874: val_loss did not improve from 1.29446
Epoch 875/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4066 - val_loss: 1.2991 - val_accuracy: 0.4123

Epoch 00875: val_loss did not improve from 1.29446
Epoch 876/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4068 - val_loss: 1.2981 - val_accuracy: 0.4091

Epoch 00876: val_loss did not improve from 1.29446
Epoch 877/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4089 - val_loss: 1.3004 - val_accuracy: 0.4035

Epoch 00877: val_loss did not improve from 1.29446
Epoch 878/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4021 - val_loss: 1.2986 - val_accuracy: 0.4043

Epoch 00878: val_loss did not improve from 1.29446
Epoch 879/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4078 - val_loss: 1.2967 - val_accuracy: 0.4075

Epoch 00879: val_loss did not improve from 1.29446
Epoch 880/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4042 - val_loss: 1.2977 - val_accuracy: 0.3995

Epoch 00880: val_loss did not improve from 1.29446
Epoch 881/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4042 - val_loss: 1.3016 - val_accuracy: 0.3963

Epoch 00881: val_loss did not improve from 1.29446
Epoch 882/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4073 - val_loss: 1.2951 - val_accuracy: 0.4051

Epoch 00882: val_loss did not improve from 1.29446
Epoch 883/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4056 - val_loss: 1.2965 - val_accuracy: 0.4051

Epoch 00883: val_loss did not improve from 1.29446
Epoch 884/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4066 - val_loss: 1.2963 - val_accuracy: 0.4011

Epoch 00884: val_loss did not improve from 1.29446
Epoch 885/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4071 - val_loss: 1.2958 - val_accuracy: 0.4027

Epoch 00885: val_loss did not improve from 1.29446
Epoch 886/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4012 - val_loss: 1.3009 - val_accuracy: 0.4003

Epoch 00886: val_loss did not improve from 1.29446
Epoch 887/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4050 - val_loss: 1.2949 - val_accuracy: 0.4027

Epoch 00887: val_loss did not improve from 1.29446
Epoch 888/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4055 - val_loss: 1.2953 - val_accuracy: 0.4067

Epoch 00888: val_loss did not improve from 1.29446
Epoch 889/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4025 - val_loss: 1.2984 - val_accuracy: 0.4067

Epoch 00889: val_loss did not improve from 1.29446
Epoch 890/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4088 - val_loss: 1.2964 - val_accuracy: 0.3995

Epoch 00890: val_loss did not improve from 1.29446
Epoch 891/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4031 - val_loss: 1.2962 - val_accuracy: 0.3963

Epoch 00891: val_loss did not improve from 1.29446
Epoch 892/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4042 - val_loss: 1.2971 - val_accuracy: 0.4011

Epoch 00892: val_loss did not improve from 1.29446
Epoch 893/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4075 - val_loss: 1.2973 - val_accuracy: 0.4075

Epoch 00893: val_loss did not improve from 1.29446
Epoch 894/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4050 - val_loss: 1.2972 - val_accuracy: 0.4083

Epoch 00894: val_loss did not improve from 1.29446
Epoch 895/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4015 - val_loss: 1.3004 - val_accuracy: 0.4003

Epoch 00895: val_loss did not improve from 1.29446
Epoch 896/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4059 - val_loss: 1.2973 - val_accuracy: 0.4051

Epoch 00896: val_loss did not improve from 1.29446
Epoch 897/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4058 - val_loss: 1.2980 - val_accuracy: 0.4043

Epoch 00897: val_loss did not improve from 1.29446
Epoch 898/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4040 - val_loss: 1.2957 - val_accuracy: 0.4035

Epoch 00898: val_loss did not improve from 1.29446
Epoch 899/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4076 - val_loss: 1.2972 - val_accuracy: 0.4019

Epoch 00899: val_loss did not improve from 1.29446
Epoch 900/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4076 - val_loss: 1.2962 - val_accuracy: 0.4019

Epoch 00900: val_loss did not improve from 1.29446
Epoch 901/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4055 - val_loss: 1.2962 - val_accuracy: 0.4091

Epoch 00901: val_loss did not improve from 1.29446
Epoch 902/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4061 - val_loss: 1.2980 - val_accuracy: 0.4043

Epoch 00902: val_loss did not improve from 1.29446
Epoch 903/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4070 - val_loss: 1.2964 - val_accuracy: 0.3963

Epoch 00903: val_loss did not improve from 1.29446
Epoch 904/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4020 - val_loss: 1.2983 - val_accuracy: 0.3979

Epoch 00904: val_loss did not improve from 1.29446
Epoch 905/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4063 - val_loss: 1.2970 - val_accuracy: 0.3947

Epoch 00905: val_loss did not improve from 1.29446
Epoch 906/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4075 - val_loss: 1.2959 - val_accuracy: 0.4027

Epoch 00906: val_loss did not improve from 1.29446
Epoch 907/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4055 - val_loss: 1.2956 - val_accuracy: 0.3963

Epoch 00907: val_loss did not improve from 1.29446
Epoch 908/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4034 - val_loss: 1.3027 - val_accuracy: 0.4051

Epoch 00908: val_loss did not improve from 1.29446
Epoch 909/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4049 - val_loss: 1.2956 - val_accuracy: 0.4051

Epoch 00909: val_loss did not improve from 1.29446
Epoch 910/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4048 - val_loss: 1.2973 - val_accuracy: 0.4043

Epoch 00910: val_loss did not improve from 1.29446
Epoch 911/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4074 - val_loss: 1.2962 - val_accuracy: 0.4027

Epoch 00911: val_loss did not improve from 1.29446
Epoch 912/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4074 - val_loss: 1.2969 - val_accuracy: 0.4027

Epoch 00912: val_loss did not improve from 1.29446
Epoch 913/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4084 - val_loss: 1.2941 - val_accuracy: 0.4083

Epoch 00913: val_loss improved from 1.29446 to 1.29411, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 914/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.3994 - val_loss: 1.2965 - val_accuracy: 0.4091

Epoch 00914: val_loss did not improve from 1.29411
Epoch 915/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4072 - val_loss: 1.2970 - val_accuracy: 0.4059

Epoch 00915: val_loss did not improve from 1.29411
Epoch 916/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4047 - val_loss: 1.2955 - val_accuracy: 0.4075

Epoch 00916: val_loss did not improve from 1.29411
Epoch 917/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4056 - val_loss: 1.2964 - val_accuracy: 0.4003

Epoch 00917: val_loss did not improve from 1.29411
Epoch 918/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4039 - val_loss: 1.2961 - val_accuracy: 0.4051

Epoch 00918: val_loss did not improve from 1.29411
Epoch 919/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4074 - val_loss: 1.2942 - val_accuracy: 0.4067

Epoch 00919: val_loss did not improve from 1.29411
Epoch 920/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4051 - val_loss: 1.2939 - val_accuracy: 0.4027

Epoch 00920: val_loss improved from 1.29411 to 1.29393, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 921/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4043 - val_loss: 1.2973 - val_accuracy: 0.4011

Epoch 00921: val_loss did not improve from 1.29393
Epoch 922/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4068 - val_loss: 1.2952 - val_accuracy: 0.4051

Epoch 00922: val_loss did not improve from 1.29393
Epoch 923/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4043 - val_loss: 1.2980 - val_accuracy: 0.4003

Epoch 00923: val_loss did not improve from 1.29393
Epoch 924/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4076 - val_loss: 1.2945 - val_accuracy: 0.4067

Epoch 00924: val_loss did not improve from 1.29393
Epoch 925/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4007 - val_loss: 1.2999 - val_accuracy: 0.4043

Epoch 00925: val_loss did not improve from 1.29393
Epoch 926/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4082 - val_loss: 1.2940 - val_accuracy: 0.4083

Epoch 00926: val_loss did not improve from 1.29393
Epoch 927/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4046 - val_loss: 1.2958 - val_accuracy: 0.4067

Epoch 00927: val_loss did not improve from 1.29393
Epoch 928/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4016 - val_loss: 1.2987 - val_accuracy: 0.4083

Epoch 00928: val_loss did not improve from 1.29393
Epoch 929/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4078 - val_loss: 1.2963 - val_accuracy: 0.4075

Epoch 00929: val_loss did not improve from 1.29393
Epoch 930/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4050 - val_loss: 1.2954 - val_accuracy: 0.4051

Epoch 00930: val_loss did not improve from 1.29393
Epoch 931/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4037 - val_loss: 1.2966 - val_accuracy: 0.3987

Epoch 00931: val_loss did not improve from 1.29393
Epoch 932/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4069 - val_loss: 1.2949 - val_accuracy: 0.4059

Epoch 00932: val_loss did not improve from 1.29393
Epoch 933/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4088 - val_loss: 1.2958 - val_accuracy: 0.3987

Epoch 00933: val_loss did not improve from 1.29393
Epoch 934/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4024 - val_loss: 1.2994 - val_accuracy: 0.4011

Epoch 00934: val_loss did not improve from 1.29393
Epoch 935/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4055 - val_loss: 1.2963 - val_accuracy: 0.4083

Epoch 00935: val_loss did not improve from 1.29393
Epoch 936/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4061 - val_loss: 1.2970 - val_accuracy: 0.4091

Epoch 00936: val_loss did not improve from 1.29393
Epoch 937/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4023 - val_loss: 1.2940 - val_accuracy: 0.3923

Epoch 00937: val_loss did not improve from 1.29393
Epoch 938/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4047 - val_loss: 1.2951 - val_accuracy: 0.4067

Epoch 00938: val_loss did not improve from 1.29393
Epoch 939/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4044 - val_loss: 1.2963 - val_accuracy: 0.4027

Epoch 00939: val_loss did not improve from 1.29393
Epoch 940/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4051 - val_loss: 1.2956 - val_accuracy: 0.4051

Epoch 00940: val_loss did not improve from 1.29393
Epoch 941/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4061 - val_loss: 1.2948 - val_accuracy: 0.4027

Epoch 00941: val_loss did not improve from 1.29393
Epoch 942/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4059 - val_loss: 1.2949 - val_accuracy: 0.4011

Epoch 00942: val_loss did not improve from 1.29393
Epoch 943/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4057 - val_loss: 1.2940 - val_accuracy: 0.4003

Epoch 00943: val_loss did not improve from 1.29393
Epoch 944/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4039 - val_loss: 1.2943 - val_accuracy: 0.4051

Epoch 00944: val_loss did not improve from 1.29393
Epoch 945/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4053 - val_loss: 1.2975 - val_accuracy: 0.4011

Epoch 00945: val_loss did not improve from 1.29393
Epoch 946/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4104 - val_loss: 1.2936 - val_accuracy: 0.4027

Epoch 00946: val_loss improved from 1.29393 to 1.29361, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 947/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4037 - val_loss: 1.2944 - val_accuracy: 0.4003

Epoch 00947: val_loss did not improve from 1.29361
Epoch 948/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.3990 - val_loss: 1.2961 - val_accuracy: 0.4035

Epoch 00948: val_loss did not improve from 1.29361
Epoch 949/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4067 - val_loss: 1.2935 - val_accuracy: 0.4027

Epoch 00949: val_loss improved from 1.29361 to 1.29347, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 950/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4026 - val_loss: 1.2953 - val_accuracy: 0.3931

Epoch 00950: val_loss did not improve from 1.29347
Epoch 951/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4032 - val_loss: 1.2981 - val_accuracy: 0.4091

Epoch 00951: val_loss did not improve from 1.29347
Epoch 952/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4036 - val_loss: 1.2974 - val_accuracy: 0.4027

Epoch 00952: val_loss did not improve from 1.29347
Epoch 953/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4076 - val_loss: 1.2937 - val_accuracy: 0.4075

Epoch 00953: val_loss did not improve from 1.29347
Epoch 954/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4081 - val_loss: 1.2954 - val_accuracy: 0.4043

Epoch 00954: val_loss did not improve from 1.29347
Epoch 955/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4059 - val_loss: 1.2945 - val_accuracy: 0.4027

Epoch 00955: val_loss did not improve from 1.29347
Epoch 956/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4037 - val_loss: 1.2937 - val_accuracy: 0.4051

Epoch 00956: val_loss did not improve from 1.29347
Epoch 957/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4070 - val_loss: 1.2944 - val_accuracy: 0.4099

Epoch 00957: val_loss did not improve from 1.29347
Epoch 958/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4077 - val_loss: 1.2951 - val_accuracy: 0.4083

Epoch 00958: val_loss did not improve from 1.29347
Epoch 959/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4063 - val_loss: 1.2948 - val_accuracy: 0.4035

Epoch 00959: val_loss did not improve from 1.29347
Epoch 960/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4089 - val_loss: 1.2947 - val_accuracy: 0.4131

Epoch 00960: val_loss did not improve from 1.29347
Epoch 961/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4070 - val_loss: 1.2968 - val_accuracy: 0.4091

Epoch 00961: val_loss did not improve from 1.29347
Epoch 962/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4018 - val_loss: 1.2987 - val_accuracy: 0.4091

Epoch 00962: val_loss did not improve from 1.29347
Epoch 963/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4054 - val_loss: 1.2931 - val_accuracy: 0.4059

Epoch 00963: val_loss improved from 1.29347 to 1.29315, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 964/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4079 - val_loss: 1.2939 - val_accuracy: 0.4051

Epoch 00964: val_loss did not improve from 1.29315
Epoch 965/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4078 - val_loss: 1.2947 - val_accuracy: 0.4019

Epoch 00965: val_loss did not improve from 1.29315
Epoch 966/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4004 - val_loss: 1.2991 - val_accuracy: 0.4035

Epoch 00966: val_loss did not improve from 1.29315
Epoch 967/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4066 - val_loss: 1.2954 - val_accuracy: 0.4003

Epoch 00967: val_loss did not improve from 1.29315
Epoch 968/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4034 - val_loss: 1.2942 - val_accuracy: 0.4075

Epoch 00968: val_loss did not improve from 1.29315
Epoch 969/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4083 - val_loss: 1.2931 - val_accuracy: 0.4043

Epoch 00969: val_loss improved from 1.29315 to 1.29314, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 970/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4037 - val_loss: 1.2960 - val_accuracy: 0.4011

Epoch 00970: val_loss did not improve from 1.29314
Epoch 971/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4068 - val_loss: 1.2943 - val_accuracy: 0.4083

Epoch 00971: val_loss did not improve from 1.29314
Epoch 972/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4047 - val_loss: 1.2964 - val_accuracy: 0.4011

Epoch 00972: val_loss did not improve from 1.29314
Epoch 973/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4046 - val_loss: 1.2939 - val_accuracy: 0.4075

Epoch 00973: val_loss did not improve from 1.29314
Epoch 974/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4058 - val_loss: 1.2970 - val_accuracy: 0.4043

Epoch 00974: val_loss did not improve from 1.29314
Epoch 975/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4086 - val_loss: 1.2930 - val_accuracy: 0.4091

Epoch 00975: val_loss improved from 1.29314 to 1.29300, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 976/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4071 - val_loss: 1.2949 - val_accuracy: 0.4011

Epoch 00976: val_loss did not improve from 1.29300
Epoch 977/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4041 - val_loss: 1.2932 - val_accuracy: 0.4035

Epoch 00977: val_loss did not improve from 1.29300
Epoch 978/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4097 - val_loss: 1.2927 - val_accuracy: 0.4067

Epoch 00978: val_loss improved from 1.29300 to 1.29270, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 979/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4073 - val_loss: 1.2944 - val_accuracy: 0.4035

Epoch 00979: val_loss did not improve from 1.29270
Epoch 980/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4046 - val_loss: 1.2944 - val_accuracy: 0.4075

Epoch 00980: val_loss did not improve from 1.29270
Epoch 981/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4040 - val_loss: 1.2949 - val_accuracy: 0.3947

Epoch 00981: val_loss did not improve from 1.29270
Epoch 982/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4073 - val_loss: 1.2942 - val_accuracy: 0.4091

Epoch 00982: val_loss did not improve from 1.29270
Epoch 983/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4117 - val_loss: 1.2944 - val_accuracy: 0.4043

Epoch 00983: val_loss did not improve from 1.29270
Epoch 984/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4059 - val_loss: 1.3008 - val_accuracy: 0.4043

Epoch 00984: val_loss did not improve from 1.29270
Epoch 985/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4071 - val_loss: 1.2936 - val_accuracy: 0.4067

Epoch 00985: val_loss did not improve from 1.29270
Epoch 986/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4039 - val_loss: 1.2939 - val_accuracy: 0.4115

Epoch 00986: val_loss did not improve from 1.29270
Epoch 987/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4005 - val_loss: 1.2965 - val_accuracy: 0.4091

Epoch 00987: val_loss did not improve from 1.29270
Epoch 988/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4086 - val_loss: 1.2952 - val_accuracy: 0.4107

Epoch 00988: val_loss did not improve from 1.29270
Epoch 989/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4056 - val_loss: 1.2966 - val_accuracy: 0.4043

Epoch 00989: val_loss did not improve from 1.29270
Epoch 990/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4051 - val_loss: 1.2937 - val_accuracy: 0.4099

Epoch 00990: val_loss did not improve from 1.29270
Epoch 991/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4064 - val_loss: 1.2931 - val_accuracy: 0.4123

Epoch 00991: val_loss did not improve from 1.29270
Epoch 992/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4057 - val_loss: 1.2945 - val_accuracy: 0.4075

Epoch 00992: val_loss did not improve from 1.29270
Epoch 993/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4067 - val_loss: 1.2931 - val_accuracy: 0.4147

Epoch 00993: val_loss did not improve from 1.29270
Epoch 994/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4024 - val_loss: 1.2971 - val_accuracy: 0.4083

Epoch 00994: val_loss did not improve from 1.29270
Epoch 995/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4075 - val_loss: 1.2932 - val_accuracy: 0.4091

Epoch 00995: val_loss did not improve from 1.29270
Epoch 996/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4074 - val_loss: 1.2957 - val_accuracy: 0.3979

Epoch 00996: val_loss did not improve from 1.29270
Epoch 997/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4068 - val_loss: 1.2932 - val_accuracy: 0.4099

Epoch 00997: val_loss did not improve from 1.29270
Epoch 998/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4055 - val_loss: 1.2939 - val_accuracy: 0.4019

Epoch 00998: val_loss did not improve from 1.29270
Epoch 999/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4054 - val_loss: 1.2959 - val_accuracy: 0.4019

Epoch 00999: val_loss did not improve from 1.29270
Epoch 1000/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4074 - val_loss: 1.2923 - val_accuracy: 0.4035

Epoch 01000: val_loss improved from 1.29270 to 1.29226, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1001/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4094 - val_loss: 1.2925 - val_accuracy: 0.4123

Epoch 01001: val_loss did not improve from 1.29226
Epoch 1002/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4078 - val_loss: 1.2947 - val_accuracy: 0.4075

Epoch 01002: val_loss did not improve from 1.29226
Epoch 1003/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4051 - val_loss: 1.2949 - val_accuracy: 0.4059

Epoch 01003: val_loss did not improve from 1.29226
Epoch 1004/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4084 - val_loss: 1.2940 - val_accuracy: 0.4059

Epoch 01004: val_loss did not improve from 1.29226
Epoch 1005/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4093 - val_loss: 1.2963 - val_accuracy: 0.3955

Epoch 01005: val_loss did not improve from 1.29226
Epoch 1006/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4058 - val_loss: 1.2929 - val_accuracy: 0.4115

Epoch 01006: val_loss did not improve from 1.29226
Epoch 1007/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4047 - val_loss: 1.2962 - val_accuracy: 0.4043

Epoch 01007: val_loss did not improve from 1.29226
Epoch 1008/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4078 - val_loss: 1.2926 - val_accuracy: 0.4099

Epoch 01008: val_loss did not improve from 1.29226
Epoch 1009/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4081 - val_loss: 1.2941 - val_accuracy: 0.4107

Epoch 01009: val_loss did not improve from 1.29226
Epoch 1010/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4076 - val_loss: 1.2936 - val_accuracy: 0.4099

Epoch 01010: val_loss did not improve from 1.29226
Epoch 1011/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4060 - val_loss: 1.2953 - val_accuracy: 0.4131

Epoch 01011: val_loss did not improve from 1.29226
Epoch 1012/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4064 - val_loss: 1.2933 - val_accuracy: 0.4083

Epoch 01012: val_loss did not improve from 1.29226
Epoch 1013/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4070 - val_loss: 1.2932 - val_accuracy: 0.4011

Epoch 01013: val_loss did not improve from 1.29226
Epoch 1014/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4068 - val_loss: 1.2940 - val_accuracy: 0.4099

Epoch 01014: val_loss did not improve from 1.29226
Epoch 1015/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4088 - val_loss: 1.2925 - val_accuracy: 0.4107

Epoch 01015: val_loss did not improve from 1.29226
Epoch 1016/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4068 - val_loss: 1.2945 - val_accuracy: 0.4075

Epoch 01016: val_loss did not improve from 1.29226
Epoch 1017/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4099 - val_loss: 1.2937 - val_accuracy: 0.4059

Epoch 01017: val_loss did not improve from 1.29226
Epoch 1018/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4006 - val_loss: 1.3008 - val_accuracy: 0.4059

Epoch 01018: val_loss did not improve from 1.29226
Epoch 1019/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4072 - val_loss: 1.2922 - val_accuracy: 0.4083

Epoch 01019: val_loss improved from 1.29226 to 1.29224, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1020/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4101 - val_loss: 1.2926 - val_accuracy: 0.4123

Epoch 01020: val_loss did not improve from 1.29224
Epoch 1021/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4074 - val_loss: 1.2966 - val_accuracy: 0.4099

Epoch 01021: val_loss did not improve from 1.29224
Epoch 1022/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4080 - val_loss: 1.2943 - val_accuracy: 0.4147

Epoch 01022: val_loss did not improve from 1.29224
Epoch 1023/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4052 - val_loss: 1.2937 - val_accuracy: 0.4083

Epoch 01023: val_loss did not improve from 1.29224
Epoch 1024/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4096 - val_loss: 1.2931 - val_accuracy: 0.4107

Epoch 01024: val_loss did not improve from 1.29224
Epoch 1025/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4077 - val_loss: 1.2926 - val_accuracy: 0.4083

Epoch 01025: val_loss did not improve from 1.29224
Epoch 1026/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4053 - val_loss: 1.2928 - val_accuracy: 0.4083

Epoch 01026: val_loss did not improve from 1.29224
Epoch 1027/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4074 - val_loss: 1.2923 - val_accuracy: 0.4163

Epoch 01027: val_loss did not improve from 1.29224
Epoch 1028/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4066 - val_loss: 1.2932 - val_accuracy: 0.4163

Epoch 01028: val_loss did not improve from 1.29224
Epoch 1029/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4084 - val_loss: 1.2932 - val_accuracy: 0.4091

Epoch 01029: val_loss did not improve from 1.29224
Epoch 1030/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4092 - val_loss: 1.2917 - val_accuracy: 0.4083

Epoch 01030: val_loss improved from 1.29224 to 1.29169, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1031/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4084 - val_loss: 1.2922 - val_accuracy: 0.4115

Epoch 01031: val_loss did not improve from 1.29169
Epoch 1032/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4099 - val_loss: 1.2991 - val_accuracy: 0.3987

Epoch 01032: val_loss did not improve from 1.29169
Epoch 1033/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4072 - val_loss: 1.2927 - val_accuracy: 0.4035

Epoch 01033: val_loss did not improve from 1.29169
Epoch 1034/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4076 - val_loss: 1.2932 - val_accuracy: 0.4123

Epoch 01034: val_loss did not improve from 1.29169
Epoch 1035/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4093 - val_loss: 1.2915 - val_accuracy: 0.4091

Epoch 01035: val_loss improved from 1.29169 to 1.29155, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1036/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4093 - val_loss: 1.2944 - val_accuracy: 0.4075

Epoch 01036: val_loss did not improve from 1.29155
Epoch 1037/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4061 - val_loss: 1.2926 - val_accuracy: 0.4107

Epoch 01037: val_loss did not improve from 1.29155
Epoch 1038/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4059 - val_loss: 1.2951 - val_accuracy: 0.4083

Epoch 01038: val_loss did not improve from 1.29155
Epoch 1039/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4087 - val_loss: 1.2949 - val_accuracy: 0.4123

Epoch 01039: val_loss did not improve from 1.29155
Epoch 1040/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4002 - val_loss: 1.2938 - val_accuracy: 0.4003

Epoch 01040: val_loss did not improve from 1.29155
Epoch 1041/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4057 - val_loss: 1.2963 - val_accuracy: 0.4035

Epoch 01041: val_loss did not improve from 1.29155
Epoch 1042/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4075 - val_loss: 1.2928 - val_accuracy: 0.4051

Epoch 01042: val_loss did not improve from 1.29155
Epoch 1043/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4073 - val_loss: 1.2932 - val_accuracy: 0.4099

Epoch 01043: val_loss did not improve from 1.29155
Epoch 1044/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4071 - val_loss: 1.2954 - val_accuracy: 0.4115

Epoch 01044: val_loss did not improve from 1.29155
Epoch 1045/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4114 - val_loss: 1.2920 - val_accuracy: 0.4155

Epoch 01045: val_loss did not improve from 1.29155
Epoch 1046/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4074 - val_loss: 1.2960 - val_accuracy: 0.4011

Epoch 01046: val_loss did not improve from 1.29155
Epoch 1047/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4074 - val_loss: 1.2922 - val_accuracy: 0.3955

Epoch 01047: val_loss did not improve from 1.29155
Epoch 1048/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4084 - val_loss: 1.2932 - val_accuracy: 0.4043

Epoch 01048: val_loss did not improve from 1.29155
Epoch 1049/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4109 - val_loss: 1.2905 - val_accuracy: 0.4099

Epoch 01049: val_loss improved from 1.29155 to 1.29054, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1050/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4099 - val_loss: 1.2915 - val_accuracy: 0.4083

Epoch 01050: val_loss did not improve from 1.29054
Epoch 1051/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4082 - val_loss: 1.2911 - val_accuracy: 0.4051

Epoch 01051: val_loss did not improve from 1.29054
Epoch 1052/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4074 - val_loss: 1.2931 - val_accuracy: 0.4051

Epoch 01052: val_loss did not improve from 1.29054
Epoch 1053/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4082 - val_loss: 1.2910 - val_accuracy: 0.4091

Epoch 01053: val_loss did not improve from 1.29054
Epoch 1054/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4069 - val_loss: 1.2930 - val_accuracy: 0.4051

Epoch 01054: val_loss did not improve from 1.29054
Epoch 1055/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4096 - val_loss: 1.2915 - val_accuracy: 0.4147

Epoch 01055: val_loss did not improve from 1.29054
Epoch 1056/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4099 - val_loss: 1.2913 - val_accuracy: 0.4051

Epoch 01056: val_loss did not improve from 1.29054
Epoch 1057/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4043 - val_loss: 1.2915 - val_accuracy: 0.4003

Epoch 01057: val_loss did not improve from 1.29054
Epoch 1058/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4096 - val_loss: 1.2931 - val_accuracy: 0.4099

Epoch 01058: val_loss did not improve from 1.29054
Epoch 1059/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4053 - val_loss: 1.2935 - val_accuracy: 0.4051

Epoch 01059: val_loss did not improve from 1.29054
Epoch 1060/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4103 - val_loss: 1.2918 - val_accuracy: 0.4035

Epoch 01060: val_loss did not improve from 1.29054
Epoch 1061/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4105 - val_loss: 1.2917 - val_accuracy: 0.4115

Epoch 01061: val_loss did not improve from 1.29054
Epoch 1062/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4086 - val_loss: 1.2899 - val_accuracy: 0.4115

Epoch 01062: val_loss improved from 1.29054 to 1.28994, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1063/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4074 - val_loss: 1.2930 - val_accuracy: 0.4027

Epoch 01063: val_loss did not improve from 1.28994
Epoch 1064/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4084 - val_loss: 1.2906 - val_accuracy: 0.4107

Epoch 01064: val_loss did not improve from 1.28994
Epoch 1065/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4093 - val_loss: 1.2912 - val_accuracy: 0.4035

Epoch 01065: val_loss did not improve from 1.28994
Epoch 1066/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4085 - val_loss: 1.2917 - val_accuracy: 0.4019

Epoch 01066: val_loss did not improve from 1.28994
Epoch 1067/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4076 - val_loss: 1.2910 - val_accuracy: 0.4075

Epoch 01067: val_loss did not improve from 1.28994
Epoch 1068/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4072 - val_loss: 1.2953 - val_accuracy: 0.4115

Epoch 01068: val_loss did not improve from 1.28994
Epoch 1069/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4090 - val_loss: 1.2910 - val_accuracy: 0.4187

Epoch 01069: val_loss did not improve from 1.28994
Epoch 1070/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4106 - val_loss: 1.2951 - val_accuracy: 0.4091

Epoch 01070: val_loss did not improve from 1.28994
Epoch 1071/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4080 - val_loss: 1.2931 - val_accuracy: 0.4171

Epoch 01071: val_loss did not improve from 1.28994
Epoch 1072/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4078 - val_loss: 1.2932 - val_accuracy: 0.4027

Epoch 01072: val_loss did not improve from 1.28994
Epoch 1073/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4068 - val_loss: 1.2907 - val_accuracy: 0.4155

Epoch 01073: val_loss did not improve from 1.28994
Epoch 1074/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4107 - val_loss: 1.2912 - val_accuracy: 0.4099

Epoch 01074: val_loss did not improve from 1.28994
Epoch 1075/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4067 - val_loss: 1.2899 - val_accuracy: 0.4075

Epoch 01075: val_loss improved from 1.28994 to 1.28988, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1076/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4066 - val_loss: 1.2907 - val_accuracy: 0.4051

Epoch 01076: val_loss did not improve from 1.28988
Epoch 1077/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4059 - val_loss: 1.2918 - val_accuracy: 0.4091

Epoch 01077: val_loss did not improve from 1.28988
Epoch 1078/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4076 - val_loss: 1.2915 - val_accuracy: 0.4059

Epoch 01078: val_loss did not improve from 1.28988
Epoch 1079/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4047 - val_loss: 1.2917 - val_accuracy: 0.4107

Epoch 01079: val_loss did not improve from 1.28988
Epoch 1080/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4051 - val_loss: 1.2928 - val_accuracy: 0.4027

Epoch 01080: val_loss did not improve from 1.28988
Epoch 1081/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4080 - val_loss: 1.2907 - val_accuracy: 0.4083

Epoch 01081: val_loss did not improve from 1.28988
Epoch 1082/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4086 - val_loss: 1.2918 - val_accuracy: 0.4075

Epoch 01082: val_loss did not improve from 1.28988
Epoch 1083/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4109 - val_loss: 1.2954 - val_accuracy: 0.3963

Epoch 01083: val_loss did not improve from 1.28988
Epoch 1084/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4066 - val_loss: 1.2898 - val_accuracy: 0.4147

Epoch 01084: val_loss improved from 1.28988 to 1.28981, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1085/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4095 - val_loss: 1.2904 - val_accuracy: 0.4131

Epoch 01085: val_loss did not improve from 1.28981
Epoch 1086/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4107 - val_loss: 1.2903 - val_accuracy: 0.4147

Epoch 01086: val_loss did not improve from 1.28981
Epoch 1087/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4107 - val_loss: 1.2902 - val_accuracy: 0.4035

Epoch 01087: val_loss did not improve from 1.28981
Epoch 1088/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4084 - val_loss: 1.2915 - val_accuracy: 0.4123

Epoch 01088: val_loss did not improve from 1.28981
Epoch 1089/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4052 - val_loss: 1.2932 - val_accuracy: 0.4027

Epoch 01089: val_loss did not improve from 1.28981
Epoch 1090/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4094 - val_loss: 1.2896 - val_accuracy: 0.4203

Epoch 01090: val_loss improved from 1.28981 to 1.28955, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1091/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4079 - val_loss: 1.2927 - val_accuracy: 0.4059

Epoch 01091: val_loss did not improve from 1.28955
Epoch 1092/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4078 - val_loss: 1.2916 - val_accuracy: 0.4059

Epoch 01092: val_loss did not improve from 1.28955
Epoch 1093/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4090 - val_loss: 1.2892 - val_accuracy: 0.4171

Epoch 01093: val_loss improved from 1.28955 to 1.28918, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1094/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4093 - val_loss: 1.2921 - val_accuracy: 0.4115

Epoch 01094: val_loss did not improve from 1.28918
Epoch 1095/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4032 - val_loss: 1.2918 - val_accuracy: 0.4019

Epoch 01095: val_loss did not improve from 1.28918
Epoch 1096/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4112 - val_loss: 1.2901 - val_accuracy: 0.4091

Epoch 01096: val_loss did not improve from 1.28918
Epoch 1097/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4070 - val_loss: 1.2953 - val_accuracy: 0.3971

Epoch 01097: val_loss did not improve from 1.28918
Epoch 1098/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4041 - val_loss: 1.2912 - val_accuracy: 0.4107

Epoch 01098: val_loss did not improve from 1.28918
Epoch 1099/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4078 - val_loss: 1.2955 - val_accuracy: 0.4043

Epoch 01099: val_loss did not improve from 1.28918
Epoch 1100/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4074 - val_loss: 1.2911 - val_accuracy: 0.4091

Epoch 01100: val_loss did not improve from 1.28918
Epoch 1101/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4074 - val_loss: 1.2900 - val_accuracy: 0.4091

Epoch 01101: val_loss did not improve from 1.28918
Epoch 1102/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4089 - val_loss: 1.2906 - val_accuracy: 0.4115

Epoch 01102: val_loss did not improve from 1.28918
Epoch 1103/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4091 - val_loss: 1.2902 - val_accuracy: 0.4131

Epoch 01103: val_loss did not improve from 1.28918
Epoch 1104/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4088 - val_loss: 1.2921 - val_accuracy: 0.4107

Epoch 01104: val_loss did not improve from 1.28918
Epoch 1105/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4096 - val_loss: 1.2919 - val_accuracy: 0.4155

Epoch 01105: val_loss did not improve from 1.28918
Epoch 1106/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4060 - val_loss: 1.2901 - val_accuracy: 0.4147

Epoch 01106: val_loss did not improve from 1.28918
Epoch 1107/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4082 - val_loss: 1.2960 - val_accuracy: 0.4075

Epoch 01107: val_loss did not improve from 1.28918
Epoch 1108/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4086 - val_loss: 1.2889 - val_accuracy: 0.4083

Epoch 01108: val_loss improved from 1.28918 to 1.28891, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1109/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4029 - val_loss: 1.2938 - val_accuracy: 0.4035

Epoch 01109: val_loss did not improve from 1.28891
Epoch 1110/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4069 - val_loss: 1.2906 - val_accuracy: 0.4115

Epoch 01110: val_loss did not improve from 1.28891
Epoch 1111/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4061 - val_loss: 1.2898 - val_accuracy: 0.4187

Epoch 01111: val_loss did not improve from 1.28891
Epoch 1112/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4062 - val_loss: 1.2886 - val_accuracy: 0.4075

Epoch 01112: val_loss improved from 1.28891 to 1.28861, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1113/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4045 - val_loss: 1.2971 - val_accuracy: 0.4019

Epoch 01113: val_loss did not improve from 1.28861
Epoch 1114/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4077 - val_loss: 1.2895 - val_accuracy: 0.4083

Epoch 01114: val_loss did not improve from 1.28861
Epoch 1115/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4071 - val_loss: 1.2906 - val_accuracy: 0.4019

Epoch 01115: val_loss did not improve from 1.28861
Epoch 1116/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4093 - val_loss: 1.2900 - val_accuracy: 0.4067

Epoch 01116: val_loss did not improve from 1.28861
Epoch 1117/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4078 - val_loss: 1.2906 - val_accuracy: 0.4226

Epoch 01117: val_loss did not improve from 1.28861
Epoch 1118/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4084 - val_loss: 1.2958 - val_accuracy: 0.4051

Epoch 01118: val_loss did not improve from 1.28861
Epoch 1119/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4061 - val_loss: 1.2894 - val_accuracy: 0.4123

Epoch 01119: val_loss did not improve from 1.28861
Epoch 1120/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4109 - val_loss: 1.2890 - val_accuracy: 0.4123

Epoch 01120: val_loss did not improve from 1.28861
Epoch 1121/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4070 - val_loss: 1.2920 - val_accuracy: 0.4147

Epoch 01121: val_loss did not improve from 1.28861
Epoch 1122/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4085 - val_loss: 1.2917 - val_accuracy: 0.4035

Epoch 01122: val_loss did not improve from 1.28861
Epoch 1123/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4071 - val_loss: 1.2912 - val_accuracy: 0.4139

Epoch 01123: val_loss did not improve from 1.28861
Epoch 1124/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4077 - val_loss: 1.2941 - val_accuracy: 0.4059

Epoch 01124: val_loss did not improve from 1.28861
Epoch 1125/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4067 - val_loss: 1.2914 - val_accuracy: 0.4059

Epoch 01125: val_loss did not improve from 1.28861
Epoch 1126/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4078 - val_loss: 1.2952 - val_accuracy: 0.4035

Epoch 01126: val_loss did not improve from 1.28861
Epoch 1127/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4058 - val_loss: 1.2915 - val_accuracy: 0.4115

Epoch 01127: val_loss did not improve from 1.28861
Epoch 1128/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4067 - val_loss: 1.2890 - val_accuracy: 0.4067

Epoch 01128: val_loss did not improve from 1.28861
Epoch 1129/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4078 - val_loss: 1.2911 - val_accuracy: 0.4067

Epoch 01129: val_loss did not improve from 1.28861
Epoch 1130/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4054 - val_loss: 1.2890 - val_accuracy: 0.4139

Epoch 01130: val_loss did not improve from 1.28861
Epoch 1131/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4059 - val_loss: 1.2895 - val_accuracy: 0.4123

Epoch 01131: val_loss did not improve from 1.28861
Epoch 1132/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4093 - val_loss: 1.2881 - val_accuracy: 0.4115

Epoch 01132: val_loss improved from 1.28861 to 1.28809, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1133/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4112 - val_loss: 1.2870 - val_accuracy: 0.4139

Epoch 01133: val_loss improved from 1.28809 to 1.28704, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1134/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4046 - val_loss: 1.2882 - val_accuracy: 0.4059

Epoch 01134: val_loss did not improve from 1.28704
Epoch 1135/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4094 - val_loss: 1.2902 - val_accuracy: 0.4107

Epoch 01135: val_loss did not improve from 1.28704
Epoch 1136/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4091 - val_loss: 1.2893 - val_accuracy: 0.4203

Epoch 01136: val_loss did not improve from 1.28704
Epoch 1137/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4095 - val_loss: 1.2888 - val_accuracy: 0.4075

Epoch 01137: val_loss did not improve from 1.28704
Epoch 1138/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4071 - val_loss: 1.2884 - val_accuracy: 0.4099

Epoch 01138: val_loss did not improve from 1.28704
Epoch 1139/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4125 - val_loss: 1.2915 - val_accuracy: 0.4099

Epoch 01139: val_loss did not improve from 1.28704
Epoch 1140/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4105 - val_loss: 1.2904 - val_accuracy: 0.4059

Epoch 01140: val_loss did not improve from 1.28704
Epoch 1141/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4085 - val_loss: 1.2889 - val_accuracy: 0.4163

Epoch 01141: val_loss did not improve from 1.28704
Epoch 1142/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4090 - val_loss: 1.2881 - val_accuracy: 0.4115

Epoch 01142: val_loss did not improve from 1.28704
Epoch 1143/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4096 - val_loss: 1.2890 - val_accuracy: 0.4171

Epoch 01143: val_loss did not improve from 1.28704
Epoch 1144/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4080 - val_loss: 1.2911 - val_accuracy: 0.4075

Epoch 01144: val_loss did not improve from 1.28704
Epoch 1145/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4040 - val_loss: 1.2890 - val_accuracy: 0.4171

Epoch 01145: val_loss did not improve from 1.28704
Epoch 1146/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4088 - val_loss: 1.2937 - val_accuracy: 0.4163

Epoch 01146: val_loss did not improve from 1.28704
Epoch 1147/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4063 - val_loss: 1.2878 - val_accuracy: 0.4155

Epoch 01147: val_loss did not improve from 1.28704
Epoch 1148/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4084 - val_loss: 1.2884 - val_accuracy: 0.4099

Epoch 01148: val_loss did not improve from 1.28704
Epoch 1149/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4072 - val_loss: 1.2900 - val_accuracy: 0.4131

Epoch 01149: val_loss did not improve from 1.28704
Epoch 1150/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4101 - val_loss: 1.2884 - val_accuracy: 0.4163

Epoch 01150: val_loss did not improve from 1.28704
Epoch 1151/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4091 - val_loss: 1.2888 - val_accuracy: 0.4131

Epoch 01151: val_loss did not improve from 1.28704
Epoch 1152/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4086 - val_loss: 1.2871 - val_accuracy: 0.4067

Epoch 01152: val_loss did not improve from 1.28704
Epoch 1153/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4060 - val_loss: 1.2892 - val_accuracy: 0.4123

Epoch 01153: val_loss did not improve from 1.28704
Epoch 1154/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4100 - val_loss: 1.2876 - val_accuracy: 0.4203

Epoch 01154: val_loss did not improve from 1.28704
Epoch 1155/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4077 - val_loss: 1.2881 - val_accuracy: 0.4147

Epoch 01155: val_loss did not improve from 1.28704
Epoch 1156/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4090 - val_loss: 1.2928 - val_accuracy: 0.4067

Epoch 01156: val_loss did not improve from 1.28704
Epoch 1157/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4088 - val_loss: 1.2885 - val_accuracy: 0.4242

Epoch 01157: val_loss did not improve from 1.28704
Epoch 1158/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4068 - val_loss: 1.2916 - val_accuracy: 0.4155

Epoch 01158: val_loss did not improve from 1.28704
Epoch 1159/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4109 - val_loss: 1.2898 - val_accuracy: 0.4195

Epoch 01159: val_loss did not improve from 1.28704
Epoch 1160/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4093 - val_loss: 1.2897 - val_accuracy: 0.4171

Epoch 01160: val_loss did not improve from 1.28704
Epoch 1161/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4113 - val_loss: 1.2887 - val_accuracy: 0.4059

Epoch 01161: val_loss did not improve from 1.28704
Epoch 1162/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4104 - val_loss: 1.2873 - val_accuracy: 0.4139

Epoch 01162: val_loss did not improve from 1.28704
Epoch 1163/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4085 - val_loss: 1.2879 - val_accuracy: 0.4179

Epoch 01163: val_loss did not improve from 1.28704
Epoch 1164/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4093 - val_loss: 1.2875 - val_accuracy: 0.4139

Epoch 01164: val_loss did not improve from 1.28704
Epoch 1165/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4084 - val_loss: 1.2868 - val_accuracy: 0.4123

Epoch 01165: val_loss improved from 1.28704 to 1.28684, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1166/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4067 - val_loss: 1.2920 - val_accuracy: 0.4091

Epoch 01166: val_loss did not improve from 1.28684
Epoch 1167/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4088 - val_loss: 1.2869 - val_accuracy: 0.4219

Epoch 01167: val_loss did not improve from 1.28684
Epoch 1168/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4095 - val_loss: 1.2921 - val_accuracy: 0.3995

Epoch 01168: val_loss did not improve from 1.28684
Epoch 1169/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4073 - val_loss: 1.2895 - val_accuracy: 0.4123

Epoch 01169: val_loss did not improve from 1.28684
Epoch 1170/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4098 - val_loss: 1.2885 - val_accuracy: 0.4139

Epoch 01170: val_loss did not improve from 1.28684
Epoch 1171/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4087 - val_loss: 1.2895 - val_accuracy: 0.4099

Epoch 01171: val_loss did not improve from 1.28684
Epoch 1172/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4078 - val_loss: 1.2880 - val_accuracy: 0.4131

Epoch 01172: val_loss did not improve from 1.28684
Epoch 1173/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4098 - val_loss: 1.2883 - val_accuracy: 0.4091

Epoch 01173: val_loss did not improve from 1.28684
Epoch 1174/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4119 - val_loss: 1.2889 - val_accuracy: 0.4067

Epoch 01174: val_loss did not improve from 1.28684
Epoch 1175/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4100 - val_loss: 1.2858 - val_accuracy: 0.4147

Epoch 01175: val_loss improved from 1.28684 to 1.28583, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1176/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4109 - val_loss: 1.2876 - val_accuracy: 0.4035

Epoch 01176: val_loss did not improve from 1.28583
Epoch 1177/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4079 - val_loss: 1.2869 - val_accuracy: 0.4155

Epoch 01177: val_loss did not improve from 1.28583
Epoch 1178/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4049 - val_loss: 1.2914 - val_accuracy: 0.4019

Epoch 01178: val_loss did not improve from 1.28583
Epoch 1179/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4089 - val_loss: 1.2868 - val_accuracy: 0.4131

Epoch 01179: val_loss did not improve from 1.28583
Epoch 1180/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4101 - val_loss: 1.2871 - val_accuracy: 0.4147

Epoch 01180: val_loss did not improve from 1.28583
Epoch 1181/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4116 - val_loss: 1.2870 - val_accuracy: 0.4155

Epoch 01181: val_loss did not improve from 1.28583
Epoch 1182/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4101 - val_loss: 1.2912 - val_accuracy: 0.4171

Epoch 01182: val_loss did not improve from 1.28583
Epoch 1183/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4089 - val_loss: 1.2866 - val_accuracy: 0.4187

Epoch 01183: val_loss did not improve from 1.28583
Epoch 1184/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4082 - val_loss: 1.2898 - val_accuracy: 0.4091

Epoch 01184: val_loss did not improve from 1.28583
Epoch 1185/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4086 - val_loss: 1.2872 - val_accuracy: 0.4123

Epoch 01185: val_loss did not improve from 1.28583
Epoch 1186/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4070 - val_loss: 1.2857 - val_accuracy: 0.4211

Epoch 01186: val_loss improved from 1.28583 to 1.28570, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1187/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4111 - val_loss: 1.2880 - val_accuracy: 0.4075

Epoch 01187: val_loss did not improve from 1.28570
Epoch 1188/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4100 - val_loss: 1.2871 - val_accuracy: 0.4179

Epoch 01188: val_loss did not improve from 1.28570
Epoch 1189/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4102 - val_loss: 1.2879 - val_accuracy: 0.4226

Epoch 01189: val_loss did not improve from 1.28570
Epoch 1190/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4070 - val_loss: 1.2959 - val_accuracy: 0.3947

Epoch 01190: val_loss did not improve from 1.28570
Epoch 1191/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4096 - val_loss: 1.2849 - val_accuracy: 0.4155

Epoch 01191: val_loss improved from 1.28570 to 1.28487, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1192/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4101 - val_loss: 1.2883 - val_accuracy: 0.4075

Epoch 01192: val_loss did not improve from 1.28487
Epoch 1193/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4079 - val_loss: 1.2858 - val_accuracy: 0.4234

Epoch 01193: val_loss did not improve from 1.28487
Epoch 1194/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4103 - val_loss: 1.2885 - val_accuracy: 0.4107

Epoch 01194: val_loss did not improve from 1.28487
Epoch 1195/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4095 - val_loss: 1.2871 - val_accuracy: 0.4274

Epoch 01195: val_loss did not improve from 1.28487
Epoch 1196/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4048 - val_loss: 1.2907 - val_accuracy: 0.4163

Epoch 01196: val_loss did not improve from 1.28487
Epoch 1197/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4092 - val_loss: 1.2892 - val_accuracy: 0.4147

Epoch 01197: val_loss did not improve from 1.28487
Epoch 1198/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4089 - val_loss: 1.2858 - val_accuracy: 0.4226

Epoch 01198: val_loss did not improve from 1.28487
Epoch 1199/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4082 - val_loss: 1.2845 - val_accuracy: 0.4219

Epoch 01199: val_loss improved from 1.28487 to 1.28451, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1200/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4065 - val_loss: 1.2908 - val_accuracy: 0.4075

Epoch 01200: val_loss did not improve from 1.28451
Epoch 1201/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4076 - val_loss: 1.2861 - val_accuracy: 0.4155

Epoch 01201: val_loss did not improve from 1.28451
Epoch 1202/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4086 - val_loss: 1.2895 - val_accuracy: 0.4139

Epoch 01202: val_loss did not improve from 1.28451
Epoch 1203/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4070 - val_loss: 1.2910 - val_accuracy: 0.4131

Epoch 01203: val_loss did not improve from 1.28451
Epoch 1204/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4043 - val_loss: 1.2879 - val_accuracy: 0.4234

Epoch 01204: val_loss did not improve from 1.28451
Epoch 1205/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4104 - val_loss: 1.2912 - val_accuracy: 0.4019

Epoch 01205: val_loss did not improve from 1.28451
Epoch 1206/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4102 - val_loss: 1.2854 - val_accuracy: 0.4179

Epoch 01206: val_loss did not improve from 1.28451
Epoch 1207/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4111 - val_loss: 1.2860 - val_accuracy: 0.4242

Epoch 01207: val_loss did not improve from 1.28451
Epoch 1208/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4085 - val_loss: 1.2877 - val_accuracy: 0.4147

Epoch 01208: val_loss did not improve from 1.28451
Epoch 1209/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4090 - val_loss: 1.2853 - val_accuracy: 0.4171

Epoch 01209: val_loss did not improve from 1.28451
Epoch 1210/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4071 - val_loss: 1.2887 - val_accuracy: 0.4139

Epoch 01210: val_loss did not improve from 1.28451
Epoch 1211/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4120 - val_loss: 1.2857 - val_accuracy: 0.4250

Epoch 01211: val_loss did not improve from 1.28451
Epoch 1212/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4047 - val_loss: 1.2864 - val_accuracy: 0.4099

Epoch 01212: val_loss did not improve from 1.28451
Epoch 1213/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4090 - val_loss: 1.2862 - val_accuracy: 0.4147

Epoch 01213: val_loss did not improve from 1.28451
Epoch 1214/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4099 - val_loss: 1.2878 - val_accuracy: 0.4155

Epoch 01214: val_loss did not improve from 1.28451
Epoch 1215/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4073 - val_loss: 1.2874 - val_accuracy: 0.4203

Epoch 01215: val_loss did not improve from 1.28451
Epoch 1216/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4104 - val_loss: 1.2948 - val_accuracy: 0.4019

Epoch 01216: val_loss did not improve from 1.28451
Epoch 1217/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4099 - val_loss: 1.2914 - val_accuracy: 0.3955

Epoch 01217: val_loss did not improve from 1.28451
Epoch 1218/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4030 - val_loss: 1.2869 - val_accuracy: 0.4051

Epoch 01218: val_loss did not improve from 1.28451
Epoch 1219/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4070 - val_loss: 1.2911 - val_accuracy: 0.4051

Epoch 01219: val_loss did not improve from 1.28451
Epoch 1220/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4075 - val_loss: 1.2872 - val_accuracy: 0.4067

Epoch 01220: val_loss did not improve from 1.28451
Epoch 1221/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4104 - val_loss: 1.2885 - val_accuracy: 0.4091

Epoch 01221: val_loss did not improve from 1.28451
Epoch 1222/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4109 - val_loss: 1.2874 - val_accuracy: 0.4067

Epoch 01222: val_loss did not improve from 1.28451
Epoch 1223/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4088 - val_loss: 1.2847 - val_accuracy: 0.4171

Epoch 01223: val_loss did not improve from 1.28451
Epoch 1224/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4085 - val_loss: 1.2861 - val_accuracy: 0.4131

Epoch 01224: val_loss did not improve from 1.28451
Epoch 1225/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4108 - val_loss: 1.2846 - val_accuracy: 0.4171

Epoch 01225: val_loss did not improve from 1.28451
Epoch 1226/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4110 - val_loss: 1.2864 - val_accuracy: 0.4139

Epoch 01226: val_loss did not improve from 1.28451
Epoch 1227/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4086 - val_loss: 1.2845 - val_accuracy: 0.4131

Epoch 01227: val_loss did not improve from 1.28451
Epoch 1228/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4107 - val_loss: 1.2885 - val_accuracy: 0.4155

Epoch 01228: val_loss did not improve from 1.28451
Epoch 1229/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4104 - val_loss: 1.2863 - val_accuracy: 0.4219

Epoch 01229: val_loss did not improve from 1.28451
Epoch 1230/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4065 - val_loss: 1.2872 - val_accuracy: 0.4171

Epoch 01230: val_loss did not improve from 1.28451
Epoch 1231/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4095 - val_loss: 1.2845 - val_accuracy: 0.4139

Epoch 01231: val_loss did not improve from 1.28451
Epoch 1232/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4112 - val_loss: 1.2868 - val_accuracy: 0.4107

Epoch 01232: val_loss did not improve from 1.28451
Epoch 1233/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4129 - val_loss: 1.2848 - val_accuracy: 0.4250

Epoch 01233: val_loss did not improve from 1.28451
Epoch 1234/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4120 - val_loss: 1.2869 - val_accuracy: 0.4211

Epoch 01234: val_loss did not improve from 1.28451
Epoch 1235/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4102 - val_loss: 1.2871 - val_accuracy: 0.4147

Epoch 01235: val_loss did not improve from 1.28451
Epoch 1236/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4113 - val_loss: 1.2853 - val_accuracy: 0.4123

Epoch 01236: val_loss did not improve from 1.28451
Epoch 1237/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4130 - val_loss: 1.2847 - val_accuracy: 0.4234

Epoch 01237: val_loss did not improve from 1.28451
Epoch 1238/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4096 - val_loss: 1.2897 - val_accuracy: 0.4107

Epoch 01238: val_loss did not improve from 1.28451
Epoch 1239/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4094 - val_loss: 1.2881 - val_accuracy: 0.4067

Epoch 01239: val_loss did not improve from 1.28451
Epoch 1240/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4102 - val_loss: 1.2853 - val_accuracy: 0.4211

Epoch 01240: val_loss did not improve from 1.28451
Epoch 1241/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4104 - val_loss: 1.2836 - val_accuracy: 0.4139

Epoch 01241: val_loss improved from 1.28451 to 1.28364, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1242/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4103 - val_loss: 1.2853 - val_accuracy: 0.4115

Epoch 01242: val_loss did not improve from 1.28364
Epoch 1243/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4083 - val_loss: 1.2861 - val_accuracy: 0.4226

Epoch 01243: val_loss did not improve from 1.28364
Epoch 1244/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4075 - val_loss: 1.2893 - val_accuracy: 0.4107

Epoch 01244: val_loss did not improve from 1.28364
Epoch 1245/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4101 - val_loss: 1.2852 - val_accuracy: 0.4219

Epoch 01245: val_loss did not improve from 1.28364
Epoch 1246/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4092 - val_loss: 1.2859 - val_accuracy: 0.4187

Epoch 01246: val_loss did not improve from 1.28364
Epoch 1247/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4121 - val_loss: 1.2857 - val_accuracy: 0.4163

Epoch 01247: val_loss did not improve from 1.28364
Epoch 1248/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4104 - val_loss: 1.2866 - val_accuracy: 0.4179

Epoch 01248: val_loss did not improve from 1.28364
Epoch 1249/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4096 - val_loss: 1.2858 - val_accuracy: 0.4195

Epoch 01249: val_loss did not improve from 1.28364
Epoch 1250/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4121 - val_loss: 1.2859 - val_accuracy: 0.4131

Epoch 01250: val_loss did not improve from 1.28364
Epoch 1251/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4039 - val_loss: 1.2872 - val_accuracy: 0.4131

Epoch 01251: val_loss did not improve from 1.28364
Epoch 1252/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4110 - val_loss: 1.2853 - val_accuracy: 0.4179

Epoch 01252: val_loss did not improve from 1.28364
Epoch 1253/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4076 - val_loss: 1.2876 - val_accuracy: 0.4115

Epoch 01253: val_loss did not improve from 1.28364
Epoch 1254/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4096 - val_loss: 1.2840 - val_accuracy: 0.4234

Epoch 01254: val_loss did not improve from 1.28364
Epoch 1255/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4088 - val_loss: 1.2859 - val_accuracy: 0.4067

Epoch 01255: val_loss did not improve from 1.28364
Epoch 1256/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4116 - val_loss: 1.2870 - val_accuracy: 0.4027

Epoch 01256: val_loss did not improve from 1.28364
Epoch 1257/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4082 - val_loss: 1.2854 - val_accuracy: 0.4147

Epoch 01257: val_loss did not improve from 1.28364
Epoch 1258/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4117 - val_loss: 1.2870 - val_accuracy: 0.4099

Epoch 01258: val_loss did not improve from 1.28364
Epoch 1259/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4116 - val_loss: 1.2862 - val_accuracy: 0.4099

Epoch 01259: val_loss did not improve from 1.28364
Epoch 1260/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4116 - val_loss: 1.2888 - val_accuracy: 0.4035

Epoch 01260: val_loss did not improve from 1.28364
Epoch 1261/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4112 - val_loss: 1.2837 - val_accuracy: 0.4155

Epoch 01261: val_loss did not improve from 1.28364
Epoch 1262/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4119 - val_loss: 1.2833 - val_accuracy: 0.4234

Epoch 01262: val_loss improved from 1.28364 to 1.28332, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1263/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4092 - val_loss: 1.2862 - val_accuracy: 0.4059

Epoch 01263: val_loss did not improve from 1.28332
Epoch 1264/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4107 - val_loss: 1.2827 - val_accuracy: 0.4083

Epoch 01264: val_loss improved from 1.28332 to 1.28274, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1265/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4109 - val_loss: 1.2843 - val_accuracy: 0.4115

Epoch 01265: val_loss did not improve from 1.28274
Epoch 1266/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4111 - val_loss: 1.2873 - val_accuracy: 0.4091

Epoch 01266: val_loss did not improve from 1.28274
Epoch 1267/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4101 - val_loss: 1.2837 - val_accuracy: 0.4163

Epoch 01267: val_loss did not improve from 1.28274
Epoch 1268/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4087 - val_loss: 1.2829 - val_accuracy: 0.4155

Epoch 01268: val_loss did not improve from 1.28274
Epoch 1269/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4109 - val_loss: 1.2833 - val_accuracy: 0.4099

Epoch 01269: val_loss did not improve from 1.28274
Epoch 1270/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4116 - val_loss: 1.2833 - val_accuracy: 0.4219

Epoch 01270: val_loss did not improve from 1.28274
Epoch 1271/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4122 - val_loss: 1.2828 - val_accuracy: 0.4226

Epoch 01271: val_loss did not improve from 1.28274
Epoch 1272/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4089 - val_loss: 1.2846 - val_accuracy: 0.4163

Epoch 01272: val_loss did not improve from 1.28274
Epoch 1273/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4087 - val_loss: 1.2851 - val_accuracy: 0.4147

Epoch 01273: val_loss did not improve from 1.28274
Epoch 1274/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4083 - val_loss: 1.2882 - val_accuracy: 0.4059

Epoch 01274: val_loss did not improve from 1.28274
Epoch 1275/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4127 - val_loss: 1.2823 - val_accuracy: 0.4163

Epoch 01275: val_loss improved from 1.28274 to 1.28234, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1276/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4134 - val_loss: 1.2835 - val_accuracy: 0.4179

Epoch 01276: val_loss did not improve from 1.28234
Epoch 1277/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4133 - val_loss: 1.2830 - val_accuracy: 0.4187

Epoch 01277: val_loss did not improve from 1.28234
Epoch 1278/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4114 - val_loss: 1.2838 - val_accuracy: 0.4099

Epoch 01278: val_loss did not improve from 1.28234
Epoch 1279/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4136 - val_loss: 1.2839 - val_accuracy: 0.4083

Epoch 01279: val_loss did not improve from 1.28234
Epoch 1280/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4121 - val_loss: 1.2836 - val_accuracy: 0.4139

Epoch 01280: val_loss did not improve from 1.28234
Epoch 1281/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4095 - val_loss: 1.2836 - val_accuracy: 0.4131

Epoch 01281: val_loss did not improve from 1.28234
Epoch 1282/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4073 - val_loss: 1.2833 - val_accuracy: 0.4234

Epoch 01282: val_loss did not improve from 1.28234
Epoch 1283/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4071 - val_loss: 1.2881 - val_accuracy: 0.4011

Epoch 01283: val_loss did not improve from 1.28234
Epoch 1284/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4123 - val_loss: 1.2830 - val_accuracy: 0.4171

Epoch 01284: val_loss did not improve from 1.28234
Epoch 1285/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4106 - val_loss: 1.2871 - val_accuracy: 0.4075

Epoch 01285: val_loss did not improve from 1.28234
Epoch 1286/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4110 - val_loss: 1.2826 - val_accuracy: 0.4171

Epoch 01286: val_loss did not improve from 1.28234
Epoch 1287/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4114 - val_loss: 1.2827 - val_accuracy: 0.4171

Epoch 01287: val_loss did not improve from 1.28234
Epoch 1288/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4109 - val_loss: 1.2850 - val_accuracy: 0.4139

Epoch 01288: val_loss did not improve from 1.28234
Epoch 1289/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4087 - val_loss: 1.2829 - val_accuracy: 0.4195

Epoch 01289: val_loss did not improve from 1.28234
Epoch 1290/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4146 - val_loss: 1.2828 - val_accuracy: 0.4147

Epoch 01290: val_loss did not improve from 1.28234
Epoch 1291/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4116 - val_loss: 1.2825 - val_accuracy: 0.4139

Epoch 01291: val_loss did not improve from 1.28234
Epoch 1292/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4108 - val_loss: 1.2826 - val_accuracy: 0.4242

Epoch 01292: val_loss did not improve from 1.28234
Epoch 1293/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4107 - val_loss: 1.2845 - val_accuracy: 0.4107

Epoch 01293: val_loss did not improve from 1.28234
Epoch 1294/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4098 - val_loss: 1.2836 - val_accuracy: 0.4226

Epoch 01294: val_loss did not improve from 1.28234
Epoch 1295/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4070 - val_loss: 1.2862 - val_accuracy: 0.4035

Epoch 01295: val_loss did not improve from 1.28234
Epoch 1296/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4108 - val_loss: 1.2823 - val_accuracy: 0.4211

Epoch 01296: val_loss improved from 1.28234 to 1.28225, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1297/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4114 - val_loss: 1.2850 - val_accuracy: 0.4123

Epoch 01297: val_loss did not improve from 1.28225
Epoch 1298/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4137 - val_loss: 1.2832 - val_accuracy: 0.4203

Epoch 01298: val_loss did not improve from 1.28225
Epoch 1299/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4121 - val_loss: 1.2840 - val_accuracy: 0.4123

Epoch 01299: val_loss did not improve from 1.28225
Epoch 1300/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4103 - val_loss: 1.2852 - val_accuracy: 0.4163

Epoch 01300: val_loss did not improve from 1.28225
Epoch 1301/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4088 - val_loss: 1.2832 - val_accuracy: 0.4107

Epoch 01301: val_loss did not improve from 1.28225
Epoch 1302/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4100 - val_loss: 1.2838 - val_accuracy: 0.4147

Epoch 01302: val_loss did not improve from 1.28225
Epoch 1303/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4106 - val_loss: 1.2831 - val_accuracy: 0.4226

Epoch 01303: val_loss did not improve from 1.28225
Epoch 1304/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4147 - val_loss: 1.2824 - val_accuracy: 0.4219

Epoch 01304: val_loss did not improve from 1.28225
Epoch 1305/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4117 - val_loss: 1.2828 - val_accuracy: 0.4226

Epoch 01305: val_loss did not improve from 1.28225
Epoch 1306/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4069 - val_loss: 1.2853 - val_accuracy: 0.4163

Epoch 01306: val_loss did not improve from 1.28225
Epoch 1307/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4095 - val_loss: 1.2822 - val_accuracy: 0.4242

Epoch 01307: val_loss improved from 1.28225 to 1.28215, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1308/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4110 - val_loss: 1.2843 - val_accuracy: 0.4155

Epoch 01308: val_loss did not improve from 1.28215
Epoch 1309/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4106 - val_loss: 1.2813 - val_accuracy: 0.4163

Epoch 01309: val_loss improved from 1.28215 to 1.28125, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1310/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4084 - val_loss: 1.2863 - val_accuracy: 0.4179

Epoch 01310: val_loss did not improve from 1.28125
Epoch 1311/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4124 - val_loss: 1.2818 - val_accuracy: 0.4211

Epoch 01311: val_loss did not improve from 1.28125
Epoch 1312/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4114 - val_loss: 1.2829 - val_accuracy: 0.4242

Epoch 01312: val_loss did not improve from 1.28125
Epoch 1313/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4091 - val_loss: 1.2848 - val_accuracy: 0.4123

Epoch 01313: val_loss did not improve from 1.28125
Epoch 1314/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4083 - val_loss: 1.2816 - val_accuracy: 0.4163

Epoch 01314: val_loss did not improve from 1.28125
Epoch 1315/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4075 - val_loss: 1.2827 - val_accuracy: 0.4242

Epoch 01315: val_loss did not improve from 1.28125
Epoch 1316/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4101 - val_loss: 1.2838 - val_accuracy: 0.4179

Epoch 01316: val_loss did not improve from 1.28125
Epoch 1317/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4114 - val_loss: 1.2818 - val_accuracy: 0.4203

Epoch 01317: val_loss did not improve from 1.28125
Epoch 1318/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4099 - val_loss: 1.2813 - val_accuracy: 0.4211

Epoch 01318: val_loss did not improve from 1.28125
Epoch 1319/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4109 - val_loss: 1.2876 - val_accuracy: 0.4131

Epoch 01319: val_loss did not improve from 1.28125
Epoch 1320/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4116 - val_loss: 1.2810 - val_accuracy: 0.4155

Epoch 01320: val_loss improved from 1.28125 to 1.28098, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1321/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4094 - val_loss: 1.2811 - val_accuracy: 0.4163

Epoch 01321: val_loss did not improve from 1.28098
Epoch 1322/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4120 - val_loss: 1.2851 - val_accuracy: 0.4091

Epoch 01322: val_loss did not improve from 1.28098
Epoch 1323/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4095 - val_loss: 1.2820 - val_accuracy: 0.4274

Epoch 01323: val_loss did not improve from 1.28098
Epoch 1324/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4108 - val_loss: 1.2820 - val_accuracy: 0.4091

Epoch 01324: val_loss did not improve from 1.28098
Epoch 1325/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4070 - val_loss: 1.2846 - val_accuracy: 0.4123

Epoch 01325: val_loss did not improve from 1.28098
Epoch 1326/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4123 - val_loss: 1.2815 - val_accuracy: 0.4131

Epoch 01326: val_loss did not improve from 1.28098
Epoch 1327/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4117 - val_loss: 1.2822 - val_accuracy: 0.4242

Epoch 01327: val_loss did not improve from 1.28098
Epoch 1328/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4080 - val_loss: 1.2854 - val_accuracy: 0.4179

Epoch 01328: val_loss did not improve from 1.28098
Epoch 1329/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4143 - val_loss: 1.2816 - val_accuracy: 0.4219

Epoch 01329: val_loss did not improve from 1.28098
Epoch 1330/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4127 - val_loss: 1.2797 - val_accuracy: 0.4139

Epoch 01330: val_loss improved from 1.28098 to 1.27974, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1331/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4110 - val_loss: 1.2820 - val_accuracy: 0.4147

Epoch 01331: val_loss did not improve from 1.27974
Epoch 1332/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4127 - val_loss: 1.2811 - val_accuracy: 0.4107

Epoch 01332: val_loss did not improve from 1.27974
Epoch 1333/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4128 - val_loss: 1.2845 - val_accuracy: 0.4155

Epoch 01333: val_loss did not improve from 1.27974
Epoch 1334/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4086 - val_loss: 1.2800 - val_accuracy: 0.4250

Epoch 01334: val_loss did not improve from 1.27974
Epoch 1335/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4110 - val_loss: 1.2801 - val_accuracy: 0.4083

Epoch 01335: val_loss did not improve from 1.27974
Epoch 1336/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4136 - val_loss: 1.2795 - val_accuracy: 0.4083

Epoch 01336: val_loss improved from 1.27974 to 1.27953, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1337/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4145 - val_loss: 1.2819 - val_accuracy: 0.4123

Epoch 01337: val_loss did not improve from 1.27953
Epoch 1338/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4113 - val_loss: 1.2802 - val_accuracy: 0.4131

Epoch 01338: val_loss did not improve from 1.27953
Epoch 1339/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4115 - val_loss: 1.2844 - val_accuracy: 0.4171

Epoch 01339: val_loss did not improve from 1.27953
Epoch 1340/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4111 - val_loss: 1.2812 - val_accuracy: 0.4226

Epoch 01340: val_loss did not improve from 1.27953
Epoch 1341/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4132 - val_loss: 1.2816 - val_accuracy: 0.4155

Epoch 01341: val_loss did not improve from 1.27953
Epoch 1342/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4086 - val_loss: 1.2800 - val_accuracy: 0.4322

Epoch 01342: val_loss did not improve from 1.27953
Epoch 1343/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4096 - val_loss: 1.2819 - val_accuracy: 0.4226

Epoch 01343: val_loss did not improve from 1.27953
Epoch 1344/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4100 - val_loss: 1.2818 - val_accuracy: 0.4179

Epoch 01344: val_loss did not improve from 1.27953
Epoch 1345/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4114 - val_loss: 1.2799 - val_accuracy: 0.4203

Epoch 01345: val_loss did not improve from 1.27953
Epoch 1346/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4114 - val_loss: 1.2804 - val_accuracy: 0.4219

Epoch 01346: val_loss did not improve from 1.27953
Epoch 1347/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4104 - val_loss: 1.2818 - val_accuracy: 0.4179

Epoch 01347: val_loss did not improve from 1.27953
Epoch 1348/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4144 - val_loss: 1.2806 - val_accuracy: 0.4258

Epoch 01348: val_loss did not improve from 1.27953
Epoch 1349/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4121 - val_loss: 1.2813 - val_accuracy: 0.4179

Epoch 01349: val_loss did not improve from 1.27953
Epoch 1350/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4125 - val_loss: 1.2804 - val_accuracy: 0.4123

Epoch 01350: val_loss did not improve from 1.27953
Epoch 1351/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4099 - val_loss: 1.2816 - val_accuracy: 0.4179

Epoch 01351: val_loss did not improve from 1.27953
Epoch 1352/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4111 - val_loss: 1.2810 - val_accuracy: 0.4139

Epoch 01352: val_loss did not improve from 1.27953
Epoch 1353/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4119 - val_loss: 1.2797 - val_accuracy: 0.4115

Epoch 01353: val_loss did not improve from 1.27953
Epoch 1354/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4103 - val_loss: 1.2814 - val_accuracy: 0.4147

Epoch 01354: val_loss did not improve from 1.27953
Epoch 1355/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4090 - val_loss: 1.2813 - val_accuracy: 0.4155

Epoch 01355: val_loss did not improve from 1.27953
Epoch 1356/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4101 - val_loss: 1.2817 - val_accuracy: 0.4226

Epoch 01356: val_loss did not improve from 1.27953
Epoch 1357/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4140 - val_loss: 1.2817 - val_accuracy: 0.4123

Epoch 01357: val_loss did not improve from 1.27953
Epoch 1358/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4103 - val_loss: 1.2808 - val_accuracy: 0.4171

Epoch 01358: val_loss did not improve from 1.27953
Epoch 1359/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4095 - val_loss: 1.2841 - val_accuracy: 0.4043

Epoch 01359: val_loss did not improve from 1.27953
Epoch 1360/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4103 - val_loss: 1.2800 - val_accuracy: 0.4179

Epoch 01360: val_loss did not improve from 1.27953
Epoch 1361/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4107 - val_loss: 1.2780 - val_accuracy: 0.4123

Epoch 01361: val_loss improved from 1.27953 to 1.27799, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1362/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4161 - val_loss: 1.2796 - val_accuracy: 0.4075

Epoch 01362: val_loss did not improve from 1.27799
Epoch 1363/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4150 - val_loss: 1.2787 - val_accuracy: 0.4107

Epoch 01363: val_loss did not improve from 1.27799
Epoch 1364/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4117 - val_loss: 1.2803 - val_accuracy: 0.4179

Epoch 01364: val_loss did not improve from 1.27799
Epoch 1365/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4135 - val_loss: 1.2811 - val_accuracy: 0.4163

Epoch 01365: val_loss did not improve from 1.27799
Epoch 1366/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4139 - val_loss: 1.2835 - val_accuracy: 0.4242

Epoch 01366: val_loss did not improve from 1.27799
Epoch 1367/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4126 - val_loss: 1.2792 - val_accuracy: 0.4274

Epoch 01367: val_loss did not improve from 1.27799
Epoch 1368/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4135 - val_loss: 1.2811 - val_accuracy: 0.4115

Epoch 01368: val_loss did not improve from 1.27799
Epoch 1369/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4145 - val_loss: 1.2846 - val_accuracy: 0.4234

Epoch 01369: val_loss did not improve from 1.27799
Epoch 1370/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4134 - val_loss: 1.2793 - val_accuracy: 0.4155

Epoch 01370: val_loss did not improve from 1.27799
Epoch 1371/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4098 - val_loss: 1.2800 - val_accuracy: 0.4242

Epoch 01371: val_loss did not improve from 1.27799
Epoch 1372/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4139 - val_loss: 1.2788 - val_accuracy: 0.4195

Epoch 01372: val_loss did not improve from 1.27799
Epoch 1373/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4132 - val_loss: 1.2792 - val_accuracy: 0.4155

Epoch 01373: val_loss did not improve from 1.27799
Epoch 1374/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4109 - val_loss: 1.2798 - val_accuracy: 0.4187

Epoch 01374: val_loss did not improve from 1.27799
Epoch 1375/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4129 - val_loss: 1.2790 - val_accuracy: 0.4171

Epoch 01375: val_loss did not improve from 1.27799
Epoch 1376/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4124 - val_loss: 1.2808 - val_accuracy: 0.4155

Epoch 01376: val_loss did not improve from 1.27799
Epoch 1377/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4129 - val_loss: 1.2812 - val_accuracy: 0.4219

Epoch 01377: val_loss did not improve from 1.27799
Epoch 1378/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4119 - val_loss: 1.2801 - val_accuracy: 0.4258

Epoch 01378: val_loss did not improve from 1.27799
Epoch 1379/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4158 - val_loss: 1.2855 - val_accuracy: 0.4179

Epoch 01379: val_loss did not improve from 1.27799
Epoch 1380/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4108 - val_loss: 1.2815 - val_accuracy: 0.4203

Epoch 01380: val_loss did not improve from 1.27799
Epoch 1381/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4134 - val_loss: 1.2788 - val_accuracy: 0.4139

Epoch 01381: val_loss did not improve from 1.27799
Epoch 1382/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4142 - val_loss: 1.2803 - val_accuracy: 0.4306

Epoch 01382: val_loss did not improve from 1.27799
Epoch 1383/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4140 - val_loss: 1.2789 - val_accuracy: 0.4195

Epoch 01383: val_loss did not improve from 1.27799
Epoch 1384/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4156 - val_loss: 1.2810 - val_accuracy: 0.4250

Epoch 01384: val_loss did not improve from 1.27799
Epoch 1385/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4115 - val_loss: 1.2805 - val_accuracy: 0.4258

Epoch 01385: val_loss did not improve from 1.27799
Epoch 1386/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4135 - val_loss: 1.2809 - val_accuracy: 0.4187

Epoch 01386: val_loss did not improve from 1.27799
Epoch 1387/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4131 - val_loss: 1.2797 - val_accuracy: 0.4155

Epoch 01387: val_loss did not improve from 1.27799
Epoch 1388/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4139 - val_loss: 1.2792 - val_accuracy: 0.4203

Epoch 01388: val_loss did not improve from 1.27799
Epoch 1389/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4144 - val_loss: 1.2787 - val_accuracy: 0.4258

Epoch 01389: val_loss did not improve from 1.27799
Epoch 1390/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4141 - val_loss: 1.2787 - val_accuracy: 0.4155

Epoch 01390: val_loss did not improve from 1.27799
Epoch 1391/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4150 - val_loss: 1.2782 - val_accuracy: 0.4179

Epoch 01391: val_loss did not improve from 1.27799
Epoch 1392/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4125 - val_loss: 1.2817 - val_accuracy: 0.4211

Epoch 01392: val_loss did not improve from 1.27799
Epoch 1393/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4148 - val_loss: 1.2786 - val_accuracy: 0.4187

Epoch 01393: val_loss did not improve from 1.27799
Epoch 1394/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4144 - val_loss: 1.2792 - val_accuracy: 0.4147

Epoch 01394: val_loss did not improve from 1.27799
Epoch 1395/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4148 - val_loss: 1.2842 - val_accuracy: 0.4179

Epoch 01395: val_loss did not improve from 1.27799
Epoch 1396/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4135 - val_loss: 1.2809 - val_accuracy: 0.4163

Epoch 01396: val_loss did not improve from 1.27799
Epoch 1397/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4150 - val_loss: 1.2792 - val_accuracy: 0.4226

Epoch 01397: val_loss did not improve from 1.27799
Epoch 1398/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4119 - val_loss: 1.2798 - val_accuracy: 0.4179

Epoch 01398: val_loss did not improve from 1.27799
Epoch 1399/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4121 - val_loss: 1.2790 - val_accuracy: 0.4219

Epoch 01399: val_loss did not improve from 1.27799
Epoch 1400/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4140 - val_loss: 1.2818 - val_accuracy: 0.4179

Epoch 01400: val_loss did not improve from 1.27799
Epoch 1401/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4155 - val_loss: 1.2776 - val_accuracy: 0.4163

Epoch 01401: val_loss improved from 1.27799 to 1.27756, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1402/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4121 - val_loss: 1.2808 - val_accuracy: 0.4219

Epoch 01402: val_loss did not improve from 1.27756
Epoch 1403/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4118 - val_loss: 1.2812 - val_accuracy: 0.4187

Epoch 01403: val_loss did not improve from 1.27756
Epoch 1404/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4132 - val_loss: 1.2791 - val_accuracy: 0.4195

Epoch 01404: val_loss did not improve from 1.27756
Epoch 1405/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4117 - val_loss: 1.2785 - val_accuracy: 0.4179

Epoch 01405: val_loss did not improve from 1.27756
Epoch 1406/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4150 - val_loss: 1.2785 - val_accuracy: 0.4179

Epoch 01406: val_loss did not improve from 1.27756
Epoch 1407/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4155 - val_loss: 1.2785 - val_accuracy: 0.4179

Epoch 01407: val_loss did not improve from 1.27756
Epoch 1408/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4156 - val_loss: 1.2779 - val_accuracy: 0.4266

Epoch 01408: val_loss did not improve from 1.27756
Epoch 1409/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4162 - val_loss: 1.2772 - val_accuracy: 0.4187

Epoch 01409: val_loss improved from 1.27756 to 1.27722, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1410/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4155 - val_loss: 1.2796 - val_accuracy: 0.4274

Epoch 01410: val_loss did not improve from 1.27722
Epoch 1411/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4172 - val_loss: 1.2767 - val_accuracy: 0.4139

Epoch 01411: val_loss improved from 1.27722 to 1.27670, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1412/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4135 - val_loss: 1.2768 - val_accuracy: 0.4211

Epoch 01412: val_loss did not improve from 1.27670
Epoch 1413/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4137 - val_loss: 1.2792 - val_accuracy: 0.4139

Epoch 01413: val_loss did not improve from 1.27670
Epoch 1414/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4119 - val_loss: 1.2782 - val_accuracy: 0.4211

Epoch 01414: val_loss did not improve from 1.27670
Epoch 1415/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4137 - val_loss: 1.2790 - val_accuracy: 0.4179

Epoch 01415: val_loss did not improve from 1.27670
Epoch 1416/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4063 - val_loss: 1.2821 - val_accuracy: 0.4219

Epoch 01416: val_loss did not improve from 1.27670
Epoch 1417/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4132 - val_loss: 1.2766 - val_accuracy: 0.4163

Epoch 01417: val_loss improved from 1.27670 to 1.27663, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1418/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4142 - val_loss: 1.2772 - val_accuracy: 0.4139

Epoch 01418: val_loss did not improve from 1.27663
Epoch 1419/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4108 - val_loss: 1.2808 - val_accuracy: 0.4203

Epoch 01419: val_loss did not improve from 1.27663
Epoch 1420/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4143 - val_loss: 1.2777 - val_accuracy: 0.4203

Epoch 01420: val_loss did not improve from 1.27663
Epoch 1421/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4128 - val_loss: 1.2797 - val_accuracy: 0.4226

Epoch 01421: val_loss did not improve from 1.27663
Epoch 1422/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4125 - val_loss: 1.2781 - val_accuracy: 0.4226

Epoch 01422: val_loss did not improve from 1.27663
Epoch 1423/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4159 - val_loss: 1.2801 - val_accuracy: 0.4195

Epoch 01423: val_loss did not improve from 1.27663
Epoch 1424/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4138 - val_loss: 1.2807 - val_accuracy: 0.4226

Epoch 01424: val_loss did not improve from 1.27663
Epoch 1425/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4109 - val_loss: 1.2777 - val_accuracy: 0.4203

Epoch 01425: val_loss did not improve from 1.27663
Epoch 1426/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4138 - val_loss: 1.2777 - val_accuracy: 0.4234

Epoch 01426: val_loss did not improve from 1.27663
Epoch 1427/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4169 - val_loss: 1.2751 - val_accuracy: 0.4211

Epoch 01427: val_loss improved from 1.27663 to 1.27511, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1428/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4150 - val_loss: 1.2778 - val_accuracy: 0.4211

Epoch 01428: val_loss did not improve from 1.27511
Epoch 1429/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4173 - val_loss: 1.2775 - val_accuracy: 0.4203

Epoch 01429: val_loss did not improve from 1.27511
Epoch 1430/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4128 - val_loss: 1.2768 - val_accuracy: 0.4187

Epoch 01430: val_loss did not improve from 1.27511
Epoch 1431/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4140 - val_loss: 1.2789 - val_accuracy: 0.4203

Epoch 01431: val_loss did not improve from 1.27511
Epoch 1432/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4130 - val_loss: 1.2775 - val_accuracy: 0.4242

Epoch 01432: val_loss did not improve from 1.27511
Epoch 1433/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4141 - val_loss: 1.2766 - val_accuracy: 0.4211

Epoch 01433: val_loss did not improve from 1.27511
Epoch 1434/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4137 - val_loss: 1.2800 - val_accuracy: 0.4051

Epoch 01434: val_loss did not improve from 1.27511
Epoch 1435/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4118 - val_loss: 1.2788 - val_accuracy: 0.4163

Epoch 01435: val_loss did not improve from 1.27511
Epoch 1436/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4131 - val_loss: 1.2773 - val_accuracy: 0.4211

Epoch 01436: val_loss did not improve from 1.27511
Epoch 1437/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4140 - val_loss: 1.2789 - val_accuracy: 0.4091

Epoch 01437: val_loss did not improve from 1.27511
Epoch 1438/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4132 - val_loss: 1.2789 - val_accuracy: 0.4163

Epoch 01438: val_loss did not improve from 1.27511
Epoch 1439/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4167 - val_loss: 1.2754 - val_accuracy: 0.4203

Epoch 01439: val_loss did not improve from 1.27511
Epoch 1440/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4167 - val_loss: 1.2824 - val_accuracy: 0.4203

Epoch 01440: val_loss did not improve from 1.27511
Epoch 1441/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4168 - val_loss: 1.2753 - val_accuracy: 0.4282

Epoch 01441: val_loss did not improve from 1.27511
Epoch 1442/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4163 - val_loss: 1.2774 - val_accuracy: 0.4203

Epoch 01442: val_loss did not improve from 1.27511
Epoch 1443/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4139 - val_loss: 1.2779 - val_accuracy: 0.4179

Epoch 01443: val_loss did not improve from 1.27511
Epoch 1444/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4179 - val_loss: 1.2794 - val_accuracy: 0.4211

Epoch 01444: val_loss did not improve from 1.27511
Epoch 1445/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4179 - val_loss: 1.2745 - val_accuracy: 0.4219

Epoch 01445: val_loss improved from 1.27511 to 1.27447, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1446/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4151 - val_loss: 1.2777 - val_accuracy: 0.4203

Epoch 01446: val_loss did not improve from 1.27447
Epoch 1447/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4135 - val_loss: 1.2749 - val_accuracy: 0.4179

Epoch 01447: val_loss did not improve from 1.27447
Epoch 1448/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4168 - val_loss: 1.2765 - val_accuracy: 0.4155

Epoch 01448: val_loss did not improve from 1.27447
Epoch 1449/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4166 - val_loss: 1.2792 - val_accuracy: 0.4211

Epoch 01449: val_loss did not improve from 1.27447
Epoch 1450/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4162 - val_loss: 1.2745 - val_accuracy: 0.4226

Epoch 01450: val_loss improved from 1.27447 to 1.27447, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1451/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4167 - val_loss: 1.2740 - val_accuracy: 0.4187

Epoch 01451: val_loss improved from 1.27447 to 1.27400, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1452/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4175 - val_loss: 1.2750 - val_accuracy: 0.4226

Epoch 01452: val_loss did not improve from 1.27400
Epoch 1453/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4174 - val_loss: 1.2754 - val_accuracy: 0.4179

Epoch 01453: val_loss did not improve from 1.27400
Epoch 1454/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4133 - val_loss: 1.2755 - val_accuracy: 0.4179

Epoch 01454: val_loss did not improve from 1.27400
Epoch 1455/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4178 - val_loss: 1.2820 - val_accuracy: 0.4226

Epoch 01455: val_loss did not improve from 1.27400
Epoch 1456/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4132 - val_loss: 1.2773 - val_accuracy: 0.4250

Epoch 01456: val_loss did not improve from 1.27400
Epoch 1457/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4135 - val_loss: 1.2796 - val_accuracy: 0.4203

Epoch 01457: val_loss did not improve from 1.27400
Epoch 1458/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4165 - val_loss: 1.2768 - val_accuracy: 0.4163

Epoch 01458: val_loss did not improve from 1.27400
Epoch 1459/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4128 - val_loss: 1.2768 - val_accuracy: 0.4211

Epoch 01459: val_loss did not improve from 1.27400
Epoch 1460/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4148 - val_loss: 1.2760 - val_accuracy: 0.4179

Epoch 01460: val_loss did not improve from 1.27400
Epoch 1461/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4184 - val_loss: 1.2746 - val_accuracy: 0.4131

Epoch 01461: val_loss did not improve from 1.27400
Epoch 1462/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4174 - val_loss: 1.2753 - val_accuracy: 0.4195

Epoch 01462: val_loss did not improve from 1.27400
Epoch 1463/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4158 - val_loss: 1.2760 - val_accuracy: 0.4211

Epoch 01463: val_loss did not improve from 1.27400
Epoch 1464/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4157 - val_loss: 1.2767 - val_accuracy: 0.4195

Epoch 01464: val_loss did not improve from 1.27400
Epoch 1465/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4146 - val_loss: 1.2743 - val_accuracy: 0.4195

Epoch 01465: val_loss did not improve from 1.27400
Epoch 1466/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4176 - val_loss: 1.2737 - val_accuracy: 0.4171

Epoch 01466: val_loss improved from 1.27400 to 1.27366, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1467/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4169 - val_loss: 1.2751 - val_accuracy: 0.4242

Epoch 01467: val_loss did not improve from 1.27366
Epoch 1468/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4182 - val_loss: 1.2760 - val_accuracy: 0.4250

Epoch 01468: val_loss did not improve from 1.27366
Epoch 1469/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4131 - val_loss: 1.2754 - val_accuracy: 0.4282

Epoch 01469: val_loss did not improve from 1.27366
Epoch 1470/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4187 - val_loss: 1.2760 - val_accuracy: 0.4338

Epoch 01470: val_loss did not improve from 1.27366
Epoch 1471/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4140 - val_loss: 1.2755 - val_accuracy: 0.4219

Epoch 01471: val_loss did not improve from 1.27366
Epoch 1472/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4170 - val_loss: 1.2734 - val_accuracy: 0.4163

Epoch 01472: val_loss improved from 1.27366 to 1.27341, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1473/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4177 - val_loss: 1.2748 - val_accuracy: 0.4250

Epoch 01473: val_loss did not improve from 1.27341
Epoch 1474/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4131 - val_loss: 1.2788 - val_accuracy: 0.4306

Epoch 01474: val_loss did not improve from 1.27341
Epoch 1475/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4146 - val_loss: 1.2741 - val_accuracy: 0.4282

Epoch 01475: val_loss did not improve from 1.27341
Epoch 1476/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4182 - val_loss: 1.2731 - val_accuracy: 0.4282

Epoch 01476: val_loss improved from 1.27341 to 1.27313, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1477/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4118 - val_loss: 1.2743 - val_accuracy: 0.4258

Epoch 01477: val_loss did not improve from 1.27313
Epoch 1478/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4163 - val_loss: 1.2755 - val_accuracy: 0.4274

Epoch 01478: val_loss did not improve from 1.27313
Epoch 1479/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4126 - val_loss: 1.2757 - val_accuracy: 0.4226

Epoch 01479: val_loss did not improve from 1.27313
Epoch 1480/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4171 - val_loss: 1.2740 - val_accuracy: 0.4242

Epoch 01480: val_loss did not improve from 1.27313
Epoch 1481/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4173 - val_loss: 1.2732 - val_accuracy: 0.4171

Epoch 01481: val_loss did not improve from 1.27313
Epoch 1482/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4165 - val_loss: 1.2753 - val_accuracy: 0.4250

Epoch 01482: val_loss did not improve from 1.27313
Epoch 1483/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4167 - val_loss: 1.2736 - val_accuracy: 0.4226

Epoch 01483: val_loss did not improve from 1.27313
Epoch 1484/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4159 - val_loss: 1.2738 - val_accuracy: 0.4274

Epoch 01484: val_loss did not improve from 1.27313
Epoch 1485/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4153 - val_loss: 1.2752 - val_accuracy: 0.4338

Epoch 01485: val_loss did not improve from 1.27313
Epoch 1486/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4151 - val_loss: 1.2724 - val_accuracy: 0.4250

Epoch 01486: val_loss improved from 1.27313 to 1.27239, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1487/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4170 - val_loss: 1.2742 - val_accuracy: 0.4306

Epoch 01487: val_loss did not improve from 1.27239
Epoch 1488/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4193 - val_loss: 1.2754 - val_accuracy: 0.4234

Epoch 01488: val_loss did not improve from 1.27239
Epoch 1489/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4148 - val_loss: 1.2757 - val_accuracy: 0.4179

Epoch 01489: val_loss did not improve from 1.27239
Epoch 1490/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4164 - val_loss: 1.2736 - val_accuracy: 0.4163

Epoch 01490: val_loss did not improve from 1.27239
Epoch 1491/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4200 - val_loss: 1.2745 - val_accuracy: 0.4282

Epoch 01491: val_loss did not improve from 1.27239
Epoch 1492/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4176 - val_loss: 1.2779 - val_accuracy: 0.4250

Epoch 01492: val_loss did not improve from 1.27239
Epoch 1493/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4181 - val_loss: 1.2731 - val_accuracy: 0.4187

Epoch 01493: val_loss did not improve from 1.27239
Epoch 1494/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4140 - val_loss: 1.2754 - val_accuracy: 0.4203

Epoch 01494: val_loss did not improve from 1.27239
Epoch 1495/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4179 - val_loss: 1.2734 - val_accuracy: 0.4258

Epoch 01495: val_loss did not improve from 1.27239
Epoch 1496/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4165 - val_loss: 1.2732 - val_accuracy: 0.4258

Epoch 01496: val_loss did not improve from 1.27239
Epoch 1497/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4179 - val_loss: 1.2763 - val_accuracy: 0.4211

Epoch 01497: val_loss did not improve from 1.27239
Epoch 1498/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4200 - val_loss: 1.2725 - val_accuracy: 0.4250

Epoch 01498: val_loss did not improve from 1.27239
Epoch 1499/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4222 - val_loss: 1.2741 - val_accuracy: 0.4242

Epoch 01499: val_loss did not improve from 1.27239
Epoch 1500/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4131 - val_loss: 1.2751 - val_accuracy: 0.4195

Epoch 01500: val_loss did not improve from 1.27239
Epoch 1501/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4140 - val_loss: 1.2768 - val_accuracy: 0.4282

Epoch 01501: val_loss did not improve from 1.27239
Epoch 1502/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4125 - val_loss: 1.2823 - val_accuracy: 0.4179

Epoch 01502: val_loss did not improve from 1.27239
Epoch 1503/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4107 - val_loss: 1.2768 - val_accuracy: 0.4258

Epoch 01503: val_loss did not improve from 1.27239
Epoch 1504/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4155 - val_loss: 1.2741 - val_accuracy: 0.4250

Epoch 01504: val_loss did not improve from 1.27239
Epoch 1505/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4140 - val_loss: 1.2743 - val_accuracy: 0.4290

Epoch 01505: val_loss did not improve from 1.27239
Epoch 1506/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4140 - val_loss: 1.2734 - val_accuracy: 0.4242

Epoch 01506: val_loss did not improve from 1.27239
Epoch 1507/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4152 - val_loss: 1.2751 - val_accuracy: 0.4338

Epoch 01507: val_loss did not improve from 1.27239
Epoch 1508/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4194 - val_loss: 1.2715 - val_accuracy: 0.4290

Epoch 01508: val_loss improved from 1.27239 to 1.27146, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1509/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4196 - val_loss: 1.2701 - val_accuracy: 0.4322

Epoch 01509: val_loss improved from 1.27146 to 1.27009, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1510/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4205 - val_loss: 1.2733 - val_accuracy: 0.4330

Epoch 01510: val_loss did not improve from 1.27009
Epoch 1511/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4181 - val_loss: 1.2719 - val_accuracy: 0.4258

Epoch 01511: val_loss did not improve from 1.27009
Epoch 1512/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4166 - val_loss: 1.2729 - val_accuracy: 0.4219

Epoch 01512: val_loss did not improve from 1.27009
Epoch 1513/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4203 - val_loss: 1.2758 - val_accuracy: 0.4219

Epoch 01513: val_loss did not improve from 1.27009
Epoch 1514/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4191 - val_loss: 1.2740 - val_accuracy: 0.4219

Epoch 01514: val_loss did not improve from 1.27009
Epoch 1515/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4179 - val_loss: 1.2733 - val_accuracy: 0.4219

Epoch 01515: val_loss did not improve from 1.27009
Epoch 1516/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4145 - val_loss: 1.2724 - val_accuracy: 0.4250

Epoch 01516: val_loss did not improve from 1.27009
Epoch 1517/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4152 - val_loss: 1.2726 - val_accuracy: 0.4195

Epoch 01517: val_loss did not improve from 1.27009
Epoch 1518/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4162 - val_loss: 1.2730 - val_accuracy: 0.4306

Epoch 01518: val_loss did not improve from 1.27009
Epoch 1519/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4173 - val_loss: 1.2743 - val_accuracy: 0.4282

Epoch 01519: val_loss did not improve from 1.27009
Epoch 1520/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4212 - val_loss: 1.2736 - val_accuracy: 0.4346

Epoch 01520: val_loss did not improve from 1.27009
Epoch 1521/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4156 - val_loss: 1.2776 - val_accuracy: 0.4370

Epoch 01521: val_loss did not improve from 1.27009
Epoch 1522/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4194 - val_loss: 1.2734 - val_accuracy: 0.4282

Epoch 01522: val_loss did not improve from 1.27009
Epoch 1523/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4183 - val_loss: 1.2751 - val_accuracy: 0.4242

Epoch 01523: val_loss did not improve from 1.27009
Epoch 1524/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4173 - val_loss: 1.2742 - val_accuracy: 0.4306

Epoch 01524: val_loss did not improve from 1.27009
Epoch 1525/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4218 - val_loss: 1.2721 - val_accuracy: 0.4290

Epoch 01525: val_loss did not improve from 1.27009
Epoch 1526/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4180 - val_loss: 1.2721 - val_accuracy: 0.4226

Epoch 01526: val_loss did not improve from 1.27009
Epoch 1527/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4171 - val_loss: 1.2741 - val_accuracy: 0.4258

Epoch 01527: val_loss did not improve from 1.27009
Epoch 1528/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4200 - val_loss: 1.2763 - val_accuracy: 0.4290

Epoch 01528: val_loss did not improve from 1.27009
Epoch 1529/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4179 - val_loss: 1.2728 - val_accuracy: 0.4258

Epoch 01529: val_loss did not improve from 1.27009
Epoch 1530/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4180 - val_loss: 1.2716 - val_accuracy: 0.4274

Epoch 01530: val_loss did not improve from 1.27009
Epoch 1531/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4186 - val_loss: 1.2730 - val_accuracy: 0.4274

Epoch 01531: val_loss did not improve from 1.27009
Epoch 1532/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4175 - val_loss: 1.2718 - val_accuracy: 0.4250

Epoch 01532: val_loss did not improve from 1.27009
Epoch 1533/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4173 - val_loss: 1.2738 - val_accuracy: 0.4234

Epoch 01533: val_loss did not improve from 1.27009
Epoch 1534/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4158 - val_loss: 1.2725 - val_accuracy: 0.4234

Epoch 01534: val_loss did not improve from 1.27009
Epoch 1535/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4194 - val_loss: 1.2716 - val_accuracy: 0.4242

Epoch 01535: val_loss did not improve from 1.27009
Epoch 1536/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4190 - val_loss: 1.2713 - val_accuracy: 0.4242

Epoch 01536: val_loss did not improve from 1.27009
Epoch 1537/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4178 - val_loss: 1.2720 - val_accuracy: 0.4282

Epoch 01537: val_loss did not improve from 1.27009
Epoch 1538/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4185 - val_loss: 1.2711 - val_accuracy: 0.4314

Epoch 01538: val_loss did not improve from 1.27009
Epoch 1539/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4192 - val_loss: 1.2715 - val_accuracy: 0.4203

Epoch 01539: val_loss did not improve from 1.27009
Epoch 1540/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4177 - val_loss: 1.2744 - val_accuracy: 0.4179

Epoch 01540: val_loss did not improve from 1.27009
Epoch 1541/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4137 - val_loss: 1.2722 - val_accuracy: 0.4242

Epoch 01541: val_loss did not improve from 1.27009
Epoch 1542/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4197 - val_loss: 1.2750 - val_accuracy: 0.4306

Epoch 01542: val_loss did not improve from 1.27009
Epoch 1543/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4167 - val_loss: 1.2736 - val_accuracy: 0.4258

Epoch 01543: val_loss did not improve from 1.27009
Epoch 1544/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4163 - val_loss: 1.2752 - val_accuracy: 0.4242

Epoch 01544: val_loss did not improve from 1.27009
Epoch 1545/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4174 - val_loss: 1.2736 - val_accuracy: 0.4298

Epoch 01545: val_loss did not improve from 1.27009
Epoch 1546/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4182 - val_loss: 1.2730 - val_accuracy: 0.4179

Epoch 01546: val_loss did not improve from 1.27009
Epoch 1547/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4194 - val_loss: 1.2713 - val_accuracy: 0.4298

Epoch 01547: val_loss did not improve from 1.27009
Epoch 1548/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4175 - val_loss: 1.2728 - val_accuracy: 0.4282

Epoch 01548: val_loss did not improve from 1.27009
Epoch 1549/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4161 - val_loss: 1.2709 - val_accuracy: 0.4290

Epoch 01549: val_loss did not improve from 1.27009
Epoch 1550/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4166 - val_loss: 1.2759 - val_accuracy: 0.4234

Epoch 01550: val_loss did not improve from 1.27009
Epoch 1551/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4156 - val_loss: 1.2715 - val_accuracy: 0.4195

Epoch 01551: val_loss did not improve from 1.27009
Epoch 1552/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4164 - val_loss: 1.2732 - val_accuracy: 0.4290

Epoch 01552: val_loss did not improve from 1.27009
Epoch 1553/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4179 - val_loss: 1.2724 - val_accuracy: 0.4258

Epoch 01553: val_loss did not improve from 1.27009
Epoch 1554/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4150 - val_loss: 1.2786 - val_accuracy: 0.4266

Epoch 01554: val_loss did not improve from 1.27009
Epoch 1555/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4185 - val_loss: 1.2707 - val_accuracy: 0.4211

Epoch 01555: val_loss did not improve from 1.27009
Epoch 1556/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4207 - val_loss: 1.2720 - val_accuracy: 0.4306

Epoch 01556: val_loss did not improve from 1.27009
Epoch 1557/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4181 - val_loss: 1.2726 - val_accuracy: 0.4306

Epoch 01557: val_loss did not improve from 1.27009
Epoch 1558/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4165 - val_loss: 1.2703 - val_accuracy: 0.4266

Epoch 01558: val_loss did not improve from 1.27009
Epoch 1559/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4184 - val_loss: 1.2729 - val_accuracy: 0.4242

Epoch 01559: val_loss did not improve from 1.27009
Epoch 1560/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4133 - val_loss: 1.2720 - val_accuracy: 0.4330

Epoch 01560: val_loss did not improve from 1.27009
Epoch 1561/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4187 - val_loss: 1.2718 - val_accuracy: 0.4226

Epoch 01561: val_loss did not improve from 1.27009
Epoch 1562/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4174 - val_loss: 1.2717 - val_accuracy: 0.4226

Epoch 01562: val_loss did not improve from 1.27009
Epoch 1563/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4161 - val_loss: 1.2756 - val_accuracy: 0.4155

Epoch 01563: val_loss did not improve from 1.27009
Epoch 1564/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4173 - val_loss: 1.2711 - val_accuracy: 0.4290

Epoch 01564: val_loss did not improve from 1.27009
Epoch 1565/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4153 - val_loss: 1.2731 - val_accuracy: 0.4274

Epoch 01565: val_loss did not improve from 1.27009
Epoch 1566/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4156 - val_loss: 1.2809 - val_accuracy: 0.4282

Epoch 01566: val_loss did not improve from 1.27009
Epoch 1567/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4170 - val_loss: 1.2741 - val_accuracy: 0.4139

Epoch 01567: val_loss did not improve from 1.27009
Epoch 1568/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4170 - val_loss: 1.2693 - val_accuracy: 0.4314

Epoch 01568: val_loss improved from 1.27009 to 1.26929, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1569/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4193 - val_loss: 1.2723 - val_accuracy: 0.4298

Epoch 01569: val_loss did not improve from 1.26929
Epoch 1570/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4202 - val_loss: 1.2713 - val_accuracy: 0.4258

Epoch 01570: val_loss did not improve from 1.26929
Epoch 1571/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4184 - val_loss: 1.2735 - val_accuracy: 0.4226

Epoch 01571: val_loss did not improve from 1.26929
Epoch 1572/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4174 - val_loss: 1.2711 - val_accuracy: 0.4234

Epoch 01572: val_loss did not improve from 1.26929
Epoch 1573/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4142 - val_loss: 1.2750 - val_accuracy: 0.4250

Epoch 01573: val_loss did not improve from 1.26929
Epoch 1574/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4206 - val_loss: 1.2713 - val_accuracy: 0.4234

Epoch 01574: val_loss did not improve from 1.26929
Epoch 1575/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4153 - val_loss: 1.2743 - val_accuracy: 0.4242

Epoch 01575: val_loss did not improve from 1.26929
Epoch 1576/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4185 - val_loss: 1.2718 - val_accuracy: 0.4242

Epoch 01576: val_loss did not improve from 1.26929
Epoch 1577/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4204 - val_loss: 1.2719 - val_accuracy: 0.4306

Epoch 01577: val_loss did not improve from 1.26929
Epoch 1578/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4163 - val_loss: 1.2720 - val_accuracy: 0.4242

Epoch 01578: val_loss did not improve from 1.26929
Epoch 1579/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4201 - val_loss: 1.2722 - val_accuracy: 0.4362

Epoch 01579: val_loss did not improve from 1.26929
Epoch 1580/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4187 - val_loss: 1.2754 - val_accuracy: 0.4338

Epoch 01580: val_loss did not improve from 1.26929
Epoch 1581/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4148 - val_loss: 1.2738 - val_accuracy: 0.4266

Epoch 01581: val_loss did not improve from 1.26929
Epoch 1582/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4192 - val_loss: 1.2703 - val_accuracy: 0.4306

Epoch 01582: val_loss did not improve from 1.26929
Epoch 1583/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4187 - val_loss: 1.2720 - val_accuracy: 0.4290

Epoch 01583: val_loss did not improve from 1.26929
Epoch 1584/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4192 - val_loss: 1.2748 - val_accuracy: 0.4282

Epoch 01584: val_loss did not improve from 1.26929
Epoch 1585/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4185 - val_loss: 1.2731 - val_accuracy: 0.4250

Epoch 01585: val_loss did not improve from 1.26929
Epoch 1586/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4184 - val_loss: 1.2758 - val_accuracy: 0.4226

Epoch 01586: val_loss did not improve from 1.26929
Epoch 1587/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4148 - val_loss: 1.2719 - val_accuracy: 0.4290

Epoch 01587: val_loss did not improve from 1.26929
Epoch 1588/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4195 - val_loss: 1.2709 - val_accuracy: 0.4266

Epoch 01588: val_loss did not improve from 1.26929
Epoch 1589/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4204 - val_loss: 1.2717 - val_accuracy: 0.4242

Epoch 01589: val_loss did not improve from 1.26929
Epoch 1590/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4175 - val_loss: 1.2720 - val_accuracy: 0.4242

Epoch 01590: val_loss did not improve from 1.26929
Epoch 1591/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4188 - val_loss: 1.2715 - val_accuracy: 0.4211

Epoch 01591: val_loss did not improve from 1.26929
Epoch 1592/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4204 - val_loss: 1.2698 - val_accuracy: 0.4250

Epoch 01592: val_loss did not improve from 1.26929
Epoch 1593/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4168 - val_loss: 1.2704 - val_accuracy: 0.4219

Epoch 01593: val_loss did not improve from 1.26929
Epoch 1594/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4152 - val_loss: 1.2724 - val_accuracy: 0.4219

Epoch 01594: val_loss did not improve from 1.26929
Epoch 1595/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4178 - val_loss: 1.2701 - val_accuracy: 0.4266

Epoch 01595: val_loss did not improve from 1.26929
Epoch 1596/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4191 - val_loss: 1.2723 - val_accuracy: 0.4258

Epoch 01596: val_loss did not improve from 1.26929
Epoch 1597/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4183 - val_loss: 1.2708 - val_accuracy: 0.4274

Epoch 01597: val_loss did not improve from 1.26929
Epoch 1598/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4202 - val_loss: 1.2718 - val_accuracy: 0.4250

Epoch 01598: val_loss did not improve from 1.26929
Epoch 1599/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4202 - val_loss: 1.2720 - val_accuracy: 0.4314

Epoch 01599: val_loss did not improve from 1.26929
Epoch 1600/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4176 - val_loss: 1.2718 - val_accuracy: 0.4330

Epoch 01600: val_loss did not improve from 1.26929
Epoch 1601/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4189 - val_loss: 1.2696 - val_accuracy: 0.4298

Epoch 01601: val_loss did not improve from 1.26929
Epoch 1602/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4177 - val_loss: 1.2722 - val_accuracy: 0.4290

Epoch 01602: val_loss did not improve from 1.26929
Epoch 1603/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4179 - val_loss: 1.2720 - val_accuracy: 0.4226

Epoch 01603: val_loss did not improve from 1.26929
Epoch 1604/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4152 - val_loss: 1.2703 - val_accuracy: 0.4274

Epoch 01604: val_loss did not improve from 1.26929
Epoch 1605/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4215 - val_loss: 1.2701 - val_accuracy: 0.4290

Epoch 01605: val_loss did not improve from 1.26929
Epoch 1606/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4194 - val_loss: 1.2705 - val_accuracy: 0.4330

Epoch 01606: val_loss did not improve from 1.26929
Epoch 1607/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4207 - val_loss: 1.2702 - val_accuracy: 0.4322

Epoch 01607: val_loss did not improve from 1.26929
Epoch 1608/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4202 - val_loss: 1.2711 - val_accuracy: 0.4314

Epoch 01608: val_loss did not improve from 1.26929
Epoch 1609/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4157 - val_loss: 1.2718 - val_accuracy: 0.4274

Epoch 01609: val_loss did not improve from 1.26929
Epoch 1610/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4168 - val_loss: 1.2733 - val_accuracy: 0.4322

Epoch 01610: val_loss did not improve from 1.26929
Epoch 1611/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4172 - val_loss: 1.2692 - val_accuracy: 0.4266

Epoch 01611: val_loss improved from 1.26929 to 1.26925, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1612/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4163 - val_loss: 1.2713 - val_accuracy: 0.4282

Epoch 01612: val_loss did not improve from 1.26925
Epoch 1613/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4109 - val_loss: 1.2745 - val_accuracy: 0.4203

Epoch 01613: val_loss did not improve from 1.26925
Epoch 1614/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4195 - val_loss: 1.2735 - val_accuracy: 0.4203

Epoch 01614: val_loss did not improve from 1.26925
Epoch 1615/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4194 - val_loss: 1.2697 - val_accuracy: 0.4242

Epoch 01615: val_loss did not improve from 1.26925
Epoch 1616/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4213 - val_loss: 1.2723 - val_accuracy: 0.4306

Epoch 01616: val_loss did not improve from 1.26925
Epoch 1617/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4186 - val_loss: 1.2788 - val_accuracy: 0.4298

Epoch 01617: val_loss did not improve from 1.26925
Epoch 1618/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4179 - val_loss: 1.2704 - val_accuracy: 0.4258

Epoch 01618: val_loss did not improve from 1.26925
Epoch 1619/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4169 - val_loss: 1.2700 - val_accuracy: 0.4314

Epoch 01619: val_loss did not improve from 1.26925
Epoch 1620/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4163 - val_loss: 1.2745 - val_accuracy: 0.4314

Epoch 01620: val_loss did not improve from 1.26925
Epoch 1621/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4202 - val_loss: 1.2711 - val_accuracy: 0.4282

Epoch 01621: val_loss did not improve from 1.26925
Epoch 1622/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4186 - val_loss: 1.2746 - val_accuracy: 0.4290

Epoch 01622: val_loss did not improve from 1.26925
Epoch 1623/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4155 - val_loss: 1.2720 - val_accuracy: 0.4314

Epoch 01623: val_loss did not improve from 1.26925
Epoch 1624/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4194 - val_loss: 1.2711 - val_accuracy: 0.4258

Epoch 01624: val_loss did not improve from 1.26925
Epoch 1625/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4208 - val_loss: 1.2679 - val_accuracy: 0.4290

Epoch 01625: val_loss improved from 1.26925 to 1.26793, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1626/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4211 - val_loss: 1.2690 - val_accuracy: 0.4298

Epoch 01626: val_loss did not improve from 1.26793
Epoch 1627/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4157 - val_loss: 1.2699 - val_accuracy: 0.4298

Epoch 01627: val_loss did not improve from 1.26793
Epoch 1628/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4197 - val_loss: 1.2719 - val_accuracy: 0.4306

Epoch 01628: val_loss did not improve from 1.26793
Epoch 1629/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4189 - val_loss: 1.2718 - val_accuracy: 0.4330

Epoch 01629: val_loss did not improve from 1.26793
Epoch 1630/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4214 - val_loss: 1.2696 - val_accuracy: 0.4338

Epoch 01630: val_loss did not improve from 1.26793
Epoch 1631/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4156 - val_loss: 1.2713 - val_accuracy: 0.4282

Epoch 01631: val_loss did not improve from 1.26793
Epoch 1632/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4194 - val_loss: 1.2743 - val_accuracy: 0.4139

Epoch 01632: val_loss did not improve from 1.26793
Epoch 1633/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4169 - val_loss: 1.2746 - val_accuracy: 0.4290

Epoch 01633: val_loss did not improve from 1.26793
Epoch 1634/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4174 - val_loss: 1.2718 - val_accuracy: 0.4322

Epoch 01634: val_loss did not improve from 1.26793
Epoch 1635/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4187 - val_loss: 1.2706 - val_accuracy: 0.4290

Epoch 01635: val_loss did not improve from 1.26793
Epoch 1636/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4186 - val_loss: 1.2707 - val_accuracy: 0.4226

Epoch 01636: val_loss did not improve from 1.26793
Epoch 1637/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4201 - val_loss: 1.2694 - val_accuracy: 0.4250

Epoch 01637: val_loss did not improve from 1.26793
Epoch 1638/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4182 - val_loss: 1.2703 - val_accuracy: 0.4338

Epoch 01638: val_loss did not improve from 1.26793
Epoch 1639/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4186 - val_loss: 1.2754 - val_accuracy: 0.4298

Epoch 01639: val_loss did not improve from 1.26793
Epoch 1640/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4180 - val_loss: 1.2703 - val_accuracy: 0.4338

Epoch 01640: val_loss did not improve from 1.26793
Epoch 1641/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4194 - val_loss: 1.2703 - val_accuracy: 0.4266

Epoch 01641: val_loss did not improve from 1.26793
Epoch 1642/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4154 - val_loss: 1.2761 - val_accuracy: 0.4306

Epoch 01642: val_loss did not improve from 1.26793
Epoch 1643/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4189 - val_loss: 1.2690 - val_accuracy: 0.4322

Epoch 01643: val_loss did not improve from 1.26793
Epoch 1644/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4173 - val_loss: 1.2714 - val_accuracy: 0.4234

Epoch 01644: val_loss did not improve from 1.26793
Epoch 1645/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4170 - val_loss: 1.2711 - val_accuracy: 0.4258

Epoch 01645: val_loss did not improve from 1.26793
Epoch 1646/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4195 - val_loss: 1.2686 - val_accuracy: 0.4306

Epoch 01646: val_loss did not improve from 1.26793
Epoch 1647/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4226 - val_loss: 1.2689 - val_accuracy: 0.4338

Epoch 01647: val_loss did not improve from 1.26793
Epoch 1648/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4222 - val_loss: 1.2686 - val_accuracy: 0.4242

Epoch 01648: val_loss did not improve from 1.26793
Epoch 1649/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4233 - val_loss: 1.2702 - val_accuracy: 0.4211

Epoch 01649: val_loss did not improve from 1.26793
Epoch 1650/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4221 - val_loss: 1.2706 - val_accuracy: 0.4330

Epoch 01650: val_loss did not improve from 1.26793
Epoch 1651/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4183 - val_loss: 1.2702 - val_accuracy: 0.4290

Epoch 01651: val_loss did not improve from 1.26793
Epoch 1652/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4196 - val_loss: 1.2698 - val_accuracy: 0.4250

Epoch 01652: val_loss did not improve from 1.26793
Epoch 1653/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4197 - val_loss: 1.2707 - val_accuracy: 0.4314

Epoch 01653: val_loss did not improve from 1.26793
Epoch 1654/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4218 - val_loss: 1.2709 - val_accuracy: 0.4282

Epoch 01654: val_loss did not improve from 1.26793
Epoch 1655/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4154 - val_loss: 1.2701 - val_accuracy: 0.4282

Epoch 01655: val_loss did not improve from 1.26793
Epoch 1656/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4187 - val_loss: 1.2682 - val_accuracy: 0.4314

Epoch 01656: val_loss did not improve from 1.26793
Epoch 1657/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4217 - val_loss: 1.2686 - val_accuracy: 0.4266

Epoch 01657: val_loss did not improve from 1.26793
Epoch 1658/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4220 - val_loss: 1.2725 - val_accuracy: 0.4290

Epoch 01658: val_loss did not improve from 1.26793
Epoch 1659/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4209 - val_loss: 1.2695 - val_accuracy: 0.4298

Epoch 01659: val_loss did not improve from 1.26793
Epoch 1660/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4210 - val_loss: 1.2718 - val_accuracy: 0.4330

Epoch 01660: val_loss did not improve from 1.26793
Epoch 1661/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4213 - val_loss: 1.2669 - val_accuracy: 0.4266

Epoch 01661: val_loss improved from 1.26793 to 1.26692, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1662/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4207 - val_loss: 1.2701 - val_accuracy: 0.4362

Epoch 01662: val_loss did not improve from 1.26692
Epoch 1663/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4187 - val_loss: 1.2702 - val_accuracy: 0.4290

Epoch 01663: val_loss did not improve from 1.26692
Epoch 1664/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4224 - val_loss: 1.2710 - val_accuracy: 0.4306

Epoch 01664: val_loss did not improve from 1.26692
Epoch 1665/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4194 - val_loss: 1.2696 - val_accuracy: 0.4298

Epoch 01665: val_loss did not improve from 1.26692
Epoch 1666/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4213 - val_loss: 1.2680 - val_accuracy: 0.4378

Epoch 01666: val_loss did not improve from 1.26692
Epoch 1667/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4192 - val_loss: 1.2719 - val_accuracy: 0.4266

Epoch 01667: val_loss did not improve from 1.26692
Epoch 1668/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4179 - val_loss: 1.2691 - val_accuracy: 0.4306

Epoch 01668: val_loss did not improve from 1.26692
Epoch 1669/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4194 - val_loss: 1.2700 - val_accuracy: 0.4298

Epoch 01669: val_loss did not improve from 1.26692
Epoch 1670/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4149 - val_loss: 1.2695 - val_accuracy: 0.4290

Epoch 01670: val_loss did not improve from 1.26692
Epoch 1671/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4177 - val_loss: 1.2696 - val_accuracy: 0.4266

Epoch 01671: val_loss did not improve from 1.26692
Epoch 1672/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4194 - val_loss: 1.2711 - val_accuracy: 0.4314

Epoch 01672: val_loss did not improve from 1.26692
Epoch 1673/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4196 - val_loss: 1.2679 - val_accuracy: 0.4346

Epoch 01673: val_loss did not improve from 1.26692
Epoch 1674/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4193 - val_loss: 1.2684 - val_accuracy: 0.4298

Epoch 01674: val_loss did not improve from 1.26692
Epoch 1675/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4190 - val_loss: 1.2709 - val_accuracy: 0.4298

Epoch 01675: val_loss did not improve from 1.26692
Epoch 1676/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4175 - val_loss: 1.2708 - val_accuracy: 0.4290

Epoch 01676: val_loss did not improve from 1.26692
Epoch 1677/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4175 - val_loss: 1.2700 - val_accuracy: 0.4290

Epoch 01677: val_loss did not improve from 1.26692
Epoch 1678/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4206 - val_loss: 1.2657 - val_accuracy: 0.4354

Epoch 01678: val_loss improved from 1.26692 to 1.26570, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1679/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4188 - val_loss: 1.2708 - val_accuracy: 0.4298

Epoch 01679: val_loss did not improve from 1.26570
Epoch 1680/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4187 - val_loss: 1.2693 - val_accuracy: 0.4322

Epoch 01680: val_loss did not improve from 1.26570
Epoch 1681/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4185 - val_loss: 1.2685 - val_accuracy: 0.4306

Epoch 01681: val_loss did not improve from 1.26570
Epoch 1682/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4205 - val_loss: 1.2667 - val_accuracy: 0.4338

Epoch 01682: val_loss did not improve from 1.26570
Epoch 1683/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4193 - val_loss: 1.2723 - val_accuracy: 0.4314

Epoch 01683: val_loss did not improve from 1.26570
Epoch 1684/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4210 - val_loss: 1.2661 - val_accuracy: 0.4330

Epoch 01684: val_loss did not improve from 1.26570
Epoch 1685/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4184 - val_loss: 1.2675 - val_accuracy: 0.4330

Epoch 01685: val_loss did not improve from 1.26570
Epoch 1686/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4219 - val_loss: 1.2740 - val_accuracy: 0.4298

Epoch 01686: val_loss did not improve from 1.26570
Epoch 1687/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4221 - val_loss: 1.2692 - val_accuracy: 0.4203

Epoch 01687: val_loss did not improve from 1.26570
Epoch 1688/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4187 - val_loss: 1.2705 - val_accuracy: 0.4250

Epoch 01688: val_loss did not improve from 1.26570
Epoch 1689/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4141 - val_loss: 1.2699 - val_accuracy: 0.4322

Epoch 01689: val_loss did not improve from 1.26570
Epoch 1690/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4187 - val_loss: 1.2706 - val_accuracy: 0.4266

Epoch 01690: val_loss did not improve from 1.26570
Epoch 1691/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4186 - val_loss: 1.2681 - val_accuracy: 0.4306

Epoch 01691: val_loss did not improve from 1.26570
Epoch 1692/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4213 - val_loss: 1.2693 - val_accuracy: 0.4226

Epoch 01692: val_loss did not improve from 1.26570
Epoch 1693/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4133 - val_loss: 1.2784 - val_accuracy: 0.4242

Epoch 01693: val_loss did not improve from 1.26570
Epoch 1694/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4176 - val_loss: 1.2653 - val_accuracy: 0.4298

Epoch 01694: val_loss improved from 1.26570 to 1.26534, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1695/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4152 - val_loss: 1.2650 - val_accuracy: 0.4338

Epoch 01695: val_loss improved from 1.26534 to 1.26504, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1696/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4207 - val_loss: 1.2684 - val_accuracy: 0.4290

Epoch 01696: val_loss did not improve from 1.26504
Epoch 1697/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4202 - val_loss: 1.2671 - val_accuracy: 0.4314

Epoch 01697: val_loss did not improve from 1.26504
Epoch 1698/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4209 - val_loss: 1.2672 - val_accuracy: 0.4346

Epoch 01698: val_loss did not improve from 1.26504
Epoch 1699/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4218 - val_loss: 1.2669 - val_accuracy: 0.4266

Epoch 01699: val_loss did not improve from 1.26504
Epoch 1700/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4194 - val_loss: 1.2690 - val_accuracy: 0.4306

Epoch 01700: val_loss did not improve from 1.26504
Epoch 1701/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4172 - val_loss: 1.2664 - val_accuracy: 0.4346

Epoch 01701: val_loss did not improve from 1.26504
Epoch 1702/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4224 - val_loss: 1.2681 - val_accuracy: 0.4266

Epoch 01702: val_loss did not improve from 1.26504
Epoch 1703/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4236 - val_loss: 1.2677 - val_accuracy: 0.4322

Epoch 01703: val_loss did not improve from 1.26504
Epoch 1704/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4225 - val_loss: 1.2677 - val_accuracy: 0.4266

Epoch 01704: val_loss did not improve from 1.26504
Epoch 1705/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4187 - val_loss: 1.2691 - val_accuracy: 0.4282

Epoch 01705: val_loss did not improve from 1.26504
Epoch 1706/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4196 - val_loss: 1.2669 - val_accuracy: 0.4322

Epoch 01706: val_loss did not improve from 1.26504
Epoch 1707/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4200 - val_loss: 1.2659 - val_accuracy: 0.4266

Epoch 01707: val_loss did not improve from 1.26504
Epoch 1708/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4235 - val_loss: 1.2680 - val_accuracy: 0.4282

Epoch 01708: val_loss did not improve from 1.26504
Epoch 1709/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4209 - val_loss: 1.2677 - val_accuracy: 0.4258

Epoch 01709: val_loss did not improve from 1.26504
Epoch 1710/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4200 - val_loss: 1.2681 - val_accuracy: 0.4282

Epoch 01710: val_loss did not improve from 1.26504
Epoch 1711/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4202 - val_loss: 1.2673 - val_accuracy: 0.4274

Epoch 01711: val_loss did not improve from 1.26504
Epoch 1712/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4214 - val_loss: 1.2702 - val_accuracy: 0.4354

Epoch 01712: val_loss did not improve from 1.26504
Epoch 1713/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4227 - val_loss: 1.2689 - val_accuracy: 0.4266

Epoch 01713: val_loss did not improve from 1.26504
Epoch 1714/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4190 - val_loss: 1.2685 - val_accuracy: 0.4266

Epoch 01714: val_loss did not improve from 1.26504
Epoch 1715/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4203 - val_loss: 1.2660 - val_accuracy: 0.4274

Epoch 01715: val_loss did not improve from 1.26504
Epoch 1716/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4225 - val_loss: 1.2652 - val_accuracy: 0.4258

Epoch 01716: val_loss did not improve from 1.26504
Epoch 1717/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4210 - val_loss: 1.2701 - val_accuracy: 0.4338

Epoch 01717: val_loss did not improve from 1.26504
Epoch 1718/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4230 - val_loss: 1.2709 - val_accuracy: 0.4203

Epoch 01718: val_loss did not improve from 1.26504
Epoch 1719/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4194 - val_loss: 1.2661 - val_accuracy: 0.4298

Epoch 01719: val_loss did not improve from 1.26504
Epoch 1720/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4233 - val_loss: 1.2688 - val_accuracy: 0.4266

Epoch 01720: val_loss did not improve from 1.26504
Epoch 1721/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4155 - val_loss: 1.2789 - val_accuracy: 0.4203

Epoch 01721: val_loss did not improve from 1.26504
Epoch 1722/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4168 - val_loss: 1.2674 - val_accuracy: 0.4282

Epoch 01722: val_loss did not improve from 1.26504
Epoch 1723/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4220 - val_loss: 1.2675 - val_accuracy: 0.4298

Epoch 01723: val_loss did not improve from 1.26504
Epoch 1724/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4211 - val_loss: 1.2696 - val_accuracy: 0.4362

Epoch 01724: val_loss did not improve from 1.26504
Epoch 1725/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4230 - val_loss: 1.2706 - val_accuracy: 0.4354

Epoch 01725: val_loss did not improve from 1.26504
Epoch 1726/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4179 - val_loss: 1.2663 - val_accuracy: 0.4370

Epoch 01726: val_loss did not improve from 1.26504
Epoch 1727/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4215 - val_loss: 1.2711 - val_accuracy: 0.4322

Epoch 01727: val_loss did not improve from 1.26504
Epoch 1728/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4187 - val_loss: 1.2648 - val_accuracy: 0.4338

Epoch 01728: val_loss improved from 1.26504 to 1.26481, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1729/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4199 - val_loss: 1.2665 - val_accuracy: 0.4258

Epoch 01729: val_loss did not improve from 1.26481
Epoch 1730/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4211 - val_loss: 1.2689 - val_accuracy: 0.4306

Epoch 01730: val_loss did not improve from 1.26481
Epoch 1731/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4202 - val_loss: 1.2698 - val_accuracy: 0.4258

Epoch 01731: val_loss did not improve from 1.26481
Epoch 1732/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4183 - val_loss: 1.2691 - val_accuracy: 0.4195

Epoch 01732: val_loss did not improve from 1.26481
Epoch 1733/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4180 - val_loss: 1.2664 - val_accuracy: 0.4266

Epoch 01733: val_loss did not improve from 1.26481
Epoch 1734/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4182 - val_loss: 1.2647 - val_accuracy: 0.4282

Epoch 01734: val_loss improved from 1.26481 to 1.26467, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1735/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4232 - val_loss: 1.2653 - val_accuracy: 0.4346

Epoch 01735: val_loss did not improve from 1.26467
Epoch 1736/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4215 - val_loss: 1.2661 - val_accuracy: 0.4330

Epoch 01736: val_loss did not improve from 1.26467
Epoch 1737/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4241 - val_loss: 1.2671 - val_accuracy: 0.4330

Epoch 01737: val_loss did not improve from 1.26467
Epoch 1738/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4203 - val_loss: 1.2656 - val_accuracy: 0.4354

Epoch 01738: val_loss did not improve from 1.26467
Epoch 1739/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4225 - val_loss: 1.2638 - val_accuracy: 0.4250

Epoch 01739: val_loss improved from 1.26467 to 1.26377, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1740/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4218 - val_loss: 1.2656 - val_accuracy: 0.4306

Epoch 01740: val_loss did not improve from 1.26377
Epoch 1741/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4160 - val_loss: 1.2671 - val_accuracy: 0.4298

Epoch 01741: val_loss did not improve from 1.26377
Epoch 1742/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4210 - val_loss: 1.2683 - val_accuracy: 0.4282

Epoch 01742: val_loss did not improve from 1.26377
Epoch 1743/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4194 - val_loss: 1.2687 - val_accuracy: 0.4346

Epoch 01743: val_loss did not improve from 1.26377
Epoch 1744/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4228 - val_loss: 1.2729 - val_accuracy: 0.4258

Epoch 01744: val_loss did not improve from 1.26377
Epoch 1745/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4216 - val_loss: 1.2661 - val_accuracy: 0.4306

Epoch 01745: val_loss did not improve from 1.26377
Epoch 1746/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4212 - val_loss: 1.2676 - val_accuracy: 0.4274

Epoch 01746: val_loss did not improve from 1.26377
Epoch 1747/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4212 - val_loss: 1.2703 - val_accuracy: 0.4290

Epoch 01747: val_loss did not improve from 1.26377
Epoch 1748/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4195 - val_loss: 1.2682 - val_accuracy: 0.4346

Epoch 01748: val_loss did not improve from 1.26377
Epoch 1749/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4187 - val_loss: 1.2682 - val_accuracy: 0.4314

Epoch 01749: val_loss did not improve from 1.26377
Epoch 1750/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4221 - val_loss: 1.2674 - val_accuracy: 0.4330

Epoch 01750: val_loss did not improve from 1.26377
Epoch 1751/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4231 - val_loss: 1.2669 - val_accuracy: 0.4266

Epoch 01751: val_loss did not improve from 1.26377
Epoch 1752/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4223 - val_loss: 1.2665 - val_accuracy: 0.4338

Epoch 01752: val_loss did not improve from 1.26377
Epoch 1753/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4200 - val_loss: 1.2666 - val_accuracy: 0.4346

Epoch 01753: val_loss did not improve from 1.26377
Epoch 1754/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4173 - val_loss: 1.2675 - val_accuracy: 0.4266

Epoch 01754: val_loss did not improve from 1.26377
Epoch 1755/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4217 - val_loss: 1.2640 - val_accuracy: 0.4370

Epoch 01755: val_loss did not improve from 1.26377
Epoch 1756/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4222 - val_loss: 1.2660 - val_accuracy: 0.4234

Epoch 01756: val_loss did not improve from 1.26377
Epoch 1757/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4225 - val_loss: 1.2654 - val_accuracy: 0.4370

Epoch 01757: val_loss did not improve from 1.26377
Epoch 1758/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4234 - val_loss: 1.2643 - val_accuracy: 0.4378

Epoch 01758: val_loss did not improve from 1.26377
Epoch 1759/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4213 - val_loss: 1.2656 - val_accuracy: 0.4354

Epoch 01759: val_loss did not improve from 1.26377
Epoch 1760/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4207 - val_loss: 1.2666 - val_accuracy: 0.4306

Epoch 01760: val_loss did not improve from 1.26377
Epoch 1761/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4199 - val_loss: 1.2689 - val_accuracy: 0.4330

Epoch 01761: val_loss did not improve from 1.26377
Epoch 1762/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4240 - val_loss: 1.2637 - val_accuracy: 0.4338

Epoch 01762: val_loss improved from 1.26377 to 1.26372, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1763/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4231 - val_loss: 1.2652 - val_accuracy: 0.4354

Epoch 01763: val_loss did not improve from 1.26372
Epoch 1764/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4229 - val_loss: 1.2646 - val_accuracy: 0.4322

Epoch 01764: val_loss did not improve from 1.26372
Epoch 1765/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4213 - val_loss: 1.2648 - val_accuracy: 0.4322

Epoch 01765: val_loss did not improve from 1.26372
Epoch 1766/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4214 - val_loss: 1.2691 - val_accuracy: 0.4394

Epoch 01766: val_loss did not improve from 1.26372
Epoch 1767/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4221 - val_loss: 1.2662 - val_accuracy: 0.4378

Epoch 01767: val_loss did not improve from 1.26372
Epoch 1768/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4176 - val_loss: 1.2680 - val_accuracy: 0.4338

Epoch 01768: val_loss did not improve from 1.26372
Epoch 1769/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4249 - val_loss: 1.2674 - val_accuracy: 0.4314

Epoch 01769: val_loss did not improve from 1.26372
Epoch 1770/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4246 - val_loss: 1.2643 - val_accuracy: 0.4338

Epoch 01770: val_loss did not improve from 1.26372
Epoch 1771/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4222 - val_loss: 1.2696 - val_accuracy: 0.4234

Epoch 01771: val_loss did not improve from 1.26372
Epoch 1772/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4214 - val_loss: 1.2671 - val_accuracy: 0.4378

Epoch 01772: val_loss did not improve from 1.26372
Epoch 1773/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4227 - val_loss: 1.2635 - val_accuracy: 0.4226

Epoch 01773: val_loss improved from 1.26372 to 1.26352, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1774/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4237 - val_loss: 1.2671 - val_accuracy: 0.4330

Epoch 01774: val_loss did not improve from 1.26352
Epoch 1775/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4188 - val_loss: 1.2682 - val_accuracy: 0.4219

Epoch 01775: val_loss did not improve from 1.26352
Epoch 1776/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4175 - val_loss: 1.2640 - val_accuracy: 0.4362

Epoch 01776: val_loss did not improve from 1.26352
Epoch 1777/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4210 - val_loss: 1.2675 - val_accuracy: 0.4266

Epoch 01777: val_loss did not improve from 1.26352
Epoch 1778/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4187 - val_loss: 1.2679 - val_accuracy: 0.4282

Epoch 01778: val_loss did not improve from 1.26352
Epoch 1779/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4173 - val_loss: 1.2746 - val_accuracy: 0.4195

Epoch 01779: val_loss did not improve from 1.26352
Epoch 1780/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4235 - val_loss: 1.2665 - val_accuracy: 0.4330

Epoch 01780: val_loss did not improve from 1.26352
Epoch 1781/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4223 - val_loss: 1.2647 - val_accuracy: 0.4378

Epoch 01781: val_loss did not improve from 1.26352
Epoch 1782/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4233 - val_loss: 1.2665 - val_accuracy: 0.4242

Epoch 01782: val_loss did not improve from 1.26352
Epoch 1783/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4217 - val_loss: 1.2690 - val_accuracy: 0.4282

Epoch 01783: val_loss did not improve from 1.26352
Epoch 1784/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4208 - val_loss: 1.2679 - val_accuracy: 0.4314

Epoch 01784: val_loss did not improve from 1.26352
Epoch 1785/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4227 - val_loss: 1.2684 - val_accuracy: 0.4338

Epoch 01785: val_loss did not improve from 1.26352
Epoch 1786/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4249 - val_loss: 1.2662 - val_accuracy: 0.4282

Epoch 01786: val_loss did not improve from 1.26352
Epoch 1787/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4204 - val_loss: 1.2653 - val_accuracy: 0.4290

Epoch 01787: val_loss did not improve from 1.26352
Epoch 1788/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4235 - val_loss: 1.2669 - val_accuracy: 0.4250

Epoch 01788: val_loss did not improve from 1.26352
Epoch 1789/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4210 - val_loss: 1.2671 - val_accuracy: 0.4234

Epoch 01789: val_loss did not improve from 1.26352
Epoch 1790/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4221 - val_loss: 1.2639 - val_accuracy: 0.4354

Epoch 01790: val_loss did not improve from 1.26352
Epoch 1791/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4184 - val_loss: 1.2674 - val_accuracy: 0.4266

Epoch 01791: val_loss did not improve from 1.26352
Epoch 1792/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4214 - val_loss: 1.2664 - val_accuracy: 0.4290

Epoch 01792: val_loss did not improve from 1.26352
Epoch 1793/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4194 - val_loss: 1.2676 - val_accuracy: 0.4330

Epoch 01793: val_loss did not improve from 1.26352
Epoch 1794/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4211 - val_loss: 1.2660 - val_accuracy: 0.4362

Epoch 01794: val_loss did not improve from 1.26352
Epoch 1795/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4227 - val_loss: 1.2676 - val_accuracy: 0.4282

Epoch 01795: val_loss did not improve from 1.26352
Epoch 1796/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4218 - val_loss: 1.2639 - val_accuracy: 0.4338

Epoch 01796: val_loss did not improve from 1.26352
Epoch 1797/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4203 - val_loss: 1.2686 - val_accuracy: 0.4242

Epoch 01797: val_loss did not improve from 1.26352
Epoch 1798/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4233 - val_loss: 1.2653 - val_accuracy: 0.4290

Epoch 01798: val_loss did not improve from 1.26352
Epoch 1799/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4193 - val_loss: 1.2636 - val_accuracy: 0.4298

Epoch 01799: val_loss did not improve from 1.26352
Epoch 1800/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4224 - val_loss: 1.2657 - val_accuracy: 0.4354

Epoch 01800: val_loss did not improve from 1.26352
Epoch 1801/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4192 - val_loss: 1.2650 - val_accuracy: 0.4314

Epoch 01801: val_loss did not improve from 1.26352
Epoch 1802/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4228 - val_loss: 1.2663 - val_accuracy: 0.4322

Epoch 01802: val_loss did not improve from 1.26352
Epoch 1803/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4235 - val_loss: 1.2649 - val_accuracy: 0.4306

Epoch 01803: val_loss did not improve from 1.26352
Epoch 1804/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4246 - val_loss: 1.2640 - val_accuracy: 0.4298

Epoch 01804: val_loss did not improve from 1.26352
Epoch 1805/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4221 - val_loss: 1.2703 - val_accuracy: 0.4290

Epoch 01805: val_loss did not improve from 1.26352
Epoch 1806/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4202 - val_loss: 1.2678 - val_accuracy: 0.4274

Epoch 01806: val_loss did not improve from 1.26352
Epoch 1807/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4150 - val_loss: 1.2663 - val_accuracy: 0.4298

Epoch 01807: val_loss did not improve from 1.26352
Epoch 1808/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4213 - val_loss: 1.2639 - val_accuracy: 0.4242

Epoch 01808: val_loss did not improve from 1.26352
Epoch 1809/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4249 - val_loss: 1.2677 - val_accuracy: 0.4330

Epoch 01809: val_loss did not improve from 1.26352
Epoch 1810/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4247 - val_loss: 1.2690 - val_accuracy: 0.4330

Epoch 01810: val_loss did not improve from 1.26352
Epoch 1811/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4197 - val_loss: 1.2681 - val_accuracy: 0.4314

Epoch 01811: val_loss did not improve from 1.26352
Epoch 1812/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4215 - val_loss: 1.2670 - val_accuracy: 0.4290

Epoch 01812: val_loss did not improve from 1.26352
Epoch 1813/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4153 - val_loss: 1.2661 - val_accuracy: 0.4314

Epoch 01813: val_loss did not improve from 1.26352
Epoch 1814/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4233 - val_loss: 1.2692 - val_accuracy: 0.4242

Epoch 01814: val_loss did not improve from 1.26352
Epoch 1815/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4214 - val_loss: 1.2625 - val_accuracy: 0.4274

Epoch 01815: val_loss improved from 1.26352 to 1.26246, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1816/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4225 - val_loss: 1.2653 - val_accuracy: 0.4370

Epoch 01816: val_loss did not improve from 1.26246
Epoch 1817/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4215 - val_loss: 1.2635 - val_accuracy: 0.4330

Epoch 01817: val_loss did not improve from 1.26246
Epoch 1818/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4191 - val_loss: 1.2649 - val_accuracy: 0.4314

Epoch 01818: val_loss did not improve from 1.26246
Epoch 1819/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4207 - val_loss: 1.2630 - val_accuracy: 0.4234

Epoch 01819: val_loss did not improve from 1.26246
Epoch 1820/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4253 - val_loss: 1.2637 - val_accuracy: 0.4346

Epoch 01820: val_loss did not improve from 1.26246
Epoch 1821/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4255 - val_loss: 1.2653 - val_accuracy: 0.4282

Epoch 01821: val_loss did not improve from 1.26246
Epoch 1822/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4203 - val_loss: 1.2650 - val_accuracy: 0.4242

Epoch 01822: val_loss did not improve from 1.26246
Epoch 1823/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4238 - val_loss: 1.2644 - val_accuracy: 0.4346

Epoch 01823: val_loss did not improve from 1.26246
Epoch 1824/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4247 - val_loss: 1.2665 - val_accuracy: 0.4354

Epoch 01824: val_loss did not improve from 1.26246
Epoch 1825/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4236 - val_loss: 1.2645 - val_accuracy: 0.4354

Epoch 01825: val_loss did not improve from 1.26246
Epoch 1826/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4215 - val_loss: 1.2660 - val_accuracy: 0.4282

Epoch 01826: val_loss did not improve from 1.26246
Epoch 1827/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4212 - val_loss: 1.2686 - val_accuracy: 0.4258

Epoch 01827: val_loss did not improve from 1.26246
Epoch 1828/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4210 - val_loss: 1.2648 - val_accuracy: 0.4306

Epoch 01828: val_loss did not improve from 1.26246
Epoch 1829/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4194 - val_loss: 1.2648 - val_accuracy: 0.4346

Epoch 01829: val_loss did not improve from 1.26246
Epoch 1830/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4205 - val_loss: 1.2660 - val_accuracy: 0.4306

Epoch 01830: val_loss did not improve from 1.26246
Epoch 1831/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4207 - val_loss: 1.2669 - val_accuracy: 0.4298

Epoch 01831: val_loss did not improve from 1.26246
Epoch 1832/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4208 - val_loss: 1.2626 - val_accuracy: 0.4258

Epoch 01832: val_loss did not improve from 1.26246
Epoch 1833/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4225 - val_loss: 1.2624 - val_accuracy: 0.4330

Epoch 01833: val_loss improved from 1.26246 to 1.26243, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1834/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4199 - val_loss: 1.2681 - val_accuracy: 0.4290

Epoch 01834: val_loss did not improve from 1.26243
Epoch 1835/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4173 - val_loss: 1.2664 - val_accuracy: 0.4314

Epoch 01835: val_loss did not improve from 1.26243
Epoch 1836/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4195 - val_loss: 1.2644 - val_accuracy: 0.4346

Epoch 01836: val_loss did not improve from 1.26243
Epoch 1837/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4227 - val_loss: 1.2674 - val_accuracy: 0.4322

Epoch 01837: val_loss did not improve from 1.26243
Epoch 1838/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4218 - val_loss: 1.2654 - val_accuracy: 0.4322

Epoch 01838: val_loss did not improve from 1.26243
Epoch 1839/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4235 - val_loss: 1.2622 - val_accuracy: 0.4378

Epoch 01839: val_loss improved from 1.26243 to 1.26219, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1840/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4190 - val_loss: 1.2671 - val_accuracy: 0.4338

Epoch 01840: val_loss did not improve from 1.26219
Epoch 1841/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4231 - val_loss: 1.2659 - val_accuracy: 0.4418

Epoch 01841: val_loss did not improve from 1.26219
Epoch 1842/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4225 - val_loss: 1.2634 - val_accuracy: 0.4314

Epoch 01842: val_loss did not improve from 1.26219
Epoch 1843/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4217 - val_loss: 1.2636 - val_accuracy: 0.4370

Epoch 01843: val_loss did not improve from 1.26219
Epoch 1844/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4237 - val_loss: 1.2614 - val_accuracy: 0.4370

Epoch 01844: val_loss improved from 1.26219 to 1.26142, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1845/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4236 - val_loss: 1.2638 - val_accuracy: 0.4330

Epoch 01845: val_loss did not improve from 1.26142
Epoch 1846/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4185 - val_loss: 1.2672 - val_accuracy: 0.4290

Epoch 01846: val_loss did not improve from 1.26142
Epoch 1847/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4237 - val_loss: 1.2650 - val_accuracy: 0.4330

Epoch 01847: val_loss did not improve from 1.26142
Epoch 1848/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4236 - val_loss: 1.2652 - val_accuracy: 0.4378

Epoch 01848: val_loss did not improve from 1.26142
Epoch 1849/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4180 - val_loss: 1.2734 - val_accuracy: 0.4322

Epoch 01849: val_loss did not improve from 1.26142
Epoch 1850/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4201 - val_loss: 1.2646 - val_accuracy: 0.4266

Epoch 01850: val_loss did not improve from 1.26142
Epoch 1851/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4213 - val_loss: 1.2638 - val_accuracy: 0.4219

Epoch 01851: val_loss did not improve from 1.26142
Epoch 1852/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4186 - val_loss: 1.2649 - val_accuracy: 0.4290

Epoch 01852: val_loss did not improve from 1.26142
Epoch 1853/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4241 - val_loss: 1.2624 - val_accuracy: 0.4250

Epoch 01853: val_loss did not improve from 1.26142
Epoch 1854/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4218 - val_loss: 1.2642 - val_accuracy: 0.4330

Epoch 01854: val_loss did not improve from 1.26142
Epoch 1855/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4244 - val_loss: 1.2627 - val_accuracy: 0.4306

Epoch 01855: val_loss did not improve from 1.26142
Epoch 1856/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4259 - val_loss: 1.2628 - val_accuracy: 0.4314

Epoch 01856: val_loss did not improve from 1.26142
Epoch 1857/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4202 - val_loss: 1.2662 - val_accuracy: 0.4298

Epoch 01857: val_loss did not improve from 1.26142
Epoch 1858/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4171 - val_loss: 1.2627 - val_accuracy: 0.4274

Epoch 01858: val_loss did not improve from 1.26142
Epoch 1859/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4233 - val_loss: 1.2608 - val_accuracy: 0.4418

Epoch 01859: val_loss improved from 1.26142 to 1.26084, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1860/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4236 - val_loss: 1.2637 - val_accuracy: 0.4330

Epoch 01860: val_loss did not improve from 1.26084
Epoch 1861/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4210 - val_loss: 1.2725 - val_accuracy: 0.4322

Epoch 01861: val_loss did not improve from 1.26084
Epoch 1862/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4213 - val_loss: 1.2669 - val_accuracy: 0.4250

Epoch 01862: val_loss did not improve from 1.26084
Epoch 1863/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4211 - val_loss: 1.2681 - val_accuracy: 0.4298

Epoch 01863: val_loss did not improve from 1.26084
Epoch 1864/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4229 - val_loss: 1.2660 - val_accuracy: 0.4306

Epoch 01864: val_loss did not improve from 1.26084
Epoch 1865/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4278 - val_loss: 1.2634 - val_accuracy: 0.4330

Epoch 01865: val_loss did not improve from 1.26084
Epoch 1866/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4241 - val_loss: 1.2618 - val_accuracy: 0.4298

Epoch 01866: val_loss did not improve from 1.26084
Epoch 1867/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4194 - val_loss: 1.2677 - val_accuracy: 0.4306

Epoch 01867: val_loss did not improve from 1.26084
Epoch 1868/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4235 - val_loss: 1.2619 - val_accuracy: 0.4362

Epoch 01868: val_loss did not improve from 1.26084
Epoch 1869/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4262 - val_loss: 1.2645 - val_accuracy: 0.4298

Epoch 01869: val_loss did not improve from 1.26084
Epoch 1870/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4242 - val_loss: 1.2659 - val_accuracy: 0.4338

Epoch 01870: val_loss did not improve from 1.26084
Epoch 1871/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4233 - val_loss: 1.2634 - val_accuracy: 0.4290

Epoch 01871: val_loss did not improve from 1.26084
Epoch 1872/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4226 - val_loss: 1.2627 - val_accuracy: 0.4354

Epoch 01872: val_loss did not improve from 1.26084
Epoch 1873/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4237 - val_loss: 1.2627 - val_accuracy: 0.4290

Epoch 01873: val_loss did not improve from 1.26084
Epoch 1874/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4214 - val_loss: 1.2636 - val_accuracy: 0.4322

Epoch 01874: val_loss did not improve from 1.26084
Epoch 1875/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4208 - val_loss: 1.2601 - val_accuracy: 0.4322

Epoch 01875: val_loss improved from 1.26084 to 1.26011, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1876/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4219 - val_loss: 1.2610 - val_accuracy: 0.4314

Epoch 01876: val_loss did not improve from 1.26011
Epoch 1877/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4243 - val_loss: 1.2660 - val_accuracy: 0.4258

Epoch 01877: val_loss did not improve from 1.26011
Epoch 1878/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4225 - val_loss: 1.2632 - val_accuracy: 0.4298

Epoch 01878: val_loss did not improve from 1.26011
Epoch 1879/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4222 - val_loss: 1.2636 - val_accuracy: 0.4338

Epoch 01879: val_loss did not improve from 1.26011
Epoch 1880/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4293 - val_loss: 1.2609 - val_accuracy: 0.4330

Epoch 01880: val_loss did not improve from 1.26011
Epoch 1881/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4262 - val_loss: 1.2636 - val_accuracy: 0.4378

Epoch 01881: val_loss did not improve from 1.26011
Epoch 1882/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4232 - val_loss: 1.2621 - val_accuracy: 0.4338

Epoch 01882: val_loss did not improve from 1.26011
Epoch 1883/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4234 - val_loss: 1.2611 - val_accuracy: 0.4298

Epoch 01883: val_loss did not improve from 1.26011
Epoch 1884/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4219 - val_loss: 1.2602 - val_accuracy: 0.4322

Epoch 01884: val_loss did not improve from 1.26011
Epoch 1885/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4232 - val_loss: 1.2605 - val_accuracy: 0.4314

Epoch 01885: val_loss did not improve from 1.26011
Epoch 1886/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4250 - val_loss: 1.2626 - val_accuracy: 0.4402

Epoch 01886: val_loss did not improve from 1.26011
Epoch 1887/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4206 - val_loss: 1.2616 - val_accuracy: 0.4290

Epoch 01887: val_loss did not improve from 1.26011
Epoch 1888/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4185 - val_loss: 1.2655 - val_accuracy: 0.4362

Epoch 01888: val_loss did not improve from 1.26011
Epoch 1889/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4234 - val_loss: 1.2606 - val_accuracy: 0.4378

Epoch 01889: val_loss did not improve from 1.26011
Epoch 1890/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4209 - val_loss: 1.2610 - val_accuracy: 0.4354

Epoch 01890: val_loss did not improve from 1.26011
Epoch 1891/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4233 - val_loss: 1.2654 - val_accuracy: 0.4290

Epoch 01891: val_loss did not improve from 1.26011
Epoch 1892/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4211 - val_loss: 1.2618 - val_accuracy: 0.4306

Epoch 01892: val_loss did not improve from 1.26011
Epoch 1893/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4262 - val_loss: 1.2621 - val_accuracy: 0.4298

Epoch 01893: val_loss did not improve from 1.26011
Epoch 1894/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4236 - val_loss: 1.2613 - val_accuracy: 0.4346

Epoch 01894: val_loss did not improve from 1.26011
Epoch 1895/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4236 - val_loss: 1.2629 - val_accuracy: 0.4242

Epoch 01895: val_loss did not improve from 1.26011
Epoch 1896/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4216 - val_loss: 1.2653 - val_accuracy: 0.4290

Epoch 01896: val_loss did not improve from 1.26011
Epoch 1897/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4228 - val_loss: 1.2680 - val_accuracy: 0.4290

Epoch 01897: val_loss did not improve from 1.26011
Epoch 1898/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4211 - val_loss: 1.2650 - val_accuracy: 0.4266

Epoch 01898: val_loss did not improve from 1.26011
Epoch 1899/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4194 - val_loss: 1.2688 - val_accuracy: 0.4250

Epoch 01899: val_loss did not improve from 1.26011
Epoch 1900/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4251 - val_loss: 1.2606 - val_accuracy: 0.4306

Epoch 01900: val_loss did not improve from 1.26011
Epoch 1901/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4241 - val_loss: 1.2602 - val_accuracy: 0.4314

Epoch 01901: val_loss did not improve from 1.26011
Epoch 1902/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4219 - val_loss: 1.2641 - val_accuracy: 0.4330

Epoch 01902: val_loss did not improve from 1.26011
Epoch 1903/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4239 - val_loss: 1.2616 - val_accuracy: 0.4242

Epoch 01903: val_loss did not improve from 1.26011
Epoch 1904/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4211 - val_loss: 1.2602 - val_accuracy: 0.4330

Epoch 01904: val_loss did not improve from 1.26011
Epoch 1905/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4232 - val_loss: 1.2639 - val_accuracy: 0.4322

Epoch 01905: val_loss did not improve from 1.26011
Epoch 1906/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4216 - val_loss: 1.2616 - val_accuracy: 0.4290

Epoch 01906: val_loss did not improve from 1.26011
Epoch 1907/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4269 - val_loss: 1.2667 - val_accuracy: 0.4306

Epoch 01907: val_loss did not improve from 1.26011
Epoch 1908/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4179 - val_loss: 1.2645 - val_accuracy: 0.4314

Epoch 01908: val_loss did not improve from 1.26011
Epoch 1909/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4218 - val_loss: 1.2645 - val_accuracy: 0.4338

Epoch 01909: val_loss did not improve from 1.26011
Epoch 1910/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4210 - val_loss: 1.2596 - val_accuracy: 0.4290

Epoch 01910: val_loss improved from 1.26011 to 1.25962, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1911/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4272 - val_loss: 1.2626 - val_accuracy: 0.4338

Epoch 01911: val_loss did not improve from 1.25962
Epoch 1912/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4166 - val_loss: 1.2634 - val_accuracy: 0.4258

Epoch 01912: val_loss did not improve from 1.25962
Epoch 1913/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4241 - val_loss: 1.2636 - val_accuracy: 0.4338

Epoch 01913: val_loss did not improve from 1.25962
Epoch 1914/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4258 - val_loss: 1.2607 - val_accuracy: 0.4298

Epoch 01914: val_loss did not improve from 1.25962
Epoch 1915/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4214 - val_loss: 1.2619 - val_accuracy: 0.4274

Epoch 01915: val_loss did not improve from 1.25962
Epoch 1916/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4231 - val_loss: 1.2612 - val_accuracy: 0.4314

Epoch 01916: val_loss did not improve from 1.25962
Epoch 1917/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4194 - val_loss: 1.2638 - val_accuracy: 0.4274

Epoch 01917: val_loss did not improve from 1.25962
Epoch 1918/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4191 - val_loss: 1.2693 - val_accuracy: 0.4219

Epoch 01918: val_loss did not improve from 1.25962
Epoch 1919/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4218 - val_loss: 1.2612 - val_accuracy: 0.4378

Epoch 01919: val_loss did not improve from 1.25962
Epoch 1920/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4224 - val_loss: 1.2646 - val_accuracy: 0.4322

Epoch 01920: val_loss did not improve from 1.25962
Epoch 1921/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4263 - val_loss: 1.2623 - val_accuracy: 0.4298

Epoch 01921: val_loss did not improve from 1.25962
Epoch 1922/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4217 - val_loss: 1.2624 - val_accuracy: 0.4266

Epoch 01922: val_loss did not improve from 1.25962
Epoch 1923/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4229 - val_loss: 1.2622 - val_accuracy: 0.4290

Epoch 01923: val_loss did not improve from 1.25962
Epoch 1924/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4225 - val_loss: 1.2666 - val_accuracy: 0.4306

Epoch 01924: val_loss did not improve from 1.25962
Epoch 1925/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4241 - val_loss: 1.2650 - val_accuracy: 0.4314

Epoch 01925: val_loss did not improve from 1.25962
Epoch 1926/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4208 - val_loss: 1.2674 - val_accuracy: 0.4234

Epoch 01926: val_loss did not improve from 1.25962
Epoch 1927/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4209 - val_loss: 1.2611 - val_accuracy: 0.4346

Epoch 01927: val_loss did not improve from 1.25962
Epoch 1928/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4223 - val_loss: 1.2662 - val_accuracy: 0.4234

Epoch 01928: val_loss did not improve from 1.25962
Epoch 1929/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4224 - val_loss: 1.2632 - val_accuracy: 0.4274

Epoch 01929: val_loss did not improve from 1.25962
Epoch 1930/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4234 - val_loss: 1.2636 - val_accuracy: 0.4314

Epoch 01930: val_loss did not improve from 1.25962
Epoch 1931/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4256 - val_loss: 1.2616 - val_accuracy: 0.4330

Epoch 01931: val_loss did not improve from 1.25962
Epoch 1932/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4235 - val_loss: 1.2613 - val_accuracy: 0.4330

Epoch 01932: val_loss did not improve from 1.25962
Epoch 1933/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4220 - val_loss: 1.2699 - val_accuracy: 0.4314

Epoch 01933: val_loss did not improve from 1.25962
Epoch 1934/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4233 - val_loss: 1.2669 - val_accuracy: 0.4274

Epoch 01934: val_loss did not improve from 1.25962
Epoch 1935/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4225 - val_loss: 1.2670 - val_accuracy: 0.4298

Epoch 01935: val_loss did not improve from 1.25962
Epoch 1936/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4229 - val_loss: 1.2606 - val_accuracy: 0.4274

Epoch 01936: val_loss did not improve from 1.25962
Epoch 1937/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4254 - val_loss: 1.2605 - val_accuracy: 0.4306

Epoch 01937: val_loss did not improve from 1.25962
Epoch 1938/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4210 - val_loss: 1.2598 - val_accuracy: 0.4346

Epoch 01938: val_loss did not improve from 1.25962
Epoch 1939/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4244 - val_loss: 1.2609 - val_accuracy: 0.4314

Epoch 01939: val_loss did not improve from 1.25962
Epoch 1940/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4192 - val_loss: 1.2663 - val_accuracy: 0.4250

Epoch 01940: val_loss did not improve from 1.25962
Epoch 1941/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4251 - val_loss: 1.2618 - val_accuracy: 0.4330

Epoch 01941: val_loss did not improve from 1.25962
Epoch 1942/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4242 - val_loss: 1.2639 - val_accuracy: 0.4346

Epoch 01942: val_loss did not improve from 1.25962
Epoch 1943/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4243 - val_loss: 1.2614 - val_accuracy: 0.4250

Epoch 01943: val_loss did not improve from 1.25962
Epoch 1944/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4269 - val_loss: 1.2618 - val_accuracy: 0.4290

Epoch 01944: val_loss did not improve from 1.25962
Epoch 1945/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4250 - val_loss: 1.2597 - val_accuracy: 0.4290

Epoch 01945: val_loss did not improve from 1.25962
Epoch 1946/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4214 - val_loss: 1.2662 - val_accuracy: 0.4290

Epoch 01946: val_loss did not improve from 1.25962
Epoch 1947/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4224 - val_loss: 1.2617 - val_accuracy: 0.4298

Epoch 01947: val_loss did not improve from 1.25962
Epoch 1948/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4222 - val_loss: 1.2635 - val_accuracy: 0.4274

Epoch 01948: val_loss did not improve from 1.25962
Epoch 1949/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4219 - val_loss: 1.2623 - val_accuracy: 0.4354

Epoch 01949: val_loss did not improve from 1.25962
Epoch 1950/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4232 - val_loss: 1.2624 - val_accuracy: 0.4234

Epoch 01950: val_loss did not improve from 1.25962
Epoch 1951/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4213 - val_loss: 1.2599 - val_accuracy: 0.4298

Epoch 01951: val_loss did not improve from 1.25962
Epoch 1952/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4243 - val_loss: 1.2599 - val_accuracy: 0.4219

Epoch 01952: val_loss did not improve from 1.25962
Epoch 1953/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4268 - val_loss: 1.2647 - val_accuracy: 0.4298

Epoch 01953: val_loss did not improve from 1.25962
Epoch 1954/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4233 - val_loss: 1.2596 - val_accuracy: 0.4370

Epoch 01954: val_loss improved from 1.25962 to 1.25961, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1955/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4229 - val_loss: 1.2606 - val_accuracy: 0.4266

Epoch 01955: val_loss did not improve from 1.25961
Epoch 1956/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4230 - val_loss: 1.2620 - val_accuracy: 0.4211

Epoch 01956: val_loss did not improve from 1.25961
Epoch 1957/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4208 - val_loss: 1.2689 - val_accuracy: 0.4234

Epoch 01957: val_loss did not improve from 1.25961
Epoch 1958/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4235 - val_loss: 1.2599 - val_accuracy: 0.4314

Epoch 01958: val_loss did not improve from 1.25961
Epoch 1959/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4234 - val_loss: 1.2586 - val_accuracy: 0.4346

Epoch 01959: val_loss improved from 1.25961 to 1.25864, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 1960/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4250 - val_loss: 1.2596 - val_accuracy: 0.4314

Epoch 01960: val_loss did not improve from 1.25864
Epoch 1961/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4223 - val_loss: 1.2600 - val_accuracy: 0.4314

Epoch 01961: val_loss did not improve from 1.25864
Epoch 1962/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4220 - val_loss: 1.2629 - val_accuracy: 0.4282

Epoch 01962: val_loss did not improve from 1.25864
Epoch 1963/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4210 - val_loss: 1.2627 - val_accuracy: 0.4290

Epoch 01963: val_loss did not improve from 1.25864
Epoch 1964/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4256 - val_loss: 1.2589 - val_accuracy: 0.4306

Epoch 01964: val_loss did not improve from 1.25864
Epoch 1965/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4244 - val_loss: 1.2604 - val_accuracy: 0.4282

Epoch 01965: val_loss did not improve from 1.25864
Epoch 1966/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4253 - val_loss: 1.2613 - val_accuracy: 0.4258

Epoch 01966: val_loss did not improve from 1.25864
Epoch 1967/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4235 - val_loss: 1.2631 - val_accuracy: 0.4354

Epoch 01967: val_loss did not improve from 1.25864
Epoch 1968/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4247 - val_loss: 1.2627 - val_accuracy: 0.4394

Epoch 01968: val_loss did not improve from 1.25864
Epoch 1969/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4221 - val_loss: 1.2609 - val_accuracy: 0.4354

Epoch 01969: val_loss did not improve from 1.25864
Epoch 1970/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4248 - val_loss: 1.2634 - val_accuracy: 0.4250

Epoch 01970: val_loss did not improve from 1.25864
Epoch 1971/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4231 - val_loss: 1.2616 - val_accuracy: 0.4266

Epoch 01971: val_loss did not improve from 1.25864
Epoch 1972/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4247 - val_loss: 1.2621 - val_accuracy: 0.4274

Epoch 01972: val_loss did not improve from 1.25864
Epoch 1973/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4234 - val_loss: 1.2611 - val_accuracy: 0.4322

Epoch 01973: val_loss did not improve from 1.25864
Epoch 1974/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4234 - val_loss: 1.2633 - val_accuracy: 0.4410

Epoch 01974: val_loss did not improve from 1.25864
Epoch 1975/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4272 - val_loss: 1.2598 - val_accuracy: 0.4346

Epoch 01975: val_loss did not improve from 1.25864
Epoch 1976/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4257 - val_loss: 1.2600 - val_accuracy: 0.4338

Epoch 01976: val_loss did not improve from 1.25864
Epoch 1977/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4243 - val_loss: 1.2661 - val_accuracy: 0.4282

Epoch 01977: val_loss did not improve from 1.25864
Epoch 1978/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4241 - val_loss: 1.2616 - val_accuracy: 0.4314

Epoch 01978: val_loss did not improve from 1.25864
Epoch 1979/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4256 - val_loss: 1.2590 - val_accuracy: 0.4338

Epoch 01979: val_loss did not improve from 1.25864
Epoch 1980/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4225 - val_loss: 1.2606 - val_accuracy: 0.4306

Epoch 01980: val_loss did not improve from 1.25864
Epoch 1981/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4228 - val_loss: 1.2591 - val_accuracy: 0.4266

Epoch 01981: val_loss did not improve from 1.25864
Epoch 1982/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4239 - val_loss: 1.2646 - val_accuracy: 0.4330

Epoch 01982: val_loss did not improve from 1.25864
Epoch 1983/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4238 - val_loss: 1.2605 - val_accuracy: 0.4298

Epoch 01983: val_loss did not improve from 1.25864
Epoch 1984/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4231 - val_loss: 1.2613 - val_accuracy: 0.4362

Epoch 01984: val_loss did not improve from 1.25864
Epoch 1985/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4251 - val_loss: 1.2651 - val_accuracy: 0.4282

Epoch 01985: val_loss did not improve from 1.25864
Epoch 1986/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4209 - val_loss: 1.2616 - val_accuracy: 0.4211

Epoch 01986: val_loss did not improve from 1.25864
Epoch 1987/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4264 - val_loss: 1.2599 - val_accuracy: 0.4330

Epoch 01987: val_loss did not improve from 1.25864
Epoch 1988/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4225 - val_loss: 1.2589 - val_accuracy: 0.4266

Epoch 01988: val_loss did not improve from 1.25864
Epoch 1989/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4252 - val_loss: 1.2614 - val_accuracy: 0.4274

Epoch 01989: val_loss did not improve from 1.25864
Epoch 1990/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4220 - val_loss: 1.2615 - val_accuracy: 0.4266

Epoch 01990: val_loss did not improve from 1.25864
Epoch 1991/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4218 - val_loss: 1.2624 - val_accuracy: 0.4282

Epoch 01991: val_loss did not improve from 1.25864
Epoch 1992/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4261 - val_loss: 1.2592 - val_accuracy: 0.4250

Epoch 01992: val_loss did not improve from 1.25864
Epoch 1993/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4278 - val_loss: 1.2600 - val_accuracy: 0.4322

Epoch 01993: val_loss did not improve from 1.25864
Epoch 1994/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4221 - val_loss: 1.2686 - val_accuracy: 0.4298

Epoch 01994: val_loss did not improve from 1.25864
Epoch 1995/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4265 - val_loss: 1.2595 - val_accuracy: 0.4306

Epoch 01995: val_loss did not improve from 1.25864
Epoch 1996/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4251 - val_loss: 1.2593 - val_accuracy: 0.4258

Epoch 01996: val_loss did not improve from 1.25864
Epoch 1997/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4241 - val_loss: 1.2642 - val_accuracy: 0.4298

Epoch 01997: val_loss did not improve from 1.25864
Epoch 1998/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4220 - val_loss: 1.2618 - val_accuracy: 0.4258

Epoch 01998: val_loss did not improve from 1.25864
Epoch 1999/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4225 - val_loss: 1.2590 - val_accuracy: 0.4346

Epoch 01999: val_loss did not improve from 1.25864
Epoch 2000/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4251 - val_loss: 1.2606 - val_accuracy: 0.4250

Epoch 02000: val_loss did not improve from 1.25864
Epoch 2001/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4257 - val_loss: 1.2633 - val_accuracy: 0.4298

Epoch 02001: val_loss did not improve from 1.25864
Epoch 2002/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4236 - val_loss: 1.2602 - val_accuracy: 0.4274

Epoch 02002: val_loss did not improve from 1.25864
Epoch 2003/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4249 - val_loss: 1.2594 - val_accuracy: 0.4306

Epoch 02003: val_loss did not improve from 1.25864
Epoch 2004/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4267 - val_loss: 1.2606 - val_accuracy: 0.4354

Epoch 02004: val_loss did not improve from 1.25864
Epoch 2005/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4236 - val_loss: 1.2605 - val_accuracy: 0.4298

Epoch 02005: val_loss did not improve from 1.25864
Epoch 2006/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4237 - val_loss: 1.2621 - val_accuracy: 0.4346

Epoch 02006: val_loss did not improve from 1.25864
Epoch 2007/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4266 - val_loss: 1.2590 - val_accuracy: 0.4322

Epoch 02007: val_loss did not improve from 1.25864
Epoch 2008/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4262 - val_loss: 1.2605 - val_accuracy: 0.4306

Epoch 02008: val_loss did not improve from 1.25864
Epoch 2009/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4241 - val_loss: 1.2647 - val_accuracy: 0.4322

Epoch 02009: val_loss did not improve from 1.25864
Epoch 2010/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4250 - val_loss: 1.2611 - val_accuracy: 0.4346

Epoch 02010: val_loss did not improve from 1.25864
Epoch 2011/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4244 - val_loss: 1.2611 - val_accuracy: 0.4290

Epoch 02011: val_loss did not improve from 1.25864
Epoch 2012/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4264 - val_loss: 1.2623 - val_accuracy: 0.4258

Epoch 02012: val_loss did not improve from 1.25864
Epoch 2013/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4205 - val_loss: 1.2637 - val_accuracy: 0.4274

Epoch 02013: val_loss did not improve from 1.25864
Epoch 2014/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4231 - val_loss: 1.2630 - val_accuracy: 0.4258

Epoch 02014: val_loss did not improve from 1.25864
Epoch 2015/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4237 - val_loss: 1.2623 - val_accuracy: 0.4370

Epoch 02015: val_loss did not improve from 1.25864
Epoch 2016/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4249 - val_loss: 1.2589 - val_accuracy: 0.4370

Epoch 02016: val_loss did not improve from 1.25864
Epoch 2017/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4273 - val_loss: 1.2576 - val_accuracy: 0.4370

Epoch 02017: val_loss improved from 1.25864 to 1.25759, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2018/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4255 - val_loss: 1.2606 - val_accuracy: 0.4330

Epoch 02018: val_loss did not improve from 1.25759
Epoch 2019/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4241 - val_loss: 1.2578 - val_accuracy: 0.4266

Epoch 02019: val_loss did not improve from 1.25759
Epoch 2020/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4278 - val_loss: 1.2601 - val_accuracy: 0.4306

Epoch 02020: val_loss did not improve from 1.25759
Epoch 2021/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4254 - val_loss: 1.2626 - val_accuracy: 0.4346

Epoch 02021: val_loss did not improve from 1.25759
Epoch 2022/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4249 - val_loss: 1.2596 - val_accuracy: 0.4354

Epoch 02022: val_loss did not improve from 1.25759
Epoch 2023/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4264 - val_loss: 1.2592 - val_accuracy: 0.4346

Epoch 02023: val_loss did not improve from 1.25759
Epoch 2024/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4275 - val_loss: 1.2639 - val_accuracy: 0.4274

Epoch 02024: val_loss did not improve from 1.25759
Epoch 2025/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4242 - val_loss: 1.2595 - val_accuracy: 0.4266

Epoch 02025: val_loss did not improve from 1.25759
Epoch 2026/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4185 - val_loss: 1.2604 - val_accuracy: 0.4250

Epoch 02026: val_loss did not improve from 1.25759
Epoch 2027/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4250 - val_loss: 1.2602 - val_accuracy: 0.4346

Epoch 02027: val_loss did not improve from 1.25759
Epoch 2028/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4238 - val_loss: 1.2608 - val_accuracy: 0.4378

Epoch 02028: val_loss did not improve from 1.25759
Epoch 2029/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4272 - val_loss: 1.2595 - val_accuracy: 0.4306

Epoch 02029: val_loss did not improve from 1.25759
Epoch 2030/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4256 - val_loss: 1.2600 - val_accuracy: 0.4354

Epoch 02030: val_loss did not improve from 1.25759
Epoch 2031/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4270 - val_loss: 1.2590 - val_accuracy: 0.4394

Epoch 02031: val_loss did not improve from 1.25759
Epoch 2032/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4247 - val_loss: 1.2628 - val_accuracy: 0.4354

Epoch 02032: val_loss did not improve from 1.25759
Epoch 2033/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4268 - val_loss: 1.2613 - val_accuracy: 0.4378

Epoch 02033: val_loss did not improve from 1.25759
Epoch 2034/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4268 - val_loss: 1.2581 - val_accuracy: 0.4290

Epoch 02034: val_loss did not improve from 1.25759
Epoch 2035/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4256 - val_loss: 1.2594 - val_accuracy: 0.4354

Epoch 02035: val_loss did not improve from 1.25759
Epoch 2036/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4202 - val_loss: 1.2668 - val_accuracy: 0.4314

Epoch 02036: val_loss did not improve from 1.25759
Epoch 2037/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4248 - val_loss: 1.2582 - val_accuracy: 0.4322

Epoch 02037: val_loss did not improve from 1.25759
Epoch 2038/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4262 - val_loss: 1.2582 - val_accuracy: 0.4378

Epoch 02038: val_loss did not improve from 1.25759
Epoch 2039/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4240 - val_loss: 1.2570 - val_accuracy: 0.4298

Epoch 02039: val_loss improved from 1.25759 to 1.25702, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2040/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4272 - val_loss: 1.2583 - val_accuracy: 0.4346

Epoch 02040: val_loss did not improve from 1.25702
Epoch 2041/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4249 - val_loss: 1.2576 - val_accuracy: 0.4314

Epoch 02041: val_loss did not improve from 1.25702
Epoch 2042/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4245 - val_loss: 1.2606 - val_accuracy: 0.4306

Epoch 02042: val_loss did not improve from 1.25702
Epoch 2043/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4246 - val_loss: 1.2600 - val_accuracy: 0.4338

Epoch 02043: val_loss did not improve from 1.25702
Epoch 2044/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4241 - val_loss: 1.2596 - val_accuracy: 0.4330

Epoch 02044: val_loss did not improve from 1.25702
Epoch 2045/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4267 - val_loss: 1.2585 - val_accuracy: 0.4354

Epoch 02045: val_loss did not improve from 1.25702
Epoch 2046/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4241 - val_loss: 1.2609 - val_accuracy: 0.4258

Epoch 02046: val_loss did not improve from 1.25702
Epoch 2047/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4269 - val_loss: 1.2618 - val_accuracy: 0.4354

Epoch 02047: val_loss did not improve from 1.25702
Epoch 2048/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4280 - val_loss: 1.2582 - val_accuracy: 0.4282

Epoch 02048: val_loss did not improve from 1.25702
Epoch 2049/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4289 - val_loss: 1.2592 - val_accuracy: 0.4290

Epoch 02049: val_loss did not improve from 1.25702
Epoch 2050/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4278 - val_loss: 1.2594 - val_accuracy: 0.4290

Epoch 02050: val_loss did not improve from 1.25702
Epoch 2051/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4267 - val_loss: 1.2600 - val_accuracy: 0.4226

Epoch 02051: val_loss did not improve from 1.25702
Epoch 2052/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4275 - val_loss: 1.2553 - val_accuracy: 0.4370

Epoch 02052: val_loss improved from 1.25702 to 1.25528, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2053/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4266 - val_loss: 1.2587 - val_accuracy: 0.4322

Epoch 02053: val_loss did not improve from 1.25528
Epoch 2054/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4257 - val_loss: 1.2579 - val_accuracy: 0.4282

Epoch 02054: val_loss did not improve from 1.25528
Epoch 2055/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4260 - val_loss: 1.2568 - val_accuracy: 0.4330

Epoch 02055: val_loss did not improve from 1.25528
Epoch 2056/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4220 - val_loss: 1.2655 - val_accuracy: 0.4314

Epoch 02056: val_loss did not improve from 1.25528
Epoch 2057/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4243 - val_loss: 1.2627 - val_accuracy: 0.4330

Epoch 02057: val_loss did not improve from 1.25528
Epoch 2058/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4254 - val_loss: 1.2600 - val_accuracy: 0.4330

Epoch 02058: val_loss did not improve from 1.25528
Epoch 2059/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4244 - val_loss: 1.2565 - val_accuracy: 0.4282

Epoch 02059: val_loss did not improve from 1.25528
Epoch 2060/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4273 - val_loss: 1.2678 - val_accuracy: 0.4274

Epoch 02060: val_loss did not improve from 1.25528
Epoch 2061/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4293 - val_loss: 1.2606 - val_accuracy: 0.4258

Epoch 02061: val_loss did not improve from 1.25528
Epoch 2062/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4289 - val_loss: 1.2583 - val_accuracy: 0.4234

Epoch 02062: val_loss did not improve from 1.25528
Epoch 2063/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4210 - val_loss: 1.2592 - val_accuracy: 0.4370

Epoch 02063: val_loss did not improve from 1.25528
Epoch 2064/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4239 - val_loss: 1.2601 - val_accuracy: 0.4306

Epoch 02064: val_loss did not improve from 1.25528
Epoch 2065/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4298 - val_loss: 1.2589 - val_accuracy: 0.4378

Epoch 02065: val_loss did not improve from 1.25528
Epoch 2066/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4286 - val_loss: 1.2620 - val_accuracy: 0.4258

Epoch 02066: val_loss did not improve from 1.25528
Epoch 2067/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4312 - val_loss: 1.2586 - val_accuracy: 0.4282

Epoch 02067: val_loss did not improve from 1.25528
Epoch 2068/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4294 - val_loss: 1.2608 - val_accuracy: 0.4290

Epoch 02068: val_loss did not improve from 1.25528
Epoch 2069/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4247 - val_loss: 1.2592 - val_accuracy: 0.4234

Epoch 02069: val_loss did not improve from 1.25528
Epoch 2070/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4245 - val_loss: 1.2568 - val_accuracy: 0.4306

Epoch 02070: val_loss did not improve from 1.25528
Epoch 2071/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4301 - val_loss: 1.2574 - val_accuracy: 0.4362

Epoch 02071: val_loss did not improve from 1.25528
Epoch 2072/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4253 - val_loss: 1.2603 - val_accuracy: 0.4258

Epoch 02072: val_loss did not improve from 1.25528
Epoch 2073/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4252 - val_loss: 1.2579 - val_accuracy: 0.4258

Epoch 02073: val_loss did not improve from 1.25528
Epoch 2074/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4294 - val_loss: 1.2578 - val_accuracy: 0.4330

Epoch 02074: val_loss did not improve from 1.25528
Epoch 2075/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4241 - val_loss: 1.2579 - val_accuracy: 0.4203

Epoch 02075: val_loss did not improve from 1.25528
Epoch 2076/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4273 - val_loss: 1.2628 - val_accuracy: 0.4298

Epoch 02076: val_loss did not improve from 1.25528
Epoch 2077/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4183 - val_loss: 1.2606 - val_accuracy: 0.4211

Epoch 02077: val_loss did not improve from 1.25528
Epoch 2078/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4287 - val_loss: 1.2594 - val_accuracy: 0.4306

Epoch 02078: val_loss did not improve from 1.25528
Epoch 2079/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4308 - val_loss: 1.2600 - val_accuracy: 0.4386

Epoch 02079: val_loss did not improve from 1.25528
Epoch 2080/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4266 - val_loss: 1.2576 - val_accuracy: 0.4290

Epoch 02080: val_loss did not improve from 1.25528
Epoch 2081/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4239 - val_loss: 1.2620 - val_accuracy: 0.4314

Epoch 02081: val_loss did not improve from 1.25528
Epoch 2082/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4280 - val_loss: 1.2602 - val_accuracy: 0.4298

Epoch 02082: val_loss did not improve from 1.25528
Epoch 2083/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4299 - val_loss: 1.2616 - val_accuracy: 0.4378

Epoch 02083: val_loss did not improve from 1.25528
Epoch 2084/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4252 - val_loss: 1.2608 - val_accuracy: 0.4290

Epoch 02084: val_loss did not improve from 1.25528
Epoch 2085/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4284 - val_loss: 1.2645 - val_accuracy: 0.4306

Epoch 02085: val_loss did not improve from 1.25528
Epoch 2086/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4252 - val_loss: 1.2594 - val_accuracy: 0.4370

Epoch 02086: val_loss did not improve from 1.25528
Epoch 2087/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4293 - val_loss: 1.2597 - val_accuracy: 0.4314

Epoch 02087: val_loss did not improve from 1.25528
Epoch 2088/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4292 - val_loss: 1.2585 - val_accuracy: 0.4258

Epoch 02088: val_loss did not improve from 1.25528
Epoch 2089/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4303 - val_loss: 1.2593 - val_accuracy: 0.4250

Epoch 02089: val_loss did not improve from 1.25528
Epoch 2090/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4278 - val_loss: 1.2643 - val_accuracy: 0.4274

Epoch 02090: val_loss did not improve from 1.25528
Epoch 2091/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4315 - val_loss: 1.2583 - val_accuracy: 0.4266

Epoch 02091: val_loss did not improve from 1.25528
Epoch 2092/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4301 - val_loss: 1.2580 - val_accuracy: 0.4290

Epoch 02092: val_loss did not improve from 1.25528
Epoch 2093/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4267 - val_loss: 1.2579 - val_accuracy: 0.4274

Epoch 02093: val_loss did not improve from 1.25528
Epoch 2094/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4287 - val_loss: 1.2636 - val_accuracy: 0.4362

Epoch 02094: val_loss did not improve from 1.25528
Epoch 2095/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4300 - val_loss: 1.2619 - val_accuracy: 0.4346

Epoch 02095: val_loss did not improve from 1.25528
Epoch 2096/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4262 - val_loss: 1.2576 - val_accuracy: 0.4402

Epoch 02096: val_loss did not improve from 1.25528
Epoch 2097/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4309 - val_loss: 1.2568 - val_accuracy: 0.4370

Epoch 02097: val_loss did not improve from 1.25528
Epoch 2098/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4284 - val_loss: 1.2608 - val_accuracy: 0.4290

Epoch 02098: val_loss did not improve from 1.25528
Epoch 2099/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4308 - val_loss: 1.2579 - val_accuracy: 0.4274

Epoch 02099: val_loss did not improve from 1.25528
Epoch 2100/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4312 - val_loss: 1.2554 - val_accuracy: 0.4322

Epoch 02100: val_loss did not improve from 1.25528
Epoch 2101/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4296 - val_loss: 1.2555 - val_accuracy: 0.4282

Epoch 02101: val_loss did not improve from 1.25528
Epoch 2102/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4285 - val_loss: 1.2551 - val_accuracy: 0.4354

Epoch 02102: val_loss improved from 1.25528 to 1.25512, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2103/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4280 - val_loss: 1.2641 - val_accuracy: 0.4274

Epoch 02103: val_loss did not improve from 1.25512
Epoch 2104/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4251 - val_loss: 1.2572 - val_accuracy: 0.4314

Epoch 02104: val_loss did not improve from 1.25512
Epoch 2105/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4308 - val_loss: 1.2555 - val_accuracy: 0.4322

Epoch 02105: val_loss did not improve from 1.25512
Epoch 2106/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4293 - val_loss: 1.2591 - val_accuracy: 0.4434

Epoch 02106: val_loss did not improve from 1.25512
Epoch 2107/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4278 - val_loss: 1.2630 - val_accuracy: 0.4298

Epoch 02107: val_loss did not improve from 1.25512
Epoch 2108/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4317 - val_loss: 1.2586 - val_accuracy: 0.4282

Epoch 02108: val_loss did not improve from 1.25512
Epoch 2109/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4276 - val_loss: 1.2593 - val_accuracy: 0.4266

Epoch 02109: val_loss did not improve from 1.25512
Epoch 2110/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4292 - val_loss: 1.2632 - val_accuracy: 0.4234

Epoch 02110: val_loss did not improve from 1.25512
Epoch 2111/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4275 - val_loss: 1.2573 - val_accuracy: 0.4354

Epoch 02111: val_loss did not improve from 1.25512
Epoch 2112/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4275 - val_loss: 1.2607 - val_accuracy: 0.4322

Epoch 02112: val_loss did not improve from 1.25512
Epoch 2113/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4283 - val_loss: 1.2572 - val_accuracy: 0.4298

Epoch 02113: val_loss did not improve from 1.25512
Epoch 2114/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4326 - val_loss: 1.2582 - val_accuracy: 0.4370

Epoch 02114: val_loss did not improve from 1.25512
Epoch 2115/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4293 - val_loss: 1.2594 - val_accuracy: 0.4330

Epoch 02115: val_loss did not improve from 1.25512
Epoch 2116/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4295 - val_loss: 1.2602 - val_accuracy: 0.4322

Epoch 02116: val_loss did not improve from 1.25512
Epoch 2117/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4307 - val_loss: 1.2603 - val_accuracy: 0.4266

Epoch 02117: val_loss did not improve from 1.25512
Epoch 2118/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4268 - val_loss: 1.2643 - val_accuracy: 0.4354

Epoch 02118: val_loss did not improve from 1.25512
Epoch 2119/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4261 - val_loss: 1.2588 - val_accuracy: 0.4314

Epoch 02119: val_loss did not improve from 1.25512
Epoch 2120/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4242 - val_loss: 1.2604 - val_accuracy: 0.4314

Epoch 02120: val_loss did not improve from 1.25512
Epoch 2121/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4294 - val_loss: 1.2606 - val_accuracy: 0.4330

Epoch 02121: val_loss did not improve from 1.25512
Epoch 2122/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4301 - val_loss: 1.2598 - val_accuracy: 0.4314

Epoch 02122: val_loss did not improve from 1.25512
Epoch 2123/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4300 - val_loss: 1.2604 - val_accuracy: 0.4386

Epoch 02123: val_loss did not improve from 1.25512
Epoch 2124/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4269 - val_loss: 1.2586 - val_accuracy: 0.4410

Epoch 02124: val_loss did not improve from 1.25512
Epoch 2125/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4309 - val_loss: 1.2562 - val_accuracy: 0.4322

Epoch 02125: val_loss did not improve from 1.25512
Epoch 2126/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4268 - val_loss: 1.2609 - val_accuracy: 0.4274

Epoch 02126: val_loss did not improve from 1.25512
Epoch 2127/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4234 - val_loss: 1.2659 - val_accuracy: 0.4298

Epoch 02127: val_loss did not improve from 1.25512
Epoch 2128/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4284 - val_loss: 1.2577 - val_accuracy: 0.4298

Epoch 02128: val_loss did not improve from 1.25512
Epoch 2129/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4297 - val_loss: 1.2595 - val_accuracy: 0.4282

Epoch 02129: val_loss did not improve from 1.25512
Epoch 2130/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4239 - val_loss: 1.2588 - val_accuracy: 0.4346

Epoch 02130: val_loss did not improve from 1.25512
Epoch 2131/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4251 - val_loss: 1.2725 - val_accuracy: 0.4378

Epoch 02131: val_loss did not improve from 1.25512
Epoch 2132/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4264 - val_loss: 1.2616 - val_accuracy: 0.4378

Epoch 02132: val_loss did not improve from 1.25512
Epoch 2133/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4261 - val_loss: 1.2595 - val_accuracy: 0.4306

Epoch 02133: val_loss did not improve from 1.25512
Epoch 2134/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4213 - val_loss: 1.2707 - val_accuracy: 0.4378

Epoch 02134: val_loss did not improve from 1.25512
Epoch 2135/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4273 - val_loss: 1.2564 - val_accuracy: 0.4226

Epoch 02135: val_loss did not improve from 1.25512
Epoch 2136/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4254 - val_loss: 1.2595 - val_accuracy: 0.4354

Epoch 02136: val_loss did not improve from 1.25512
Epoch 2137/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4281 - val_loss: 1.2587 - val_accuracy: 0.4282

Epoch 02137: val_loss did not improve from 1.25512
Epoch 2138/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4313 - val_loss: 1.2578 - val_accuracy: 0.4338

Epoch 02138: val_loss did not improve from 1.25512
Epoch 2139/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4300 - val_loss: 1.2586 - val_accuracy: 0.4242

Epoch 02139: val_loss did not improve from 1.25512
Epoch 2140/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4296 - val_loss: 1.2577 - val_accuracy: 0.4266

Epoch 02140: val_loss did not improve from 1.25512
Epoch 2141/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4285 - val_loss: 1.2592 - val_accuracy: 0.4314

Epoch 02141: val_loss did not improve from 1.25512
Epoch 2142/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4310 - val_loss: 1.2565 - val_accuracy: 0.4282

Epoch 02142: val_loss did not improve from 1.25512
Epoch 2143/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4319 - val_loss: 1.2561 - val_accuracy: 0.4338

Epoch 02143: val_loss did not improve from 1.25512
Epoch 2144/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4268 - val_loss: 1.2588 - val_accuracy: 0.4354

Epoch 02144: val_loss did not improve from 1.25512
Epoch 2145/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4263 - val_loss: 1.2576 - val_accuracy: 0.4322

Epoch 02145: val_loss did not improve from 1.25512
Epoch 2146/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4281 - val_loss: 1.2596 - val_accuracy: 0.4394

Epoch 02146: val_loss did not improve from 1.25512
Epoch 2147/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4279 - val_loss: 1.2625 - val_accuracy: 0.4234

Epoch 02147: val_loss did not improve from 1.25512
Epoch 2148/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4268 - val_loss: 1.2581 - val_accuracy: 0.4282

Epoch 02148: val_loss did not improve from 1.25512
Epoch 2149/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4311 - val_loss: 1.2568 - val_accuracy: 0.4234

Epoch 02149: val_loss did not improve from 1.25512
Epoch 2150/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4259 - val_loss: 1.2598 - val_accuracy: 0.4370

Epoch 02150: val_loss did not improve from 1.25512
Epoch 2151/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4269 - val_loss: 1.2576 - val_accuracy: 0.4250

Epoch 02151: val_loss did not improve from 1.25512
Epoch 2152/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4297 - val_loss: 1.2599 - val_accuracy: 0.4330

Epoch 02152: val_loss did not improve from 1.25512
Epoch 2153/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4297 - val_loss: 1.2569 - val_accuracy: 0.4298

Epoch 02153: val_loss did not improve from 1.25512
Epoch 2154/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4261 - val_loss: 1.2644 - val_accuracy: 0.4298

Epoch 02154: val_loss did not improve from 1.25512
Epoch 2155/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4281 - val_loss: 1.2570 - val_accuracy: 0.4306

Epoch 02155: val_loss did not improve from 1.25512
Epoch 2156/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4292 - val_loss: 1.2612 - val_accuracy: 0.4314

Epoch 02156: val_loss did not improve from 1.25512
Epoch 2157/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4305 - val_loss: 1.2585 - val_accuracy: 0.4330

Epoch 02157: val_loss did not improve from 1.25512
Epoch 2158/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4311 - val_loss: 1.2563 - val_accuracy: 0.4362

Epoch 02158: val_loss did not improve from 1.25512
Epoch 2159/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4286 - val_loss: 1.2562 - val_accuracy: 0.4354

Epoch 02159: val_loss did not improve from 1.25512
Epoch 2160/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4318 - val_loss: 1.2572 - val_accuracy: 0.4274

Epoch 02160: val_loss did not improve from 1.25512
Epoch 2161/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4312 - val_loss: 1.2620 - val_accuracy: 0.4226

Epoch 02161: val_loss did not improve from 1.25512
Epoch 2162/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4279 - val_loss: 1.2591 - val_accuracy: 0.4314

Epoch 02162: val_loss did not improve from 1.25512
Epoch 2163/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4336 - val_loss: 1.2561 - val_accuracy: 0.4330

Epoch 02163: val_loss did not improve from 1.25512
Epoch 2164/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4291 - val_loss: 1.2564 - val_accuracy: 0.4338

Epoch 02164: val_loss did not improve from 1.25512
Epoch 2165/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4280 - val_loss: 1.2563 - val_accuracy: 0.4290

Epoch 02165: val_loss did not improve from 1.25512
Epoch 2166/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4283 - val_loss: 1.2575 - val_accuracy: 0.4426

Epoch 02166: val_loss did not improve from 1.25512
Epoch 2167/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4259 - val_loss: 1.2587 - val_accuracy: 0.4306

Epoch 02167: val_loss did not improve from 1.25512
Epoch 2168/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4272 - val_loss: 1.2596 - val_accuracy: 0.4290

Epoch 02168: val_loss did not improve from 1.25512
Epoch 2169/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4302 - val_loss: 1.2557 - val_accuracy: 0.4306

Epoch 02169: val_loss did not improve from 1.25512
Epoch 2170/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4288 - val_loss: 1.2599 - val_accuracy: 0.4370

Epoch 02170: val_loss did not improve from 1.25512
Epoch 2171/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4305 - val_loss: 1.2577 - val_accuracy: 0.4234

Epoch 02171: val_loss did not improve from 1.25512
Epoch 2172/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4305 - val_loss: 1.2694 - val_accuracy: 0.4322

Epoch 02172: val_loss did not improve from 1.25512
Epoch 2173/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4266 - val_loss: 1.2610 - val_accuracy: 0.4346

Epoch 02173: val_loss did not improve from 1.25512
Epoch 2174/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4286 - val_loss: 1.2576 - val_accuracy: 0.4298

Epoch 02174: val_loss did not improve from 1.25512
Epoch 2175/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4277 - val_loss: 1.2556 - val_accuracy: 0.4274

Epoch 02175: val_loss did not improve from 1.25512
Epoch 2176/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4334 - val_loss: 1.2562 - val_accuracy: 0.4266

Epoch 02176: val_loss did not improve from 1.25512
Epoch 2177/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4288 - val_loss: 1.2605 - val_accuracy: 0.4298

Epoch 02177: val_loss did not improve from 1.25512
Epoch 2178/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4283 - val_loss: 1.2580 - val_accuracy: 0.4258

Epoch 02178: val_loss did not improve from 1.25512
Epoch 2179/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4273 - val_loss: 1.2580 - val_accuracy: 0.4402

Epoch 02179: val_loss did not improve from 1.25512
Epoch 2180/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4303 - val_loss: 1.2591 - val_accuracy: 0.4282

Epoch 02180: val_loss did not improve from 1.25512
Epoch 2181/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4299 - val_loss: 1.2620 - val_accuracy: 0.4195

Epoch 02181: val_loss did not improve from 1.25512
Epoch 2182/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4281 - val_loss: 1.2601 - val_accuracy: 0.4322

Epoch 02182: val_loss did not improve from 1.25512
Epoch 2183/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4246 - val_loss: 1.2573 - val_accuracy: 0.4250

Epoch 02183: val_loss did not improve from 1.25512
Epoch 2184/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4243 - val_loss: 1.2598 - val_accuracy: 0.4362

Epoch 02184: val_loss did not improve from 1.25512
Epoch 2185/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4283 - val_loss: 1.2589 - val_accuracy: 0.4258

Epoch 02185: val_loss did not improve from 1.25512
Epoch 2186/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4286 - val_loss: 1.2576 - val_accuracy: 0.4370

Epoch 02186: val_loss did not improve from 1.25512
Epoch 2187/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4297 - val_loss: 1.2569 - val_accuracy: 0.4266

Epoch 02187: val_loss did not improve from 1.25512
Epoch 2188/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4275 - val_loss: 1.2593 - val_accuracy: 0.4242

Epoch 02188: val_loss did not improve from 1.25512
Epoch 2189/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4315 - val_loss: 1.2556 - val_accuracy: 0.4298

Epoch 02189: val_loss did not improve from 1.25512
Epoch 2190/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4295 - val_loss: 1.2562 - val_accuracy: 0.4330

Epoch 02190: val_loss did not improve from 1.25512
Epoch 2191/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4314 - val_loss: 1.2577 - val_accuracy: 0.4378

Epoch 02191: val_loss did not improve from 1.25512
Epoch 2192/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4312 - val_loss: 1.2575 - val_accuracy: 0.4330

Epoch 02192: val_loss did not improve from 1.25512
Epoch 2193/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4284 - val_loss: 1.2565 - val_accuracy: 0.4410

Epoch 02193: val_loss did not improve from 1.25512
Epoch 2194/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4279 - val_loss: 1.2598 - val_accuracy: 0.4290

Epoch 02194: val_loss did not improve from 1.25512
Epoch 2195/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4268 - val_loss: 1.2611 - val_accuracy: 0.4362

Epoch 02195: val_loss did not improve from 1.25512
Epoch 2196/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4301 - val_loss: 1.2582 - val_accuracy: 0.4378

Epoch 02196: val_loss did not improve from 1.25512
Epoch 2197/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4273 - val_loss: 1.2582 - val_accuracy: 0.4362

Epoch 02197: val_loss did not improve from 1.25512
Epoch 2198/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4261 - val_loss: 1.2686 - val_accuracy: 0.4211

Epoch 02198: val_loss did not improve from 1.25512
Epoch 2199/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4286 - val_loss: 1.2565 - val_accuracy: 0.4386

Epoch 02199: val_loss did not improve from 1.25512
Epoch 2200/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4299 - val_loss: 1.2550 - val_accuracy: 0.4290

Epoch 02200: val_loss improved from 1.25512 to 1.25501, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2201/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4307 - val_loss: 1.2552 - val_accuracy: 0.4330

Epoch 02201: val_loss did not improve from 1.25501
Epoch 2202/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4308 - val_loss: 1.2572 - val_accuracy: 0.4298

Epoch 02202: val_loss did not improve from 1.25501
Epoch 2203/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4301 - val_loss: 1.2548 - val_accuracy: 0.4370

Epoch 02203: val_loss improved from 1.25501 to 1.25485, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2204/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4321 - val_loss: 1.2576 - val_accuracy: 0.4282

Epoch 02204: val_loss did not improve from 1.25485
Epoch 2205/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4284 - val_loss: 1.2573 - val_accuracy: 0.4370

Epoch 02205: val_loss did not improve from 1.25485
Epoch 2206/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4264 - val_loss: 1.2603 - val_accuracy: 0.4266

Epoch 02206: val_loss did not improve from 1.25485
Epoch 2207/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4291 - val_loss: 1.2555 - val_accuracy: 0.4306

Epoch 02207: val_loss did not improve from 1.25485
Epoch 2208/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4298 - val_loss: 1.2573 - val_accuracy: 0.4266

Epoch 02208: val_loss did not improve from 1.25485
Epoch 2209/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4286 - val_loss: 1.2606 - val_accuracy: 0.4226

Epoch 02209: val_loss did not improve from 1.25485
Epoch 2210/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4280 - val_loss: 1.2580 - val_accuracy: 0.4211

Epoch 02210: val_loss did not improve from 1.25485
Epoch 2211/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4320 - val_loss: 1.2589 - val_accuracy: 0.4234

Epoch 02211: val_loss did not improve from 1.25485
Epoch 2212/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4289 - val_loss: 1.2553 - val_accuracy: 0.4346

Epoch 02212: val_loss did not improve from 1.25485
Epoch 2213/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4299 - val_loss: 1.2537 - val_accuracy: 0.4282

Epoch 02213: val_loss improved from 1.25485 to 1.25369, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2214/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4311 - val_loss: 1.2560 - val_accuracy: 0.4226

Epoch 02214: val_loss did not improve from 1.25369
Epoch 2215/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4308 - val_loss: 1.2606 - val_accuracy: 0.4338

Epoch 02215: val_loss did not improve from 1.25369
Epoch 2216/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4299 - val_loss: 1.2576 - val_accuracy: 0.4250

Epoch 02216: val_loss did not improve from 1.25369
Epoch 2217/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4318 - val_loss: 1.2584 - val_accuracy: 0.4362

Epoch 02217: val_loss did not improve from 1.25369
Epoch 2218/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4296 - val_loss: 1.2581 - val_accuracy: 0.4314

Epoch 02218: val_loss did not improve from 1.25369
Epoch 2219/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4301 - val_loss: 1.2614 - val_accuracy: 0.4322

Epoch 02219: val_loss did not improve from 1.25369
Epoch 2220/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4287 - val_loss: 1.2567 - val_accuracy: 0.4354

Epoch 02220: val_loss did not improve from 1.25369
Epoch 2221/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4299 - val_loss: 1.2576 - val_accuracy: 0.4306

Epoch 02221: val_loss did not improve from 1.25369
Epoch 2222/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4319 - val_loss: 1.2562 - val_accuracy: 0.4314

Epoch 02222: val_loss did not improve from 1.25369
Epoch 2223/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4318 - val_loss: 1.2552 - val_accuracy: 0.4354

Epoch 02223: val_loss did not improve from 1.25369
Epoch 2224/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4295 - val_loss: 1.2554 - val_accuracy: 0.4354

Epoch 02224: val_loss did not improve from 1.25369
Epoch 2225/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4295 - val_loss: 1.2586 - val_accuracy: 0.4346

Epoch 02225: val_loss did not improve from 1.25369
Epoch 2226/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4311 - val_loss: 1.2593 - val_accuracy: 0.4282

Epoch 02226: val_loss did not improve from 1.25369
Epoch 2227/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4246 - val_loss: 1.2562 - val_accuracy: 0.4370

Epoch 02227: val_loss did not improve from 1.25369
Epoch 2228/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4280 - val_loss: 1.2581 - val_accuracy: 0.4290

Epoch 02228: val_loss did not improve from 1.25369
Epoch 2229/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4252 - val_loss: 1.2602 - val_accuracy: 0.4362

Epoch 02229: val_loss did not improve from 1.25369
Epoch 2230/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4283 - val_loss: 1.2598 - val_accuracy: 0.4306

Epoch 02230: val_loss did not improve from 1.25369
Epoch 2231/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4326 - val_loss: 1.2582 - val_accuracy: 0.4418

Epoch 02231: val_loss did not improve from 1.25369
Epoch 2232/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4270 - val_loss: 1.2580 - val_accuracy: 0.4362

Epoch 02232: val_loss did not improve from 1.25369
Epoch 2233/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4295 - val_loss: 1.2667 - val_accuracy: 0.4179

Epoch 02233: val_loss did not improve from 1.25369
Epoch 2234/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4299 - val_loss: 1.2570 - val_accuracy: 0.4250

Epoch 02234: val_loss did not improve from 1.25369
Epoch 2235/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4293 - val_loss: 1.2581 - val_accuracy: 0.4354

Epoch 02235: val_loss did not improve from 1.25369
Epoch 2236/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4270 - val_loss: 1.2580 - val_accuracy: 0.4322

Epoch 02236: val_loss did not improve from 1.25369
Epoch 2237/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4316 - val_loss: 1.2544 - val_accuracy: 0.4306

Epoch 02237: val_loss did not improve from 1.25369
Epoch 2238/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4315 - val_loss: 1.2555 - val_accuracy: 0.4306

Epoch 02238: val_loss did not improve from 1.25369
Epoch 2239/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4320 - val_loss: 1.2625 - val_accuracy: 0.4298

Epoch 02239: val_loss did not improve from 1.25369
Epoch 2240/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4314 - val_loss: 1.2538 - val_accuracy: 0.4330

Epoch 02240: val_loss did not improve from 1.25369
Epoch 2241/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4298 - val_loss: 1.2553 - val_accuracy: 0.4258

Epoch 02241: val_loss did not improve from 1.25369
Epoch 2242/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4295 - val_loss: 1.2553 - val_accuracy: 0.4258

Epoch 02242: val_loss did not improve from 1.25369
Epoch 2243/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4324 - val_loss: 1.2573 - val_accuracy: 0.4442

Epoch 02243: val_loss did not improve from 1.25369
Epoch 2244/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4304 - val_loss: 1.2568 - val_accuracy: 0.4290

Epoch 02244: val_loss did not improve from 1.25369
Epoch 2245/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4298 - val_loss: 1.2680 - val_accuracy: 0.4322

Epoch 02245: val_loss did not improve from 1.25369
Epoch 2246/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4241 - val_loss: 1.2550 - val_accuracy: 0.4282

Epoch 02246: val_loss did not improve from 1.25369
Epoch 2247/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4313 - val_loss: 1.2564 - val_accuracy: 0.4338

Epoch 02247: val_loss did not improve from 1.25369
Epoch 2248/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4267 - val_loss: 1.2554 - val_accuracy: 0.4330

Epoch 02248: val_loss did not improve from 1.25369
Epoch 2249/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4279 - val_loss: 1.2634 - val_accuracy: 0.4242

Epoch 02249: val_loss did not improve from 1.25369
Epoch 2250/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4282 - val_loss: 1.2548 - val_accuracy: 0.4362

Epoch 02250: val_loss did not improve from 1.25369
Epoch 2251/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4313 - val_loss: 1.2596 - val_accuracy: 0.4330

Epoch 02251: val_loss did not improve from 1.25369
Epoch 2252/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4253 - val_loss: 1.2574 - val_accuracy: 0.4234

Epoch 02252: val_loss did not improve from 1.25369
Epoch 2253/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4327 - val_loss: 1.2552 - val_accuracy: 0.4322

Epoch 02253: val_loss did not improve from 1.25369
Epoch 2254/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4317 - val_loss: 1.2537 - val_accuracy: 0.4306

Epoch 02254: val_loss improved from 1.25369 to 1.25367, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2255/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4306 - val_loss: 1.2569 - val_accuracy: 0.4370

Epoch 02255: val_loss did not improve from 1.25367
Epoch 2256/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4292 - val_loss: 1.2559 - val_accuracy: 0.4282

Epoch 02256: val_loss did not improve from 1.25367
Epoch 2257/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4311 - val_loss: 1.2573 - val_accuracy: 0.4338

Epoch 02257: val_loss did not improve from 1.25367
Epoch 2258/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4341 - val_loss: 1.2556 - val_accuracy: 0.4274

Epoch 02258: val_loss did not improve from 1.25367
Epoch 2259/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4332 - val_loss: 1.2569 - val_accuracy: 0.4338

Epoch 02259: val_loss did not improve from 1.25367
Epoch 2260/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4299 - val_loss: 1.2603 - val_accuracy: 0.4226

Epoch 02260: val_loss did not improve from 1.25367
Epoch 2261/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4295 - val_loss: 1.2561 - val_accuracy: 0.4250

Epoch 02261: val_loss did not improve from 1.25367
Epoch 2262/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4334 - val_loss: 1.2554 - val_accuracy: 0.4314

Epoch 02262: val_loss did not improve from 1.25367
Epoch 2263/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4284 - val_loss: 1.2577 - val_accuracy: 0.4346

Epoch 02263: val_loss did not improve from 1.25367
Epoch 2264/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4322 - val_loss: 1.2535 - val_accuracy: 0.4306

Epoch 02264: val_loss improved from 1.25367 to 1.25354, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2265/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4303 - val_loss: 1.2553 - val_accuracy: 0.4314

Epoch 02265: val_loss did not improve from 1.25354
Epoch 2266/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4338 - val_loss: 1.2603 - val_accuracy: 0.4362

Epoch 02266: val_loss did not improve from 1.25354
Epoch 2267/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4264 - val_loss: 1.2581 - val_accuracy: 0.4242

Epoch 02267: val_loss did not improve from 1.25354
Epoch 2268/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4311 - val_loss: 1.2567 - val_accuracy: 0.4298

Epoch 02268: val_loss did not improve from 1.25354
Epoch 2269/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4271 - val_loss: 1.2546 - val_accuracy: 0.4266

Epoch 02269: val_loss did not improve from 1.25354
Epoch 2270/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4298 - val_loss: 1.2566 - val_accuracy: 0.4226

Epoch 02270: val_loss did not improve from 1.25354
Epoch 2271/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4337 - val_loss: 1.2551 - val_accuracy: 0.4426

Epoch 02271: val_loss did not improve from 1.25354
Epoch 2272/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4289 - val_loss: 1.2552 - val_accuracy: 0.4226

Epoch 02272: val_loss did not improve from 1.25354
Epoch 2273/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4310 - val_loss: 1.2641 - val_accuracy: 0.4250

Epoch 02273: val_loss did not improve from 1.25354
Epoch 2274/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4304 - val_loss: 1.2579 - val_accuracy: 0.4362

Epoch 02274: val_loss did not improve from 1.25354
Epoch 2275/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4309 - val_loss: 1.2588 - val_accuracy: 0.4322

Epoch 02275: val_loss did not improve from 1.25354
Epoch 2276/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4284 - val_loss: 1.2562 - val_accuracy: 0.4338

Epoch 02276: val_loss did not improve from 1.25354
Epoch 2277/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4295 - val_loss: 1.2603 - val_accuracy: 0.4378

Epoch 02277: val_loss did not improve from 1.25354
Epoch 2278/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4257 - val_loss: 1.2582 - val_accuracy: 0.4338

Epoch 02278: val_loss did not improve from 1.25354
Epoch 2279/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4279 - val_loss: 1.2572 - val_accuracy: 0.4378

Epoch 02279: val_loss did not improve from 1.25354
Epoch 2280/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4265 - val_loss: 1.2658 - val_accuracy: 0.4338

Epoch 02280: val_loss did not improve from 1.25354
Epoch 2281/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4249 - val_loss: 1.2553 - val_accuracy: 0.4266

Epoch 02281: val_loss did not improve from 1.25354
Epoch 2282/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4290 - val_loss: 1.2564 - val_accuracy: 0.4330

Epoch 02282: val_loss did not improve from 1.25354
Epoch 2283/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4294 - val_loss: 1.2622 - val_accuracy: 0.4234

Epoch 02283: val_loss did not improve from 1.25354
Epoch 2284/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4265 - val_loss: 1.2606 - val_accuracy: 0.4219

Epoch 02284: val_loss did not improve from 1.25354
Epoch 2285/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4287 - val_loss: 1.2589 - val_accuracy: 0.4298

Epoch 02285: val_loss did not improve from 1.25354
Epoch 2286/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4307 - val_loss: 1.2591 - val_accuracy: 0.4338

Epoch 02286: val_loss did not improve from 1.25354
Epoch 2287/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4295 - val_loss: 1.2580 - val_accuracy: 0.4330

Epoch 02287: val_loss did not improve from 1.25354
Epoch 2288/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4276 - val_loss: 1.2570 - val_accuracy: 0.4290

Epoch 02288: val_loss did not improve from 1.25354
Epoch 2289/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4288 - val_loss: 1.2579 - val_accuracy: 0.4346

Epoch 02289: val_loss did not improve from 1.25354
Epoch 2290/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4323 - val_loss: 1.2578 - val_accuracy: 0.4402

Epoch 02290: val_loss did not improve from 1.25354
Epoch 2291/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4274 - val_loss: 1.2603 - val_accuracy: 0.4314

Epoch 02291: val_loss did not improve from 1.25354
Epoch 2292/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4318 - val_loss: 1.2573 - val_accuracy: 0.4402

Epoch 02292: val_loss did not improve from 1.25354
Epoch 2293/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4303 - val_loss: 1.2576 - val_accuracy: 0.4282

Epoch 02293: val_loss did not improve from 1.25354
Epoch 2294/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4285 - val_loss: 1.2590 - val_accuracy: 0.4378

Epoch 02294: val_loss did not improve from 1.25354
Epoch 2295/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4321 - val_loss: 1.2594 - val_accuracy: 0.4442

Epoch 02295: val_loss did not improve from 1.25354
Epoch 2296/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4275 - val_loss: 1.2617 - val_accuracy: 0.4282

Epoch 02296: val_loss did not improve from 1.25354
Epoch 2297/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4314 - val_loss: 1.2562 - val_accuracy: 0.4346

Epoch 02297: val_loss did not improve from 1.25354
Epoch 2298/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4270 - val_loss: 1.2580 - val_accuracy: 0.4314

Epoch 02298: val_loss did not improve from 1.25354
Epoch 2299/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4307 - val_loss: 1.2584 - val_accuracy: 0.4322

Epoch 02299: val_loss did not improve from 1.25354
Epoch 2300/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4303 - val_loss: 1.2607 - val_accuracy: 0.4274

Epoch 02300: val_loss did not improve from 1.25354
Epoch 2301/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4277 - val_loss: 1.2570 - val_accuracy: 0.4330

Epoch 02301: val_loss did not improve from 1.25354
Epoch 2302/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4241 - val_loss: 1.2564 - val_accuracy: 0.4282

Epoch 02302: val_loss did not improve from 1.25354
Epoch 2303/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4339 - val_loss: 1.2592 - val_accuracy: 0.4282

Epoch 02303: val_loss did not improve from 1.25354
Epoch 2304/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4306 - val_loss: 1.2564 - val_accuracy: 0.4322

Epoch 02304: val_loss did not improve from 1.25354
Epoch 2305/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4308 - val_loss: 1.2549 - val_accuracy: 0.4338

Epoch 02305: val_loss did not improve from 1.25354
Epoch 2306/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4298 - val_loss: 1.2572 - val_accuracy: 0.4314

Epoch 02306: val_loss did not improve from 1.25354
Epoch 2307/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4292 - val_loss: 1.2604 - val_accuracy: 0.4242

Epoch 02307: val_loss did not improve from 1.25354
Epoch 2308/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4311 - val_loss: 1.2600 - val_accuracy: 0.4250

Epoch 02308: val_loss did not improve from 1.25354
Epoch 2309/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4314 - val_loss: 1.2595 - val_accuracy: 0.4330

Epoch 02309: val_loss did not improve from 1.25354
Epoch 2310/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4320 - val_loss: 1.2572 - val_accuracy: 0.4362

Epoch 02310: val_loss did not improve from 1.25354
Epoch 2311/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4321 - val_loss: 1.2627 - val_accuracy: 0.4282

Epoch 02311: val_loss did not improve from 1.25354
Epoch 2312/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4272 - val_loss: 1.2601 - val_accuracy: 0.4282

Epoch 02312: val_loss did not improve from 1.25354
Epoch 2313/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4313 - val_loss: 1.2567 - val_accuracy: 0.4378

Epoch 02313: val_loss did not improve from 1.25354
Epoch 2314/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4305 - val_loss: 1.2577 - val_accuracy: 0.4314

Epoch 02314: val_loss did not improve from 1.25354
Epoch 2315/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4285 - val_loss: 1.2579 - val_accuracy: 0.4274

Epoch 02315: val_loss did not improve from 1.25354
Epoch 2316/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4335 - val_loss: 1.2569 - val_accuracy: 0.4370

Epoch 02316: val_loss did not improve from 1.25354
Epoch 2317/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4294 - val_loss: 1.2577 - val_accuracy: 0.4290

Epoch 02317: val_loss did not improve from 1.25354
Epoch 2318/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4336 - val_loss: 1.2547 - val_accuracy: 0.4314

Epoch 02318: val_loss did not improve from 1.25354
Epoch 2319/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4247 - val_loss: 1.2684 - val_accuracy: 0.4322

Epoch 02319: val_loss did not improve from 1.25354
Epoch 2320/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4283 - val_loss: 1.2586 - val_accuracy: 0.4330

Epoch 02320: val_loss did not improve from 1.25354
Epoch 2321/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4273 - val_loss: 1.2607 - val_accuracy: 0.4250

Epoch 02321: val_loss did not improve from 1.25354
Epoch 2322/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4296 - val_loss: 1.2649 - val_accuracy: 0.4306

Epoch 02322: val_loss did not improve from 1.25354
Epoch 2323/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4285 - val_loss: 1.2576 - val_accuracy: 0.4314

Epoch 02323: val_loss did not improve from 1.25354
Epoch 2324/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4364 - val_loss: 1.2556 - val_accuracy: 0.4346

Epoch 02324: val_loss did not improve from 1.25354
Epoch 2325/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4309 - val_loss: 1.2609 - val_accuracy: 0.4394

Epoch 02325: val_loss did not improve from 1.25354
Epoch 2326/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4280 - val_loss: 1.2605 - val_accuracy: 0.4322

Epoch 02326: val_loss did not improve from 1.25354
Epoch 2327/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4329 - val_loss: 1.2597 - val_accuracy: 0.4354

Epoch 02327: val_loss did not improve from 1.25354
Epoch 2328/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4313 - val_loss: 1.2596 - val_accuracy: 0.4378

Epoch 02328: val_loss did not improve from 1.25354
Epoch 2329/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4355 - val_loss: 1.2582 - val_accuracy: 0.4290

Epoch 02329: val_loss did not improve from 1.25354
Epoch 2330/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4283 - val_loss: 1.2643 - val_accuracy: 0.4203

Epoch 02330: val_loss did not improve from 1.25354
Epoch 2331/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4315 - val_loss: 1.2561 - val_accuracy: 0.4386

Epoch 02331: val_loss did not improve from 1.25354
Epoch 2332/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4274 - val_loss: 1.2566 - val_accuracy: 0.4290

Epoch 02332: val_loss did not improve from 1.25354
Epoch 2333/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4265 - val_loss: 1.2582 - val_accuracy: 0.4314

Epoch 02333: val_loss did not improve from 1.25354
Epoch 2334/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4281 - val_loss: 1.2602 - val_accuracy: 0.4290

Epoch 02334: val_loss did not improve from 1.25354
Epoch 2335/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4329 - val_loss: 1.2600 - val_accuracy: 0.4298

Epoch 02335: val_loss did not improve from 1.25354
Epoch 2336/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4306 - val_loss: 1.2643 - val_accuracy: 0.4306

Epoch 02336: val_loss did not improve from 1.25354
Epoch 2337/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4301 - val_loss: 1.2593 - val_accuracy: 0.4362

Epoch 02337: val_loss did not improve from 1.25354
Epoch 2338/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4295 - val_loss: 1.2575 - val_accuracy: 0.4306

Epoch 02338: val_loss did not improve from 1.25354
Epoch 2339/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4311 - val_loss: 1.2661 - val_accuracy: 0.4203

Epoch 02339: val_loss did not improve from 1.25354
Epoch 2340/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4280 - val_loss: 1.2596 - val_accuracy: 0.4370

Epoch 02340: val_loss did not improve from 1.25354
Epoch 2341/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4319 - val_loss: 1.2585 - val_accuracy: 0.4346

Epoch 02341: val_loss did not improve from 1.25354
Epoch 2342/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4287 - val_loss: 1.2569 - val_accuracy: 0.4266

Epoch 02342: val_loss did not improve from 1.25354
Epoch 2343/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4333 - val_loss: 1.2573 - val_accuracy: 0.4370

Epoch 02343: val_loss did not improve from 1.25354
Epoch 2344/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4278 - val_loss: 1.2567 - val_accuracy: 0.4274

Epoch 02344: val_loss did not improve from 1.25354
Epoch 2345/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4279 - val_loss: 1.2673 - val_accuracy: 0.4306

Epoch 02345: val_loss did not improve from 1.25354
Epoch 2346/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4299 - val_loss: 1.2611 - val_accuracy: 0.4362

Epoch 02346: val_loss did not improve from 1.25354
Epoch 2347/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4256 - val_loss: 1.2584 - val_accuracy: 0.4306

Epoch 02347: val_loss did not improve from 1.25354
Epoch 2348/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4271 - val_loss: 1.2569 - val_accuracy: 0.4354

Epoch 02348: val_loss did not improve from 1.25354
Epoch 2349/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4280 - val_loss: 1.2591 - val_accuracy: 0.4211

Epoch 02349: val_loss did not improve from 1.25354
Epoch 2350/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4303 - val_loss: 1.2576 - val_accuracy: 0.4314

Epoch 02350: val_loss did not improve from 1.25354
Epoch 2351/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4344 - val_loss: 1.2558 - val_accuracy: 0.4394

Epoch 02351: val_loss did not improve from 1.25354
Epoch 2352/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4275 - val_loss: 1.2588 - val_accuracy: 0.4258

Epoch 02352: val_loss did not improve from 1.25354
Epoch 2353/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4304 - val_loss: 1.2585 - val_accuracy: 0.4306

Epoch 02353: val_loss did not improve from 1.25354
Epoch 2354/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4309 - val_loss: 1.2567 - val_accuracy: 0.4402

Epoch 02354: val_loss did not improve from 1.25354
Epoch 2355/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4328 - val_loss: 1.2560 - val_accuracy: 0.4290

Epoch 02355: val_loss did not improve from 1.25354
Epoch 2356/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4314 - val_loss: 1.2559 - val_accuracy: 0.4338

Epoch 02356: val_loss did not improve from 1.25354
Epoch 2357/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4285 - val_loss: 1.2575 - val_accuracy: 0.4298

Epoch 02357: val_loss did not improve from 1.25354
Epoch 2358/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4309 - val_loss: 1.2563 - val_accuracy: 0.4234

Epoch 02358: val_loss did not improve from 1.25354
Epoch 2359/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4318 - val_loss: 1.2562 - val_accuracy: 0.4306

Epoch 02359: val_loss did not improve from 1.25354
Epoch 2360/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4349 - val_loss: 1.2638 - val_accuracy: 0.4226

Epoch 02360: val_loss did not improve from 1.25354
Epoch 2361/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4304 - val_loss: 1.2573 - val_accuracy: 0.4418

Epoch 02361: val_loss did not improve from 1.25354
Epoch 2362/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4319 - val_loss: 1.2596 - val_accuracy: 0.4298

Epoch 02362: val_loss did not improve from 1.25354
Epoch 2363/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4300 - val_loss: 1.2565 - val_accuracy: 0.4290

Epoch 02363: val_loss did not improve from 1.25354
Epoch 2364/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4316 - val_loss: 1.2578 - val_accuracy: 0.4362

Epoch 02364: val_loss did not improve from 1.25354
Epoch 2365/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4315 - val_loss: 1.2575 - val_accuracy: 0.4330

Epoch 02365: val_loss did not improve from 1.25354
Epoch 2366/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4308 - val_loss: 1.2563 - val_accuracy: 0.4330

Epoch 02366: val_loss did not improve from 1.25354
Epoch 2367/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4290 - val_loss: 1.2585 - val_accuracy: 0.4298

Epoch 02367: val_loss did not improve from 1.25354
Epoch 2368/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4311 - val_loss: 1.2601 - val_accuracy: 0.4306

Epoch 02368: val_loss did not improve from 1.25354
Epoch 2369/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4299 - val_loss: 1.2590 - val_accuracy: 0.4314

Epoch 02369: val_loss did not improve from 1.25354
Epoch 2370/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4321 - val_loss: 1.2572 - val_accuracy: 0.4354

Epoch 02370: val_loss did not improve from 1.25354
Epoch 2371/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4319 - val_loss: 1.2610 - val_accuracy: 0.4250

Epoch 02371: val_loss did not improve from 1.25354
Epoch 2372/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4317 - val_loss: 1.2557 - val_accuracy: 0.4362

Epoch 02372: val_loss did not improve from 1.25354
Epoch 2373/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4298 - val_loss: 1.2591 - val_accuracy: 0.4354

Epoch 02373: val_loss did not improve from 1.25354
Epoch 2374/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4321 - val_loss: 1.2585 - val_accuracy: 0.4314

Epoch 02374: val_loss did not improve from 1.25354
Epoch 2375/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4302 - val_loss: 1.2566 - val_accuracy: 0.4298

Epoch 02375: val_loss did not improve from 1.25354
Epoch 2376/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4282 - val_loss: 1.2567 - val_accuracy: 0.4378

Epoch 02376: val_loss did not improve from 1.25354
Epoch 2377/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4299 - val_loss: 1.2634 - val_accuracy: 0.4250

Epoch 02377: val_loss did not improve from 1.25354
Epoch 2378/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4311 - val_loss: 1.2592 - val_accuracy: 0.4426

Epoch 02378: val_loss did not improve from 1.25354
Epoch 2379/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4300 - val_loss: 1.2620 - val_accuracy: 0.4282

Epoch 02379: val_loss did not improve from 1.25354
Epoch 2380/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4273 - val_loss: 1.2575 - val_accuracy: 0.4354

Epoch 02380: val_loss did not improve from 1.25354
Epoch 2381/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4297 - val_loss: 1.2591 - val_accuracy: 0.4306

Epoch 02381: val_loss did not improve from 1.25354
Epoch 2382/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4288 - val_loss: 1.2608 - val_accuracy: 0.4314

Epoch 02382: val_loss did not improve from 1.25354
Epoch 2383/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4301 - val_loss: 1.2620 - val_accuracy: 0.4386

Epoch 02383: val_loss did not improve from 1.25354
Epoch 2384/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4284 - val_loss: 1.2607 - val_accuracy: 0.4290

Epoch 02384: val_loss did not improve from 1.25354
Epoch 2385/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4315 - val_loss: 1.2562 - val_accuracy: 0.4362

Epoch 02385: val_loss did not improve from 1.25354
Epoch 2386/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4273 - val_loss: 1.2603 - val_accuracy: 0.4330

Epoch 02386: val_loss did not improve from 1.25354
Epoch 2387/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4359 - val_loss: 1.2590 - val_accuracy: 0.4338

Epoch 02387: val_loss did not improve from 1.25354
Epoch 2388/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4273 - val_loss: 1.2602 - val_accuracy: 0.4362

Epoch 02388: val_loss did not improve from 1.25354
Epoch 2389/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4287 - val_loss: 1.2631 - val_accuracy: 0.4314

Epoch 02389: val_loss did not improve from 1.25354
Epoch 2390/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4291 - val_loss: 1.2552 - val_accuracy: 0.4282

Epoch 02390: val_loss did not improve from 1.25354
Epoch 2391/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4282 - val_loss: 1.2574 - val_accuracy: 0.4306

Epoch 02391: val_loss did not improve from 1.25354
Epoch 2392/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4295 - val_loss: 1.2591 - val_accuracy: 0.4298

Epoch 02392: val_loss did not improve from 1.25354
Epoch 2393/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4299 - val_loss: 1.2582 - val_accuracy: 0.4362

Epoch 02393: val_loss did not improve from 1.25354
Epoch 2394/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4296 - val_loss: 1.2597 - val_accuracy: 0.4322

Epoch 02394: val_loss did not improve from 1.25354
Epoch 2395/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4316 - val_loss: 1.2584 - val_accuracy: 0.4298

Epoch 02395: val_loss did not improve from 1.25354
Epoch 2396/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4283 - val_loss: 1.2575 - val_accuracy: 0.4266

Epoch 02396: val_loss did not improve from 1.25354
Epoch 2397/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4319 - val_loss: 1.2592 - val_accuracy: 0.4258

Epoch 02397: val_loss did not improve from 1.25354
Epoch 2398/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4295 - val_loss: 1.2578 - val_accuracy: 0.4346

Epoch 02398: val_loss did not improve from 1.25354
Epoch 2399/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4295 - val_loss: 1.2552 - val_accuracy: 0.4322

Epoch 02399: val_loss did not improve from 1.25354
Epoch 2400/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4344 - val_loss: 1.2599 - val_accuracy: 0.4354

Epoch 02400: val_loss did not improve from 1.25354
Epoch 2401/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4321 - val_loss: 1.2581 - val_accuracy: 0.4290

Epoch 02401: val_loss did not improve from 1.25354
Epoch 2402/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4300 - val_loss: 1.2598 - val_accuracy: 0.4330

Epoch 02402: val_loss did not improve from 1.25354
Epoch 2403/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4291 - val_loss: 1.2607 - val_accuracy: 0.4442

Epoch 02403: val_loss did not improve from 1.25354
Epoch 2404/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4288 - val_loss: 1.2648 - val_accuracy: 0.4338

Epoch 02404: val_loss did not improve from 1.25354
Epoch 2405/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4313 - val_loss: 1.2561 - val_accuracy: 0.4426

Epoch 02405: val_loss did not improve from 1.25354
Epoch 2406/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4304 - val_loss: 1.2545 - val_accuracy: 0.4394

Epoch 02406: val_loss did not improve from 1.25354
Epoch 2407/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4319 - val_loss: 1.2561 - val_accuracy: 0.4274

Epoch 02407: val_loss did not improve from 1.25354
Epoch 2408/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4316 - val_loss: 1.2624 - val_accuracy: 0.4266

Epoch 02408: val_loss did not improve from 1.25354
Epoch 2409/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4291 - val_loss: 1.2585 - val_accuracy: 0.4274

Epoch 02409: val_loss did not improve from 1.25354
Epoch 2410/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4283 - val_loss: 1.2595 - val_accuracy: 0.4226

Epoch 02410: val_loss did not improve from 1.25354
Epoch 2411/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4317 - val_loss: 1.2573 - val_accuracy: 0.4314

Epoch 02411: val_loss did not improve from 1.25354
Epoch 2412/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4300 - val_loss: 1.2577 - val_accuracy: 0.4234

Epoch 02412: val_loss did not improve from 1.25354
Epoch 2413/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4281 - val_loss: 1.2590 - val_accuracy: 0.4378

Epoch 02413: val_loss did not improve from 1.25354
Epoch 2414/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4319 - val_loss: 1.2616 - val_accuracy: 0.4338

Epoch 02414: val_loss did not improve from 1.25354
Epoch 2415/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4282 - val_loss: 1.2583 - val_accuracy: 0.4338

Epoch 02415: val_loss did not improve from 1.25354
Epoch 2416/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4307 - val_loss: 1.2549 - val_accuracy: 0.4394

Epoch 02416: val_loss did not improve from 1.25354
Epoch 2417/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4295 - val_loss: 1.2559 - val_accuracy: 0.4330

Epoch 02417: val_loss did not improve from 1.25354
Epoch 2418/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4336 - val_loss: 1.2572 - val_accuracy: 0.4434

Epoch 02418: val_loss did not improve from 1.25354
Epoch 2419/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4241 - val_loss: 1.2574 - val_accuracy: 0.4266

Epoch 02419: val_loss did not improve from 1.25354
Epoch 2420/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4321 - val_loss: 1.2588 - val_accuracy: 0.4298

Epoch 02420: val_loss did not improve from 1.25354
Epoch 2421/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4340 - val_loss: 1.2569 - val_accuracy: 0.4338

Epoch 02421: val_loss did not improve from 1.25354
Epoch 2422/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4303 - val_loss: 1.2566 - val_accuracy: 0.4354

Epoch 02422: val_loss did not improve from 1.25354
Epoch 2423/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4311 - val_loss: 1.2577 - val_accuracy: 0.4187

Epoch 02423: val_loss did not improve from 1.25354
Epoch 2424/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4319 - val_loss: 1.2551 - val_accuracy: 0.4274

Epoch 02424: val_loss did not improve from 1.25354
Epoch 2425/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4354 - val_loss: 1.2543 - val_accuracy: 0.4242

Epoch 02425: val_loss did not improve from 1.25354
Epoch 2426/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4324 - val_loss: 1.2570 - val_accuracy: 0.4394

Epoch 02426: val_loss did not improve from 1.25354
Epoch 2427/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4311 - val_loss: 1.2579 - val_accuracy: 0.4314

Epoch 02427: val_loss did not improve from 1.25354
Epoch 2428/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4366 - val_loss: 1.2591 - val_accuracy: 0.4322

Epoch 02428: val_loss did not improve from 1.25354
Epoch 2429/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4288 - val_loss: 1.2593 - val_accuracy: 0.4290

Epoch 02429: val_loss did not improve from 1.25354
Epoch 2430/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4303 - val_loss: 1.2581 - val_accuracy: 0.4362

Epoch 02430: val_loss did not improve from 1.25354
Epoch 2431/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4316 - val_loss: 1.2568 - val_accuracy: 0.4298

Epoch 02431: val_loss did not improve from 1.25354
Epoch 2432/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4329 - val_loss: 1.2557 - val_accuracy: 0.4378

Epoch 02432: val_loss did not improve from 1.25354
Epoch 2433/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4351 - val_loss: 1.2565 - val_accuracy: 0.4338

Epoch 02433: val_loss did not improve from 1.25354
Epoch 2434/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4340 - val_loss: 1.2590 - val_accuracy: 0.4346

Epoch 02434: val_loss did not improve from 1.25354
Epoch 2435/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4279 - val_loss: 1.2572 - val_accuracy: 0.4298

Epoch 02435: val_loss did not improve from 1.25354
Epoch 2436/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4320 - val_loss: 1.2559 - val_accuracy: 0.4346

Epoch 02436: val_loss did not improve from 1.25354
Epoch 2437/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4296 - val_loss: 1.2574 - val_accuracy: 0.4362

Epoch 02437: val_loss did not improve from 1.25354
Epoch 2438/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4324 - val_loss: 1.2556 - val_accuracy: 0.4346

Epoch 02438: val_loss did not improve from 1.25354
Epoch 2439/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4340 - val_loss: 1.2581 - val_accuracy: 0.4274

Epoch 02439: val_loss did not improve from 1.25354
Epoch 2440/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4328 - val_loss: 1.2584 - val_accuracy: 0.4370

Epoch 02440: val_loss did not improve from 1.25354
Epoch 2441/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4333 - val_loss: 1.2563 - val_accuracy: 0.4386

Epoch 02441: val_loss did not improve from 1.25354
Epoch 2442/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4301 - val_loss: 1.2534 - val_accuracy: 0.4346

Epoch 02442: val_loss improved from 1.25354 to 1.25340, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2443/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4334 - val_loss: 1.2568 - val_accuracy: 0.4338

Epoch 02443: val_loss did not improve from 1.25340
Epoch 2444/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4301 - val_loss: 1.2568 - val_accuracy: 0.4266

Epoch 02444: val_loss did not improve from 1.25340
Epoch 2445/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4306 - val_loss: 1.2566 - val_accuracy: 0.4346

Epoch 02445: val_loss did not improve from 1.25340
Epoch 2446/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4322 - val_loss: 1.2565 - val_accuracy: 0.4338

Epoch 02446: val_loss did not improve from 1.25340
Epoch 2447/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4319 - val_loss: 1.2584 - val_accuracy: 0.4354

Epoch 02447: val_loss did not improve from 1.25340
Epoch 2448/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4295 - val_loss: 1.2581 - val_accuracy: 0.4282

Epoch 02448: val_loss did not improve from 1.25340
Epoch 2449/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4307 - val_loss: 1.2588 - val_accuracy: 0.4394

Epoch 02449: val_loss did not improve from 1.25340
Epoch 2450/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4295 - val_loss: 1.2692 - val_accuracy: 0.4242

Epoch 02450: val_loss did not improve from 1.25340
Epoch 2451/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4298 - val_loss: 1.2548 - val_accuracy: 0.4362

Epoch 02451: val_loss did not improve from 1.25340
Epoch 2452/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4268 - val_loss: 1.2576 - val_accuracy: 0.4290

Epoch 02452: val_loss did not improve from 1.25340
Epoch 2453/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4292 - val_loss: 1.2599 - val_accuracy: 0.4282

Epoch 02453: val_loss did not improve from 1.25340
Epoch 2454/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4306 - val_loss: 1.2596 - val_accuracy: 0.4203

Epoch 02454: val_loss did not improve from 1.25340
Epoch 2455/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4321 - val_loss: 1.2601 - val_accuracy: 0.4370

Epoch 02455: val_loss did not improve from 1.25340
Epoch 2456/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4303 - val_loss: 1.2602 - val_accuracy: 0.4314

Epoch 02456: val_loss did not improve from 1.25340
Epoch 2457/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4356 - val_loss: 1.2568 - val_accuracy: 0.4354

Epoch 02457: val_loss did not improve from 1.25340
Epoch 2458/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4287 - val_loss: 1.2619 - val_accuracy: 0.4346

Epoch 02458: val_loss did not improve from 1.25340
Epoch 2459/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4289 - val_loss: 1.2573 - val_accuracy: 0.4362

Epoch 02459: val_loss did not improve from 1.25340
Epoch 2460/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4287 - val_loss: 1.2599 - val_accuracy: 0.4298

Epoch 02460: val_loss did not improve from 1.25340
Epoch 2461/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4289 - val_loss: 1.2623 - val_accuracy: 0.4266

Epoch 02461: val_loss did not improve from 1.25340
Epoch 2462/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4311 - val_loss: 1.2552 - val_accuracy: 0.4330

Epoch 02462: val_loss did not improve from 1.25340
Epoch 2463/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4287 - val_loss: 1.2591 - val_accuracy: 0.4370

Epoch 02463: val_loss did not improve from 1.25340
Epoch 2464/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4318 - val_loss: 1.2564 - val_accuracy: 0.4346

Epoch 02464: val_loss did not improve from 1.25340
Epoch 2465/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4321 - val_loss: 1.2595 - val_accuracy: 0.4370

Epoch 02465: val_loss did not improve from 1.25340
Epoch 2466/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4281 - val_loss: 1.2572 - val_accuracy: 0.4298

Epoch 02466: val_loss did not improve from 1.25340
Epoch 2467/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4323 - val_loss: 1.2619 - val_accuracy: 0.4290

Epoch 02467: val_loss did not improve from 1.25340
Epoch 2468/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4318 - val_loss: 1.2585 - val_accuracy: 0.4386

Epoch 02468: val_loss did not improve from 1.25340
Epoch 2469/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4312 - val_loss: 1.2615 - val_accuracy: 0.4266

Epoch 02469: val_loss did not improve from 1.25340
Epoch 2470/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4311 - val_loss: 1.2570 - val_accuracy: 0.4346

Epoch 02470: val_loss did not improve from 1.25340
Epoch 2471/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4296 - val_loss: 1.2559 - val_accuracy: 0.4282

Epoch 02471: val_loss did not improve from 1.25340
Epoch 2472/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4318 - val_loss: 1.2558 - val_accuracy: 0.4386

Epoch 02472: val_loss did not improve from 1.25340
Epoch 2473/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4325 - val_loss: 1.2585 - val_accuracy: 0.4362

Epoch 02473: val_loss did not improve from 1.25340
Epoch 2474/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4306 - val_loss: 1.2557 - val_accuracy: 0.4378

Epoch 02474: val_loss did not improve from 1.25340
Epoch 2475/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4318 - val_loss: 1.2562 - val_accuracy: 0.4322

Epoch 02475: val_loss did not improve from 1.25340
Epoch 2476/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4345 - val_loss: 1.2575 - val_accuracy: 0.4298

Epoch 02476: val_loss did not improve from 1.25340
Epoch 2477/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4289 - val_loss: 1.2589 - val_accuracy: 0.4330

Epoch 02477: val_loss did not improve from 1.25340
Epoch 2478/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4332 - val_loss: 1.2555 - val_accuracy: 0.4346

Epoch 02478: val_loss did not improve from 1.25340
Epoch 2479/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4313 - val_loss: 1.2589 - val_accuracy: 0.4410

Epoch 02479: val_loss did not improve from 1.25340
Epoch 2480/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4321 - val_loss: 1.2584 - val_accuracy: 0.4203

Epoch 02480: val_loss did not improve from 1.25340
Epoch 2481/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4339 - val_loss: 1.2556 - val_accuracy: 0.4274

Epoch 02481: val_loss did not improve from 1.25340
Epoch 2482/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4322 - val_loss: 1.2593 - val_accuracy: 0.4242

Epoch 02482: val_loss did not improve from 1.25340
Epoch 2483/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4276 - val_loss: 1.2583 - val_accuracy: 0.4410

Epoch 02483: val_loss did not improve from 1.25340
Epoch 2484/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4319 - val_loss: 1.2591 - val_accuracy: 0.4211

Epoch 02484: val_loss did not improve from 1.25340
Epoch 2485/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4321 - val_loss: 1.2575 - val_accuracy: 0.4314

Epoch 02485: val_loss did not improve from 1.25340
Epoch 2486/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4319 - val_loss: 1.2587 - val_accuracy: 0.4290

Epoch 02486: val_loss did not improve from 1.25340
Epoch 2487/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4305 - val_loss: 1.2558 - val_accuracy: 0.4338

Epoch 02487: val_loss did not improve from 1.25340
Epoch 2488/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4243 - val_loss: 1.2573 - val_accuracy: 0.4330

Epoch 02488: val_loss did not improve from 1.25340
Epoch 2489/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4295 - val_loss: 1.2572 - val_accuracy: 0.4338

Epoch 02489: val_loss did not improve from 1.25340
Epoch 2490/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4286 - val_loss: 1.2631 - val_accuracy: 0.4330

Epoch 02490: val_loss did not improve from 1.25340
Epoch 2491/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4250 - val_loss: 1.2582 - val_accuracy: 0.4282

Epoch 02491: val_loss did not improve from 1.25340
Epoch 2492/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4299 - val_loss: 1.2557 - val_accuracy: 0.4274

Epoch 02492: val_loss did not improve from 1.25340
Epoch 2493/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4336 - val_loss: 1.2598 - val_accuracy: 0.4330

Epoch 02493: val_loss did not improve from 1.25340
Epoch 2494/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4267 - val_loss: 1.2567 - val_accuracy: 0.4242

Epoch 02494: val_loss did not improve from 1.25340
Epoch 2495/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4336 - val_loss: 1.2549 - val_accuracy: 0.4362

Epoch 02495: val_loss did not improve from 1.25340
Epoch 2496/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4349 - val_loss: 1.2537 - val_accuracy: 0.4306

Epoch 02496: val_loss did not improve from 1.25340
Epoch 2497/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4303 - val_loss: 1.2575 - val_accuracy: 0.4242

Epoch 02497: val_loss did not improve from 1.25340
Epoch 2498/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4322 - val_loss: 1.2567 - val_accuracy: 0.4290

Epoch 02498: val_loss did not improve from 1.25340
Epoch 2499/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4366 - val_loss: 1.2558 - val_accuracy: 0.4386

Epoch 02499: val_loss did not improve from 1.25340
Epoch 2500/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4301 - val_loss: 1.2571 - val_accuracy: 0.4250

Epoch 02500: val_loss did not improve from 1.25340
Epoch 2501/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4280 - val_loss: 1.2601 - val_accuracy: 0.4306

Epoch 02501: val_loss did not improve from 1.25340
Epoch 2502/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4322 - val_loss: 1.2566 - val_accuracy: 0.4370

Epoch 02502: val_loss did not improve from 1.25340
Epoch 2503/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4304 - val_loss: 1.2570 - val_accuracy: 0.4354

Epoch 02503: val_loss did not improve from 1.25340
Epoch 2504/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4311 - val_loss: 1.2578 - val_accuracy: 0.4330

Epoch 02504: val_loss did not improve from 1.25340
Epoch 2505/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4308 - val_loss: 1.2650 - val_accuracy: 0.4266

Epoch 02505: val_loss did not improve from 1.25340
Epoch 2506/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4296 - val_loss: 1.2585 - val_accuracy: 0.4386

Epoch 02506: val_loss did not improve from 1.25340
Epoch 2507/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4272 - val_loss: 1.2589 - val_accuracy: 0.4226

Epoch 02507: val_loss did not improve from 1.25340
Epoch 2508/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4327 - val_loss: 1.2554 - val_accuracy: 0.4426

Epoch 02508: val_loss did not improve from 1.25340
Epoch 2509/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4290 - val_loss: 1.2573 - val_accuracy: 0.4258

Epoch 02509: val_loss did not improve from 1.25340
Epoch 2510/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4300 - val_loss: 1.2599 - val_accuracy: 0.4290

Epoch 02510: val_loss did not improve from 1.25340
Epoch 2511/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4275 - val_loss: 1.2555 - val_accuracy: 0.4322

Epoch 02511: val_loss did not improve from 1.25340
Epoch 2512/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4338 - val_loss: 1.2560 - val_accuracy: 0.4346

Epoch 02512: val_loss did not improve from 1.25340
Epoch 2513/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4291 - val_loss: 1.2586 - val_accuracy: 0.4306

Epoch 02513: val_loss did not improve from 1.25340
Epoch 2514/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4292 - val_loss: 1.2564 - val_accuracy: 0.4346

Epoch 02514: val_loss did not improve from 1.25340
Epoch 2515/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4324 - val_loss: 1.2592 - val_accuracy: 0.4314

Epoch 02515: val_loss did not improve from 1.25340
Epoch 2516/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4293 - val_loss: 1.2551 - val_accuracy: 0.4290

Epoch 02516: val_loss did not improve from 1.25340
Epoch 2517/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4336 - val_loss: 1.2567 - val_accuracy: 0.4338

Epoch 02517: val_loss did not improve from 1.25340
Epoch 2518/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4311 - val_loss: 1.2608 - val_accuracy: 0.4346

Epoch 02518: val_loss did not improve from 1.25340
Epoch 2519/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4304 - val_loss: 1.2604 - val_accuracy: 0.4314

Epoch 02519: val_loss did not improve from 1.25340
Epoch 2520/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4313 - val_loss: 1.2574 - val_accuracy: 0.4314

Epoch 02520: val_loss did not improve from 1.25340
Epoch 2521/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4324 - val_loss: 1.2596 - val_accuracy: 0.4266

Epoch 02521: val_loss did not improve from 1.25340
Epoch 2522/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4278 - val_loss: 1.2563 - val_accuracy: 0.4314

Epoch 02522: val_loss did not improve from 1.25340
Epoch 2523/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4298 - val_loss: 1.2544 - val_accuracy: 0.4290

Epoch 02523: val_loss did not improve from 1.25340
Epoch 2524/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4326 - val_loss: 1.2628 - val_accuracy: 0.4306

Epoch 02524: val_loss did not improve from 1.25340
Epoch 2525/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4363 - val_loss: 1.2569 - val_accuracy: 0.4314

Epoch 02525: val_loss did not improve from 1.25340
Epoch 2526/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4344 - val_loss: 1.2558 - val_accuracy: 0.4386

Epoch 02526: val_loss did not improve from 1.25340
Epoch 2527/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4300 - val_loss: 1.2584 - val_accuracy: 0.4322

Epoch 02527: val_loss did not improve from 1.25340
Epoch 2528/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4336 - val_loss: 1.2560 - val_accuracy: 0.4362

Epoch 02528: val_loss did not improve from 1.25340
Epoch 2529/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4311 - val_loss: 1.2571 - val_accuracy: 0.4394

Epoch 02529: val_loss did not improve from 1.25340
Epoch 2530/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4279 - val_loss: 1.2655 - val_accuracy: 0.4306

Epoch 02530: val_loss did not improve from 1.25340
Epoch 2531/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4315 - val_loss: 1.2603 - val_accuracy: 0.4370

Epoch 02531: val_loss did not improve from 1.25340
Epoch 2532/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4314 - val_loss: 1.2597 - val_accuracy: 0.4282

Epoch 02532: val_loss did not improve from 1.25340
Epoch 2533/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4359 - val_loss: 1.2562 - val_accuracy: 0.4362

Epoch 02533: val_loss did not improve from 1.25340
Epoch 2534/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4324 - val_loss: 1.2578 - val_accuracy: 0.4306

Epoch 02534: val_loss did not improve from 1.25340
Epoch 2535/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4318 - val_loss: 1.2561 - val_accuracy: 0.4290

Epoch 02535: val_loss did not improve from 1.25340
Epoch 2536/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4326 - val_loss: 1.2587 - val_accuracy: 0.4290

Epoch 02536: val_loss did not improve from 1.25340
Epoch 2537/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4316 - val_loss: 1.2564 - val_accuracy: 0.4306

Epoch 02537: val_loss did not improve from 1.25340
Epoch 2538/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4328 - val_loss: 1.2558 - val_accuracy: 0.4338

Epoch 02538: val_loss did not improve from 1.25340
Epoch 2539/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4321 - val_loss: 1.2636 - val_accuracy: 0.4314

Epoch 02539: val_loss did not improve from 1.25340
Epoch 2540/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4272 - val_loss: 1.2613 - val_accuracy: 0.4258

Epoch 02540: val_loss did not improve from 1.25340
Epoch 2541/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4324 - val_loss: 1.2552 - val_accuracy: 0.4330

Epoch 02541: val_loss did not improve from 1.25340
Epoch 2542/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4325 - val_loss: 1.2564 - val_accuracy: 0.4298

Epoch 02542: val_loss did not improve from 1.25340
Epoch 2543/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4316 - val_loss: 1.2581 - val_accuracy: 0.4290

Epoch 02543: val_loss did not improve from 1.25340
Epoch 2544/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4325 - val_loss: 1.2578 - val_accuracy: 0.4338

Epoch 02544: val_loss did not improve from 1.25340
Epoch 2545/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4354 - val_loss: 1.2543 - val_accuracy: 0.4314

Epoch 02545: val_loss did not improve from 1.25340
Epoch 2546/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4332 - val_loss: 1.2546 - val_accuracy: 0.4322

Epoch 02546: val_loss did not improve from 1.25340
Epoch 2547/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4335 - val_loss: 1.2591 - val_accuracy: 0.4274

Epoch 02547: val_loss did not improve from 1.25340
Epoch 2548/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4326 - val_loss: 1.2552 - val_accuracy: 0.4314

Epoch 02548: val_loss did not improve from 1.25340
Epoch 2549/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4291 - val_loss: 1.2521 - val_accuracy: 0.4274

Epoch 02549: val_loss improved from 1.25340 to 1.25214, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2550/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4340 - val_loss: 1.2569 - val_accuracy: 0.4322

Epoch 02550: val_loss did not improve from 1.25214
Epoch 2551/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4304 - val_loss: 1.2567 - val_accuracy: 0.4250

Epoch 02551: val_loss did not improve from 1.25214
Epoch 2552/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4342 - val_loss: 1.2533 - val_accuracy: 0.4314

Epoch 02552: val_loss did not improve from 1.25214
Epoch 2553/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4343 - val_loss: 1.2562 - val_accuracy: 0.4290

Epoch 02553: val_loss did not improve from 1.25214
Epoch 2554/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4330 - val_loss: 1.2544 - val_accuracy: 0.4346

Epoch 02554: val_loss did not improve from 1.25214
Epoch 2555/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4312 - val_loss: 1.2546 - val_accuracy: 0.4306

Epoch 02555: val_loss did not improve from 1.25214
Epoch 2556/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4306 - val_loss: 1.2713 - val_accuracy: 0.4282

Epoch 02556: val_loss did not improve from 1.25214
Epoch 2557/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4304 - val_loss: 1.2579 - val_accuracy: 0.4402

Epoch 02557: val_loss did not improve from 1.25214
Epoch 2558/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4314 - val_loss: 1.2555 - val_accuracy: 0.4306

Epoch 02558: val_loss did not improve from 1.25214
Epoch 2559/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4338 - val_loss: 1.2562 - val_accuracy: 0.4314

Epoch 02559: val_loss did not improve from 1.25214
Epoch 2560/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4282 - val_loss: 1.2623 - val_accuracy: 0.4354

Epoch 02560: val_loss did not improve from 1.25214
Epoch 2561/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4287 - val_loss: 1.2574 - val_accuracy: 0.4258

Epoch 02561: val_loss did not improve from 1.25214
Epoch 2562/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4332 - val_loss: 1.2572 - val_accuracy: 0.4362

Epoch 02562: val_loss did not improve from 1.25214
Epoch 2563/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4336 - val_loss: 1.2580 - val_accuracy: 0.4290

Epoch 02563: val_loss did not improve from 1.25214
Epoch 2564/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4340 - val_loss: 1.2549 - val_accuracy: 0.4330

Epoch 02564: val_loss did not improve from 1.25214
Epoch 2565/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4345 - val_loss: 1.2558 - val_accuracy: 0.4298

Epoch 02565: val_loss did not improve from 1.25214
Epoch 2566/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4337 - val_loss: 1.2549 - val_accuracy: 0.4258

Epoch 02566: val_loss did not improve from 1.25214
Epoch 2567/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4348 - val_loss: 1.2560 - val_accuracy: 0.4290

Epoch 02567: val_loss did not improve from 1.25214
Epoch 2568/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4385 - val_loss: 1.2566 - val_accuracy: 0.4306

Epoch 02568: val_loss did not improve from 1.25214
Epoch 2569/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4347 - val_loss: 1.2566 - val_accuracy: 0.4346

Epoch 02569: val_loss did not improve from 1.25214
Epoch 2570/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4332 - val_loss: 1.2616 - val_accuracy: 0.4266

Epoch 02570: val_loss did not improve from 1.25214
Epoch 2571/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4305 - val_loss: 1.2605 - val_accuracy: 0.4298

Epoch 02571: val_loss did not improve from 1.25214
Epoch 2572/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4281 - val_loss: 1.2589 - val_accuracy: 0.4274

Epoch 02572: val_loss did not improve from 1.25214
Epoch 2573/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4287 - val_loss: 1.2611 - val_accuracy: 0.4298

Epoch 02573: val_loss did not improve from 1.25214
Epoch 2574/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4332 - val_loss: 1.2588 - val_accuracy: 0.4378

Epoch 02574: val_loss did not improve from 1.25214
Epoch 2575/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4326 - val_loss: 1.2564 - val_accuracy: 0.4370

Epoch 02575: val_loss did not improve from 1.25214
Epoch 2576/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4318 - val_loss: 1.2570 - val_accuracy: 0.4362

Epoch 02576: val_loss did not improve from 1.25214
Epoch 2577/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4302 - val_loss: 1.2577 - val_accuracy: 0.4378

Epoch 02577: val_loss did not improve from 1.25214
Epoch 2578/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4313 - val_loss: 1.2603 - val_accuracy: 0.4274

Epoch 02578: val_loss did not improve from 1.25214
Epoch 2579/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4317 - val_loss: 1.2569 - val_accuracy: 0.4306

Epoch 02579: val_loss did not improve from 1.25214
Epoch 2580/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4321 - val_loss: 1.2581 - val_accuracy: 0.4362

Epoch 02580: val_loss did not improve from 1.25214
Epoch 2581/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4340 - val_loss: 1.2584 - val_accuracy: 0.4282

Epoch 02581: val_loss did not improve from 1.25214
Epoch 2582/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4376 - val_loss: 1.2554 - val_accuracy: 0.4290

Epoch 02582: val_loss did not improve from 1.25214
Epoch 2583/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4316 - val_loss: 1.2537 - val_accuracy: 0.4362

Epoch 02583: val_loss did not improve from 1.25214
Epoch 2584/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4361 - val_loss: 1.2565 - val_accuracy: 0.4394

Epoch 02584: val_loss did not improve from 1.25214
Epoch 2585/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4282 - val_loss: 1.2591 - val_accuracy: 0.4306

Epoch 02585: val_loss did not improve from 1.25214
Epoch 2586/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4329 - val_loss: 1.2585 - val_accuracy: 0.4322

Epoch 02586: val_loss did not improve from 1.25214
Epoch 2587/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4348 - val_loss: 1.2563 - val_accuracy: 0.4234

Epoch 02587: val_loss did not improve from 1.25214
Epoch 2588/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4336 - val_loss: 1.2559 - val_accuracy: 0.4346

Epoch 02588: val_loss did not improve from 1.25214
Epoch 2589/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4309 - val_loss: 1.2553 - val_accuracy: 0.4346

Epoch 02589: val_loss did not improve from 1.25214
Epoch 2590/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4334 - val_loss: 1.2570 - val_accuracy: 0.4354

Epoch 02590: val_loss did not improve from 1.25214
Epoch 2591/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4334 - val_loss: 1.2587 - val_accuracy: 0.4266

Epoch 02591: val_loss did not improve from 1.25214
Epoch 2592/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4334 - val_loss: 1.2566 - val_accuracy: 0.4298

Epoch 02592: val_loss did not improve from 1.25214
Epoch 2593/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4349 - val_loss: 1.2576 - val_accuracy: 0.4211

Epoch 02593: val_loss did not improve from 1.25214
Epoch 2594/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4318 - val_loss: 1.2601 - val_accuracy: 0.4346

Epoch 02594: val_loss did not improve from 1.25214
Epoch 2595/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4308 - val_loss: 1.2562 - val_accuracy: 0.4250

Epoch 02595: val_loss did not improve from 1.25214
Epoch 2596/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4312 - val_loss: 1.2573 - val_accuracy: 0.4290

Epoch 02596: val_loss did not improve from 1.25214
Epoch 2597/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4326 - val_loss: 1.2550 - val_accuracy: 0.4338

Epoch 02597: val_loss did not improve from 1.25214
Epoch 2598/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4344 - val_loss: 1.2545 - val_accuracy: 0.4362

Epoch 02598: val_loss did not improve from 1.25214
Epoch 2599/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4325 - val_loss: 1.2606 - val_accuracy: 0.4250

Epoch 02599: val_loss did not improve from 1.25214
Epoch 2600/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4336 - val_loss: 1.2560 - val_accuracy: 0.4298

Epoch 02600: val_loss did not improve from 1.25214
Epoch 2601/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4339 - val_loss: 1.2571 - val_accuracy: 0.4354

Epoch 02601: val_loss did not improve from 1.25214
Epoch 2602/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4329 - val_loss: 1.2585 - val_accuracy: 0.4306

Epoch 02602: val_loss did not improve from 1.25214
Epoch 2603/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4313 - val_loss: 1.2584 - val_accuracy: 0.4370

Epoch 02603: val_loss did not improve from 1.25214
Epoch 2604/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4318 - val_loss: 1.2589 - val_accuracy: 0.4378

Epoch 02604: val_loss did not improve from 1.25214
Epoch 2605/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4267 - val_loss: 1.2595 - val_accuracy: 0.4219

Epoch 02605: val_loss did not improve from 1.25214
Epoch 2606/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4325 - val_loss: 1.2576 - val_accuracy: 0.4402

Epoch 02606: val_loss did not improve from 1.25214
Epoch 2607/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4332 - val_loss: 1.2575 - val_accuracy: 0.4322

Epoch 02607: val_loss did not improve from 1.25214
Epoch 2608/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4302 - val_loss: 1.2615 - val_accuracy: 0.4211

Epoch 02608: val_loss did not improve from 1.25214
Epoch 2609/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4271 - val_loss: 1.2573 - val_accuracy: 0.4250

Epoch 02609: val_loss did not improve from 1.25214
Epoch 2610/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4277 - val_loss: 1.2629 - val_accuracy: 0.4354

Epoch 02610: val_loss did not improve from 1.25214
Epoch 2611/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4358 - val_loss: 1.2545 - val_accuracy: 0.4378

Epoch 02611: val_loss did not improve from 1.25214
Epoch 2612/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4321 - val_loss: 1.2547 - val_accuracy: 0.4346

Epoch 02612: val_loss did not improve from 1.25214
Epoch 2613/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4333 - val_loss: 1.2565 - val_accuracy: 0.4226

Epoch 02613: val_loss did not improve from 1.25214
Epoch 2614/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4330 - val_loss: 1.2551 - val_accuracy: 0.4274

Epoch 02614: val_loss did not improve from 1.25214
Epoch 2615/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4316 - val_loss: 1.2563 - val_accuracy: 0.4242

Epoch 02615: val_loss did not improve from 1.25214
Epoch 2616/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4345 - val_loss: 1.2562 - val_accuracy: 0.4282

Epoch 02616: val_loss did not improve from 1.25214
Epoch 2617/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4341 - val_loss: 1.2535 - val_accuracy: 0.4322

Epoch 02617: val_loss did not improve from 1.25214
Epoch 2618/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4331 - val_loss: 1.2565 - val_accuracy: 0.4346

Epoch 02618: val_loss did not improve from 1.25214
Epoch 2619/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4281 - val_loss: 1.2613 - val_accuracy: 0.4258

Epoch 02619: val_loss did not improve from 1.25214
Epoch 2620/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4328 - val_loss: 1.2594 - val_accuracy: 0.4290

Epoch 02620: val_loss did not improve from 1.25214
Epoch 2621/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4270 - val_loss: 1.2606 - val_accuracy: 0.4298

Epoch 02621: val_loss did not improve from 1.25214
Epoch 2622/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4316 - val_loss: 1.2629 - val_accuracy: 0.4322

Epoch 02622: val_loss did not improve from 1.25214
Epoch 2623/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4337 - val_loss: 1.2570 - val_accuracy: 0.4282

Epoch 02623: val_loss did not improve from 1.25214
Epoch 2624/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4334 - val_loss: 1.2541 - val_accuracy: 0.4338

Epoch 02624: val_loss did not improve from 1.25214
Epoch 2625/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4356 - val_loss: 1.2572 - val_accuracy: 0.4330

Epoch 02625: val_loss did not improve from 1.25214
Epoch 2626/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4363 - val_loss: 1.2573 - val_accuracy: 0.4354

Epoch 02626: val_loss did not improve from 1.25214
Epoch 2627/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4321 - val_loss: 1.2615 - val_accuracy: 0.4322

Epoch 02627: val_loss did not improve from 1.25214
Epoch 2628/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4370 - val_loss: 1.2564 - val_accuracy: 0.4258

Epoch 02628: val_loss did not improve from 1.25214
Epoch 2629/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4309 - val_loss: 1.2562 - val_accuracy: 0.4258

Epoch 02629: val_loss did not improve from 1.25214
Epoch 2630/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4270 - val_loss: 1.2579 - val_accuracy: 0.4266

Epoch 02630: val_loss did not improve from 1.25214
Epoch 2631/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4297 - val_loss: 1.2585 - val_accuracy: 0.4322

Epoch 02631: val_loss did not improve from 1.25214
Epoch 2632/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4366 - val_loss: 1.2556 - val_accuracy: 0.4330

Epoch 02632: val_loss did not improve from 1.25214
Epoch 2633/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4371 - val_loss: 1.2621 - val_accuracy: 0.4362

Epoch 02633: val_loss did not improve from 1.25214
Epoch 2634/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4321 - val_loss: 1.2562 - val_accuracy: 0.4330

Epoch 02634: val_loss did not improve from 1.25214
Epoch 2635/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4318 - val_loss: 1.2578 - val_accuracy: 0.4402

Epoch 02635: val_loss did not improve from 1.25214
Epoch 2636/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4245 - val_loss: 1.2568 - val_accuracy: 0.4203

Epoch 02636: val_loss did not improve from 1.25214
Epoch 2637/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4318 - val_loss: 1.2565 - val_accuracy: 0.4370

Epoch 02637: val_loss did not improve from 1.25214
Epoch 2638/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4329 - val_loss: 1.2583 - val_accuracy: 0.4298

Epoch 02638: val_loss did not improve from 1.25214
Epoch 2639/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4332 - val_loss: 1.2570 - val_accuracy: 0.4386

Epoch 02639: val_loss did not improve from 1.25214
Epoch 2640/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4262 - val_loss: 1.2582 - val_accuracy: 0.4219

Epoch 02640: val_loss did not improve from 1.25214
Epoch 2641/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4311 - val_loss: 1.2581 - val_accuracy: 0.4298

Epoch 02641: val_loss did not improve from 1.25214
Epoch 2642/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4306 - val_loss: 1.2553 - val_accuracy: 0.4282

Epoch 02642: val_loss did not improve from 1.25214
Epoch 2643/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4352 - val_loss: 1.2542 - val_accuracy: 0.4346

Epoch 02643: val_loss did not improve from 1.25214
Epoch 2644/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4317 - val_loss: 1.2589 - val_accuracy: 0.4258

Epoch 02644: val_loss did not improve from 1.25214
Epoch 2645/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4294 - val_loss: 1.2597 - val_accuracy: 0.4370

Epoch 02645: val_loss did not improve from 1.25214
Epoch 2646/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4282 - val_loss: 1.2585 - val_accuracy: 0.4163

Epoch 02646: val_loss did not improve from 1.25214
Epoch 2647/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4356 - val_loss: 1.2546 - val_accuracy: 0.4306

Epoch 02647: val_loss did not improve from 1.25214
Epoch 2648/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4349 - val_loss: 1.2550 - val_accuracy: 0.4203

Epoch 02648: val_loss did not improve from 1.25214
Epoch 2649/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4310 - val_loss: 1.2578 - val_accuracy: 0.4266

Epoch 02649: val_loss did not improve from 1.25214
Epoch 2650/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4266 - val_loss: 1.2632 - val_accuracy: 0.4274

Epoch 02650: val_loss did not improve from 1.25214
Epoch 2651/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4298 - val_loss: 1.2556 - val_accuracy: 0.4314

Epoch 02651: val_loss did not improve from 1.25214
Epoch 2652/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4308 - val_loss: 1.2565 - val_accuracy: 0.4298

Epoch 02652: val_loss did not improve from 1.25214
Epoch 2653/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4277 - val_loss: 1.2584 - val_accuracy: 0.4234

Epoch 02653: val_loss did not improve from 1.25214
Epoch 2654/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4317 - val_loss: 1.2564 - val_accuracy: 0.4346

Epoch 02654: val_loss did not improve from 1.25214
Epoch 2655/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4343 - val_loss: 1.2565 - val_accuracy: 0.4330

Epoch 02655: val_loss did not improve from 1.25214
Epoch 2656/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4356 - val_loss: 1.2557 - val_accuracy: 0.4362

Epoch 02656: val_loss did not improve from 1.25214
Epoch 2657/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4351 - val_loss: 1.2601 - val_accuracy: 0.4322

Epoch 02657: val_loss did not improve from 1.25214
Epoch 2658/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4340 - val_loss: 1.2535 - val_accuracy: 0.4306

Epoch 02658: val_loss did not improve from 1.25214
Epoch 2659/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4306 - val_loss: 1.2551 - val_accuracy: 0.4306

Epoch 02659: val_loss did not improve from 1.25214
Epoch 2660/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4310 - val_loss: 1.2576 - val_accuracy: 0.4346

Epoch 02660: val_loss did not improve from 1.25214
Epoch 2661/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4305 - val_loss: 1.2602 - val_accuracy: 0.4258

Epoch 02661: val_loss did not improve from 1.25214
Epoch 2662/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4306 - val_loss: 1.2592 - val_accuracy: 0.4274

Epoch 02662: val_loss did not improve from 1.25214
Epoch 2663/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4345 - val_loss: 1.2541 - val_accuracy: 0.4266

Epoch 02663: val_loss did not improve from 1.25214
Epoch 2664/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4328 - val_loss: 1.2549 - val_accuracy: 0.4338

Epoch 02664: val_loss did not improve from 1.25214
Epoch 2665/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4346 - val_loss: 1.2610 - val_accuracy: 0.4306

Epoch 02665: val_loss did not improve from 1.25214
Epoch 2666/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4316 - val_loss: 1.2574 - val_accuracy: 0.4330

Epoch 02666: val_loss did not improve from 1.25214
Epoch 2667/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4342 - val_loss: 1.2603 - val_accuracy: 0.4258

Epoch 02667: val_loss did not improve from 1.25214
Epoch 2668/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4323 - val_loss: 1.2616 - val_accuracy: 0.4266

Epoch 02668: val_loss did not improve from 1.25214
Epoch 2669/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4357 - val_loss: 1.2609 - val_accuracy: 0.4314

Epoch 02669: val_loss did not improve from 1.25214
Epoch 2670/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4298 - val_loss: 1.2625 - val_accuracy: 0.4258

Epoch 02670: val_loss did not improve from 1.25214
Epoch 2671/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4322 - val_loss: 1.2560 - val_accuracy: 0.4282

Epoch 02671: val_loss did not improve from 1.25214
Epoch 2672/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4342 - val_loss: 1.2578 - val_accuracy: 0.4354

Epoch 02672: val_loss did not improve from 1.25214
Epoch 2673/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4302 - val_loss: 1.2610 - val_accuracy: 0.4226

Epoch 02673: val_loss did not improve from 1.25214
Epoch 2674/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4322 - val_loss: 1.2543 - val_accuracy: 0.4330

Epoch 02674: val_loss did not improve from 1.25214
Epoch 2675/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4324 - val_loss: 1.2546 - val_accuracy: 0.4314

Epoch 02675: val_loss did not improve from 1.25214
Epoch 2676/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4316 - val_loss: 1.2567 - val_accuracy: 0.4282

Epoch 02676: val_loss did not improve from 1.25214
Epoch 2677/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4306 - val_loss: 1.2542 - val_accuracy: 0.4250

Epoch 02677: val_loss did not improve from 1.25214
Epoch 2678/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4372 - val_loss: 1.2582 - val_accuracy: 0.4282

Epoch 02678: val_loss did not improve from 1.25214
Epoch 2679/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4321 - val_loss: 1.2581 - val_accuracy: 0.4322

Epoch 02679: val_loss did not improve from 1.25214
Epoch 2680/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4318 - val_loss: 1.2597 - val_accuracy: 0.4234

Epoch 02680: val_loss did not improve from 1.25214
Epoch 2681/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4318 - val_loss: 1.2572 - val_accuracy: 0.4346

Epoch 02681: val_loss did not improve from 1.25214
Epoch 2682/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4330 - val_loss: 1.2563 - val_accuracy: 0.4322

Epoch 02682: val_loss did not improve from 1.25214
Epoch 2683/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4296 - val_loss: 1.2564 - val_accuracy: 0.4219

Epoch 02683: val_loss did not improve from 1.25214
Epoch 2684/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4302 - val_loss: 1.2576 - val_accuracy: 0.4258

Epoch 02684: val_loss did not improve from 1.25214
Epoch 2685/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4315 - val_loss: 1.2561 - val_accuracy: 0.4314

Epoch 02685: val_loss did not improve from 1.25214
Epoch 2686/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4289 - val_loss: 1.2622 - val_accuracy: 0.4362

Epoch 02686: val_loss did not improve from 1.25214
Epoch 2687/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4291 - val_loss: 1.2601 - val_accuracy: 0.4346

Epoch 02687: val_loss did not improve from 1.25214
Epoch 2688/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4347 - val_loss: 1.2578 - val_accuracy: 0.4354

Epoch 02688: val_loss did not improve from 1.25214
Epoch 2689/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4325 - val_loss: 1.2604 - val_accuracy: 0.4211

Epoch 02689: val_loss did not improve from 1.25214
Epoch 2690/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4296 - val_loss: 1.2557 - val_accuracy: 0.4195

Epoch 02690: val_loss did not improve from 1.25214
Epoch 2691/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4313 - val_loss: 1.2604 - val_accuracy: 0.4266

Epoch 02691: val_loss did not improve from 1.25214
Epoch 2692/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4323 - val_loss: 1.2594 - val_accuracy: 0.4338

Epoch 02692: val_loss did not improve from 1.25214
Epoch 2693/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4305 - val_loss: 1.2539 - val_accuracy: 0.4386

Epoch 02693: val_loss did not improve from 1.25214
Epoch 2694/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4350 - val_loss: 1.2601 - val_accuracy: 0.4322

Epoch 02694: val_loss did not improve from 1.25214
Epoch 2695/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4303 - val_loss: 1.2544 - val_accuracy: 0.4338

Epoch 02695: val_loss did not improve from 1.25214
Epoch 2696/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4306 - val_loss: 1.2608 - val_accuracy: 0.4274

Epoch 02696: val_loss did not improve from 1.25214
Epoch 2697/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4360 - val_loss: 1.2584 - val_accuracy: 0.4266

Epoch 02697: val_loss did not improve from 1.25214
Epoch 2698/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4360 - val_loss: 1.2585 - val_accuracy: 0.4370

Epoch 02698: val_loss did not improve from 1.25214
Epoch 2699/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4315 - val_loss: 1.2554 - val_accuracy: 0.4274

Epoch 02699: val_loss did not improve from 1.25214
Epoch 2700/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4382 - val_loss: 1.2547 - val_accuracy: 0.4298

Epoch 02700: val_loss did not improve from 1.25214
Epoch 2701/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4351 - val_loss: 1.2655 - val_accuracy: 0.4274

Epoch 02701: val_loss did not improve from 1.25214
Epoch 2702/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4330 - val_loss: 1.2589 - val_accuracy: 0.4362

Epoch 02702: val_loss did not improve from 1.25214
Epoch 2703/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4297 - val_loss: 1.2567 - val_accuracy: 0.4226

Epoch 02703: val_loss did not improve from 1.25214
Epoch 2704/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4303 - val_loss: 1.2589 - val_accuracy: 0.4394

Epoch 02704: val_loss did not improve from 1.25214
Epoch 2705/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4359 - val_loss: 1.2577 - val_accuracy: 0.4306

Epoch 02705: val_loss did not improve from 1.25214
Epoch 2706/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4343 - val_loss: 1.2594 - val_accuracy: 0.4338

Epoch 02706: val_loss did not improve from 1.25214
Epoch 2707/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4327 - val_loss: 1.2551 - val_accuracy: 0.4282

Epoch 02707: val_loss did not improve from 1.25214
Epoch 2708/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4349 - val_loss: 1.2545 - val_accuracy: 0.4362

Epoch 02708: val_loss did not improve from 1.25214
Epoch 2709/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4342 - val_loss: 1.2584 - val_accuracy: 0.4195

Epoch 02709: val_loss did not improve from 1.25214
Epoch 2710/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4315 - val_loss: 1.2555 - val_accuracy: 0.4378

Epoch 02710: val_loss did not improve from 1.25214
Epoch 2711/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4364 - val_loss: 1.2556 - val_accuracy: 0.4234

Epoch 02711: val_loss did not improve from 1.25214
Epoch 2712/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4372 - val_loss: 1.2563 - val_accuracy: 0.4306

Epoch 02712: val_loss did not improve from 1.25214
Epoch 2713/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4356 - val_loss: 1.2578 - val_accuracy: 0.4306

Epoch 02713: val_loss did not improve from 1.25214
Epoch 2714/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4324 - val_loss: 1.2561 - val_accuracy: 0.4386

Epoch 02714: val_loss did not improve from 1.25214
Epoch 2715/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4334 - val_loss: 1.2593 - val_accuracy: 0.4314

Epoch 02715: val_loss did not improve from 1.25214
Epoch 2716/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4319 - val_loss: 1.2571 - val_accuracy: 0.4330

Epoch 02716: val_loss did not improve from 1.25214
Epoch 2717/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4299 - val_loss: 1.2557 - val_accuracy: 0.4234

Epoch 02717: val_loss did not improve from 1.25214
Epoch 2718/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4340 - val_loss: 1.2577 - val_accuracy: 0.4306

Epoch 02718: val_loss did not improve from 1.25214
Epoch 2719/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4311 - val_loss: 1.2568 - val_accuracy: 0.4370

Epoch 02719: val_loss did not improve from 1.25214
Epoch 2720/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4295 - val_loss: 1.2568 - val_accuracy: 0.4298

Epoch 02720: val_loss did not improve from 1.25214
Epoch 2721/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4336 - val_loss: 1.2556 - val_accuracy: 0.4298

Epoch 02721: val_loss did not improve from 1.25214
Epoch 2722/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4351 - val_loss: 1.2539 - val_accuracy: 0.4290

Epoch 02722: val_loss did not improve from 1.25214
Epoch 2723/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4335 - val_loss: 1.2582 - val_accuracy: 0.4211

Epoch 02723: val_loss did not improve from 1.25214
Epoch 2724/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4330 - val_loss: 1.2586 - val_accuracy: 0.4266

Epoch 02724: val_loss did not improve from 1.25214
Epoch 2725/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4302 - val_loss: 1.2574 - val_accuracy: 0.4242

Epoch 02725: val_loss did not improve from 1.25214
Epoch 2726/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4365 - val_loss: 1.2552 - val_accuracy: 0.4322

Epoch 02726: val_loss did not improve from 1.25214
Epoch 2727/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4350 - val_loss: 1.2572 - val_accuracy: 0.4242

Epoch 02727: val_loss did not improve from 1.25214
Epoch 2728/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4357 - val_loss: 1.2585 - val_accuracy: 0.4314

Epoch 02728: val_loss did not improve from 1.25214
Epoch 2729/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4330 - val_loss: 1.2599 - val_accuracy: 0.4250

Epoch 02729: val_loss did not improve from 1.25214
Epoch 2730/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4363 - val_loss: 1.2582 - val_accuracy: 0.4322

Epoch 02730: val_loss did not improve from 1.25214
Epoch 2731/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4304 - val_loss: 1.2649 - val_accuracy: 0.4250

Epoch 02731: val_loss did not improve from 1.25214
Epoch 2732/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4314 - val_loss: 1.2581 - val_accuracy: 0.4322

Epoch 02732: val_loss did not improve from 1.25214
Epoch 2733/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4345 - val_loss: 1.2581 - val_accuracy: 0.4306

Epoch 02733: val_loss did not improve from 1.25214
Epoch 2734/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4318 - val_loss: 1.2564 - val_accuracy: 0.4330

Epoch 02734: val_loss did not improve from 1.25214
Epoch 2735/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4289 - val_loss: 1.2562 - val_accuracy: 0.4370

Epoch 02735: val_loss did not improve from 1.25214
Epoch 2736/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4307 - val_loss: 1.2587 - val_accuracy: 0.4258

Epoch 02736: val_loss did not improve from 1.25214
Epoch 2737/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4345 - val_loss: 1.2577 - val_accuracy: 0.4290

Epoch 02737: val_loss did not improve from 1.25214
Epoch 2738/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4346 - val_loss: 1.2587 - val_accuracy: 0.4306

Epoch 02738: val_loss did not improve from 1.25214
Epoch 2739/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4329 - val_loss: 1.2574 - val_accuracy: 0.4242

Epoch 02739: val_loss did not improve from 1.25214
Epoch 2740/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4354 - val_loss: 1.2552 - val_accuracy: 0.4242

Epoch 02740: val_loss did not improve from 1.25214
Epoch 2741/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4359 - val_loss: 1.2548 - val_accuracy: 0.4290

Epoch 02741: val_loss did not improve from 1.25214
Epoch 2742/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4336 - val_loss: 1.2553 - val_accuracy: 0.4219

Epoch 02742: val_loss did not improve from 1.25214
Epoch 2743/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4299 - val_loss: 1.2636 - val_accuracy: 0.4330

Epoch 02743: val_loss did not improve from 1.25214
Epoch 2744/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4287 - val_loss: 1.2575 - val_accuracy: 0.4266

Epoch 02744: val_loss did not improve from 1.25214
Epoch 2745/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4335 - val_loss: 1.2597 - val_accuracy: 0.4219

Epoch 02745: val_loss did not improve from 1.25214
Epoch 2746/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4311 - val_loss: 1.2579 - val_accuracy: 0.4211

Epoch 02746: val_loss did not improve from 1.25214
Epoch 2747/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4349 - val_loss: 1.2520 - val_accuracy: 0.4290

Epoch 02747: val_loss improved from 1.25214 to 1.25203, saving model to ./results/NN_thk_class/aggr_theta/ckpt_6
Epoch 2748/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4384 - val_loss: 1.2565 - val_accuracy: 0.4306

Epoch 02748: val_loss did not improve from 1.25203
Epoch 2749/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4345 - val_loss: 1.2575 - val_accuracy: 0.4338

Epoch 02749: val_loss did not improve from 1.25203
Epoch 2750/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4294 - val_loss: 1.2531 - val_accuracy: 0.4258

Epoch 02750: val_loss did not improve from 1.25203
Epoch 2751/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4359 - val_loss: 1.2578 - val_accuracy: 0.4338

Epoch 02751: val_loss did not improve from 1.25203
Epoch 2752/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4363 - val_loss: 1.2554 - val_accuracy: 0.4354

Epoch 02752: val_loss did not improve from 1.25203
Epoch 2753/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4307 - val_loss: 1.2574 - val_accuracy: 0.4330

Epoch 02753: val_loss did not improve from 1.25203
Epoch 2754/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4294 - val_loss: 1.2536 - val_accuracy: 0.4282

Epoch 02754: val_loss did not improve from 1.25203
Epoch 2755/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4338 - val_loss: 1.2580 - val_accuracy: 0.4362

Epoch 02755: val_loss did not improve from 1.25203
Epoch 2756/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4326 - val_loss: 1.2565 - val_accuracy: 0.4338

Epoch 02756: val_loss did not improve from 1.25203
Epoch 2757/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4272 - val_loss: 1.2568 - val_accuracy: 0.4338

Epoch 02757: val_loss did not improve from 1.25203
Epoch 2758/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4344 - val_loss: 1.2565 - val_accuracy: 0.4290

Epoch 02758: val_loss did not improve from 1.25203
Epoch 2759/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4337 - val_loss: 1.2568 - val_accuracy: 0.4290

Epoch 02759: val_loss did not improve from 1.25203
Epoch 2760/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4340 - val_loss: 1.2555 - val_accuracy: 0.4322

Epoch 02760: val_loss did not improve from 1.25203
Epoch 2761/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4334 - val_loss: 1.2569 - val_accuracy: 0.4322

Epoch 02761: val_loss did not improve from 1.25203
Epoch 2762/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4357 - val_loss: 1.2573 - val_accuracy: 0.4298

Epoch 02762: val_loss did not improve from 1.25203
Epoch 2763/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4287 - val_loss: 1.2583 - val_accuracy: 0.4274

Epoch 02763: val_loss did not improve from 1.25203
Epoch 2764/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4313 - val_loss: 1.2550 - val_accuracy: 0.4346

Epoch 02764: val_loss did not improve from 1.25203
Epoch 2765/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4331 - val_loss: 1.2588 - val_accuracy: 0.4330

Epoch 02765: val_loss did not improve from 1.25203
Epoch 2766/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4329 - val_loss: 1.2600 - val_accuracy: 0.4195

Epoch 02766: val_loss did not improve from 1.25203
Epoch 2767/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4336 - val_loss: 1.2556 - val_accuracy: 0.4330

Epoch 02767: val_loss did not improve from 1.25203
Epoch 2768/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4330 - val_loss: 1.2542 - val_accuracy: 0.4370

Epoch 02768: val_loss did not improve from 1.25203
Epoch 2769/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4336 - val_loss: 1.2561 - val_accuracy: 0.4378

Epoch 02769: val_loss did not improve from 1.25203
Epoch 2770/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4330 - val_loss: 1.2571 - val_accuracy: 0.4298

Epoch 02770: val_loss did not improve from 1.25203
Epoch 2771/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4340 - val_loss: 1.2558 - val_accuracy: 0.4370

Epoch 02771: val_loss did not improve from 1.25203
Epoch 2772/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4308 - val_loss: 1.2568 - val_accuracy: 0.4322

Epoch 02772: val_loss did not improve from 1.25203
Epoch 2773/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4357 - val_loss: 1.2557 - val_accuracy: 0.4370

Epoch 02773: val_loss did not improve from 1.25203
Epoch 2774/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4331 - val_loss: 1.2564 - val_accuracy: 0.4234

Epoch 02774: val_loss did not improve from 1.25203
Epoch 2775/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4367 - val_loss: 1.2563 - val_accuracy: 0.4242

Epoch 02775: val_loss did not improve from 1.25203
Epoch 2776/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4351 - val_loss: 1.2561 - val_accuracy: 0.4242

Epoch 02776: val_loss did not improve from 1.25203
Epoch 2777/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4327 - val_loss: 1.2545 - val_accuracy: 0.4298

Epoch 02777: val_loss did not improve from 1.25203
Epoch 2778/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4321 - val_loss: 1.2560 - val_accuracy: 0.4298

Epoch 02778: val_loss did not improve from 1.25203
Epoch 2779/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4316 - val_loss: 1.2593 - val_accuracy: 0.4290

Epoch 02779: val_loss did not improve from 1.25203
Epoch 2780/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4326 - val_loss: 1.2556 - val_accuracy: 0.4410

Epoch 02780: val_loss did not improve from 1.25203
Epoch 2781/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4311 - val_loss: 1.2593 - val_accuracy: 0.4386

Epoch 02781: val_loss did not improve from 1.25203
Epoch 2782/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4314 - val_loss: 1.2539 - val_accuracy: 0.4338

Epoch 02782: val_loss did not improve from 1.25203
Epoch 2783/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4315 - val_loss: 1.2562 - val_accuracy: 0.4370

Epoch 02783: val_loss did not improve from 1.25203
Epoch 2784/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4333 - val_loss: 1.2572 - val_accuracy: 0.4322

Epoch 02784: val_loss did not improve from 1.25203
Epoch 2785/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4325 - val_loss: 1.2573 - val_accuracy: 0.4466

Epoch 02785: val_loss did not improve from 1.25203
Epoch 2786/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4314 - val_loss: 1.2544 - val_accuracy: 0.4330

Epoch 02786: val_loss did not improve from 1.25203
Epoch 2787/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4312 - val_loss: 1.2624 - val_accuracy: 0.4314

Epoch 02787: val_loss did not improve from 1.25203
Epoch 2788/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4329 - val_loss: 1.2622 - val_accuracy: 0.4290

Epoch 02788: val_loss did not improve from 1.25203
Epoch 2789/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4332 - val_loss: 1.2578 - val_accuracy: 0.4330

Epoch 02789: val_loss did not improve from 1.25203
Epoch 2790/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4325 - val_loss: 1.2604 - val_accuracy: 0.4298

Epoch 02790: val_loss did not improve from 1.25203
Epoch 2791/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4349 - val_loss: 1.2538 - val_accuracy: 0.4274

Epoch 02791: val_loss did not improve from 1.25203
Epoch 2792/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4404 - val_loss: 1.2565 - val_accuracy: 0.4346

Epoch 02792: val_loss did not improve from 1.25203
Epoch 2793/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4341 - val_loss: 1.2545 - val_accuracy: 0.4322

Epoch 02793: val_loss did not improve from 1.25203
Epoch 2794/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4339 - val_loss: 1.2575 - val_accuracy: 0.4346

Epoch 02794: val_loss did not improve from 1.25203
Epoch 2795/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4388 - val_loss: 1.2548 - val_accuracy: 0.4362

Epoch 02795: val_loss did not improve from 1.25203
Epoch 2796/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4340 - val_loss: 1.2562 - val_accuracy: 0.4338

Epoch 02796: val_loss did not improve from 1.25203
Epoch 2797/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4365 - val_loss: 1.2531 - val_accuracy: 0.4266

Epoch 02797: val_loss did not improve from 1.25203
Epoch 2798/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4341 - val_loss: 1.2564 - val_accuracy: 0.4362

Epoch 02798: val_loss did not improve from 1.25203
Epoch 2799/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4364 - val_loss: 1.2625 - val_accuracy: 0.4250

Epoch 02799: val_loss did not improve from 1.25203
Epoch 2800/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4344 - val_loss: 1.2569 - val_accuracy: 0.4171

Epoch 02800: val_loss did not improve from 1.25203
Epoch 2801/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4318 - val_loss: 1.2557 - val_accuracy: 0.4386

Epoch 02801: val_loss did not improve from 1.25203
Epoch 2802/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4337 - val_loss: 1.2617 - val_accuracy: 0.4306

Epoch 02802: val_loss did not improve from 1.25203
Epoch 2803/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4371 - val_loss: 1.2568 - val_accuracy: 0.4386

Epoch 02803: val_loss did not improve from 1.25203
Epoch 2804/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4332 - val_loss: 1.2569 - val_accuracy: 0.4274

Epoch 02804: val_loss did not improve from 1.25203
Epoch 2805/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4342 - val_loss: 1.2551 - val_accuracy: 0.4386

Epoch 02805: val_loss did not improve from 1.25203
Epoch 2806/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4372 - val_loss: 1.2589 - val_accuracy: 0.4290

Epoch 02806: val_loss did not improve from 1.25203
Epoch 2807/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4343 - val_loss: 1.2576 - val_accuracy: 0.4290

Epoch 02807: val_loss did not improve from 1.25203
Epoch 2808/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4324 - val_loss: 1.2573 - val_accuracy: 0.4330

Epoch 02808: val_loss did not improve from 1.25203
Epoch 2809/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4334 - val_loss: 1.2595 - val_accuracy: 0.4290

Epoch 02809: val_loss did not improve from 1.25203
Epoch 2810/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4361 - val_loss: 1.2562 - val_accuracy: 0.4370

Epoch 02810: val_loss did not improve from 1.25203
Epoch 2811/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4355 - val_loss: 1.2544 - val_accuracy: 0.4274

Epoch 02811: val_loss did not improve from 1.25203
Epoch 2812/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4322 - val_loss: 1.2558 - val_accuracy: 0.4354

Epoch 02812: val_loss did not improve from 1.25203
Epoch 2813/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4272 - val_loss: 1.2610 - val_accuracy: 0.4226

Epoch 02813: val_loss did not improve from 1.25203
Epoch 2814/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4318 - val_loss: 1.2551 - val_accuracy: 0.4306

Epoch 02814: val_loss did not improve from 1.25203
Epoch 2815/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4319 - val_loss: 1.2543 - val_accuracy: 0.4354

Epoch 02815: val_loss did not improve from 1.25203
Epoch 2816/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4373 - val_loss: 1.2614 - val_accuracy: 0.4211

Epoch 02816: val_loss did not improve from 1.25203
Epoch 2817/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4311 - val_loss: 1.2582 - val_accuracy: 0.4219

Epoch 02817: val_loss did not improve from 1.25203
Epoch 2818/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4334 - val_loss: 1.2595 - val_accuracy: 0.4338

Epoch 02818: val_loss did not improve from 1.25203
Epoch 2819/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4303 - val_loss: 1.2551 - val_accuracy: 0.4290

Epoch 02819: val_loss did not improve from 1.25203
Epoch 2820/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4334 - val_loss: 1.2547 - val_accuracy: 0.4346

Epoch 02820: val_loss did not improve from 1.25203
Epoch 2821/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4328 - val_loss: 1.2563 - val_accuracy: 0.4298

Epoch 02821: val_loss did not improve from 1.25203
Epoch 2822/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4283 - val_loss: 1.2535 - val_accuracy: 0.4290

Epoch 02822: val_loss did not improve from 1.25203
Epoch 2823/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4338 - val_loss: 1.2604 - val_accuracy: 0.4298

Epoch 02823: val_loss did not improve from 1.25203
Epoch 2824/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4337 - val_loss: 1.2554 - val_accuracy: 0.4322

Epoch 02824: val_loss did not improve from 1.25203
Epoch 2825/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4335 - val_loss: 1.2521 - val_accuracy: 0.4338

Epoch 02825: val_loss did not improve from 1.25203
Epoch 2826/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4319 - val_loss: 1.2554 - val_accuracy: 0.4370

Epoch 02826: val_loss did not improve from 1.25203
Epoch 2827/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4330 - val_loss: 1.2567 - val_accuracy: 0.4314

Epoch 02827: val_loss did not improve from 1.25203
Epoch 2828/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4373 - val_loss: 1.2582 - val_accuracy: 0.4298

Epoch 02828: val_loss did not improve from 1.25203
Epoch 2829/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4259 - val_loss: 1.2722 - val_accuracy: 0.4211

Epoch 02829: val_loss did not improve from 1.25203
Epoch 2830/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4295 - val_loss: 1.2564 - val_accuracy: 0.4282

Epoch 02830: val_loss did not improve from 1.25203
Epoch 2831/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4284 - val_loss: 1.2534 - val_accuracy: 0.4306

Epoch 02831: val_loss did not improve from 1.25203
Epoch 2832/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4328 - val_loss: 1.2567 - val_accuracy: 0.4298

Epoch 02832: val_loss did not improve from 1.25203
Epoch 2833/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4342 - val_loss: 1.2565 - val_accuracy: 0.4322

Epoch 02833: val_loss did not improve from 1.25203
Epoch 2834/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4365 - val_loss: 1.2627 - val_accuracy: 0.4258

Epoch 02834: val_loss did not improve from 1.25203
Epoch 2835/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4297 - val_loss: 1.2603 - val_accuracy: 0.4354

Epoch 02835: val_loss did not improve from 1.25203
Epoch 2836/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4276 - val_loss: 1.2577 - val_accuracy: 0.4298

Epoch 02836: val_loss did not improve from 1.25203
Epoch 2837/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4327 - val_loss: 1.2552 - val_accuracy: 0.4394

Epoch 02837: val_loss did not improve from 1.25203
Epoch 2838/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4327 - val_loss: 1.2580 - val_accuracy: 0.4346

Epoch 02838: val_loss did not improve from 1.25203
Epoch 2839/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4292 - val_loss: 1.2562 - val_accuracy: 0.4346

Epoch 02839: val_loss did not improve from 1.25203
Epoch 2840/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4343 - val_loss: 1.2611 - val_accuracy: 0.4370

Epoch 02840: val_loss did not improve from 1.25203
Epoch 2841/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4350 - val_loss: 1.2566 - val_accuracy: 0.4338

Epoch 02841: val_loss did not improve from 1.25203
Epoch 2842/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4335 - val_loss: 1.2551 - val_accuracy: 0.4306

Epoch 02842: val_loss did not improve from 1.25203
Epoch 2843/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4327 - val_loss: 1.2587 - val_accuracy: 0.4346

Epoch 02843: val_loss did not improve from 1.25203
Epoch 2844/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4346 - val_loss: 1.2552 - val_accuracy: 0.4362

Epoch 02844: val_loss did not improve from 1.25203
Epoch 2845/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4325 - val_loss: 1.2576 - val_accuracy: 0.4362

Epoch 02845: val_loss did not improve from 1.25203
Epoch 2846/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4334 - val_loss: 1.2566 - val_accuracy: 0.4322

Epoch 02846: val_loss did not improve from 1.25203
Epoch 2847/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4333 - val_loss: 1.2584 - val_accuracy: 0.4282

Epoch 02847: val_loss did not improve from 1.25203
Epoch 2848/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4342 - val_loss: 1.2557 - val_accuracy: 0.4354

Epoch 02848: val_loss did not improve from 1.25203
Epoch 2849/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4352 - val_loss: 1.2570 - val_accuracy: 0.4266

Epoch 02849: val_loss did not improve from 1.25203
Epoch 2850/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4366 - val_loss: 1.2584 - val_accuracy: 0.4346

Epoch 02850: val_loss did not improve from 1.25203
Epoch 2851/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4333 - val_loss: 1.2554 - val_accuracy: 0.4274

Epoch 02851: val_loss did not improve from 1.25203
Epoch 2852/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4282 - val_loss: 1.2591 - val_accuracy: 0.4258

Epoch 02852: val_loss did not improve from 1.25203
Epoch 2853/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4236 - val_loss: 1.2567 - val_accuracy: 0.4314

Epoch 02853: val_loss did not improve from 1.25203
Epoch 2854/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4314 - val_loss: 1.2555 - val_accuracy: 0.4410

Epoch 02854: val_loss did not improve from 1.25203
Epoch 2855/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4265 - val_loss: 1.2606 - val_accuracy: 0.4203

Epoch 02855: val_loss did not improve from 1.25203
Epoch 2856/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4327 - val_loss: 1.2605 - val_accuracy: 0.4330

Epoch 02856: val_loss did not improve from 1.25203
Epoch 2857/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4334 - val_loss: 1.2546 - val_accuracy: 0.4274

Epoch 02857: val_loss did not improve from 1.25203
Epoch 2858/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4357 - val_loss: 1.2570 - val_accuracy: 0.4322

Epoch 02858: val_loss did not improve from 1.25203
Epoch 2859/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4330 - val_loss: 1.2561 - val_accuracy: 0.4370

Epoch 02859: val_loss did not improve from 1.25203
Epoch 2860/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4331 - val_loss: 1.2558 - val_accuracy: 0.4290

Epoch 02860: val_loss did not improve from 1.25203
Epoch 2861/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4318 - val_loss: 1.2566 - val_accuracy: 0.4290

Epoch 02861: val_loss did not improve from 1.25203
Epoch 2862/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4343 - val_loss: 1.2558 - val_accuracy: 0.4258

Epoch 02862: val_loss did not improve from 1.25203
Epoch 2863/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4327 - val_loss: 1.2583 - val_accuracy: 0.4242

Epoch 02863: val_loss did not improve from 1.25203
Epoch 2864/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4340 - val_loss: 1.2565 - val_accuracy: 0.4234

Epoch 02864: val_loss did not improve from 1.25203
Epoch 2865/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4333 - val_loss: 1.2575 - val_accuracy: 0.4314

Epoch 02865: val_loss did not improve from 1.25203
Epoch 2866/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4324 - val_loss: 1.2586 - val_accuracy: 0.4298

Epoch 02866: val_loss did not improve from 1.25203
Epoch 2867/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4351 - val_loss: 1.2582 - val_accuracy: 0.4266

Epoch 02867: val_loss did not improve from 1.25203
Epoch 2868/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4373 - val_loss: 1.2568 - val_accuracy: 0.4450

Epoch 02868: val_loss did not improve from 1.25203
Epoch 2869/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4329 - val_loss: 1.2555 - val_accuracy: 0.4250

Epoch 02869: val_loss did not improve from 1.25203
Epoch 2870/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4358 - val_loss: 1.2561 - val_accuracy: 0.4378

Epoch 02870: val_loss did not improve from 1.25203
Epoch 2871/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4301 - val_loss: 1.2563 - val_accuracy: 0.4378

Epoch 02871: val_loss did not improve from 1.25203
Epoch 2872/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4342 - val_loss: 1.2615 - val_accuracy: 0.4306

Epoch 02872: val_loss did not improve from 1.25203
Epoch 2873/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4303 - val_loss: 1.2549 - val_accuracy: 0.4314

Epoch 02873: val_loss did not improve from 1.25203
Epoch 2874/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4321 - val_loss: 1.2593 - val_accuracy: 0.4187

Epoch 02874: val_loss did not improve from 1.25203
Epoch 2875/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4315 - val_loss: 1.2576 - val_accuracy: 0.4362

Epoch 02875: val_loss did not improve from 1.25203
Epoch 2876/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4334 - val_loss: 1.2540 - val_accuracy: 0.4274

Epoch 02876: val_loss did not improve from 1.25203
Epoch 2877/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4328 - val_loss: 1.2546 - val_accuracy: 0.4266

Epoch 02877: val_loss did not improve from 1.25203
Epoch 2878/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4334 - val_loss: 1.2537 - val_accuracy: 0.4346

Epoch 02878: val_loss did not improve from 1.25203
Epoch 2879/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4297 - val_loss: 1.2682 - val_accuracy: 0.4187

Epoch 02879: val_loss did not improve from 1.25203
Epoch 2880/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4326 - val_loss: 1.2543 - val_accuracy: 0.4354

Epoch 02880: val_loss did not improve from 1.25203
Epoch 2881/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4333 - val_loss: 1.2549 - val_accuracy: 0.4402

Epoch 02881: val_loss did not improve from 1.25203
Epoch 2882/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4356 - val_loss: 1.2597 - val_accuracy: 0.4314

Epoch 02882: val_loss did not improve from 1.25203
Epoch 2883/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4340 - val_loss: 1.2593 - val_accuracy: 0.4362

Epoch 02883: val_loss did not improve from 1.25203
Epoch 2884/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4321 - val_loss: 1.2582 - val_accuracy: 0.4394

Epoch 02884: val_loss did not improve from 1.25203
Epoch 2885/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4372 - val_loss: 1.2581 - val_accuracy: 0.4314

Epoch 02885: val_loss did not improve from 1.25203
Epoch 2886/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4374 - val_loss: 1.2546 - val_accuracy: 0.4362

Epoch 02886: val_loss did not improve from 1.25203
Epoch 2887/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4345 - val_loss: 1.2544 - val_accuracy: 0.4306

Epoch 02887: val_loss did not improve from 1.25203
Epoch 2888/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4367 - val_loss: 1.2575 - val_accuracy: 0.4282

Epoch 02888: val_loss did not improve from 1.25203
Epoch 2889/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4390 - val_loss: 1.2559 - val_accuracy: 0.4378

Epoch 02889: val_loss did not improve from 1.25203
Epoch 2890/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4341 - val_loss: 1.2562 - val_accuracy: 0.4346

Epoch 02890: val_loss did not improve from 1.25203
Epoch 2891/10000
12/12 - 0s - loss: 1.2519 - accuracy: 0.4369 - val_loss: 1.2535 - val_accuracy: 0.4354

Epoch 02891: val_loss did not improve from 1.25203
Epoch 2892/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4348 - val_loss: 1.2581 - val_accuracy: 0.4306

Epoch 02892: val_loss did not improve from 1.25203
Epoch 2893/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4324 - val_loss: 1.2540 - val_accuracy: 0.4386

Epoch 02893: val_loss did not improve from 1.25203
Epoch 2894/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4342 - val_loss: 1.2551 - val_accuracy: 0.4330

Epoch 02894: val_loss did not improve from 1.25203
Epoch 2895/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4386 - val_loss: 1.2535 - val_accuracy: 0.4338

Epoch 02895: val_loss did not improve from 1.25203
Epoch 2896/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4293 - val_loss: 1.2624 - val_accuracy: 0.4258

Epoch 02896: val_loss did not improve from 1.25203
Epoch 2897/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4367 - val_loss: 1.2567 - val_accuracy: 0.4338

Epoch 02897: val_loss did not improve from 1.25203
Epoch 2898/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4354 - val_loss: 1.2572 - val_accuracy: 0.4322

Epoch 02898: val_loss did not improve from 1.25203
Epoch 2899/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4355 - val_loss: 1.2538 - val_accuracy: 0.4386

Epoch 02899: val_loss did not improve from 1.25203
Epoch 2900/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4378 - val_loss: 1.2550 - val_accuracy: 0.4346

Epoch 02900: val_loss did not improve from 1.25203
Epoch 2901/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4330 - val_loss: 1.2569 - val_accuracy: 0.4330

Epoch 02901: val_loss did not improve from 1.25203
Epoch 2902/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4313 - val_loss: 1.2549 - val_accuracy: 0.4362

Epoch 02902: val_loss did not improve from 1.25203
Epoch 2903/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4316 - val_loss: 1.2603 - val_accuracy: 0.4298

Epoch 02903: val_loss did not improve from 1.25203
Epoch 2904/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4327 - val_loss: 1.2555 - val_accuracy: 0.4410

Epoch 02904: val_loss did not improve from 1.25203
Epoch 2905/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4346 - val_loss: 1.2537 - val_accuracy: 0.4274

Epoch 02905: val_loss did not improve from 1.25203
Epoch 2906/10000
12/12 - 0s - loss: 1.2518 - accuracy: 0.4366 - val_loss: 1.2524 - val_accuracy: 0.4394

Epoch 02906: val_loss did not improve from 1.25203
Epoch 2907/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4380 - val_loss: 1.2537 - val_accuracy: 0.4330

Epoch 02907: val_loss did not improve from 1.25203
Epoch 2908/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4334 - val_loss: 1.2615 - val_accuracy: 0.4234

Epoch 02908: val_loss did not improve from 1.25203
Epoch 2909/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4300 - val_loss: 1.2558 - val_accuracy: 0.4362

Epoch 02909: val_loss did not improve from 1.25203
Epoch 2910/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4375 - val_loss: 1.2571 - val_accuracy: 0.4346

Epoch 02910: val_loss did not improve from 1.25203
Epoch 2911/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4301 - val_loss: 1.2549 - val_accuracy: 0.4282

Epoch 02911: val_loss did not improve from 1.25203
Epoch 2912/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4379 - val_loss: 1.2534 - val_accuracy: 0.4338

Epoch 02912: val_loss did not improve from 1.25203
Epoch 2913/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4300 - val_loss: 1.2549 - val_accuracy: 0.4354

Epoch 02913: val_loss did not improve from 1.25203
Epoch 2914/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4353 - val_loss: 1.2629 - val_accuracy: 0.4250

Epoch 02914: val_loss did not improve from 1.25203
Epoch 2915/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4362 - val_loss: 1.2563 - val_accuracy: 0.4402

Epoch 02915: val_loss did not improve from 1.25203
Epoch 2916/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4355 - val_loss: 1.2535 - val_accuracy: 0.4290

Epoch 02916: val_loss did not improve from 1.25203
Epoch 2917/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4340 - val_loss: 1.2593 - val_accuracy: 0.4242

Epoch 02917: val_loss did not improve from 1.25203
Epoch 2918/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4316 - val_loss: 1.2540 - val_accuracy: 0.4394

Epoch 02918: val_loss did not improve from 1.25203
Epoch 2919/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4355 - val_loss: 1.2539 - val_accuracy: 0.4306

Epoch 02919: val_loss did not improve from 1.25203
Epoch 2920/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4356 - val_loss: 1.2563 - val_accuracy: 0.4410

Epoch 02920: val_loss did not improve from 1.25203
Epoch 2921/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4338 - val_loss: 1.2558 - val_accuracy: 0.4314

Epoch 02921: val_loss did not improve from 1.25203
Epoch 2922/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4364 - val_loss: 1.2567 - val_accuracy: 0.4354

Epoch 02922: val_loss did not improve from 1.25203
Epoch 2923/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4305 - val_loss: 1.2570 - val_accuracy: 0.4274

Epoch 02923: val_loss did not improve from 1.25203
Epoch 2924/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4320 - val_loss: 1.2550 - val_accuracy: 0.4354

Epoch 02924: val_loss did not improve from 1.25203
Epoch 2925/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4361 - val_loss: 1.2603 - val_accuracy: 0.4290

Epoch 02925: val_loss did not improve from 1.25203
Epoch 2926/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4335 - val_loss: 1.2579 - val_accuracy: 0.4274

Epoch 02926: val_loss did not improve from 1.25203
Epoch 2927/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4364 - val_loss: 1.2558 - val_accuracy: 0.4314

Epoch 02927: val_loss did not improve from 1.25203
Epoch 2928/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4335 - val_loss: 1.2554 - val_accuracy: 0.4338

Epoch 02928: val_loss did not improve from 1.25203
Epoch 2929/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4352 - val_loss: 1.2537 - val_accuracy: 0.4314

Epoch 02929: val_loss did not improve from 1.25203
Epoch 2930/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4368 - val_loss: 1.2556 - val_accuracy: 0.4378

Epoch 02930: val_loss did not improve from 1.25203
Epoch 2931/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4345 - val_loss: 1.2608 - val_accuracy: 0.4330

Epoch 02931: val_loss did not improve from 1.25203
Epoch 2932/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4325 - val_loss: 1.2562 - val_accuracy: 0.4274

Epoch 02932: val_loss did not improve from 1.25203
Epoch 2933/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4318 - val_loss: 1.2541 - val_accuracy: 0.4298

Epoch 02933: val_loss did not improve from 1.25203
Epoch 2934/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4392 - val_loss: 1.2554 - val_accuracy: 0.4354

Epoch 02934: val_loss did not improve from 1.25203
Epoch 2935/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4361 - val_loss: 1.2599 - val_accuracy: 0.4346

Epoch 02935: val_loss did not improve from 1.25203
Epoch 2936/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4354 - val_loss: 1.2535 - val_accuracy: 0.4378

Epoch 02936: val_loss did not improve from 1.25203
Epoch 2937/10000
12/12 - 0s - loss: 1.2519 - accuracy: 0.4331 - val_loss: 1.2570 - val_accuracy: 0.4322

Epoch 02937: val_loss did not improve from 1.25203
Epoch 2938/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4359 - val_loss: 1.2549 - val_accuracy: 0.4314

Epoch 02938: val_loss did not improve from 1.25203
Epoch 2939/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4347 - val_loss: 1.2553 - val_accuracy: 0.4290

Epoch 02939: val_loss did not improve from 1.25203
Epoch 2940/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4317 - val_loss: 1.2531 - val_accuracy: 0.4370

Epoch 02940: val_loss did not improve from 1.25203
Epoch 2941/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4307 - val_loss: 1.2530 - val_accuracy: 0.4394

Epoch 02941: val_loss did not improve from 1.25203
Epoch 2942/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4376 - val_loss: 1.2536 - val_accuracy: 0.4338

Epoch 02942: val_loss did not improve from 1.25203
Epoch 2943/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4365 - val_loss: 1.2557 - val_accuracy: 0.4370

Epoch 02943: val_loss did not improve from 1.25203
Epoch 2944/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4317 - val_loss: 1.2540 - val_accuracy: 0.4434

Epoch 02944: val_loss did not improve from 1.25203
Epoch 2945/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4358 - val_loss: 1.2534 - val_accuracy: 0.4338

Epoch 02945: val_loss did not improve from 1.25203
Epoch 2946/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4344 - val_loss: 1.2582 - val_accuracy: 0.4314

Epoch 02946: val_loss did not improve from 1.25203
Epoch 2947/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4343 - val_loss: 1.2565 - val_accuracy: 0.4354

Epoch 02947: val_loss did not improve from 1.25203
Epoch 02947: early stopping
*************************** Fold #: 7 ***************************
Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_264 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_265 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_266 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_267 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6117 - accuracy: 0.2465 - val_loss: 1.6060 - val_accuracy: 0.2648

Epoch 00001: val_loss improved from inf to 1.60604, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2/10000
12/12 - 0s - loss: 1.6010 - accuracy: 0.2620 - val_loss: 1.5956 - val_accuracy: 0.2544

Epoch 00002: val_loss improved from 1.60604 to 1.59556, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 3/10000
12/12 - 0s - loss: 1.5903 - accuracy: 0.2650 - val_loss: 1.5832 - val_accuracy: 0.2671

Epoch 00003: val_loss improved from 1.59556 to 1.58323, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 4/10000
12/12 - 0s - loss: 1.5766 - accuracy: 0.2877 - val_loss: 1.5671 - val_accuracy: 0.2831

Epoch 00004: val_loss improved from 1.58323 to 1.56713, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 5/10000
12/12 - 0s - loss: 1.5600 - accuracy: 0.2931 - val_loss: 1.5492 - val_accuracy: 0.2831

Epoch 00005: val_loss improved from 1.56713 to 1.54919, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 6/10000
12/12 - 0s - loss: 1.5406 - accuracy: 0.3108 - val_loss: 1.5278 - val_accuracy: 0.3022

Epoch 00006: val_loss improved from 1.54919 to 1.52782, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 7/10000
12/12 - 0s - loss: 1.5180 - accuracy: 0.3162 - val_loss: 1.5018 - val_accuracy: 0.2967

Epoch 00007: val_loss improved from 1.52782 to 1.50176, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 8/10000
12/12 - 0s - loss: 1.4917 - accuracy: 0.3342 - val_loss: 1.4744 - val_accuracy: 0.3413

Epoch 00008: val_loss improved from 1.50176 to 1.47439, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 9/10000
12/12 - 0s - loss: 1.4642 - accuracy: 0.3506 - val_loss: 1.4445 - val_accuracy: 0.3485

Epoch 00009: val_loss improved from 1.47439 to 1.44452, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 10/10000
12/12 - 0s - loss: 1.4357 - accuracy: 0.3539 - val_loss: 1.4172 - val_accuracy: 0.3549

Epoch 00010: val_loss improved from 1.44452 to 1.41723, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 11/10000
12/12 - 0s - loss: 1.4075 - accuracy: 0.3596 - val_loss: 1.3887 - val_accuracy: 0.3573

Epoch 00011: val_loss improved from 1.41723 to 1.38869, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 12/10000
12/12 - 0s - loss: 1.3843 - accuracy: 0.3639 - val_loss: 1.3733 - val_accuracy: 0.3876

Epoch 00012: val_loss improved from 1.38869 to 1.37326, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 13/10000
12/12 - 0s - loss: 1.3672 - accuracy: 0.3829 - val_loss: 1.3537 - val_accuracy: 0.3844

Epoch 00013: val_loss improved from 1.37326 to 1.35369, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 14/10000
12/12 - 0s - loss: 1.3567 - accuracy: 0.3807 - val_loss: 1.3604 - val_accuracy: 0.3915

Epoch 00014: val_loss did not improve from 1.35369
Epoch 15/10000
12/12 - 0s - loss: 1.3510 - accuracy: 0.3823 - val_loss: 1.3377 - val_accuracy: 0.4011

Epoch 00015: val_loss improved from 1.35369 to 1.33766, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 16/10000
12/12 - 0s - loss: 1.3433 - accuracy: 0.3863 - val_loss: 1.3344 - val_accuracy: 0.3900

Epoch 00016: val_loss improved from 1.33766 to 1.33437, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 17/10000
12/12 - 0s - loss: 1.3443 - accuracy: 0.3799 - val_loss: 1.3488 - val_accuracy: 0.3764

Epoch 00017: val_loss did not improve from 1.33437
Epoch 18/10000
12/12 - 0s - loss: 1.3430 - accuracy: 0.3843 - val_loss: 1.3305 - val_accuracy: 0.4035

Epoch 00018: val_loss improved from 1.33437 to 1.33053, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 19/10000
12/12 - 0s - loss: 1.3422 - accuracy: 0.3962 - val_loss: 1.3272 - val_accuracy: 0.4171

Epoch 00019: val_loss improved from 1.33053 to 1.32717, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 20/10000
12/12 - 0s - loss: 1.3376 - accuracy: 0.3897 - val_loss: 1.3273 - val_accuracy: 0.3876

Epoch 00020: val_loss did not improve from 1.32717
Epoch 21/10000
12/12 - 0s - loss: 1.3374 - accuracy: 0.3855 - val_loss: 1.3336 - val_accuracy: 0.3947

Epoch 00021: val_loss did not improve from 1.32717
Epoch 22/10000
12/12 - 0s - loss: 1.3356 - accuracy: 0.3893 - val_loss: 1.3258 - val_accuracy: 0.4059

Epoch 00022: val_loss improved from 1.32717 to 1.32581, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 23/10000
12/12 - 0s - loss: 1.3348 - accuracy: 0.3925 - val_loss: 1.3247 - val_accuracy: 0.4027

Epoch 00023: val_loss improved from 1.32581 to 1.32470, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 24/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3920 - val_loss: 1.3282 - val_accuracy: 0.3995

Epoch 00024: val_loss did not improve from 1.32470
Epoch 25/10000
12/12 - 0s - loss: 1.3346 - accuracy: 0.3892 - val_loss: 1.3277 - val_accuracy: 0.3915

Epoch 00025: val_loss did not improve from 1.32470
Epoch 26/10000
12/12 - 0s - loss: 1.3341 - accuracy: 0.3860 - val_loss: 1.3269 - val_accuracy: 0.3892

Epoch 00026: val_loss did not improve from 1.32470
Epoch 27/10000
12/12 - 0s - loss: 1.3339 - accuracy: 0.3801 - val_loss: 1.3245 - val_accuracy: 0.3892

Epoch 00027: val_loss improved from 1.32470 to 1.32451, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 28/10000
12/12 - 0s - loss: 1.3352 - accuracy: 0.3847 - val_loss: 1.3261 - val_accuracy: 0.4059

Epoch 00028: val_loss did not improve from 1.32451
Epoch 29/10000
12/12 - 0s - loss: 1.3360 - accuracy: 0.3903 - val_loss: 1.3303 - val_accuracy: 0.4003

Epoch 00029: val_loss did not improve from 1.32451
Epoch 30/10000
12/12 - 0s - loss: 1.3334 - accuracy: 0.3909 - val_loss: 1.3237 - val_accuracy: 0.3971

Epoch 00030: val_loss improved from 1.32451 to 1.32370, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 31/10000
12/12 - 0s - loss: 1.3332 - accuracy: 0.3888 - val_loss: 1.3272 - val_accuracy: 0.4003

Epoch 00031: val_loss did not improve from 1.32370
Epoch 32/10000
12/12 - 0s - loss: 1.3330 - accuracy: 0.3914 - val_loss: 1.3257 - val_accuracy: 0.4075

Epoch 00032: val_loss did not improve from 1.32370
Epoch 33/10000
12/12 - 0s - loss: 1.3346 - accuracy: 0.3941 - val_loss: 1.3225 - val_accuracy: 0.3955

Epoch 00033: val_loss improved from 1.32370 to 1.32255, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 34/10000
12/12 - 0s - loss: 1.3364 - accuracy: 0.3893 - val_loss: 1.3371 - val_accuracy: 0.3915

Epoch 00034: val_loss did not improve from 1.32255
Epoch 35/10000
12/12 - 0s - loss: 1.3350 - accuracy: 0.3907 - val_loss: 1.3218 - val_accuracy: 0.4099

Epoch 00035: val_loss improved from 1.32255 to 1.32179, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 36/10000
12/12 - 0s - loss: 1.3326 - accuracy: 0.3920 - val_loss: 1.3224 - val_accuracy: 0.4099

Epoch 00036: val_loss did not improve from 1.32179
Epoch 37/10000
12/12 - 0s - loss: 1.3318 - accuracy: 0.3894 - val_loss: 1.3233 - val_accuracy: 0.4043

Epoch 00037: val_loss did not improve from 1.32179
Epoch 38/10000
12/12 - 0s - loss: 1.3316 - accuracy: 0.3900 - val_loss: 1.3207 - val_accuracy: 0.4043

Epoch 00038: val_loss improved from 1.32179 to 1.32074, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 39/10000
12/12 - 0s - loss: 1.3350 - accuracy: 0.3903 - val_loss: 1.3282 - val_accuracy: 0.3979

Epoch 00039: val_loss did not improve from 1.32074
Epoch 40/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3894 - val_loss: 1.3256 - val_accuracy: 0.4099

Epoch 00040: val_loss did not improve from 1.32074
Epoch 41/10000
12/12 - 0s - loss: 1.3318 - accuracy: 0.3931 - val_loss: 1.3215 - val_accuracy: 0.4107

Epoch 00041: val_loss did not improve from 1.32074
Epoch 42/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3893 - val_loss: 1.3276 - val_accuracy: 0.4003

Epoch 00042: val_loss did not improve from 1.32074
Epoch 43/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3866 - val_loss: 1.3236 - val_accuracy: 0.3939

Epoch 00043: val_loss did not improve from 1.32074
Epoch 44/10000
12/12 - 0s - loss: 1.3311 - accuracy: 0.3955 - val_loss: 1.3241 - val_accuracy: 0.4099

Epoch 00044: val_loss did not improve from 1.32074
Epoch 45/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3916 - val_loss: 1.3211 - val_accuracy: 0.4075

Epoch 00045: val_loss did not improve from 1.32074
Epoch 46/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3907 - val_loss: 1.3279 - val_accuracy: 0.4059

Epoch 00046: val_loss did not improve from 1.32074
Epoch 47/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3938 - val_loss: 1.3190 - val_accuracy: 0.4163

Epoch 00047: val_loss improved from 1.32074 to 1.31899, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 48/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3932 - val_loss: 1.3236 - val_accuracy: 0.4019

Epoch 00048: val_loss did not improve from 1.31899
Epoch 49/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3846 - val_loss: 1.3216 - val_accuracy: 0.3955

Epoch 00049: val_loss did not improve from 1.31899
Epoch 50/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.3870 - val_loss: 1.3225 - val_accuracy: 0.4083

Epoch 00050: val_loss did not improve from 1.31899
Epoch 51/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3852 - val_loss: 1.3203 - val_accuracy: 0.4035

Epoch 00051: val_loss did not improve from 1.31899
Epoch 52/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3940 - val_loss: 1.3218 - val_accuracy: 0.4027

Epoch 00052: val_loss did not improve from 1.31899
Epoch 53/10000
12/12 - 0s - loss: 1.3304 - accuracy: 0.3892 - val_loss: 1.3204 - val_accuracy: 0.4051

Epoch 00053: val_loss did not improve from 1.31899
Epoch 54/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3946 - val_loss: 1.3210 - val_accuracy: 0.4203

Epoch 00054: val_loss did not improve from 1.31899
Epoch 55/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3940 - val_loss: 1.3180 - val_accuracy: 0.4195

Epoch 00055: val_loss improved from 1.31899 to 1.31803, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 56/10000
12/12 - 0s - loss: 1.3335 - accuracy: 0.3920 - val_loss: 1.3341 - val_accuracy: 0.4035

Epoch 00056: val_loss did not improve from 1.31803
Epoch 57/10000
12/12 - 0s - loss: 1.3336 - accuracy: 0.3952 - val_loss: 1.3196 - val_accuracy: 0.4003

Epoch 00057: val_loss did not improve from 1.31803
Epoch 58/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3941 - val_loss: 1.3194 - val_accuracy: 0.4027

Epoch 00058: val_loss did not improve from 1.31803
Epoch 59/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3865 - val_loss: 1.3229 - val_accuracy: 0.4059

Epoch 00059: val_loss did not improve from 1.31803
Epoch 60/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3961 - val_loss: 1.3171 - val_accuracy: 0.4203

Epoch 00060: val_loss improved from 1.31803 to 1.31713, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 61/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3951 - val_loss: 1.3275 - val_accuracy: 0.4091

Epoch 00061: val_loss did not improve from 1.31713
Epoch 62/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3914 - val_loss: 1.3177 - val_accuracy: 0.4131

Epoch 00062: val_loss did not improve from 1.31713
Epoch 63/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3930 - val_loss: 1.3176 - val_accuracy: 0.4219

Epoch 00063: val_loss did not improve from 1.31713
Epoch 64/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3927 - val_loss: 1.3184 - val_accuracy: 0.4195

Epoch 00064: val_loss did not improve from 1.31713
Epoch 65/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3898 - val_loss: 1.3251 - val_accuracy: 0.4075

Epoch 00065: val_loss did not improve from 1.31713
Epoch 66/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3885 - val_loss: 1.3166 - val_accuracy: 0.3963

Epoch 00066: val_loss improved from 1.31713 to 1.31663, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 67/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3918 - val_loss: 1.3194 - val_accuracy: 0.4043

Epoch 00067: val_loss did not improve from 1.31663
Epoch 68/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3864 - val_loss: 1.3186 - val_accuracy: 0.4067

Epoch 00068: val_loss did not improve from 1.31663
Epoch 69/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3937 - val_loss: 1.3192 - val_accuracy: 0.4139

Epoch 00069: val_loss did not improve from 1.31663
Epoch 70/10000
12/12 - 0s - loss: 1.3282 - accuracy: 0.3929 - val_loss: 1.3217 - val_accuracy: 0.4115

Epoch 00070: val_loss did not improve from 1.31663
Epoch 71/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3883 - val_loss: 1.3194 - val_accuracy: 0.4011

Epoch 00071: val_loss did not improve from 1.31663
Epoch 72/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3914 - val_loss: 1.3175 - val_accuracy: 0.4211

Epoch 00072: val_loss did not improve from 1.31663
Epoch 73/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3916 - val_loss: 1.3192 - val_accuracy: 0.4067

Epoch 00073: val_loss did not improve from 1.31663
Epoch 74/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3905 - val_loss: 1.3179 - val_accuracy: 0.4131

Epoch 00074: val_loss did not improve from 1.31663
Epoch 75/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3935 - val_loss: 1.3222 - val_accuracy: 0.4163

Epoch 00075: val_loss did not improve from 1.31663
Epoch 76/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3883 - val_loss: 1.3211 - val_accuracy: 0.3955

Epoch 00076: val_loss did not improve from 1.31663
Epoch 77/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3891 - val_loss: 1.3188 - val_accuracy: 0.3963

Epoch 00077: val_loss did not improve from 1.31663
Epoch 78/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3901 - val_loss: 1.3168 - val_accuracy: 0.3995

Epoch 00078: val_loss did not improve from 1.31663
Epoch 79/10000
12/12 - 0s - loss: 1.3295 - accuracy: 0.3887 - val_loss: 1.3269 - val_accuracy: 0.4051

Epoch 00079: val_loss did not improve from 1.31663
Epoch 80/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3917 - val_loss: 1.3174 - val_accuracy: 0.4163

Epoch 00080: val_loss did not improve from 1.31663
Epoch 81/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3940 - val_loss: 1.3193 - val_accuracy: 0.4099

Epoch 00081: val_loss did not improve from 1.31663
Epoch 82/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3946 - val_loss: 1.3157 - val_accuracy: 0.4043

Epoch 00082: val_loss improved from 1.31663 to 1.31573, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 83/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3852 - val_loss: 1.3282 - val_accuracy: 0.3820

Epoch 00083: val_loss did not improve from 1.31573
Epoch 84/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3882 - val_loss: 1.3172 - val_accuracy: 0.4139

Epoch 00084: val_loss did not improve from 1.31573
Epoch 85/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3908 - val_loss: 1.3171 - val_accuracy: 0.4059

Epoch 00085: val_loss did not improve from 1.31573
Epoch 86/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3939 - val_loss: 1.3159 - val_accuracy: 0.4043

Epoch 00086: val_loss did not improve from 1.31573
Epoch 87/10000
12/12 - 0s - loss: 1.3273 - accuracy: 0.3954 - val_loss: 1.3159 - val_accuracy: 0.4043

Epoch 00087: val_loss did not improve from 1.31573
Epoch 88/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3897 - val_loss: 1.3160 - val_accuracy: 0.4019

Epoch 00088: val_loss did not improve from 1.31573
Epoch 89/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3914 - val_loss: 1.3289 - val_accuracy: 0.4051

Epoch 00089: val_loss did not improve from 1.31573
Epoch 90/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3939 - val_loss: 1.3176 - val_accuracy: 0.4091

Epoch 00090: val_loss did not improve from 1.31573
Epoch 91/10000
12/12 - 0s - loss: 1.3330 - accuracy: 0.3951 - val_loss: 1.3180 - val_accuracy: 0.3987

Epoch 00091: val_loss did not improve from 1.31573
Epoch 92/10000
12/12 - 0s - loss: 1.3311 - accuracy: 0.3926 - val_loss: 1.3270 - val_accuracy: 0.4091

Epoch 00092: val_loss did not improve from 1.31573
Epoch 93/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3958 - val_loss: 1.3188 - val_accuracy: 0.4107

Epoch 00093: val_loss did not improve from 1.31573
Epoch 94/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3946 - val_loss: 1.3151 - val_accuracy: 0.4011

Epoch 00094: val_loss improved from 1.31573 to 1.31505, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 95/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3918 - val_loss: 1.3211 - val_accuracy: 0.4107

Epoch 00095: val_loss did not improve from 1.31505
Epoch 96/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3912 - val_loss: 1.3181 - val_accuracy: 0.4187

Epoch 00096: val_loss did not improve from 1.31505
Epoch 97/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3939 - val_loss: 1.3138 - val_accuracy: 0.4067

Epoch 00097: val_loss improved from 1.31505 to 1.31380, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 98/10000
12/12 - 0s - loss: 1.3276 - accuracy: 0.3868 - val_loss: 1.3203 - val_accuracy: 0.3939

Epoch 00098: val_loss did not improve from 1.31380
Epoch 99/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3889 - val_loss: 1.3154 - val_accuracy: 0.4115

Epoch 00099: val_loss did not improve from 1.31380
Epoch 100/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3970 - val_loss: 1.3148 - val_accuracy: 0.4139

Epoch 00100: val_loss did not improve from 1.31380
Epoch 101/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.3935 - val_loss: 1.3256 - val_accuracy: 0.4155

Epoch 00101: val_loss did not improve from 1.31380
Epoch 102/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3916 - val_loss: 1.3156 - val_accuracy: 0.3963

Epoch 00102: val_loss did not improve from 1.31380
Epoch 103/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3953 - val_loss: 1.3142 - val_accuracy: 0.4019

Epoch 00103: val_loss did not improve from 1.31380
Epoch 104/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3886 - val_loss: 1.3222 - val_accuracy: 0.4115

Epoch 00104: val_loss did not improve from 1.31380
Epoch 105/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3889 - val_loss: 1.3242 - val_accuracy: 0.4131

Epoch 00105: val_loss did not improve from 1.31380
Epoch 106/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3953 - val_loss: 1.3150 - val_accuracy: 0.4147

Epoch 00106: val_loss did not improve from 1.31380
Epoch 107/10000
12/12 - 0s - loss: 1.3306 - accuracy: 0.3927 - val_loss: 1.3231 - val_accuracy: 0.4131

Epoch 00107: val_loss did not improve from 1.31380
Epoch 108/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3954 - val_loss: 1.3155 - val_accuracy: 0.4195

Epoch 00108: val_loss did not improve from 1.31380
Epoch 109/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3952 - val_loss: 1.3149 - val_accuracy: 0.4059

Epoch 00109: val_loss did not improve from 1.31380
Epoch 110/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3892 - val_loss: 1.3184 - val_accuracy: 0.4067

Epoch 00110: val_loss did not improve from 1.31380
Epoch 111/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3858 - val_loss: 1.3181 - val_accuracy: 0.4051

Epoch 00111: val_loss did not improve from 1.31380
Epoch 112/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3935 - val_loss: 1.3156 - val_accuracy: 0.4123

Epoch 00112: val_loss did not improve from 1.31380
Epoch 113/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3921 - val_loss: 1.3176 - val_accuracy: 0.4123

Epoch 00113: val_loss did not improve from 1.31380
Epoch 114/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3922 - val_loss: 1.3132 - val_accuracy: 0.4099

Epoch 00114: val_loss improved from 1.31380 to 1.31321, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 115/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3881 - val_loss: 1.3195 - val_accuracy: 0.4075

Epoch 00115: val_loss did not improve from 1.31321
Epoch 116/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3841 - val_loss: 1.3182 - val_accuracy: 0.4027

Epoch 00116: val_loss did not improve from 1.31321
Epoch 117/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3873 - val_loss: 1.3157 - val_accuracy: 0.4027

Epoch 00117: val_loss did not improve from 1.31321
Epoch 118/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3864 - val_loss: 1.3144 - val_accuracy: 0.3955

Epoch 00118: val_loss did not improve from 1.31321
Epoch 119/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3915 - val_loss: 1.3214 - val_accuracy: 0.4163

Epoch 00119: val_loss did not improve from 1.31321
Epoch 120/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3985 - val_loss: 1.3151 - val_accuracy: 0.4131

Epoch 00120: val_loss did not improve from 1.31321
Epoch 121/10000
12/12 - 0s - loss: 1.3273 - accuracy: 0.3933 - val_loss: 1.3132 - val_accuracy: 0.4147

Epoch 00121: val_loss did not improve from 1.31321
Epoch 122/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3967 - val_loss: 1.3185 - val_accuracy: 0.4107

Epoch 00122: val_loss did not improve from 1.31321
Epoch 123/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3872 - val_loss: 1.3195 - val_accuracy: 0.3947

Epoch 00123: val_loss did not improve from 1.31321
Epoch 124/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3961 - val_loss: 1.3136 - val_accuracy: 0.4051

Epoch 00124: val_loss did not improve from 1.31321
Epoch 125/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3909 - val_loss: 1.3173 - val_accuracy: 0.3963

Epoch 00125: val_loss did not improve from 1.31321
Epoch 126/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3896 - val_loss: 1.3174 - val_accuracy: 0.4107

Epoch 00126: val_loss did not improve from 1.31321
Epoch 127/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3970 - val_loss: 1.3128 - val_accuracy: 0.4115

Epoch 00127: val_loss improved from 1.31321 to 1.31276, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 128/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3874 - val_loss: 1.3205 - val_accuracy: 0.3987

Epoch 00128: val_loss did not improve from 1.31276
Epoch 129/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3915 - val_loss: 1.3137 - val_accuracy: 0.4075

Epoch 00129: val_loss did not improve from 1.31276
Epoch 130/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3903 - val_loss: 1.3209 - val_accuracy: 0.4091

Epoch 00130: val_loss did not improve from 1.31276
Epoch 131/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3968 - val_loss: 1.3149 - val_accuracy: 0.4059

Epoch 00131: val_loss did not improve from 1.31276
Epoch 132/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3938 - val_loss: 1.3167 - val_accuracy: 0.4059

Epoch 00132: val_loss did not improve from 1.31276
Epoch 133/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3973 - val_loss: 1.3147 - val_accuracy: 0.4131

Epoch 00133: val_loss did not improve from 1.31276
Epoch 134/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3938 - val_loss: 1.3160 - val_accuracy: 0.3963

Epoch 00134: val_loss did not improve from 1.31276
Epoch 135/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3883 - val_loss: 1.3136 - val_accuracy: 0.4059

Epoch 00135: val_loss did not improve from 1.31276
Epoch 136/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3939 - val_loss: 1.3127 - val_accuracy: 0.4059

Epoch 00136: val_loss improved from 1.31276 to 1.31267, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 137/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3919 - val_loss: 1.3139 - val_accuracy: 0.4083

Epoch 00137: val_loss did not improve from 1.31267
Epoch 138/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3876 - val_loss: 1.3213 - val_accuracy: 0.4003

Epoch 00138: val_loss did not improve from 1.31267
Epoch 139/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3915 - val_loss: 1.3134 - val_accuracy: 0.4067

Epoch 00139: val_loss did not improve from 1.31267
Epoch 140/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3936 - val_loss: 1.3160 - val_accuracy: 0.4067

Epoch 00140: val_loss did not improve from 1.31267
Epoch 141/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3900 - val_loss: 1.3177 - val_accuracy: 0.4075

Epoch 00141: val_loss did not improve from 1.31267
Epoch 142/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3951 - val_loss: 1.3130 - val_accuracy: 0.4123

Epoch 00142: val_loss did not improve from 1.31267
Epoch 143/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3983 - val_loss: 1.3120 - val_accuracy: 0.4003

Epoch 00143: val_loss improved from 1.31267 to 1.31203, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 144/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3873 - val_loss: 1.3223 - val_accuracy: 0.3987

Epoch 00144: val_loss did not improve from 1.31203
Epoch 145/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3926 - val_loss: 1.3117 - val_accuracy: 0.4147

Epoch 00145: val_loss improved from 1.31203 to 1.31167, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 146/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3935 - val_loss: 1.3150 - val_accuracy: 0.4131

Epoch 00146: val_loss did not improve from 1.31167
Epoch 147/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3916 - val_loss: 1.3148 - val_accuracy: 0.4226

Epoch 00147: val_loss did not improve from 1.31167
Epoch 148/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3944 - val_loss: 1.3174 - val_accuracy: 0.4179

Epoch 00148: val_loss did not improve from 1.31167
Epoch 149/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3942 - val_loss: 1.3129 - val_accuracy: 0.4043

Epoch 00149: val_loss did not improve from 1.31167
Epoch 150/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3880 - val_loss: 1.3196 - val_accuracy: 0.3900

Epoch 00150: val_loss did not improve from 1.31167
Epoch 151/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3883 - val_loss: 1.3131 - val_accuracy: 0.4075

Epoch 00151: val_loss did not improve from 1.31167
Epoch 152/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3942 - val_loss: 1.3151 - val_accuracy: 0.4147

Epoch 00152: val_loss did not improve from 1.31167
Epoch 153/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3954 - val_loss: 1.3151 - val_accuracy: 0.4067

Epoch 00153: val_loss did not improve from 1.31167
Epoch 154/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3874 - val_loss: 1.3131 - val_accuracy: 0.3939

Epoch 00154: val_loss did not improve from 1.31167
Epoch 155/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3876 - val_loss: 1.3163 - val_accuracy: 0.3995

Epoch 00155: val_loss did not improve from 1.31167
Epoch 156/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3911 - val_loss: 1.3133 - val_accuracy: 0.4107

Epoch 00156: val_loss did not improve from 1.31167
Epoch 157/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3941 - val_loss: 1.3135 - val_accuracy: 0.4147

Epoch 00157: val_loss did not improve from 1.31167
Epoch 158/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3948 - val_loss: 1.3124 - val_accuracy: 0.4099

Epoch 00158: val_loss did not improve from 1.31167
Epoch 159/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3930 - val_loss: 1.3165 - val_accuracy: 0.4147

Epoch 00159: val_loss did not improve from 1.31167
Epoch 160/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3928 - val_loss: 1.3128 - val_accuracy: 0.4123

Epoch 00160: val_loss did not improve from 1.31167
Epoch 161/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3970 - val_loss: 1.3101 - val_accuracy: 0.4019

Epoch 00161: val_loss improved from 1.31167 to 1.31010, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 162/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3927 - val_loss: 1.3122 - val_accuracy: 0.3915

Epoch 00162: val_loss did not improve from 1.31010
Epoch 163/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3934 - val_loss: 1.3181 - val_accuracy: 0.4107

Epoch 00163: val_loss did not improve from 1.31010
Epoch 164/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3975 - val_loss: 1.3129 - val_accuracy: 0.4242

Epoch 00164: val_loss did not improve from 1.31010
Epoch 165/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3966 - val_loss: 1.3115 - val_accuracy: 0.4139

Epoch 00165: val_loss did not improve from 1.31010
Epoch 166/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3889 - val_loss: 1.3267 - val_accuracy: 0.4051

Epoch 00166: val_loss did not improve from 1.31010
Epoch 167/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3925 - val_loss: 1.3102 - val_accuracy: 0.4107

Epoch 00167: val_loss did not improve from 1.31010
Epoch 168/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3941 - val_loss: 1.3114 - val_accuracy: 0.4075

Epoch 00168: val_loss did not improve from 1.31010
Epoch 169/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3866 - val_loss: 1.3165 - val_accuracy: 0.3947

Epoch 00169: val_loss did not improve from 1.31010
Epoch 170/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3904 - val_loss: 1.3119 - val_accuracy: 0.4059

Epoch 00170: val_loss did not improve from 1.31010
Epoch 171/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3863 - val_loss: 1.3180 - val_accuracy: 0.4075

Epoch 00171: val_loss did not improve from 1.31010
Epoch 172/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3926 - val_loss: 1.3110 - val_accuracy: 0.4171

Epoch 00172: val_loss did not improve from 1.31010
Epoch 173/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3960 - val_loss: 1.3116 - val_accuracy: 0.4179

Epoch 00173: val_loss did not improve from 1.31010
Epoch 174/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3909 - val_loss: 1.3148 - val_accuracy: 0.4043

Epoch 00174: val_loss did not improve from 1.31010
Epoch 175/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3947 - val_loss: 1.3138 - val_accuracy: 0.4226

Epoch 00175: val_loss did not improve from 1.31010
Epoch 176/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3978 - val_loss: 1.3110 - val_accuracy: 0.4187

Epoch 00176: val_loss did not improve from 1.31010
Epoch 177/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3964 - val_loss: 1.3110 - val_accuracy: 0.4043

Epoch 00177: val_loss did not improve from 1.31010
Epoch 178/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3849 - val_loss: 1.3233 - val_accuracy: 0.4011

Epoch 00178: val_loss did not improve from 1.31010
Epoch 179/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3915 - val_loss: 1.3098 - val_accuracy: 0.4115

Epoch 00179: val_loss improved from 1.31010 to 1.30981, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 180/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3953 - val_loss: 1.3190 - val_accuracy: 0.4091

Epoch 00180: val_loss did not improve from 1.30981
Epoch 181/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3937 - val_loss: 1.3132 - val_accuracy: 0.4011

Epoch 00181: val_loss did not improve from 1.30981
Epoch 182/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3924 - val_loss: 1.3128 - val_accuracy: 0.4123

Epoch 00182: val_loss did not improve from 1.30981
Epoch 183/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3960 - val_loss: 1.3093 - val_accuracy: 0.4266

Epoch 00183: val_loss improved from 1.30981 to 1.30931, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 184/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3961 - val_loss: 1.3106 - val_accuracy: 0.4250

Epoch 00184: val_loss did not improve from 1.30931
Epoch 185/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3944 - val_loss: 1.3142 - val_accuracy: 0.4035

Epoch 00185: val_loss did not improve from 1.30931
Epoch 186/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3886 - val_loss: 1.3183 - val_accuracy: 0.3995

Epoch 00186: val_loss did not improve from 1.30931
Epoch 187/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3900 - val_loss: 1.3107 - val_accuracy: 0.3931

Epoch 00187: val_loss did not improve from 1.30931
Epoch 188/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3915 - val_loss: 1.3116 - val_accuracy: 0.4115

Epoch 00188: val_loss did not improve from 1.30931
Epoch 189/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3930 - val_loss: 1.3148 - val_accuracy: 0.4083

Epoch 00189: val_loss did not improve from 1.30931
Epoch 190/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3947 - val_loss: 1.3105 - val_accuracy: 0.3963

Epoch 00190: val_loss did not improve from 1.30931
Epoch 191/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3866 - val_loss: 1.3111 - val_accuracy: 0.4083

Epoch 00191: val_loss did not improve from 1.30931
Epoch 192/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3921 - val_loss: 1.3201 - val_accuracy: 0.4091

Epoch 00192: val_loss did not improve from 1.30931
Epoch 193/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3947 - val_loss: 1.3114 - val_accuracy: 0.4027

Epoch 00193: val_loss did not improve from 1.30931
Epoch 194/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3914 - val_loss: 1.3129 - val_accuracy: 0.3995

Epoch 00194: val_loss did not improve from 1.30931
Epoch 195/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3917 - val_loss: 1.3115 - val_accuracy: 0.4091

Epoch 00195: val_loss did not improve from 1.30931
Epoch 196/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3970 - val_loss: 1.3133 - val_accuracy: 0.4139

Epoch 00196: val_loss did not improve from 1.30931
Epoch 197/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3960 - val_loss: 1.3191 - val_accuracy: 0.3955

Epoch 00197: val_loss did not improve from 1.30931
Epoch 198/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3869 - val_loss: 1.3118 - val_accuracy: 0.3876

Epoch 00198: val_loss did not improve from 1.30931
Epoch 199/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3913 - val_loss: 1.3140 - val_accuracy: 0.4059

Epoch 00199: val_loss did not improve from 1.30931
Epoch 200/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3986 - val_loss: 1.3108 - val_accuracy: 0.4131

Epoch 00200: val_loss did not improve from 1.30931
Epoch 201/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3931 - val_loss: 1.3116 - val_accuracy: 0.4059

Epoch 00201: val_loss did not improve from 1.30931
Epoch 202/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3895 - val_loss: 1.3145 - val_accuracy: 0.4075

Epoch 00202: val_loss did not improve from 1.30931
Epoch 203/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3970 - val_loss: 1.3110 - val_accuracy: 0.4314

Epoch 00203: val_loss did not improve from 1.30931
Epoch 204/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3989 - val_loss: 1.3102 - val_accuracy: 0.4043

Epoch 00204: val_loss did not improve from 1.30931
Epoch 205/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3930 - val_loss: 1.3106 - val_accuracy: 0.4035

Epoch 00205: val_loss did not improve from 1.30931
Epoch 206/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3947 - val_loss: 1.3150 - val_accuracy: 0.4163

Epoch 00206: val_loss did not improve from 1.30931
Epoch 207/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3974 - val_loss: 1.3110 - val_accuracy: 0.4171

Epoch 00207: val_loss did not improve from 1.30931
Epoch 208/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3964 - val_loss: 1.3116 - val_accuracy: 0.4147

Epoch 00208: val_loss did not improve from 1.30931
Epoch 209/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3943 - val_loss: 1.3147 - val_accuracy: 0.4131

Epoch 00209: val_loss did not improve from 1.30931
Epoch 210/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3923 - val_loss: 1.3103 - val_accuracy: 0.3915

Epoch 00210: val_loss did not improve from 1.30931
Epoch 211/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3954 - val_loss: 1.3096 - val_accuracy: 0.4163

Epoch 00211: val_loss did not improve from 1.30931
Epoch 212/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3964 - val_loss: 1.3151 - val_accuracy: 0.4195

Epoch 00212: val_loss did not improve from 1.30931
Epoch 213/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3950 - val_loss: 1.3105 - val_accuracy: 0.4115

Epoch 00213: val_loss did not improve from 1.30931
Epoch 214/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3965 - val_loss: 1.3102 - val_accuracy: 0.4274

Epoch 00214: val_loss did not improve from 1.30931
Epoch 215/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3978 - val_loss: 1.3126 - val_accuracy: 0.4123

Epoch 00215: val_loss did not improve from 1.30931
Epoch 216/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3906 - val_loss: 1.3130 - val_accuracy: 0.3963

Epoch 00216: val_loss did not improve from 1.30931
Epoch 217/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3964 - val_loss: 1.3227 - val_accuracy: 0.3963

Epoch 00217: val_loss did not improve from 1.30931
Epoch 218/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3966 - val_loss: 1.3087 - val_accuracy: 0.3963

Epoch 00218: val_loss improved from 1.30931 to 1.30869, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 219/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3948 - val_loss: 1.3084 - val_accuracy: 0.4123

Epoch 00219: val_loss improved from 1.30869 to 1.30844, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 220/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3948 - val_loss: 1.3174 - val_accuracy: 0.4258

Epoch 00220: val_loss did not improve from 1.30844
Epoch 221/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3931 - val_loss: 1.3088 - val_accuracy: 0.4051

Epoch 00221: val_loss did not improve from 1.30844
Epoch 222/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3975 - val_loss: 1.3076 - val_accuracy: 0.4147

Epoch 00222: val_loss improved from 1.30844 to 1.30762, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 223/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3979 - val_loss: 1.3163 - val_accuracy: 0.4139

Epoch 00223: val_loss did not improve from 1.30762
Epoch 224/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3953 - val_loss: 1.3108 - val_accuracy: 0.4195

Epoch 00224: val_loss did not improve from 1.30762
Epoch 225/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3968 - val_loss: 1.3089 - val_accuracy: 0.4091

Epoch 00225: val_loss did not improve from 1.30762
Epoch 226/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3922 - val_loss: 1.3195 - val_accuracy: 0.3971

Epoch 00226: val_loss did not improve from 1.30762
Epoch 227/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3985 - val_loss: 1.3072 - val_accuracy: 0.4091

Epoch 00227: val_loss improved from 1.30762 to 1.30715, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 228/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3991 - val_loss: 1.3079 - val_accuracy: 0.4099

Epoch 00228: val_loss did not improve from 1.30715
Epoch 229/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3913 - val_loss: 1.3239 - val_accuracy: 0.4019

Epoch 00229: val_loss did not improve from 1.30715
Epoch 230/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3952 - val_loss: 1.3091 - val_accuracy: 0.4131

Epoch 00230: val_loss did not improve from 1.30715
Epoch 231/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3977 - val_loss: 1.3085 - val_accuracy: 0.4179

Epoch 00231: val_loss did not improve from 1.30715
Epoch 232/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3969 - val_loss: 1.3134 - val_accuracy: 0.4155

Epoch 00232: val_loss did not improve from 1.30715
Epoch 233/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3968 - val_loss: 1.3079 - val_accuracy: 0.4043

Epoch 00233: val_loss did not improve from 1.30715
Epoch 234/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3896 - val_loss: 1.3157 - val_accuracy: 0.4107

Epoch 00234: val_loss did not improve from 1.30715
Epoch 235/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3939 - val_loss: 1.3099 - val_accuracy: 0.4187

Epoch 00235: val_loss did not improve from 1.30715
Epoch 236/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3973 - val_loss: 1.3064 - val_accuracy: 0.4067

Epoch 00236: val_loss improved from 1.30715 to 1.30637, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 237/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3916 - val_loss: 1.3137 - val_accuracy: 0.4011

Epoch 00237: val_loss did not improve from 1.30637
Epoch 238/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3951 - val_loss: 1.3091 - val_accuracy: 0.4242

Epoch 00238: val_loss did not improve from 1.30637
Epoch 239/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3969 - val_loss: 1.3082 - val_accuracy: 0.4139

Epoch 00239: val_loss did not improve from 1.30637
Epoch 240/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3945 - val_loss: 1.3113 - val_accuracy: 0.4099

Epoch 00240: val_loss did not improve from 1.30637
Epoch 241/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3933 - val_loss: 1.3092 - val_accuracy: 0.4123

Epoch 00241: val_loss did not improve from 1.30637
Epoch 242/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3965 - val_loss: 1.3070 - val_accuracy: 0.4155

Epoch 00242: val_loss did not improve from 1.30637
Epoch 243/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3970 - val_loss: 1.3084 - val_accuracy: 0.4242

Epoch 00243: val_loss did not improve from 1.30637
Epoch 244/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3983 - val_loss: 1.3087 - val_accuracy: 0.4019

Epoch 00244: val_loss did not improve from 1.30637
Epoch 245/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3984 - val_loss: 1.3064 - val_accuracy: 0.4059

Epoch 00245: val_loss did not improve from 1.30637
Epoch 246/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3908 - val_loss: 1.3284 - val_accuracy: 0.3939

Epoch 00246: val_loss did not improve from 1.30637
Epoch 247/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3937 - val_loss: 1.3077 - val_accuracy: 0.4091

Epoch 00247: val_loss did not improve from 1.30637
Epoch 248/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.4023 - val_loss: 1.3070 - val_accuracy: 0.4035

Epoch 00248: val_loss did not improve from 1.30637
Epoch 249/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3923 - val_loss: 1.3223 - val_accuracy: 0.4091

Epoch 00249: val_loss did not improve from 1.30637
Epoch 250/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3962 - val_loss: 1.3076 - val_accuracy: 0.4139

Epoch 00250: val_loss did not improve from 1.30637
Epoch 251/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3974 - val_loss: 1.3110 - val_accuracy: 0.4155

Epoch 00251: val_loss did not improve from 1.30637
Epoch 252/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3925 - val_loss: 1.3095 - val_accuracy: 0.3995

Epoch 00252: val_loss did not improve from 1.30637
Epoch 253/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3962 - val_loss: 1.3072 - val_accuracy: 0.4195

Epoch 00253: val_loss did not improve from 1.30637
Epoch 254/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3967 - val_loss: 1.3114 - val_accuracy: 0.3995

Epoch 00254: val_loss did not improve from 1.30637
Epoch 255/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3931 - val_loss: 1.3072 - val_accuracy: 0.4091

Epoch 00255: val_loss did not improve from 1.30637
Epoch 256/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3916 - val_loss: 1.3124 - val_accuracy: 0.4027

Epoch 00256: val_loss did not improve from 1.30637
Epoch 257/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3938 - val_loss: 1.3068 - val_accuracy: 0.3907

Epoch 00257: val_loss did not improve from 1.30637
Epoch 258/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3911 - val_loss: 1.3121 - val_accuracy: 0.4083

Epoch 00258: val_loss did not improve from 1.30637
Epoch 259/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3995 - val_loss: 1.3110 - val_accuracy: 0.4163

Epoch 00259: val_loss did not improve from 1.30637
Epoch 260/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3983 - val_loss: 1.3063 - val_accuracy: 0.4067

Epoch 00260: val_loss improved from 1.30637 to 1.30633, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 261/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3939 - val_loss: 1.3169 - val_accuracy: 0.4043

Epoch 00261: val_loss did not improve from 1.30633
Epoch 262/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3956 - val_loss: 1.3053 - val_accuracy: 0.4051

Epoch 00262: val_loss improved from 1.30633 to 1.30532, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 263/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3985 - val_loss: 1.3121 - val_accuracy: 0.4067

Epoch 00263: val_loss did not improve from 1.30532
Epoch 264/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3902 - val_loss: 1.3084 - val_accuracy: 0.3987

Epoch 00264: val_loss did not improve from 1.30532
Epoch 265/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3960 - val_loss: 1.3081 - val_accuracy: 0.4226

Epoch 00265: val_loss did not improve from 1.30532
Epoch 266/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3986 - val_loss: 1.3063 - val_accuracy: 0.4203

Epoch 00266: val_loss did not improve from 1.30532
Epoch 267/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3970 - val_loss: 1.3088 - val_accuracy: 0.4179

Epoch 00267: val_loss did not improve from 1.30532
Epoch 268/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3953 - val_loss: 1.3087 - val_accuracy: 0.4155

Epoch 00268: val_loss did not improve from 1.30532
Epoch 269/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3980 - val_loss: 1.3067 - val_accuracy: 0.4187

Epoch 00269: val_loss did not improve from 1.30532
Epoch 270/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3990 - val_loss: 1.3058 - val_accuracy: 0.4123

Epoch 00270: val_loss did not improve from 1.30532
Epoch 271/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3957 - val_loss: 1.3053 - val_accuracy: 0.3971

Epoch 00271: val_loss improved from 1.30532 to 1.30529, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 272/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3910 - val_loss: 1.3081 - val_accuracy: 0.4234

Epoch 00272: val_loss did not improve from 1.30529
Epoch 273/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3957 - val_loss: 1.3096 - val_accuracy: 0.4131

Epoch 00273: val_loss did not improve from 1.30529
Epoch 274/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4005 - val_loss: 1.3065 - val_accuracy: 0.4163

Epoch 00274: val_loss did not improve from 1.30529
Epoch 275/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3984 - val_loss: 1.3046 - val_accuracy: 0.4067

Epoch 00275: val_loss improved from 1.30529 to 1.30463, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 276/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3962 - val_loss: 1.3095 - val_accuracy: 0.4043

Epoch 00276: val_loss did not improve from 1.30463
Epoch 277/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3954 - val_loss: 1.3070 - val_accuracy: 0.4035

Epoch 00277: val_loss did not improve from 1.30463
Epoch 278/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3974 - val_loss: 1.3077 - val_accuracy: 0.4155

Epoch 00278: val_loss did not improve from 1.30463
Epoch 279/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3977 - val_loss: 1.3093 - val_accuracy: 0.4099

Epoch 00279: val_loss did not improve from 1.30463
Epoch 280/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3973 - val_loss: 1.3038 - val_accuracy: 0.4155

Epoch 00280: val_loss improved from 1.30463 to 1.30381, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 281/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3970 - val_loss: 1.3062 - val_accuracy: 0.4147

Epoch 00281: val_loss did not improve from 1.30381
Epoch 282/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3929 - val_loss: 1.3147 - val_accuracy: 0.4083

Epoch 00282: val_loss did not improve from 1.30381
Epoch 283/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3967 - val_loss: 1.3054 - val_accuracy: 0.4163

Epoch 00283: val_loss did not improve from 1.30381
Epoch 284/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4007 - val_loss: 1.3045 - val_accuracy: 0.4107

Epoch 00284: val_loss did not improve from 1.30381
Epoch 285/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3918 - val_loss: 1.3162 - val_accuracy: 0.3923

Epoch 00285: val_loss did not improve from 1.30381
Epoch 286/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3931 - val_loss: 1.3058 - val_accuracy: 0.3963

Epoch 00286: val_loss did not improve from 1.30381
Epoch 287/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3965 - val_loss: 1.3031 - val_accuracy: 0.4179

Epoch 00287: val_loss improved from 1.30381 to 1.30308, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 288/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3983 - val_loss: 1.3182 - val_accuracy: 0.4043

Epoch 00288: val_loss did not improve from 1.30308
Epoch 289/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3976 - val_loss: 1.3061 - val_accuracy: 0.4099

Epoch 00289: val_loss did not improve from 1.30308
Epoch 290/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3982 - val_loss: 1.3070 - val_accuracy: 0.4226

Epoch 00290: val_loss did not improve from 1.30308
Epoch 291/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3977 - val_loss: 1.3099 - val_accuracy: 0.4083

Epoch 00291: val_loss did not improve from 1.30308
Epoch 292/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3960 - val_loss: 1.3058 - val_accuracy: 0.4051

Epoch 00292: val_loss did not improve from 1.30308
Epoch 293/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3974 - val_loss: 1.3053 - val_accuracy: 0.4211

Epoch 00293: val_loss did not improve from 1.30308
Epoch 294/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3936 - val_loss: 1.3119 - val_accuracy: 0.4139

Epoch 00294: val_loss did not improve from 1.30308
Epoch 295/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3960 - val_loss: 1.3036 - val_accuracy: 0.3939

Epoch 00295: val_loss did not improve from 1.30308
Epoch 296/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3955 - val_loss: 1.3061 - val_accuracy: 0.4115

Epoch 00296: val_loss did not improve from 1.30308
Epoch 297/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3998 - val_loss: 1.3072 - val_accuracy: 0.4027

Epoch 00297: val_loss did not improve from 1.30308
Epoch 298/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3977 - val_loss: 1.3051 - val_accuracy: 0.4091

Epoch 00298: val_loss did not improve from 1.30308
Epoch 299/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3905 - val_loss: 1.3142 - val_accuracy: 0.3923

Epoch 00299: val_loss did not improve from 1.30308
Epoch 300/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3927 - val_loss: 1.3046 - val_accuracy: 0.4067

Epoch 00300: val_loss did not improve from 1.30308
Epoch 301/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4000 - val_loss: 1.3044 - val_accuracy: 0.4171

Epoch 00301: val_loss did not improve from 1.30308
Epoch 302/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3993 - val_loss: 1.3063 - val_accuracy: 0.4107

Epoch 00302: val_loss did not improve from 1.30308
Epoch 303/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.3969 - val_loss: 1.3080 - val_accuracy: 0.4163

Epoch 00303: val_loss did not improve from 1.30308
Epoch 304/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3993 - val_loss: 1.3027 - val_accuracy: 0.4123

Epoch 00304: val_loss improved from 1.30308 to 1.30266, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 305/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3946 - val_loss: 1.3043 - val_accuracy: 0.4179

Epoch 00305: val_loss did not improve from 1.30266
Epoch 306/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3954 - val_loss: 1.3125 - val_accuracy: 0.4035

Epoch 00306: val_loss did not improve from 1.30266
Epoch 307/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3978 - val_loss: 1.3056 - val_accuracy: 0.4075

Epoch 00307: val_loss did not improve from 1.30266
Epoch 308/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3921 - val_loss: 1.3051 - val_accuracy: 0.4051

Epoch 00308: val_loss did not improve from 1.30266
Epoch 309/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3979 - val_loss: 1.3094 - val_accuracy: 0.4099

Epoch 00309: val_loss did not improve from 1.30266
Epoch 310/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3978 - val_loss: 1.3088 - val_accuracy: 0.4043

Epoch 00310: val_loss did not improve from 1.30266
Epoch 311/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.3989 - val_loss: 1.3041 - val_accuracy: 0.4035

Epoch 00311: val_loss did not improve from 1.30266
Epoch 312/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3946 - val_loss: 1.3109 - val_accuracy: 0.3987

Epoch 00312: val_loss did not improve from 1.30266
Epoch 313/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4004 - val_loss: 1.3038 - val_accuracy: 0.4187

Epoch 00313: val_loss did not improve from 1.30266
Epoch 314/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3998 - val_loss: 1.3052 - val_accuracy: 0.4163

Epoch 00314: val_loss did not improve from 1.30266
Epoch 315/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4015 - val_loss: 1.3044 - val_accuracy: 0.4139

Epoch 00315: val_loss did not improve from 1.30266
Epoch 316/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3948 - val_loss: 1.3048 - val_accuracy: 0.4099

Epoch 00316: val_loss did not improve from 1.30266
Epoch 317/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3993 - val_loss: 1.3018 - val_accuracy: 0.4115

Epoch 00317: val_loss improved from 1.30266 to 1.30185, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 318/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3949 - val_loss: 1.3059 - val_accuracy: 0.4043

Epoch 00318: val_loss did not improve from 1.30185
Epoch 319/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4016 - val_loss: 1.3078 - val_accuracy: 0.4091

Epoch 00319: val_loss did not improve from 1.30185
Epoch 320/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3992 - val_loss: 1.3088 - val_accuracy: 0.3987

Epoch 00320: val_loss did not improve from 1.30185
Epoch 321/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4018 - val_loss: 1.3020 - val_accuracy: 0.4131

Epoch 00321: val_loss did not improve from 1.30185
Epoch 322/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4031 - val_loss: 1.3028 - val_accuracy: 0.4051

Epoch 00322: val_loss did not improve from 1.30185
Epoch 323/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.3896 - val_loss: 1.3168 - val_accuracy: 0.3876

Epoch 00323: val_loss did not improve from 1.30185
Epoch 324/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3948 - val_loss: 1.3067 - val_accuracy: 0.4171

Epoch 00324: val_loss did not improve from 1.30185
Epoch 325/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4020 - val_loss: 1.3027 - val_accuracy: 0.4179

Epoch 00325: val_loss did not improve from 1.30185
Epoch 326/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3938 - val_loss: 1.3080 - val_accuracy: 0.3939

Epoch 00326: val_loss did not improve from 1.30185
Epoch 327/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3924 - val_loss: 1.3041 - val_accuracy: 0.4115

Epoch 00327: val_loss did not improve from 1.30185
Epoch 328/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4004 - val_loss: 1.3102 - val_accuracy: 0.3995

Epoch 00328: val_loss did not improve from 1.30185
Epoch 329/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3993 - val_loss: 1.3025 - val_accuracy: 0.4139

Epoch 00329: val_loss did not improve from 1.30185
Epoch 330/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4016 - val_loss: 1.3071 - val_accuracy: 0.4067

Epoch 00330: val_loss did not improve from 1.30185
Epoch 331/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4039 - val_loss: 1.3016 - val_accuracy: 0.4019

Epoch 00331: val_loss improved from 1.30185 to 1.30164, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 332/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3945 - val_loss: 1.3113 - val_accuracy: 0.3963

Epoch 00332: val_loss did not improve from 1.30164
Epoch 333/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3993 - val_loss: 1.3041 - val_accuracy: 0.4171

Epoch 00333: val_loss did not improve from 1.30164
Epoch 334/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4022 - val_loss: 1.3030 - val_accuracy: 0.4179

Epoch 00334: val_loss did not improve from 1.30164
Epoch 335/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3985 - val_loss: 1.3023 - val_accuracy: 0.4171

Epoch 00335: val_loss did not improve from 1.30164
Epoch 336/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.3990 - val_loss: 1.3112 - val_accuracy: 0.4043

Epoch 00336: val_loss did not improve from 1.30164
Epoch 337/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4014 - val_loss: 1.3017 - val_accuracy: 0.4187

Epoch 00337: val_loss did not improve from 1.30164
Epoch 338/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4026 - val_loss: 1.3025 - val_accuracy: 0.4051

Epoch 00338: val_loss did not improve from 1.30164
Epoch 339/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3930 - val_loss: 1.3091 - val_accuracy: 0.3876

Epoch 00339: val_loss did not improve from 1.30164
Epoch 340/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.3973 - val_loss: 1.3075 - val_accuracy: 0.4011

Epoch 00340: val_loss did not improve from 1.30164
Epoch 341/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4034 - val_loss: 1.3003 - val_accuracy: 0.4171

Epoch 00341: val_loss improved from 1.30164 to 1.30033, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 342/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3962 - val_loss: 1.3172 - val_accuracy: 0.3979

Epoch 00342: val_loss did not improve from 1.30033
Epoch 343/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4015 - val_loss: 1.3023 - val_accuracy: 0.4107

Epoch 00343: val_loss did not improve from 1.30033
Epoch 344/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3959 - val_loss: 1.3020 - val_accuracy: 0.4035

Epoch 00344: val_loss did not improve from 1.30033
Epoch 345/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3995 - val_loss: 1.3091 - val_accuracy: 0.4075

Epoch 00345: val_loss did not improve from 1.30033
Epoch 346/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4008 - val_loss: 1.3027 - val_accuracy: 0.4179

Epoch 00346: val_loss did not improve from 1.30033
Epoch 347/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4013 - val_loss: 1.3019 - val_accuracy: 0.4099

Epoch 00347: val_loss did not improve from 1.30033
Epoch 348/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3958 - val_loss: 1.3066 - val_accuracy: 0.3955

Epoch 00348: val_loss did not improve from 1.30033
Epoch 349/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.3954 - val_loss: 1.3037 - val_accuracy: 0.4059

Epoch 00349: val_loss did not improve from 1.30033
Epoch 350/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4014 - val_loss: 1.3076 - val_accuracy: 0.4107

Epoch 00350: val_loss did not improve from 1.30033
Epoch 351/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.3985 - val_loss: 1.3037 - val_accuracy: 0.3947

Epoch 00351: val_loss did not improve from 1.30033
Epoch 352/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.3961 - val_loss: 1.3061 - val_accuracy: 0.3963

Epoch 00352: val_loss did not improve from 1.30033
Epoch 353/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.3993 - val_loss: 1.3015 - val_accuracy: 0.4234

Epoch 00353: val_loss did not improve from 1.30033
Epoch 354/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4013 - val_loss: 1.3009 - val_accuracy: 0.4195

Epoch 00354: val_loss did not improve from 1.30033
Epoch 355/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.3985 - val_loss: 1.3038 - val_accuracy: 0.4067

Epoch 00355: val_loss did not improve from 1.30033
Epoch 356/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3939 - val_loss: 1.3080 - val_accuracy: 0.4043

Epoch 00356: val_loss did not improve from 1.30033
Epoch 357/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4040 - val_loss: 1.3018 - val_accuracy: 0.4171

Epoch 00357: val_loss did not improve from 1.30033
Epoch 358/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4025 - val_loss: 1.3017 - val_accuracy: 0.4035

Epoch 00358: val_loss did not improve from 1.30033
Epoch 359/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4007 - val_loss: 1.3044 - val_accuracy: 0.4083

Epoch 00359: val_loss did not improve from 1.30033
Epoch 360/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.3953 - val_loss: 1.3068 - val_accuracy: 0.3955

Epoch 00360: val_loss did not improve from 1.30033
Epoch 361/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4017 - val_loss: 1.3027 - val_accuracy: 0.4139

Epoch 00361: val_loss did not improve from 1.30033
Epoch 362/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4048 - val_loss: 1.2996 - val_accuracy: 0.4163

Epoch 00362: val_loss improved from 1.30033 to 1.29963, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 363/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4036 - val_loss: 1.3007 - val_accuracy: 0.4091

Epoch 00363: val_loss did not improve from 1.29963
Epoch 364/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.3985 - val_loss: 1.3100 - val_accuracy: 0.3963

Epoch 00364: val_loss did not improve from 1.29963
Epoch 365/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.3947 - val_loss: 1.3004 - val_accuracy: 0.4123

Epoch 00365: val_loss did not improve from 1.29963
Epoch 366/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.3968 - val_loss: 1.3145 - val_accuracy: 0.3995

Epoch 00366: val_loss did not improve from 1.29963
Epoch 367/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4008 - val_loss: 1.3004 - val_accuracy: 0.4059

Epoch 00367: val_loss did not improve from 1.29963
Epoch 368/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.3949 - val_loss: 1.3014 - val_accuracy: 0.4067

Epoch 00368: val_loss did not improve from 1.29963
Epoch 369/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4001 - val_loss: 1.3038 - val_accuracy: 0.4139

Epoch 00369: val_loss did not improve from 1.29963
Epoch 370/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4016 - val_loss: 1.3019 - val_accuracy: 0.4091

Epoch 00370: val_loss did not improve from 1.29963
Epoch 371/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.3948 - val_loss: 1.3082 - val_accuracy: 0.3979

Epoch 00371: val_loss did not improve from 1.29963
Epoch 372/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.3930 - val_loss: 1.3010 - val_accuracy: 0.4075

Epoch 00372: val_loss did not improve from 1.29963
Epoch 373/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.3970 - val_loss: 1.3018 - val_accuracy: 0.4091

Epoch 00373: val_loss did not improve from 1.29963
Epoch 374/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.3996 - val_loss: 1.3005 - val_accuracy: 0.4219

Epoch 00374: val_loss did not improve from 1.29963
Epoch 375/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4027 - val_loss: 1.3144 - val_accuracy: 0.3987

Epoch 00375: val_loss did not improve from 1.29963
Epoch 376/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4032 - val_loss: 1.2987 - val_accuracy: 0.4099

Epoch 00376: val_loss improved from 1.29963 to 1.29875, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 377/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4022 - val_loss: 1.2995 - val_accuracy: 0.4083

Epoch 00377: val_loss did not improve from 1.29875
Epoch 378/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4007 - val_loss: 1.3055 - val_accuracy: 0.3987

Epoch 00378: val_loss did not improve from 1.29875
Epoch 379/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.3997 - val_loss: 1.2990 - val_accuracy: 0.4115

Epoch 00379: val_loss did not improve from 1.29875
Epoch 380/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4020 - val_loss: 1.3019 - val_accuracy: 0.4123

Epoch 00380: val_loss did not improve from 1.29875
Epoch 381/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4026 - val_loss: 1.3004 - val_accuracy: 0.4027

Epoch 00381: val_loss did not improve from 1.29875
Epoch 382/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4017 - val_loss: 1.3072 - val_accuracy: 0.4019

Epoch 00382: val_loss did not improve from 1.29875
Epoch 383/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4012 - val_loss: 1.2984 - val_accuracy: 0.4107

Epoch 00383: val_loss improved from 1.29875 to 1.29842, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 384/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.3986 - val_loss: 1.3065 - val_accuracy: 0.3987

Epoch 00384: val_loss did not improve from 1.29842
Epoch 385/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.3987 - val_loss: 1.3045 - val_accuracy: 0.3971

Epoch 00385: val_loss did not improve from 1.29842
Epoch 386/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.3970 - val_loss: 1.3015 - val_accuracy: 0.3979

Epoch 00386: val_loss did not improve from 1.29842
Epoch 387/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.3957 - val_loss: 1.2997 - val_accuracy: 0.4107

Epoch 00387: val_loss did not improve from 1.29842
Epoch 388/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4007 - val_loss: 1.3119 - val_accuracy: 0.4051

Epoch 00388: val_loss did not improve from 1.29842
Epoch 389/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4020 - val_loss: 1.2999 - val_accuracy: 0.4179

Epoch 00389: val_loss did not improve from 1.29842
Epoch 390/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4013 - val_loss: 1.2994 - val_accuracy: 0.4123

Epoch 00390: val_loss did not improve from 1.29842
Epoch 391/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4050 - val_loss: 1.3008 - val_accuracy: 0.4187

Epoch 00391: val_loss did not improve from 1.29842
Epoch 392/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4055 - val_loss: 1.3001 - val_accuracy: 0.4115

Epoch 00392: val_loss did not improve from 1.29842
Epoch 393/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4015 - val_loss: 1.3088 - val_accuracy: 0.3995

Epoch 00393: val_loss did not improve from 1.29842
Epoch 394/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4047 - val_loss: 1.2976 - val_accuracy: 0.4083

Epoch 00394: val_loss improved from 1.29842 to 1.29760, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 395/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.3946 - val_loss: 1.3064 - val_accuracy: 0.3955

Epoch 00395: val_loss did not improve from 1.29760
Epoch 396/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.3964 - val_loss: 1.3015 - val_accuracy: 0.3995

Epoch 00396: val_loss did not improve from 1.29760
Epoch 397/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4016 - val_loss: 1.3004 - val_accuracy: 0.4099

Epoch 00397: val_loss did not improve from 1.29760
Epoch 398/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4056 - val_loss: 1.2978 - val_accuracy: 0.4139

Epoch 00398: val_loss did not improve from 1.29760
Epoch 399/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.3959 - val_loss: 1.3000 - val_accuracy: 0.4027

Epoch 00399: val_loss did not improve from 1.29760
Epoch 400/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.3961 - val_loss: 1.3112 - val_accuracy: 0.3987

Epoch 00400: val_loss did not improve from 1.29760
Epoch 401/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.3974 - val_loss: 1.3035 - val_accuracy: 0.3947

Epoch 00401: val_loss did not improve from 1.29760
Epoch 402/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4014 - val_loss: 1.2993 - val_accuracy: 0.4091

Epoch 00402: val_loss did not improve from 1.29760
Epoch 403/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4049 - val_loss: 1.3007 - val_accuracy: 0.4187

Epoch 00403: val_loss did not improve from 1.29760
Epoch 404/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4042 - val_loss: 1.2988 - val_accuracy: 0.4211

Epoch 00404: val_loss did not improve from 1.29760
Epoch 405/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.3990 - val_loss: 1.3100 - val_accuracy: 0.3995

Epoch 00405: val_loss did not improve from 1.29760
Epoch 406/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.3993 - val_loss: 1.2979 - val_accuracy: 0.4083

Epoch 00406: val_loss did not improve from 1.29760
Epoch 407/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4040 - val_loss: 1.3046 - val_accuracy: 0.4019

Epoch 00407: val_loss did not improve from 1.29760
Epoch 408/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4036 - val_loss: 1.2980 - val_accuracy: 0.4027

Epoch 00408: val_loss did not improve from 1.29760
Epoch 409/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4066 - val_loss: 1.2990 - val_accuracy: 0.4099

Epoch 00409: val_loss did not improve from 1.29760
Epoch 410/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4023 - val_loss: 1.3073 - val_accuracy: 0.4011

Epoch 00410: val_loss did not improve from 1.29760
Epoch 411/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4009 - val_loss: 1.3011 - val_accuracy: 0.4155

Epoch 00411: val_loss did not improve from 1.29760
Epoch 412/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4054 - val_loss: 1.2976 - val_accuracy: 0.4282

Epoch 00412: val_loss did not improve from 1.29760
Epoch 413/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4014 - val_loss: 1.3011 - val_accuracy: 0.4051

Epoch 00413: val_loss did not improve from 1.29760
Epoch 414/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4027 - val_loss: 1.3011 - val_accuracy: 0.4043

Epoch 00414: val_loss did not improve from 1.29760
Epoch 415/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.3954 - val_loss: 1.3079 - val_accuracy: 0.3868

Epoch 00415: val_loss did not improve from 1.29760
Epoch 416/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4051 - val_loss: 1.2984 - val_accuracy: 0.4219

Epoch 00416: val_loss did not improve from 1.29760
Epoch 417/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4079 - val_loss: 1.2982 - val_accuracy: 0.4147

Epoch 00417: val_loss did not improve from 1.29760
Epoch 418/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4025 - val_loss: 1.3000 - val_accuracy: 0.4067

Epoch 00418: val_loss did not improve from 1.29760
Epoch 419/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.3978 - val_loss: 1.3095 - val_accuracy: 0.4075

Epoch 00419: val_loss did not improve from 1.29760
Epoch 420/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4035 - val_loss: 1.2999 - val_accuracy: 0.4067

Epoch 00420: val_loss did not improve from 1.29760
Epoch 421/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4043 - val_loss: 1.2985 - val_accuracy: 0.4115

Epoch 00421: val_loss did not improve from 1.29760
Epoch 422/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4004 - val_loss: 1.2980 - val_accuracy: 0.4051

Epoch 00422: val_loss did not improve from 1.29760
Epoch 423/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.3943 - val_loss: 1.3113 - val_accuracy: 0.4019

Epoch 00423: val_loss did not improve from 1.29760
Epoch 424/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4027 - val_loss: 1.2985 - val_accuracy: 0.4139

Epoch 00424: val_loss did not improve from 1.29760
Epoch 425/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.3943 - val_loss: 1.2998 - val_accuracy: 0.3900

Epoch 00425: val_loss did not improve from 1.29760
Epoch 426/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4011 - val_loss: 1.2991 - val_accuracy: 0.4091

Epoch 00426: val_loss did not improve from 1.29760
Epoch 427/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4030 - val_loss: 1.3023 - val_accuracy: 0.4083

Epoch 00427: val_loss did not improve from 1.29760
Epoch 428/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4032 - val_loss: 1.2995 - val_accuracy: 0.4163

Epoch 00428: val_loss did not improve from 1.29760
Epoch 429/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4063 - val_loss: 1.2989 - val_accuracy: 0.4043

Epoch 00429: val_loss did not improve from 1.29760
Epoch 430/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4039 - val_loss: 1.2987 - val_accuracy: 0.4107

Epoch 00430: val_loss did not improve from 1.29760
Epoch 431/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4024 - val_loss: 1.3000 - val_accuracy: 0.4051

Epoch 00431: val_loss did not improve from 1.29760
Epoch 432/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4033 - val_loss: 1.3019 - val_accuracy: 0.4027

Epoch 00432: val_loss did not improve from 1.29760
Epoch 433/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4063 - val_loss: 1.2979 - val_accuracy: 0.4131

Epoch 00433: val_loss did not improve from 1.29760
Epoch 434/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4043 - val_loss: 1.2986 - val_accuracy: 0.4003

Epoch 00434: val_loss did not improve from 1.29760
Epoch 435/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4005 - val_loss: 1.2983 - val_accuracy: 0.3979

Epoch 00435: val_loss did not improve from 1.29760
Epoch 436/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4020 - val_loss: 1.3051 - val_accuracy: 0.3987

Epoch 00436: val_loss did not improve from 1.29760
Epoch 437/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4017 - val_loss: 1.3033 - val_accuracy: 0.3820

Epoch 00437: val_loss did not improve from 1.29760
Epoch 438/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.3961 - val_loss: 1.2980 - val_accuracy: 0.4091

Epoch 00438: val_loss did not improve from 1.29760
Epoch 439/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4047 - val_loss: 1.2978 - val_accuracy: 0.4131

Epoch 00439: val_loss did not improve from 1.29760
Epoch 440/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4067 - val_loss: 1.3038 - val_accuracy: 0.4011

Epoch 00440: val_loss did not improve from 1.29760
Epoch 441/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4074 - val_loss: 1.2977 - val_accuracy: 0.4019

Epoch 00441: val_loss did not improve from 1.29760
Epoch 442/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.3989 - val_loss: 1.2989 - val_accuracy: 0.4083

Epoch 00442: val_loss did not improve from 1.29760
Epoch 443/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4060 - val_loss: 1.2997 - val_accuracy: 0.4099

Epoch 00443: val_loss did not improve from 1.29760
Epoch 444/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4017 - val_loss: 1.2959 - val_accuracy: 0.4075

Epoch 00444: val_loss improved from 1.29760 to 1.29590, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 445/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4005 - val_loss: 1.3034 - val_accuracy: 0.4035

Epoch 00445: val_loss did not improve from 1.29590
Epoch 446/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4024 - val_loss: 1.3036 - val_accuracy: 0.4011

Epoch 00446: val_loss did not improve from 1.29590
Epoch 447/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4046 - val_loss: 1.2998 - val_accuracy: 0.3995

Epoch 00447: val_loss did not improve from 1.29590
Epoch 448/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.3986 - val_loss: 1.2973 - val_accuracy: 0.4019

Epoch 00448: val_loss did not improve from 1.29590
Epoch 449/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4001 - val_loss: 1.2987 - val_accuracy: 0.4083

Epoch 00449: val_loss did not improve from 1.29590
Epoch 450/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4024 - val_loss: 1.3030 - val_accuracy: 0.4011

Epoch 00450: val_loss did not improve from 1.29590
Epoch 451/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4053 - val_loss: 1.2971 - val_accuracy: 0.4099

Epoch 00451: val_loss did not improve from 1.29590
Epoch 452/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4000 - val_loss: 1.3004 - val_accuracy: 0.3971

Epoch 00452: val_loss did not improve from 1.29590
Epoch 453/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.3970 - val_loss: 1.2971 - val_accuracy: 0.3971

Epoch 00453: val_loss did not improve from 1.29590
Epoch 454/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4035 - val_loss: 1.2960 - val_accuracy: 0.4107

Epoch 00454: val_loss did not improve from 1.29590
Epoch 455/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4036 - val_loss: 1.3035 - val_accuracy: 0.3892

Epoch 00455: val_loss did not improve from 1.29590
Epoch 456/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4035 - val_loss: 1.2991 - val_accuracy: 0.4051

Epoch 00456: val_loss did not improve from 1.29590
Epoch 457/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4044 - val_loss: 1.2968 - val_accuracy: 0.4107

Epoch 00457: val_loss did not improve from 1.29590
Epoch 458/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4030 - val_loss: 1.2979 - val_accuracy: 0.4163

Epoch 00458: val_loss did not improve from 1.29590
Epoch 459/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4070 - val_loss: 1.2938 - val_accuracy: 0.4171

Epoch 00459: val_loss improved from 1.29590 to 1.29380, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 460/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4023 - val_loss: 1.2971 - val_accuracy: 0.4067

Epoch 00460: val_loss did not improve from 1.29380
Epoch 461/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4035 - val_loss: 1.3040 - val_accuracy: 0.4027

Epoch 00461: val_loss did not improve from 1.29380
Epoch 462/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4078 - val_loss: 1.2955 - val_accuracy: 0.4203

Epoch 00462: val_loss did not improve from 1.29380
Epoch 463/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4063 - val_loss: 1.2931 - val_accuracy: 0.4163

Epoch 00463: val_loss improved from 1.29380 to 1.29314, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 464/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4043 - val_loss: 1.3032 - val_accuracy: 0.3963

Epoch 00464: val_loss did not improve from 1.29314
Epoch 465/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4030 - val_loss: 1.2960 - val_accuracy: 0.4139

Epoch 00465: val_loss did not improve from 1.29314
Epoch 466/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4044 - val_loss: 1.2997 - val_accuracy: 0.4003

Epoch 00466: val_loss did not improve from 1.29314
Epoch 467/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4009 - val_loss: 1.3019 - val_accuracy: 0.4027

Epoch 00467: val_loss did not improve from 1.29314
Epoch 468/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4029 - val_loss: 1.2962 - val_accuracy: 0.4051

Epoch 00468: val_loss did not improve from 1.29314
Epoch 469/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4063 - val_loss: 1.2938 - val_accuracy: 0.4139

Epoch 00469: val_loss did not improve from 1.29314
Epoch 470/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4002 - val_loss: 1.3045 - val_accuracy: 0.4019

Epoch 00470: val_loss did not improve from 1.29314
Epoch 471/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.3970 - val_loss: 1.2968 - val_accuracy: 0.3995

Epoch 00471: val_loss did not improve from 1.29314
Epoch 472/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4055 - val_loss: 1.2953 - val_accuracy: 0.4083

Epoch 00472: val_loss did not improve from 1.29314
Epoch 473/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4027 - val_loss: 1.3010 - val_accuracy: 0.3947

Epoch 00473: val_loss did not improve from 1.29314
Epoch 474/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4047 - val_loss: 1.2960 - val_accuracy: 0.4139

Epoch 00474: val_loss did not improve from 1.29314
Epoch 475/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4052 - val_loss: 1.3030 - val_accuracy: 0.4115

Epoch 00475: val_loss did not improve from 1.29314
Epoch 476/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4063 - val_loss: 1.2986 - val_accuracy: 0.3979

Epoch 00476: val_loss did not improve from 1.29314
Epoch 477/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4100 - val_loss: 1.2936 - val_accuracy: 0.4067

Epoch 00477: val_loss did not improve from 1.29314
Epoch 478/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4039 - val_loss: 1.2976 - val_accuracy: 0.3995

Epoch 00478: val_loss did not improve from 1.29314
Epoch 479/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4022 - val_loss: 1.2974 - val_accuracy: 0.3963

Epoch 00479: val_loss did not improve from 1.29314
Epoch 480/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4056 - val_loss: 1.2928 - val_accuracy: 0.4027

Epoch 00480: val_loss improved from 1.29314 to 1.29282, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 481/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4005 - val_loss: 1.3152 - val_accuracy: 0.4043

Epoch 00481: val_loss did not improve from 1.29282
Epoch 482/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4022 - val_loss: 1.2951 - val_accuracy: 0.4123

Epoch 00482: val_loss did not improve from 1.29282
Epoch 483/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.3999 - val_loss: 1.3021 - val_accuracy: 0.3860

Epoch 00483: val_loss did not improve from 1.29282
Epoch 484/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4029 - val_loss: 1.2970 - val_accuracy: 0.4067

Epoch 00484: val_loss did not improve from 1.29282
Epoch 485/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4085 - val_loss: 1.2973 - val_accuracy: 0.3987

Epoch 00485: val_loss did not improve from 1.29282
Epoch 486/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4052 - val_loss: 1.2953 - val_accuracy: 0.4019

Epoch 00486: val_loss did not improve from 1.29282
Epoch 487/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.3978 - val_loss: 1.2971 - val_accuracy: 0.4027

Epoch 00487: val_loss did not improve from 1.29282
Epoch 488/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4005 - val_loss: 1.2998 - val_accuracy: 0.3963

Epoch 00488: val_loss did not improve from 1.29282
Epoch 489/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4075 - val_loss: 1.2988 - val_accuracy: 0.4059

Epoch 00489: val_loss did not improve from 1.29282
Epoch 490/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4019 - val_loss: 1.2950 - val_accuracy: 0.4091

Epoch 00490: val_loss did not improve from 1.29282
Epoch 491/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4096 - val_loss: 1.2941 - val_accuracy: 0.4059

Epoch 00491: val_loss did not improve from 1.29282
Epoch 492/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4078 - val_loss: 1.2988 - val_accuracy: 0.3931

Epoch 00492: val_loss did not improve from 1.29282
Epoch 493/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4061 - val_loss: 1.2994 - val_accuracy: 0.3979

Epoch 00493: val_loss did not improve from 1.29282
Epoch 494/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4055 - val_loss: 1.2949 - val_accuracy: 0.4123

Epoch 00494: val_loss did not improve from 1.29282
Epoch 495/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4045 - val_loss: 1.2979 - val_accuracy: 0.4027

Epoch 00495: val_loss did not improve from 1.29282
Epoch 496/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4063 - val_loss: 1.2932 - val_accuracy: 0.4075

Epoch 00496: val_loss did not improve from 1.29282
Epoch 497/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.3981 - val_loss: 1.3039 - val_accuracy: 0.4003

Epoch 00497: val_loss did not improve from 1.29282
Epoch 498/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4092 - val_loss: 1.3002 - val_accuracy: 0.4043

Epoch 00498: val_loss did not improve from 1.29282
Epoch 499/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4065 - val_loss: 1.2932 - val_accuracy: 0.4099

Epoch 00499: val_loss did not improve from 1.29282
Epoch 500/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4051 - val_loss: 1.3049 - val_accuracy: 0.3955

Epoch 00500: val_loss did not improve from 1.29282
Epoch 501/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4059 - val_loss: 1.2950 - val_accuracy: 0.4083

Epoch 00501: val_loss did not improve from 1.29282
Epoch 502/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4083 - val_loss: 1.2968 - val_accuracy: 0.4067

Epoch 00502: val_loss did not improve from 1.29282
Epoch 503/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4038 - val_loss: 1.2962 - val_accuracy: 0.4083

Epoch 00503: val_loss did not improve from 1.29282
Epoch 504/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4048 - val_loss: 1.2968 - val_accuracy: 0.4067

Epoch 00504: val_loss did not improve from 1.29282
Epoch 505/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4082 - val_loss: 1.2992 - val_accuracy: 0.4051

Epoch 00505: val_loss did not improve from 1.29282
Epoch 506/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4066 - val_loss: 1.2955 - val_accuracy: 0.4091

Epoch 00506: val_loss did not improve from 1.29282
Epoch 507/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4102 - val_loss: 1.2983 - val_accuracy: 0.3995

Epoch 00507: val_loss did not improve from 1.29282
Epoch 508/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4005 - val_loss: 1.2950 - val_accuracy: 0.4043

Epoch 00508: val_loss did not improve from 1.29282
Epoch 509/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4044 - val_loss: 1.2938 - val_accuracy: 0.4203

Epoch 00509: val_loss did not improve from 1.29282
Epoch 510/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4055 - val_loss: 1.2968 - val_accuracy: 0.4123

Epoch 00510: val_loss did not improve from 1.29282
Epoch 511/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4078 - val_loss: 1.2939 - val_accuracy: 0.4099

Epoch 00511: val_loss did not improve from 1.29282
Epoch 512/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4079 - val_loss: 1.2972 - val_accuracy: 0.4043

Epoch 00512: val_loss did not improve from 1.29282
Epoch 513/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4093 - val_loss: 1.2925 - val_accuracy: 0.4163

Epoch 00513: val_loss improved from 1.29282 to 1.29255, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 514/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4047 - val_loss: 1.3057 - val_accuracy: 0.3987

Epoch 00514: val_loss did not improve from 1.29255
Epoch 515/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4045 - val_loss: 1.2938 - val_accuracy: 0.4155

Epoch 00515: val_loss did not improve from 1.29255
Epoch 516/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4109 - val_loss: 1.2934 - val_accuracy: 0.4211

Epoch 00516: val_loss did not improve from 1.29255
Epoch 517/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4076 - val_loss: 1.3053 - val_accuracy: 0.4027

Epoch 00517: val_loss did not improve from 1.29255
Epoch 518/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4060 - val_loss: 1.2936 - val_accuracy: 0.3971

Epoch 00518: val_loss did not improve from 1.29255
Epoch 519/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4047 - val_loss: 1.2952 - val_accuracy: 0.3971

Epoch 00519: val_loss did not improve from 1.29255
Epoch 520/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4052 - val_loss: 1.2933 - val_accuracy: 0.4123

Epoch 00520: val_loss did not improve from 1.29255
Epoch 521/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4067 - val_loss: 1.2988 - val_accuracy: 0.3963

Epoch 00521: val_loss did not improve from 1.29255
Epoch 522/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4040 - val_loss: 1.2967 - val_accuracy: 0.3995

Epoch 00522: val_loss did not improve from 1.29255
Epoch 523/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4096 - val_loss: 1.2928 - val_accuracy: 0.4091

Epoch 00523: val_loss did not improve from 1.29255
Epoch 524/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4102 - val_loss: 1.2924 - val_accuracy: 0.4059

Epoch 00524: val_loss improved from 1.29255 to 1.29244, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 525/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4055 - val_loss: 1.3063 - val_accuracy: 0.3971

Epoch 00525: val_loss did not improve from 1.29244
Epoch 526/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4089 - val_loss: 1.2956 - val_accuracy: 0.4059

Epoch 00526: val_loss did not improve from 1.29244
Epoch 527/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4011 - val_loss: 1.2956 - val_accuracy: 0.3987

Epoch 00527: val_loss did not improve from 1.29244
Epoch 528/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4088 - val_loss: 1.2952 - val_accuracy: 0.4099

Epoch 00528: val_loss did not improve from 1.29244
Epoch 529/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4088 - val_loss: 1.2962 - val_accuracy: 0.4027

Epoch 00529: val_loss did not improve from 1.29244
Epoch 530/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4064 - val_loss: 1.2925 - val_accuracy: 0.4099

Epoch 00530: val_loss did not improve from 1.29244
Epoch 531/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4048 - val_loss: 1.2951 - val_accuracy: 0.3971

Epoch 00531: val_loss did not improve from 1.29244
Epoch 532/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4056 - val_loss: 1.2998 - val_accuracy: 0.3963

Epoch 00532: val_loss did not improve from 1.29244
Epoch 533/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4063 - val_loss: 1.2968 - val_accuracy: 0.3955

Epoch 00533: val_loss did not improve from 1.29244
Epoch 534/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4057 - val_loss: 1.2941 - val_accuracy: 0.4099

Epoch 00534: val_loss did not improve from 1.29244
Epoch 535/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4065 - val_loss: 1.2908 - val_accuracy: 0.4187

Epoch 00535: val_loss improved from 1.29244 to 1.29083, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 536/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4020 - val_loss: 1.2934 - val_accuracy: 0.3971

Epoch 00536: val_loss did not improve from 1.29083
Epoch 537/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4082 - val_loss: 1.3004 - val_accuracy: 0.4043

Epoch 00537: val_loss did not improve from 1.29083
Epoch 538/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4039 - val_loss: 1.2961 - val_accuracy: 0.4003

Epoch 00538: val_loss did not improve from 1.29083
Epoch 539/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4107 - val_loss: 1.2917 - val_accuracy: 0.4219

Epoch 00539: val_loss did not improve from 1.29083
Epoch 540/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4097 - val_loss: 1.3027 - val_accuracy: 0.3860

Epoch 00540: val_loss did not improve from 1.29083
Epoch 541/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.3982 - val_loss: 1.2990 - val_accuracy: 0.3812

Epoch 00541: val_loss did not improve from 1.29083
Epoch 542/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4058 - val_loss: 1.2928 - val_accuracy: 0.4171

Epoch 00542: val_loss did not improve from 1.29083
Epoch 543/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4048 - val_loss: 1.2927 - val_accuracy: 0.4051

Epoch 00543: val_loss did not improve from 1.29083
Epoch 544/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4070 - val_loss: 1.3075 - val_accuracy: 0.3907

Epoch 00544: val_loss did not improve from 1.29083
Epoch 545/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.3994 - val_loss: 1.2928 - val_accuracy: 0.4035

Epoch 00545: val_loss did not improve from 1.29083
Epoch 546/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4059 - val_loss: 1.2921 - val_accuracy: 0.4171

Epoch 00546: val_loss did not improve from 1.29083
Epoch 547/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4061 - val_loss: 1.2989 - val_accuracy: 0.3995

Epoch 00547: val_loss did not improve from 1.29083
Epoch 548/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4035 - val_loss: 1.2972 - val_accuracy: 0.3987

Epoch 00548: val_loss did not improve from 1.29083
Epoch 549/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4102 - val_loss: 1.3005 - val_accuracy: 0.4003

Epoch 00549: val_loss did not improve from 1.29083
Epoch 550/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4073 - val_loss: 1.2918 - val_accuracy: 0.4147

Epoch 00550: val_loss did not improve from 1.29083
Epoch 551/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4036 - val_loss: 1.2963 - val_accuracy: 0.4083

Epoch 00551: val_loss did not improve from 1.29083
Epoch 552/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4108 - val_loss: 1.2979 - val_accuracy: 0.4027

Epoch 00552: val_loss did not improve from 1.29083
Epoch 553/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4089 - val_loss: 1.2937 - val_accuracy: 0.4139

Epoch 00553: val_loss did not improve from 1.29083
Epoch 554/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4071 - val_loss: 1.2933 - val_accuracy: 0.4107

Epoch 00554: val_loss did not improve from 1.29083
Epoch 555/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4047 - val_loss: 1.2909 - val_accuracy: 0.4051

Epoch 00555: val_loss did not improve from 1.29083
Epoch 556/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4058 - val_loss: 1.3018 - val_accuracy: 0.3947

Epoch 00556: val_loss did not improve from 1.29083
Epoch 557/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4110 - val_loss: 1.2947 - val_accuracy: 0.3987

Epoch 00557: val_loss did not improve from 1.29083
Epoch 558/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4095 - val_loss: 1.2928 - val_accuracy: 0.4203

Epoch 00558: val_loss did not improve from 1.29083
Epoch 559/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4100 - val_loss: 1.2974 - val_accuracy: 0.4003

Epoch 00559: val_loss did not improve from 1.29083
Epoch 560/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4051 - val_loss: 1.2944 - val_accuracy: 0.3995

Epoch 00560: val_loss did not improve from 1.29083
Epoch 561/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4094 - val_loss: 1.2908 - val_accuracy: 0.4107

Epoch 00561: val_loss improved from 1.29083 to 1.29080, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 562/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4024 - val_loss: 1.2977 - val_accuracy: 0.3939

Epoch 00562: val_loss did not improve from 1.29080
Epoch 563/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4072 - val_loss: 1.2919 - val_accuracy: 0.4123

Epoch 00563: val_loss did not improve from 1.29080
Epoch 564/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4071 - val_loss: 1.2961 - val_accuracy: 0.4059

Epoch 00564: val_loss did not improve from 1.29080
Epoch 565/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4048 - val_loss: 1.2987 - val_accuracy: 0.3947

Epoch 00565: val_loss did not improve from 1.29080
Epoch 566/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.3996 - val_loss: 1.2991 - val_accuracy: 0.3844

Epoch 00566: val_loss did not improve from 1.29080
Epoch 567/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4069 - val_loss: 1.2936 - val_accuracy: 0.4091

Epoch 00567: val_loss did not improve from 1.29080
Epoch 568/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4064 - val_loss: 1.2982 - val_accuracy: 0.3884

Epoch 00568: val_loss did not improve from 1.29080
Epoch 569/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4053 - val_loss: 1.2923 - val_accuracy: 0.4011

Epoch 00569: val_loss did not improve from 1.29080
Epoch 570/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4087 - val_loss: 1.2912 - val_accuracy: 0.4067

Epoch 00570: val_loss did not improve from 1.29080
Epoch 571/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4002 - val_loss: 1.3045 - val_accuracy: 0.3963

Epoch 00571: val_loss did not improve from 1.29080
Epoch 572/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4094 - val_loss: 1.2950 - val_accuracy: 0.4107

Epoch 00572: val_loss did not improve from 1.29080
Epoch 573/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4101 - val_loss: 1.2918 - val_accuracy: 0.4075

Epoch 00573: val_loss did not improve from 1.29080
Epoch 574/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4104 - val_loss: 1.2961 - val_accuracy: 0.3963

Epoch 00574: val_loss did not improve from 1.29080
Epoch 575/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4048 - val_loss: 1.2976 - val_accuracy: 0.4067

Epoch 00575: val_loss did not improve from 1.29080
Epoch 576/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4086 - val_loss: 1.2923 - val_accuracy: 0.4139

Epoch 00576: val_loss did not improve from 1.29080
Epoch 577/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4124 - val_loss: 1.2925 - val_accuracy: 0.4035

Epoch 00577: val_loss did not improve from 1.29080
Epoch 578/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4051 - val_loss: 1.2993 - val_accuracy: 0.4035

Epoch 00578: val_loss did not improve from 1.29080
Epoch 579/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4091 - val_loss: 1.2892 - val_accuracy: 0.4234

Epoch 00579: val_loss improved from 1.29080 to 1.28922, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 580/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4130 - val_loss: 1.2906 - val_accuracy: 0.4075

Epoch 00580: val_loss did not improve from 1.28922
Epoch 581/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4116 - val_loss: 1.2942 - val_accuracy: 0.4115

Epoch 00581: val_loss did not improve from 1.28922
Epoch 582/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4101 - val_loss: 1.2934 - val_accuracy: 0.4107

Epoch 00582: val_loss did not improve from 1.28922
Epoch 583/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4098 - val_loss: 1.2898 - val_accuracy: 0.4043

Epoch 00583: val_loss did not improve from 1.28922
Epoch 584/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4081 - val_loss: 1.2919 - val_accuracy: 0.4019

Epoch 00584: val_loss did not improve from 1.28922
Epoch 585/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4070 - val_loss: 1.2922 - val_accuracy: 0.4019

Epoch 00585: val_loss did not improve from 1.28922
Epoch 586/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4082 - val_loss: 1.3000 - val_accuracy: 0.4035

Epoch 00586: val_loss did not improve from 1.28922
Epoch 587/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4123 - val_loss: 1.2917 - val_accuracy: 0.4155

Epoch 00587: val_loss did not improve from 1.28922
Epoch 588/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4078 - val_loss: 1.2922 - val_accuracy: 0.4051

Epoch 00588: val_loss did not improve from 1.28922
Epoch 589/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4083 - val_loss: 1.2934 - val_accuracy: 0.4019

Epoch 00589: val_loss did not improve from 1.28922
Epoch 590/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4094 - val_loss: 1.2952 - val_accuracy: 0.4003

Epoch 00590: val_loss did not improve from 1.28922
Epoch 591/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4076 - val_loss: 1.2902 - val_accuracy: 0.4075

Epoch 00591: val_loss did not improve from 1.28922
Epoch 592/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4110 - val_loss: 1.2946 - val_accuracy: 0.4059

Epoch 00592: val_loss did not improve from 1.28922
Epoch 593/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4088 - val_loss: 1.2923 - val_accuracy: 0.4075

Epoch 00593: val_loss did not improve from 1.28922
Epoch 594/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4077 - val_loss: 1.2919 - val_accuracy: 0.4059

Epoch 00594: val_loss did not improve from 1.28922
Epoch 595/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4067 - val_loss: 1.2932 - val_accuracy: 0.4035

Epoch 00595: val_loss did not improve from 1.28922
Epoch 596/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4063 - val_loss: 1.2908 - val_accuracy: 0.4035

Epoch 00596: val_loss did not improve from 1.28922
Epoch 597/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4145 - val_loss: 1.2899 - val_accuracy: 0.4203

Epoch 00597: val_loss did not improve from 1.28922
Epoch 598/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4077 - val_loss: 1.2988 - val_accuracy: 0.3979

Epoch 00598: val_loss did not improve from 1.28922
Epoch 599/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4067 - val_loss: 1.2965 - val_accuracy: 0.3907

Epoch 00599: val_loss did not improve from 1.28922
Epoch 600/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4081 - val_loss: 1.2930 - val_accuracy: 0.4043

Epoch 00600: val_loss did not improve from 1.28922
Epoch 601/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4075 - val_loss: 1.2912 - val_accuracy: 0.4147

Epoch 00601: val_loss did not improve from 1.28922
Epoch 602/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4099 - val_loss: 1.2926 - val_accuracy: 0.4091

Epoch 00602: val_loss did not improve from 1.28922
Epoch 603/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4061 - val_loss: 1.2889 - val_accuracy: 0.4091

Epoch 00603: val_loss improved from 1.28922 to 1.28893, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 604/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4078 - val_loss: 1.2900 - val_accuracy: 0.4043

Epoch 00604: val_loss did not improve from 1.28893
Epoch 605/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4074 - val_loss: 1.2939 - val_accuracy: 0.3939

Epoch 00605: val_loss did not improve from 1.28893
Epoch 606/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4085 - val_loss: 1.2899 - val_accuracy: 0.4027

Epoch 00606: val_loss did not improve from 1.28893
Epoch 607/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4093 - val_loss: 1.2935 - val_accuracy: 0.4035

Epoch 00607: val_loss did not improve from 1.28893
Epoch 608/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4094 - val_loss: 1.2888 - val_accuracy: 0.4147

Epoch 00608: val_loss improved from 1.28893 to 1.28884, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 609/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4117 - val_loss: 1.2990 - val_accuracy: 0.3939

Epoch 00609: val_loss did not improve from 1.28884
Epoch 610/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4086 - val_loss: 1.2915 - val_accuracy: 0.4115

Epoch 00610: val_loss did not improve from 1.28884
Epoch 611/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4069 - val_loss: 1.2934 - val_accuracy: 0.4027

Epoch 00611: val_loss did not improve from 1.28884
Epoch 612/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4078 - val_loss: 1.2923 - val_accuracy: 0.3979

Epoch 00612: val_loss did not improve from 1.28884
Epoch 613/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4060 - val_loss: 1.2911 - val_accuracy: 0.4139

Epoch 00613: val_loss did not improve from 1.28884
Epoch 614/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4080 - val_loss: 1.2987 - val_accuracy: 0.3971

Epoch 00614: val_loss did not improve from 1.28884
Epoch 615/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4095 - val_loss: 1.2921 - val_accuracy: 0.4131

Epoch 00615: val_loss did not improve from 1.28884
Epoch 616/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4060 - val_loss: 1.2933 - val_accuracy: 0.4035

Epoch 00616: val_loss did not improve from 1.28884
Epoch 617/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4097 - val_loss: 1.2964 - val_accuracy: 0.4011

Epoch 00617: val_loss did not improve from 1.28884
Epoch 618/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4084 - val_loss: 1.2966 - val_accuracy: 0.4035

Epoch 00618: val_loss did not improve from 1.28884
Epoch 619/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4073 - val_loss: 1.2943 - val_accuracy: 0.4027

Epoch 00619: val_loss did not improve from 1.28884
Epoch 620/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4114 - val_loss: 1.2923 - val_accuracy: 0.3995

Epoch 00620: val_loss did not improve from 1.28884
Epoch 621/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4087 - val_loss: 1.2897 - val_accuracy: 0.4187

Epoch 00621: val_loss did not improve from 1.28884
Epoch 622/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4067 - val_loss: 1.2912 - val_accuracy: 0.3955

Epoch 00622: val_loss did not improve from 1.28884
Epoch 623/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4099 - val_loss: 1.2915 - val_accuracy: 0.4011

Epoch 00623: val_loss did not improve from 1.28884
Epoch 624/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4101 - val_loss: 1.2905 - val_accuracy: 0.4051

Epoch 00624: val_loss did not improve from 1.28884
Epoch 625/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4114 - val_loss: 1.2903 - val_accuracy: 0.4139

Epoch 00625: val_loss did not improve from 1.28884
Epoch 626/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4075 - val_loss: 1.2883 - val_accuracy: 0.4226

Epoch 00626: val_loss improved from 1.28884 to 1.28826, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 627/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4071 - val_loss: 1.2922 - val_accuracy: 0.4059

Epoch 00627: val_loss did not improve from 1.28826
Epoch 628/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4129 - val_loss: 1.2900 - val_accuracy: 0.3963

Epoch 00628: val_loss did not improve from 1.28826
Epoch 629/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4088 - val_loss: 1.2923 - val_accuracy: 0.4035

Epoch 00629: val_loss did not improve from 1.28826
Epoch 630/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4073 - val_loss: 1.2877 - val_accuracy: 0.4211

Epoch 00630: val_loss improved from 1.28826 to 1.28771, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 631/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4104 - val_loss: 1.3041 - val_accuracy: 0.3955

Epoch 00631: val_loss did not improve from 1.28771
Epoch 632/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4035 - val_loss: 1.2886 - val_accuracy: 0.4155

Epoch 00632: val_loss did not improve from 1.28771
Epoch 633/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4099 - val_loss: 1.2887 - val_accuracy: 0.4187

Epoch 00633: val_loss did not improve from 1.28771
Epoch 634/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4096 - val_loss: 1.2966 - val_accuracy: 0.4011

Epoch 00634: val_loss did not improve from 1.28771
Epoch 635/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4093 - val_loss: 1.2928 - val_accuracy: 0.3955

Epoch 00635: val_loss did not improve from 1.28771
Epoch 636/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4058 - val_loss: 1.2909 - val_accuracy: 0.4059

Epoch 00636: val_loss did not improve from 1.28771
Epoch 637/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4112 - val_loss: 1.2933 - val_accuracy: 0.3923

Epoch 00637: val_loss did not improve from 1.28771
Epoch 638/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4081 - val_loss: 1.2936 - val_accuracy: 0.4059

Epoch 00638: val_loss did not improve from 1.28771
Epoch 639/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4137 - val_loss: 1.2885 - val_accuracy: 0.4123

Epoch 00639: val_loss did not improve from 1.28771
Epoch 640/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4095 - val_loss: 1.2918 - val_accuracy: 0.4003

Epoch 00640: val_loss did not improve from 1.28771
Epoch 641/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4026 - val_loss: 1.2939 - val_accuracy: 0.4003

Epoch 00641: val_loss did not improve from 1.28771
Epoch 642/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4102 - val_loss: 1.2932 - val_accuracy: 0.4115

Epoch 00642: val_loss did not improve from 1.28771
Epoch 643/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4024 - val_loss: 1.2942 - val_accuracy: 0.3939

Epoch 00643: val_loss did not improve from 1.28771
Epoch 644/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4125 - val_loss: 1.2878 - val_accuracy: 0.4298

Epoch 00644: val_loss did not improve from 1.28771
Epoch 645/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4040 - val_loss: 1.2975 - val_accuracy: 0.3963

Epoch 00645: val_loss did not improve from 1.28771
Epoch 646/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4069 - val_loss: 1.2888 - val_accuracy: 0.4003

Epoch 00646: val_loss did not improve from 1.28771
Epoch 647/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4104 - val_loss: 1.2904 - val_accuracy: 0.4027

Epoch 00647: val_loss did not improve from 1.28771
Epoch 648/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4117 - val_loss: 1.2911 - val_accuracy: 0.4059

Epoch 00648: val_loss did not improve from 1.28771
Epoch 649/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4106 - val_loss: 1.2889 - val_accuracy: 0.4003

Epoch 00649: val_loss did not improve from 1.28771
Epoch 650/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4100 - val_loss: 1.2921 - val_accuracy: 0.4043

Epoch 00650: val_loss did not improve from 1.28771
Epoch 651/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4103 - val_loss: 1.2901 - val_accuracy: 0.3955

Epoch 00651: val_loss did not improve from 1.28771
Epoch 652/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4135 - val_loss: 1.2885 - val_accuracy: 0.4163

Epoch 00652: val_loss did not improve from 1.28771
Epoch 653/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4071 - val_loss: 1.2916 - val_accuracy: 0.4011

Epoch 00653: val_loss did not improve from 1.28771
Epoch 654/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4096 - val_loss: 1.2898 - val_accuracy: 0.4059

Epoch 00654: val_loss did not improve from 1.28771
Epoch 655/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4101 - val_loss: 1.2889 - val_accuracy: 0.4123

Epoch 00655: val_loss did not improve from 1.28771
Epoch 656/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4069 - val_loss: 1.2920 - val_accuracy: 0.4059

Epoch 00656: val_loss did not improve from 1.28771
Epoch 657/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4099 - val_loss: 1.2886 - val_accuracy: 0.4099

Epoch 00657: val_loss did not improve from 1.28771
Epoch 658/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4107 - val_loss: 1.2885 - val_accuracy: 0.4003

Epoch 00658: val_loss did not improve from 1.28771
Epoch 659/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4114 - val_loss: 1.2917 - val_accuracy: 0.4043

Epoch 00659: val_loss did not improve from 1.28771
Epoch 660/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4108 - val_loss: 1.2875 - val_accuracy: 0.4226

Epoch 00660: val_loss improved from 1.28771 to 1.28752, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 661/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4055 - val_loss: 1.2890 - val_accuracy: 0.4043

Epoch 00661: val_loss did not improve from 1.28752
Epoch 662/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4094 - val_loss: 1.2918 - val_accuracy: 0.4067

Epoch 00662: val_loss did not improve from 1.28752
Epoch 663/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4085 - val_loss: 1.2884 - val_accuracy: 0.4099

Epoch 00663: val_loss did not improve from 1.28752
Epoch 664/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4078 - val_loss: 1.2911 - val_accuracy: 0.4019

Epoch 00664: val_loss did not improve from 1.28752
Epoch 665/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4104 - val_loss: 1.2871 - val_accuracy: 0.3995

Epoch 00665: val_loss improved from 1.28752 to 1.28705, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 666/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4094 - val_loss: 1.2887 - val_accuracy: 0.4019

Epoch 00666: val_loss did not improve from 1.28705
Epoch 667/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4094 - val_loss: 1.3015 - val_accuracy: 0.4035

Epoch 00667: val_loss did not improve from 1.28705
Epoch 668/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4107 - val_loss: 1.2912 - val_accuracy: 0.4011

Epoch 00668: val_loss did not improve from 1.28705
Epoch 669/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4102 - val_loss: 1.2881 - val_accuracy: 0.4258

Epoch 00669: val_loss did not improve from 1.28705
Epoch 670/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4084 - val_loss: 1.3023 - val_accuracy: 0.4011

Epoch 00670: val_loss did not improve from 1.28705
Epoch 671/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4078 - val_loss: 1.2882 - val_accuracy: 0.4043

Epoch 00671: val_loss did not improve from 1.28705
Epoch 672/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4112 - val_loss: 1.2884 - val_accuracy: 0.4075

Epoch 00672: val_loss did not improve from 1.28705
Epoch 673/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4104 - val_loss: 1.2977 - val_accuracy: 0.3860

Epoch 00673: val_loss did not improve from 1.28705
Epoch 674/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4093 - val_loss: 1.2866 - val_accuracy: 0.4051

Epoch 00674: val_loss improved from 1.28705 to 1.28660, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 675/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4132 - val_loss: 1.2895 - val_accuracy: 0.4123

Epoch 00675: val_loss did not improve from 1.28660
Epoch 676/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4125 - val_loss: 1.2878 - val_accuracy: 0.4115

Epoch 00676: val_loss did not improve from 1.28660
Epoch 677/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4089 - val_loss: 1.2889 - val_accuracy: 0.4155

Epoch 00677: val_loss did not improve from 1.28660
Epoch 678/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4058 - val_loss: 1.2991 - val_accuracy: 0.3995

Epoch 00678: val_loss did not improve from 1.28660
Epoch 679/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4109 - val_loss: 1.2855 - val_accuracy: 0.4123

Epoch 00679: val_loss improved from 1.28660 to 1.28545, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 680/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4114 - val_loss: 1.2901 - val_accuracy: 0.4019

Epoch 00680: val_loss did not improve from 1.28545
Epoch 681/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4109 - val_loss: 1.2908 - val_accuracy: 0.3955

Epoch 00681: val_loss did not improve from 1.28545
Epoch 682/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4115 - val_loss: 1.2872 - val_accuracy: 0.4155

Epoch 00682: val_loss did not improve from 1.28545
Epoch 683/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4105 - val_loss: 1.2870 - val_accuracy: 0.4107

Epoch 00683: val_loss did not improve from 1.28545
Epoch 684/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4105 - val_loss: 1.2847 - val_accuracy: 0.4011

Epoch 00684: val_loss improved from 1.28545 to 1.28474, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 685/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4127 - val_loss: 1.2841 - val_accuracy: 0.4107

Epoch 00685: val_loss improved from 1.28474 to 1.28412, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 686/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4109 - val_loss: 1.2879 - val_accuracy: 0.4115

Epoch 00686: val_loss did not improve from 1.28412
Epoch 687/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4114 - val_loss: 1.3041 - val_accuracy: 0.3995

Epoch 00687: val_loss did not improve from 1.28412
Epoch 688/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4104 - val_loss: 1.2858 - val_accuracy: 0.4322

Epoch 00688: val_loss did not improve from 1.28412
Epoch 689/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4107 - val_loss: 1.2882 - val_accuracy: 0.4099

Epoch 00689: val_loss did not improve from 1.28412
Epoch 690/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4108 - val_loss: 1.2870 - val_accuracy: 0.4099

Epoch 00690: val_loss did not improve from 1.28412
Epoch 691/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4138 - val_loss: 1.2876 - val_accuracy: 0.4099

Epoch 00691: val_loss did not improve from 1.28412
Epoch 692/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4069 - val_loss: 1.3015 - val_accuracy: 0.4011

Epoch 00692: val_loss did not improve from 1.28412
Epoch 693/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4072 - val_loss: 1.2864 - val_accuracy: 0.4115

Epoch 00693: val_loss did not improve from 1.28412
Epoch 694/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4113 - val_loss: 1.2875 - val_accuracy: 0.4139

Epoch 00694: val_loss did not improve from 1.28412
Epoch 695/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4113 - val_loss: 1.2918 - val_accuracy: 0.3995

Epoch 00695: val_loss did not improve from 1.28412
Epoch 696/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4134 - val_loss: 1.2890 - val_accuracy: 0.4043

Epoch 00696: val_loss did not improve from 1.28412
Epoch 697/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4098 - val_loss: 1.2894 - val_accuracy: 0.4163

Epoch 00697: val_loss did not improve from 1.28412
Epoch 698/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4086 - val_loss: 1.2981 - val_accuracy: 0.3979

Epoch 00698: val_loss did not improve from 1.28412
Epoch 699/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4134 - val_loss: 1.2857 - val_accuracy: 0.3979

Epoch 00699: val_loss did not improve from 1.28412
Epoch 700/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4117 - val_loss: 1.2884 - val_accuracy: 0.3963

Epoch 00700: val_loss did not improve from 1.28412
Epoch 701/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4105 - val_loss: 1.2935 - val_accuracy: 0.4123

Epoch 00701: val_loss did not improve from 1.28412
Epoch 702/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4104 - val_loss: 1.2864 - val_accuracy: 0.4139

Epoch 00702: val_loss did not improve from 1.28412
Epoch 703/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4114 - val_loss: 1.2888 - val_accuracy: 0.4067

Epoch 00703: val_loss did not improve from 1.28412
Epoch 704/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4122 - val_loss: 1.2917 - val_accuracy: 0.4003

Epoch 00704: val_loss did not improve from 1.28412
Epoch 705/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4109 - val_loss: 1.2885 - val_accuracy: 0.4083

Epoch 00705: val_loss did not improve from 1.28412
Epoch 706/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4137 - val_loss: 1.2864 - val_accuracy: 0.4155

Epoch 00706: val_loss did not improve from 1.28412
Epoch 707/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4113 - val_loss: 1.2937 - val_accuracy: 0.3955

Epoch 00707: val_loss did not improve from 1.28412
Epoch 708/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4128 - val_loss: 1.2856 - val_accuracy: 0.4075

Epoch 00708: val_loss did not improve from 1.28412
Epoch 709/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4085 - val_loss: 1.2841 - val_accuracy: 0.4234

Epoch 00709: val_loss did not improve from 1.28412
Epoch 710/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4112 - val_loss: 1.3049 - val_accuracy: 0.3939

Epoch 00710: val_loss did not improve from 1.28412
Epoch 711/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4100 - val_loss: 1.2872 - val_accuracy: 0.4139

Epoch 00711: val_loss did not improve from 1.28412
Epoch 712/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4094 - val_loss: 1.2891 - val_accuracy: 0.4011

Epoch 00712: val_loss did not improve from 1.28412
Epoch 713/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4150 - val_loss: 1.2901 - val_accuracy: 0.4027

Epoch 00713: val_loss did not improve from 1.28412
Epoch 714/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4063 - val_loss: 1.2882 - val_accuracy: 0.4051

Epoch 00714: val_loss did not improve from 1.28412
Epoch 715/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4101 - val_loss: 1.2864 - val_accuracy: 0.4003

Epoch 00715: val_loss did not improve from 1.28412
Epoch 716/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4119 - val_loss: 1.2901 - val_accuracy: 0.3939

Epoch 00716: val_loss did not improve from 1.28412
Epoch 717/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4131 - val_loss: 1.2845 - val_accuracy: 0.4035

Epoch 00717: val_loss did not improve from 1.28412
Epoch 718/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4125 - val_loss: 1.2881 - val_accuracy: 0.4027

Epoch 00718: val_loss did not improve from 1.28412
Epoch 719/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4047 - val_loss: 1.2918 - val_accuracy: 0.3971

Epoch 00719: val_loss did not improve from 1.28412
Epoch 720/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4116 - val_loss: 1.2840 - val_accuracy: 0.4059

Epoch 00720: val_loss improved from 1.28412 to 1.28397, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 721/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4120 - val_loss: 1.2845 - val_accuracy: 0.4059

Epoch 00721: val_loss did not improve from 1.28397
Epoch 722/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4111 - val_loss: 1.2864 - val_accuracy: 0.4075

Epoch 00722: val_loss did not improve from 1.28397
Epoch 723/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4114 - val_loss: 1.2970 - val_accuracy: 0.4011

Epoch 00723: val_loss did not improve from 1.28397
Epoch 724/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4098 - val_loss: 1.2854 - val_accuracy: 0.4155

Epoch 00724: val_loss did not improve from 1.28397
Epoch 725/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4118 - val_loss: 1.2833 - val_accuracy: 0.4171

Epoch 00725: val_loss improved from 1.28397 to 1.28332, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 726/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4134 - val_loss: 1.2939 - val_accuracy: 0.4051

Epoch 00726: val_loss did not improve from 1.28332
Epoch 727/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4117 - val_loss: 1.2881 - val_accuracy: 0.4027

Epoch 00727: val_loss did not improve from 1.28332
Epoch 728/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4129 - val_loss: 1.2853 - val_accuracy: 0.4171

Epoch 00728: val_loss did not improve from 1.28332
Epoch 729/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4119 - val_loss: 1.2855 - val_accuracy: 0.4067

Epoch 00729: val_loss did not improve from 1.28332
Epoch 730/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4123 - val_loss: 1.2901 - val_accuracy: 0.4067

Epoch 00730: val_loss did not improve from 1.28332
Epoch 731/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4103 - val_loss: 1.2848 - val_accuracy: 0.4107

Epoch 00731: val_loss did not improve from 1.28332
Epoch 732/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4109 - val_loss: 1.2879 - val_accuracy: 0.4027

Epoch 00732: val_loss did not improve from 1.28332
Epoch 733/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4086 - val_loss: 1.2855 - val_accuracy: 0.4115

Epoch 00733: val_loss did not improve from 1.28332
Epoch 734/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4096 - val_loss: 1.2865 - val_accuracy: 0.4147

Epoch 00734: val_loss did not improve from 1.28332
Epoch 735/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4113 - val_loss: 1.2878 - val_accuracy: 0.4139

Epoch 00735: val_loss did not improve from 1.28332
Epoch 736/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4140 - val_loss: 1.2891 - val_accuracy: 0.4067

Epoch 00736: val_loss did not improve from 1.28332
Epoch 737/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4140 - val_loss: 1.2873 - val_accuracy: 0.4147

Epoch 00737: val_loss did not improve from 1.28332
Epoch 738/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4094 - val_loss: 1.2880 - val_accuracy: 0.4043

Epoch 00738: val_loss did not improve from 1.28332
Epoch 739/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4101 - val_loss: 1.2845 - val_accuracy: 0.4019

Epoch 00739: val_loss did not improve from 1.28332
Epoch 740/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4120 - val_loss: 1.2875 - val_accuracy: 0.4003

Epoch 00740: val_loss did not improve from 1.28332
Epoch 741/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4108 - val_loss: 1.2812 - val_accuracy: 0.4083

Epoch 00741: val_loss improved from 1.28332 to 1.28120, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 742/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4086 - val_loss: 1.2889 - val_accuracy: 0.4099

Epoch 00742: val_loss did not improve from 1.28120
Epoch 743/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4106 - val_loss: 1.2908 - val_accuracy: 0.4059

Epoch 00743: val_loss did not improve from 1.28120
Epoch 744/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4116 - val_loss: 1.2858 - val_accuracy: 0.4171

Epoch 00744: val_loss did not improve from 1.28120
Epoch 745/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4104 - val_loss: 1.2858 - val_accuracy: 0.4059

Epoch 00745: val_loss did not improve from 1.28120
Epoch 746/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4106 - val_loss: 1.2877 - val_accuracy: 0.4043

Epoch 00746: val_loss did not improve from 1.28120
Epoch 747/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4083 - val_loss: 1.2887 - val_accuracy: 0.4067

Epoch 00747: val_loss did not improve from 1.28120
Epoch 748/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4097 - val_loss: 1.2881 - val_accuracy: 0.4099

Epoch 00748: val_loss did not improve from 1.28120
Epoch 749/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4077 - val_loss: 1.2915 - val_accuracy: 0.4043

Epoch 00749: val_loss did not improve from 1.28120
Epoch 750/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4118 - val_loss: 1.2858 - val_accuracy: 0.4123

Epoch 00750: val_loss did not improve from 1.28120
Epoch 751/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4125 - val_loss: 1.2858 - val_accuracy: 0.4075

Epoch 00751: val_loss did not improve from 1.28120
Epoch 752/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4080 - val_loss: 1.3001 - val_accuracy: 0.3860

Epoch 00752: val_loss did not improve from 1.28120
Epoch 753/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4110 - val_loss: 1.2824 - val_accuracy: 0.4226

Epoch 00753: val_loss did not improve from 1.28120
Epoch 754/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4110 - val_loss: 1.2906 - val_accuracy: 0.4099

Epoch 00754: val_loss did not improve from 1.28120
Epoch 755/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4089 - val_loss: 1.2857 - val_accuracy: 0.4099

Epoch 00755: val_loss did not improve from 1.28120
Epoch 756/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4110 - val_loss: 1.2855 - val_accuracy: 0.4027

Epoch 00756: val_loss did not improve from 1.28120
Epoch 757/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4145 - val_loss: 1.2840 - val_accuracy: 0.4107

Epoch 00757: val_loss did not improve from 1.28120
Epoch 758/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4106 - val_loss: 1.2871 - val_accuracy: 0.4115

Epoch 00758: val_loss did not improve from 1.28120
Epoch 759/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4123 - val_loss: 1.2846 - val_accuracy: 0.4282

Epoch 00759: val_loss did not improve from 1.28120
Epoch 760/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4148 - val_loss: 1.2901 - val_accuracy: 0.4083

Epoch 00760: val_loss did not improve from 1.28120
Epoch 761/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4104 - val_loss: 1.2967 - val_accuracy: 0.3963

Epoch 00761: val_loss did not improve from 1.28120
Epoch 762/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4101 - val_loss: 1.2860 - val_accuracy: 0.4067

Epoch 00762: val_loss did not improve from 1.28120
Epoch 763/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4107 - val_loss: 1.2839 - val_accuracy: 0.4115

Epoch 00763: val_loss did not improve from 1.28120
Epoch 764/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4128 - val_loss: 1.2826 - val_accuracy: 0.4099

Epoch 00764: val_loss did not improve from 1.28120
Epoch 765/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4089 - val_loss: 1.2874 - val_accuracy: 0.4035

Epoch 00765: val_loss did not improve from 1.28120
Epoch 766/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4143 - val_loss: 1.2858 - val_accuracy: 0.4011

Epoch 00766: val_loss did not improve from 1.28120
Epoch 767/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4143 - val_loss: 1.2877 - val_accuracy: 0.4067

Epoch 00767: val_loss did not improve from 1.28120
Epoch 768/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4102 - val_loss: 1.2876 - val_accuracy: 0.4083

Epoch 00768: val_loss did not improve from 1.28120
Epoch 769/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4125 - val_loss: 1.2847 - val_accuracy: 0.4107

Epoch 00769: val_loss did not improve from 1.28120
Epoch 770/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4091 - val_loss: 1.2933 - val_accuracy: 0.3939

Epoch 00770: val_loss did not improve from 1.28120
Epoch 771/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4107 - val_loss: 1.2923 - val_accuracy: 0.4011

Epoch 00771: val_loss did not improve from 1.28120
Epoch 772/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4118 - val_loss: 1.2835 - val_accuracy: 0.4163

Epoch 00772: val_loss did not improve from 1.28120
Epoch 773/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4122 - val_loss: 1.2859 - val_accuracy: 0.4075

Epoch 00773: val_loss did not improve from 1.28120
Epoch 774/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4155 - val_loss: 1.2839 - val_accuracy: 0.4131

Epoch 00774: val_loss did not improve from 1.28120
Epoch 775/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4119 - val_loss: 1.3052 - val_accuracy: 0.3955

Epoch 00775: val_loss did not improve from 1.28120
Epoch 776/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4089 - val_loss: 1.2886 - val_accuracy: 0.4234

Epoch 00776: val_loss did not improve from 1.28120
Epoch 777/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4094 - val_loss: 1.2901 - val_accuracy: 0.3971

Epoch 00777: val_loss did not improve from 1.28120
Epoch 778/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4121 - val_loss: 1.2913 - val_accuracy: 0.4051

Epoch 00778: val_loss did not improve from 1.28120
Epoch 779/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4128 - val_loss: 1.2828 - val_accuracy: 0.4274

Epoch 00779: val_loss did not improve from 1.28120
Epoch 780/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4109 - val_loss: 1.2885 - val_accuracy: 0.4059

Epoch 00780: val_loss did not improve from 1.28120
Epoch 781/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4144 - val_loss: 1.2849 - val_accuracy: 0.4179

Epoch 00781: val_loss did not improve from 1.28120
Epoch 782/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4130 - val_loss: 1.2942 - val_accuracy: 0.4099

Epoch 00782: val_loss did not improve from 1.28120
Epoch 783/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4115 - val_loss: 1.2829 - val_accuracy: 0.4115

Epoch 00783: val_loss did not improve from 1.28120
Epoch 784/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4094 - val_loss: 1.2816 - val_accuracy: 0.4163

Epoch 00784: val_loss did not improve from 1.28120
Epoch 785/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4136 - val_loss: 1.2875 - val_accuracy: 0.4019

Epoch 00785: val_loss did not improve from 1.28120
Epoch 786/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4138 - val_loss: 1.2933 - val_accuracy: 0.3995

Epoch 00786: val_loss did not improve from 1.28120
Epoch 787/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4142 - val_loss: 1.2836 - val_accuracy: 0.4131

Epoch 00787: val_loss did not improve from 1.28120
Epoch 788/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4140 - val_loss: 1.2813 - val_accuracy: 0.4179

Epoch 00788: val_loss did not improve from 1.28120
Epoch 789/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4139 - val_loss: 1.2869 - val_accuracy: 0.3987

Epoch 00789: val_loss did not improve from 1.28120
Epoch 790/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4120 - val_loss: 1.2871 - val_accuracy: 0.4123

Epoch 00790: val_loss did not improve from 1.28120
Epoch 791/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4122 - val_loss: 1.2904 - val_accuracy: 0.4019

Epoch 00791: val_loss did not improve from 1.28120
Epoch 792/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4119 - val_loss: 1.2834 - val_accuracy: 0.4195

Epoch 00792: val_loss did not improve from 1.28120
Epoch 793/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4139 - val_loss: 1.2891 - val_accuracy: 0.4019

Epoch 00793: val_loss did not improve from 1.28120
Epoch 794/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4144 - val_loss: 1.2848 - val_accuracy: 0.4131

Epoch 00794: val_loss did not improve from 1.28120
Epoch 795/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4127 - val_loss: 1.2855 - val_accuracy: 0.4075

Epoch 00795: val_loss did not improve from 1.28120
Epoch 796/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4125 - val_loss: 1.2880 - val_accuracy: 0.4011

Epoch 00796: val_loss did not improve from 1.28120
Epoch 797/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4117 - val_loss: 1.2830 - val_accuracy: 0.4155

Epoch 00797: val_loss did not improve from 1.28120
Epoch 798/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4141 - val_loss: 1.2865 - val_accuracy: 0.4027

Epoch 00798: val_loss did not improve from 1.28120
Epoch 799/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4128 - val_loss: 1.2869 - val_accuracy: 0.4051

Epoch 00799: val_loss did not improve from 1.28120
Epoch 800/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4117 - val_loss: 1.2838 - val_accuracy: 0.4107

Epoch 00800: val_loss did not improve from 1.28120
Epoch 801/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4139 - val_loss: 1.2817 - val_accuracy: 0.4155

Epoch 00801: val_loss did not improve from 1.28120
Epoch 802/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4102 - val_loss: 1.2906 - val_accuracy: 0.4051

Epoch 00802: val_loss did not improve from 1.28120
Epoch 803/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4133 - val_loss: 1.2916 - val_accuracy: 0.3979

Epoch 00803: val_loss did not improve from 1.28120
Epoch 804/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4134 - val_loss: 1.2882 - val_accuracy: 0.4003

Epoch 00804: val_loss did not improve from 1.28120
Epoch 805/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4148 - val_loss: 1.2840 - val_accuracy: 0.4171

Epoch 00805: val_loss did not improve from 1.28120
Epoch 806/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4129 - val_loss: 1.2870 - val_accuracy: 0.4099

Epoch 00806: val_loss did not improve from 1.28120
Epoch 807/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4137 - val_loss: 1.2859 - val_accuracy: 0.4115

Epoch 00807: val_loss did not improve from 1.28120
Epoch 808/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4144 - val_loss: 1.2867 - val_accuracy: 0.4083

Epoch 00808: val_loss did not improve from 1.28120
Epoch 809/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4150 - val_loss: 1.2869 - val_accuracy: 0.4035

Epoch 00809: val_loss did not improve from 1.28120
Epoch 810/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4111 - val_loss: 1.2878 - val_accuracy: 0.4075

Epoch 00810: val_loss did not improve from 1.28120
Epoch 811/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4111 - val_loss: 1.2839 - val_accuracy: 0.4027

Epoch 00811: val_loss did not improve from 1.28120
Epoch 812/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4133 - val_loss: 1.2900 - val_accuracy: 0.4075

Epoch 00812: val_loss did not improve from 1.28120
Epoch 813/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4120 - val_loss: 1.2913 - val_accuracy: 0.4067

Epoch 00813: val_loss did not improve from 1.28120
Epoch 814/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4160 - val_loss: 1.2829 - val_accuracy: 0.4091

Epoch 00814: val_loss did not improve from 1.28120
Epoch 815/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4147 - val_loss: 1.2866 - val_accuracy: 0.4051

Epoch 00815: val_loss did not improve from 1.28120
Epoch 816/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4124 - val_loss: 1.2827 - val_accuracy: 0.4234

Epoch 00816: val_loss did not improve from 1.28120
Epoch 817/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4125 - val_loss: 1.3039 - val_accuracy: 0.3987

Epoch 00817: val_loss did not improve from 1.28120
Epoch 818/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4122 - val_loss: 1.2831 - val_accuracy: 0.4067

Epoch 00818: val_loss did not improve from 1.28120
Epoch 819/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4100 - val_loss: 1.2853 - val_accuracy: 0.4155

Epoch 00819: val_loss did not improve from 1.28120
Epoch 820/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4133 - val_loss: 1.2877 - val_accuracy: 0.3987

Epoch 00820: val_loss did not improve from 1.28120
Epoch 821/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4127 - val_loss: 1.2809 - val_accuracy: 0.4123

Epoch 00821: val_loss improved from 1.28120 to 1.28087, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 822/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4129 - val_loss: 1.2822 - val_accuracy: 0.4059

Epoch 00822: val_loss did not improve from 1.28087
Epoch 823/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4130 - val_loss: 1.2814 - val_accuracy: 0.4195

Epoch 00823: val_loss did not improve from 1.28087
Epoch 824/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4143 - val_loss: 1.2890 - val_accuracy: 0.4059

Epoch 00824: val_loss did not improve from 1.28087
Epoch 825/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4135 - val_loss: 1.2855 - val_accuracy: 0.4091

Epoch 00825: val_loss did not improve from 1.28087
Epoch 826/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4150 - val_loss: 1.2867 - val_accuracy: 0.4203

Epoch 00826: val_loss did not improve from 1.28087
Epoch 827/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4142 - val_loss: 1.2834 - val_accuracy: 0.4107

Epoch 00827: val_loss did not improve from 1.28087
Epoch 828/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4148 - val_loss: 1.2978 - val_accuracy: 0.3987

Epoch 00828: val_loss did not improve from 1.28087
Epoch 829/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4139 - val_loss: 1.2832 - val_accuracy: 0.4242

Epoch 00829: val_loss did not improve from 1.28087
Epoch 830/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4124 - val_loss: 1.2829 - val_accuracy: 0.4099

Epoch 00830: val_loss did not improve from 1.28087
Epoch 831/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4132 - val_loss: 1.2837 - val_accuracy: 0.4059

Epoch 00831: val_loss did not improve from 1.28087
Epoch 832/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4128 - val_loss: 1.2864 - val_accuracy: 0.4019

Epoch 00832: val_loss did not improve from 1.28087
Epoch 833/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4117 - val_loss: 1.2843 - val_accuracy: 0.4067

Epoch 00833: val_loss did not improve from 1.28087
Epoch 834/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4135 - val_loss: 1.2826 - val_accuracy: 0.4067

Epoch 00834: val_loss did not improve from 1.28087
Epoch 835/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4139 - val_loss: 1.2986 - val_accuracy: 0.3971

Epoch 00835: val_loss did not improve from 1.28087
Epoch 836/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4117 - val_loss: 1.2829 - val_accuracy: 0.4155

Epoch 00836: val_loss did not improve from 1.28087
Epoch 837/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4148 - val_loss: 1.2823 - val_accuracy: 0.4115

Epoch 00837: val_loss did not improve from 1.28087
Epoch 838/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4134 - val_loss: 1.2852 - val_accuracy: 0.4019

Epoch 00838: val_loss did not improve from 1.28087
Epoch 839/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4094 - val_loss: 1.2870 - val_accuracy: 0.3955

Epoch 00839: val_loss did not improve from 1.28087
Epoch 840/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4134 - val_loss: 1.2794 - val_accuracy: 0.4139

Epoch 00840: val_loss improved from 1.28087 to 1.27943, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 841/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4135 - val_loss: 1.2937 - val_accuracy: 0.4019

Epoch 00841: val_loss did not improve from 1.27943
Epoch 842/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4119 - val_loss: 1.2931 - val_accuracy: 0.3955

Epoch 00842: val_loss did not improve from 1.27943
Epoch 843/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4140 - val_loss: 1.2831 - val_accuracy: 0.4115

Epoch 00843: val_loss did not improve from 1.27943
Epoch 844/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4143 - val_loss: 1.2837 - val_accuracy: 0.4075

Epoch 00844: val_loss did not improve from 1.27943
Epoch 845/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4129 - val_loss: 1.2861 - val_accuracy: 0.4019

Epoch 00845: val_loss did not improve from 1.27943
Epoch 846/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4125 - val_loss: 1.2861 - val_accuracy: 0.4043

Epoch 00846: val_loss did not improve from 1.27943
Epoch 847/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4141 - val_loss: 1.2845 - val_accuracy: 0.4107

Epoch 00847: val_loss did not improve from 1.27943
Epoch 848/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4117 - val_loss: 1.2862 - val_accuracy: 0.3979

Epoch 00848: val_loss did not improve from 1.27943
Epoch 849/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4125 - val_loss: 1.2934 - val_accuracy: 0.3979

Epoch 00849: val_loss did not improve from 1.27943
Epoch 850/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4099 - val_loss: 1.2882 - val_accuracy: 0.4059

Epoch 00850: val_loss did not improve from 1.27943
Epoch 851/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4166 - val_loss: 1.2827 - val_accuracy: 0.4131

Epoch 00851: val_loss did not improve from 1.27943
Epoch 852/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4145 - val_loss: 1.2862 - val_accuracy: 0.4019

Epoch 00852: val_loss did not improve from 1.27943
Epoch 853/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4143 - val_loss: 1.2853 - val_accuracy: 0.4059

Epoch 00853: val_loss did not improve from 1.27943
Epoch 854/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4113 - val_loss: 1.2834 - val_accuracy: 0.4091

Epoch 00854: val_loss did not improve from 1.27943
Epoch 855/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4102 - val_loss: 1.2874 - val_accuracy: 0.3955

Epoch 00855: val_loss did not improve from 1.27943
Epoch 856/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4094 - val_loss: 1.2812 - val_accuracy: 0.4067

Epoch 00856: val_loss did not improve from 1.27943
Epoch 857/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4164 - val_loss: 1.2845 - val_accuracy: 0.4075

Epoch 00857: val_loss did not improve from 1.27943
Epoch 858/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4134 - val_loss: 1.2828 - val_accuracy: 0.4139

Epoch 00858: val_loss did not improve from 1.27943
Epoch 859/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4129 - val_loss: 1.3002 - val_accuracy: 0.3987

Epoch 00859: val_loss did not improve from 1.27943
Epoch 860/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4130 - val_loss: 1.2878 - val_accuracy: 0.3955

Epoch 00860: val_loss did not improve from 1.27943
Epoch 861/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4114 - val_loss: 1.2806 - val_accuracy: 0.4139

Epoch 00861: val_loss did not improve from 1.27943
Epoch 862/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4109 - val_loss: 1.2844 - val_accuracy: 0.4043

Epoch 00862: val_loss did not improve from 1.27943
Epoch 863/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4126 - val_loss: 1.2881 - val_accuracy: 0.4003

Epoch 00863: val_loss did not improve from 1.27943
Epoch 864/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4132 - val_loss: 1.2815 - val_accuracy: 0.4083

Epoch 00864: val_loss did not improve from 1.27943
Epoch 865/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4135 - val_loss: 1.2808 - val_accuracy: 0.4099

Epoch 00865: val_loss did not improve from 1.27943
Epoch 866/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4121 - val_loss: 1.2858 - val_accuracy: 0.4091

Epoch 00866: val_loss did not improve from 1.27943
Epoch 867/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4122 - val_loss: 1.2897 - val_accuracy: 0.3955

Epoch 00867: val_loss did not improve from 1.27943
Epoch 868/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4133 - val_loss: 1.2807 - val_accuracy: 0.4075

Epoch 00868: val_loss did not improve from 1.27943
Epoch 869/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4133 - val_loss: 1.2875 - val_accuracy: 0.3979

Epoch 00869: val_loss did not improve from 1.27943
Epoch 870/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4135 - val_loss: 1.2857 - val_accuracy: 0.4003

Epoch 00870: val_loss did not improve from 1.27943
Epoch 871/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4124 - val_loss: 1.2822 - val_accuracy: 0.4123

Epoch 00871: val_loss did not improve from 1.27943
Epoch 872/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4156 - val_loss: 1.2855 - val_accuracy: 0.4123

Epoch 00872: val_loss did not improve from 1.27943
Epoch 873/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4114 - val_loss: 1.2884 - val_accuracy: 0.4019

Epoch 00873: val_loss did not improve from 1.27943
Epoch 874/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4108 - val_loss: 1.2874 - val_accuracy: 0.4043

Epoch 00874: val_loss did not improve from 1.27943
Epoch 875/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4141 - val_loss: 1.2826 - val_accuracy: 0.4043

Epoch 00875: val_loss did not improve from 1.27943
Epoch 876/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4134 - val_loss: 1.2845 - val_accuracy: 0.4043

Epoch 00876: val_loss did not improve from 1.27943
Epoch 877/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4102 - val_loss: 1.2836 - val_accuracy: 0.4019

Epoch 00877: val_loss did not improve from 1.27943
Epoch 878/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4141 - val_loss: 1.2826 - val_accuracy: 0.4107

Epoch 00878: val_loss did not improve from 1.27943
Epoch 879/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4134 - val_loss: 1.2805 - val_accuracy: 0.4203

Epoch 00879: val_loss did not improve from 1.27943
Epoch 880/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4101 - val_loss: 1.2921 - val_accuracy: 0.3971

Epoch 00880: val_loss did not improve from 1.27943
Epoch 881/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4117 - val_loss: 1.2964 - val_accuracy: 0.4019

Epoch 00881: val_loss did not improve from 1.27943
Epoch 882/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4135 - val_loss: 1.2839 - val_accuracy: 0.4115

Epoch 00882: val_loss did not improve from 1.27943
Epoch 883/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4158 - val_loss: 1.2848 - val_accuracy: 0.4155

Epoch 00883: val_loss did not improve from 1.27943
Epoch 884/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4150 - val_loss: 1.2820 - val_accuracy: 0.4083

Epoch 00884: val_loss did not improve from 1.27943
Epoch 885/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4148 - val_loss: 1.2807 - val_accuracy: 0.4099

Epoch 00885: val_loss did not improve from 1.27943
Epoch 886/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4158 - val_loss: 1.2897 - val_accuracy: 0.3955

Epoch 00886: val_loss did not improve from 1.27943
Epoch 887/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4156 - val_loss: 1.2852 - val_accuracy: 0.4035

Epoch 00887: val_loss did not improve from 1.27943
Epoch 888/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4155 - val_loss: 1.2815 - val_accuracy: 0.4211

Epoch 00888: val_loss did not improve from 1.27943
Epoch 889/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4173 - val_loss: 1.2857 - val_accuracy: 0.4051

Epoch 00889: val_loss did not improve from 1.27943
Epoch 890/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4131 - val_loss: 1.2838 - val_accuracy: 0.4051

Epoch 00890: val_loss did not improve from 1.27943
Epoch 891/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4139 - val_loss: 1.2864 - val_accuracy: 0.4091

Epoch 00891: val_loss did not improve from 1.27943
Epoch 892/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4138 - val_loss: 1.2822 - val_accuracy: 0.4147

Epoch 00892: val_loss did not improve from 1.27943
Epoch 893/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4157 - val_loss: 1.2863 - val_accuracy: 0.4011

Epoch 00893: val_loss did not improve from 1.27943
Epoch 894/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4117 - val_loss: 1.2817 - val_accuracy: 0.4091

Epoch 00894: val_loss did not improve from 1.27943
Epoch 895/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4130 - val_loss: 1.2875 - val_accuracy: 0.4003

Epoch 00895: val_loss did not improve from 1.27943
Epoch 896/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4150 - val_loss: 1.2812 - val_accuracy: 0.4075

Epoch 00896: val_loss did not improve from 1.27943
Epoch 897/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4181 - val_loss: 1.2875 - val_accuracy: 0.4035

Epoch 00897: val_loss did not improve from 1.27943
Epoch 898/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4121 - val_loss: 1.2837 - val_accuracy: 0.4011

Epoch 00898: val_loss did not improve from 1.27943
Epoch 899/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4152 - val_loss: 1.2882 - val_accuracy: 0.3939

Epoch 00899: val_loss did not improve from 1.27943
Epoch 900/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4132 - val_loss: 1.2811 - val_accuracy: 0.4099

Epoch 00900: val_loss did not improve from 1.27943
Epoch 901/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4147 - val_loss: 1.2822 - val_accuracy: 0.4011

Epoch 00901: val_loss did not improve from 1.27943
Epoch 902/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4163 - val_loss: 1.2914 - val_accuracy: 0.4027

Epoch 00902: val_loss did not improve from 1.27943
Epoch 903/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4134 - val_loss: 1.2818 - val_accuracy: 0.4131

Epoch 00903: val_loss did not improve from 1.27943
Epoch 904/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4101 - val_loss: 1.2810 - val_accuracy: 0.4107

Epoch 00904: val_loss did not improve from 1.27943
Epoch 905/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4136 - val_loss: 1.3040 - val_accuracy: 0.3987

Epoch 00905: val_loss did not improve from 1.27943
Epoch 906/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4101 - val_loss: 1.2833 - val_accuracy: 0.4258

Epoch 00906: val_loss did not improve from 1.27943
Epoch 907/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4105 - val_loss: 1.2839 - val_accuracy: 0.4019

Epoch 00907: val_loss did not improve from 1.27943
Epoch 908/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4140 - val_loss: 1.2905 - val_accuracy: 0.4067

Epoch 00908: val_loss did not improve from 1.27943
Epoch 909/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4143 - val_loss: 1.2777 - val_accuracy: 0.4083

Epoch 00909: val_loss improved from 1.27943 to 1.27773, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 910/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4121 - val_loss: 1.2884 - val_accuracy: 0.4059

Epoch 00910: val_loss did not improve from 1.27773
Epoch 911/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4110 - val_loss: 1.2873 - val_accuracy: 0.4083

Epoch 00911: val_loss did not improve from 1.27773
Epoch 912/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4163 - val_loss: 1.2822 - val_accuracy: 0.4067

Epoch 00912: val_loss did not improve from 1.27773
Epoch 913/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4155 - val_loss: 1.2913 - val_accuracy: 0.3987

Epoch 00913: val_loss did not improve from 1.27773
Epoch 914/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4123 - val_loss: 1.2889 - val_accuracy: 0.3931

Epoch 00914: val_loss did not improve from 1.27773
Epoch 915/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4143 - val_loss: 1.2812 - val_accuracy: 0.4139

Epoch 00915: val_loss did not improve from 1.27773
Epoch 916/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4150 - val_loss: 1.2847 - val_accuracy: 0.3979

Epoch 00916: val_loss did not improve from 1.27773
Epoch 917/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4140 - val_loss: 1.2821 - val_accuracy: 0.4083

Epoch 00917: val_loss did not improve from 1.27773
Epoch 918/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4131 - val_loss: 1.2900 - val_accuracy: 0.3995

Epoch 00918: val_loss did not improve from 1.27773
Epoch 919/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4145 - val_loss: 1.2874 - val_accuracy: 0.4075

Epoch 00919: val_loss did not improve from 1.27773
Epoch 920/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4171 - val_loss: 1.2845 - val_accuracy: 0.4051

Epoch 00920: val_loss did not improve from 1.27773
Epoch 921/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4145 - val_loss: 1.2798 - val_accuracy: 0.4091

Epoch 00921: val_loss did not improve from 1.27773
Epoch 922/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4138 - val_loss: 1.2867 - val_accuracy: 0.4123

Epoch 00922: val_loss did not improve from 1.27773
Epoch 923/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4163 - val_loss: 1.2837 - val_accuracy: 0.4123

Epoch 00923: val_loss did not improve from 1.27773
Epoch 924/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4125 - val_loss: 1.2881 - val_accuracy: 0.4059

Epoch 00924: val_loss did not improve from 1.27773
Epoch 925/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4154 - val_loss: 1.2837 - val_accuracy: 0.4115

Epoch 00925: val_loss did not improve from 1.27773
Epoch 926/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4155 - val_loss: 1.2819 - val_accuracy: 0.4163

Epoch 00926: val_loss did not improve from 1.27773
Epoch 927/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4159 - val_loss: 1.2953 - val_accuracy: 0.4083

Epoch 00927: val_loss did not improve from 1.27773
Epoch 928/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4150 - val_loss: 1.2814 - val_accuracy: 0.4123

Epoch 00928: val_loss did not improve from 1.27773
Epoch 929/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4135 - val_loss: 1.2817 - val_accuracy: 0.4091

Epoch 00929: val_loss did not improve from 1.27773
Epoch 930/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4171 - val_loss: 1.2824 - val_accuracy: 0.4035

Epoch 00930: val_loss did not improve from 1.27773
Epoch 931/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4186 - val_loss: 1.2910 - val_accuracy: 0.4091

Epoch 00931: val_loss did not improve from 1.27773
Epoch 932/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4123 - val_loss: 1.2808 - val_accuracy: 0.4067

Epoch 00932: val_loss did not improve from 1.27773
Epoch 933/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4148 - val_loss: 1.2814 - val_accuracy: 0.4091

Epoch 00933: val_loss did not improve from 1.27773
Epoch 934/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4192 - val_loss: 1.2806 - val_accuracy: 0.4147

Epoch 00934: val_loss did not improve from 1.27773
Epoch 935/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4133 - val_loss: 1.2795 - val_accuracy: 0.4179

Epoch 00935: val_loss did not improve from 1.27773
Epoch 936/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4144 - val_loss: 1.2911 - val_accuracy: 0.4123

Epoch 00936: val_loss did not improve from 1.27773
Epoch 937/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4154 - val_loss: 1.2801 - val_accuracy: 0.4027

Epoch 00937: val_loss did not improve from 1.27773
Epoch 938/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4134 - val_loss: 1.2826 - val_accuracy: 0.4091

Epoch 00938: val_loss did not improve from 1.27773
Epoch 939/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4128 - val_loss: 1.2894 - val_accuracy: 0.4059

Epoch 00939: val_loss did not improve from 1.27773
Epoch 940/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4099 - val_loss: 1.2828 - val_accuracy: 0.4147

Epoch 00940: val_loss did not improve from 1.27773
Epoch 941/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4135 - val_loss: 1.2966 - val_accuracy: 0.4099

Epoch 00941: val_loss did not improve from 1.27773
Epoch 942/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4170 - val_loss: 1.2792 - val_accuracy: 0.4107

Epoch 00942: val_loss did not improve from 1.27773
Epoch 943/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4108 - val_loss: 1.2791 - val_accuracy: 0.4219

Epoch 00943: val_loss did not improve from 1.27773
Epoch 944/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4156 - val_loss: 1.2949 - val_accuracy: 0.3939

Epoch 00944: val_loss did not improve from 1.27773
Epoch 945/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4162 - val_loss: 1.2827 - val_accuracy: 0.4067

Epoch 00945: val_loss did not improve from 1.27773
Epoch 946/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4199 - val_loss: 1.2801 - val_accuracy: 0.4203

Epoch 00946: val_loss did not improve from 1.27773
Epoch 947/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4166 - val_loss: 1.2882 - val_accuracy: 0.4027

Epoch 00947: val_loss did not improve from 1.27773
Epoch 948/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4177 - val_loss: 1.2848 - val_accuracy: 0.4003

Epoch 00948: val_loss did not improve from 1.27773
Epoch 949/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4163 - val_loss: 1.2812 - val_accuracy: 0.4115

Epoch 00949: val_loss did not improve from 1.27773
Epoch 950/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4166 - val_loss: 1.2869 - val_accuracy: 0.4075

Epoch 00950: val_loss did not improve from 1.27773
Epoch 951/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4159 - val_loss: 1.2795 - val_accuracy: 0.4115

Epoch 00951: val_loss did not improve from 1.27773
Epoch 952/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4117 - val_loss: 1.2828 - val_accuracy: 0.4051

Epoch 00952: val_loss did not improve from 1.27773
Epoch 953/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4133 - val_loss: 1.2811 - val_accuracy: 0.4155

Epoch 00953: val_loss did not improve from 1.27773
Epoch 954/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4142 - val_loss: 1.2959 - val_accuracy: 0.3987

Epoch 00954: val_loss did not improve from 1.27773
Epoch 955/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4162 - val_loss: 1.2818 - val_accuracy: 0.4043

Epoch 00955: val_loss did not improve from 1.27773
Epoch 956/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4145 - val_loss: 1.2821 - val_accuracy: 0.4075

Epoch 00956: val_loss did not improve from 1.27773
Epoch 957/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4129 - val_loss: 1.2823 - val_accuracy: 0.4027

Epoch 00957: val_loss did not improve from 1.27773
Epoch 958/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4134 - val_loss: 1.2793 - val_accuracy: 0.4059

Epoch 00958: val_loss did not improve from 1.27773
Epoch 959/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4132 - val_loss: 1.2826 - val_accuracy: 0.4163

Epoch 00959: val_loss did not improve from 1.27773
Epoch 960/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4110 - val_loss: 1.2903 - val_accuracy: 0.4035

Epoch 00960: val_loss did not improve from 1.27773
Epoch 961/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4146 - val_loss: 1.2826 - val_accuracy: 0.4131

Epoch 00961: val_loss did not improve from 1.27773
Epoch 962/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4162 - val_loss: 1.2833 - val_accuracy: 0.4035

Epoch 00962: val_loss did not improve from 1.27773
Epoch 963/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4151 - val_loss: 1.2841 - val_accuracy: 0.4091

Epoch 00963: val_loss did not improve from 1.27773
Epoch 964/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4157 - val_loss: 1.2791 - val_accuracy: 0.4091

Epoch 00964: val_loss did not improve from 1.27773
Epoch 965/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4122 - val_loss: 1.2798 - val_accuracy: 0.4115

Epoch 00965: val_loss did not improve from 1.27773
Epoch 966/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4095 - val_loss: 1.2870 - val_accuracy: 0.4075

Epoch 00966: val_loss did not improve from 1.27773
Epoch 967/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4150 - val_loss: 1.2827 - val_accuracy: 0.4003

Epoch 00967: val_loss did not improve from 1.27773
Epoch 968/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4158 - val_loss: 1.2822 - val_accuracy: 0.4035

Epoch 00968: val_loss did not improve from 1.27773
Epoch 969/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4165 - val_loss: 1.2805 - val_accuracy: 0.4155

Epoch 00969: val_loss did not improve from 1.27773
Epoch 970/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4144 - val_loss: 1.2944 - val_accuracy: 0.4035

Epoch 00970: val_loss did not improve from 1.27773
Epoch 971/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4170 - val_loss: 1.2819 - val_accuracy: 0.4131

Epoch 00971: val_loss did not improve from 1.27773
Epoch 972/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4132 - val_loss: 1.2821 - val_accuracy: 0.4035

Epoch 00972: val_loss did not improve from 1.27773
Epoch 973/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4143 - val_loss: 1.2899 - val_accuracy: 0.4019

Epoch 00973: val_loss did not improve from 1.27773
Epoch 974/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4153 - val_loss: 1.2868 - val_accuracy: 0.4059

Epoch 00974: val_loss did not improve from 1.27773
Epoch 975/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4149 - val_loss: 1.2799 - val_accuracy: 0.4123

Epoch 00975: val_loss did not improve from 1.27773
Epoch 976/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4127 - val_loss: 1.2785 - val_accuracy: 0.4067

Epoch 00976: val_loss did not improve from 1.27773
Epoch 977/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4169 - val_loss: 1.2863 - val_accuracy: 0.4027

Epoch 00977: val_loss did not improve from 1.27773
Epoch 978/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4135 - val_loss: 1.2842 - val_accuracy: 0.4043

Epoch 00978: val_loss did not improve from 1.27773
Epoch 979/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4130 - val_loss: 1.2806 - val_accuracy: 0.4059

Epoch 00979: val_loss did not improve from 1.27773
Epoch 980/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4153 - val_loss: 1.2829 - val_accuracy: 0.3971

Epoch 00980: val_loss did not improve from 1.27773
Epoch 981/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4143 - val_loss: 1.2847 - val_accuracy: 0.3995

Epoch 00981: val_loss did not improve from 1.27773
Epoch 982/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4148 - val_loss: 1.2818 - val_accuracy: 0.4123

Epoch 00982: val_loss did not improve from 1.27773
Epoch 983/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4153 - val_loss: 1.2812 - val_accuracy: 0.4075

Epoch 00983: val_loss did not improve from 1.27773
Epoch 984/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4171 - val_loss: 1.2829 - val_accuracy: 0.4067

Epoch 00984: val_loss did not improve from 1.27773
Epoch 985/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4146 - val_loss: 1.2811 - val_accuracy: 0.4075

Epoch 00985: val_loss did not improve from 1.27773
Epoch 986/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4157 - val_loss: 1.2856 - val_accuracy: 0.4035

Epoch 00986: val_loss did not improve from 1.27773
Epoch 987/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4171 - val_loss: 1.2792 - val_accuracy: 0.4083

Epoch 00987: val_loss did not improve from 1.27773
Epoch 988/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4162 - val_loss: 1.2782 - val_accuracy: 0.4155

Epoch 00988: val_loss did not improve from 1.27773
Epoch 989/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4114 - val_loss: 1.2944 - val_accuracy: 0.4003

Epoch 00989: val_loss did not improve from 1.27773
Epoch 990/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4147 - val_loss: 1.2795 - val_accuracy: 0.4115

Epoch 00990: val_loss did not improve from 1.27773
Epoch 991/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4179 - val_loss: 1.2921 - val_accuracy: 0.4059

Epoch 00991: val_loss did not improve from 1.27773
Epoch 992/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4138 - val_loss: 1.2816 - val_accuracy: 0.4195

Epoch 00992: val_loss did not improve from 1.27773
Epoch 993/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4147 - val_loss: 1.2796 - val_accuracy: 0.4131

Epoch 00993: val_loss did not improve from 1.27773
Epoch 994/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4125 - val_loss: 1.2836 - val_accuracy: 0.4019

Epoch 00994: val_loss did not improve from 1.27773
Epoch 995/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4132 - val_loss: 1.2832 - val_accuracy: 0.4035

Epoch 00995: val_loss did not improve from 1.27773
Epoch 996/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4157 - val_loss: 1.2798 - val_accuracy: 0.4043

Epoch 00996: val_loss did not improve from 1.27773
Epoch 997/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4161 - val_loss: 1.2795 - val_accuracy: 0.4115

Epoch 00997: val_loss did not improve from 1.27773
Epoch 998/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4161 - val_loss: 1.2848 - val_accuracy: 0.4011

Epoch 00998: val_loss did not improve from 1.27773
Epoch 999/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4141 - val_loss: 1.2829 - val_accuracy: 0.4067

Epoch 00999: val_loss did not improve from 1.27773
Epoch 1000/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4192 - val_loss: 1.2778 - val_accuracy: 0.4171

Epoch 01000: val_loss did not improve from 1.27773
Epoch 1001/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4183 - val_loss: 1.2830 - val_accuracy: 0.4027

Epoch 01001: val_loss did not improve from 1.27773
Epoch 1002/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4153 - val_loss: 1.2889 - val_accuracy: 0.4027

Epoch 01002: val_loss did not improve from 1.27773
Epoch 1003/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4144 - val_loss: 1.2802 - val_accuracy: 0.4099

Epoch 01003: val_loss did not improve from 1.27773
Epoch 1004/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4134 - val_loss: 1.2809 - val_accuracy: 0.4059

Epoch 01004: val_loss did not improve from 1.27773
Epoch 1005/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4163 - val_loss: 1.2779 - val_accuracy: 0.4083

Epoch 01005: val_loss did not improve from 1.27773
Epoch 1006/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4170 - val_loss: 1.2914 - val_accuracy: 0.4043

Epoch 01006: val_loss did not improve from 1.27773
Epoch 1007/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4164 - val_loss: 1.2780 - val_accuracy: 0.4067

Epoch 01007: val_loss did not improve from 1.27773
Epoch 1008/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4154 - val_loss: 1.2822 - val_accuracy: 0.4043

Epoch 01008: val_loss did not improve from 1.27773
Epoch 1009/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4204 - val_loss: 1.2823 - val_accuracy: 0.4123

Epoch 01009: val_loss did not improve from 1.27773
Epoch 1010/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4174 - val_loss: 1.2801 - val_accuracy: 0.4043

Epoch 01010: val_loss did not improve from 1.27773
Epoch 1011/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4179 - val_loss: 1.2883 - val_accuracy: 0.4043

Epoch 01011: val_loss did not improve from 1.27773
Epoch 1012/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4141 - val_loss: 1.2811 - val_accuracy: 0.4075

Epoch 01012: val_loss did not improve from 1.27773
Epoch 1013/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4159 - val_loss: 1.2788 - val_accuracy: 0.4043

Epoch 01013: val_loss did not improve from 1.27773
Epoch 1014/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4130 - val_loss: 1.2830 - val_accuracy: 0.4019

Epoch 01014: val_loss did not improve from 1.27773
Epoch 1015/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4171 - val_loss: 1.2900 - val_accuracy: 0.4059

Epoch 01015: val_loss did not improve from 1.27773
Epoch 1016/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4156 - val_loss: 1.2822 - val_accuracy: 0.4035

Epoch 01016: val_loss did not improve from 1.27773
Epoch 1017/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4171 - val_loss: 1.2796 - val_accuracy: 0.4195

Epoch 01017: val_loss did not improve from 1.27773
Epoch 1018/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4194 - val_loss: 1.2859 - val_accuracy: 0.4067

Epoch 01018: val_loss did not improve from 1.27773
Epoch 1019/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4125 - val_loss: 1.2812 - val_accuracy: 0.4019

Epoch 01019: val_loss did not improve from 1.27773
Epoch 1020/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4165 - val_loss: 1.2777 - val_accuracy: 0.4139

Epoch 01020: val_loss improved from 1.27773 to 1.27770, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1021/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4187 - val_loss: 1.2918 - val_accuracy: 0.4067

Epoch 01021: val_loss did not improve from 1.27770
Epoch 1022/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4163 - val_loss: 1.2876 - val_accuracy: 0.4075

Epoch 01022: val_loss did not improve from 1.27770
Epoch 1023/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4151 - val_loss: 1.2831 - val_accuracy: 0.4035

Epoch 01023: val_loss did not improve from 1.27770
Epoch 1024/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4161 - val_loss: 1.2798 - val_accuracy: 0.4155

Epoch 01024: val_loss did not improve from 1.27770
Epoch 1025/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4152 - val_loss: 1.2887 - val_accuracy: 0.4091

Epoch 01025: val_loss did not improve from 1.27770
Epoch 1026/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4215 - val_loss: 1.2825 - val_accuracy: 0.4051

Epoch 01026: val_loss did not improve from 1.27770
Epoch 1027/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4146 - val_loss: 1.2799 - val_accuracy: 0.4035

Epoch 01027: val_loss did not improve from 1.27770
Epoch 1028/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4156 - val_loss: 1.2811 - val_accuracy: 0.4011

Epoch 01028: val_loss did not improve from 1.27770
Epoch 1029/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4174 - val_loss: 1.2844 - val_accuracy: 0.4043

Epoch 01029: val_loss did not improve from 1.27770
Epoch 1030/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4170 - val_loss: 1.2795 - val_accuracy: 0.3987

Epoch 01030: val_loss did not improve from 1.27770
Epoch 1031/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4126 - val_loss: 1.2812 - val_accuracy: 0.4051

Epoch 01031: val_loss did not improve from 1.27770
Epoch 1032/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4176 - val_loss: 1.2792 - val_accuracy: 0.4107

Epoch 01032: val_loss did not improve from 1.27770
Epoch 1033/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4172 - val_loss: 1.2878 - val_accuracy: 0.4059

Epoch 01033: val_loss did not improve from 1.27770
Epoch 1034/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4194 - val_loss: 1.2864 - val_accuracy: 0.3995

Epoch 01034: val_loss did not improve from 1.27770
Epoch 1035/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4163 - val_loss: 1.2820 - val_accuracy: 0.4107

Epoch 01035: val_loss did not improve from 1.27770
Epoch 1036/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4181 - val_loss: 1.2799 - val_accuracy: 0.4115

Epoch 01036: val_loss did not improve from 1.27770
Epoch 1037/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4185 - val_loss: 1.2896 - val_accuracy: 0.3979

Epoch 01037: val_loss did not improve from 1.27770
Epoch 1038/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4169 - val_loss: 1.2820 - val_accuracy: 0.4027

Epoch 01038: val_loss did not improve from 1.27770
Epoch 1039/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4151 - val_loss: 1.2800 - val_accuracy: 0.4067

Epoch 01039: val_loss did not improve from 1.27770
Epoch 1040/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4138 - val_loss: 1.2777 - val_accuracy: 0.4027

Epoch 01040: val_loss improved from 1.27770 to 1.27767, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1041/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4187 - val_loss: 1.2838 - val_accuracy: 0.3955

Epoch 01041: val_loss did not improve from 1.27767
Epoch 1042/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4205 - val_loss: 1.2793 - val_accuracy: 0.4059

Epoch 01042: val_loss did not improve from 1.27767
Epoch 1043/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4171 - val_loss: 1.2773 - val_accuracy: 0.4091

Epoch 01043: val_loss improved from 1.27767 to 1.27730, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1044/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4121 - val_loss: 1.2787 - val_accuracy: 0.4091

Epoch 01044: val_loss did not improve from 1.27730
Epoch 1045/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4160 - val_loss: 1.2856 - val_accuracy: 0.4099

Epoch 01045: val_loss did not improve from 1.27730
Epoch 1046/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4173 - val_loss: 1.2774 - val_accuracy: 0.4147

Epoch 01046: val_loss did not improve from 1.27730
Epoch 1047/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4198 - val_loss: 1.2774 - val_accuracy: 0.4107

Epoch 01047: val_loss did not improve from 1.27730
Epoch 1048/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4160 - val_loss: 1.2799 - val_accuracy: 0.4123

Epoch 01048: val_loss did not improve from 1.27730
Epoch 1049/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4171 - val_loss: 1.2876 - val_accuracy: 0.4059

Epoch 01049: val_loss did not improve from 1.27730
Epoch 1050/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4156 - val_loss: 1.2798 - val_accuracy: 0.4163

Epoch 01050: val_loss did not improve from 1.27730
Epoch 1051/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4148 - val_loss: 1.2849 - val_accuracy: 0.4107

Epoch 01051: val_loss did not improve from 1.27730
Epoch 1052/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4175 - val_loss: 1.2820 - val_accuracy: 0.4083

Epoch 01052: val_loss did not improve from 1.27730
Epoch 1053/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4128 - val_loss: 1.2790 - val_accuracy: 0.4179

Epoch 01053: val_loss did not improve from 1.27730
Epoch 1054/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4168 - val_loss: 1.2790 - val_accuracy: 0.4155

Epoch 01054: val_loss did not improve from 1.27730
Epoch 1055/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4171 - val_loss: 1.2849 - val_accuracy: 0.4099

Epoch 01055: val_loss did not improve from 1.27730
Epoch 1056/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4127 - val_loss: 1.2848 - val_accuracy: 0.4099

Epoch 01056: val_loss did not improve from 1.27730
Epoch 1057/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4172 - val_loss: 1.2825 - val_accuracy: 0.4083

Epoch 01057: val_loss did not improve from 1.27730
Epoch 1058/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4157 - val_loss: 1.2781 - val_accuracy: 0.4195

Epoch 01058: val_loss did not improve from 1.27730
Epoch 1059/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4130 - val_loss: 1.2984 - val_accuracy: 0.4019

Epoch 01059: val_loss did not improve from 1.27730
Epoch 1060/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4125 - val_loss: 1.2866 - val_accuracy: 0.4011

Epoch 01060: val_loss did not improve from 1.27730
Epoch 1061/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4185 - val_loss: 1.2774 - val_accuracy: 0.4075

Epoch 01061: val_loss did not improve from 1.27730
Epoch 1062/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4179 - val_loss: 1.2842 - val_accuracy: 0.4043

Epoch 01062: val_loss did not improve from 1.27730
Epoch 1063/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4181 - val_loss: 1.2827 - val_accuracy: 0.4011

Epoch 01063: val_loss did not improve from 1.27730
Epoch 1064/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4135 - val_loss: 1.2779 - val_accuracy: 0.4115

Epoch 01064: val_loss did not improve from 1.27730
Epoch 1065/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4177 - val_loss: 1.2860 - val_accuracy: 0.4171

Epoch 01065: val_loss did not improve from 1.27730
Epoch 1066/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4145 - val_loss: 1.2793 - val_accuracy: 0.4139

Epoch 01066: val_loss did not improve from 1.27730
Epoch 1067/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4170 - val_loss: 1.2786 - val_accuracy: 0.4083

Epoch 01067: val_loss did not improve from 1.27730
Epoch 1068/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4187 - val_loss: 1.2809 - val_accuracy: 0.4107

Epoch 01068: val_loss did not improve from 1.27730
Epoch 1069/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4165 - val_loss: 1.2867 - val_accuracy: 0.4163

Epoch 01069: val_loss did not improve from 1.27730
Epoch 1070/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4160 - val_loss: 1.2809 - val_accuracy: 0.4147

Epoch 01070: val_loss did not improve from 1.27730
Epoch 1071/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4114 - val_loss: 1.2846 - val_accuracy: 0.4035

Epoch 01071: val_loss did not improve from 1.27730
Epoch 1072/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4133 - val_loss: 1.2816 - val_accuracy: 0.4059

Epoch 01072: val_loss did not improve from 1.27730
Epoch 1073/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4169 - val_loss: 1.2790 - val_accuracy: 0.4075

Epoch 01073: val_loss did not improve from 1.27730
Epoch 1074/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4179 - val_loss: 1.2887 - val_accuracy: 0.4043

Epoch 01074: val_loss did not improve from 1.27730
Epoch 1075/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4155 - val_loss: 1.2758 - val_accuracy: 0.4011

Epoch 01075: val_loss improved from 1.27730 to 1.27577, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1076/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4194 - val_loss: 1.2809 - val_accuracy: 0.4035

Epoch 01076: val_loss did not improve from 1.27577
Epoch 1077/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4118 - val_loss: 1.2818 - val_accuracy: 0.4051

Epoch 01077: val_loss did not improve from 1.27577
Epoch 1078/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4161 - val_loss: 1.2780 - val_accuracy: 0.4123

Epoch 01078: val_loss did not improve from 1.27577
Epoch 1079/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4182 - val_loss: 1.2825 - val_accuracy: 0.4075

Epoch 01079: val_loss did not improve from 1.27577
Epoch 1080/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4180 - val_loss: 1.2892 - val_accuracy: 0.4027

Epoch 01080: val_loss did not improve from 1.27577
Epoch 1081/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4151 - val_loss: 1.2768 - val_accuracy: 0.4075

Epoch 01081: val_loss did not improve from 1.27577
Epoch 1082/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4180 - val_loss: 1.2859 - val_accuracy: 0.4107

Epoch 01082: val_loss did not improve from 1.27577
Epoch 1083/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4183 - val_loss: 1.2790 - val_accuracy: 0.4091

Epoch 01083: val_loss did not improve from 1.27577
Epoch 1084/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4163 - val_loss: 1.2795 - val_accuracy: 0.4123

Epoch 01084: val_loss did not improve from 1.27577
Epoch 1085/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4164 - val_loss: 1.2801 - val_accuracy: 0.4123

Epoch 01085: val_loss did not improve from 1.27577
Epoch 1086/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4161 - val_loss: 1.2802 - val_accuracy: 0.4115

Epoch 01086: val_loss did not improve from 1.27577
Epoch 1087/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4181 - val_loss: 1.2840 - val_accuracy: 0.4107

Epoch 01087: val_loss did not improve from 1.27577
Epoch 1088/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4141 - val_loss: 1.2778 - val_accuracy: 0.4147

Epoch 01088: val_loss did not improve from 1.27577
Epoch 1089/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4192 - val_loss: 1.2807 - val_accuracy: 0.4139

Epoch 01089: val_loss did not improve from 1.27577
Epoch 1090/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4174 - val_loss: 1.2846 - val_accuracy: 0.4051

Epoch 01090: val_loss did not improve from 1.27577
Epoch 1091/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4123 - val_loss: 1.2793 - val_accuracy: 0.4075

Epoch 01091: val_loss did not improve from 1.27577
Epoch 1092/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4160 - val_loss: 1.2809 - val_accuracy: 0.4091

Epoch 01092: val_loss did not improve from 1.27577
Epoch 1093/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4177 - val_loss: 1.2799 - val_accuracy: 0.4043

Epoch 01093: val_loss did not improve from 1.27577
Epoch 1094/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4164 - val_loss: 1.2814 - val_accuracy: 0.4059

Epoch 01094: val_loss did not improve from 1.27577
Epoch 1095/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4180 - val_loss: 1.2825 - val_accuracy: 0.4091

Epoch 01095: val_loss did not improve from 1.27577
Epoch 1096/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4205 - val_loss: 1.2837 - val_accuracy: 0.4051

Epoch 01096: val_loss did not improve from 1.27577
Epoch 1097/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4144 - val_loss: 1.2785 - val_accuracy: 0.4027

Epoch 01097: val_loss did not improve from 1.27577
Epoch 1098/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4140 - val_loss: 1.2752 - val_accuracy: 0.4195

Epoch 01098: val_loss improved from 1.27577 to 1.27522, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1099/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4134 - val_loss: 1.2792 - val_accuracy: 0.4123

Epoch 01099: val_loss did not improve from 1.27522
Epoch 1100/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4159 - val_loss: 1.2883 - val_accuracy: 0.4043

Epoch 01100: val_loss did not improve from 1.27522
Epoch 1101/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4144 - val_loss: 1.2825 - val_accuracy: 0.4067

Epoch 01101: val_loss did not improve from 1.27522
Epoch 1102/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4143 - val_loss: 1.2805 - val_accuracy: 0.4019

Epoch 01102: val_loss did not improve from 1.27522
Epoch 1103/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4193 - val_loss: 1.2845 - val_accuracy: 0.4075

Epoch 01103: val_loss did not improve from 1.27522
Epoch 1104/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4216 - val_loss: 1.2850 - val_accuracy: 0.4027

Epoch 01104: val_loss did not improve from 1.27522
Epoch 1105/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4170 - val_loss: 1.2792 - val_accuracy: 0.4155

Epoch 01105: val_loss did not improve from 1.27522
Epoch 1106/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4176 - val_loss: 1.2868 - val_accuracy: 0.3979

Epoch 01106: val_loss did not improve from 1.27522
Epoch 1107/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4165 - val_loss: 1.3004 - val_accuracy: 0.4011

Epoch 01107: val_loss did not improve from 1.27522
Epoch 1108/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4129 - val_loss: 1.2795 - val_accuracy: 0.4179

Epoch 01108: val_loss did not improve from 1.27522
Epoch 1109/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4101 - val_loss: 1.2804 - val_accuracy: 0.4075

Epoch 01109: val_loss did not improve from 1.27522
Epoch 1110/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4183 - val_loss: 1.2833 - val_accuracy: 0.4043

Epoch 01110: val_loss did not improve from 1.27522
Epoch 1111/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4180 - val_loss: 1.2804 - val_accuracy: 0.4051

Epoch 01111: val_loss did not improve from 1.27522
Epoch 1112/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4164 - val_loss: 1.2825 - val_accuracy: 0.4043

Epoch 01112: val_loss did not improve from 1.27522
Epoch 1113/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4180 - val_loss: 1.2757 - val_accuracy: 0.4091

Epoch 01113: val_loss did not improve from 1.27522
Epoch 1114/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4168 - val_loss: 1.2779 - val_accuracy: 0.4075

Epoch 01114: val_loss did not improve from 1.27522
Epoch 1115/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4163 - val_loss: 1.2823 - val_accuracy: 0.4043

Epoch 01115: val_loss did not improve from 1.27522
Epoch 1116/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4184 - val_loss: 1.2789 - val_accuracy: 0.4123

Epoch 01116: val_loss did not improve from 1.27522
Epoch 1117/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4125 - val_loss: 1.2783 - val_accuracy: 0.4131

Epoch 01117: val_loss did not improve from 1.27522
Epoch 1118/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4171 - val_loss: 1.2769 - val_accuracy: 0.4075

Epoch 01118: val_loss did not improve from 1.27522
Epoch 1119/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4118 - val_loss: 1.2845 - val_accuracy: 0.3995

Epoch 01119: val_loss did not improve from 1.27522
Epoch 1120/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4091 - val_loss: 1.2865 - val_accuracy: 0.4067

Epoch 01120: val_loss did not improve from 1.27522
Epoch 1121/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4193 - val_loss: 1.2818 - val_accuracy: 0.4131

Epoch 01121: val_loss did not improve from 1.27522
Epoch 1122/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4175 - val_loss: 1.2759 - val_accuracy: 0.4226

Epoch 01122: val_loss did not improve from 1.27522
Epoch 1123/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4188 - val_loss: 1.2909 - val_accuracy: 0.4043

Epoch 01123: val_loss did not improve from 1.27522
Epoch 1124/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4122 - val_loss: 1.2770 - val_accuracy: 0.4187

Epoch 01124: val_loss did not improve from 1.27522
Epoch 1125/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4152 - val_loss: 1.2776 - val_accuracy: 0.4139

Epoch 01125: val_loss did not improve from 1.27522
Epoch 1126/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4172 - val_loss: 1.2949 - val_accuracy: 0.4027

Epoch 01126: val_loss did not improve from 1.27522
Epoch 1127/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4171 - val_loss: 1.2770 - val_accuracy: 0.4131

Epoch 01127: val_loss did not improve from 1.27522
Epoch 1128/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4194 - val_loss: 1.2773 - val_accuracy: 0.4179

Epoch 01128: val_loss did not improve from 1.27522
Epoch 1129/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4167 - val_loss: 1.2893 - val_accuracy: 0.4035

Epoch 01129: val_loss did not improve from 1.27522
Epoch 1130/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4156 - val_loss: 1.2838 - val_accuracy: 0.4067

Epoch 01130: val_loss did not improve from 1.27522
Epoch 1131/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4140 - val_loss: 1.2770 - val_accuracy: 0.4075

Epoch 01131: val_loss did not improve from 1.27522
Epoch 1132/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4149 - val_loss: 1.2796 - val_accuracy: 0.4091

Epoch 01132: val_loss did not improve from 1.27522
Epoch 1133/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4184 - val_loss: 1.2792 - val_accuracy: 0.4051

Epoch 01133: val_loss did not improve from 1.27522
Epoch 1134/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4188 - val_loss: 1.2803 - val_accuracy: 0.4091

Epoch 01134: val_loss did not improve from 1.27522
Epoch 1135/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4159 - val_loss: 1.2795 - val_accuracy: 0.4035

Epoch 01135: val_loss did not improve from 1.27522
Epoch 1136/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4194 - val_loss: 1.2757 - val_accuracy: 0.4067

Epoch 01136: val_loss did not improve from 1.27522
Epoch 1137/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4191 - val_loss: 1.2842 - val_accuracy: 0.4139

Epoch 01137: val_loss did not improve from 1.27522
Epoch 1138/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4128 - val_loss: 1.2839 - val_accuracy: 0.4027

Epoch 01138: val_loss did not improve from 1.27522
Epoch 1139/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4181 - val_loss: 1.2787 - val_accuracy: 0.4115

Epoch 01139: val_loss did not improve from 1.27522
Epoch 1140/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4194 - val_loss: 1.2788 - val_accuracy: 0.4059

Epoch 01140: val_loss did not improve from 1.27522
Epoch 1141/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4204 - val_loss: 1.2785 - val_accuracy: 0.4139

Epoch 01141: val_loss did not improve from 1.27522
Epoch 1142/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4177 - val_loss: 1.2792 - val_accuracy: 0.4115

Epoch 01142: val_loss did not improve from 1.27522
Epoch 1143/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4133 - val_loss: 1.2885 - val_accuracy: 0.3987

Epoch 01143: val_loss did not improve from 1.27522
Epoch 1144/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4153 - val_loss: 1.2778 - val_accuracy: 0.4099

Epoch 01144: val_loss did not improve from 1.27522
Epoch 1145/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4177 - val_loss: 1.2810 - val_accuracy: 0.4067

Epoch 01145: val_loss did not improve from 1.27522
Epoch 1146/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4163 - val_loss: 1.2962 - val_accuracy: 0.3987

Epoch 01146: val_loss did not improve from 1.27522
Epoch 1147/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4184 - val_loss: 1.2785 - val_accuracy: 0.4163

Epoch 01147: val_loss did not improve from 1.27522
Epoch 1148/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4163 - val_loss: 1.2771 - val_accuracy: 0.4131

Epoch 01148: val_loss did not improve from 1.27522
Epoch 1149/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4132 - val_loss: 1.2846 - val_accuracy: 0.4019

Epoch 01149: val_loss did not improve from 1.27522
Epoch 1150/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4190 - val_loss: 1.2787 - val_accuracy: 0.4051

Epoch 01150: val_loss did not improve from 1.27522
Epoch 1151/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4188 - val_loss: 1.2773 - val_accuracy: 0.4115

Epoch 01151: val_loss did not improve from 1.27522
Epoch 1152/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4194 - val_loss: 1.2767 - val_accuracy: 0.4131

Epoch 01152: val_loss did not improve from 1.27522
Epoch 1153/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4195 - val_loss: 1.2760 - val_accuracy: 0.4107

Epoch 01153: val_loss did not improve from 1.27522
Epoch 1154/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4173 - val_loss: 1.2748 - val_accuracy: 0.4139

Epoch 01154: val_loss improved from 1.27522 to 1.27476, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1155/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4184 - val_loss: 1.2921 - val_accuracy: 0.4003

Epoch 01155: val_loss did not improve from 1.27476
Epoch 1156/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4167 - val_loss: 1.2755 - val_accuracy: 0.4139

Epoch 01156: val_loss did not improve from 1.27476
Epoch 1157/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4196 - val_loss: 1.2776 - val_accuracy: 0.4163

Epoch 01157: val_loss did not improve from 1.27476
Epoch 1158/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4194 - val_loss: 1.2783 - val_accuracy: 0.4131

Epoch 01158: val_loss did not improve from 1.27476
Epoch 1159/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4188 - val_loss: 1.2809 - val_accuracy: 0.4059

Epoch 01159: val_loss did not improve from 1.27476
Epoch 1160/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4122 - val_loss: 1.2920 - val_accuracy: 0.3963

Epoch 01160: val_loss did not improve from 1.27476
Epoch 1161/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4174 - val_loss: 1.2779 - val_accuracy: 0.4187

Epoch 01161: val_loss did not improve from 1.27476
Epoch 1162/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4172 - val_loss: 1.2760 - val_accuracy: 0.4107

Epoch 01162: val_loss did not improve from 1.27476
Epoch 1163/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4179 - val_loss: 1.2764 - val_accuracy: 0.4051

Epoch 01163: val_loss did not improve from 1.27476
Epoch 1164/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4166 - val_loss: 1.2765 - val_accuracy: 0.4155

Epoch 01164: val_loss did not improve from 1.27476
Epoch 1165/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4165 - val_loss: 1.2898 - val_accuracy: 0.4011

Epoch 01165: val_loss did not improve from 1.27476
Epoch 1166/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4149 - val_loss: 1.2781 - val_accuracy: 0.4123

Epoch 01166: val_loss did not improve from 1.27476
Epoch 1167/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4171 - val_loss: 1.2763 - val_accuracy: 0.4211

Epoch 01167: val_loss did not improve from 1.27476
Epoch 1168/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4118 - val_loss: 1.2831 - val_accuracy: 0.4059

Epoch 01168: val_loss did not improve from 1.27476
Epoch 1169/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4181 - val_loss: 1.2881 - val_accuracy: 0.4091

Epoch 01169: val_loss did not improve from 1.27476
Epoch 1170/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4147 - val_loss: 1.2769 - val_accuracy: 0.4075

Epoch 01170: val_loss did not improve from 1.27476
Epoch 1171/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4185 - val_loss: 1.2785 - val_accuracy: 0.4123

Epoch 01171: val_loss did not improve from 1.27476
Epoch 1172/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4160 - val_loss: 1.2770 - val_accuracy: 0.4091

Epoch 01172: val_loss did not improve from 1.27476
Epoch 1173/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4129 - val_loss: 1.2910 - val_accuracy: 0.4051

Epoch 01173: val_loss did not improve from 1.27476
Epoch 1174/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4178 - val_loss: 1.2857 - val_accuracy: 0.4003

Epoch 01174: val_loss did not improve from 1.27476
Epoch 1175/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4143 - val_loss: 1.2794 - val_accuracy: 0.4195

Epoch 01175: val_loss did not improve from 1.27476
Epoch 1176/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4179 - val_loss: 1.2751 - val_accuracy: 0.4282

Epoch 01176: val_loss did not improve from 1.27476
Epoch 1177/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4156 - val_loss: 1.3012 - val_accuracy: 0.4003

Epoch 01177: val_loss did not improve from 1.27476
Epoch 1178/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4150 - val_loss: 1.2777 - val_accuracy: 0.4059

Epoch 01178: val_loss did not improve from 1.27476
Epoch 1179/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4200 - val_loss: 1.2764 - val_accuracy: 0.4099

Epoch 01179: val_loss did not improve from 1.27476
Epoch 1180/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4171 - val_loss: 1.2809 - val_accuracy: 0.4075

Epoch 01180: val_loss did not improve from 1.27476
Epoch 1181/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4176 - val_loss: 1.2772 - val_accuracy: 0.4179

Epoch 01181: val_loss did not improve from 1.27476
Epoch 1182/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4133 - val_loss: 1.2806 - val_accuracy: 0.4115

Epoch 01182: val_loss did not improve from 1.27476
Epoch 1183/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4188 - val_loss: 1.2764 - val_accuracy: 0.4179

Epoch 01183: val_loss did not improve from 1.27476
Epoch 1184/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4182 - val_loss: 1.2778 - val_accuracy: 0.4099

Epoch 01184: val_loss did not improve from 1.27476
Epoch 1185/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4185 - val_loss: 1.2766 - val_accuracy: 0.4195

Epoch 01185: val_loss did not improve from 1.27476
Epoch 1186/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4191 - val_loss: 1.2754 - val_accuracy: 0.4099

Epoch 01186: val_loss did not improve from 1.27476
Epoch 1187/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4202 - val_loss: 1.2803 - val_accuracy: 0.4019

Epoch 01187: val_loss did not improve from 1.27476
Epoch 1188/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4173 - val_loss: 1.2761 - val_accuracy: 0.4163

Epoch 01188: val_loss did not improve from 1.27476
Epoch 1189/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4186 - val_loss: 1.2805 - val_accuracy: 0.4219

Epoch 01189: val_loss did not improve from 1.27476
Epoch 1190/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4190 - val_loss: 1.2773 - val_accuracy: 0.4139

Epoch 01190: val_loss did not improve from 1.27476
Epoch 1191/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4178 - val_loss: 1.2791 - val_accuracy: 0.4067

Epoch 01191: val_loss did not improve from 1.27476
Epoch 1192/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4190 - val_loss: 1.2759 - val_accuracy: 0.4179

Epoch 01192: val_loss did not improve from 1.27476
Epoch 1193/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4187 - val_loss: 1.2769 - val_accuracy: 0.4091

Epoch 01193: val_loss did not improve from 1.27476
Epoch 1194/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4204 - val_loss: 1.2844 - val_accuracy: 0.4059

Epoch 01194: val_loss did not improve from 1.27476
Epoch 1195/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4222 - val_loss: 1.2744 - val_accuracy: 0.4195

Epoch 01195: val_loss improved from 1.27476 to 1.27443, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1196/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4183 - val_loss: 1.2803 - val_accuracy: 0.4075

Epoch 01196: val_loss did not improve from 1.27443
Epoch 1197/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4203 - val_loss: 1.2896 - val_accuracy: 0.4011

Epoch 01197: val_loss did not improve from 1.27443
Epoch 1198/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4229 - val_loss: 1.2746 - val_accuracy: 0.4123

Epoch 01198: val_loss did not improve from 1.27443
Epoch 1199/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4179 - val_loss: 1.2802 - val_accuracy: 0.4123

Epoch 01199: val_loss did not improve from 1.27443
Epoch 1200/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4194 - val_loss: 1.2778 - val_accuracy: 0.4091

Epoch 01200: val_loss did not improve from 1.27443
Epoch 1201/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4201 - val_loss: 1.2769 - val_accuracy: 0.4115

Epoch 01201: val_loss did not improve from 1.27443
Epoch 1202/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4220 - val_loss: 1.2808 - val_accuracy: 0.4075

Epoch 01202: val_loss did not improve from 1.27443
Epoch 1203/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4221 - val_loss: 1.2769 - val_accuracy: 0.4163

Epoch 01203: val_loss did not improve from 1.27443
Epoch 1204/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4185 - val_loss: 1.2760 - val_accuracy: 0.4131

Epoch 01204: val_loss did not improve from 1.27443
Epoch 1205/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4188 - val_loss: 1.2750 - val_accuracy: 0.4195

Epoch 01205: val_loss did not improve from 1.27443
Epoch 1206/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4167 - val_loss: 1.2866 - val_accuracy: 0.4059

Epoch 01206: val_loss did not improve from 1.27443
Epoch 1207/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4167 - val_loss: 1.2745 - val_accuracy: 0.4155

Epoch 01207: val_loss did not improve from 1.27443
Epoch 1208/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4202 - val_loss: 1.2767 - val_accuracy: 0.4163

Epoch 01208: val_loss did not improve from 1.27443
Epoch 1209/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4220 - val_loss: 1.2792 - val_accuracy: 0.4003

Epoch 01209: val_loss did not improve from 1.27443
Epoch 1210/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4199 - val_loss: 1.2755 - val_accuracy: 0.4107

Epoch 01210: val_loss did not improve from 1.27443
Epoch 1211/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4182 - val_loss: 1.2803 - val_accuracy: 0.4123

Epoch 01211: val_loss did not improve from 1.27443
Epoch 1212/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4174 - val_loss: 1.2754 - val_accuracy: 0.4139

Epoch 01212: val_loss did not improve from 1.27443
Epoch 1213/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4187 - val_loss: 1.2877 - val_accuracy: 0.4027

Epoch 01213: val_loss did not improve from 1.27443
Epoch 1214/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4196 - val_loss: 1.2796 - val_accuracy: 0.4091

Epoch 01214: val_loss did not improve from 1.27443
Epoch 1215/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4202 - val_loss: 1.2786 - val_accuracy: 0.4123

Epoch 01215: val_loss did not improve from 1.27443
Epoch 1216/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4153 - val_loss: 1.2760 - val_accuracy: 0.4187

Epoch 01216: val_loss did not improve from 1.27443
Epoch 1217/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4172 - val_loss: 1.2811 - val_accuracy: 0.4011

Epoch 01217: val_loss did not improve from 1.27443
Epoch 1218/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4185 - val_loss: 1.2920 - val_accuracy: 0.4043

Epoch 01218: val_loss did not improve from 1.27443
Epoch 1219/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4187 - val_loss: 1.2739 - val_accuracy: 0.4147

Epoch 01219: val_loss improved from 1.27443 to 1.27390, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1220/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4185 - val_loss: 1.2775 - val_accuracy: 0.4075

Epoch 01220: val_loss did not improve from 1.27390
Epoch 1221/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4148 - val_loss: 1.2907 - val_accuracy: 0.4003

Epoch 01221: val_loss did not improve from 1.27390
Epoch 1222/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4177 - val_loss: 1.2786 - val_accuracy: 0.4147

Epoch 01222: val_loss did not improve from 1.27390
Epoch 1223/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4213 - val_loss: 1.2744 - val_accuracy: 0.4123

Epoch 01223: val_loss did not improve from 1.27390
Epoch 1224/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4141 - val_loss: 1.2835 - val_accuracy: 0.4027

Epoch 01224: val_loss did not improve from 1.27390
Epoch 1225/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4206 - val_loss: 1.2763 - val_accuracy: 0.4123

Epoch 01225: val_loss did not improve from 1.27390
Epoch 1226/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4187 - val_loss: 1.2760 - val_accuracy: 0.4242

Epoch 01226: val_loss did not improve from 1.27390
Epoch 1227/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4177 - val_loss: 1.2765 - val_accuracy: 0.4123

Epoch 01227: val_loss did not improve from 1.27390
Epoch 1228/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4152 - val_loss: 1.2801 - val_accuracy: 0.4115

Epoch 01228: val_loss did not improve from 1.27390
Epoch 1229/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4186 - val_loss: 1.2815 - val_accuracy: 0.4083

Epoch 01229: val_loss did not improve from 1.27390
Epoch 1230/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4201 - val_loss: 1.2755 - val_accuracy: 0.4011

Epoch 01230: val_loss did not improve from 1.27390
Epoch 1231/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4170 - val_loss: 1.2802 - val_accuracy: 0.4091

Epoch 01231: val_loss did not improve from 1.27390
Epoch 1232/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4179 - val_loss: 1.2772 - val_accuracy: 0.4123

Epoch 01232: val_loss did not improve from 1.27390
Epoch 1233/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4175 - val_loss: 1.2796 - val_accuracy: 0.4051

Epoch 01233: val_loss did not improve from 1.27390
Epoch 1234/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4172 - val_loss: 1.2792 - val_accuracy: 0.4155

Epoch 01234: val_loss did not improve from 1.27390
Epoch 1235/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4210 - val_loss: 1.2733 - val_accuracy: 0.4211

Epoch 01235: val_loss improved from 1.27390 to 1.27333, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1236/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4183 - val_loss: 1.2895 - val_accuracy: 0.3987

Epoch 01236: val_loss did not improve from 1.27333
Epoch 1237/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4164 - val_loss: 1.2782 - val_accuracy: 0.4099

Epoch 01237: val_loss did not improve from 1.27333
Epoch 1238/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4211 - val_loss: 1.2784 - val_accuracy: 0.4107

Epoch 01238: val_loss did not improve from 1.27333
Epoch 1239/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4208 - val_loss: 1.2771 - val_accuracy: 0.4147

Epoch 01239: val_loss did not improve from 1.27333
Epoch 1240/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4168 - val_loss: 1.2813 - val_accuracy: 0.4107

Epoch 01240: val_loss did not improve from 1.27333
Epoch 1241/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4215 - val_loss: 1.2774 - val_accuracy: 0.4115

Epoch 01241: val_loss did not improve from 1.27333
Epoch 1242/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4205 - val_loss: 1.2744 - val_accuracy: 0.4131

Epoch 01242: val_loss did not improve from 1.27333
Epoch 1243/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4202 - val_loss: 1.2845 - val_accuracy: 0.4091

Epoch 01243: val_loss did not improve from 1.27333
Epoch 1244/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4190 - val_loss: 1.2774 - val_accuracy: 0.4123

Epoch 01244: val_loss did not improve from 1.27333
Epoch 1245/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4170 - val_loss: 1.2756 - val_accuracy: 0.4155

Epoch 01245: val_loss did not improve from 1.27333
Epoch 1246/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4187 - val_loss: 1.2776 - val_accuracy: 0.4211

Epoch 01246: val_loss did not improve from 1.27333
Epoch 1247/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4210 - val_loss: 1.2774 - val_accuracy: 0.4043

Epoch 01247: val_loss did not improve from 1.27333
Epoch 1248/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4177 - val_loss: 1.2780 - val_accuracy: 0.4067

Epoch 01248: val_loss did not improve from 1.27333
Epoch 1249/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4220 - val_loss: 1.2835 - val_accuracy: 0.4075

Epoch 01249: val_loss did not improve from 1.27333
Epoch 1250/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4187 - val_loss: 1.2787 - val_accuracy: 0.4099

Epoch 01250: val_loss did not improve from 1.27333
Epoch 1251/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4187 - val_loss: 1.2769 - val_accuracy: 0.4107

Epoch 01251: val_loss did not improve from 1.27333
Epoch 1252/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4221 - val_loss: 1.2810 - val_accuracy: 0.4107

Epoch 01252: val_loss did not improve from 1.27333
Epoch 1253/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4201 - val_loss: 1.2769 - val_accuracy: 0.4083

Epoch 01253: val_loss did not improve from 1.27333
Epoch 1254/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4204 - val_loss: 1.2807 - val_accuracy: 0.4051

Epoch 01254: val_loss did not improve from 1.27333
Epoch 1255/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4183 - val_loss: 1.2760 - val_accuracy: 0.4115

Epoch 01255: val_loss did not improve from 1.27333
Epoch 1256/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4161 - val_loss: 1.2872 - val_accuracy: 0.4035

Epoch 01256: val_loss did not improve from 1.27333
Epoch 1257/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4218 - val_loss: 1.2744 - val_accuracy: 0.4195

Epoch 01257: val_loss did not improve from 1.27333
Epoch 1258/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4206 - val_loss: 1.2748 - val_accuracy: 0.4067

Epoch 01258: val_loss did not improve from 1.27333
Epoch 1259/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4174 - val_loss: 1.2832 - val_accuracy: 0.4067

Epoch 01259: val_loss did not improve from 1.27333
Epoch 1260/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4214 - val_loss: 1.2834 - val_accuracy: 0.4051

Epoch 01260: val_loss did not improve from 1.27333
Epoch 1261/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4192 - val_loss: 1.2727 - val_accuracy: 0.4163

Epoch 01261: val_loss improved from 1.27333 to 1.27269, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1262/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4165 - val_loss: 1.2772 - val_accuracy: 0.4027

Epoch 01262: val_loss did not improve from 1.27269
Epoch 1263/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4152 - val_loss: 1.2830 - val_accuracy: 0.4067

Epoch 01263: val_loss did not improve from 1.27269
Epoch 1264/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4205 - val_loss: 1.2826 - val_accuracy: 0.4131

Epoch 01264: val_loss did not improve from 1.27269
Epoch 1265/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4157 - val_loss: 1.2754 - val_accuracy: 0.4131

Epoch 01265: val_loss did not improve from 1.27269
Epoch 1266/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4163 - val_loss: 1.2796 - val_accuracy: 0.4051

Epoch 01266: val_loss did not improve from 1.27269
Epoch 1267/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4210 - val_loss: 1.2756 - val_accuracy: 0.4131

Epoch 01267: val_loss did not improve from 1.27269
Epoch 1268/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4214 - val_loss: 1.2804 - val_accuracy: 0.4123

Epoch 01268: val_loss did not improve from 1.27269
Epoch 1269/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4204 - val_loss: 1.2764 - val_accuracy: 0.4123

Epoch 01269: val_loss did not improve from 1.27269
Epoch 1270/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4216 - val_loss: 1.2756 - val_accuracy: 0.4147

Epoch 01270: val_loss did not improve from 1.27269
Epoch 1271/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4216 - val_loss: 1.2820 - val_accuracy: 0.4099

Epoch 01271: val_loss did not improve from 1.27269
Epoch 1272/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4218 - val_loss: 1.2742 - val_accuracy: 0.4163

Epoch 01272: val_loss did not improve from 1.27269
Epoch 1273/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4171 - val_loss: 1.2755 - val_accuracy: 0.4107

Epoch 01273: val_loss did not improve from 1.27269
Epoch 1274/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4212 - val_loss: 1.2899 - val_accuracy: 0.3987

Epoch 01274: val_loss did not improve from 1.27269
Epoch 1275/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4218 - val_loss: 1.2758 - val_accuracy: 0.4147

Epoch 01275: val_loss did not improve from 1.27269
Epoch 1276/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4220 - val_loss: 1.2770 - val_accuracy: 0.4099

Epoch 01276: val_loss did not improve from 1.27269
Epoch 1277/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4216 - val_loss: 1.2751 - val_accuracy: 0.4171

Epoch 01277: val_loss did not improve from 1.27269
Epoch 1278/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4199 - val_loss: 1.2820 - val_accuracy: 0.4059

Epoch 01278: val_loss did not improve from 1.27269
Epoch 1279/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4113 - val_loss: 1.2764 - val_accuracy: 0.4075

Epoch 01279: val_loss did not improve from 1.27269
Epoch 1280/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4167 - val_loss: 1.2755 - val_accuracy: 0.4171

Epoch 01280: val_loss did not improve from 1.27269
Epoch 1281/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4191 - val_loss: 1.2824 - val_accuracy: 0.4059

Epoch 01281: val_loss did not improve from 1.27269
Epoch 1282/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4217 - val_loss: 1.2790 - val_accuracy: 0.4099

Epoch 01282: val_loss did not improve from 1.27269
Epoch 1283/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4112 - val_loss: 1.2848 - val_accuracy: 0.4027

Epoch 01283: val_loss did not improve from 1.27269
Epoch 1284/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4202 - val_loss: 1.2812 - val_accuracy: 0.4083

Epoch 01284: val_loss did not improve from 1.27269
Epoch 1285/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4233 - val_loss: 1.2728 - val_accuracy: 0.4234

Epoch 01285: val_loss did not improve from 1.27269
Epoch 1286/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4177 - val_loss: 1.2841 - val_accuracy: 0.4075

Epoch 01286: val_loss did not improve from 1.27269
Epoch 1287/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4163 - val_loss: 1.2806 - val_accuracy: 0.4051

Epoch 01287: val_loss did not improve from 1.27269
Epoch 1288/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4191 - val_loss: 1.2740 - val_accuracy: 0.4107

Epoch 01288: val_loss did not improve from 1.27269
Epoch 1289/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4210 - val_loss: 1.2759 - val_accuracy: 0.4115

Epoch 01289: val_loss did not improve from 1.27269
Epoch 1290/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4163 - val_loss: 1.2857 - val_accuracy: 0.4059

Epoch 01290: val_loss did not improve from 1.27269
Epoch 1291/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4224 - val_loss: 1.2767 - val_accuracy: 0.4043

Epoch 01291: val_loss did not improve from 1.27269
Epoch 1292/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4187 - val_loss: 1.2721 - val_accuracy: 0.4075

Epoch 01292: val_loss improved from 1.27269 to 1.27208, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1293/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4204 - val_loss: 1.2783 - val_accuracy: 0.4075

Epoch 01293: val_loss did not improve from 1.27208
Epoch 1294/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4165 - val_loss: 1.2762 - val_accuracy: 0.4075

Epoch 01294: val_loss did not improve from 1.27208
Epoch 1295/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4204 - val_loss: 1.2783 - val_accuracy: 0.4011

Epoch 01295: val_loss did not improve from 1.27208
Epoch 1296/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4146 - val_loss: 1.2752 - val_accuracy: 0.4043

Epoch 01296: val_loss did not improve from 1.27208
Epoch 1297/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4202 - val_loss: 1.2713 - val_accuracy: 0.4155

Epoch 01297: val_loss improved from 1.27208 to 1.27129, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1298/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4216 - val_loss: 1.2751 - val_accuracy: 0.4123

Epoch 01298: val_loss did not improve from 1.27129
Epoch 1299/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4205 - val_loss: 1.2755 - val_accuracy: 0.4139

Epoch 01299: val_loss did not improve from 1.27129
Epoch 1300/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4160 - val_loss: 1.2828 - val_accuracy: 0.4075

Epoch 01300: val_loss did not improve from 1.27129
Epoch 1301/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4210 - val_loss: 1.2769 - val_accuracy: 0.4115

Epoch 01301: val_loss did not improve from 1.27129
Epoch 1302/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4186 - val_loss: 1.2741 - val_accuracy: 0.4091

Epoch 01302: val_loss did not improve from 1.27129
Epoch 1303/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4137 - val_loss: 1.2825 - val_accuracy: 0.4011

Epoch 01303: val_loss did not improve from 1.27129
Epoch 1304/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4168 - val_loss: 1.2770 - val_accuracy: 0.4099

Epoch 01304: val_loss did not improve from 1.27129
Epoch 1305/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4186 - val_loss: 1.2742 - val_accuracy: 0.4147

Epoch 01305: val_loss did not improve from 1.27129
Epoch 1306/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4210 - val_loss: 1.2733 - val_accuracy: 0.4179

Epoch 01306: val_loss did not improve from 1.27129
Epoch 1307/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4167 - val_loss: 1.2850 - val_accuracy: 0.4067

Epoch 01307: val_loss did not improve from 1.27129
Epoch 1308/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4223 - val_loss: 1.2756 - val_accuracy: 0.4131

Epoch 01308: val_loss did not improve from 1.27129
Epoch 1309/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4206 - val_loss: 1.2707 - val_accuracy: 0.4226

Epoch 01309: val_loss improved from 1.27129 to 1.27073, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1310/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4207 - val_loss: 1.2748 - val_accuracy: 0.4027

Epoch 01310: val_loss did not improve from 1.27073
Epoch 1311/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4216 - val_loss: 1.2788 - val_accuracy: 0.4075

Epoch 01311: val_loss did not improve from 1.27073
Epoch 1312/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4242 - val_loss: 1.2760 - val_accuracy: 0.4067

Epoch 01312: val_loss did not improve from 1.27073
Epoch 1313/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4194 - val_loss: 1.2732 - val_accuracy: 0.4203

Epoch 01313: val_loss did not improve from 1.27073
Epoch 1314/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4204 - val_loss: 1.2755 - val_accuracy: 0.4051

Epoch 01314: val_loss did not improve from 1.27073
Epoch 1315/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4183 - val_loss: 1.2820 - val_accuracy: 0.4043

Epoch 01315: val_loss did not improve from 1.27073
Epoch 1316/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4204 - val_loss: 1.2735 - val_accuracy: 0.4155

Epoch 01316: val_loss did not improve from 1.27073
Epoch 1317/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4204 - val_loss: 1.2844 - val_accuracy: 0.4107

Epoch 01317: val_loss did not improve from 1.27073
Epoch 1318/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4204 - val_loss: 1.2780 - val_accuracy: 0.4115

Epoch 01318: val_loss did not improve from 1.27073
Epoch 1319/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4212 - val_loss: 1.2829 - val_accuracy: 0.4027

Epoch 01319: val_loss did not improve from 1.27073
Epoch 1320/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4254 - val_loss: 1.2718 - val_accuracy: 0.4099

Epoch 01320: val_loss did not improve from 1.27073
Epoch 1321/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4238 - val_loss: 1.2730 - val_accuracy: 0.4115

Epoch 01321: val_loss did not improve from 1.27073
Epoch 1322/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4210 - val_loss: 1.2764 - val_accuracy: 0.4195

Epoch 01322: val_loss did not improve from 1.27073
Epoch 1323/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4186 - val_loss: 1.2874 - val_accuracy: 0.3995

Epoch 01323: val_loss did not improve from 1.27073
Epoch 1324/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4192 - val_loss: 1.2737 - val_accuracy: 0.4123

Epoch 01324: val_loss did not improve from 1.27073
Epoch 1325/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4233 - val_loss: 1.2731 - val_accuracy: 0.4226

Epoch 01325: val_loss did not improve from 1.27073
Epoch 1326/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4211 - val_loss: 1.2799 - val_accuracy: 0.4067

Epoch 01326: val_loss did not improve from 1.27073
Epoch 1327/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4204 - val_loss: 1.2896 - val_accuracy: 0.4043

Epoch 01327: val_loss did not improve from 1.27073
Epoch 1328/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4214 - val_loss: 1.2776 - val_accuracy: 0.4067

Epoch 01328: val_loss did not improve from 1.27073
Epoch 1329/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4230 - val_loss: 1.2733 - val_accuracy: 0.4123

Epoch 01329: val_loss did not improve from 1.27073
Epoch 1330/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4147 - val_loss: 1.2756 - val_accuracy: 0.4075

Epoch 01330: val_loss did not improve from 1.27073
Epoch 1331/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4199 - val_loss: 1.2779 - val_accuracy: 0.4115

Epoch 01331: val_loss did not improve from 1.27073
Epoch 1332/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4234 - val_loss: 1.2748 - val_accuracy: 0.4083

Epoch 01332: val_loss did not improve from 1.27073
Epoch 1333/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4218 - val_loss: 1.2723 - val_accuracy: 0.4234

Epoch 01333: val_loss did not improve from 1.27073
Epoch 1334/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4202 - val_loss: 1.2797 - val_accuracy: 0.4027

Epoch 01334: val_loss did not improve from 1.27073
Epoch 1335/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4172 - val_loss: 1.2812 - val_accuracy: 0.3995

Epoch 01335: val_loss did not improve from 1.27073
Epoch 1336/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4227 - val_loss: 1.2730 - val_accuracy: 0.4163

Epoch 01336: val_loss did not improve from 1.27073
Epoch 1337/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4201 - val_loss: 1.2725 - val_accuracy: 0.4139

Epoch 01337: val_loss did not improve from 1.27073
Epoch 1338/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4223 - val_loss: 1.2764 - val_accuracy: 0.4091

Epoch 01338: val_loss did not improve from 1.27073
Epoch 1339/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4228 - val_loss: 1.2785 - val_accuracy: 0.3979

Epoch 01339: val_loss did not improve from 1.27073
Epoch 1340/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4187 - val_loss: 1.2725 - val_accuracy: 0.4123

Epoch 01340: val_loss did not improve from 1.27073
Epoch 1341/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4196 - val_loss: 1.2719 - val_accuracy: 0.4099

Epoch 01341: val_loss did not improve from 1.27073
Epoch 1342/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4225 - val_loss: 1.2751 - val_accuracy: 0.4123

Epoch 01342: val_loss did not improve from 1.27073
Epoch 1343/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4208 - val_loss: 1.2817 - val_accuracy: 0.4043

Epoch 01343: val_loss did not improve from 1.27073
Epoch 1344/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4194 - val_loss: 1.2734 - val_accuracy: 0.4059

Epoch 01344: val_loss did not improve from 1.27073
Epoch 1345/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4264 - val_loss: 1.2728 - val_accuracy: 0.4123

Epoch 01345: val_loss did not improve from 1.27073
Epoch 1346/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4218 - val_loss: 1.2745 - val_accuracy: 0.4083

Epoch 01346: val_loss did not improve from 1.27073
Epoch 1347/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4161 - val_loss: 1.2773 - val_accuracy: 0.4091

Epoch 01347: val_loss did not improve from 1.27073
Epoch 1348/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4225 - val_loss: 1.2861 - val_accuracy: 0.4067

Epoch 01348: val_loss did not improve from 1.27073
Epoch 1349/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4222 - val_loss: 1.2721 - val_accuracy: 0.4187

Epoch 01349: val_loss did not improve from 1.27073
Epoch 1350/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4215 - val_loss: 1.2729 - val_accuracy: 0.4187

Epoch 01350: val_loss did not improve from 1.27073
Epoch 1351/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4267 - val_loss: 1.2782 - val_accuracy: 0.4139

Epoch 01351: val_loss did not improve from 1.27073
Epoch 1352/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4225 - val_loss: 1.2818 - val_accuracy: 0.4019

Epoch 01352: val_loss did not improve from 1.27073
Epoch 1353/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4271 - val_loss: 1.2735 - val_accuracy: 0.4179

Epoch 01353: val_loss did not improve from 1.27073
Epoch 1354/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4175 - val_loss: 1.2738 - val_accuracy: 0.4123

Epoch 01354: val_loss did not improve from 1.27073
Epoch 1355/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4202 - val_loss: 1.2782 - val_accuracy: 0.4131

Epoch 01355: val_loss did not improve from 1.27073
Epoch 1356/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4202 - val_loss: 1.2795 - val_accuracy: 0.4067

Epoch 01356: val_loss did not improve from 1.27073
Epoch 1357/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4245 - val_loss: 1.2746 - val_accuracy: 0.4099

Epoch 01357: val_loss did not improve from 1.27073
Epoch 1358/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4193 - val_loss: 1.2723 - val_accuracy: 0.4242

Epoch 01358: val_loss did not improve from 1.27073
Epoch 1359/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4180 - val_loss: 1.2718 - val_accuracy: 0.4115

Epoch 01359: val_loss did not improve from 1.27073
Epoch 1360/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4196 - val_loss: 1.2752 - val_accuracy: 0.4091

Epoch 01360: val_loss did not improve from 1.27073
Epoch 1361/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4232 - val_loss: 1.2820 - val_accuracy: 0.3979

Epoch 01361: val_loss did not improve from 1.27073
Epoch 1362/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4192 - val_loss: 1.2786 - val_accuracy: 0.4003

Epoch 01362: val_loss did not improve from 1.27073
Epoch 1363/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4225 - val_loss: 1.2730 - val_accuracy: 0.4171

Epoch 01363: val_loss did not improve from 1.27073
Epoch 1364/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4183 - val_loss: 1.2760 - val_accuracy: 0.4163

Epoch 01364: val_loss did not improve from 1.27073
Epoch 1365/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4194 - val_loss: 1.2746 - val_accuracy: 0.4083

Epoch 01365: val_loss did not improve from 1.27073
Epoch 1366/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4163 - val_loss: 1.2733 - val_accuracy: 0.4298

Epoch 01366: val_loss did not improve from 1.27073
Epoch 1367/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4204 - val_loss: 1.2983 - val_accuracy: 0.4051

Epoch 01367: val_loss did not improve from 1.27073
Epoch 1368/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4166 - val_loss: 1.2824 - val_accuracy: 0.4083

Epoch 01368: val_loss did not improve from 1.27073
Epoch 1369/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4200 - val_loss: 1.2729 - val_accuracy: 0.4171

Epoch 01369: val_loss did not improve from 1.27073
Epoch 1370/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4151 - val_loss: 1.2748 - val_accuracy: 0.4298

Epoch 01370: val_loss did not improve from 1.27073
Epoch 1371/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4133 - val_loss: 1.2812 - val_accuracy: 0.4163

Epoch 01371: val_loss did not improve from 1.27073
Epoch 1372/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4185 - val_loss: 1.2813 - val_accuracy: 0.4107

Epoch 01372: val_loss did not improve from 1.27073
Epoch 1373/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4207 - val_loss: 1.2823 - val_accuracy: 0.4083

Epoch 01373: val_loss did not improve from 1.27073
Epoch 1374/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4213 - val_loss: 1.2716 - val_accuracy: 0.4155

Epoch 01374: val_loss did not improve from 1.27073
Epoch 1375/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4197 - val_loss: 1.2747 - val_accuracy: 0.4163

Epoch 01375: val_loss did not improve from 1.27073
Epoch 1376/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4220 - val_loss: 1.2840 - val_accuracy: 0.3987

Epoch 01376: val_loss did not improve from 1.27073
Epoch 1377/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4180 - val_loss: 1.2750 - val_accuracy: 0.4027

Epoch 01377: val_loss did not improve from 1.27073
Epoch 1378/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4208 - val_loss: 1.2712 - val_accuracy: 0.4179

Epoch 01378: val_loss did not improve from 1.27073
Epoch 1379/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4175 - val_loss: 1.2743 - val_accuracy: 0.4139

Epoch 01379: val_loss did not improve from 1.27073
Epoch 1380/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4152 - val_loss: 1.2850 - val_accuracy: 0.4003

Epoch 01380: val_loss did not improve from 1.27073
Epoch 1381/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4232 - val_loss: 1.2778 - val_accuracy: 0.4075

Epoch 01381: val_loss did not improve from 1.27073
Epoch 1382/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4214 - val_loss: 1.2713 - val_accuracy: 0.4091

Epoch 01382: val_loss did not improve from 1.27073
Epoch 1383/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4194 - val_loss: 1.2820 - val_accuracy: 0.4099

Epoch 01383: val_loss did not improve from 1.27073
Epoch 1384/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4255 - val_loss: 1.2732 - val_accuracy: 0.4067

Epoch 01384: val_loss did not improve from 1.27073
Epoch 1385/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4233 - val_loss: 1.2725 - val_accuracy: 0.4067

Epoch 01385: val_loss did not improve from 1.27073
Epoch 1386/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4168 - val_loss: 1.2727 - val_accuracy: 0.4147

Epoch 01386: val_loss did not improve from 1.27073
Epoch 1387/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4128 - val_loss: 1.2851 - val_accuracy: 0.4059

Epoch 01387: val_loss did not improve from 1.27073
Epoch 1388/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4210 - val_loss: 1.2729 - val_accuracy: 0.4123

Epoch 01388: val_loss did not improve from 1.27073
Epoch 1389/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4213 - val_loss: 1.2775 - val_accuracy: 0.4035

Epoch 01389: val_loss did not improve from 1.27073
Epoch 1390/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4229 - val_loss: 1.2769 - val_accuracy: 0.4131

Epoch 01390: val_loss did not improve from 1.27073
Epoch 1391/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4175 - val_loss: 1.2777 - val_accuracy: 0.4067

Epoch 01391: val_loss did not improve from 1.27073
Epoch 1392/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4176 - val_loss: 1.2720 - val_accuracy: 0.4171

Epoch 01392: val_loss did not improve from 1.27073
Epoch 1393/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4248 - val_loss: 1.2741 - val_accuracy: 0.4187

Epoch 01393: val_loss did not improve from 1.27073
Epoch 1394/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4198 - val_loss: 1.2734 - val_accuracy: 0.4099

Epoch 01394: val_loss did not improve from 1.27073
Epoch 1395/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4115 - val_loss: 1.2817 - val_accuracy: 0.4019

Epoch 01395: val_loss did not improve from 1.27073
Epoch 1396/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4176 - val_loss: 1.2722 - val_accuracy: 0.4179

Epoch 01396: val_loss did not improve from 1.27073
Epoch 1397/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4165 - val_loss: 1.2814 - val_accuracy: 0.4011

Epoch 01397: val_loss did not improve from 1.27073
Epoch 1398/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4187 - val_loss: 1.2717 - val_accuracy: 0.4035

Epoch 01398: val_loss did not improve from 1.27073
Epoch 1399/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4228 - val_loss: 1.2719 - val_accuracy: 0.4187

Epoch 01399: val_loss did not improve from 1.27073
Epoch 1400/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4226 - val_loss: 1.2730 - val_accuracy: 0.4011

Epoch 01400: val_loss did not improve from 1.27073
Epoch 1401/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4182 - val_loss: 1.3030 - val_accuracy: 0.3947

Epoch 01401: val_loss did not improve from 1.27073
Epoch 1402/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4174 - val_loss: 1.2705 - val_accuracy: 0.4187

Epoch 01402: val_loss improved from 1.27073 to 1.27055, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1403/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4213 - val_loss: 1.2741 - val_accuracy: 0.4195

Epoch 01403: val_loss did not improve from 1.27055
Epoch 1404/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4185 - val_loss: 1.2706 - val_accuracy: 0.4195

Epoch 01404: val_loss did not improve from 1.27055
Epoch 1405/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4217 - val_loss: 1.2701 - val_accuracy: 0.4195

Epoch 01405: val_loss improved from 1.27055 to 1.27014, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1406/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4208 - val_loss: 1.2828 - val_accuracy: 0.4115

Epoch 01406: val_loss did not improve from 1.27014
Epoch 1407/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4232 - val_loss: 1.2700 - val_accuracy: 0.4211

Epoch 01407: val_loss improved from 1.27014 to 1.26999, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1408/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4222 - val_loss: 1.2775 - val_accuracy: 0.4035

Epoch 01408: val_loss did not improve from 1.26999
Epoch 1409/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4202 - val_loss: 1.2940 - val_accuracy: 0.4059

Epoch 01409: val_loss did not improve from 1.26999
Epoch 1410/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4211 - val_loss: 1.2709 - val_accuracy: 0.4226

Epoch 01410: val_loss did not improve from 1.26999
Epoch 1411/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4221 - val_loss: 1.2738 - val_accuracy: 0.4075

Epoch 01411: val_loss did not improve from 1.26999
Epoch 1412/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4251 - val_loss: 1.2770 - val_accuracy: 0.4027

Epoch 01412: val_loss did not improve from 1.26999
Epoch 1413/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4209 - val_loss: 1.2840 - val_accuracy: 0.4059

Epoch 01413: val_loss did not improve from 1.26999
Epoch 1414/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4196 - val_loss: 1.2698 - val_accuracy: 0.4139

Epoch 01414: val_loss improved from 1.26999 to 1.26981, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1415/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4205 - val_loss: 1.2708 - val_accuracy: 0.4131

Epoch 01415: val_loss did not improve from 1.26981
Epoch 1416/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4225 - val_loss: 1.2735 - val_accuracy: 0.4163

Epoch 01416: val_loss did not improve from 1.26981
Epoch 1417/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4225 - val_loss: 1.2864 - val_accuracy: 0.4091

Epoch 01417: val_loss did not improve from 1.26981
Epoch 1418/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4194 - val_loss: 1.2712 - val_accuracy: 0.4043

Epoch 01418: val_loss did not improve from 1.26981
Epoch 1419/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4203 - val_loss: 1.2693 - val_accuracy: 0.4171

Epoch 01419: val_loss improved from 1.26981 to 1.26925, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1420/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4215 - val_loss: 1.2771 - val_accuracy: 0.4123

Epoch 01420: val_loss did not improve from 1.26925
Epoch 1421/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4212 - val_loss: 1.2750 - val_accuracy: 0.4123

Epoch 01421: val_loss did not improve from 1.26925
Epoch 1422/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4225 - val_loss: 1.2707 - val_accuracy: 0.4147

Epoch 01422: val_loss did not improve from 1.26925
Epoch 1423/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4215 - val_loss: 1.2812 - val_accuracy: 0.4059

Epoch 01423: val_loss did not improve from 1.26925
Epoch 1424/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4231 - val_loss: 1.2740 - val_accuracy: 0.4099

Epoch 01424: val_loss did not improve from 1.26925
Epoch 1425/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4174 - val_loss: 1.2779 - val_accuracy: 0.4115

Epoch 01425: val_loss did not improve from 1.26925
Epoch 1426/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4223 - val_loss: 1.2740 - val_accuracy: 0.4091

Epoch 01426: val_loss did not improve from 1.26925
Epoch 1427/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4246 - val_loss: 1.2688 - val_accuracy: 0.4163

Epoch 01427: val_loss improved from 1.26925 to 1.26882, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1428/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4229 - val_loss: 1.2720 - val_accuracy: 0.4203

Epoch 01428: val_loss did not improve from 1.26882
Epoch 1429/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4217 - val_loss: 1.2849 - val_accuracy: 0.4075

Epoch 01429: val_loss did not improve from 1.26882
Epoch 1430/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4164 - val_loss: 1.2711 - val_accuracy: 0.4211

Epoch 01430: val_loss did not improve from 1.26882
Epoch 1431/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4217 - val_loss: 1.2691 - val_accuracy: 0.4139

Epoch 01431: val_loss did not improve from 1.26882
Epoch 1432/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4208 - val_loss: 1.2769 - val_accuracy: 0.4091

Epoch 01432: val_loss did not improve from 1.26882
Epoch 1433/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4196 - val_loss: 1.2911 - val_accuracy: 0.3987

Epoch 01433: val_loss did not improve from 1.26882
Epoch 1434/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4191 - val_loss: 1.2700 - val_accuracy: 0.4139

Epoch 01434: val_loss did not improve from 1.26882
Epoch 1435/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4234 - val_loss: 1.2703 - val_accuracy: 0.4147

Epoch 01435: val_loss did not improve from 1.26882
Epoch 1436/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4170 - val_loss: 1.2748 - val_accuracy: 0.4027

Epoch 01436: val_loss did not improve from 1.26882
Epoch 1437/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4185 - val_loss: 1.2703 - val_accuracy: 0.4171

Epoch 01437: val_loss did not improve from 1.26882
Epoch 1438/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4212 - val_loss: 1.2753 - val_accuracy: 0.4147

Epoch 01438: val_loss did not improve from 1.26882
Epoch 1439/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4202 - val_loss: 1.2720 - val_accuracy: 0.4123

Epoch 01439: val_loss did not improve from 1.26882
Epoch 1440/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4256 - val_loss: 1.2744 - val_accuracy: 0.3979

Epoch 01440: val_loss did not improve from 1.26882
Epoch 1441/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4207 - val_loss: 1.2730 - val_accuracy: 0.4139

Epoch 01441: val_loss did not improve from 1.26882
Epoch 1442/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4240 - val_loss: 1.2775 - val_accuracy: 0.4123

Epoch 01442: val_loss did not improve from 1.26882
Epoch 1443/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4244 - val_loss: 1.2705 - val_accuracy: 0.4083

Epoch 01443: val_loss did not improve from 1.26882
Epoch 1444/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4176 - val_loss: 1.2724 - val_accuracy: 0.4091

Epoch 01444: val_loss did not improve from 1.26882
Epoch 1445/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4235 - val_loss: 1.2769 - val_accuracy: 0.4099

Epoch 01445: val_loss did not improve from 1.26882
Epoch 1446/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4191 - val_loss: 1.2756 - val_accuracy: 0.4019

Epoch 01446: val_loss did not improve from 1.26882
Epoch 1447/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4149 - val_loss: 1.2749 - val_accuracy: 0.4043

Epoch 01447: val_loss did not improve from 1.26882
Epoch 1448/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4188 - val_loss: 1.2729 - val_accuracy: 0.4067

Epoch 01448: val_loss did not improve from 1.26882
Epoch 1449/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4223 - val_loss: 1.2845 - val_accuracy: 0.3987

Epoch 01449: val_loss did not improve from 1.26882
Epoch 1450/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4221 - val_loss: 1.2711 - val_accuracy: 0.4107

Epoch 01450: val_loss did not improve from 1.26882
Epoch 1451/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4230 - val_loss: 1.2741 - val_accuracy: 0.4035

Epoch 01451: val_loss did not improve from 1.26882
Epoch 1452/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4213 - val_loss: 1.2704 - val_accuracy: 0.4107

Epoch 01452: val_loss did not improve from 1.26882
Epoch 1453/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4265 - val_loss: 1.2766 - val_accuracy: 0.4083

Epoch 01453: val_loss did not improve from 1.26882
Epoch 1454/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4179 - val_loss: 1.2724 - val_accuracy: 0.4027

Epoch 01454: val_loss did not improve from 1.26882
Epoch 1455/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4210 - val_loss: 1.2792 - val_accuracy: 0.4091

Epoch 01455: val_loss did not improve from 1.26882
Epoch 1456/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4211 - val_loss: 1.2731 - val_accuracy: 0.4219

Epoch 01456: val_loss did not improve from 1.26882
Epoch 1457/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4225 - val_loss: 1.2780 - val_accuracy: 0.4115

Epoch 01457: val_loss did not improve from 1.26882
Epoch 1458/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4178 - val_loss: 1.2833 - val_accuracy: 0.4051

Epoch 01458: val_loss did not improve from 1.26882
Epoch 1459/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4241 - val_loss: 1.2706 - val_accuracy: 0.4067

Epoch 01459: val_loss did not improve from 1.26882
Epoch 1460/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4231 - val_loss: 1.2816 - val_accuracy: 0.4075

Epoch 01460: val_loss did not improve from 1.26882
Epoch 1461/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4220 - val_loss: 1.2781 - val_accuracy: 0.4067

Epoch 01461: val_loss did not improve from 1.26882
Epoch 1462/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4229 - val_loss: 1.2693 - val_accuracy: 0.4123

Epoch 01462: val_loss did not improve from 1.26882
Epoch 1463/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4249 - val_loss: 1.2707 - val_accuracy: 0.4123

Epoch 01463: val_loss did not improve from 1.26882
Epoch 1464/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4225 - val_loss: 1.2753 - val_accuracy: 0.4051

Epoch 01464: val_loss did not improve from 1.26882
Epoch 1465/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4204 - val_loss: 1.2736 - val_accuracy: 0.4147

Epoch 01465: val_loss did not improve from 1.26882
Epoch 1466/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4211 - val_loss: 1.2701 - val_accuracy: 0.4163

Epoch 01466: val_loss did not improve from 1.26882
Epoch 1467/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4198 - val_loss: 1.2699 - val_accuracy: 0.4171

Epoch 01467: val_loss did not improve from 1.26882
Epoch 1468/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4259 - val_loss: 1.2753 - val_accuracy: 0.4099

Epoch 01468: val_loss did not improve from 1.26882
Epoch 1469/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4249 - val_loss: 1.2873 - val_accuracy: 0.4067

Epoch 01469: val_loss did not improve from 1.26882
Epoch 1470/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4221 - val_loss: 1.2727 - val_accuracy: 0.4123

Epoch 01470: val_loss did not improve from 1.26882
Epoch 1471/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4215 - val_loss: 1.2711 - val_accuracy: 0.4123

Epoch 01471: val_loss did not improve from 1.26882
Epoch 1472/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4204 - val_loss: 1.2723 - val_accuracy: 0.4027

Epoch 01472: val_loss did not improve from 1.26882
Epoch 1473/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4225 - val_loss: 1.2713 - val_accuracy: 0.4147

Epoch 01473: val_loss did not improve from 1.26882
Epoch 1474/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4232 - val_loss: 1.2734 - val_accuracy: 0.4131

Epoch 01474: val_loss did not improve from 1.26882
Epoch 1475/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4264 - val_loss: 1.2709 - val_accuracy: 0.4171

Epoch 01475: val_loss did not improve from 1.26882
Epoch 1476/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4239 - val_loss: 1.2678 - val_accuracy: 0.4226

Epoch 01476: val_loss improved from 1.26882 to 1.26784, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1477/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4253 - val_loss: 1.2715 - val_accuracy: 0.4171

Epoch 01477: val_loss did not improve from 1.26784
Epoch 1478/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4268 - val_loss: 1.2819 - val_accuracy: 0.4123

Epoch 01478: val_loss did not improve from 1.26784
Epoch 1479/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4248 - val_loss: 1.2767 - val_accuracy: 0.4059

Epoch 01479: val_loss did not improve from 1.26784
Epoch 1480/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4213 - val_loss: 1.2696 - val_accuracy: 0.4219

Epoch 01480: val_loss did not improve from 1.26784
Epoch 1481/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4199 - val_loss: 1.2724 - val_accuracy: 0.4131

Epoch 01481: val_loss did not improve from 1.26784
Epoch 1482/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4215 - val_loss: 1.2829 - val_accuracy: 0.4107

Epoch 01482: val_loss did not improve from 1.26784
Epoch 1483/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4233 - val_loss: 1.2753 - val_accuracy: 0.4099

Epoch 01483: val_loss did not improve from 1.26784
Epoch 1484/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4229 - val_loss: 1.2690 - val_accuracy: 0.4171

Epoch 01484: val_loss did not improve from 1.26784
Epoch 1485/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4223 - val_loss: 1.2690 - val_accuracy: 0.4211

Epoch 01485: val_loss did not improve from 1.26784
Epoch 1486/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4215 - val_loss: 1.2711 - val_accuracy: 0.4131

Epoch 01486: val_loss did not improve from 1.26784
Epoch 1487/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4243 - val_loss: 1.2779 - val_accuracy: 0.4107

Epoch 01487: val_loss did not improve from 1.26784
Epoch 1488/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4229 - val_loss: 1.2738 - val_accuracy: 0.4171

Epoch 01488: val_loss did not improve from 1.26784
Epoch 1489/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4249 - val_loss: 1.2699 - val_accuracy: 0.4083

Epoch 01489: val_loss did not improve from 1.26784
Epoch 1490/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4232 - val_loss: 1.2925 - val_accuracy: 0.4083

Epoch 01490: val_loss did not improve from 1.26784
Epoch 1491/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4229 - val_loss: 1.2732 - val_accuracy: 0.4139

Epoch 01491: val_loss did not improve from 1.26784
Epoch 1492/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4231 - val_loss: 1.2701 - val_accuracy: 0.4187

Epoch 01492: val_loss did not improve from 1.26784
Epoch 1493/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4266 - val_loss: 1.2707 - val_accuracy: 0.4147

Epoch 01493: val_loss did not improve from 1.26784
Epoch 1494/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4228 - val_loss: 1.2744 - val_accuracy: 0.4059

Epoch 01494: val_loss did not improve from 1.26784
Epoch 1495/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4222 - val_loss: 1.2725 - val_accuracy: 0.4147

Epoch 01495: val_loss did not improve from 1.26784
Epoch 1496/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4226 - val_loss: 1.2716 - val_accuracy: 0.4075

Epoch 01496: val_loss did not improve from 1.26784
Epoch 1497/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4211 - val_loss: 1.2726 - val_accuracy: 0.4123

Epoch 01497: val_loss did not improve from 1.26784
Epoch 1498/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4259 - val_loss: 1.2715 - val_accuracy: 0.4171

Epoch 01498: val_loss did not improve from 1.26784
Epoch 1499/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4264 - val_loss: 1.2677 - val_accuracy: 0.4282

Epoch 01499: val_loss improved from 1.26784 to 1.26771, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1500/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4210 - val_loss: 1.2876 - val_accuracy: 0.4123

Epoch 01500: val_loss did not improve from 1.26771
Epoch 1501/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4240 - val_loss: 1.2724 - val_accuracy: 0.4107

Epoch 01501: val_loss did not improve from 1.26771
Epoch 1502/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4202 - val_loss: 1.2717 - val_accuracy: 0.4075

Epoch 01502: val_loss did not improve from 1.26771
Epoch 1503/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4228 - val_loss: 1.2692 - val_accuracy: 0.4234

Epoch 01503: val_loss did not improve from 1.26771
Epoch 1504/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4215 - val_loss: 1.2785 - val_accuracy: 0.4091

Epoch 01504: val_loss did not improve from 1.26771
Epoch 1505/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4219 - val_loss: 1.2761 - val_accuracy: 0.4027

Epoch 01505: val_loss did not improve from 1.26771
Epoch 1506/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4260 - val_loss: 1.2812 - val_accuracy: 0.4107

Epoch 01506: val_loss did not improve from 1.26771
Epoch 1507/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4284 - val_loss: 1.2707 - val_accuracy: 0.4155

Epoch 01507: val_loss did not improve from 1.26771
Epoch 1508/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4267 - val_loss: 1.2727 - val_accuracy: 0.4099

Epoch 01508: val_loss did not improve from 1.26771
Epoch 1509/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4228 - val_loss: 1.2701 - val_accuracy: 0.4163

Epoch 01509: val_loss did not improve from 1.26771
Epoch 1510/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4236 - val_loss: 1.2721 - val_accuracy: 0.4171

Epoch 01510: val_loss did not improve from 1.26771
Epoch 1511/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4227 - val_loss: 1.2993 - val_accuracy: 0.4067

Epoch 01511: val_loss did not improve from 1.26771
Epoch 1512/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4233 - val_loss: 1.2694 - val_accuracy: 0.4155

Epoch 01512: val_loss did not improve from 1.26771
Epoch 1513/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4187 - val_loss: 1.2731 - val_accuracy: 0.4123

Epoch 01513: val_loss did not improve from 1.26771
Epoch 1514/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4218 - val_loss: 1.2716 - val_accuracy: 0.4147

Epoch 01514: val_loss did not improve from 1.26771
Epoch 1515/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4220 - val_loss: 1.2814 - val_accuracy: 0.4051

Epoch 01515: val_loss did not improve from 1.26771
Epoch 1516/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4204 - val_loss: 1.2753 - val_accuracy: 0.4139

Epoch 01516: val_loss did not improve from 1.26771
Epoch 1517/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4247 - val_loss: 1.2716 - val_accuracy: 0.4115

Epoch 01517: val_loss did not improve from 1.26771
Epoch 1518/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4260 - val_loss: 1.2696 - val_accuracy: 0.4155

Epoch 01518: val_loss did not improve from 1.26771
Epoch 1519/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4257 - val_loss: 1.2714 - val_accuracy: 0.4027

Epoch 01519: val_loss did not improve from 1.26771
Epoch 1520/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4206 - val_loss: 1.2722 - val_accuracy: 0.4107

Epoch 01520: val_loss did not improve from 1.26771
Epoch 1521/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4244 - val_loss: 1.2874 - val_accuracy: 0.4107

Epoch 01521: val_loss did not improve from 1.26771
Epoch 1522/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4269 - val_loss: 1.2724 - val_accuracy: 0.4075

Epoch 01522: val_loss did not improve from 1.26771
Epoch 1523/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4246 - val_loss: 1.2713 - val_accuracy: 0.4171

Epoch 01523: val_loss did not improve from 1.26771
Epoch 1524/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4208 - val_loss: 1.2690 - val_accuracy: 0.4123

Epoch 01524: val_loss did not improve from 1.26771
Epoch 1525/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4249 - val_loss: 1.2712 - val_accuracy: 0.4123

Epoch 01525: val_loss did not improve from 1.26771
Epoch 1526/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4248 - val_loss: 1.2755 - val_accuracy: 0.4083

Epoch 01526: val_loss did not improve from 1.26771
Epoch 1527/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4237 - val_loss: 1.2689 - val_accuracy: 0.4123

Epoch 01527: val_loss did not improve from 1.26771
Epoch 1528/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4219 - val_loss: 1.2759 - val_accuracy: 0.4035

Epoch 01528: val_loss did not improve from 1.26771
Epoch 1529/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4241 - val_loss: 1.2697 - val_accuracy: 0.4163

Epoch 01529: val_loss did not improve from 1.26771
Epoch 1530/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4230 - val_loss: 1.2723 - val_accuracy: 0.4147

Epoch 01530: val_loss did not improve from 1.26771
Epoch 1531/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4224 - val_loss: 1.2716 - val_accuracy: 0.4083

Epoch 01531: val_loss did not improve from 1.26771
Epoch 1532/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4249 - val_loss: 1.2696 - val_accuracy: 0.4187

Epoch 01532: val_loss did not improve from 1.26771
Epoch 1533/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4223 - val_loss: 1.2726 - val_accuracy: 0.4043

Epoch 01533: val_loss did not improve from 1.26771
Epoch 1534/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4249 - val_loss: 1.2743 - val_accuracy: 0.4171

Epoch 01534: val_loss did not improve from 1.26771
Epoch 1535/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4221 - val_loss: 1.2743 - val_accuracy: 0.4147

Epoch 01535: val_loss did not improve from 1.26771
Epoch 1536/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4241 - val_loss: 1.2796 - val_accuracy: 0.4139

Epoch 01536: val_loss did not improve from 1.26771
Epoch 1537/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4253 - val_loss: 1.2697 - val_accuracy: 0.4099

Epoch 01537: val_loss did not improve from 1.26771
Epoch 1538/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4246 - val_loss: 1.2705 - val_accuracy: 0.4075

Epoch 01538: val_loss did not improve from 1.26771
Epoch 1539/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4220 - val_loss: 1.2702 - val_accuracy: 0.4187

Epoch 01539: val_loss did not improve from 1.26771
Epoch 1540/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4233 - val_loss: 1.2713 - val_accuracy: 0.4147

Epoch 01540: val_loss did not improve from 1.26771
Epoch 1541/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4228 - val_loss: 1.2715 - val_accuracy: 0.4139

Epoch 01541: val_loss did not improve from 1.26771
Epoch 1542/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4223 - val_loss: 1.2841 - val_accuracy: 0.4091

Epoch 01542: val_loss did not improve from 1.26771
Epoch 1543/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4257 - val_loss: 1.2692 - val_accuracy: 0.4171

Epoch 01543: val_loss did not improve from 1.26771
Epoch 1544/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4251 - val_loss: 1.2684 - val_accuracy: 0.4155

Epoch 01544: val_loss did not improve from 1.26771
Epoch 1545/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4252 - val_loss: 1.2811 - val_accuracy: 0.4123

Epoch 01545: val_loss did not improve from 1.26771
Epoch 1546/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4242 - val_loss: 1.2698 - val_accuracy: 0.4083

Epoch 01546: val_loss did not improve from 1.26771
Epoch 1547/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4241 - val_loss: 1.2733 - val_accuracy: 0.4115

Epoch 01547: val_loss did not improve from 1.26771
Epoch 1548/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4185 - val_loss: 1.2669 - val_accuracy: 0.4226

Epoch 01548: val_loss improved from 1.26771 to 1.26685, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1549/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4232 - val_loss: 1.2727 - val_accuracy: 0.4139

Epoch 01549: val_loss did not improve from 1.26685
Epoch 1550/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4171 - val_loss: 1.2709 - val_accuracy: 0.4131

Epoch 01550: val_loss did not improve from 1.26685
Epoch 1551/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4195 - val_loss: 1.2760 - val_accuracy: 0.4131

Epoch 01551: val_loss did not improve from 1.26685
Epoch 1552/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4189 - val_loss: 1.2742 - val_accuracy: 0.4067

Epoch 01552: val_loss did not improve from 1.26685
Epoch 1553/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4235 - val_loss: 1.2679 - val_accuracy: 0.4187

Epoch 01553: val_loss did not improve from 1.26685
Epoch 1554/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4253 - val_loss: 1.2695 - val_accuracy: 0.4282

Epoch 01554: val_loss did not improve from 1.26685
Epoch 1555/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4247 - val_loss: 1.2693 - val_accuracy: 0.4155

Epoch 01555: val_loss did not improve from 1.26685
Epoch 1556/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4202 - val_loss: 1.2783 - val_accuracy: 0.3979

Epoch 01556: val_loss did not improve from 1.26685
Epoch 1557/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4253 - val_loss: 1.2693 - val_accuracy: 0.4187

Epoch 01557: val_loss did not improve from 1.26685
Epoch 1558/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4239 - val_loss: 1.2679 - val_accuracy: 0.4242

Epoch 01558: val_loss did not improve from 1.26685
Epoch 1559/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4231 - val_loss: 1.2741 - val_accuracy: 0.4099

Epoch 01559: val_loss did not improve from 1.26685
Epoch 1560/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4247 - val_loss: 1.2758 - val_accuracy: 0.4083

Epoch 01560: val_loss did not improve from 1.26685
Epoch 1561/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4231 - val_loss: 1.2677 - val_accuracy: 0.4083

Epoch 01561: val_loss did not improve from 1.26685
Epoch 1562/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4236 - val_loss: 1.2812 - val_accuracy: 0.4099

Epoch 01562: val_loss did not improve from 1.26685
Epoch 1563/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4237 - val_loss: 1.2681 - val_accuracy: 0.4226

Epoch 01563: val_loss did not improve from 1.26685
Epoch 1564/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4210 - val_loss: 1.2781 - val_accuracy: 0.4083

Epoch 01564: val_loss did not improve from 1.26685
Epoch 1565/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4175 - val_loss: 1.2694 - val_accuracy: 0.4163

Epoch 01565: val_loss did not improve from 1.26685
Epoch 1566/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4233 - val_loss: 1.2676 - val_accuracy: 0.4187

Epoch 01566: val_loss did not improve from 1.26685
Epoch 1567/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4248 - val_loss: 1.2749 - val_accuracy: 0.4083

Epoch 01567: val_loss did not improve from 1.26685
Epoch 1568/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4226 - val_loss: 1.2690 - val_accuracy: 0.4155

Epoch 01568: val_loss did not improve from 1.26685
Epoch 1569/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4262 - val_loss: 1.2846 - val_accuracy: 0.4075

Epoch 01569: val_loss did not improve from 1.26685
Epoch 1570/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4210 - val_loss: 1.2758 - val_accuracy: 0.4123

Epoch 01570: val_loss did not improve from 1.26685
Epoch 1571/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4231 - val_loss: 1.2671 - val_accuracy: 0.4171

Epoch 01571: val_loss did not improve from 1.26685
Epoch 1572/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4272 - val_loss: 1.2680 - val_accuracy: 0.4274

Epoch 01572: val_loss did not improve from 1.26685
Epoch 1573/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4228 - val_loss: 1.2739 - val_accuracy: 0.4091

Epoch 01573: val_loss did not improve from 1.26685
Epoch 1574/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4180 - val_loss: 1.2685 - val_accuracy: 0.4171

Epoch 01574: val_loss did not improve from 1.26685
Epoch 1575/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4241 - val_loss: 1.2716 - val_accuracy: 0.4083

Epoch 01575: val_loss did not improve from 1.26685
Epoch 1576/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4208 - val_loss: 1.2678 - val_accuracy: 0.4139

Epoch 01576: val_loss did not improve from 1.26685
Epoch 1577/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4243 - val_loss: 1.2735 - val_accuracy: 0.4019

Epoch 01577: val_loss did not improve from 1.26685
Epoch 1578/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4258 - val_loss: 1.2704 - val_accuracy: 0.4147

Epoch 01578: val_loss did not improve from 1.26685
Epoch 1579/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4260 - val_loss: 1.2698 - val_accuracy: 0.4051

Epoch 01579: val_loss did not improve from 1.26685
Epoch 1580/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4217 - val_loss: 1.2681 - val_accuracy: 0.4171

Epoch 01580: val_loss did not improve from 1.26685
Epoch 1581/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4241 - val_loss: 1.2847 - val_accuracy: 0.4035

Epoch 01581: val_loss did not improve from 1.26685
Epoch 1582/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4228 - val_loss: 1.2687 - val_accuracy: 0.4139

Epoch 01582: val_loss did not improve from 1.26685
Epoch 1583/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4283 - val_loss: 1.2702 - val_accuracy: 0.4099

Epoch 01583: val_loss did not improve from 1.26685
Epoch 1584/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4251 - val_loss: 1.2692 - val_accuracy: 0.4043

Epoch 01584: val_loss did not improve from 1.26685
Epoch 1585/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4226 - val_loss: 1.2722 - val_accuracy: 0.4155

Epoch 01585: val_loss did not improve from 1.26685
Epoch 1586/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4202 - val_loss: 1.2734 - val_accuracy: 0.4107

Epoch 01586: val_loss did not improve from 1.26685
Epoch 1587/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4289 - val_loss: 1.2843 - val_accuracy: 0.4083

Epoch 01587: val_loss did not improve from 1.26685
Epoch 1588/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4234 - val_loss: 1.2691 - val_accuracy: 0.4226

Epoch 01588: val_loss did not improve from 1.26685
Epoch 1589/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4207 - val_loss: 1.2656 - val_accuracy: 0.4203

Epoch 01589: val_loss improved from 1.26685 to 1.26562, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1590/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4228 - val_loss: 1.2732 - val_accuracy: 0.4091

Epoch 01590: val_loss did not improve from 1.26562
Epoch 1591/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4239 - val_loss: 1.2675 - val_accuracy: 0.4187

Epoch 01591: val_loss did not improve from 1.26562
Epoch 1592/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4196 - val_loss: 1.2797 - val_accuracy: 0.4075

Epoch 01592: val_loss did not improve from 1.26562
Epoch 1593/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4251 - val_loss: 1.2693 - val_accuracy: 0.4187

Epoch 01593: val_loss did not improve from 1.26562
Epoch 1594/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4265 - val_loss: 1.2695 - val_accuracy: 0.4091

Epoch 01594: val_loss did not improve from 1.26562
Epoch 1595/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4210 - val_loss: 1.2793 - val_accuracy: 0.4059

Epoch 01595: val_loss did not improve from 1.26562
Epoch 1596/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4254 - val_loss: 1.2685 - val_accuracy: 0.4099

Epoch 01596: val_loss did not improve from 1.26562
Epoch 1597/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4246 - val_loss: 1.2716 - val_accuracy: 0.4091

Epoch 01597: val_loss did not improve from 1.26562
Epoch 1598/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4270 - val_loss: 1.2657 - val_accuracy: 0.4131

Epoch 01598: val_loss did not improve from 1.26562
Epoch 1599/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4221 - val_loss: 1.2769 - val_accuracy: 0.4083

Epoch 01599: val_loss did not improve from 1.26562
Epoch 1600/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4239 - val_loss: 1.2751 - val_accuracy: 0.4043

Epoch 01600: val_loss did not improve from 1.26562
Epoch 1601/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4222 - val_loss: 1.2687 - val_accuracy: 0.4139

Epoch 01601: val_loss did not improve from 1.26562
Epoch 1602/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4247 - val_loss: 1.2789 - val_accuracy: 0.4027

Epoch 01602: val_loss did not improve from 1.26562
Epoch 1603/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4218 - val_loss: 1.2662 - val_accuracy: 0.4187

Epoch 01603: val_loss did not improve from 1.26562
Epoch 1604/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4224 - val_loss: 1.2688 - val_accuracy: 0.4163

Epoch 01604: val_loss did not improve from 1.26562
Epoch 1605/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4257 - val_loss: 1.2707 - val_accuracy: 0.4171

Epoch 01605: val_loss did not improve from 1.26562
Epoch 1606/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4256 - val_loss: 1.2699 - val_accuracy: 0.4163

Epoch 01606: val_loss did not improve from 1.26562
Epoch 1607/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4252 - val_loss: 1.2684 - val_accuracy: 0.4083

Epoch 01607: val_loss did not improve from 1.26562
Epoch 1608/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4256 - val_loss: 1.2667 - val_accuracy: 0.4179

Epoch 01608: val_loss did not improve from 1.26562
Epoch 1609/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4260 - val_loss: 1.2681 - val_accuracy: 0.4171

Epoch 01609: val_loss did not improve from 1.26562
Epoch 1610/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4283 - val_loss: 1.2789 - val_accuracy: 0.4115

Epoch 01610: val_loss did not improve from 1.26562
Epoch 1611/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4283 - val_loss: 1.2686 - val_accuracy: 0.4115

Epoch 01611: val_loss did not improve from 1.26562
Epoch 1612/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4240 - val_loss: 1.2713 - val_accuracy: 0.4075

Epoch 01612: val_loss did not improve from 1.26562
Epoch 1613/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4215 - val_loss: 1.2684 - val_accuracy: 0.4179

Epoch 01613: val_loss did not improve from 1.26562
Epoch 1614/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4239 - val_loss: 1.2672 - val_accuracy: 0.4195

Epoch 01614: val_loss did not improve from 1.26562
Epoch 1615/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4167 - val_loss: 1.2890 - val_accuracy: 0.4003

Epoch 01615: val_loss did not improve from 1.26562
Epoch 1616/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4221 - val_loss: 1.2766 - val_accuracy: 0.4099

Epoch 01616: val_loss did not improve from 1.26562
Epoch 1617/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4238 - val_loss: 1.2678 - val_accuracy: 0.4290

Epoch 01617: val_loss did not improve from 1.26562
Epoch 1618/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4216 - val_loss: 1.2705 - val_accuracy: 0.4091

Epoch 01618: val_loss did not improve from 1.26562
Epoch 1619/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4249 - val_loss: 1.2685 - val_accuracy: 0.4131

Epoch 01619: val_loss did not improve from 1.26562
Epoch 1620/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4236 - val_loss: 1.2677 - val_accuracy: 0.4155

Epoch 01620: val_loss did not improve from 1.26562
Epoch 1621/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4210 - val_loss: 1.2769 - val_accuracy: 0.4107

Epoch 01621: val_loss did not improve from 1.26562
Epoch 1622/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4240 - val_loss: 1.2677 - val_accuracy: 0.4147

Epoch 01622: val_loss did not improve from 1.26562
Epoch 1623/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4233 - val_loss: 1.2662 - val_accuracy: 0.4306

Epoch 01623: val_loss did not improve from 1.26562
Epoch 1624/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4233 - val_loss: 1.2684 - val_accuracy: 0.4179

Epoch 01624: val_loss did not improve from 1.26562
Epoch 1625/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4243 - val_loss: 1.2766 - val_accuracy: 0.4123

Epoch 01625: val_loss did not improve from 1.26562
Epoch 1626/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4288 - val_loss: 1.2664 - val_accuracy: 0.4242

Epoch 01626: val_loss did not improve from 1.26562
Epoch 1627/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4289 - val_loss: 1.2727 - val_accuracy: 0.4091

Epoch 01627: val_loss did not improve from 1.26562
Epoch 1628/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4249 - val_loss: 1.2675 - val_accuracy: 0.4115

Epoch 01628: val_loss did not improve from 1.26562
Epoch 1629/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4255 - val_loss: 1.2687 - val_accuracy: 0.4115

Epoch 01629: val_loss did not improve from 1.26562
Epoch 1630/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4239 - val_loss: 1.2688 - val_accuracy: 0.4155

Epoch 01630: val_loss did not improve from 1.26562
Epoch 1631/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4260 - val_loss: 1.2709 - val_accuracy: 0.4123

Epoch 01631: val_loss did not improve from 1.26562
Epoch 1632/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4241 - val_loss: 1.2668 - val_accuracy: 0.4219

Epoch 01632: val_loss did not improve from 1.26562
Epoch 1633/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4241 - val_loss: 1.2683 - val_accuracy: 0.4131

Epoch 01633: val_loss did not improve from 1.26562
Epoch 1634/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4216 - val_loss: 1.2732 - val_accuracy: 0.4123

Epoch 01634: val_loss did not improve from 1.26562
Epoch 1635/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4226 - val_loss: 1.2724 - val_accuracy: 0.4139

Epoch 01635: val_loss did not improve from 1.26562
Epoch 1636/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4227 - val_loss: 1.2722 - val_accuracy: 0.4059

Epoch 01636: val_loss did not improve from 1.26562
Epoch 1637/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4238 - val_loss: 1.2675 - val_accuracy: 0.4298

Epoch 01637: val_loss did not improve from 1.26562
Epoch 1638/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4251 - val_loss: 1.2681 - val_accuracy: 0.4171

Epoch 01638: val_loss did not improve from 1.26562
Epoch 1639/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4280 - val_loss: 1.2653 - val_accuracy: 0.4195

Epoch 01639: val_loss improved from 1.26562 to 1.26534, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1640/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4308 - val_loss: 1.2672 - val_accuracy: 0.4179

Epoch 01640: val_loss did not improve from 1.26534
Epoch 1641/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4265 - val_loss: 1.2852 - val_accuracy: 0.3939

Epoch 01641: val_loss did not improve from 1.26534
Epoch 1642/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4208 - val_loss: 1.2664 - val_accuracy: 0.4179

Epoch 01642: val_loss did not improve from 1.26534
Epoch 1643/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4275 - val_loss: 1.2658 - val_accuracy: 0.4123

Epoch 01643: val_loss did not improve from 1.26534
Epoch 1644/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4266 - val_loss: 1.2707 - val_accuracy: 0.4091

Epoch 01644: val_loss did not improve from 1.26534
Epoch 1645/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4220 - val_loss: 1.2725 - val_accuracy: 0.4091

Epoch 01645: val_loss did not improve from 1.26534
Epoch 1646/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4262 - val_loss: 1.2670 - val_accuracy: 0.4195

Epoch 01646: val_loss did not improve from 1.26534
Epoch 1647/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4260 - val_loss: 1.2684 - val_accuracy: 0.4091

Epoch 01647: val_loss did not improve from 1.26534
Epoch 1648/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4211 - val_loss: 1.2715 - val_accuracy: 0.4067

Epoch 01648: val_loss did not improve from 1.26534
Epoch 1649/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4241 - val_loss: 1.2683 - val_accuracy: 0.4131

Epoch 01649: val_loss did not improve from 1.26534
Epoch 1650/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4251 - val_loss: 1.2682 - val_accuracy: 0.4155

Epoch 01650: val_loss did not improve from 1.26534
Epoch 1651/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4276 - val_loss: 1.2784 - val_accuracy: 0.4011

Epoch 01651: val_loss did not improve from 1.26534
Epoch 1652/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4220 - val_loss: 1.2751 - val_accuracy: 0.3995

Epoch 01652: val_loss did not improve from 1.26534
Epoch 1653/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4256 - val_loss: 1.2662 - val_accuracy: 0.4346

Epoch 01653: val_loss did not improve from 1.26534
Epoch 1654/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4249 - val_loss: 1.2719 - val_accuracy: 0.4179

Epoch 01654: val_loss did not improve from 1.26534
Epoch 1655/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4258 - val_loss: 1.2672 - val_accuracy: 0.4226

Epoch 01655: val_loss did not improve from 1.26534
Epoch 1656/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4226 - val_loss: 1.2723 - val_accuracy: 0.4147

Epoch 01656: val_loss did not improve from 1.26534
Epoch 1657/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4268 - val_loss: 1.2760 - val_accuracy: 0.4091

Epoch 01657: val_loss did not improve from 1.26534
Epoch 1658/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4281 - val_loss: 1.2674 - val_accuracy: 0.4179

Epoch 01658: val_loss did not improve from 1.26534
Epoch 1659/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4234 - val_loss: 1.2705 - val_accuracy: 0.4179

Epoch 01659: val_loss did not improve from 1.26534
Epoch 1660/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4209 - val_loss: 1.2702 - val_accuracy: 0.4115

Epoch 01660: val_loss did not improve from 1.26534
Epoch 1661/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4238 - val_loss: 1.2727 - val_accuracy: 0.4123

Epoch 01661: val_loss did not improve from 1.26534
Epoch 1662/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4249 - val_loss: 1.2702 - val_accuracy: 0.4163

Epoch 01662: val_loss did not improve from 1.26534
Epoch 1663/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4206 - val_loss: 1.2747 - val_accuracy: 0.4027

Epoch 01663: val_loss did not improve from 1.26534
Epoch 1664/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4234 - val_loss: 1.2695 - val_accuracy: 0.4115

Epoch 01664: val_loss did not improve from 1.26534
Epoch 1665/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4272 - val_loss: 1.2743 - val_accuracy: 0.4099

Epoch 01665: val_loss did not improve from 1.26534
Epoch 1666/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4244 - val_loss: 1.2797 - val_accuracy: 0.4107

Epoch 01666: val_loss did not improve from 1.26534
Epoch 1667/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4241 - val_loss: 1.2691 - val_accuracy: 0.4179

Epoch 01667: val_loss did not improve from 1.26534
Epoch 1668/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4259 - val_loss: 1.2669 - val_accuracy: 0.4083

Epoch 01668: val_loss did not improve from 1.26534
Epoch 1669/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4223 - val_loss: 1.2671 - val_accuracy: 0.4187

Epoch 01669: val_loss did not improve from 1.26534
Epoch 1670/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4279 - val_loss: 1.2743 - val_accuracy: 0.4091

Epoch 01670: val_loss did not improve from 1.26534
Epoch 1671/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4265 - val_loss: 1.2724 - val_accuracy: 0.4083

Epoch 01671: val_loss did not improve from 1.26534
Epoch 1672/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4195 - val_loss: 1.2685 - val_accuracy: 0.4226

Epoch 01672: val_loss did not improve from 1.26534
Epoch 1673/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4242 - val_loss: 1.2690 - val_accuracy: 0.4115

Epoch 01673: val_loss did not improve from 1.26534
Epoch 1674/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4203 - val_loss: 1.2696 - val_accuracy: 0.4123

Epoch 01674: val_loss did not improve from 1.26534
Epoch 1675/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4269 - val_loss: 1.2659 - val_accuracy: 0.4179

Epoch 01675: val_loss did not improve from 1.26534
Epoch 1676/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4291 - val_loss: 1.2751 - val_accuracy: 0.4099

Epoch 01676: val_loss did not improve from 1.26534
Epoch 1677/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4218 - val_loss: 1.2729 - val_accuracy: 0.4099

Epoch 01677: val_loss did not improve from 1.26534
Epoch 1678/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4255 - val_loss: 1.2697 - val_accuracy: 0.4187

Epoch 01678: val_loss did not improve from 1.26534
Epoch 1679/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4229 - val_loss: 1.2720 - val_accuracy: 0.4091

Epoch 01679: val_loss did not improve from 1.26534
Epoch 1680/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4248 - val_loss: 1.2693 - val_accuracy: 0.4219

Epoch 01680: val_loss did not improve from 1.26534
Epoch 1681/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4231 - val_loss: 1.2726 - val_accuracy: 0.4131

Epoch 01681: val_loss did not improve from 1.26534
Epoch 1682/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4289 - val_loss: 1.2707 - val_accuracy: 0.4211

Epoch 01682: val_loss did not improve from 1.26534
Epoch 1683/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4299 - val_loss: 1.2685 - val_accuracy: 0.4131

Epoch 01683: val_loss did not improve from 1.26534
Epoch 1684/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4250 - val_loss: 1.2714 - val_accuracy: 0.4083

Epoch 01684: val_loss did not improve from 1.26534
Epoch 1685/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4265 - val_loss: 1.2725 - val_accuracy: 0.4099

Epoch 01685: val_loss did not improve from 1.26534
Epoch 1686/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4243 - val_loss: 1.2649 - val_accuracy: 0.4203

Epoch 01686: val_loss improved from 1.26534 to 1.26485, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1687/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4271 - val_loss: 1.2692 - val_accuracy: 0.4187

Epoch 01687: val_loss did not improve from 1.26485
Epoch 1688/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4233 - val_loss: 1.2686 - val_accuracy: 0.4083

Epoch 01688: val_loss did not improve from 1.26485
Epoch 1689/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4253 - val_loss: 1.2736 - val_accuracy: 0.4107

Epoch 01689: val_loss did not improve from 1.26485
Epoch 1690/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4281 - val_loss: 1.2722 - val_accuracy: 0.4091

Epoch 01690: val_loss did not improve from 1.26485
Epoch 1691/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4262 - val_loss: 1.2709 - val_accuracy: 0.4067

Epoch 01691: val_loss did not improve from 1.26485
Epoch 1692/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4215 - val_loss: 1.2707 - val_accuracy: 0.4059

Epoch 01692: val_loss did not improve from 1.26485
Epoch 1693/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4272 - val_loss: 1.2689 - val_accuracy: 0.4067

Epoch 01693: val_loss did not improve from 1.26485
Epoch 1694/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4291 - val_loss: 1.2700 - val_accuracy: 0.4139

Epoch 01694: val_loss did not improve from 1.26485
Epoch 1695/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4242 - val_loss: 1.2686 - val_accuracy: 0.4163

Epoch 01695: val_loss did not improve from 1.26485
Epoch 1696/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4239 - val_loss: 1.2685 - val_accuracy: 0.4211

Epoch 01696: val_loss did not improve from 1.26485
Epoch 1697/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4240 - val_loss: 1.2794 - val_accuracy: 0.4083

Epoch 01697: val_loss did not improve from 1.26485
Epoch 1698/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4252 - val_loss: 1.2729 - val_accuracy: 0.4147

Epoch 01698: val_loss did not improve from 1.26485
Epoch 1699/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4203 - val_loss: 1.2682 - val_accuracy: 0.4250

Epoch 01699: val_loss did not improve from 1.26485
Epoch 1700/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4228 - val_loss: 1.2690 - val_accuracy: 0.4163

Epoch 01700: val_loss did not improve from 1.26485
Epoch 1701/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4228 - val_loss: 1.2670 - val_accuracy: 0.4203

Epoch 01701: val_loss did not improve from 1.26485
Epoch 1702/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4256 - val_loss: 1.2688 - val_accuracy: 0.4195

Epoch 01702: val_loss did not improve from 1.26485
Epoch 1703/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4256 - val_loss: 1.2784 - val_accuracy: 0.4051

Epoch 01703: val_loss did not improve from 1.26485
Epoch 1704/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4240 - val_loss: 1.2682 - val_accuracy: 0.4147

Epoch 01704: val_loss did not improve from 1.26485
Epoch 1705/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4269 - val_loss: 1.2693 - val_accuracy: 0.4163

Epoch 01705: val_loss did not improve from 1.26485
Epoch 1706/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4251 - val_loss: 1.2674 - val_accuracy: 0.4187

Epoch 01706: val_loss did not improve from 1.26485
Epoch 1707/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4200 - val_loss: 1.2668 - val_accuracy: 0.4115

Epoch 01707: val_loss did not improve from 1.26485
Epoch 1708/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4246 - val_loss: 1.2680 - val_accuracy: 0.4123

Epoch 01708: val_loss did not improve from 1.26485
Epoch 1709/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4264 - val_loss: 1.2688 - val_accuracy: 0.4179

Epoch 01709: val_loss did not improve from 1.26485
Epoch 1710/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4284 - val_loss: 1.2785 - val_accuracy: 0.4075

Epoch 01710: val_loss did not improve from 1.26485
Epoch 1711/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4260 - val_loss: 1.2668 - val_accuracy: 0.4115

Epoch 01711: val_loss did not improve from 1.26485
Epoch 1712/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4280 - val_loss: 1.2695 - val_accuracy: 0.4107

Epoch 01712: val_loss did not improve from 1.26485
Epoch 1713/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4246 - val_loss: 1.2667 - val_accuracy: 0.4155

Epoch 01713: val_loss did not improve from 1.26485
Epoch 1714/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4277 - val_loss: 1.2691 - val_accuracy: 0.4131

Epoch 01714: val_loss did not improve from 1.26485
Epoch 1715/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4240 - val_loss: 1.2668 - val_accuracy: 0.4115

Epoch 01715: val_loss did not improve from 1.26485
Epoch 1716/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4255 - val_loss: 1.2711 - val_accuracy: 0.4123

Epoch 01716: val_loss did not improve from 1.26485
Epoch 1717/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4227 - val_loss: 1.2682 - val_accuracy: 0.4155

Epoch 01717: val_loss did not improve from 1.26485
Epoch 1718/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4259 - val_loss: 1.2728 - val_accuracy: 0.4099

Epoch 01718: val_loss did not improve from 1.26485
Epoch 1719/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4255 - val_loss: 1.2671 - val_accuracy: 0.4171

Epoch 01719: val_loss did not improve from 1.26485
Epoch 1720/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4227 - val_loss: 1.2650 - val_accuracy: 0.4179

Epoch 01720: val_loss did not improve from 1.26485
Epoch 1721/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4303 - val_loss: 1.2655 - val_accuracy: 0.4131

Epoch 01721: val_loss did not improve from 1.26485
Epoch 1722/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4262 - val_loss: 1.2652 - val_accuracy: 0.4266

Epoch 01722: val_loss did not improve from 1.26485
Epoch 1723/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4262 - val_loss: 1.2663 - val_accuracy: 0.4163

Epoch 01723: val_loss did not improve from 1.26485
Epoch 1724/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4280 - val_loss: 1.2684 - val_accuracy: 0.4059

Epoch 01724: val_loss did not improve from 1.26485
Epoch 1725/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4254 - val_loss: 1.2676 - val_accuracy: 0.4107

Epoch 01725: val_loss did not improve from 1.26485
Epoch 1726/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4280 - val_loss: 1.2666 - val_accuracy: 0.4123

Epoch 01726: val_loss did not improve from 1.26485
Epoch 1727/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4287 - val_loss: 1.2649 - val_accuracy: 0.4115

Epoch 01727: val_loss did not improve from 1.26485
Epoch 1728/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4244 - val_loss: 1.2776 - val_accuracy: 0.4075

Epoch 01728: val_loss did not improve from 1.26485
Epoch 1729/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4233 - val_loss: 1.2785 - val_accuracy: 0.3939

Epoch 01729: val_loss did not improve from 1.26485
Epoch 1730/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4213 - val_loss: 1.2762 - val_accuracy: 0.4003

Epoch 01730: val_loss did not improve from 1.26485
Epoch 1731/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4264 - val_loss: 1.2710 - val_accuracy: 0.4187

Epoch 01731: val_loss did not improve from 1.26485
Epoch 1732/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4291 - val_loss: 1.2654 - val_accuracy: 0.4219

Epoch 01732: val_loss did not improve from 1.26485
Epoch 1733/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4271 - val_loss: 1.2698 - val_accuracy: 0.4099

Epoch 01733: val_loss did not improve from 1.26485
Epoch 1734/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4226 - val_loss: 1.2717 - val_accuracy: 0.4107

Epoch 01734: val_loss did not improve from 1.26485
Epoch 1735/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4274 - val_loss: 1.2723 - val_accuracy: 0.4147

Epoch 01735: val_loss did not improve from 1.26485
Epoch 1736/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4280 - val_loss: 1.2674 - val_accuracy: 0.4147

Epoch 01736: val_loss did not improve from 1.26485
Epoch 1737/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4225 - val_loss: 1.2701 - val_accuracy: 0.4107

Epoch 01737: val_loss did not improve from 1.26485
Epoch 1738/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4286 - val_loss: 1.2702 - val_accuracy: 0.4155

Epoch 01738: val_loss did not improve from 1.26485
Epoch 1739/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4273 - val_loss: 1.2667 - val_accuracy: 0.4211

Epoch 01739: val_loss did not improve from 1.26485
Epoch 1740/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4278 - val_loss: 1.2715 - val_accuracy: 0.4059

Epoch 01740: val_loss did not improve from 1.26485
Epoch 1741/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4281 - val_loss: 1.2767 - val_accuracy: 0.4115

Epoch 01741: val_loss did not improve from 1.26485
Epoch 1742/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4234 - val_loss: 1.2674 - val_accuracy: 0.4203

Epoch 01742: val_loss did not improve from 1.26485
Epoch 1743/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4282 - val_loss: 1.2660 - val_accuracy: 0.4155

Epoch 01743: val_loss did not improve from 1.26485
Epoch 1744/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4240 - val_loss: 1.2656 - val_accuracy: 0.4155

Epoch 01744: val_loss did not improve from 1.26485
Epoch 1745/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4275 - val_loss: 1.2659 - val_accuracy: 0.4234

Epoch 01745: val_loss did not improve from 1.26485
Epoch 1746/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4246 - val_loss: 1.2683 - val_accuracy: 0.4226

Epoch 01746: val_loss did not improve from 1.26485
Epoch 1747/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4251 - val_loss: 1.2692 - val_accuracy: 0.4131

Epoch 01747: val_loss did not improve from 1.26485
Epoch 1748/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4292 - val_loss: 1.2738 - val_accuracy: 0.4147

Epoch 01748: val_loss did not improve from 1.26485
Epoch 1749/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4242 - val_loss: 1.2668 - val_accuracy: 0.4131

Epoch 01749: val_loss did not improve from 1.26485
Epoch 1750/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4280 - val_loss: 1.2697 - val_accuracy: 0.4171

Epoch 01750: val_loss did not improve from 1.26485
Epoch 1751/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4280 - val_loss: 1.2705 - val_accuracy: 0.4075

Epoch 01751: val_loss did not improve from 1.26485
Epoch 1752/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4261 - val_loss: 1.2693 - val_accuracy: 0.4083

Epoch 01752: val_loss did not improve from 1.26485
Epoch 1753/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4275 - val_loss: 1.2690 - val_accuracy: 0.4147

Epoch 01753: val_loss did not improve from 1.26485
Epoch 1754/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4220 - val_loss: 1.2671 - val_accuracy: 0.4242

Epoch 01754: val_loss did not improve from 1.26485
Epoch 1755/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4235 - val_loss: 1.2668 - val_accuracy: 0.4091

Epoch 01755: val_loss did not improve from 1.26485
Epoch 1756/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4247 - val_loss: 1.2777 - val_accuracy: 0.4067

Epoch 01756: val_loss did not improve from 1.26485
Epoch 1757/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4253 - val_loss: 1.2801 - val_accuracy: 0.4131

Epoch 01757: val_loss did not improve from 1.26485
Epoch 1758/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4280 - val_loss: 1.2638 - val_accuracy: 0.4219

Epoch 01758: val_loss improved from 1.26485 to 1.26379, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1759/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4279 - val_loss: 1.2703 - val_accuracy: 0.4067

Epoch 01759: val_loss did not improve from 1.26379
Epoch 1760/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4253 - val_loss: 1.2722 - val_accuracy: 0.4075

Epoch 01760: val_loss did not improve from 1.26379
Epoch 1761/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4285 - val_loss: 1.2747 - val_accuracy: 0.4115

Epoch 01761: val_loss did not improve from 1.26379
Epoch 1762/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4295 - val_loss: 1.2686 - val_accuracy: 0.4107

Epoch 01762: val_loss did not improve from 1.26379
Epoch 1763/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4255 - val_loss: 1.2642 - val_accuracy: 0.4179

Epoch 01763: val_loss did not improve from 1.26379
Epoch 1764/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4290 - val_loss: 1.2637 - val_accuracy: 0.4290

Epoch 01764: val_loss improved from 1.26379 to 1.26368, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1765/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4287 - val_loss: 1.2722 - val_accuracy: 0.4107

Epoch 01765: val_loss did not improve from 1.26368
Epoch 1766/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4265 - val_loss: 1.2835 - val_accuracy: 0.4107

Epoch 01766: val_loss did not improve from 1.26368
Epoch 1767/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4279 - val_loss: 1.2646 - val_accuracy: 0.4139

Epoch 01767: val_loss did not improve from 1.26368
Epoch 1768/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4259 - val_loss: 1.2736 - val_accuracy: 0.4123

Epoch 01768: val_loss did not improve from 1.26368
Epoch 1769/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4280 - val_loss: 1.2670 - val_accuracy: 0.4163

Epoch 01769: val_loss did not improve from 1.26368
Epoch 1770/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4241 - val_loss: 1.2659 - val_accuracy: 0.4099

Epoch 01770: val_loss did not improve from 1.26368
Epoch 1771/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4267 - val_loss: 1.2646 - val_accuracy: 0.4187

Epoch 01771: val_loss did not improve from 1.26368
Epoch 1772/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4309 - val_loss: 1.2660 - val_accuracy: 0.4139

Epoch 01772: val_loss did not improve from 1.26368
Epoch 1773/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4296 - val_loss: 1.2682 - val_accuracy: 0.4115

Epoch 01773: val_loss did not improve from 1.26368
Epoch 1774/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4326 - val_loss: 1.2740 - val_accuracy: 0.4107

Epoch 01774: val_loss did not improve from 1.26368
Epoch 1775/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4293 - val_loss: 1.2735 - val_accuracy: 0.4139

Epoch 01775: val_loss did not improve from 1.26368
Epoch 1776/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4248 - val_loss: 1.2673 - val_accuracy: 0.4163

Epoch 01776: val_loss did not improve from 1.26368
Epoch 1777/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4241 - val_loss: 1.2782 - val_accuracy: 0.4019

Epoch 01777: val_loss did not improve from 1.26368
Epoch 1778/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4287 - val_loss: 1.2720 - val_accuracy: 0.4147

Epoch 01778: val_loss did not improve from 1.26368
Epoch 1779/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4278 - val_loss: 1.2665 - val_accuracy: 0.4203

Epoch 01779: val_loss did not improve from 1.26368
Epoch 1780/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4270 - val_loss: 1.2656 - val_accuracy: 0.4179

Epoch 01780: val_loss did not improve from 1.26368
Epoch 1781/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4291 - val_loss: 1.2643 - val_accuracy: 0.4195

Epoch 01781: val_loss did not improve from 1.26368
Epoch 1782/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4302 - val_loss: 1.2644 - val_accuracy: 0.4258

Epoch 01782: val_loss did not improve from 1.26368
Epoch 1783/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4272 - val_loss: 1.2766 - val_accuracy: 0.4083

Epoch 01783: val_loss did not improve from 1.26368
Epoch 1784/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4264 - val_loss: 1.2669 - val_accuracy: 0.4203

Epoch 01784: val_loss did not improve from 1.26368
Epoch 1785/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4288 - val_loss: 1.2630 - val_accuracy: 0.4242

Epoch 01785: val_loss improved from 1.26368 to 1.26299, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1786/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4284 - val_loss: 1.2771 - val_accuracy: 0.4155

Epoch 01786: val_loss did not improve from 1.26299
Epoch 1787/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4269 - val_loss: 1.2725 - val_accuracy: 0.4051

Epoch 01787: val_loss did not improve from 1.26299
Epoch 1788/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4287 - val_loss: 1.2645 - val_accuracy: 0.4195

Epoch 01788: val_loss did not improve from 1.26299
Epoch 1789/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4326 - val_loss: 1.2648 - val_accuracy: 0.4219

Epoch 01789: val_loss did not improve from 1.26299
Epoch 1790/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4259 - val_loss: 1.2727 - val_accuracy: 0.3987

Epoch 01790: val_loss did not improve from 1.26299
Epoch 1791/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4271 - val_loss: 1.2723 - val_accuracy: 0.4115

Epoch 01791: val_loss did not improve from 1.26299
Epoch 1792/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4290 - val_loss: 1.2652 - val_accuracy: 0.4195

Epoch 01792: val_loss did not improve from 1.26299
Epoch 1793/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4250 - val_loss: 1.2641 - val_accuracy: 0.4203

Epoch 01793: val_loss did not improve from 1.26299
Epoch 1794/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4265 - val_loss: 1.2675 - val_accuracy: 0.4115

Epoch 01794: val_loss did not improve from 1.26299
Epoch 1795/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4261 - val_loss: 1.2707 - val_accuracy: 0.4067

Epoch 01795: val_loss did not improve from 1.26299
Epoch 1796/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4272 - val_loss: 1.2737 - val_accuracy: 0.4155

Epoch 01796: val_loss did not improve from 1.26299
Epoch 1797/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4237 - val_loss: 1.2651 - val_accuracy: 0.4306

Epoch 01797: val_loss did not improve from 1.26299
Epoch 1798/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4235 - val_loss: 1.2687 - val_accuracy: 0.4163

Epoch 01798: val_loss did not improve from 1.26299
Epoch 1799/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4246 - val_loss: 1.2718 - val_accuracy: 0.4059

Epoch 01799: val_loss did not improve from 1.26299
Epoch 1800/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4243 - val_loss: 1.2768 - val_accuracy: 0.4115

Epoch 01800: val_loss did not improve from 1.26299
Epoch 1801/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4284 - val_loss: 1.2702 - val_accuracy: 0.4211

Epoch 01801: val_loss did not improve from 1.26299
Epoch 1802/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4282 - val_loss: 1.2704 - val_accuracy: 0.4139

Epoch 01802: val_loss did not improve from 1.26299
Epoch 1803/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4248 - val_loss: 1.2684 - val_accuracy: 0.4147

Epoch 01803: val_loss did not improve from 1.26299
Epoch 1804/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4248 - val_loss: 1.2687 - val_accuracy: 0.4139

Epoch 01804: val_loss did not improve from 1.26299
Epoch 1805/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4223 - val_loss: 1.2655 - val_accuracy: 0.4099

Epoch 01805: val_loss did not improve from 1.26299
Epoch 1806/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4256 - val_loss: 1.2632 - val_accuracy: 0.4234

Epoch 01806: val_loss did not improve from 1.26299
Epoch 1807/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4246 - val_loss: 1.2653 - val_accuracy: 0.4171

Epoch 01807: val_loss did not improve from 1.26299
Epoch 1808/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4261 - val_loss: 1.2948 - val_accuracy: 0.4011

Epoch 01808: val_loss did not improve from 1.26299
Epoch 1809/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4176 - val_loss: 1.2661 - val_accuracy: 0.4203

Epoch 01809: val_loss did not improve from 1.26299
Epoch 1810/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4249 - val_loss: 1.2680 - val_accuracy: 0.4187

Epoch 01810: val_loss did not improve from 1.26299
Epoch 1811/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4273 - val_loss: 1.2638 - val_accuracy: 0.4179

Epoch 01811: val_loss did not improve from 1.26299
Epoch 1812/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4287 - val_loss: 1.2620 - val_accuracy: 0.4250

Epoch 01812: val_loss improved from 1.26299 to 1.26205, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1813/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4267 - val_loss: 1.2923 - val_accuracy: 0.4083

Epoch 01813: val_loss did not improve from 1.26205
Epoch 1814/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4288 - val_loss: 1.2650 - val_accuracy: 0.4203

Epoch 01814: val_loss did not improve from 1.26205
Epoch 1815/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4225 - val_loss: 1.2633 - val_accuracy: 0.4234

Epoch 01815: val_loss did not improve from 1.26205
Epoch 1816/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4273 - val_loss: 1.2693 - val_accuracy: 0.4123

Epoch 01816: val_loss did not improve from 1.26205
Epoch 1817/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4270 - val_loss: 1.2717 - val_accuracy: 0.4163

Epoch 01817: val_loss did not improve from 1.26205
Epoch 1818/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4267 - val_loss: 1.2645 - val_accuracy: 0.4107

Epoch 01818: val_loss did not improve from 1.26205
Epoch 1819/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4251 - val_loss: 1.2671 - val_accuracy: 0.4226

Epoch 01819: val_loss did not improve from 1.26205
Epoch 1820/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4299 - val_loss: 1.2654 - val_accuracy: 0.4203

Epoch 01820: val_loss did not improve from 1.26205
Epoch 1821/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4259 - val_loss: 1.2649 - val_accuracy: 0.4131

Epoch 01821: val_loss did not improve from 1.26205
Epoch 1822/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4292 - val_loss: 1.2676 - val_accuracy: 0.4059

Epoch 01822: val_loss did not improve from 1.26205
Epoch 1823/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4307 - val_loss: 1.2655 - val_accuracy: 0.4099

Epoch 01823: val_loss did not improve from 1.26205
Epoch 1824/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4276 - val_loss: 1.2671 - val_accuracy: 0.4163

Epoch 01824: val_loss did not improve from 1.26205
Epoch 1825/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4242 - val_loss: 1.2708 - val_accuracy: 0.4139

Epoch 01825: val_loss did not improve from 1.26205
Epoch 1826/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4225 - val_loss: 1.2653 - val_accuracy: 0.4234

Epoch 01826: val_loss did not improve from 1.26205
Epoch 1827/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4254 - val_loss: 1.2690 - val_accuracy: 0.4163

Epoch 01827: val_loss did not improve from 1.26205
Epoch 1828/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4247 - val_loss: 1.2693 - val_accuracy: 0.4131

Epoch 01828: val_loss did not improve from 1.26205
Epoch 1829/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4287 - val_loss: 1.2669 - val_accuracy: 0.4131

Epoch 01829: val_loss did not improve from 1.26205
Epoch 1830/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4297 - val_loss: 1.2767 - val_accuracy: 0.4099

Epoch 01830: val_loss did not improve from 1.26205
Epoch 1831/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4299 - val_loss: 1.2679 - val_accuracy: 0.4155

Epoch 01831: val_loss did not improve from 1.26205
Epoch 1832/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4256 - val_loss: 1.2706 - val_accuracy: 0.4107

Epoch 01832: val_loss did not improve from 1.26205
Epoch 1833/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4252 - val_loss: 1.2657 - val_accuracy: 0.4155

Epoch 01833: val_loss did not improve from 1.26205
Epoch 1834/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4295 - val_loss: 1.2648 - val_accuracy: 0.4187

Epoch 01834: val_loss did not improve from 1.26205
Epoch 1835/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4241 - val_loss: 1.2668 - val_accuracy: 0.4155

Epoch 01835: val_loss did not improve from 1.26205
Epoch 1836/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4295 - val_loss: 1.2643 - val_accuracy: 0.4195

Epoch 01836: val_loss did not improve from 1.26205
Epoch 1837/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4311 - val_loss: 1.2639 - val_accuracy: 0.4219

Epoch 01837: val_loss did not improve from 1.26205
Epoch 1838/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4278 - val_loss: 1.2748 - val_accuracy: 0.4115

Epoch 01838: val_loss did not improve from 1.26205
Epoch 1839/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4301 - val_loss: 1.2690 - val_accuracy: 0.4147

Epoch 01839: val_loss did not improve from 1.26205
Epoch 1840/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4275 - val_loss: 1.2649 - val_accuracy: 0.4195

Epoch 01840: val_loss did not improve from 1.26205
Epoch 1841/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4280 - val_loss: 1.2643 - val_accuracy: 0.4187

Epoch 01841: val_loss did not improve from 1.26205
Epoch 1842/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4281 - val_loss: 1.2644 - val_accuracy: 0.4179

Epoch 01842: val_loss did not improve from 1.26205
Epoch 1843/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4296 - val_loss: 1.2654 - val_accuracy: 0.4179

Epoch 01843: val_loss did not improve from 1.26205
Epoch 1844/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4303 - val_loss: 1.2643 - val_accuracy: 0.4147

Epoch 01844: val_loss did not improve from 1.26205
Epoch 1845/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4299 - val_loss: 1.2699 - val_accuracy: 0.4043

Epoch 01845: val_loss did not improve from 1.26205
Epoch 1846/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4273 - val_loss: 1.2786 - val_accuracy: 0.4091

Epoch 01846: val_loss did not improve from 1.26205
Epoch 1847/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4268 - val_loss: 1.2608 - val_accuracy: 0.4195

Epoch 01847: val_loss improved from 1.26205 to 1.26081, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1848/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4246 - val_loss: 1.2641 - val_accuracy: 0.4258

Epoch 01848: val_loss did not improve from 1.26081
Epoch 1849/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4264 - val_loss: 1.2743 - val_accuracy: 0.4075

Epoch 01849: val_loss did not improve from 1.26081
Epoch 1850/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4249 - val_loss: 1.2625 - val_accuracy: 0.4258

Epoch 01850: val_loss did not improve from 1.26081
Epoch 1851/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4245 - val_loss: 1.2713 - val_accuracy: 0.4123

Epoch 01851: val_loss did not improve from 1.26081
Epoch 1852/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4235 - val_loss: 1.2724 - val_accuracy: 0.4099

Epoch 01852: val_loss did not improve from 1.26081
Epoch 1853/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4269 - val_loss: 1.2659 - val_accuracy: 0.4226

Epoch 01853: val_loss did not improve from 1.26081
Epoch 1854/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4239 - val_loss: 1.2641 - val_accuracy: 0.4195

Epoch 01854: val_loss did not improve from 1.26081
Epoch 1855/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4280 - val_loss: 1.2647 - val_accuracy: 0.4242

Epoch 01855: val_loss did not improve from 1.26081
Epoch 1856/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4246 - val_loss: 1.2647 - val_accuracy: 0.4203

Epoch 01856: val_loss did not improve from 1.26081
Epoch 1857/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4226 - val_loss: 1.2646 - val_accuracy: 0.4298

Epoch 01857: val_loss did not improve from 1.26081
Epoch 1858/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4256 - val_loss: 1.2799 - val_accuracy: 0.4099

Epoch 01858: val_loss did not improve from 1.26081
Epoch 1859/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4208 - val_loss: 1.2640 - val_accuracy: 0.4179

Epoch 01859: val_loss did not improve from 1.26081
Epoch 1860/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4253 - val_loss: 1.2628 - val_accuracy: 0.4211

Epoch 01860: val_loss did not improve from 1.26081
Epoch 1861/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4282 - val_loss: 1.2689 - val_accuracy: 0.4163

Epoch 01861: val_loss did not improve from 1.26081
Epoch 1862/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4254 - val_loss: 1.2716 - val_accuracy: 0.4099

Epoch 01862: val_loss did not improve from 1.26081
Epoch 1863/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4274 - val_loss: 1.2738 - val_accuracy: 0.4115

Epoch 01863: val_loss did not improve from 1.26081
Epoch 1864/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4271 - val_loss: 1.2754 - val_accuracy: 0.4139

Epoch 01864: val_loss did not improve from 1.26081
Epoch 1865/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4278 - val_loss: 1.2724 - val_accuracy: 0.4155

Epoch 01865: val_loss did not improve from 1.26081
Epoch 1866/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4272 - val_loss: 1.2759 - val_accuracy: 0.4035

Epoch 01866: val_loss did not improve from 1.26081
Epoch 1867/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4281 - val_loss: 1.2676 - val_accuracy: 0.4083

Epoch 01867: val_loss did not improve from 1.26081
Epoch 1868/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4244 - val_loss: 1.2671 - val_accuracy: 0.4139

Epoch 01868: val_loss did not improve from 1.26081
Epoch 1869/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4248 - val_loss: 1.2684 - val_accuracy: 0.4274

Epoch 01869: val_loss did not improve from 1.26081
Epoch 1870/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4300 - val_loss: 1.2740 - val_accuracy: 0.4187

Epoch 01870: val_loss did not improve from 1.26081
Epoch 1871/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4257 - val_loss: 1.2689 - val_accuracy: 0.4187

Epoch 01871: val_loss did not improve from 1.26081
Epoch 1872/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4249 - val_loss: 1.2632 - val_accuracy: 0.4226

Epoch 01872: val_loss did not improve from 1.26081
Epoch 1873/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4272 - val_loss: 1.2660 - val_accuracy: 0.4195

Epoch 01873: val_loss did not improve from 1.26081
Epoch 1874/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4267 - val_loss: 1.2643 - val_accuracy: 0.4203

Epoch 01874: val_loss did not improve from 1.26081
Epoch 1875/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4288 - val_loss: 1.2649 - val_accuracy: 0.4226

Epoch 01875: val_loss did not improve from 1.26081
Epoch 1876/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4279 - val_loss: 1.2743 - val_accuracy: 0.4187

Epoch 01876: val_loss did not improve from 1.26081
Epoch 1877/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4265 - val_loss: 1.2644 - val_accuracy: 0.4234

Epoch 01877: val_loss did not improve from 1.26081
Epoch 1878/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4264 - val_loss: 1.2754 - val_accuracy: 0.4147

Epoch 01878: val_loss did not improve from 1.26081
Epoch 1879/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4310 - val_loss: 1.2633 - val_accuracy: 0.4219

Epoch 01879: val_loss did not improve from 1.26081
Epoch 1880/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4307 - val_loss: 1.2662 - val_accuracy: 0.4211

Epoch 01880: val_loss did not improve from 1.26081
Epoch 1881/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4303 - val_loss: 1.2810 - val_accuracy: 0.4083

Epoch 01881: val_loss did not improve from 1.26081
Epoch 1882/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4265 - val_loss: 1.2714 - val_accuracy: 0.4131

Epoch 01882: val_loss did not improve from 1.26081
Epoch 1883/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4280 - val_loss: 1.2683 - val_accuracy: 0.4107

Epoch 01883: val_loss did not improve from 1.26081
Epoch 1884/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4250 - val_loss: 1.2627 - val_accuracy: 0.4242

Epoch 01884: val_loss did not improve from 1.26081
Epoch 1885/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4251 - val_loss: 1.2726 - val_accuracy: 0.4035

Epoch 01885: val_loss did not improve from 1.26081
Epoch 1886/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4242 - val_loss: 1.2638 - val_accuracy: 0.4139

Epoch 01886: val_loss did not improve from 1.26081
Epoch 1887/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4268 - val_loss: 1.2614 - val_accuracy: 0.4211

Epoch 01887: val_loss did not improve from 1.26081
Epoch 1888/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4310 - val_loss: 1.2657 - val_accuracy: 0.4099

Epoch 01888: val_loss did not improve from 1.26081
Epoch 1889/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4278 - val_loss: 1.2657 - val_accuracy: 0.4131

Epoch 01889: val_loss did not improve from 1.26081
Epoch 1890/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4256 - val_loss: 1.2654 - val_accuracy: 0.4179

Epoch 01890: val_loss did not improve from 1.26081
Epoch 1891/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4248 - val_loss: 1.2653 - val_accuracy: 0.4131

Epoch 01891: val_loss did not improve from 1.26081
Epoch 1892/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4272 - val_loss: 1.2761 - val_accuracy: 0.4027

Epoch 01892: val_loss did not improve from 1.26081
Epoch 1893/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4298 - val_loss: 1.2684 - val_accuracy: 0.4099

Epoch 01893: val_loss did not improve from 1.26081
Epoch 1894/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4218 - val_loss: 1.2697 - val_accuracy: 0.4115

Epoch 01894: val_loss did not improve from 1.26081
Epoch 1895/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4248 - val_loss: 1.2712 - val_accuracy: 0.4163

Epoch 01895: val_loss did not improve from 1.26081
Epoch 1896/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4244 - val_loss: 1.2708 - val_accuracy: 0.4123

Epoch 01896: val_loss did not improve from 1.26081
Epoch 1897/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4273 - val_loss: 1.2648 - val_accuracy: 0.4282

Epoch 01897: val_loss did not improve from 1.26081
Epoch 1898/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4201 - val_loss: 1.2686 - val_accuracy: 0.4187

Epoch 01898: val_loss did not improve from 1.26081
Epoch 1899/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4315 - val_loss: 1.2673 - val_accuracy: 0.4171

Epoch 01899: val_loss did not improve from 1.26081
Epoch 1900/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4305 - val_loss: 1.2684 - val_accuracy: 0.4203

Epoch 01900: val_loss did not improve from 1.26081
Epoch 1901/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4269 - val_loss: 1.2634 - val_accuracy: 0.4274

Epoch 01901: val_loss did not improve from 1.26081
Epoch 1902/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4266 - val_loss: 1.2772 - val_accuracy: 0.4147

Epoch 01902: val_loss did not improve from 1.26081
Epoch 1903/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4321 - val_loss: 1.2661 - val_accuracy: 0.4155

Epoch 01903: val_loss did not improve from 1.26081
Epoch 1904/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4266 - val_loss: 1.2798 - val_accuracy: 0.4123

Epoch 01904: val_loss did not improve from 1.26081
Epoch 1905/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4287 - val_loss: 1.2663 - val_accuracy: 0.4163

Epoch 01905: val_loss did not improve from 1.26081
Epoch 1906/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4260 - val_loss: 1.2622 - val_accuracy: 0.4187

Epoch 01906: val_loss did not improve from 1.26081
Epoch 1907/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4244 - val_loss: 1.2621 - val_accuracy: 0.4242

Epoch 01907: val_loss did not improve from 1.26081
Epoch 1908/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4254 - val_loss: 1.2645 - val_accuracy: 0.4155

Epoch 01908: val_loss did not improve from 1.26081
Epoch 1909/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4314 - val_loss: 1.2825 - val_accuracy: 0.4043

Epoch 01909: val_loss did not improve from 1.26081
Epoch 1910/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4282 - val_loss: 1.2647 - val_accuracy: 0.4171

Epoch 01910: val_loss did not improve from 1.26081
Epoch 1911/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4276 - val_loss: 1.2617 - val_accuracy: 0.4139

Epoch 01911: val_loss did not improve from 1.26081
Epoch 1912/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4264 - val_loss: 1.2654 - val_accuracy: 0.4155

Epoch 01912: val_loss did not improve from 1.26081
Epoch 1913/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4272 - val_loss: 1.2709 - val_accuracy: 0.4035

Epoch 01913: val_loss did not improve from 1.26081
Epoch 1914/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4249 - val_loss: 1.2697 - val_accuracy: 0.4147

Epoch 01914: val_loss did not improve from 1.26081
Epoch 1915/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4245 - val_loss: 1.2640 - val_accuracy: 0.4211

Epoch 01915: val_loss did not improve from 1.26081
Epoch 1916/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4246 - val_loss: 1.2689 - val_accuracy: 0.4131

Epoch 01916: val_loss did not improve from 1.26081
Epoch 1917/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4250 - val_loss: 1.2661 - val_accuracy: 0.4139

Epoch 01917: val_loss did not improve from 1.26081
Epoch 1918/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4304 - val_loss: 1.2762 - val_accuracy: 0.4131

Epoch 01918: val_loss did not improve from 1.26081
Epoch 1919/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4271 - val_loss: 1.2658 - val_accuracy: 0.4306

Epoch 01919: val_loss did not improve from 1.26081
Epoch 1920/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4255 - val_loss: 1.2641 - val_accuracy: 0.4298

Epoch 01920: val_loss did not improve from 1.26081
Epoch 1921/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4249 - val_loss: 1.2811 - val_accuracy: 0.4051

Epoch 01921: val_loss did not improve from 1.26081
Epoch 1922/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4257 - val_loss: 1.2628 - val_accuracy: 0.4290

Epoch 01922: val_loss did not improve from 1.26081
Epoch 1923/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4323 - val_loss: 1.2667 - val_accuracy: 0.4179

Epoch 01923: val_loss did not improve from 1.26081
Epoch 1924/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4297 - val_loss: 1.2623 - val_accuracy: 0.4226

Epoch 01924: val_loss did not improve from 1.26081
Epoch 1925/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4301 - val_loss: 1.2631 - val_accuracy: 0.4123

Epoch 01925: val_loss did not improve from 1.26081
Epoch 1926/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4272 - val_loss: 1.2632 - val_accuracy: 0.4187

Epoch 01926: val_loss did not improve from 1.26081
Epoch 1927/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4252 - val_loss: 1.2643 - val_accuracy: 0.4179

Epoch 01927: val_loss did not improve from 1.26081
Epoch 1928/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4249 - val_loss: 1.2679 - val_accuracy: 0.4219

Epoch 01928: val_loss did not improve from 1.26081
Epoch 1929/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4280 - val_loss: 1.2655 - val_accuracy: 0.4179

Epoch 01929: val_loss did not improve from 1.26081
Epoch 1930/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4269 - val_loss: 1.2694 - val_accuracy: 0.4139

Epoch 01930: val_loss did not improve from 1.26081
Epoch 1931/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4270 - val_loss: 1.2685 - val_accuracy: 0.4195

Epoch 01931: val_loss did not improve from 1.26081
Epoch 1932/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4263 - val_loss: 1.2682 - val_accuracy: 0.4139

Epoch 01932: val_loss did not improve from 1.26081
Epoch 1933/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4223 - val_loss: 1.2632 - val_accuracy: 0.4123

Epoch 01933: val_loss did not improve from 1.26081
Epoch 1934/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4292 - val_loss: 1.2654 - val_accuracy: 0.4147

Epoch 01934: val_loss did not improve from 1.26081
Epoch 1935/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4242 - val_loss: 1.2642 - val_accuracy: 0.4203

Epoch 01935: val_loss did not improve from 1.26081
Epoch 1936/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4274 - val_loss: 1.2645 - val_accuracy: 0.4163

Epoch 01936: val_loss did not improve from 1.26081
Epoch 1937/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4279 - val_loss: 1.2637 - val_accuracy: 0.4203

Epoch 01937: val_loss did not improve from 1.26081
Epoch 1938/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4272 - val_loss: 1.2682 - val_accuracy: 0.4163

Epoch 01938: val_loss did not improve from 1.26081
Epoch 1939/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4311 - val_loss: 1.2682 - val_accuracy: 0.4195

Epoch 01939: val_loss did not improve from 1.26081
Epoch 1940/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4282 - val_loss: 1.2628 - val_accuracy: 0.4258

Epoch 01940: val_loss did not improve from 1.26081
Epoch 1941/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4256 - val_loss: 1.2634 - val_accuracy: 0.4155

Epoch 01941: val_loss did not improve from 1.26081
Epoch 1942/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4278 - val_loss: 1.2639 - val_accuracy: 0.4242

Epoch 01942: val_loss did not improve from 1.26081
Epoch 1943/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4242 - val_loss: 1.2630 - val_accuracy: 0.4378

Epoch 01943: val_loss did not improve from 1.26081
Epoch 1944/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4199 - val_loss: 1.2831 - val_accuracy: 0.3979

Epoch 01944: val_loss did not improve from 1.26081
Epoch 1945/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4225 - val_loss: 1.2666 - val_accuracy: 0.4171

Epoch 01945: val_loss did not improve from 1.26081
Epoch 1946/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4275 - val_loss: 1.2651 - val_accuracy: 0.4139

Epoch 01946: val_loss did not improve from 1.26081
Epoch 1947/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4258 - val_loss: 1.2646 - val_accuracy: 0.4226

Epoch 01947: val_loss did not improve from 1.26081
Epoch 1948/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4246 - val_loss: 1.2676 - val_accuracy: 0.4155

Epoch 01948: val_loss did not improve from 1.26081
Epoch 1949/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4278 - val_loss: 1.2643 - val_accuracy: 0.4187

Epoch 01949: val_loss did not improve from 1.26081
Epoch 1950/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4256 - val_loss: 1.2602 - val_accuracy: 0.4322

Epoch 01950: val_loss improved from 1.26081 to 1.26023, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1951/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4263 - val_loss: 1.2692 - val_accuracy: 0.4179

Epoch 01951: val_loss did not improve from 1.26023
Epoch 1952/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4300 - val_loss: 1.2629 - val_accuracy: 0.4211

Epoch 01952: val_loss did not improve from 1.26023
Epoch 1953/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4280 - val_loss: 1.2615 - val_accuracy: 0.4250

Epoch 01953: val_loss did not improve from 1.26023
Epoch 1954/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4262 - val_loss: 1.2693 - val_accuracy: 0.4099

Epoch 01954: val_loss did not improve from 1.26023
Epoch 1955/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4241 - val_loss: 1.2660 - val_accuracy: 0.4163

Epoch 01955: val_loss did not improve from 1.26023
Epoch 1956/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4310 - val_loss: 1.2623 - val_accuracy: 0.4195

Epoch 01956: val_loss did not improve from 1.26023
Epoch 1957/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4311 - val_loss: 1.2714 - val_accuracy: 0.4043

Epoch 01957: val_loss did not improve from 1.26023
Epoch 1958/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4248 - val_loss: 1.2661 - val_accuracy: 0.4051

Epoch 01958: val_loss did not improve from 1.26023
Epoch 1959/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4286 - val_loss: 1.2749 - val_accuracy: 0.4091

Epoch 01959: val_loss did not improve from 1.26023
Epoch 1960/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4303 - val_loss: 1.2649 - val_accuracy: 0.4266

Epoch 01960: val_loss did not improve from 1.26023
Epoch 1961/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4281 - val_loss: 1.2676 - val_accuracy: 0.4107

Epoch 01961: val_loss did not improve from 1.26023
Epoch 1962/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4293 - val_loss: 1.2626 - val_accuracy: 0.4226

Epoch 01962: val_loss did not improve from 1.26023
Epoch 1963/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4256 - val_loss: 1.2711 - val_accuracy: 0.4211

Epoch 01963: val_loss did not improve from 1.26023
Epoch 1964/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4307 - val_loss: 1.2642 - val_accuracy: 0.4258

Epoch 01964: val_loss did not improve from 1.26023
Epoch 1965/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4317 - val_loss: 1.2687 - val_accuracy: 0.4211

Epoch 01965: val_loss did not improve from 1.26023
Epoch 1966/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4315 - val_loss: 1.2612 - val_accuracy: 0.4322

Epoch 01966: val_loss did not improve from 1.26023
Epoch 1967/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4280 - val_loss: 1.2769 - val_accuracy: 0.4187

Epoch 01967: val_loss did not improve from 1.26023
Epoch 1968/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4291 - val_loss: 1.2688 - val_accuracy: 0.4155

Epoch 01968: val_loss did not improve from 1.26023
Epoch 1969/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4263 - val_loss: 1.2657 - val_accuracy: 0.4179

Epoch 01969: val_loss did not improve from 1.26023
Epoch 1970/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4269 - val_loss: 1.2637 - val_accuracy: 0.4195

Epoch 01970: val_loss did not improve from 1.26023
Epoch 1971/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4285 - val_loss: 1.2620 - val_accuracy: 0.4226

Epoch 01971: val_loss did not improve from 1.26023
Epoch 1972/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4294 - val_loss: 1.2814 - val_accuracy: 0.4115

Epoch 01972: val_loss did not improve from 1.26023
Epoch 1973/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4259 - val_loss: 1.2653 - val_accuracy: 0.4195

Epoch 01973: val_loss did not improve from 1.26023
Epoch 1974/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4258 - val_loss: 1.2676 - val_accuracy: 0.4131

Epoch 01974: val_loss did not improve from 1.26023
Epoch 1975/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4292 - val_loss: 1.2641 - val_accuracy: 0.4131

Epoch 01975: val_loss did not improve from 1.26023
Epoch 1976/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4276 - val_loss: 1.2614 - val_accuracy: 0.4234

Epoch 01976: val_loss did not improve from 1.26023
Epoch 1977/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4286 - val_loss: 1.2624 - val_accuracy: 0.4155

Epoch 01977: val_loss did not improve from 1.26023
Epoch 1978/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4284 - val_loss: 1.2750 - val_accuracy: 0.4139

Epoch 01978: val_loss did not improve from 1.26023
Epoch 1979/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4279 - val_loss: 1.2666 - val_accuracy: 0.4131

Epoch 01979: val_loss did not improve from 1.26023
Epoch 1980/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4301 - val_loss: 1.2619 - val_accuracy: 0.4219

Epoch 01980: val_loss did not improve from 1.26023
Epoch 1981/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4255 - val_loss: 1.2624 - val_accuracy: 0.4171

Epoch 01981: val_loss did not improve from 1.26023
Epoch 1982/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4273 - val_loss: 1.2664 - val_accuracy: 0.4115

Epoch 01982: val_loss did not improve from 1.26023
Epoch 1983/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4270 - val_loss: 1.2648 - val_accuracy: 0.4187

Epoch 01983: val_loss did not improve from 1.26023
Epoch 1984/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4249 - val_loss: 1.2636 - val_accuracy: 0.4234

Epoch 01984: val_loss did not improve from 1.26023
Epoch 1985/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4300 - val_loss: 1.2596 - val_accuracy: 0.4211

Epoch 01985: val_loss improved from 1.26023 to 1.25958, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 1986/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4288 - val_loss: 1.2636 - val_accuracy: 0.4083

Epoch 01986: val_loss did not improve from 1.25958
Epoch 1987/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4277 - val_loss: 1.2652 - val_accuracy: 0.4115

Epoch 01987: val_loss did not improve from 1.25958
Epoch 1988/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4287 - val_loss: 1.2614 - val_accuracy: 0.4195

Epoch 01988: val_loss did not improve from 1.25958
Epoch 1989/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4279 - val_loss: 1.2674 - val_accuracy: 0.4131

Epoch 01989: val_loss did not improve from 1.25958
Epoch 1990/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4303 - val_loss: 1.2658 - val_accuracy: 0.4155

Epoch 01990: val_loss did not improve from 1.25958
Epoch 1991/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4287 - val_loss: 1.2700 - val_accuracy: 0.4155

Epoch 01991: val_loss did not improve from 1.25958
Epoch 1992/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4299 - val_loss: 1.2679 - val_accuracy: 0.4139

Epoch 01992: val_loss did not improve from 1.25958
Epoch 1993/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4304 - val_loss: 1.2656 - val_accuracy: 0.4195

Epoch 01993: val_loss did not improve from 1.25958
Epoch 1994/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4259 - val_loss: 1.2610 - val_accuracy: 0.4195

Epoch 01994: val_loss did not improve from 1.25958
Epoch 1995/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4301 - val_loss: 1.2655 - val_accuracy: 0.4163

Epoch 01995: val_loss did not improve from 1.25958
Epoch 1996/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4299 - val_loss: 1.2599 - val_accuracy: 0.4219

Epoch 01996: val_loss did not improve from 1.25958
Epoch 1997/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4238 - val_loss: 1.2730 - val_accuracy: 0.4107

Epoch 01997: val_loss did not improve from 1.25958
Epoch 1998/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4285 - val_loss: 1.2686 - val_accuracy: 0.4147

Epoch 01998: val_loss did not improve from 1.25958
Epoch 1999/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4301 - val_loss: 1.2652 - val_accuracy: 0.4234

Epoch 01999: val_loss did not improve from 1.25958
Epoch 2000/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4256 - val_loss: 1.2636 - val_accuracy: 0.4226

Epoch 02000: val_loss did not improve from 1.25958
Epoch 2001/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4271 - val_loss: 1.2606 - val_accuracy: 0.4163

Epoch 02001: val_loss did not improve from 1.25958
Epoch 2002/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4272 - val_loss: 1.2612 - val_accuracy: 0.4211

Epoch 02002: val_loss did not improve from 1.25958
Epoch 2003/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4278 - val_loss: 1.2612 - val_accuracy: 0.4195

Epoch 02003: val_loss did not improve from 1.25958
Epoch 2004/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4275 - val_loss: 1.2641 - val_accuracy: 0.4250

Epoch 02004: val_loss did not improve from 1.25958
Epoch 2005/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4287 - val_loss: 1.2743 - val_accuracy: 0.4067

Epoch 02005: val_loss did not improve from 1.25958
Epoch 2006/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4282 - val_loss: 1.2707 - val_accuracy: 0.4147

Epoch 02006: val_loss did not improve from 1.25958
Epoch 2007/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4324 - val_loss: 1.2598 - val_accuracy: 0.4211

Epoch 02007: val_loss did not improve from 1.25958
Epoch 2008/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4251 - val_loss: 1.2643 - val_accuracy: 0.4107

Epoch 02008: val_loss did not improve from 1.25958
Epoch 2009/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4239 - val_loss: 1.2637 - val_accuracy: 0.4203

Epoch 02009: val_loss did not improve from 1.25958
Epoch 2010/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4337 - val_loss: 1.2621 - val_accuracy: 0.4290

Epoch 02010: val_loss did not improve from 1.25958
Epoch 2011/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4276 - val_loss: 1.2696 - val_accuracy: 0.4187

Epoch 02011: val_loss did not improve from 1.25958
Epoch 2012/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4297 - val_loss: 1.2627 - val_accuracy: 0.4203

Epoch 02012: val_loss did not improve from 1.25958
Epoch 2013/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4283 - val_loss: 1.2621 - val_accuracy: 0.4242

Epoch 02013: val_loss did not improve from 1.25958
Epoch 2014/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4327 - val_loss: 1.2666 - val_accuracy: 0.4203

Epoch 02014: val_loss did not improve from 1.25958
Epoch 2015/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4293 - val_loss: 1.2613 - val_accuracy: 0.4203

Epoch 02015: val_loss did not improve from 1.25958
Epoch 2016/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4273 - val_loss: 1.2615 - val_accuracy: 0.4179

Epoch 02016: val_loss did not improve from 1.25958
Epoch 2017/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4288 - val_loss: 1.2662 - val_accuracy: 0.4211

Epoch 02017: val_loss did not improve from 1.25958
Epoch 2018/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4265 - val_loss: 1.2642 - val_accuracy: 0.4091

Epoch 02018: val_loss did not improve from 1.25958
Epoch 2019/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4287 - val_loss: 1.2610 - val_accuracy: 0.4171

Epoch 02019: val_loss did not improve from 1.25958
Epoch 2020/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4295 - val_loss: 1.2615 - val_accuracy: 0.4139

Epoch 02020: val_loss did not improve from 1.25958
Epoch 2021/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4326 - val_loss: 1.2611 - val_accuracy: 0.4306

Epoch 02021: val_loss did not improve from 1.25958
Epoch 2022/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4264 - val_loss: 1.2600 - val_accuracy: 0.4282

Epoch 02022: val_loss did not improve from 1.25958
Epoch 2023/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4268 - val_loss: 1.2708 - val_accuracy: 0.4139

Epoch 02023: val_loss did not improve from 1.25958
Epoch 2024/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4297 - val_loss: 1.2672 - val_accuracy: 0.4107

Epoch 02024: val_loss did not improve from 1.25958
Epoch 2025/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4297 - val_loss: 1.2630 - val_accuracy: 0.4195

Epoch 02025: val_loss did not improve from 1.25958
Epoch 2026/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4300 - val_loss: 1.2600 - val_accuracy: 0.4195

Epoch 02026: val_loss did not improve from 1.25958
Epoch 2027/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4315 - val_loss: 1.2661 - val_accuracy: 0.4203

Epoch 02027: val_loss did not improve from 1.25958
Epoch 2028/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4318 - val_loss: 1.2712 - val_accuracy: 0.4147

Epoch 02028: val_loss did not improve from 1.25958
Epoch 2029/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4303 - val_loss: 1.2625 - val_accuracy: 0.4266

Epoch 02029: val_loss did not improve from 1.25958
Epoch 2030/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4312 - val_loss: 1.2630 - val_accuracy: 0.4187

Epoch 02030: val_loss did not improve from 1.25958
Epoch 2031/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4236 - val_loss: 1.2678 - val_accuracy: 0.4107

Epoch 02031: val_loss did not improve from 1.25958
Epoch 2032/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4268 - val_loss: 1.2638 - val_accuracy: 0.4322

Epoch 02032: val_loss did not improve from 1.25958
Epoch 2033/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4274 - val_loss: 1.2734 - val_accuracy: 0.4083

Epoch 02033: val_loss did not improve from 1.25958
Epoch 2034/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4312 - val_loss: 1.2708 - val_accuracy: 0.4083

Epoch 02034: val_loss did not improve from 1.25958
Epoch 2035/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4241 - val_loss: 1.2625 - val_accuracy: 0.4211

Epoch 02035: val_loss did not improve from 1.25958
Epoch 2036/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4237 - val_loss: 1.2638 - val_accuracy: 0.4250

Epoch 02036: val_loss did not improve from 1.25958
Epoch 2037/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4253 - val_loss: 1.2694 - val_accuracy: 0.4083

Epoch 02037: val_loss did not improve from 1.25958
Epoch 2038/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4223 - val_loss: 1.2771 - val_accuracy: 0.4075

Epoch 02038: val_loss did not improve from 1.25958
Epoch 2039/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4257 - val_loss: 1.2731 - val_accuracy: 0.4099

Epoch 02039: val_loss did not improve from 1.25958
Epoch 2040/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4303 - val_loss: 1.2610 - val_accuracy: 0.4147

Epoch 02040: val_loss did not improve from 1.25958
Epoch 2041/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4288 - val_loss: 1.2645 - val_accuracy: 0.4091

Epoch 02041: val_loss did not improve from 1.25958
Epoch 2042/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4316 - val_loss: 1.2654 - val_accuracy: 0.4171

Epoch 02042: val_loss did not improve from 1.25958
Epoch 2043/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4284 - val_loss: 1.2750 - val_accuracy: 0.4131

Epoch 02043: val_loss did not improve from 1.25958
Epoch 2044/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4280 - val_loss: 1.2659 - val_accuracy: 0.4107

Epoch 02044: val_loss did not improve from 1.25958
Epoch 2045/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4317 - val_loss: 1.2624 - val_accuracy: 0.4282

Epoch 02045: val_loss did not improve from 1.25958
Epoch 2046/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4312 - val_loss: 1.2619 - val_accuracy: 0.4274

Epoch 02046: val_loss did not improve from 1.25958
Epoch 2047/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4253 - val_loss: 1.2638 - val_accuracy: 0.4155

Epoch 02047: val_loss did not improve from 1.25958
Epoch 2048/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4280 - val_loss: 1.2673 - val_accuracy: 0.4067

Epoch 02048: val_loss did not improve from 1.25958
Epoch 2049/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4272 - val_loss: 1.2692 - val_accuracy: 0.4123

Epoch 02049: val_loss did not improve from 1.25958
Epoch 2050/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4295 - val_loss: 1.2659 - val_accuracy: 0.4123

Epoch 02050: val_loss did not improve from 1.25958
Epoch 2051/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4292 - val_loss: 1.2594 - val_accuracy: 0.4203

Epoch 02051: val_loss improved from 1.25958 to 1.25941, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2052/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4281 - val_loss: 1.2623 - val_accuracy: 0.4219

Epoch 02052: val_loss did not improve from 1.25941
Epoch 2053/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4211 - val_loss: 1.2705 - val_accuracy: 0.4195

Epoch 02053: val_loss did not improve from 1.25941
Epoch 2054/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4269 - val_loss: 1.2857 - val_accuracy: 0.4091

Epoch 02054: val_loss did not improve from 1.25941
Epoch 2055/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4280 - val_loss: 1.2638 - val_accuracy: 0.4139

Epoch 02055: val_loss did not improve from 1.25941
Epoch 2056/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4299 - val_loss: 1.2608 - val_accuracy: 0.4203

Epoch 02056: val_loss did not improve from 1.25941
Epoch 2057/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4303 - val_loss: 1.2737 - val_accuracy: 0.4115

Epoch 02057: val_loss did not improve from 1.25941
Epoch 2058/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4251 - val_loss: 1.2757 - val_accuracy: 0.4027

Epoch 02058: val_loss did not improve from 1.25941
Epoch 2059/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4277 - val_loss: 1.2639 - val_accuracy: 0.4179

Epoch 02059: val_loss did not improve from 1.25941
Epoch 2060/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4311 - val_loss: 1.2637 - val_accuracy: 0.4410

Epoch 02060: val_loss did not improve from 1.25941
Epoch 2061/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4308 - val_loss: 1.2636 - val_accuracy: 0.4219

Epoch 02061: val_loss did not improve from 1.25941
Epoch 2062/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4295 - val_loss: 1.2669 - val_accuracy: 0.4195

Epoch 02062: val_loss did not improve from 1.25941
Epoch 2063/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4263 - val_loss: 1.2640 - val_accuracy: 0.4163

Epoch 02063: val_loss did not improve from 1.25941
Epoch 2064/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4246 - val_loss: 1.2633 - val_accuracy: 0.4226

Epoch 02064: val_loss did not improve from 1.25941
Epoch 2065/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4250 - val_loss: 1.2620 - val_accuracy: 0.4322

Epoch 02065: val_loss did not improve from 1.25941
Epoch 2066/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4282 - val_loss: 1.2642 - val_accuracy: 0.4147

Epoch 02066: val_loss did not improve from 1.25941
Epoch 2067/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4303 - val_loss: 1.2755 - val_accuracy: 0.4131

Epoch 02067: val_loss did not improve from 1.25941
Epoch 2068/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4311 - val_loss: 1.2712 - val_accuracy: 0.4115

Epoch 02068: val_loss did not improve from 1.25941
Epoch 2069/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4285 - val_loss: 1.2611 - val_accuracy: 0.4171

Epoch 02069: val_loss did not improve from 1.25941
Epoch 2070/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4217 - val_loss: 1.2620 - val_accuracy: 0.4274

Epoch 02070: val_loss did not improve from 1.25941
Epoch 2071/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4255 - val_loss: 1.2707 - val_accuracy: 0.4059

Epoch 02071: val_loss did not improve from 1.25941
Epoch 2072/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4287 - val_loss: 1.2652 - val_accuracy: 0.4163

Epoch 02072: val_loss did not improve from 1.25941
Epoch 2073/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4281 - val_loss: 1.2603 - val_accuracy: 0.4290

Epoch 02073: val_loss did not improve from 1.25941
Epoch 2074/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4225 - val_loss: 1.2679 - val_accuracy: 0.4171

Epoch 02074: val_loss did not improve from 1.25941
Epoch 2075/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4308 - val_loss: 1.2669 - val_accuracy: 0.4234

Epoch 02075: val_loss did not improve from 1.25941
Epoch 2076/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4303 - val_loss: 1.2674 - val_accuracy: 0.4219

Epoch 02076: val_loss did not improve from 1.25941
Epoch 2077/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4286 - val_loss: 1.2659 - val_accuracy: 0.4043

Epoch 02077: val_loss did not improve from 1.25941
Epoch 2078/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4283 - val_loss: 1.2611 - val_accuracy: 0.4242

Epoch 02078: val_loss did not improve from 1.25941
Epoch 2079/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4321 - val_loss: 1.2654 - val_accuracy: 0.4171

Epoch 02079: val_loss did not improve from 1.25941
Epoch 2080/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4303 - val_loss: 1.2606 - val_accuracy: 0.4211

Epoch 02080: val_loss did not improve from 1.25941
Epoch 2081/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4296 - val_loss: 1.2597 - val_accuracy: 0.4282

Epoch 02081: val_loss did not improve from 1.25941
Epoch 2082/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4281 - val_loss: 1.2690 - val_accuracy: 0.4107

Epoch 02082: val_loss did not improve from 1.25941
Epoch 2083/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4280 - val_loss: 1.2651 - val_accuracy: 0.4171

Epoch 02083: val_loss did not improve from 1.25941
Epoch 2084/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4295 - val_loss: 1.2661 - val_accuracy: 0.4131

Epoch 02084: val_loss did not improve from 1.25941
Epoch 2085/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4274 - val_loss: 1.2600 - val_accuracy: 0.4266

Epoch 02085: val_loss did not improve from 1.25941
Epoch 2086/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4283 - val_loss: 1.2633 - val_accuracy: 0.4274

Epoch 02086: val_loss did not improve from 1.25941
Epoch 2087/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4285 - val_loss: 1.2597 - val_accuracy: 0.4322

Epoch 02087: val_loss did not improve from 1.25941
Epoch 2088/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4222 - val_loss: 1.2820 - val_accuracy: 0.4099

Epoch 02088: val_loss did not improve from 1.25941
Epoch 2089/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4297 - val_loss: 1.2712 - val_accuracy: 0.4099

Epoch 02089: val_loss did not improve from 1.25941
Epoch 2090/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4290 - val_loss: 1.2681 - val_accuracy: 0.4107

Epoch 02090: val_loss did not improve from 1.25941
Epoch 2091/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4266 - val_loss: 1.2631 - val_accuracy: 0.4131

Epoch 02091: val_loss did not improve from 1.25941
Epoch 2092/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4267 - val_loss: 1.2641 - val_accuracy: 0.4171

Epoch 02092: val_loss did not improve from 1.25941
Epoch 2093/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4287 - val_loss: 1.2596 - val_accuracy: 0.4234

Epoch 02093: val_loss did not improve from 1.25941
Epoch 2094/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4309 - val_loss: 1.2607 - val_accuracy: 0.4234

Epoch 02094: val_loss did not improve from 1.25941
Epoch 2095/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4303 - val_loss: 1.2607 - val_accuracy: 0.4282

Epoch 02095: val_loss did not improve from 1.25941
Epoch 2096/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4308 - val_loss: 1.2651 - val_accuracy: 0.4171

Epoch 02096: val_loss did not improve from 1.25941
Epoch 2097/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4314 - val_loss: 1.2613 - val_accuracy: 0.4234

Epoch 02097: val_loss did not improve from 1.25941
Epoch 2098/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4276 - val_loss: 1.2642 - val_accuracy: 0.4163

Epoch 02098: val_loss did not improve from 1.25941
Epoch 2099/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4267 - val_loss: 1.2618 - val_accuracy: 0.4250

Epoch 02099: val_loss did not improve from 1.25941
Epoch 2100/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4294 - val_loss: 1.2691 - val_accuracy: 0.4083

Epoch 02100: val_loss did not improve from 1.25941
Epoch 2101/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4305 - val_loss: 1.2596 - val_accuracy: 0.4250

Epoch 02101: val_loss did not improve from 1.25941
Epoch 2102/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4286 - val_loss: 1.2654 - val_accuracy: 0.4195

Epoch 02102: val_loss did not improve from 1.25941
Epoch 2103/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4286 - val_loss: 1.2697 - val_accuracy: 0.4179

Epoch 02103: val_loss did not improve from 1.25941
Epoch 2104/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4291 - val_loss: 1.2607 - val_accuracy: 0.4187

Epoch 02104: val_loss did not improve from 1.25941
Epoch 2105/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4311 - val_loss: 1.2658 - val_accuracy: 0.4099

Epoch 02105: val_loss did not improve from 1.25941
Epoch 2106/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4295 - val_loss: 1.2735 - val_accuracy: 0.4171

Epoch 02106: val_loss did not improve from 1.25941
Epoch 2107/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4275 - val_loss: 1.2693 - val_accuracy: 0.4019

Epoch 02107: val_loss did not improve from 1.25941
Epoch 2108/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4258 - val_loss: 1.2613 - val_accuracy: 0.4195

Epoch 02108: val_loss did not improve from 1.25941
Epoch 2109/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4312 - val_loss: 1.2586 - val_accuracy: 0.4242

Epoch 02109: val_loss improved from 1.25941 to 1.25859, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2110/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4245 - val_loss: 1.2638 - val_accuracy: 0.4203

Epoch 02110: val_loss did not improve from 1.25859
Epoch 2111/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4240 - val_loss: 1.2624 - val_accuracy: 0.4139

Epoch 02111: val_loss did not improve from 1.25859
Epoch 2112/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4322 - val_loss: 1.2581 - val_accuracy: 0.4266

Epoch 02112: val_loss improved from 1.25859 to 1.25812, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2113/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4312 - val_loss: 1.2729 - val_accuracy: 0.4099

Epoch 02113: val_loss did not improve from 1.25812
Epoch 2114/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4334 - val_loss: 1.2630 - val_accuracy: 0.4195

Epoch 02114: val_loss did not improve from 1.25812
Epoch 2115/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4321 - val_loss: 1.2639 - val_accuracy: 0.4155

Epoch 02115: val_loss did not improve from 1.25812
Epoch 2116/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4308 - val_loss: 1.2678 - val_accuracy: 0.4131

Epoch 02116: val_loss did not improve from 1.25812
Epoch 2117/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4309 - val_loss: 1.2578 - val_accuracy: 0.4290

Epoch 02117: val_loss improved from 1.25812 to 1.25775, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2118/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4308 - val_loss: 1.2619 - val_accuracy: 0.4187

Epoch 02118: val_loss did not improve from 1.25775
Epoch 2119/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4299 - val_loss: 1.2621 - val_accuracy: 0.4147

Epoch 02119: val_loss did not improve from 1.25775
Epoch 2120/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4296 - val_loss: 1.2644 - val_accuracy: 0.4091

Epoch 02120: val_loss did not improve from 1.25775
Epoch 2121/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4292 - val_loss: 1.2645 - val_accuracy: 0.4107

Epoch 02121: val_loss did not improve from 1.25775
Epoch 2122/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4278 - val_loss: 1.2686 - val_accuracy: 0.4115

Epoch 02122: val_loss did not improve from 1.25775
Epoch 2123/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4249 - val_loss: 1.2650 - val_accuracy: 0.4226

Epoch 02123: val_loss did not improve from 1.25775
Epoch 2124/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4316 - val_loss: 1.2614 - val_accuracy: 0.4115

Epoch 02124: val_loss did not improve from 1.25775
Epoch 2125/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4299 - val_loss: 1.2636 - val_accuracy: 0.4075

Epoch 02125: val_loss did not improve from 1.25775
Epoch 2126/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4263 - val_loss: 1.2593 - val_accuracy: 0.4226

Epoch 02126: val_loss did not improve from 1.25775
Epoch 2127/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4303 - val_loss: 1.2679 - val_accuracy: 0.4115

Epoch 02127: val_loss did not improve from 1.25775
Epoch 2128/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4301 - val_loss: 1.2606 - val_accuracy: 0.4226

Epoch 02128: val_loss did not improve from 1.25775
Epoch 2129/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4300 - val_loss: 1.2616 - val_accuracy: 0.4203

Epoch 02129: val_loss did not improve from 1.25775
Epoch 2130/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4300 - val_loss: 1.2641 - val_accuracy: 0.4211

Epoch 02130: val_loss did not improve from 1.25775
Epoch 2131/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4295 - val_loss: 1.2660 - val_accuracy: 0.4187

Epoch 02131: val_loss did not improve from 1.25775
Epoch 2132/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4272 - val_loss: 1.2602 - val_accuracy: 0.4234

Epoch 02132: val_loss did not improve from 1.25775
Epoch 2133/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4262 - val_loss: 1.2717 - val_accuracy: 0.4123

Epoch 02133: val_loss did not improve from 1.25775
Epoch 2134/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4313 - val_loss: 1.2605 - val_accuracy: 0.4250

Epoch 02134: val_loss did not improve from 1.25775
Epoch 2135/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4281 - val_loss: 1.2643 - val_accuracy: 0.4274

Epoch 02135: val_loss did not improve from 1.25775
Epoch 2136/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4217 - val_loss: 1.2680 - val_accuracy: 0.4083

Epoch 02136: val_loss did not improve from 1.25775
Epoch 2137/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4244 - val_loss: 1.2795 - val_accuracy: 0.4043

Epoch 02137: val_loss did not improve from 1.25775
Epoch 2138/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4304 - val_loss: 1.2654 - val_accuracy: 0.4266

Epoch 02138: val_loss did not improve from 1.25775
Epoch 2139/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4278 - val_loss: 1.2664 - val_accuracy: 0.4163

Epoch 02139: val_loss did not improve from 1.25775
Epoch 2140/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4297 - val_loss: 1.2619 - val_accuracy: 0.4330

Epoch 02140: val_loss did not improve from 1.25775
Epoch 2141/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4343 - val_loss: 1.2787 - val_accuracy: 0.4195

Epoch 02141: val_loss did not improve from 1.25775
Epoch 2142/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4300 - val_loss: 1.2619 - val_accuracy: 0.4219

Epoch 02142: val_loss did not improve from 1.25775
Epoch 2143/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4307 - val_loss: 1.2607 - val_accuracy: 0.4266

Epoch 02143: val_loss did not improve from 1.25775
Epoch 2144/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4344 - val_loss: 1.2680 - val_accuracy: 0.4099

Epoch 02144: val_loss did not improve from 1.25775
Epoch 2145/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4278 - val_loss: 1.2608 - val_accuracy: 0.4258

Epoch 02145: val_loss did not improve from 1.25775
Epoch 2146/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4328 - val_loss: 1.2621 - val_accuracy: 0.4234

Epoch 02146: val_loss did not improve from 1.25775
Epoch 2147/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4286 - val_loss: 1.2590 - val_accuracy: 0.4266

Epoch 02147: val_loss did not improve from 1.25775
Epoch 2148/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4232 - val_loss: 1.2772 - val_accuracy: 0.4163

Epoch 02148: val_loss did not improve from 1.25775
Epoch 2149/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4324 - val_loss: 1.2635 - val_accuracy: 0.4187

Epoch 02149: val_loss did not improve from 1.25775
Epoch 2150/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4289 - val_loss: 1.2593 - val_accuracy: 0.4306

Epoch 02150: val_loss did not improve from 1.25775
Epoch 2151/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4311 - val_loss: 1.2641 - val_accuracy: 0.4147

Epoch 02151: val_loss did not improve from 1.25775
Epoch 2152/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4313 - val_loss: 1.2636 - val_accuracy: 0.4179

Epoch 02152: val_loss did not improve from 1.25775
Epoch 2153/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4345 - val_loss: 1.2619 - val_accuracy: 0.4179

Epoch 02153: val_loss did not improve from 1.25775
Epoch 2154/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4346 - val_loss: 1.2596 - val_accuracy: 0.4314

Epoch 02154: val_loss did not improve from 1.25775
Epoch 2155/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4310 - val_loss: 1.2642 - val_accuracy: 0.4155

Epoch 02155: val_loss did not improve from 1.25775
Epoch 2156/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4286 - val_loss: 1.2736 - val_accuracy: 0.4131

Epoch 02156: val_loss did not improve from 1.25775
Epoch 2157/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4327 - val_loss: 1.2614 - val_accuracy: 0.4147

Epoch 02157: val_loss did not improve from 1.25775
Epoch 2158/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4303 - val_loss: 1.2604 - val_accuracy: 0.4290

Epoch 02158: val_loss did not improve from 1.25775
Epoch 2159/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4321 - val_loss: 1.2618 - val_accuracy: 0.4203

Epoch 02159: val_loss did not improve from 1.25775
Epoch 2160/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4309 - val_loss: 1.2592 - val_accuracy: 0.4250

Epoch 02160: val_loss did not improve from 1.25775
Epoch 2161/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4335 - val_loss: 1.2595 - val_accuracy: 0.4219

Epoch 02161: val_loss did not improve from 1.25775
Epoch 2162/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4343 - val_loss: 1.2652 - val_accuracy: 0.4075

Epoch 02162: val_loss did not improve from 1.25775
Epoch 2163/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4329 - val_loss: 1.2681 - val_accuracy: 0.4115

Epoch 02163: val_loss did not improve from 1.25775
Epoch 2164/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4289 - val_loss: 1.2681 - val_accuracy: 0.4147

Epoch 02164: val_loss did not improve from 1.25775
Epoch 2165/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4339 - val_loss: 1.2577 - val_accuracy: 0.4219

Epoch 02165: val_loss improved from 1.25775 to 1.25769, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2166/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4297 - val_loss: 1.2596 - val_accuracy: 0.4179

Epoch 02166: val_loss did not improve from 1.25769
Epoch 2167/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4303 - val_loss: 1.2754 - val_accuracy: 0.4091

Epoch 02167: val_loss did not improve from 1.25769
Epoch 2168/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4286 - val_loss: 1.2691 - val_accuracy: 0.4131

Epoch 02168: val_loss did not improve from 1.25769
Epoch 2169/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4310 - val_loss: 1.2576 - val_accuracy: 0.4219

Epoch 02169: val_loss improved from 1.25769 to 1.25759, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2170/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4353 - val_loss: 1.2634 - val_accuracy: 0.4234

Epoch 02170: val_loss did not improve from 1.25759
Epoch 2171/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4317 - val_loss: 1.2622 - val_accuracy: 0.4211

Epoch 02171: val_loss did not improve from 1.25759
Epoch 2172/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4303 - val_loss: 1.2583 - val_accuracy: 0.4274

Epoch 02172: val_loss did not improve from 1.25759
Epoch 2173/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4316 - val_loss: 1.2749 - val_accuracy: 0.4027

Epoch 02173: val_loss did not improve from 1.25759
Epoch 2174/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4295 - val_loss: 1.2679 - val_accuracy: 0.4226

Epoch 02174: val_loss did not improve from 1.25759
Epoch 2175/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4249 - val_loss: 1.2590 - val_accuracy: 0.4234

Epoch 02175: val_loss did not improve from 1.25759
Epoch 2176/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4294 - val_loss: 1.2585 - val_accuracy: 0.4346

Epoch 02176: val_loss did not improve from 1.25759
Epoch 2177/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4296 - val_loss: 1.2602 - val_accuracy: 0.4131

Epoch 02177: val_loss did not improve from 1.25759
Epoch 2178/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4309 - val_loss: 1.2574 - val_accuracy: 0.4266

Epoch 02178: val_loss improved from 1.25759 to 1.25738, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2179/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4267 - val_loss: 1.2666 - val_accuracy: 0.4155

Epoch 02179: val_loss did not improve from 1.25738
Epoch 2180/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4323 - val_loss: 1.2769 - val_accuracy: 0.4195

Epoch 02180: val_loss did not improve from 1.25738
Epoch 2181/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4271 - val_loss: 1.2588 - val_accuracy: 0.4163

Epoch 02181: val_loss did not improve from 1.25738
Epoch 2182/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4289 - val_loss: 1.2627 - val_accuracy: 0.4163

Epoch 02182: val_loss did not improve from 1.25738
Epoch 2183/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4322 - val_loss: 1.2572 - val_accuracy: 0.4211

Epoch 02183: val_loss improved from 1.25738 to 1.25719, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2184/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4324 - val_loss: 1.2574 - val_accuracy: 0.4298

Epoch 02184: val_loss did not improve from 1.25719
Epoch 2185/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4311 - val_loss: 1.2579 - val_accuracy: 0.4211

Epoch 02185: val_loss did not improve from 1.25719
Epoch 2186/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4325 - val_loss: 1.2751 - val_accuracy: 0.4123

Epoch 02186: val_loss did not improve from 1.25719
Epoch 2187/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4258 - val_loss: 1.2590 - val_accuracy: 0.4195

Epoch 02187: val_loss did not improve from 1.25719
Epoch 2188/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4270 - val_loss: 1.2713 - val_accuracy: 0.4059

Epoch 02188: val_loss did not improve from 1.25719
Epoch 2189/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4343 - val_loss: 1.2616 - val_accuracy: 0.4219

Epoch 02189: val_loss did not improve from 1.25719
Epoch 2190/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4295 - val_loss: 1.2662 - val_accuracy: 0.4139

Epoch 02190: val_loss did not improve from 1.25719
Epoch 2191/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4287 - val_loss: 1.2597 - val_accuracy: 0.4211

Epoch 02191: val_loss did not improve from 1.25719
Epoch 2192/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4334 - val_loss: 1.2608 - val_accuracy: 0.4203

Epoch 02192: val_loss did not improve from 1.25719
Epoch 2193/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4317 - val_loss: 1.2612 - val_accuracy: 0.4282

Epoch 02193: val_loss did not improve from 1.25719
Epoch 2194/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4328 - val_loss: 1.2589 - val_accuracy: 0.4250

Epoch 02194: val_loss did not improve from 1.25719
Epoch 2195/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4259 - val_loss: 1.2621 - val_accuracy: 0.4171

Epoch 02195: val_loss did not improve from 1.25719
Epoch 2196/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4321 - val_loss: 1.2708 - val_accuracy: 0.4123

Epoch 02196: val_loss did not improve from 1.25719
Epoch 2197/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4281 - val_loss: 1.2648 - val_accuracy: 0.4226

Epoch 02197: val_loss did not improve from 1.25719
Epoch 2198/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4324 - val_loss: 1.2621 - val_accuracy: 0.4203

Epoch 02198: val_loss did not improve from 1.25719
Epoch 2199/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4334 - val_loss: 1.2598 - val_accuracy: 0.4354

Epoch 02199: val_loss did not improve from 1.25719
Epoch 2200/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4329 - val_loss: 1.2636 - val_accuracy: 0.4234

Epoch 02200: val_loss did not improve from 1.25719
Epoch 2201/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4308 - val_loss: 1.2592 - val_accuracy: 0.4274

Epoch 02201: val_loss did not improve from 1.25719
Epoch 2202/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4326 - val_loss: 1.2599 - val_accuracy: 0.4234

Epoch 02202: val_loss did not improve from 1.25719
Epoch 2203/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4289 - val_loss: 1.2655 - val_accuracy: 0.4179

Epoch 02203: val_loss did not improve from 1.25719
Epoch 2204/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4305 - val_loss: 1.2682 - val_accuracy: 0.4147

Epoch 02204: val_loss did not improve from 1.25719
Epoch 2205/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4320 - val_loss: 1.2616 - val_accuracy: 0.4171

Epoch 02205: val_loss did not improve from 1.25719
Epoch 2206/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4326 - val_loss: 1.2570 - val_accuracy: 0.4290

Epoch 02206: val_loss improved from 1.25719 to 1.25698, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2207/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4300 - val_loss: 1.2620 - val_accuracy: 0.4179

Epoch 02207: val_loss did not improve from 1.25698
Epoch 2208/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4302 - val_loss: 1.2625 - val_accuracy: 0.4155

Epoch 02208: val_loss did not improve from 1.25698
Epoch 2209/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4341 - val_loss: 1.2613 - val_accuracy: 0.4314

Epoch 02209: val_loss did not improve from 1.25698
Epoch 2210/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4344 - val_loss: 1.2604 - val_accuracy: 0.4250

Epoch 02210: val_loss did not improve from 1.25698
Epoch 2211/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4282 - val_loss: 1.2646 - val_accuracy: 0.4123

Epoch 02211: val_loss did not improve from 1.25698
Epoch 2212/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4326 - val_loss: 1.2614 - val_accuracy: 0.4115

Epoch 02212: val_loss did not improve from 1.25698
Epoch 2213/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4265 - val_loss: 1.2734 - val_accuracy: 0.4171

Epoch 02213: val_loss did not improve from 1.25698
Epoch 2214/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4275 - val_loss: 1.2655 - val_accuracy: 0.4187

Epoch 02214: val_loss did not improve from 1.25698
Epoch 2215/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4315 - val_loss: 1.2640 - val_accuracy: 0.4139

Epoch 02215: val_loss did not improve from 1.25698
Epoch 2216/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4317 - val_loss: 1.2610 - val_accuracy: 0.4203

Epoch 02216: val_loss did not improve from 1.25698
Epoch 2217/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4335 - val_loss: 1.2649 - val_accuracy: 0.4266

Epoch 02217: val_loss did not improve from 1.25698
Epoch 2218/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4324 - val_loss: 1.2602 - val_accuracy: 0.4211

Epoch 02218: val_loss did not improve from 1.25698
Epoch 2219/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4294 - val_loss: 1.2655 - val_accuracy: 0.4147

Epoch 02219: val_loss did not improve from 1.25698
Epoch 2220/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4323 - val_loss: 1.2678 - val_accuracy: 0.4123

Epoch 02220: val_loss did not improve from 1.25698
Epoch 2221/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4310 - val_loss: 1.2603 - val_accuracy: 0.4282

Epoch 02221: val_loss did not improve from 1.25698
Epoch 2222/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4287 - val_loss: 1.2622 - val_accuracy: 0.4131

Epoch 02222: val_loss did not improve from 1.25698
Epoch 2223/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4297 - val_loss: 1.2599 - val_accuracy: 0.4139

Epoch 02223: val_loss did not improve from 1.25698
Epoch 2224/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4278 - val_loss: 1.2593 - val_accuracy: 0.4226

Epoch 02224: val_loss did not improve from 1.25698
Epoch 2225/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4277 - val_loss: 1.2571 - val_accuracy: 0.4203

Epoch 02225: val_loss did not improve from 1.25698
Epoch 2226/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4293 - val_loss: 1.2591 - val_accuracy: 0.4115

Epoch 02226: val_loss did not improve from 1.25698
Epoch 2227/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4282 - val_loss: 1.2589 - val_accuracy: 0.4226

Epoch 02227: val_loss did not improve from 1.25698
Epoch 2228/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4327 - val_loss: 1.2625 - val_accuracy: 0.4298

Epoch 02228: val_loss did not improve from 1.25698
Epoch 2229/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4303 - val_loss: 1.2714 - val_accuracy: 0.4234

Epoch 02229: val_loss did not improve from 1.25698
Epoch 2230/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4312 - val_loss: 1.2625 - val_accuracy: 0.4179

Epoch 02230: val_loss did not improve from 1.25698
Epoch 2231/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4299 - val_loss: 1.2588 - val_accuracy: 0.4203

Epoch 02231: val_loss did not improve from 1.25698
Epoch 2232/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4316 - val_loss: 1.2641 - val_accuracy: 0.4234

Epoch 02232: val_loss did not improve from 1.25698
Epoch 2233/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4333 - val_loss: 1.2653 - val_accuracy: 0.4147

Epoch 02233: val_loss did not improve from 1.25698
Epoch 2234/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4324 - val_loss: 1.2610 - val_accuracy: 0.4258

Epoch 02234: val_loss did not improve from 1.25698
Epoch 2235/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4331 - val_loss: 1.2577 - val_accuracy: 0.4298

Epoch 02235: val_loss did not improve from 1.25698
Epoch 2236/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4287 - val_loss: 1.2608 - val_accuracy: 0.4219

Epoch 02236: val_loss did not improve from 1.25698
Epoch 2237/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4258 - val_loss: 1.2843 - val_accuracy: 0.4115

Epoch 02237: val_loss did not improve from 1.25698
Epoch 2238/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4298 - val_loss: 1.2696 - val_accuracy: 0.4179

Epoch 02238: val_loss did not improve from 1.25698
Epoch 2239/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4295 - val_loss: 1.2752 - val_accuracy: 0.4083

Epoch 02239: val_loss did not improve from 1.25698
Epoch 2240/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4266 - val_loss: 1.2629 - val_accuracy: 0.4163

Epoch 02240: val_loss did not improve from 1.25698
Epoch 2241/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4348 - val_loss: 1.2581 - val_accuracy: 0.4234

Epoch 02241: val_loss did not improve from 1.25698
Epoch 2242/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4295 - val_loss: 1.2632 - val_accuracy: 0.4091

Epoch 02242: val_loss did not improve from 1.25698
Epoch 2243/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4329 - val_loss: 1.2627 - val_accuracy: 0.4242

Epoch 02243: val_loss did not improve from 1.25698
Epoch 2244/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4328 - val_loss: 1.2603 - val_accuracy: 0.4211

Epoch 02244: val_loss did not improve from 1.25698
Epoch 2245/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4330 - val_loss: 1.2654 - val_accuracy: 0.4163

Epoch 02245: val_loss did not improve from 1.25698
Epoch 2246/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4332 - val_loss: 1.2565 - val_accuracy: 0.4211

Epoch 02246: val_loss improved from 1.25698 to 1.25648, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2247/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4342 - val_loss: 1.2570 - val_accuracy: 0.4266

Epoch 02247: val_loss did not improve from 1.25648
Epoch 2248/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4325 - val_loss: 1.2634 - val_accuracy: 0.4250

Epoch 02248: val_loss did not improve from 1.25648
Epoch 2249/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4318 - val_loss: 1.2623 - val_accuracy: 0.4179

Epoch 02249: val_loss did not improve from 1.25648
Epoch 2250/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4311 - val_loss: 1.2575 - val_accuracy: 0.4242

Epoch 02250: val_loss did not improve from 1.25648
Epoch 2251/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4320 - val_loss: 1.2602 - val_accuracy: 0.4242

Epoch 02251: val_loss did not improve from 1.25648
Epoch 2252/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4285 - val_loss: 1.2598 - val_accuracy: 0.4306

Epoch 02252: val_loss did not improve from 1.25648
Epoch 2253/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4299 - val_loss: 1.2652 - val_accuracy: 0.4226

Epoch 02253: val_loss did not improve from 1.25648
Epoch 2254/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4334 - val_loss: 1.2800 - val_accuracy: 0.4147

Epoch 02254: val_loss did not improve from 1.25648
Epoch 2255/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4310 - val_loss: 1.2666 - val_accuracy: 0.4163

Epoch 02255: val_loss did not improve from 1.25648
Epoch 2256/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4329 - val_loss: 1.2586 - val_accuracy: 0.4187

Epoch 02256: val_loss did not improve from 1.25648
Epoch 2257/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4323 - val_loss: 1.2581 - val_accuracy: 0.4274

Epoch 02257: val_loss did not improve from 1.25648
Epoch 2258/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4314 - val_loss: 1.2627 - val_accuracy: 0.4242

Epoch 02258: val_loss did not improve from 1.25648
Epoch 2259/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4351 - val_loss: 1.2651 - val_accuracy: 0.4163

Epoch 02259: val_loss did not improve from 1.25648
Epoch 2260/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4301 - val_loss: 1.2649 - val_accuracy: 0.4147

Epoch 02260: val_loss did not improve from 1.25648
Epoch 2261/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4373 - val_loss: 1.2613 - val_accuracy: 0.4187

Epoch 02261: val_loss did not improve from 1.25648
Epoch 2262/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4314 - val_loss: 1.2595 - val_accuracy: 0.4242

Epoch 02262: val_loss did not improve from 1.25648
Epoch 2263/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4297 - val_loss: 1.2723 - val_accuracy: 0.4242

Epoch 02263: val_loss did not improve from 1.25648
Epoch 2264/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4281 - val_loss: 1.2653 - val_accuracy: 0.4131

Epoch 02264: val_loss did not improve from 1.25648
Epoch 2265/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4317 - val_loss: 1.2634 - val_accuracy: 0.4258

Epoch 02265: val_loss did not improve from 1.25648
Epoch 2266/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4317 - val_loss: 1.2583 - val_accuracy: 0.4226

Epoch 02266: val_loss did not improve from 1.25648
Epoch 2267/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4303 - val_loss: 1.2583 - val_accuracy: 0.4203

Epoch 02267: val_loss did not improve from 1.25648
Epoch 2268/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4350 - val_loss: 1.2597 - val_accuracy: 0.4250

Epoch 02268: val_loss did not improve from 1.25648
Epoch 2269/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4303 - val_loss: 1.2651 - val_accuracy: 0.4147

Epoch 02269: val_loss did not improve from 1.25648
Epoch 2270/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4277 - val_loss: 1.2624 - val_accuracy: 0.4195

Epoch 02270: val_loss did not improve from 1.25648
Epoch 2271/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4283 - val_loss: 1.2604 - val_accuracy: 0.4282

Epoch 02271: val_loss did not improve from 1.25648
Epoch 2272/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4273 - val_loss: 1.2638 - val_accuracy: 0.4139

Epoch 02272: val_loss did not improve from 1.25648
Epoch 2273/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4325 - val_loss: 1.2622 - val_accuracy: 0.4242

Epoch 02273: val_loss did not improve from 1.25648
Epoch 2274/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4370 - val_loss: 1.2767 - val_accuracy: 0.4234

Epoch 02274: val_loss did not improve from 1.25648
Epoch 2275/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4299 - val_loss: 1.2665 - val_accuracy: 0.4139

Epoch 02275: val_loss did not improve from 1.25648
Epoch 2276/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4309 - val_loss: 1.2594 - val_accuracy: 0.4226

Epoch 02276: val_loss did not improve from 1.25648
Epoch 2277/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4348 - val_loss: 1.2566 - val_accuracy: 0.4195

Epoch 02277: val_loss did not improve from 1.25648
Epoch 2278/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4316 - val_loss: 1.2648 - val_accuracy: 0.4091

Epoch 02278: val_loss did not improve from 1.25648
Epoch 2279/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4325 - val_loss: 1.2678 - val_accuracy: 0.4155

Epoch 02279: val_loss did not improve from 1.25648
Epoch 2280/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4322 - val_loss: 1.2639 - val_accuracy: 0.4211

Epoch 02280: val_loss did not improve from 1.25648
Epoch 2281/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4303 - val_loss: 1.2554 - val_accuracy: 0.4187

Epoch 02281: val_loss improved from 1.25648 to 1.25539, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2282/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4325 - val_loss: 1.2574 - val_accuracy: 0.4219

Epoch 02282: val_loss did not improve from 1.25539
Epoch 2283/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4281 - val_loss: 1.2640 - val_accuracy: 0.4163

Epoch 02283: val_loss did not improve from 1.25539
Epoch 2284/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4334 - val_loss: 1.2585 - val_accuracy: 0.4394

Epoch 02284: val_loss did not improve from 1.25539
Epoch 2285/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4295 - val_loss: 1.2585 - val_accuracy: 0.4250

Epoch 02285: val_loss did not improve from 1.25539
Epoch 2286/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4243 - val_loss: 1.2637 - val_accuracy: 0.4219

Epoch 02286: val_loss did not improve from 1.25539
Epoch 2287/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4301 - val_loss: 1.2833 - val_accuracy: 0.4091

Epoch 02287: val_loss did not improve from 1.25539
Epoch 2288/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4289 - val_loss: 1.2602 - val_accuracy: 0.4266

Epoch 02288: val_loss did not improve from 1.25539
Epoch 2289/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4323 - val_loss: 1.2579 - val_accuracy: 0.4354

Epoch 02289: val_loss did not improve from 1.25539
Epoch 2290/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4300 - val_loss: 1.2596 - val_accuracy: 0.4242

Epoch 02290: val_loss did not improve from 1.25539
Epoch 2291/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4331 - val_loss: 1.2707 - val_accuracy: 0.4203

Epoch 02291: val_loss did not improve from 1.25539
Epoch 2292/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4337 - val_loss: 1.2603 - val_accuracy: 0.4298

Epoch 02292: val_loss did not improve from 1.25539
Epoch 2293/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4326 - val_loss: 1.2631 - val_accuracy: 0.4139

Epoch 02293: val_loss did not improve from 1.25539
Epoch 2294/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4288 - val_loss: 1.2586 - val_accuracy: 0.4322

Epoch 02294: val_loss did not improve from 1.25539
Epoch 2295/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4318 - val_loss: 1.2595 - val_accuracy: 0.4203

Epoch 02295: val_loss did not improve from 1.25539
Epoch 2296/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4326 - val_loss: 1.2618 - val_accuracy: 0.4211

Epoch 02296: val_loss did not improve from 1.25539
Epoch 2297/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4291 - val_loss: 1.2632 - val_accuracy: 0.4163

Epoch 02297: val_loss did not improve from 1.25539
Epoch 2298/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4362 - val_loss: 1.2593 - val_accuracy: 0.4203

Epoch 02298: val_loss did not improve from 1.25539
Epoch 2299/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4319 - val_loss: 1.2816 - val_accuracy: 0.4083

Epoch 02299: val_loss did not improve from 1.25539
Epoch 2300/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4275 - val_loss: 1.2613 - val_accuracy: 0.4306

Epoch 02300: val_loss did not improve from 1.25539
Epoch 2301/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4348 - val_loss: 1.2596 - val_accuracy: 0.4290

Epoch 02301: val_loss did not improve from 1.25539
Epoch 2302/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4349 - val_loss: 1.2626 - val_accuracy: 0.4203

Epoch 02302: val_loss did not improve from 1.25539
Epoch 2303/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4339 - val_loss: 1.2679 - val_accuracy: 0.4107

Epoch 02303: val_loss did not improve from 1.25539
Epoch 2304/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4326 - val_loss: 1.2689 - val_accuracy: 0.4115

Epoch 02304: val_loss did not improve from 1.25539
Epoch 2305/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4281 - val_loss: 1.2603 - val_accuracy: 0.4282

Epoch 02305: val_loss did not improve from 1.25539
Epoch 2306/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4318 - val_loss: 1.2575 - val_accuracy: 0.4330

Epoch 02306: val_loss did not improve from 1.25539
Epoch 2307/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4350 - val_loss: 1.2646 - val_accuracy: 0.4107

Epoch 02307: val_loss did not improve from 1.25539
Epoch 2308/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4302 - val_loss: 1.2602 - val_accuracy: 0.4195

Epoch 02308: val_loss did not improve from 1.25539
Epoch 2309/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4347 - val_loss: 1.2619 - val_accuracy: 0.4171

Epoch 02309: val_loss did not improve from 1.25539
Epoch 2310/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4357 - val_loss: 1.2578 - val_accuracy: 0.4298

Epoch 02310: val_loss did not improve from 1.25539
Epoch 2311/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4306 - val_loss: 1.2642 - val_accuracy: 0.4195

Epoch 02311: val_loss did not improve from 1.25539
Epoch 2312/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4311 - val_loss: 1.2604 - val_accuracy: 0.4203

Epoch 02312: val_loss did not improve from 1.25539
Epoch 2313/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4334 - val_loss: 1.2689 - val_accuracy: 0.4155

Epoch 02313: val_loss did not improve from 1.25539
Epoch 2314/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4320 - val_loss: 1.2602 - val_accuracy: 0.4211

Epoch 02314: val_loss did not improve from 1.25539
Epoch 2315/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4355 - val_loss: 1.2667 - val_accuracy: 0.4147

Epoch 02315: val_loss did not improve from 1.25539
Epoch 2316/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4323 - val_loss: 1.2569 - val_accuracy: 0.4250

Epoch 02316: val_loss did not improve from 1.25539
Epoch 2317/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4326 - val_loss: 1.2664 - val_accuracy: 0.4226

Epoch 02317: val_loss did not improve from 1.25539
Epoch 2318/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4312 - val_loss: 1.2591 - val_accuracy: 0.4298

Epoch 02318: val_loss did not improve from 1.25539
Epoch 2319/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4309 - val_loss: 1.2614 - val_accuracy: 0.4298

Epoch 02319: val_loss did not improve from 1.25539
Epoch 2320/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4353 - val_loss: 1.2664 - val_accuracy: 0.4179

Epoch 02320: val_loss did not improve from 1.25539
Epoch 2321/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4317 - val_loss: 1.2644 - val_accuracy: 0.4179

Epoch 02321: val_loss did not improve from 1.25539
Epoch 2322/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4350 - val_loss: 1.2585 - val_accuracy: 0.4250

Epoch 02322: val_loss did not improve from 1.25539
Epoch 2323/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4338 - val_loss: 1.2585 - val_accuracy: 0.4155

Epoch 02323: val_loss did not improve from 1.25539
Epoch 2324/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4326 - val_loss: 1.2565 - val_accuracy: 0.4219

Epoch 02324: val_loss did not improve from 1.25539
Epoch 2325/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4316 - val_loss: 1.2597 - val_accuracy: 0.4306

Epoch 02325: val_loss did not improve from 1.25539
Epoch 2326/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4325 - val_loss: 1.2641 - val_accuracy: 0.4234

Epoch 02326: val_loss did not improve from 1.25539
Epoch 2327/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4329 - val_loss: 1.2633 - val_accuracy: 0.4123

Epoch 02327: val_loss did not improve from 1.25539
Epoch 2328/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4334 - val_loss: 1.2648 - val_accuracy: 0.4187

Epoch 02328: val_loss did not improve from 1.25539
Epoch 2329/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4304 - val_loss: 1.2585 - val_accuracy: 0.4163

Epoch 02329: val_loss did not improve from 1.25539
Epoch 2330/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4308 - val_loss: 1.2558 - val_accuracy: 0.4258

Epoch 02330: val_loss did not improve from 1.25539
Epoch 2331/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4322 - val_loss: 1.2611 - val_accuracy: 0.4115

Epoch 02331: val_loss did not improve from 1.25539
Epoch 2332/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4317 - val_loss: 1.2690 - val_accuracy: 0.4203

Epoch 02332: val_loss did not improve from 1.25539
Epoch 2333/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4347 - val_loss: 1.2567 - val_accuracy: 0.4250

Epoch 02333: val_loss did not improve from 1.25539
Epoch 2334/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4306 - val_loss: 1.2579 - val_accuracy: 0.4274

Epoch 02334: val_loss did not improve from 1.25539
Epoch 2335/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4271 - val_loss: 1.2644 - val_accuracy: 0.4179

Epoch 02335: val_loss did not improve from 1.25539
Epoch 2336/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4286 - val_loss: 1.2601 - val_accuracy: 0.4211

Epoch 02336: val_loss did not improve from 1.25539
Epoch 2337/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4322 - val_loss: 1.2584 - val_accuracy: 0.4346

Epoch 02337: val_loss did not improve from 1.25539
Epoch 2338/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4323 - val_loss: 1.2565 - val_accuracy: 0.4434

Epoch 02338: val_loss did not improve from 1.25539
Epoch 2339/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4342 - val_loss: 1.2614 - val_accuracy: 0.4179

Epoch 02339: val_loss did not improve from 1.25539
Epoch 2340/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4335 - val_loss: 1.2642 - val_accuracy: 0.4187

Epoch 02340: val_loss did not improve from 1.25539
Epoch 2341/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4299 - val_loss: 1.2639 - val_accuracy: 0.4242

Epoch 02341: val_loss did not improve from 1.25539
Epoch 2342/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4316 - val_loss: 1.2556 - val_accuracy: 0.4330

Epoch 02342: val_loss did not improve from 1.25539
Epoch 2343/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4316 - val_loss: 1.2584 - val_accuracy: 0.4258

Epoch 02343: val_loss did not improve from 1.25539
Epoch 2344/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4318 - val_loss: 1.2673 - val_accuracy: 0.4219

Epoch 02344: val_loss did not improve from 1.25539
Epoch 2345/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4325 - val_loss: 1.2630 - val_accuracy: 0.4234

Epoch 02345: val_loss did not improve from 1.25539
Epoch 2346/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4342 - val_loss: 1.2584 - val_accuracy: 0.4274

Epoch 02346: val_loss did not improve from 1.25539
Epoch 2347/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4384 - val_loss: 1.2580 - val_accuracy: 0.4338

Epoch 02347: val_loss did not improve from 1.25539
Epoch 2348/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4291 - val_loss: 1.2587 - val_accuracy: 0.4322

Epoch 02348: val_loss did not improve from 1.25539
Epoch 2349/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4273 - val_loss: 1.2587 - val_accuracy: 0.4298

Epoch 02349: val_loss did not improve from 1.25539
Epoch 2350/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4340 - val_loss: 1.2586 - val_accuracy: 0.4171

Epoch 02350: val_loss did not improve from 1.25539
Epoch 2351/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4326 - val_loss: 1.2599 - val_accuracy: 0.4195

Epoch 02351: val_loss did not improve from 1.25539
Epoch 2352/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4328 - val_loss: 1.2581 - val_accuracy: 0.4298

Epoch 02352: val_loss did not improve from 1.25539
Epoch 2353/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4306 - val_loss: 1.2717 - val_accuracy: 0.4219

Epoch 02353: val_loss did not improve from 1.25539
Epoch 2354/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4300 - val_loss: 1.2687 - val_accuracy: 0.4187

Epoch 02354: val_loss did not improve from 1.25539
Epoch 2355/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4327 - val_loss: 1.2614 - val_accuracy: 0.4258

Epoch 02355: val_loss did not improve from 1.25539
Epoch 2356/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4328 - val_loss: 1.2603 - val_accuracy: 0.4378

Epoch 02356: val_loss did not improve from 1.25539
Epoch 2357/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4248 - val_loss: 1.2612 - val_accuracy: 0.4195

Epoch 02357: val_loss did not improve from 1.25539
Epoch 2358/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4291 - val_loss: 1.2742 - val_accuracy: 0.4155

Epoch 02358: val_loss did not improve from 1.25539
Epoch 2359/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4344 - val_loss: 1.2579 - val_accuracy: 0.4266

Epoch 02359: val_loss did not improve from 1.25539
Epoch 2360/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4342 - val_loss: 1.2605 - val_accuracy: 0.4250

Epoch 02360: val_loss did not improve from 1.25539
Epoch 2361/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4359 - val_loss: 1.2686 - val_accuracy: 0.4115

Epoch 02361: val_loss did not improve from 1.25539
Epoch 2362/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4335 - val_loss: 1.2599 - val_accuracy: 0.4123

Epoch 02362: val_loss did not improve from 1.25539
Epoch 2363/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4297 - val_loss: 1.2697 - val_accuracy: 0.4234

Epoch 02363: val_loss did not improve from 1.25539
Epoch 2364/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4333 - val_loss: 1.2582 - val_accuracy: 0.4282

Epoch 02364: val_loss did not improve from 1.25539
Epoch 2365/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4294 - val_loss: 1.2617 - val_accuracy: 0.4219

Epoch 02365: val_loss did not improve from 1.25539
Epoch 2366/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4334 - val_loss: 1.2768 - val_accuracy: 0.4163

Epoch 02366: val_loss did not improve from 1.25539
Epoch 2367/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4355 - val_loss: 1.2566 - val_accuracy: 0.4290

Epoch 02367: val_loss did not improve from 1.25539
Epoch 2368/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4305 - val_loss: 1.2601 - val_accuracy: 0.4266

Epoch 02368: val_loss did not improve from 1.25539
Epoch 2369/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4319 - val_loss: 1.2615 - val_accuracy: 0.4219

Epoch 02369: val_loss did not improve from 1.25539
Epoch 2370/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4358 - val_loss: 1.2615 - val_accuracy: 0.4274

Epoch 02370: val_loss did not improve from 1.25539
Epoch 2371/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4334 - val_loss: 1.2690 - val_accuracy: 0.4107

Epoch 02371: val_loss did not improve from 1.25539
Epoch 2372/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4325 - val_loss: 1.2596 - val_accuracy: 0.4322

Epoch 02372: val_loss did not improve from 1.25539
Epoch 2373/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4349 - val_loss: 1.2582 - val_accuracy: 0.4211

Epoch 02373: val_loss did not improve from 1.25539
Epoch 2374/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4297 - val_loss: 1.2602 - val_accuracy: 0.4195

Epoch 02374: val_loss did not improve from 1.25539
Epoch 2375/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4351 - val_loss: 1.2577 - val_accuracy: 0.4346

Epoch 02375: val_loss did not improve from 1.25539
Epoch 2376/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4340 - val_loss: 1.2583 - val_accuracy: 0.4266

Epoch 02376: val_loss did not improve from 1.25539
Epoch 2377/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4353 - val_loss: 1.2617 - val_accuracy: 0.4147

Epoch 02377: val_loss did not improve from 1.25539
Epoch 2378/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4309 - val_loss: 1.2635 - val_accuracy: 0.4171

Epoch 02378: val_loss did not improve from 1.25539
Epoch 2379/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4289 - val_loss: 1.2626 - val_accuracy: 0.4171

Epoch 02379: val_loss did not improve from 1.25539
Epoch 2380/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4329 - val_loss: 1.2622 - val_accuracy: 0.4219

Epoch 02380: val_loss did not improve from 1.25539
Epoch 2381/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4334 - val_loss: 1.2561 - val_accuracy: 0.4306

Epoch 02381: val_loss did not improve from 1.25539
Epoch 2382/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4328 - val_loss: 1.2571 - val_accuracy: 0.4242

Epoch 02382: val_loss did not improve from 1.25539
Epoch 2383/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4363 - val_loss: 1.2560 - val_accuracy: 0.4211

Epoch 02383: val_loss did not improve from 1.25539
Epoch 2384/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4361 - val_loss: 1.2647 - val_accuracy: 0.4203

Epoch 02384: val_loss did not improve from 1.25539
Epoch 2385/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4275 - val_loss: 1.2580 - val_accuracy: 0.4234

Epoch 02385: val_loss did not improve from 1.25539
Epoch 2386/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4331 - val_loss: 1.2738 - val_accuracy: 0.4179

Epoch 02386: val_loss did not improve from 1.25539
Epoch 2387/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4355 - val_loss: 1.2604 - val_accuracy: 0.4195

Epoch 02387: val_loss did not improve from 1.25539
Epoch 2388/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4347 - val_loss: 1.2601 - val_accuracy: 0.4242

Epoch 02388: val_loss did not improve from 1.25539
Epoch 2389/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4262 - val_loss: 1.2613 - val_accuracy: 0.4242

Epoch 02389: val_loss did not improve from 1.25539
Epoch 2390/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4314 - val_loss: 1.2773 - val_accuracy: 0.4195

Epoch 02390: val_loss did not improve from 1.25539
Epoch 2391/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4306 - val_loss: 1.2654 - val_accuracy: 0.4147

Epoch 02391: val_loss did not improve from 1.25539
Epoch 2392/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4323 - val_loss: 1.2610 - val_accuracy: 0.4219

Epoch 02392: val_loss did not improve from 1.25539
Epoch 2393/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4361 - val_loss: 1.2580 - val_accuracy: 0.4306

Epoch 02393: val_loss did not improve from 1.25539
Epoch 2394/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4349 - val_loss: 1.2670 - val_accuracy: 0.4123

Epoch 02394: val_loss did not improve from 1.25539
Epoch 2395/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4308 - val_loss: 1.2605 - val_accuracy: 0.4290

Epoch 02395: val_loss did not improve from 1.25539
Epoch 2396/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4332 - val_loss: 1.2560 - val_accuracy: 0.4274

Epoch 02396: val_loss did not improve from 1.25539
Epoch 2397/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4337 - val_loss: 1.2536 - val_accuracy: 0.4250

Epoch 02397: val_loss improved from 1.25539 to 1.25356, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2398/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4356 - val_loss: 1.2561 - val_accuracy: 0.4266

Epoch 02398: val_loss did not improve from 1.25356
Epoch 2399/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4288 - val_loss: 1.2648 - val_accuracy: 0.4250

Epoch 02399: val_loss did not improve from 1.25356
Epoch 2400/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4291 - val_loss: 1.2712 - val_accuracy: 0.4211

Epoch 02400: val_loss did not improve from 1.25356
Epoch 2401/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4313 - val_loss: 1.2592 - val_accuracy: 0.4123

Epoch 02401: val_loss did not improve from 1.25356
Epoch 2402/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4292 - val_loss: 1.2576 - val_accuracy: 0.4195

Epoch 02402: val_loss did not improve from 1.25356
Epoch 2403/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4328 - val_loss: 1.2609 - val_accuracy: 0.4266

Epoch 02403: val_loss did not improve from 1.25356
Epoch 2404/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4343 - val_loss: 1.2560 - val_accuracy: 0.4282

Epoch 02404: val_loss did not improve from 1.25356
Epoch 2405/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4349 - val_loss: 1.2571 - val_accuracy: 0.4274

Epoch 02405: val_loss did not improve from 1.25356
Epoch 2406/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4331 - val_loss: 1.2610 - val_accuracy: 0.4147

Epoch 02406: val_loss did not improve from 1.25356
Epoch 2407/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4311 - val_loss: 1.2584 - val_accuracy: 0.4219

Epoch 02407: val_loss did not improve from 1.25356
Epoch 2408/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4307 - val_loss: 1.2599 - val_accuracy: 0.4187

Epoch 02408: val_loss did not improve from 1.25356
Epoch 2409/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4324 - val_loss: 1.2599 - val_accuracy: 0.4226

Epoch 02409: val_loss did not improve from 1.25356
Epoch 2410/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4355 - val_loss: 1.2558 - val_accuracy: 0.4234

Epoch 02410: val_loss did not improve from 1.25356
Epoch 2411/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4312 - val_loss: 1.2625 - val_accuracy: 0.4195

Epoch 02411: val_loss did not improve from 1.25356
Epoch 2412/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4324 - val_loss: 1.2576 - val_accuracy: 0.4266

Epoch 02412: val_loss did not improve from 1.25356
Epoch 2413/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4338 - val_loss: 1.2640 - val_accuracy: 0.4155

Epoch 02413: val_loss did not improve from 1.25356
Epoch 2414/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4334 - val_loss: 1.2660 - val_accuracy: 0.4242

Epoch 02414: val_loss did not improve from 1.25356
Epoch 2415/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4338 - val_loss: 1.2562 - val_accuracy: 0.4362

Epoch 02415: val_loss did not improve from 1.25356
Epoch 2416/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4290 - val_loss: 1.2712 - val_accuracy: 0.4067

Epoch 02416: val_loss did not improve from 1.25356
Epoch 2417/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4355 - val_loss: 1.2561 - val_accuracy: 0.4266

Epoch 02417: val_loss did not improve from 1.25356
Epoch 2418/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4371 - val_loss: 1.2631 - val_accuracy: 0.4115

Epoch 02418: val_loss did not improve from 1.25356
Epoch 2419/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4278 - val_loss: 1.2574 - val_accuracy: 0.4362

Epoch 02419: val_loss did not improve from 1.25356
Epoch 2420/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4345 - val_loss: 1.2568 - val_accuracy: 0.4282

Epoch 02420: val_loss did not improve from 1.25356
Epoch 2421/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4342 - val_loss: 1.2592 - val_accuracy: 0.4195

Epoch 02421: val_loss did not improve from 1.25356
Epoch 2422/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4242 - val_loss: 1.2576 - val_accuracy: 0.4123

Epoch 02422: val_loss did not improve from 1.25356
Epoch 2423/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4309 - val_loss: 1.2571 - val_accuracy: 0.4242

Epoch 02423: val_loss did not improve from 1.25356
Epoch 2424/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4340 - val_loss: 1.2584 - val_accuracy: 0.4171

Epoch 02424: val_loss did not improve from 1.25356
Epoch 2425/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4294 - val_loss: 1.2619 - val_accuracy: 0.4203

Epoch 02425: val_loss did not improve from 1.25356
Epoch 2426/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4318 - val_loss: 1.2636 - val_accuracy: 0.4219

Epoch 02426: val_loss did not improve from 1.25356
Epoch 2427/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4340 - val_loss: 1.2624 - val_accuracy: 0.4203

Epoch 02427: val_loss did not improve from 1.25356
Epoch 2428/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4343 - val_loss: 1.2610 - val_accuracy: 0.4179

Epoch 02428: val_loss did not improve from 1.25356
Epoch 2429/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4374 - val_loss: 1.2618 - val_accuracy: 0.4274

Epoch 02429: val_loss did not improve from 1.25356
Epoch 2430/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4331 - val_loss: 1.2646 - val_accuracy: 0.4171

Epoch 02430: val_loss did not improve from 1.25356
Epoch 2431/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4345 - val_loss: 1.2619 - val_accuracy: 0.4274

Epoch 02431: val_loss did not improve from 1.25356
Epoch 2432/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4346 - val_loss: 1.2621 - val_accuracy: 0.4242

Epoch 02432: val_loss did not improve from 1.25356
Epoch 2433/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4310 - val_loss: 1.2568 - val_accuracy: 0.4338

Epoch 02433: val_loss did not improve from 1.25356
Epoch 2434/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4346 - val_loss: 1.2576 - val_accuracy: 0.4274

Epoch 02434: val_loss did not improve from 1.25356
Epoch 2435/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4342 - val_loss: 1.2717 - val_accuracy: 0.4123

Epoch 02435: val_loss did not improve from 1.25356
Epoch 2436/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4331 - val_loss: 1.2559 - val_accuracy: 0.4314

Epoch 02436: val_loss did not improve from 1.25356
Epoch 2437/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4363 - val_loss: 1.2591 - val_accuracy: 0.4282

Epoch 02437: val_loss did not improve from 1.25356
Epoch 2438/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4346 - val_loss: 1.2670 - val_accuracy: 0.4107

Epoch 02438: val_loss did not improve from 1.25356
Epoch 2439/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4349 - val_loss: 1.2602 - val_accuracy: 0.4226

Epoch 02439: val_loss did not improve from 1.25356
Epoch 2440/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4314 - val_loss: 1.2620 - val_accuracy: 0.4394

Epoch 02440: val_loss did not improve from 1.25356
Epoch 2441/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4299 - val_loss: 1.2600 - val_accuracy: 0.4266

Epoch 02441: val_loss did not improve from 1.25356
Epoch 2442/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4315 - val_loss: 1.2681 - val_accuracy: 0.4171

Epoch 02442: val_loss did not improve from 1.25356
Epoch 2443/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4374 - val_loss: 1.2687 - val_accuracy: 0.4163

Epoch 02443: val_loss did not improve from 1.25356
Epoch 2444/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4312 - val_loss: 1.2581 - val_accuracy: 0.4155

Epoch 02444: val_loss did not improve from 1.25356
Epoch 2445/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4342 - val_loss: 1.2575 - val_accuracy: 0.4226

Epoch 02445: val_loss did not improve from 1.25356
Epoch 2446/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4328 - val_loss: 1.2636 - val_accuracy: 0.4171

Epoch 02446: val_loss did not improve from 1.25356
Epoch 2447/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4322 - val_loss: 1.2700 - val_accuracy: 0.4219

Epoch 02447: val_loss did not improve from 1.25356
Epoch 2448/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4336 - val_loss: 1.2584 - val_accuracy: 0.4298

Epoch 02448: val_loss did not improve from 1.25356
Epoch 2449/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4326 - val_loss: 1.2582 - val_accuracy: 0.4266

Epoch 02449: val_loss did not improve from 1.25356
Epoch 2450/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4349 - val_loss: 1.2625 - val_accuracy: 0.4147

Epoch 02450: val_loss did not improve from 1.25356
Epoch 2451/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4325 - val_loss: 1.2586 - val_accuracy: 0.4226

Epoch 02451: val_loss did not improve from 1.25356
Epoch 2452/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4323 - val_loss: 1.2683 - val_accuracy: 0.4258

Epoch 02452: val_loss did not improve from 1.25356
Epoch 2453/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4349 - val_loss: 1.2612 - val_accuracy: 0.4258

Epoch 02453: val_loss did not improve from 1.25356
Epoch 2454/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4334 - val_loss: 1.2556 - val_accuracy: 0.4266

Epoch 02454: val_loss did not improve from 1.25356
Epoch 2455/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4350 - val_loss: 1.2633 - val_accuracy: 0.4242

Epoch 02455: val_loss did not improve from 1.25356
Epoch 2456/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4349 - val_loss: 1.2596 - val_accuracy: 0.4266

Epoch 02456: val_loss did not improve from 1.25356
Epoch 2457/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4351 - val_loss: 1.2638 - val_accuracy: 0.4139

Epoch 02457: val_loss did not improve from 1.25356
Epoch 2458/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4318 - val_loss: 1.2587 - val_accuracy: 0.4219

Epoch 02458: val_loss did not improve from 1.25356
Epoch 2459/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4343 - val_loss: 1.2602 - val_accuracy: 0.4147

Epoch 02459: val_loss did not improve from 1.25356
Epoch 2460/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4303 - val_loss: 1.2594 - val_accuracy: 0.4298

Epoch 02460: val_loss did not improve from 1.25356
Epoch 2461/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4322 - val_loss: 1.2562 - val_accuracy: 0.4386

Epoch 02461: val_loss did not improve from 1.25356
Epoch 2462/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4346 - val_loss: 1.2583 - val_accuracy: 0.4386

Epoch 02462: val_loss did not improve from 1.25356
Epoch 2463/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4322 - val_loss: 1.2576 - val_accuracy: 0.4298

Epoch 02463: val_loss did not improve from 1.25356
Epoch 2464/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4357 - val_loss: 1.2578 - val_accuracy: 0.4171

Epoch 02464: val_loss did not improve from 1.25356
Epoch 2465/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4312 - val_loss: 1.2638 - val_accuracy: 0.4242

Epoch 02465: val_loss did not improve from 1.25356
Epoch 2466/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4326 - val_loss: 1.2673 - val_accuracy: 0.4123

Epoch 02466: val_loss did not improve from 1.25356
Epoch 2467/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4319 - val_loss: 1.2718 - val_accuracy: 0.4203

Epoch 02467: val_loss did not improve from 1.25356
Epoch 2468/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4305 - val_loss: 1.2556 - val_accuracy: 0.4338

Epoch 02468: val_loss did not improve from 1.25356
Epoch 2469/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4324 - val_loss: 1.2572 - val_accuracy: 0.4442

Epoch 02469: val_loss did not improve from 1.25356
Epoch 2470/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4306 - val_loss: 1.2626 - val_accuracy: 0.4179

Epoch 02470: val_loss did not improve from 1.25356
Epoch 2471/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4322 - val_loss: 1.2677 - val_accuracy: 0.4163

Epoch 02471: val_loss did not improve from 1.25356
Epoch 2472/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4358 - val_loss: 1.2597 - val_accuracy: 0.4242

Epoch 02472: val_loss did not improve from 1.25356
Epoch 2473/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4385 - val_loss: 1.2604 - val_accuracy: 0.4226

Epoch 02473: val_loss did not improve from 1.25356
Epoch 2474/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4366 - val_loss: 1.2672 - val_accuracy: 0.4115

Epoch 02474: val_loss did not improve from 1.25356
Epoch 2475/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4363 - val_loss: 1.2551 - val_accuracy: 0.4306

Epoch 02475: val_loss did not improve from 1.25356
Epoch 2476/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4353 - val_loss: 1.2557 - val_accuracy: 0.4258

Epoch 02476: val_loss did not improve from 1.25356
Epoch 2477/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4322 - val_loss: 1.2587 - val_accuracy: 0.4242

Epoch 02477: val_loss did not improve from 1.25356
Epoch 2478/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4314 - val_loss: 1.2603 - val_accuracy: 0.4242

Epoch 02478: val_loss did not improve from 1.25356
Epoch 2479/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4340 - val_loss: 1.2634 - val_accuracy: 0.4219

Epoch 02479: val_loss did not improve from 1.25356
Epoch 2480/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4347 - val_loss: 1.2610 - val_accuracy: 0.4242

Epoch 02480: val_loss did not improve from 1.25356
Epoch 2481/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4330 - val_loss: 1.2551 - val_accuracy: 0.4402

Epoch 02481: val_loss did not improve from 1.25356
Epoch 2482/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4285 - val_loss: 1.2635 - val_accuracy: 0.4203

Epoch 02482: val_loss did not improve from 1.25356
Epoch 2483/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4356 - val_loss: 1.2592 - val_accuracy: 0.4226

Epoch 02483: val_loss did not improve from 1.25356
Epoch 2484/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4368 - val_loss: 1.2628 - val_accuracy: 0.4187

Epoch 02484: val_loss did not improve from 1.25356
Epoch 2485/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4351 - val_loss: 1.2684 - val_accuracy: 0.4139

Epoch 02485: val_loss did not improve from 1.25356
Epoch 2486/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4336 - val_loss: 1.2570 - val_accuracy: 0.4370

Epoch 02486: val_loss did not improve from 1.25356
Epoch 2487/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4337 - val_loss: 1.2572 - val_accuracy: 0.4274

Epoch 02487: val_loss did not improve from 1.25356
Epoch 2488/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4352 - val_loss: 1.2593 - val_accuracy: 0.4171

Epoch 02488: val_loss did not improve from 1.25356
Epoch 2489/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4370 - val_loss: 1.2661 - val_accuracy: 0.4219

Epoch 02489: val_loss did not improve from 1.25356
Epoch 2490/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4368 - val_loss: 1.2648 - val_accuracy: 0.4163

Epoch 02490: val_loss did not improve from 1.25356
Epoch 2491/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4348 - val_loss: 1.2594 - val_accuracy: 0.4346

Epoch 02491: val_loss did not improve from 1.25356
Epoch 2492/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4342 - val_loss: 1.2606 - val_accuracy: 0.4203

Epoch 02492: val_loss did not improve from 1.25356
Epoch 2493/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4353 - val_loss: 1.2592 - val_accuracy: 0.4171

Epoch 02493: val_loss did not improve from 1.25356
Epoch 2494/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4349 - val_loss: 1.2580 - val_accuracy: 0.4187

Epoch 02494: val_loss did not improve from 1.25356
Epoch 2495/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4350 - val_loss: 1.2691 - val_accuracy: 0.4139

Epoch 02495: val_loss did not improve from 1.25356
Epoch 2496/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4334 - val_loss: 1.2604 - val_accuracy: 0.4234

Epoch 02496: val_loss did not improve from 1.25356
Epoch 2497/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4329 - val_loss: 1.2613 - val_accuracy: 0.4179

Epoch 02497: val_loss did not improve from 1.25356
Epoch 2498/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4314 - val_loss: 1.2587 - val_accuracy: 0.4179

Epoch 02498: val_loss did not improve from 1.25356
Epoch 2499/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4318 - val_loss: 1.2565 - val_accuracy: 0.4226

Epoch 02499: val_loss did not improve from 1.25356
Epoch 2500/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4373 - val_loss: 1.2578 - val_accuracy: 0.4314

Epoch 02500: val_loss did not improve from 1.25356
Epoch 2501/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4342 - val_loss: 1.2581 - val_accuracy: 0.4250

Epoch 02501: val_loss did not improve from 1.25356
Epoch 2502/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4326 - val_loss: 1.2561 - val_accuracy: 0.4330

Epoch 02502: val_loss did not improve from 1.25356
Epoch 2503/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4357 - val_loss: 1.2570 - val_accuracy: 0.4203

Epoch 02503: val_loss did not improve from 1.25356
Epoch 2504/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4287 - val_loss: 1.2908 - val_accuracy: 0.4115

Epoch 02504: val_loss did not improve from 1.25356
Epoch 2505/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4261 - val_loss: 1.2688 - val_accuracy: 0.4179

Epoch 02505: val_loss did not improve from 1.25356
Epoch 2506/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4318 - val_loss: 1.2591 - val_accuracy: 0.4290

Epoch 02506: val_loss did not improve from 1.25356
Epoch 2507/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4357 - val_loss: 1.2548 - val_accuracy: 0.4314

Epoch 02507: val_loss did not improve from 1.25356
Epoch 2508/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4328 - val_loss: 1.2543 - val_accuracy: 0.4314

Epoch 02508: val_loss did not improve from 1.25356
Epoch 2509/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4326 - val_loss: 1.2639 - val_accuracy: 0.4195

Epoch 02509: val_loss did not improve from 1.25356
Epoch 2510/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4321 - val_loss: 1.2667 - val_accuracy: 0.4211

Epoch 02510: val_loss did not improve from 1.25356
Epoch 2511/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4326 - val_loss: 1.2649 - val_accuracy: 0.4147

Epoch 02511: val_loss did not improve from 1.25356
Epoch 2512/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4338 - val_loss: 1.2634 - val_accuracy: 0.4211

Epoch 02512: val_loss did not improve from 1.25356
Epoch 2513/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4291 - val_loss: 1.2566 - val_accuracy: 0.4219

Epoch 02513: val_loss did not improve from 1.25356
Epoch 2514/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4342 - val_loss: 1.2548 - val_accuracy: 0.4258

Epoch 02514: val_loss did not improve from 1.25356
Epoch 2515/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4294 - val_loss: 1.2627 - val_accuracy: 0.4226

Epoch 02515: val_loss did not improve from 1.25356
Epoch 2516/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4347 - val_loss: 1.2822 - val_accuracy: 0.4139

Epoch 02516: val_loss did not improve from 1.25356
Epoch 2517/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4269 - val_loss: 1.2549 - val_accuracy: 0.4219

Epoch 02517: val_loss did not improve from 1.25356
Epoch 2518/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4314 - val_loss: 1.2549 - val_accuracy: 0.4290

Epoch 02518: val_loss did not improve from 1.25356
Epoch 2519/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4349 - val_loss: 1.2657 - val_accuracy: 0.4107

Epoch 02519: val_loss did not improve from 1.25356
Epoch 2520/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4304 - val_loss: 1.2635 - val_accuracy: 0.4163

Epoch 02520: val_loss did not improve from 1.25356
Epoch 2521/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4324 - val_loss: 1.2579 - val_accuracy: 0.4266

Epoch 02521: val_loss did not improve from 1.25356
Epoch 2522/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4279 - val_loss: 1.2594 - val_accuracy: 0.4290

Epoch 02522: val_loss did not improve from 1.25356
Epoch 2523/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4328 - val_loss: 1.2552 - val_accuracy: 0.4410

Epoch 02523: val_loss did not improve from 1.25356
Epoch 2524/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4372 - val_loss: 1.2612 - val_accuracy: 0.4203

Epoch 02524: val_loss did not improve from 1.25356
Epoch 2525/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4302 - val_loss: 1.2559 - val_accuracy: 0.4226

Epoch 02525: val_loss did not improve from 1.25356
Epoch 2526/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4358 - val_loss: 1.2587 - val_accuracy: 0.4330

Epoch 02526: val_loss did not improve from 1.25356
Epoch 2527/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4331 - val_loss: 1.2596 - val_accuracy: 0.4234

Epoch 02527: val_loss did not improve from 1.25356
Epoch 2528/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4357 - val_loss: 1.2546 - val_accuracy: 0.4187

Epoch 02528: val_loss did not improve from 1.25356
Epoch 2529/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4377 - val_loss: 1.2591 - val_accuracy: 0.4179

Epoch 02529: val_loss did not improve from 1.25356
Epoch 2530/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4301 - val_loss: 1.2758 - val_accuracy: 0.4195

Epoch 02530: val_loss did not improve from 1.25356
Epoch 2531/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4337 - val_loss: 1.2577 - val_accuracy: 0.4226

Epoch 02531: val_loss did not improve from 1.25356
Epoch 2532/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4361 - val_loss: 1.2638 - val_accuracy: 0.4131

Epoch 02532: val_loss did not improve from 1.25356
Epoch 2533/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4328 - val_loss: 1.2591 - val_accuracy: 0.4155

Epoch 02533: val_loss did not improve from 1.25356
Epoch 2534/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4377 - val_loss: 1.2629 - val_accuracy: 0.4187

Epoch 02534: val_loss did not improve from 1.25356
Epoch 2535/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4331 - val_loss: 1.2561 - val_accuracy: 0.4282

Epoch 02535: val_loss did not improve from 1.25356
Epoch 2536/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4317 - val_loss: 1.2634 - val_accuracy: 0.4179

Epoch 02536: val_loss did not improve from 1.25356
Epoch 2537/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4318 - val_loss: 1.2604 - val_accuracy: 0.4187

Epoch 02537: val_loss did not improve from 1.25356
Epoch 2538/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4294 - val_loss: 1.2577 - val_accuracy: 0.4314

Epoch 02538: val_loss did not improve from 1.25356
Epoch 2539/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4320 - val_loss: 1.2539 - val_accuracy: 0.4258

Epoch 02539: val_loss did not improve from 1.25356
Epoch 2540/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4312 - val_loss: 1.2591 - val_accuracy: 0.4107

Epoch 02540: val_loss did not improve from 1.25356
Epoch 2541/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4311 - val_loss: 1.2609 - val_accuracy: 0.4219

Epoch 02541: val_loss did not improve from 1.25356
Epoch 2542/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4346 - val_loss: 1.2573 - val_accuracy: 0.4338

Epoch 02542: val_loss did not improve from 1.25356
Epoch 2543/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4319 - val_loss: 1.2577 - val_accuracy: 0.4306

Epoch 02543: val_loss did not improve from 1.25356
Epoch 2544/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4356 - val_loss: 1.2603 - val_accuracy: 0.4219

Epoch 02544: val_loss did not improve from 1.25356
Epoch 2545/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4304 - val_loss: 1.2627 - val_accuracy: 0.4211

Epoch 02545: val_loss did not improve from 1.25356
Epoch 2546/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4358 - val_loss: 1.2592 - val_accuracy: 0.4155

Epoch 02546: val_loss did not improve from 1.25356
Epoch 2547/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4387 - val_loss: 1.2580 - val_accuracy: 0.4346

Epoch 02547: val_loss did not improve from 1.25356
Epoch 2548/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4334 - val_loss: 1.2668 - val_accuracy: 0.4147

Epoch 02548: val_loss did not improve from 1.25356
Epoch 2549/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4347 - val_loss: 1.2587 - val_accuracy: 0.4203

Epoch 02549: val_loss did not improve from 1.25356
Epoch 2550/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4324 - val_loss: 1.2566 - val_accuracy: 0.4195

Epoch 02550: val_loss did not improve from 1.25356
Epoch 2551/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4303 - val_loss: 1.2606 - val_accuracy: 0.4187

Epoch 02551: val_loss did not improve from 1.25356
Epoch 2552/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4330 - val_loss: 1.2566 - val_accuracy: 0.4250

Epoch 02552: val_loss did not improve from 1.25356
Epoch 2553/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4327 - val_loss: 1.2568 - val_accuracy: 0.4266

Epoch 02553: val_loss did not improve from 1.25356
Epoch 2554/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4324 - val_loss: 1.2716 - val_accuracy: 0.4147

Epoch 02554: val_loss did not improve from 1.25356
Epoch 2555/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4311 - val_loss: 1.2571 - val_accuracy: 0.4219

Epoch 02555: val_loss did not improve from 1.25356
Epoch 2556/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4347 - val_loss: 1.2633 - val_accuracy: 0.4234

Epoch 02556: val_loss did not improve from 1.25356
Epoch 2557/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4362 - val_loss: 1.2547 - val_accuracy: 0.4219

Epoch 02557: val_loss did not improve from 1.25356
Epoch 2558/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4328 - val_loss: 1.2560 - val_accuracy: 0.4179

Epoch 02558: val_loss did not improve from 1.25356
Epoch 2559/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4328 - val_loss: 1.2561 - val_accuracy: 0.4410

Epoch 02559: val_loss did not improve from 1.25356
Epoch 2560/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4324 - val_loss: 1.2632 - val_accuracy: 0.4226

Epoch 02560: val_loss did not improve from 1.25356
Epoch 2561/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4353 - val_loss: 1.2779 - val_accuracy: 0.4195

Epoch 02561: val_loss did not improve from 1.25356
Epoch 2562/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4300 - val_loss: 1.2571 - val_accuracy: 0.4378

Epoch 02562: val_loss did not improve from 1.25356
Epoch 2563/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4330 - val_loss: 1.2547 - val_accuracy: 0.4386

Epoch 02563: val_loss did not improve from 1.25356
Epoch 2564/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4366 - val_loss: 1.2560 - val_accuracy: 0.4378

Epoch 02564: val_loss did not improve from 1.25356
Epoch 2565/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4312 - val_loss: 1.2568 - val_accuracy: 0.4282

Epoch 02565: val_loss did not improve from 1.25356
Epoch 2566/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4286 - val_loss: 1.2631 - val_accuracy: 0.4131

Epoch 02566: val_loss did not improve from 1.25356
Epoch 2567/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4348 - val_loss: 1.2697 - val_accuracy: 0.4107

Epoch 02567: val_loss did not improve from 1.25356
Epoch 2568/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4350 - val_loss: 1.2650 - val_accuracy: 0.4290

Epoch 02568: val_loss did not improve from 1.25356
Epoch 2569/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4318 - val_loss: 1.2614 - val_accuracy: 0.4163

Epoch 02569: val_loss did not improve from 1.25356
Epoch 2570/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4360 - val_loss: 1.2530 - val_accuracy: 0.4314

Epoch 02570: val_loss improved from 1.25356 to 1.25298, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2571/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4364 - val_loss: 1.2552 - val_accuracy: 0.4266

Epoch 02571: val_loss did not improve from 1.25298
Epoch 2572/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4312 - val_loss: 1.2730 - val_accuracy: 0.4139

Epoch 02572: val_loss did not improve from 1.25298
Epoch 2573/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4311 - val_loss: 1.2857 - val_accuracy: 0.4091

Epoch 02573: val_loss did not improve from 1.25298
Epoch 2574/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4282 - val_loss: 1.2542 - val_accuracy: 0.4346

Epoch 02574: val_loss did not improve from 1.25298
Epoch 2575/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4311 - val_loss: 1.2551 - val_accuracy: 0.4346

Epoch 02575: val_loss did not improve from 1.25298
Epoch 2576/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4338 - val_loss: 1.2547 - val_accuracy: 0.4274

Epoch 02576: val_loss did not improve from 1.25298
Epoch 2577/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4351 - val_loss: 1.2605 - val_accuracy: 0.4298

Epoch 02577: val_loss did not improve from 1.25298
Epoch 2578/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4341 - val_loss: 1.2537 - val_accuracy: 0.4330

Epoch 02578: val_loss did not improve from 1.25298
Epoch 2579/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4288 - val_loss: 1.2655 - val_accuracy: 0.4171

Epoch 02579: val_loss did not improve from 1.25298
Epoch 2580/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4341 - val_loss: 1.2679 - val_accuracy: 0.4187

Epoch 02580: val_loss did not improve from 1.25298
Epoch 2581/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4365 - val_loss: 1.2692 - val_accuracy: 0.4242

Epoch 02581: val_loss did not improve from 1.25298
Epoch 2582/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4345 - val_loss: 1.2573 - val_accuracy: 0.4298

Epoch 02582: val_loss did not improve from 1.25298
Epoch 2583/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4377 - val_loss: 1.2547 - val_accuracy: 0.4211

Epoch 02583: val_loss did not improve from 1.25298
Epoch 2584/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4339 - val_loss: 1.2734 - val_accuracy: 0.4091

Epoch 02584: val_loss did not improve from 1.25298
Epoch 2585/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4316 - val_loss: 1.2556 - val_accuracy: 0.4378

Epoch 02585: val_loss did not improve from 1.25298
Epoch 2586/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4359 - val_loss: 1.2611 - val_accuracy: 0.4250

Epoch 02586: val_loss did not improve from 1.25298
Epoch 2587/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4300 - val_loss: 1.2578 - val_accuracy: 0.4338

Epoch 02587: val_loss did not improve from 1.25298
Epoch 2588/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4358 - val_loss: 1.2622 - val_accuracy: 0.4179

Epoch 02588: val_loss did not improve from 1.25298
Epoch 2589/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4347 - val_loss: 1.2602 - val_accuracy: 0.4314

Epoch 02589: val_loss did not improve from 1.25298
Epoch 2590/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4316 - val_loss: 1.2613 - val_accuracy: 0.4179

Epoch 02590: val_loss did not improve from 1.25298
Epoch 2591/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4339 - val_loss: 1.2587 - val_accuracy: 0.4163

Epoch 02591: val_loss did not improve from 1.25298
Epoch 2592/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4373 - val_loss: 1.2644 - val_accuracy: 0.4203

Epoch 02592: val_loss did not improve from 1.25298
Epoch 2593/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4322 - val_loss: 1.2592 - val_accuracy: 0.4274

Epoch 02593: val_loss did not improve from 1.25298
Epoch 2594/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4329 - val_loss: 1.2578 - val_accuracy: 0.4362

Epoch 02594: val_loss did not improve from 1.25298
Epoch 2595/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4326 - val_loss: 1.2647 - val_accuracy: 0.4187

Epoch 02595: val_loss did not improve from 1.25298
Epoch 2596/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4342 - val_loss: 1.2561 - val_accuracy: 0.4402

Epoch 02596: val_loss did not improve from 1.25298
Epoch 2597/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4362 - val_loss: 1.2579 - val_accuracy: 0.4226

Epoch 02597: val_loss did not improve from 1.25298
Epoch 2598/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4311 - val_loss: 1.2743 - val_accuracy: 0.4107

Epoch 02598: val_loss did not improve from 1.25298
Epoch 2599/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4311 - val_loss: 1.2588 - val_accuracy: 0.4211

Epoch 02599: val_loss did not improve from 1.25298
Epoch 2600/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4357 - val_loss: 1.2543 - val_accuracy: 0.4386

Epoch 02600: val_loss did not improve from 1.25298
Epoch 2601/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4338 - val_loss: 1.2566 - val_accuracy: 0.4346

Epoch 02601: val_loss did not improve from 1.25298
Epoch 2602/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4319 - val_loss: 1.2630 - val_accuracy: 0.4187

Epoch 02602: val_loss did not improve from 1.25298
Epoch 2603/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4318 - val_loss: 1.2630 - val_accuracy: 0.4211

Epoch 02603: val_loss did not improve from 1.25298
Epoch 2604/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4314 - val_loss: 1.2638 - val_accuracy: 0.4187

Epoch 02604: val_loss did not improve from 1.25298
Epoch 2605/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4344 - val_loss: 1.2593 - val_accuracy: 0.4338

Epoch 02605: val_loss did not improve from 1.25298
Epoch 2606/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4386 - val_loss: 1.2570 - val_accuracy: 0.4258

Epoch 02606: val_loss did not improve from 1.25298
Epoch 2607/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4349 - val_loss: 1.2574 - val_accuracy: 0.4322

Epoch 02607: val_loss did not improve from 1.25298
Epoch 2608/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4356 - val_loss: 1.2564 - val_accuracy: 0.4250

Epoch 02608: val_loss did not improve from 1.25298
Epoch 2609/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4346 - val_loss: 1.2571 - val_accuracy: 0.4274

Epoch 02609: val_loss did not improve from 1.25298
Epoch 2610/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4382 - val_loss: 1.2665 - val_accuracy: 0.4195

Epoch 02610: val_loss did not improve from 1.25298
Epoch 2611/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4332 - val_loss: 1.2597 - val_accuracy: 0.4195

Epoch 02611: val_loss did not improve from 1.25298
Epoch 2612/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4320 - val_loss: 1.2577 - val_accuracy: 0.4266

Epoch 02612: val_loss did not improve from 1.25298
Epoch 2613/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4302 - val_loss: 1.2545 - val_accuracy: 0.4298

Epoch 02613: val_loss did not improve from 1.25298
Epoch 2614/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4355 - val_loss: 1.2557 - val_accuracy: 0.4298

Epoch 02614: val_loss did not improve from 1.25298
Epoch 2615/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4351 - val_loss: 1.2636 - val_accuracy: 0.4195

Epoch 02615: val_loss did not improve from 1.25298
Epoch 2616/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4318 - val_loss: 1.2828 - val_accuracy: 0.4203

Epoch 02616: val_loss did not improve from 1.25298
Epoch 2617/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4352 - val_loss: 1.2552 - val_accuracy: 0.4346

Epoch 02617: val_loss did not improve from 1.25298
Epoch 2618/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4379 - val_loss: 1.2554 - val_accuracy: 0.4362

Epoch 02618: val_loss did not improve from 1.25298
Epoch 2619/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4329 - val_loss: 1.2585 - val_accuracy: 0.4187

Epoch 02619: val_loss did not improve from 1.25298
Epoch 2620/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4357 - val_loss: 1.2576 - val_accuracy: 0.4282

Epoch 02620: val_loss did not improve from 1.25298
Epoch 2621/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4360 - val_loss: 1.2567 - val_accuracy: 0.4338

Epoch 02621: val_loss did not improve from 1.25298
Epoch 2622/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4342 - val_loss: 1.2654 - val_accuracy: 0.4258

Epoch 02622: val_loss did not improve from 1.25298
Epoch 2623/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4354 - val_loss: 1.2762 - val_accuracy: 0.4179

Epoch 02623: val_loss did not improve from 1.25298
Epoch 2624/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4270 - val_loss: 1.2552 - val_accuracy: 0.4242

Epoch 02624: val_loss did not improve from 1.25298
Epoch 2625/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4355 - val_loss: 1.2565 - val_accuracy: 0.4314

Epoch 02625: val_loss did not improve from 1.25298
Epoch 2626/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4333 - val_loss: 1.2572 - val_accuracy: 0.4266

Epoch 02626: val_loss did not improve from 1.25298
Epoch 2627/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4335 - val_loss: 1.2573 - val_accuracy: 0.4242

Epoch 02627: val_loss did not improve from 1.25298
Epoch 2628/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4383 - val_loss: 1.2630 - val_accuracy: 0.4346

Epoch 02628: val_loss did not improve from 1.25298
Epoch 2629/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4383 - val_loss: 1.2528 - val_accuracy: 0.4370

Epoch 02629: val_loss improved from 1.25298 to 1.25284, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2630/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4365 - val_loss: 1.2582 - val_accuracy: 0.4203

Epoch 02630: val_loss did not improve from 1.25284
Epoch 2631/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4339 - val_loss: 1.2584 - val_accuracy: 0.4322

Epoch 02631: val_loss did not improve from 1.25284
Epoch 2632/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4373 - val_loss: 1.2529 - val_accuracy: 0.4258

Epoch 02632: val_loss did not improve from 1.25284
Epoch 2633/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4340 - val_loss: 1.2569 - val_accuracy: 0.4234

Epoch 02633: val_loss did not improve from 1.25284
Epoch 2634/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4339 - val_loss: 1.2677 - val_accuracy: 0.4211

Epoch 02634: val_loss did not improve from 1.25284
Epoch 2635/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4363 - val_loss: 1.2668 - val_accuracy: 0.4203

Epoch 02635: val_loss did not improve from 1.25284
Epoch 2636/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4370 - val_loss: 1.2574 - val_accuracy: 0.4298

Epoch 02636: val_loss did not improve from 1.25284
Epoch 2637/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4365 - val_loss: 1.2540 - val_accuracy: 0.4266

Epoch 02637: val_loss did not improve from 1.25284
Epoch 2638/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4324 - val_loss: 1.2551 - val_accuracy: 0.4242

Epoch 02638: val_loss did not improve from 1.25284
Epoch 2639/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4334 - val_loss: 1.2633 - val_accuracy: 0.4131

Epoch 02639: val_loss did not improve from 1.25284
Epoch 2640/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4376 - val_loss: 1.2547 - val_accuracy: 0.4402

Epoch 02640: val_loss did not improve from 1.25284
Epoch 2641/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4370 - val_loss: 1.2582 - val_accuracy: 0.4195

Epoch 02641: val_loss did not improve from 1.25284
Epoch 2642/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4348 - val_loss: 1.2664 - val_accuracy: 0.4179

Epoch 02642: val_loss did not improve from 1.25284
Epoch 2643/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4319 - val_loss: 1.2570 - val_accuracy: 0.4226

Epoch 02643: val_loss did not improve from 1.25284
Epoch 2644/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4342 - val_loss: 1.2531 - val_accuracy: 0.4290

Epoch 02644: val_loss did not improve from 1.25284
Epoch 2645/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4347 - val_loss: 1.2605 - val_accuracy: 0.4187

Epoch 02645: val_loss did not improve from 1.25284
Epoch 2646/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4372 - val_loss: 1.2545 - val_accuracy: 0.4226

Epoch 02646: val_loss did not improve from 1.25284
Epoch 2647/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4341 - val_loss: 1.2536 - val_accuracy: 0.4370

Epoch 02647: val_loss did not improve from 1.25284
Epoch 2648/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4357 - val_loss: 1.2539 - val_accuracy: 0.4234

Epoch 02648: val_loss did not improve from 1.25284
Epoch 2649/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4342 - val_loss: 1.2613 - val_accuracy: 0.4171

Epoch 02649: val_loss did not improve from 1.25284
Epoch 2650/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4348 - val_loss: 1.2636 - val_accuracy: 0.4266

Epoch 02650: val_loss did not improve from 1.25284
Epoch 2651/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4328 - val_loss: 1.2655 - val_accuracy: 0.4163

Epoch 02651: val_loss did not improve from 1.25284
Epoch 2652/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4324 - val_loss: 1.2535 - val_accuracy: 0.4258

Epoch 02652: val_loss did not improve from 1.25284
Epoch 2653/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4348 - val_loss: 1.2581 - val_accuracy: 0.4234

Epoch 02653: val_loss did not improve from 1.25284
Epoch 2654/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4373 - val_loss: 1.2621 - val_accuracy: 0.4290

Epoch 02654: val_loss did not improve from 1.25284
Epoch 2655/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4351 - val_loss: 1.2606 - val_accuracy: 0.4290

Epoch 02655: val_loss did not improve from 1.25284
Epoch 2656/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4380 - val_loss: 1.2687 - val_accuracy: 0.4258

Epoch 02656: val_loss did not improve from 1.25284
Epoch 2657/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4325 - val_loss: 1.2562 - val_accuracy: 0.4290

Epoch 02657: val_loss did not improve from 1.25284
Epoch 2658/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4321 - val_loss: 1.2583 - val_accuracy: 0.4290

Epoch 02658: val_loss did not improve from 1.25284
Epoch 2659/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4359 - val_loss: 1.2578 - val_accuracy: 0.4211

Epoch 02659: val_loss did not improve from 1.25284
Epoch 2660/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4359 - val_loss: 1.2608 - val_accuracy: 0.4234

Epoch 02660: val_loss did not improve from 1.25284
Epoch 2661/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4300 - val_loss: 1.2599 - val_accuracy: 0.4163

Epoch 02661: val_loss did not improve from 1.25284
Epoch 2662/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4320 - val_loss: 1.2549 - val_accuracy: 0.4346

Epoch 02662: val_loss did not improve from 1.25284
Epoch 2663/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4332 - val_loss: 1.2580 - val_accuracy: 0.4330

Epoch 02663: val_loss did not improve from 1.25284
Epoch 2664/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4317 - val_loss: 1.2635 - val_accuracy: 0.4179

Epoch 02664: val_loss did not improve from 1.25284
Epoch 2665/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4352 - val_loss: 1.2758 - val_accuracy: 0.4195

Epoch 02665: val_loss did not improve from 1.25284
Epoch 2666/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4311 - val_loss: 1.2624 - val_accuracy: 0.4179

Epoch 02666: val_loss did not improve from 1.25284
Epoch 2667/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4299 - val_loss: 1.2581 - val_accuracy: 0.4322

Epoch 02667: val_loss did not improve from 1.25284
Epoch 2668/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4360 - val_loss: 1.2542 - val_accuracy: 0.4402

Epoch 02668: val_loss did not improve from 1.25284
Epoch 2669/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4370 - val_loss: 1.2582 - val_accuracy: 0.4362

Epoch 02669: val_loss did not improve from 1.25284
Epoch 2670/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4299 - val_loss: 1.2587 - val_accuracy: 0.4234

Epoch 02670: val_loss did not improve from 1.25284
Epoch 2671/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4364 - val_loss: 1.2613 - val_accuracy: 0.4242

Epoch 02671: val_loss did not improve from 1.25284
Epoch 2672/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4347 - val_loss: 1.2625 - val_accuracy: 0.4139

Epoch 02672: val_loss did not improve from 1.25284
Epoch 2673/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4344 - val_loss: 1.2634 - val_accuracy: 0.4195

Epoch 02673: val_loss did not improve from 1.25284
Epoch 2674/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4349 - val_loss: 1.2549 - val_accuracy: 0.4354

Epoch 02674: val_loss did not improve from 1.25284
Epoch 2675/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4342 - val_loss: 1.2522 - val_accuracy: 0.4266

Epoch 02675: val_loss improved from 1.25284 to 1.25223, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2676/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4342 - val_loss: 1.2597 - val_accuracy: 0.4226

Epoch 02676: val_loss did not improve from 1.25223
Epoch 2677/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4334 - val_loss: 1.2614 - val_accuracy: 0.4139

Epoch 02677: val_loss did not improve from 1.25223
Epoch 2678/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4350 - val_loss: 1.2567 - val_accuracy: 0.4298

Epoch 02678: val_loss did not improve from 1.25223
Epoch 2679/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4386 - val_loss: 1.2564 - val_accuracy: 0.4258

Epoch 02679: val_loss did not improve from 1.25223
Epoch 2680/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4339 - val_loss: 1.2579 - val_accuracy: 0.4195

Epoch 02680: val_loss did not improve from 1.25223
Epoch 2681/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4349 - val_loss: 1.2541 - val_accuracy: 0.4282

Epoch 02681: val_loss did not improve from 1.25223
Epoch 2682/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4357 - val_loss: 1.2569 - val_accuracy: 0.4219

Epoch 02682: val_loss did not improve from 1.25223
Epoch 2683/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4371 - val_loss: 1.2608 - val_accuracy: 0.4219

Epoch 02683: val_loss did not improve from 1.25223
Epoch 2684/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4380 - val_loss: 1.2547 - val_accuracy: 0.4306

Epoch 02684: val_loss did not improve from 1.25223
Epoch 2685/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4351 - val_loss: 1.2565 - val_accuracy: 0.4250

Epoch 02685: val_loss did not improve from 1.25223
Epoch 2686/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4357 - val_loss: 1.2690 - val_accuracy: 0.4163

Epoch 02686: val_loss did not improve from 1.25223
Epoch 2687/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4368 - val_loss: 1.2553 - val_accuracy: 0.4338

Epoch 02687: val_loss did not improve from 1.25223
Epoch 2688/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4394 - val_loss: 1.2555 - val_accuracy: 0.4370

Epoch 02688: val_loss did not improve from 1.25223
Epoch 2689/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4378 - val_loss: 1.2611 - val_accuracy: 0.4330

Epoch 02689: val_loss did not improve from 1.25223
Epoch 2690/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4332 - val_loss: 1.2552 - val_accuracy: 0.4338

Epoch 02690: val_loss did not improve from 1.25223
Epoch 2691/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4351 - val_loss: 1.2579 - val_accuracy: 0.4187

Epoch 02691: val_loss did not improve from 1.25223
Epoch 2692/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4377 - val_loss: 1.2601 - val_accuracy: 0.4250

Epoch 02692: val_loss did not improve from 1.25223
Epoch 2693/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4368 - val_loss: 1.2576 - val_accuracy: 0.4282

Epoch 02693: val_loss did not improve from 1.25223
Epoch 2694/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4334 - val_loss: 1.2578 - val_accuracy: 0.4107

Epoch 02694: val_loss did not improve from 1.25223
Epoch 2695/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4331 - val_loss: 1.2553 - val_accuracy: 0.4306

Epoch 02695: val_loss did not improve from 1.25223
Epoch 2696/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4388 - val_loss: 1.2529 - val_accuracy: 0.4322

Epoch 02696: val_loss did not improve from 1.25223
Epoch 2697/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4344 - val_loss: 1.2596 - val_accuracy: 0.4163

Epoch 02697: val_loss did not improve from 1.25223
Epoch 2698/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4336 - val_loss: 1.2561 - val_accuracy: 0.4258

Epoch 02698: val_loss did not improve from 1.25223
Epoch 2699/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4372 - val_loss: 1.2585 - val_accuracy: 0.4211

Epoch 02699: val_loss did not improve from 1.25223
Epoch 2700/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4317 - val_loss: 1.2584 - val_accuracy: 0.4234

Epoch 02700: val_loss did not improve from 1.25223
Epoch 2701/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4337 - val_loss: 1.2555 - val_accuracy: 0.4330

Epoch 02701: val_loss did not improve from 1.25223
Epoch 2702/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4330 - val_loss: 1.2576 - val_accuracy: 0.4274

Epoch 02702: val_loss did not improve from 1.25223
Epoch 2703/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4370 - val_loss: 1.2558 - val_accuracy: 0.4290

Epoch 02703: val_loss did not improve from 1.25223
Epoch 2704/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4358 - val_loss: 1.2594 - val_accuracy: 0.4234

Epoch 02704: val_loss did not improve from 1.25223
Epoch 2705/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4376 - val_loss: 1.2532 - val_accuracy: 0.4330

Epoch 02705: val_loss did not improve from 1.25223
Epoch 2706/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4342 - val_loss: 1.2610 - val_accuracy: 0.4179

Epoch 02706: val_loss did not improve from 1.25223
Epoch 2707/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4357 - val_loss: 1.2589 - val_accuracy: 0.4346

Epoch 02707: val_loss did not improve from 1.25223
Epoch 2708/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4326 - val_loss: 1.2647 - val_accuracy: 0.4274

Epoch 02708: val_loss did not improve from 1.25223
Epoch 2709/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4318 - val_loss: 1.2539 - val_accuracy: 0.4346

Epoch 02709: val_loss did not improve from 1.25223
Epoch 2710/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4388 - val_loss: 1.2550 - val_accuracy: 0.4282

Epoch 02710: val_loss did not improve from 1.25223
Epoch 2711/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4375 - val_loss: 1.2527 - val_accuracy: 0.4274

Epoch 02711: val_loss did not improve from 1.25223
Epoch 2712/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4360 - val_loss: 1.2533 - val_accuracy: 0.4338

Epoch 02712: val_loss did not improve from 1.25223
Epoch 2713/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4326 - val_loss: 1.2605 - val_accuracy: 0.4226

Epoch 02713: val_loss did not improve from 1.25223
Epoch 2714/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4365 - val_loss: 1.2710 - val_accuracy: 0.4179

Epoch 02714: val_loss did not improve from 1.25223
Epoch 2715/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4326 - val_loss: 1.2582 - val_accuracy: 0.4226

Epoch 02715: val_loss did not improve from 1.25223
Epoch 2716/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4388 - val_loss: 1.2572 - val_accuracy: 0.4234

Epoch 02716: val_loss did not improve from 1.25223
Epoch 2717/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4383 - val_loss: 1.2539 - val_accuracy: 0.4338

Epoch 02717: val_loss did not improve from 1.25223
Epoch 2718/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4320 - val_loss: 1.2625 - val_accuracy: 0.4211

Epoch 02718: val_loss did not improve from 1.25223
Epoch 2719/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4327 - val_loss: 1.2594 - val_accuracy: 0.4242

Epoch 02719: val_loss did not improve from 1.25223
Epoch 2720/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4342 - val_loss: 1.2596 - val_accuracy: 0.4266

Epoch 02720: val_loss did not improve from 1.25223
Epoch 2721/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4365 - val_loss: 1.2537 - val_accuracy: 0.4282

Epoch 02721: val_loss did not improve from 1.25223
Epoch 2722/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4371 - val_loss: 1.2552 - val_accuracy: 0.4402

Epoch 02722: val_loss did not improve from 1.25223
Epoch 2723/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4297 - val_loss: 1.2581 - val_accuracy: 0.4266

Epoch 02723: val_loss did not improve from 1.25223
Epoch 2724/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4358 - val_loss: 1.2678 - val_accuracy: 0.4203

Epoch 02724: val_loss did not improve from 1.25223
Epoch 2725/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4302 - val_loss: 1.2657 - val_accuracy: 0.4195

Epoch 02725: val_loss did not improve from 1.25223
Epoch 2726/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4359 - val_loss: 1.2549 - val_accuracy: 0.4346

Epoch 02726: val_loss did not improve from 1.25223
Epoch 2727/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4389 - val_loss: 1.2638 - val_accuracy: 0.4219

Epoch 02727: val_loss did not improve from 1.25223
Epoch 2728/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4358 - val_loss: 1.2569 - val_accuracy: 0.4171

Epoch 02728: val_loss did not improve from 1.25223
Epoch 2729/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4309 - val_loss: 1.2560 - val_accuracy: 0.4386

Epoch 02729: val_loss did not improve from 1.25223
Epoch 2730/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4351 - val_loss: 1.2551 - val_accuracy: 0.4258

Epoch 02730: val_loss did not improve from 1.25223
Epoch 2731/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4378 - val_loss: 1.2540 - val_accuracy: 0.4354

Epoch 02731: val_loss did not improve from 1.25223
Epoch 2732/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4325 - val_loss: 1.2593 - val_accuracy: 0.4131

Epoch 02732: val_loss did not improve from 1.25223
Epoch 2733/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4357 - val_loss: 1.2723 - val_accuracy: 0.4147

Epoch 02733: val_loss did not improve from 1.25223
Epoch 2734/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4365 - val_loss: 1.2666 - val_accuracy: 0.4139

Epoch 02734: val_loss did not improve from 1.25223
Epoch 2735/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4329 - val_loss: 1.2535 - val_accuracy: 0.4330

Epoch 02735: val_loss did not improve from 1.25223
Epoch 2736/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4351 - val_loss: 1.2572 - val_accuracy: 0.4282

Epoch 02736: val_loss did not improve from 1.25223
Epoch 2737/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4343 - val_loss: 1.2538 - val_accuracy: 0.4274

Epoch 02737: val_loss did not improve from 1.25223
Epoch 2738/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4342 - val_loss: 1.2573 - val_accuracy: 0.4290

Epoch 02738: val_loss did not improve from 1.25223
Epoch 2739/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4396 - val_loss: 1.2574 - val_accuracy: 0.4282

Epoch 02739: val_loss did not improve from 1.25223
Epoch 2740/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4347 - val_loss: 1.2555 - val_accuracy: 0.4187

Epoch 02740: val_loss did not improve from 1.25223
Epoch 2741/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4342 - val_loss: 1.2657 - val_accuracy: 0.4211

Epoch 02741: val_loss did not improve from 1.25223
Epoch 2742/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4353 - val_loss: 1.2527 - val_accuracy: 0.4298

Epoch 02742: val_loss did not improve from 1.25223
Epoch 2743/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4384 - val_loss: 1.2522 - val_accuracy: 0.4354

Epoch 02743: val_loss did not improve from 1.25223
Epoch 2744/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4324 - val_loss: 1.2569 - val_accuracy: 0.4211

Epoch 02744: val_loss did not improve from 1.25223
Epoch 2745/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4377 - val_loss: 1.2523 - val_accuracy: 0.4330

Epoch 02745: val_loss did not improve from 1.25223
Epoch 2746/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4308 - val_loss: 1.2575 - val_accuracy: 0.4195

Epoch 02746: val_loss did not improve from 1.25223
Epoch 2747/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4369 - val_loss: 1.2584 - val_accuracy: 0.4258

Epoch 02747: val_loss did not improve from 1.25223
Epoch 2748/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4361 - val_loss: 1.2704 - val_accuracy: 0.4211

Epoch 02748: val_loss did not improve from 1.25223
Epoch 2749/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4277 - val_loss: 1.2589 - val_accuracy: 0.4219

Epoch 02749: val_loss did not improve from 1.25223
Epoch 2750/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4338 - val_loss: 1.2566 - val_accuracy: 0.4290

Epoch 02750: val_loss did not improve from 1.25223
Epoch 2751/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4363 - val_loss: 1.2546 - val_accuracy: 0.4354

Epoch 02751: val_loss did not improve from 1.25223
Epoch 2752/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4332 - val_loss: 1.2602 - val_accuracy: 0.4226

Epoch 02752: val_loss did not improve from 1.25223
Epoch 2753/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4357 - val_loss: 1.2681 - val_accuracy: 0.4266

Epoch 02753: val_loss did not improve from 1.25223
Epoch 2754/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4389 - val_loss: 1.2622 - val_accuracy: 0.4187

Epoch 02754: val_loss did not improve from 1.25223
Epoch 2755/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4379 - val_loss: 1.2568 - val_accuracy: 0.4234

Epoch 02755: val_loss did not improve from 1.25223
Epoch 2756/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4336 - val_loss: 1.2543 - val_accuracy: 0.4266

Epoch 02756: val_loss did not improve from 1.25223
Epoch 2757/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4356 - val_loss: 1.2614 - val_accuracy: 0.4258

Epoch 02757: val_loss did not improve from 1.25223
Epoch 2758/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4347 - val_loss: 1.2538 - val_accuracy: 0.4314

Epoch 02758: val_loss did not improve from 1.25223
Epoch 2759/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4347 - val_loss: 1.2632 - val_accuracy: 0.4226

Epoch 02759: val_loss did not improve from 1.25223
Epoch 2760/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4311 - val_loss: 1.2634 - val_accuracy: 0.4226

Epoch 02760: val_loss did not improve from 1.25223
Epoch 2761/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4370 - val_loss: 1.2571 - val_accuracy: 0.4322

Epoch 02761: val_loss did not improve from 1.25223
Epoch 2762/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4370 - val_loss: 1.2600 - val_accuracy: 0.4226

Epoch 02762: val_loss did not improve from 1.25223
Epoch 2763/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4354 - val_loss: 1.2615 - val_accuracy: 0.4274

Epoch 02763: val_loss did not improve from 1.25223
Epoch 2764/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4356 - val_loss: 1.2622 - val_accuracy: 0.4139

Epoch 02764: val_loss did not improve from 1.25223
Epoch 2765/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4330 - val_loss: 1.2613 - val_accuracy: 0.4219

Epoch 02765: val_loss did not improve from 1.25223
Epoch 2766/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4290 - val_loss: 1.2578 - val_accuracy: 0.4450

Epoch 02766: val_loss did not improve from 1.25223
Epoch 2767/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4287 - val_loss: 1.2568 - val_accuracy: 0.4386

Epoch 02767: val_loss did not improve from 1.25223
Epoch 2768/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4367 - val_loss: 1.2531 - val_accuracy: 0.4442

Epoch 02768: val_loss did not improve from 1.25223
Epoch 2769/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4268 - val_loss: 1.2720 - val_accuracy: 0.4195

Epoch 02769: val_loss did not improve from 1.25223
Epoch 2770/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4347 - val_loss: 1.2746 - val_accuracy: 0.4179

Epoch 02770: val_loss did not improve from 1.25223
Epoch 2771/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4318 - val_loss: 1.2615 - val_accuracy: 0.4147

Epoch 02771: val_loss did not improve from 1.25223
Epoch 2772/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4337 - val_loss: 1.2521 - val_accuracy: 0.4338

Epoch 02772: val_loss improved from 1.25223 to 1.25211, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2773/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4365 - val_loss: 1.2613 - val_accuracy: 0.4234

Epoch 02773: val_loss did not improve from 1.25211
Epoch 2774/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4331 - val_loss: 1.2668 - val_accuracy: 0.4187

Epoch 02774: val_loss did not improve from 1.25211
Epoch 2775/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4343 - val_loss: 1.2551 - val_accuracy: 0.4282

Epoch 02775: val_loss did not improve from 1.25211
Epoch 2776/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4376 - val_loss: 1.2570 - val_accuracy: 0.4258

Epoch 02776: val_loss did not improve from 1.25211
Epoch 2777/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4380 - val_loss: 1.2519 - val_accuracy: 0.4306

Epoch 02777: val_loss improved from 1.25211 to 1.25194, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2778/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4320 - val_loss: 1.2533 - val_accuracy: 0.4282

Epoch 02778: val_loss did not improve from 1.25194
Epoch 2779/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4356 - val_loss: 1.2539 - val_accuracy: 0.4370

Epoch 02779: val_loss did not improve from 1.25194
Epoch 2780/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4354 - val_loss: 1.2647 - val_accuracy: 0.4258

Epoch 02780: val_loss did not improve from 1.25194
Epoch 2781/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4345 - val_loss: 1.2565 - val_accuracy: 0.4258

Epoch 02781: val_loss did not improve from 1.25194
Epoch 2782/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4384 - val_loss: 1.2718 - val_accuracy: 0.4234

Epoch 02782: val_loss did not improve from 1.25194
Epoch 2783/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4297 - val_loss: 1.2566 - val_accuracy: 0.4242

Epoch 02783: val_loss did not improve from 1.25194
Epoch 2784/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4350 - val_loss: 1.2513 - val_accuracy: 0.4354

Epoch 02784: val_loss improved from 1.25194 to 1.25129, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2785/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4362 - val_loss: 1.2563 - val_accuracy: 0.4266

Epoch 02785: val_loss did not improve from 1.25129
Epoch 2786/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4364 - val_loss: 1.2602 - val_accuracy: 0.4306

Epoch 02786: val_loss did not improve from 1.25129
Epoch 2787/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4400 - val_loss: 1.2573 - val_accuracy: 0.4195

Epoch 02787: val_loss did not improve from 1.25129
Epoch 2788/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4328 - val_loss: 1.2581 - val_accuracy: 0.4250

Epoch 02788: val_loss did not improve from 1.25129
Epoch 2789/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4330 - val_loss: 1.2545 - val_accuracy: 0.4234

Epoch 02789: val_loss did not improve from 1.25129
Epoch 2790/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4357 - val_loss: 1.2525 - val_accuracy: 0.4362

Epoch 02790: val_loss did not improve from 1.25129
Epoch 2791/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4349 - val_loss: 1.2543 - val_accuracy: 0.4298

Epoch 02791: val_loss did not improve from 1.25129
Epoch 2792/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4372 - val_loss: 1.2587 - val_accuracy: 0.4330

Epoch 02792: val_loss did not improve from 1.25129
Epoch 2793/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4385 - val_loss: 1.2643 - val_accuracy: 0.4274

Epoch 02793: val_loss did not improve from 1.25129
Epoch 2794/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4355 - val_loss: 1.2523 - val_accuracy: 0.4338

Epoch 02794: val_loss did not improve from 1.25129
Epoch 2795/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4360 - val_loss: 1.2579 - val_accuracy: 0.4258

Epoch 02795: val_loss did not improve from 1.25129
Epoch 2796/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4313 - val_loss: 1.2554 - val_accuracy: 0.4330

Epoch 02796: val_loss did not improve from 1.25129
Epoch 2797/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4350 - val_loss: 1.2527 - val_accuracy: 0.4426

Epoch 02797: val_loss did not improve from 1.25129
Epoch 2798/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4306 - val_loss: 1.2575 - val_accuracy: 0.4290

Epoch 02798: val_loss did not improve from 1.25129
Epoch 2799/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4354 - val_loss: 1.2583 - val_accuracy: 0.4290

Epoch 02799: val_loss did not improve from 1.25129
Epoch 2800/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4356 - val_loss: 1.2664 - val_accuracy: 0.4306

Epoch 02800: val_loss did not improve from 1.25129
Epoch 2801/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4352 - val_loss: 1.2564 - val_accuracy: 0.4274

Epoch 02801: val_loss did not improve from 1.25129
Epoch 2802/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4334 - val_loss: 1.2548 - val_accuracy: 0.4394

Epoch 02802: val_loss did not improve from 1.25129
Epoch 2803/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4365 - val_loss: 1.2522 - val_accuracy: 0.4338

Epoch 02803: val_loss did not improve from 1.25129
Epoch 2804/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4341 - val_loss: 1.2520 - val_accuracy: 0.4394

Epoch 02804: val_loss did not improve from 1.25129
Epoch 2805/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4388 - val_loss: 1.2531 - val_accuracy: 0.4314

Epoch 02805: val_loss did not improve from 1.25129
Epoch 2806/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4367 - val_loss: 1.2661 - val_accuracy: 0.4242

Epoch 02806: val_loss did not improve from 1.25129
Epoch 2807/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4393 - val_loss: 1.2629 - val_accuracy: 0.4211

Epoch 02807: val_loss did not improve from 1.25129
Epoch 2808/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4352 - val_loss: 1.2530 - val_accuracy: 0.4346

Epoch 02808: val_loss did not improve from 1.25129
Epoch 2809/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4403 - val_loss: 1.2555 - val_accuracy: 0.4354

Epoch 02809: val_loss did not improve from 1.25129
Epoch 2810/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4376 - val_loss: 1.2528 - val_accuracy: 0.4258

Epoch 02810: val_loss did not improve from 1.25129
Epoch 2811/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4368 - val_loss: 1.2535 - val_accuracy: 0.4386

Epoch 02811: val_loss did not improve from 1.25129
Epoch 2812/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4375 - val_loss: 1.2558 - val_accuracy: 0.4298

Epoch 02812: val_loss did not improve from 1.25129
Epoch 2813/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4384 - val_loss: 1.2528 - val_accuracy: 0.4322

Epoch 02813: val_loss did not improve from 1.25129
Epoch 2814/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4349 - val_loss: 1.2619 - val_accuracy: 0.4226

Epoch 02814: val_loss did not improve from 1.25129
Epoch 2815/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4365 - val_loss: 1.2661 - val_accuracy: 0.4195

Epoch 02815: val_loss did not improve from 1.25129
Epoch 2816/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4318 - val_loss: 1.2590 - val_accuracy: 0.4171

Epoch 02816: val_loss did not improve from 1.25129
Epoch 2817/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4369 - val_loss: 1.2577 - val_accuracy: 0.4266

Epoch 02817: val_loss did not improve from 1.25129
Epoch 2818/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4353 - val_loss: 1.2589 - val_accuracy: 0.4282

Epoch 02818: val_loss did not improve from 1.25129
Epoch 2819/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4379 - val_loss: 1.2533 - val_accuracy: 0.4426

Epoch 02819: val_loss did not improve from 1.25129
Epoch 2820/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4384 - val_loss: 1.2579 - val_accuracy: 0.4258

Epoch 02820: val_loss did not improve from 1.25129
Epoch 2821/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4376 - val_loss: 1.2631 - val_accuracy: 0.4203

Epoch 02821: val_loss did not improve from 1.25129
Epoch 2822/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4357 - val_loss: 1.2537 - val_accuracy: 0.4346

Epoch 02822: val_loss did not improve from 1.25129
Epoch 2823/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4329 - val_loss: 1.2560 - val_accuracy: 0.4418

Epoch 02823: val_loss did not improve from 1.25129
Epoch 2824/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4315 - val_loss: 1.2574 - val_accuracy: 0.4250

Epoch 02824: val_loss did not improve from 1.25129
Epoch 2825/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4308 - val_loss: 1.2790 - val_accuracy: 0.4219

Epoch 02825: val_loss did not improve from 1.25129
Epoch 2826/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4364 - val_loss: 1.2555 - val_accuracy: 0.4290

Epoch 02826: val_loss did not improve from 1.25129
Epoch 2827/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4356 - val_loss: 1.2605 - val_accuracy: 0.4266

Epoch 02827: val_loss did not improve from 1.25129
Epoch 2828/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4411 - val_loss: 1.2511 - val_accuracy: 0.4402

Epoch 02828: val_loss improved from 1.25129 to 1.25111, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2829/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4340 - val_loss: 1.2544 - val_accuracy: 0.4322

Epoch 02829: val_loss did not improve from 1.25111
Epoch 2830/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4376 - val_loss: 1.2548 - val_accuracy: 0.4298

Epoch 02830: val_loss did not improve from 1.25111
Epoch 2831/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4365 - val_loss: 1.2569 - val_accuracy: 0.4274

Epoch 02831: val_loss did not improve from 1.25111
Epoch 2832/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4374 - val_loss: 1.2559 - val_accuracy: 0.4282

Epoch 02832: val_loss did not improve from 1.25111
Epoch 2833/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4357 - val_loss: 1.2582 - val_accuracy: 0.4266

Epoch 02833: val_loss did not improve from 1.25111
Epoch 2834/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4410 - val_loss: 1.2648 - val_accuracy: 0.4250

Epoch 02834: val_loss did not improve from 1.25111
Epoch 2835/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4313 - val_loss: 1.2532 - val_accuracy: 0.4442

Epoch 02835: val_loss did not improve from 1.25111
Epoch 2836/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4355 - val_loss: 1.2524 - val_accuracy: 0.4338

Epoch 02836: val_loss did not improve from 1.25111
Epoch 2837/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4354 - val_loss: 1.2525 - val_accuracy: 0.4306

Epoch 02837: val_loss did not improve from 1.25111
Epoch 2838/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4300 - val_loss: 1.2653 - val_accuracy: 0.4211

Epoch 02838: val_loss did not improve from 1.25111
Epoch 2839/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4359 - val_loss: 1.2779 - val_accuracy: 0.4163

Epoch 02839: val_loss did not improve from 1.25111
Epoch 2840/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4327 - val_loss: 1.2522 - val_accuracy: 0.4394

Epoch 02840: val_loss did not improve from 1.25111
Epoch 2841/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4401 - val_loss: 1.2567 - val_accuracy: 0.4298

Epoch 02841: val_loss did not improve from 1.25111
Epoch 2842/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4413 - val_loss: 1.2585 - val_accuracy: 0.4282

Epoch 02842: val_loss did not improve from 1.25111
Epoch 2843/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4385 - val_loss: 1.2564 - val_accuracy: 0.4338

Epoch 02843: val_loss did not improve from 1.25111
Epoch 2844/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4336 - val_loss: 1.2565 - val_accuracy: 0.4354

Epoch 02844: val_loss did not improve from 1.25111
Epoch 2845/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4355 - val_loss: 1.2560 - val_accuracy: 0.4362

Epoch 02845: val_loss did not improve from 1.25111
Epoch 2846/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4357 - val_loss: 1.2632 - val_accuracy: 0.4219

Epoch 02846: val_loss did not improve from 1.25111
Epoch 2847/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4375 - val_loss: 1.2585 - val_accuracy: 0.4306

Epoch 02847: val_loss did not improve from 1.25111
Epoch 2848/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4363 - val_loss: 1.2717 - val_accuracy: 0.4187

Epoch 02848: val_loss did not improve from 1.25111
Epoch 2849/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4374 - val_loss: 1.2607 - val_accuracy: 0.4338

Epoch 02849: val_loss did not improve from 1.25111
Epoch 2850/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4403 - val_loss: 1.2527 - val_accuracy: 0.4298

Epoch 02850: val_loss did not improve from 1.25111
Epoch 2851/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4371 - val_loss: 1.2549 - val_accuracy: 0.4250

Epoch 02851: val_loss did not improve from 1.25111
Epoch 2852/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4378 - val_loss: 1.2572 - val_accuracy: 0.4282

Epoch 02852: val_loss did not improve from 1.25111
Epoch 2853/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4394 - val_loss: 1.2540 - val_accuracy: 0.4234

Epoch 02853: val_loss did not improve from 1.25111
Epoch 2854/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4339 - val_loss: 1.2558 - val_accuracy: 0.4274

Epoch 02854: val_loss did not improve from 1.25111
Epoch 2855/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4342 - val_loss: 1.2585 - val_accuracy: 0.4322

Epoch 02855: val_loss did not improve from 1.25111
Epoch 2856/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4365 - val_loss: 1.2645 - val_accuracy: 0.4322

Epoch 02856: val_loss did not improve from 1.25111
Epoch 2857/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4365 - val_loss: 1.2553 - val_accuracy: 0.4242

Epoch 02857: val_loss did not improve from 1.25111
Epoch 2858/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4356 - val_loss: 1.2550 - val_accuracy: 0.4266

Epoch 02858: val_loss did not improve from 1.25111
Epoch 2859/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4366 - val_loss: 1.2621 - val_accuracy: 0.4330

Epoch 02859: val_loss did not improve from 1.25111
Epoch 2860/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4343 - val_loss: 1.2556 - val_accuracy: 0.4346

Epoch 02860: val_loss did not improve from 1.25111
Epoch 2861/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4342 - val_loss: 1.2523 - val_accuracy: 0.4282

Epoch 02861: val_loss did not improve from 1.25111
Epoch 2862/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4383 - val_loss: 1.2535 - val_accuracy: 0.4394

Epoch 02862: val_loss did not improve from 1.25111
Epoch 2863/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4318 - val_loss: 1.2567 - val_accuracy: 0.4386

Epoch 02863: val_loss did not improve from 1.25111
Epoch 2864/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4389 - val_loss: 1.2676 - val_accuracy: 0.4226

Epoch 02864: val_loss did not improve from 1.25111
Epoch 2865/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4360 - val_loss: 1.2571 - val_accuracy: 0.4242

Epoch 02865: val_loss did not improve from 1.25111
Epoch 2866/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4353 - val_loss: 1.2616 - val_accuracy: 0.4274

Epoch 02866: val_loss did not improve from 1.25111
Epoch 2867/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4372 - val_loss: 1.2525 - val_accuracy: 0.4410

Epoch 02867: val_loss did not improve from 1.25111
Epoch 2868/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4365 - val_loss: 1.2614 - val_accuracy: 0.4131

Epoch 02868: val_loss did not improve from 1.25111
Epoch 2869/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4345 - val_loss: 1.2662 - val_accuracy: 0.4242

Epoch 02869: val_loss did not improve from 1.25111
Epoch 2870/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4402 - val_loss: 1.2522 - val_accuracy: 0.4274

Epoch 02870: val_loss did not improve from 1.25111
Epoch 2871/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4358 - val_loss: 1.2544 - val_accuracy: 0.4290

Epoch 02871: val_loss did not improve from 1.25111
Epoch 2872/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4360 - val_loss: 1.2580 - val_accuracy: 0.4219

Epoch 02872: val_loss did not improve from 1.25111
Epoch 2873/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4390 - val_loss: 1.2504 - val_accuracy: 0.4362

Epoch 02873: val_loss improved from 1.25111 to 1.25043, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2874/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4349 - val_loss: 1.2531 - val_accuracy: 0.4346

Epoch 02874: val_loss did not improve from 1.25043
Epoch 2875/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4381 - val_loss: 1.2782 - val_accuracy: 0.4179

Epoch 02875: val_loss did not improve from 1.25043
Epoch 2876/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4324 - val_loss: 1.2636 - val_accuracy: 0.4163

Epoch 02876: val_loss did not improve from 1.25043
Epoch 2877/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4297 - val_loss: 1.2527 - val_accuracy: 0.4282

Epoch 02877: val_loss did not improve from 1.25043
Epoch 2878/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4394 - val_loss: 1.2535 - val_accuracy: 0.4306

Epoch 02878: val_loss did not improve from 1.25043
Epoch 2879/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4372 - val_loss: 1.2592 - val_accuracy: 0.4211

Epoch 02879: val_loss did not improve from 1.25043
Epoch 2880/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4379 - val_loss: 1.2550 - val_accuracy: 0.4282

Epoch 02880: val_loss did not improve from 1.25043
Epoch 2881/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4414 - val_loss: 1.2512 - val_accuracy: 0.4402

Epoch 02881: val_loss did not improve from 1.25043
Epoch 2882/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4338 - val_loss: 1.2653 - val_accuracy: 0.4179

Epoch 02882: val_loss did not improve from 1.25043
Epoch 2883/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4356 - val_loss: 1.2593 - val_accuracy: 0.4211

Epoch 02883: val_loss did not improve from 1.25043
Epoch 2884/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4382 - val_loss: 1.2559 - val_accuracy: 0.4258

Epoch 02884: val_loss did not improve from 1.25043
Epoch 2885/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4343 - val_loss: 1.2544 - val_accuracy: 0.4219

Epoch 02885: val_loss did not improve from 1.25043
Epoch 2886/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4384 - val_loss: 1.2534 - val_accuracy: 0.4338

Epoch 02886: val_loss did not improve from 1.25043
Epoch 2887/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4334 - val_loss: 1.2578 - val_accuracy: 0.4274

Epoch 02887: val_loss did not improve from 1.25043
Epoch 2888/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4380 - val_loss: 1.2557 - val_accuracy: 0.4314

Epoch 02888: val_loss did not improve from 1.25043
Epoch 2889/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4381 - val_loss: 1.2633 - val_accuracy: 0.4266

Epoch 02889: val_loss did not improve from 1.25043
Epoch 2890/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4344 - val_loss: 1.2537 - val_accuracy: 0.4306

Epoch 02890: val_loss did not improve from 1.25043
Epoch 2891/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4365 - val_loss: 1.2542 - val_accuracy: 0.4362

Epoch 02891: val_loss did not improve from 1.25043
Epoch 2892/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4382 - val_loss: 1.2527 - val_accuracy: 0.4211

Epoch 02892: val_loss did not improve from 1.25043
Epoch 2893/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4389 - val_loss: 1.2547 - val_accuracy: 0.4306

Epoch 02893: val_loss did not improve from 1.25043
Epoch 2894/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4397 - val_loss: 1.2543 - val_accuracy: 0.4298

Epoch 02894: val_loss did not improve from 1.25043
Epoch 2895/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4395 - val_loss: 1.2590 - val_accuracy: 0.4338

Epoch 02895: val_loss did not improve from 1.25043
Epoch 2896/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4379 - val_loss: 1.2518 - val_accuracy: 0.4378

Epoch 02896: val_loss did not improve from 1.25043
Epoch 2897/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4363 - val_loss: 1.2587 - val_accuracy: 0.4211

Epoch 02897: val_loss did not improve from 1.25043
Epoch 2898/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4385 - val_loss: 1.2569 - val_accuracy: 0.4203

Epoch 02898: val_loss did not improve from 1.25043
Epoch 2899/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4400 - val_loss: 1.2506 - val_accuracy: 0.4386

Epoch 02899: val_loss did not improve from 1.25043
Epoch 2900/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4320 - val_loss: 1.2580 - val_accuracy: 0.4266

Epoch 02900: val_loss did not improve from 1.25043
Epoch 2901/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4414 - val_loss: 1.2574 - val_accuracy: 0.4211

Epoch 02901: val_loss did not improve from 1.25043
Epoch 2902/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4362 - val_loss: 1.2562 - val_accuracy: 0.4290

Epoch 02902: val_loss did not improve from 1.25043
Epoch 2903/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4342 - val_loss: 1.2557 - val_accuracy: 0.4330

Epoch 02903: val_loss did not improve from 1.25043
Epoch 2904/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4393 - val_loss: 1.2629 - val_accuracy: 0.4139

Epoch 02904: val_loss did not improve from 1.25043
Epoch 2905/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4372 - val_loss: 1.2627 - val_accuracy: 0.4203

Epoch 02905: val_loss did not improve from 1.25043
Epoch 2906/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4334 - val_loss: 1.2518 - val_accuracy: 0.4314

Epoch 02906: val_loss did not improve from 1.25043
Epoch 2907/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4340 - val_loss: 1.2642 - val_accuracy: 0.4242

Epoch 02907: val_loss did not improve from 1.25043
Epoch 2908/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4388 - val_loss: 1.2547 - val_accuracy: 0.4250

Epoch 02908: val_loss did not improve from 1.25043
Epoch 2909/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4383 - val_loss: 1.2519 - val_accuracy: 0.4250

Epoch 02909: val_loss did not improve from 1.25043
Epoch 2910/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4401 - val_loss: 1.2538 - val_accuracy: 0.4370

Epoch 02910: val_loss did not improve from 1.25043
Epoch 2911/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4349 - val_loss: 1.2579 - val_accuracy: 0.4314

Epoch 02911: val_loss did not improve from 1.25043
Epoch 2912/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4405 - val_loss: 1.2553 - val_accuracy: 0.4274

Epoch 02912: val_loss did not improve from 1.25043
Epoch 2913/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4376 - val_loss: 1.2648 - val_accuracy: 0.4171

Epoch 02913: val_loss did not improve from 1.25043
Epoch 2914/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4334 - val_loss: 1.2546 - val_accuracy: 0.4298

Epoch 02914: val_loss did not improve from 1.25043
Epoch 2915/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4381 - val_loss: 1.2517 - val_accuracy: 0.4298

Epoch 02915: val_loss did not improve from 1.25043
Epoch 2916/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4378 - val_loss: 1.2527 - val_accuracy: 0.4195

Epoch 02916: val_loss did not improve from 1.25043
Epoch 2917/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4350 - val_loss: 1.2579 - val_accuracy: 0.4354

Epoch 02917: val_loss did not improve from 1.25043
Epoch 2918/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4367 - val_loss: 1.2585 - val_accuracy: 0.4266

Epoch 02918: val_loss did not improve from 1.25043
Epoch 2919/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4378 - val_loss: 1.2546 - val_accuracy: 0.4322

Epoch 02919: val_loss did not improve from 1.25043
Epoch 2920/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4378 - val_loss: 1.2565 - val_accuracy: 0.4258

Epoch 02920: val_loss did not improve from 1.25043
Epoch 2921/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4361 - val_loss: 1.2745 - val_accuracy: 0.4187

Epoch 02921: val_loss did not improve from 1.25043
Epoch 2922/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4393 - val_loss: 1.2576 - val_accuracy: 0.4226

Epoch 02922: val_loss did not improve from 1.25043
Epoch 2923/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4383 - val_loss: 1.2568 - val_accuracy: 0.4282

Epoch 02923: val_loss did not improve from 1.25043
Epoch 2924/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4371 - val_loss: 1.2525 - val_accuracy: 0.4258

Epoch 02924: val_loss did not improve from 1.25043
Epoch 2925/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4394 - val_loss: 1.2546 - val_accuracy: 0.4362

Epoch 02925: val_loss did not improve from 1.25043
Epoch 2926/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4382 - val_loss: 1.2562 - val_accuracy: 0.4219

Epoch 02926: val_loss did not improve from 1.25043
Epoch 2927/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4409 - val_loss: 1.2523 - val_accuracy: 0.4306

Epoch 02927: val_loss did not improve from 1.25043
Epoch 2928/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4366 - val_loss: 1.2560 - val_accuracy: 0.4282

Epoch 02928: val_loss did not improve from 1.25043
Epoch 2929/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4375 - val_loss: 1.2504 - val_accuracy: 0.4330

Epoch 02929: val_loss improved from 1.25043 to 1.25042, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 2930/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4320 - val_loss: 1.2564 - val_accuracy: 0.4234

Epoch 02930: val_loss did not improve from 1.25042
Epoch 2931/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4342 - val_loss: 1.2600 - val_accuracy: 0.4290

Epoch 02931: val_loss did not improve from 1.25042
Epoch 2932/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4317 - val_loss: 1.2665 - val_accuracy: 0.4203

Epoch 02932: val_loss did not improve from 1.25042
Epoch 2933/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4382 - val_loss: 1.2560 - val_accuracy: 0.4306

Epoch 02933: val_loss did not improve from 1.25042
Epoch 2934/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4378 - val_loss: 1.2587 - val_accuracy: 0.4234

Epoch 02934: val_loss did not improve from 1.25042
Epoch 2935/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4361 - val_loss: 1.2551 - val_accuracy: 0.4266

Epoch 02935: val_loss did not improve from 1.25042
Epoch 2936/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4369 - val_loss: 1.2529 - val_accuracy: 0.4338

Epoch 02936: val_loss did not improve from 1.25042
Epoch 2937/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4376 - val_loss: 1.2688 - val_accuracy: 0.4147

Epoch 02937: val_loss did not improve from 1.25042
Epoch 2938/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4331 - val_loss: 1.2612 - val_accuracy: 0.4219

Epoch 02938: val_loss did not improve from 1.25042
Epoch 2939/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4324 - val_loss: 1.2526 - val_accuracy: 0.4386

Epoch 02939: val_loss did not improve from 1.25042
Epoch 2940/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4327 - val_loss: 1.2518 - val_accuracy: 0.4258

Epoch 02940: val_loss did not improve from 1.25042
Epoch 2941/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4381 - val_loss: 1.2513 - val_accuracy: 0.4274

Epoch 02941: val_loss did not improve from 1.25042
Epoch 2942/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4350 - val_loss: 1.2539 - val_accuracy: 0.4394

Epoch 02942: val_loss did not improve from 1.25042
Epoch 2943/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4348 - val_loss: 1.2522 - val_accuracy: 0.4386

Epoch 02943: val_loss did not improve from 1.25042
Epoch 2944/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4326 - val_loss: 1.2703 - val_accuracy: 0.4203

Epoch 02944: val_loss did not improve from 1.25042
Epoch 2945/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4330 - val_loss: 1.2669 - val_accuracy: 0.4234

Epoch 02945: val_loss did not improve from 1.25042
Epoch 2946/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4367 - val_loss: 1.2526 - val_accuracy: 0.4290

Epoch 02946: val_loss did not improve from 1.25042
Epoch 2947/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4378 - val_loss: 1.2547 - val_accuracy: 0.4466

Epoch 02947: val_loss did not improve from 1.25042
Epoch 2948/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4324 - val_loss: 1.2570 - val_accuracy: 0.4250

Epoch 02948: val_loss did not improve from 1.25042
Epoch 2949/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4399 - val_loss: 1.2547 - val_accuracy: 0.4346

Epoch 02949: val_loss did not improve from 1.25042
Epoch 2950/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4395 - val_loss: 1.2641 - val_accuracy: 0.4290

Epoch 02950: val_loss did not improve from 1.25042
Epoch 2951/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4382 - val_loss: 1.2557 - val_accuracy: 0.4346

Epoch 02951: val_loss did not improve from 1.25042
Epoch 2952/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4376 - val_loss: 1.2530 - val_accuracy: 0.4362

Epoch 02952: val_loss did not improve from 1.25042
Epoch 2953/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4375 - val_loss: 1.2516 - val_accuracy: 0.4322

Epoch 02953: val_loss did not improve from 1.25042
Epoch 2954/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4363 - val_loss: 1.2631 - val_accuracy: 0.4282

Epoch 02954: val_loss did not improve from 1.25042
Epoch 2955/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4369 - val_loss: 1.2583 - val_accuracy: 0.4171

Epoch 02955: val_loss did not improve from 1.25042
Epoch 2956/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4368 - val_loss: 1.2517 - val_accuracy: 0.4314

Epoch 02956: val_loss did not improve from 1.25042
Epoch 2957/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4396 - val_loss: 1.2507 - val_accuracy: 0.4354

Epoch 02957: val_loss did not improve from 1.25042
Epoch 2958/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4395 - val_loss: 1.2525 - val_accuracy: 0.4402

Epoch 02958: val_loss did not improve from 1.25042
Epoch 2959/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4396 - val_loss: 1.2605 - val_accuracy: 0.4298

Epoch 02959: val_loss did not improve from 1.25042
Epoch 2960/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4365 - val_loss: 1.2585 - val_accuracy: 0.4250

Epoch 02960: val_loss did not improve from 1.25042
Epoch 2961/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4358 - val_loss: 1.2589 - val_accuracy: 0.4290

Epoch 02961: val_loss did not improve from 1.25042
Epoch 2962/10000
12/12 - 0s - loss: 1.2513 - accuracy: 0.4400 - val_loss: 1.2610 - val_accuracy: 0.4219

Epoch 02962: val_loss did not improve from 1.25042
Epoch 2963/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4390 - val_loss: 1.2602 - val_accuracy: 0.4258

Epoch 02963: val_loss did not improve from 1.25042
Epoch 2964/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4327 - val_loss: 1.2537 - val_accuracy: 0.4330

Epoch 02964: val_loss did not improve from 1.25042
Epoch 2965/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4351 - val_loss: 1.2537 - val_accuracy: 0.4322

Epoch 02965: val_loss did not improve from 1.25042
Epoch 2966/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4386 - val_loss: 1.2512 - val_accuracy: 0.4354

Epoch 02966: val_loss did not improve from 1.25042
Epoch 2967/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4404 - val_loss: 1.2598 - val_accuracy: 0.4298

Epoch 02967: val_loss did not improve from 1.25042
Epoch 2968/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4360 - val_loss: 1.2530 - val_accuracy: 0.4378

Epoch 02968: val_loss did not improve from 1.25042
Epoch 2969/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4365 - val_loss: 1.2544 - val_accuracy: 0.4274

Epoch 02969: val_loss did not improve from 1.25042
Epoch 2970/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4393 - val_loss: 1.2525 - val_accuracy: 0.4418

Epoch 02970: val_loss did not improve from 1.25042
Epoch 2971/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4400 - val_loss: 1.2605 - val_accuracy: 0.4306

Epoch 02971: val_loss did not improve from 1.25042
Epoch 2972/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4413 - val_loss: 1.2535 - val_accuracy: 0.4394

Epoch 02972: val_loss did not improve from 1.25042
Epoch 2973/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4409 - val_loss: 1.2557 - val_accuracy: 0.4330

Epoch 02973: val_loss did not improve from 1.25042
Epoch 2974/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4412 - val_loss: 1.2528 - val_accuracy: 0.4258

Epoch 02974: val_loss did not improve from 1.25042
Epoch 2975/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4351 - val_loss: 1.2533 - val_accuracy: 0.4242

Epoch 02975: val_loss did not improve from 1.25042
Epoch 2976/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4390 - val_loss: 1.2537 - val_accuracy: 0.4314

Epoch 02976: val_loss did not improve from 1.25042
Epoch 2977/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4388 - val_loss: 1.2601 - val_accuracy: 0.4258

Epoch 02977: val_loss did not improve from 1.25042
Epoch 2978/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4357 - val_loss: 1.2575 - val_accuracy: 0.4306

Epoch 02978: val_loss did not improve from 1.25042
Epoch 2979/10000
12/12 - 0s - loss: 1.2512 - accuracy: 0.4375 - val_loss: 1.2533 - val_accuracy: 0.4386

Epoch 02979: val_loss did not improve from 1.25042
Epoch 2980/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4377 - val_loss: 1.2568 - val_accuracy: 0.4250

Epoch 02980: val_loss did not improve from 1.25042
Epoch 2981/10000
12/12 - 0s - loss: 1.2513 - accuracy: 0.4368 - val_loss: 1.2525 - val_accuracy: 0.4370

Epoch 02981: val_loss did not improve from 1.25042
Epoch 2982/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4379 - val_loss: 1.2612 - val_accuracy: 0.4242

Epoch 02982: val_loss did not improve from 1.25042
Epoch 2983/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4310 - val_loss: 1.2563 - val_accuracy: 0.4226

Epoch 02983: val_loss did not improve from 1.25042
Epoch 2984/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4363 - val_loss: 1.2526 - val_accuracy: 0.4378

Epoch 02984: val_loss did not improve from 1.25042
Epoch 2985/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4394 - val_loss: 1.2559 - val_accuracy: 0.4282

Epoch 02985: val_loss did not improve from 1.25042
Epoch 2986/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4348 - val_loss: 1.2528 - val_accuracy: 0.4386

Epoch 02986: val_loss did not improve from 1.25042
Epoch 2987/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4373 - val_loss: 1.2531 - val_accuracy: 0.4298

Epoch 02987: val_loss did not improve from 1.25042
Epoch 2988/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4357 - val_loss: 1.2565 - val_accuracy: 0.4274

Epoch 02988: val_loss did not improve from 1.25042
Epoch 2989/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4379 - val_loss: 1.2543 - val_accuracy: 0.4226

Epoch 02989: val_loss did not improve from 1.25042
Epoch 2990/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4361 - val_loss: 1.2644 - val_accuracy: 0.4203

Epoch 02990: val_loss did not improve from 1.25042
Epoch 2991/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4343 - val_loss: 1.2646 - val_accuracy: 0.4266

Epoch 02991: val_loss did not improve from 1.25042
Epoch 2992/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4323 - val_loss: 1.2655 - val_accuracy: 0.4242

Epoch 02992: val_loss did not improve from 1.25042
Epoch 2993/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4397 - val_loss: 1.2618 - val_accuracy: 0.4258

Epoch 02993: val_loss did not improve from 1.25042
Epoch 2994/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4351 - val_loss: 1.2548 - val_accuracy: 0.4250

Epoch 02994: val_loss did not improve from 1.25042
Epoch 2995/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4361 - val_loss: 1.2514 - val_accuracy: 0.4306

Epoch 02995: val_loss did not improve from 1.25042
Epoch 2996/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4332 - val_loss: 1.2616 - val_accuracy: 0.4187

Epoch 02996: val_loss did not improve from 1.25042
Epoch 2997/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4405 - val_loss: 1.2548 - val_accuracy: 0.4322

Epoch 02997: val_loss did not improve from 1.25042
Epoch 2998/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4380 - val_loss: 1.2601 - val_accuracy: 0.4266

Epoch 02998: val_loss did not improve from 1.25042
Epoch 2999/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4388 - val_loss: 1.2533 - val_accuracy: 0.4354

Epoch 02999: val_loss did not improve from 1.25042
Epoch 3000/10000
12/12 - 0s - loss: 1.2515 - accuracy: 0.4423 - val_loss: 1.2546 - val_accuracy: 0.4282

Epoch 03000: val_loss did not improve from 1.25042
Epoch 3001/10000
12/12 - 0s - loss: 1.2515 - accuracy: 0.4387 - val_loss: 1.2541 - val_accuracy: 0.4426

Epoch 03001: val_loss did not improve from 1.25042
Epoch 3002/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4396 - val_loss: 1.2603 - val_accuracy: 0.4211

Epoch 03002: val_loss did not improve from 1.25042
Epoch 3003/10000
12/12 - 0s - loss: 1.2513 - accuracy: 0.4380 - val_loss: 1.2564 - val_accuracy: 0.4242

Epoch 03003: val_loss did not improve from 1.25042
Epoch 3004/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4365 - val_loss: 1.2579 - val_accuracy: 0.4290

Epoch 03004: val_loss did not improve from 1.25042
Epoch 3005/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4318 - val_loss: 1.2540 - val_accuracy: 0.4314

Epoch 03005: val_loss did not improve from 1.25042
Epoch 3006/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4358 - val_loss: 1.2542 - val_accuracy: 0.4258

Epoch 03006: val_loss did not improve from 1.25042
Epoch 3007/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4374 - val_loss: 1.2552 - val_accuracy: 0.4370

Epoch 03007: val_loss did not improve from 1.25042
Epoch 3008/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4377 - val_loss: 1.2564 - val_accuracy: 0.4290

Epoch 03008: val_loss did not improve from 1.25042
Epoch 3009/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4395 - val_loss: 1.2530 - val_accuracy: 0.4362

Epoch 03009: val_loss did not improve from 1.25042
Epoch 3010/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4404 - val_loss: 1.2658 - val_accuracy: 0.4234

Epoch 03010: val_loss did not improve from 1.25042
Epoch 3011/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4385 - val_loss: 1.2604 - val_accuracy: 0.4219

Epoch 03011: val_loss did not improve from 1.25042
Epoch 3012/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4400 - val_loss: 1.2612 - val_accuracy: 0.4266

Epoch 03012: val_loss did not improve from 1.25042
Epoch 3013/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4348 - val_loss: 1.2647 - val_accuracy: 0.4282

Epoch 03013: val_loss did not improve from 1.25042
Epoch 3014/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4366 - val_loss: 1.2513 - val_accuracy: 0.4402

Epoch 03014: val_loss did not improve from 1.25042
Epoch 3015/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4343 - val_loss: 1.2529 - val_accuracy: 0.4290

Epoch 03015: val_loss did not improve from 1.25042
Epoch 3016/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4349 - val_loss: 1.2524 - val_accuracy: 0.4282

Epoch 03016: val_loss did not improve from 1.25042
Epoch 3017/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4395 - val_loss: 1.2540 - val_accuracy: 0.4418

Epoch 03017: val_loss did not improve from 1.25042
Epoch 3018/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4303 - val_loss: 1.2558 - val_accuracy: 0.4266

Epoch 03018: val_loss did not improve from 1.25042
Epoch 3019/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4295 - val_loss: 1.2767 - val_accuracy: 0.4203

Epoch 03019: val_loss did not improve from 1.25042
Epoch 3020/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4340 - val_loss: 1.2677 - val_accuracy: 0.4250

Epoch 03020: val_loss did not improve from 1.25042
Epoch 3021/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4337 - val_loss: 1.2564 - val_accuracy: 0.4274

Epoch 03021: val_loss did not improve from 1.25042
Epoch 3022/10000
12/12 - 0s - loss: 1.2521 - accuracy: 0.4362 - val_loss: 1.2518 - val_accuracy: 0.4378

Epoch 03022: val_loss did not improve from 1.25042
Epoch 3023/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4388 - val_loss: 1.2574 - val_accuracy: 0.4242

Epoch 03023: val_loss did not improve from 1.25042
Epoch 3024/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4392 - val_loss: 1.2625 - val_accuracy: 0.4171

Epoch 03024: val_loss did not improve from 1.25042
Epoch 3025/10000
12/12 - 0s - loss: 1.2541 - accuracy: 0.4364 - val_loss: 1.2650 - val_accuracy: 0.4258

Epoch 03025: val_loss did not improve from 1.25042
Epoch 3026/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4353 - val_loss: 1.2537 - val_accuracy: 0.4322

Epoch 03026: val_loss did not improve from 1.25042
Epoch 3027/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4373 - val_loss: 1.2526 - val_accuracy: 0.4258

Epoch 03027: val_loss did not improve from 1.25042
Epoch 3028/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4388 - val_loss: 1.2564 - val_accuracy: 0.4171

Epoch 03028: val_loss did not improve from 1.25042
Epoch 3029/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4404 - val_loss: 1.2615 - val_accuracy: 0.4211

Epoch 03029: val_loss did not improve from 1.25042
Epoch 3030/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4332 - val_loss: 1.2523 - val_accuracy: 0.4282

Epoch 03030: val_loss did not improve from 1.25042
Epoch 3031/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4388 - val_loss: 1.2565 - val_accuracy: 0.4226

Epoch 03031: val_loss did not improve from 1.25042
Epoch 3032/10000
12/12 - 0s - loss: 1.2503 - accuracy: 0.4395 - val_loss: 1.2556 - val_accuracy: 0.4282

Epoch 03032: val_loss did not improve from 1.25042
Epoch 3033/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4342 - val_loss: 1.2549 - val_accuracy: 0.4211

Epoch 03033: val_loss did not improve from 1.25042
Epoch 3034/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4399 - val_loss: 1.2545 - val_accuracy: 0.4330

Epoch 03034: val_loss did not improve from 1.25042
Epoch 3035/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4388 - val_loss: 1.2517 - val_accuracy: 0.4274

Epoch 03035: val_loss did not improve from 1.25042
Epoch 3036/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4389 - val_loss: 1.2572 - val_accuracy: 0.4195

Epoch 03036: val_loss did not improve from 1.25042
Epoch 3037/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4373 - val_loss: 1.2540 - val_accuracy: 0.4163

Epoch 03037: val_loss did not improve from 1.25042
Epoch 3038/10000
12/12 - 0s - loss: 1.2507 - accuracy: 0.4435 - val_loss: 1.2541 - val_accuracy: 0.4338

Epoch 03038: val_loss did not improve from 1.25042
Epoch 3039/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4342 - val_loss: 1.2630 - val_accuracy: 0.4370

Epoch 03039: val_loss did not improve from 1.25042
Epoch 3040/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4408 - val_loss: 1.2586 - val_accuracy: 0.4234

Epoch 03040: val_loss did not improve from 1.25042
Epoch 3041/10000
12/12 - 0s - loss: 1.2511 - accuracy: 0.4410 - val_loss: 1.2556 - val_accuracy: 0.4346

Epoch 03041: val_loss did not improve from 1.25042
Epoch 3042/10000
12/12 - 0s - loss: 1.2510 - accuracy: 0.4420 - val_loss: 1.2504 - val_accuracy: 0.4362

Epoch 03042: val_loss did not improve from 1.25042
Epoch 3043/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4387 - val_loss: 1.2559 - val_accuracy: 0.4266

Epoch 03043: val_loss did not improve from 1.25042
Epoch 3044/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4374 - val_loss: 1.2677 - val_accuracy: 0.4219

Epoch 03044: val_loss did not improve from 1.25042
Epoch 3045/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4387 - val_loss: 1.2594 - val_accuracy: 0.4282

Epoch 03045: val_loss did not improve from 1.25042
Epoch 3046/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4358 - val_loss: 1.2535 - val_accuracy: 0.4394

Epoch 03046: val_loss did not improve from 1.25042
Epoch 3047/10000
12/12 - 0s - loss: 1.2510 - accuracy: 0.4402 - val_loss: 1.2573 - val_accuracy: 0.4258

Epoch 03047: val_loss did not improve from 1.25042
Epoch 3048/10000
12/12 - 0s - loss: 1.2510 - accuracy: 0.4391 - val_loss: 1.2545 - val_accuracy: 0.4282

Epoch 03048: val_loss did not improve from 1.25042
Epoch 3049/10000
12/12 - 0s - loss: 1.2506 - accuracy: 0.4399 - val_loss: 1.2516 - val_accuracy: 0.4330

Epoch 03049: val_loss did not improve from 1.25042
Epoch 3050/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4412 - val_loss: 1.2556 - val_accuracy: 0.4242

Epoch 03050: val_loss did not improve from 1.25042
Epoch 3051/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4397 - val_loss: 1.2529 - val_accuracy: 0.4219

Epoch 03051: val_loss did not improve from 1.25042
Epoch 3052/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4389 - val_loss: 1.2565 - val_accuracy: 0.4250

Epoch 03052: val_loss did not improve from 1.25042
Epoch 3053/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4361 - val_loss: 1.2563 - val_accuracy: 0.4314

Epoch 03053: val_loss did not improve from 1.25042
Epoch 3054/10000
12/12 - 0s - loss: 1.2507 - accuracy: 0.4382 - val_loss: 1.2555 - val_accuracy: 0.4298

Epoch 03054: val_loss did not improve from 1.25042
Epoch 3055/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4388 - val_loss: 1.2568 - val_accuracy: 0.4298

Epoch 03055: val_loss did not improve from 1.25042
Epoch 3056/10000
12/12 - 0s - loss: 1.2521 - accuracy: 0.4406 - val_loss: 1.2525 - val_accuracy: 0.4314

Epoch 03056: val_loss did not improve from 1.25042
Epoch 3057/10000
12/12 - 0s - loss: 1.2511 - accuracy: 0.4399 - val_loss: 1.2528 - val_accuracy: 0.4354

Epoch 03057: val_loss did not improve from 1.25042
Epoch 3058/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4427 - val_loss: 1.2496 - val_accuracy: 0.4322

Epoch 03058: val_loss improved from 1.25042 to 1.24964, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 3059/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4365 - val_loss: 1.2609 - val_accuracy: 0.4234

Epoch 03059: val_loss did not improve from 1.24964
Epoch 3060/10000
12/12 - 0s - loss: 1.2519 - accuracy: 0.4401 - val_loss: 1.2522 - val_accuracy: 0.4426

Epoch 03060: val_loss did not improve from 1.24964
Epoch 3061/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4367 - val_loss: 1.2679 - val_accuracy: 0.4274

Epoch 03061: val_loss did not improve from 1.24964
Epoch 3062/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4370 - val_loss: 1.2644 - val_accuracy: 0.4266

Epoch 03062: val_loss did not improve from 1.24964
Epoch 3063/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4389 - val_loss: 1.2589 - val_accuracy: 0.4282

Epoch 03063: val_loss did not improve from 1.24964
Epoch 3064/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4343 - val_loss: 1.2526 - val_accuracy: 0.4314

Epoch 03064: val_loss did not improve from 1.24964
Epoch 3065/10000
12/12 - 0s - loss: 1.2524 - accuracy: 0.4421 - val_loss: 1.2504 - val_accuracy: 0.4370

Epoch 03065: val_loss did not improve from 1.24964
Epoch 3066/10000
12/12 - 0s - loss: 1.2515 - accuracy: 0.4420 - val_loss: 1.2550 - val_accuracy: 0.4282

Epoch 03066: val_loss did not improve from 1.24964
Epoch 3067/10000
12/12 - 0s - loss: 1.2505 - accuracy: 0.4420 - val_loss: 1.2542 - val_accuracy: 0.4274

Epoch 03067: val_loss did not improve from 1.24964
Epoch 3068/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4396 - val_loss: 1.2665 - val_accuracy: 0.4234

Epoch 03068: val_loss did not improve from 1.24964
Epoch 3069/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4385 - val_loss: 1.2513 - val_accuracy: 0.4250

Epoch 03069: val_loss did not improve from 1.24964
Epoch 3070/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4404 - val_loss: 1.2570 - val_accuracy: 0.4211

Epoch 03070: val_loss did not improve from 1.24964
Epoch 3071/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4371 - val_loss: 1.2521 - val_accuracy: 0.4330

Epoch 03071: val_loss did not improve from 1.24964
Epoch 3072/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4369 - val_loss: 1.2491 - val_accuracy: 0.4338

Epoch 03072: val_loss improved from 1.24964 to 1.24906, saving model to ./results/NN_thk_class/aggr_theta/ckpt_7
Epoch 3073/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4374 - val_loss: 1.2519 - val_accuracy: 0.4274

Epoch 03073: val_loss did not improve from 1.24906
Epoch 3074/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4369 - val_loss: 1.2581 - val_accuracy: 0.4354

Epoch 03074: val_loss did not improve from 1.24906
Epoch 3075/10000
12/12 - 0s - loss: 1.2515 - accuracy: 0.4388 - val_loss: 1.2570 - val_accuracy: 0.4282

Epoch 03075: val_loss did not improve from 1.24906
Epoch 3076/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4424 - val_loss: 1.2642 - val_accuracy: 0.4314

Epoch 03076: val_loss did not improve from 1.24906
Epoch 3077/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4409 - val_loss: 1.2591 - val_accuracy: 0.4258

Epoch 03077: val_loss did not improve from 1.24906
Epoch 3078/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4389 - val_loss: 1.2534 - val_accuracy: 0.4274

Epoch 03078: val_loss did not improve from 1.24906
Epoch 3079/10000
12/12 - 0s - loss: 1.2527 - accuracy: 0.4397 - val_loss: 1.2587 - val_accuracy: 0.4234

Epoch 03079: val_loss did not improve from 1.24906
Epoch 3080/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4378 - val_loss: 1.2693 - val_accuracy: 0.4242

Epoch 03080: val_loss did not improve from 1.24906
Epoch 3081/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4345 - val_loss: 1.2521 - val_accuracy: 0.4330

Epoch 03081: val_loss did not improve from 1.24906
Epoch 3082/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4398 - val_loss: 1.2524 - val_accuracy: 0.4378

Epoch 03082: val_loss did not improve from 1.24906
Epoch 3083/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4404 - val_loss: 1.2532 - val_accuracy: 0.4354

Epoch 03083: val_loss did not improve from 1.24906
Epoch 3084/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4376 - val_loss: 1.2627 - val_accuracy: 0.4290

Epoch 03084: val_loss did not improve from 1.24906
Epoch 3085/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4381 - val_loss: 1.2543 - val_accuracy: 0.4346

Epoch 03085: val_loss did not improve from 1.24906
Epoch 3086/10000
12/12 - 0s - loss: 1.2518 - accuracy: 0.4380 - val_loss: 1.2540 - val_accuracy: 0.4330

Epoch 03086: val_loss did not improve from 1.24906
Epoch 3087/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4382 - val_loss: 1.2615 - val_accuracy: 0.4282

Epoch 03087: val_loss did not improve from 1.24906
Epoch 3088/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4395 - val_loss: 1.2523 - val_accuracy: 0.4402

Epoch 03088: val_loss did not improve from 1.24906
Epoch 3089/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4396 - val_loss: 1.2562 - val_accuracy: 0.4282

Epoch 03089: val_loss did not improve from 1.24906
Epoch 3090/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4389 - val_loss: 1.2589 - val_accuracy: 0.4242

Epoch 03090: val_loss did not improve from 1.24906
Epoch 3091/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4358 - val_loss: 1.2558 - val_accuracy: 0.4298

Epoch 03091: val_loss did not improve from 1.24906
Epoch 3092/10000
12/12 - 0s - loss: 1.2507 - accuracy: 0.4356 - val_loss: 1.2528 - val_accuracy: 0.4434

Epoch 03092: val_loss did not improve from 1.24906
Epoch 3093/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4373 - val_loss: 1.2545 - val_accuracy: 0.4322

Epoch 03093: val_loss did not improve from 1.24906
Epoch 3094/10000
12/12 - 0s - loss: 1.2512 - accuracy: 0.4399 - val_loss: 1.2557 - val_accuracy: 0.4226

Epoch 03094: val_loss did not improve from 1.24906
Epoch 3095/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4396 - val_loss: 1.2644 - val_accuracy: 0.4187

Epoch 03095: val_loss did not improve from 1.24906
Epoch 3096/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4354 - val_loss: 1.2521 - val_accuracy: 0.4410

Epoch 03096: val_loss did not improve from 1.24906
Epoch 3097/10000
12/12 - 0s - loss: 1.2508 - accuracy: 0.4411 - val_loss: 1.2571 - val_accuracy: 0.4290

Epoch 03097: val_loss did not improve from 1.24906
Epoch 3098/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4391 - val_loss: 1.2624 - val_accuracy: 0.4258

Epoch 03098: val_loss did not improve from 1.24906
Epoch 3099/10000
12/12 - 0s - loss: 1.2510 - accuracy: 0.4428 - val_loss: 1.2533 - val_accuracy: 0.4274

Epoch 03099: val_loss did not improve from 1.24906
Epoch 3100/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4401 - val_loss: 1.2571 - val_accuracy: 0.4346

Epoch 03100: val_loss did not improve from 1.24906
Epoch 3101/10000
12/12 - 0s - loss: 1.2521 - accuracy: 0.4379 - val_loss: 1.2643 - val_accuracy: 0.4322

Epoch 03101: val_loss did not improve from 1.24906
Epoch 3102/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4373 - val_loss: 1.2530 - val_accuracy: 0.4282

Epoch 03102: val_loss did not improve from 1.24906
Epoch 3103/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4396 - val_loss: 1.2584 - val_accuracy: 0.4338

Epoch 03103: val_loss did not improve from 1.24906
Epoch 3104/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4363 - val_loss: 1.2726 - val_accuracy: 0.4234

Epoch 03104: val_loss did not improve from 1.24906
Epoch 3105/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4365 - val_loss: 1.2566 - val_accuracy: 0.4266

Epoch 03105: val_loss did not improve from 1.24906
Epoch 3106/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4403 - val_loss: 1.2535 - val_accuracy: 0.4290

Epoch 03106: val_loss did not improve from 1.24906
Epoch 3107/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4390 - val_loss: 1.2569 - val_accuracy: 0.4258

Epoch 03107: val_loss did not improve from 1.24906
Epoch 3108/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4397 - val_loss: 1.2549 - val_accuracy: 0.4330

Epoch 03108: val_loss did not improve from 1.24906
Epoch 3109/10000
12/12 - 0s - loss: 1.2503 - accuracy: 0.4384 - val_loss: 1.2545 - val_accuracy: 0.4274

Epoch 03109: val_loss did not improve from 1.24906
Epoch 3110/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4387 - val_loss: 1.2602 - val_accuracy: 0.4338

Epoch 03110: val_loss did not improve from 1.24906
Epoch 3111/10000
12/12 - 0s - loss: 1.2513 - accuracy: 0.4366 - val_loss: 1.2624 - val_accuracy: 0.4234

Epoch 03111: val_loss did not improve from 1.24906
Epoch 3112/10000
12/12 - 0s - loss: 1.2513 - accuracy: 0.4381 - val_loss: 1.2598 - val_accuracy: 0.4250

Epoch 03112: val_loss did not improve from 1.24906
Epoch 3113/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4375 - val_loss: 1.2522 - val_accuracy: 0.4290

Epoch 03113: val_loss did not improve from 1.24906
Epoch 3114/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4369 - val_loss: 1.2541 - val_accuracy: 0.4298

Epoch 03114: val_loss did not improve from 1.24906
Epoch 3115/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4377 - val_loss: 1.2550 - val_accuracy: 0.4266

Epoch 03115: val_loss did not improve from 1.24906
Epoch 3116/10000
12/12 - 0s - loss: 1.2501 - accuracy: 0.4381 - val_loss: 1.2551 - val_accuracy: 0.4266

Epoch 03116: val_loss did not improve from 1.24906
Epoch 3117/10000
12/12 - 0s - loss: 1.2518 - accuracy: 0.4374 - val_loss: 1.2572 - val_accuracy: 0.4242

Epoch 03117: val_loss did not improve from 1.24906
Epoch 3118/10000
12/12 - 0s - loss: 1.2497 - accuracy: 0.4405 - val_loss: 1.2523 - val_accuracy: 0.4298

Epoch 03118: val_loss did not improve from 1.24906
Epoch 3119/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4334 - val_loss: 1.2543 - val_accuracy: 0.4234

Epoch 03119: val_loss did not improve from 1.24906
Epoch 3120/10000
12/12 - 0s - loss: 1.2512 - accuracy: 0.4348 - val_loss: 1.2551 - val_accuracy: 0.4242

Epoch 03120: val_loss did not improve from 1.24906
Epoch 3121/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4393 - val_loss: 1.2529 - val_accuracy: 0.4386

Epoch 03121: val_loss did not improve from 1.24906
Epoch 3122/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4380 - val_loss: 1.2550 - val_accuracy: 0.4258

Epoch 03122: val_loss did not improve from 1.24906
Epoch 3123/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4390 - val_loss: 1.2509 - val_accuracy: 0.4346

Epoch 03123: val_loss did not improve from 1.24906
Epoch 3124/10000
12/12 - 0s - loss: 1.2521 - accuracy: 0.4377 - val_loss: 1.2618 - val_accuracy: 0.4219

Epoch 03124: val_loss did not improve from 1.24906
Epoch 3125/10000
12/12 - 0s - loss: 1.2518 - accuracy: 0.4334 - val_loss: 1.2602 - val_accuracy: 0.4258

Epoch 03125: val_loss did not improve from 1.24906
Epoch 3126/10000
12/12 - 0s - loss: 1.2502 - accuracy: 0.4390 - val_loss: 1.2604 - val_accuracy: 0.4250

Epoch 03126: val_loss did not improve from 1.24906
Epoch 3127/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4372 - val_loss: 1.2597 - val_accuracy: 0.4179

Epoch 03127: val_loss did not improve from 1.24906
Epoch 3128/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4382 - val_loss: 1.2523 - val_accuracy: 0.4330

Epoch 03128: val_loss did not improve from 1.24906
Epoch 3129/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4391 - val_loss: 1.2528 - val_accuracy: 0.4346

Epoch 03129: val_loss did not improve from 1.24906
Epoch 3130/10000
12/12 - 0s - loss: 1.2501 - accuracy: 0.4427 - val_loss: 1.2525 - val_accuracy: 0.4338

Epoch 03130: val_loss did not improve from 1.24906
Epoch 3131/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4333 - val_loss: 1.2575 - val_accuracy: 0.4211

Epoch 03131: val_loss did not improve from 1.24906
Epoch 3132/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4389 - val_loss: 1.2665 - val_accuracy: 0.4187

Epoch 03132: val_loss did not improve from 1.24906
Epoch 3133/10000
12/12 - 0s - loss: 1.2496 - accuracy: 0.4393 - val_loss: 1.2533 - val_accuracy: 0.4242

Epoch 03133: val_loss did not improve from 1.24906
Epoch 3134/10000
12/12 - 0s - loss: 1.2508 - accuracy: 0.4391 - val_loss: 1.2553 - val_accuracy: 0.4290

Epoch 03134: val_loss did not improve from 1.24906
Epoch 3135/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4364 - val_loss: 1.2581 - val_accuracy: 0.4234

Epoch 03135: val_loss did not improve from 1.24906
Epoch 3136/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4352 - val_loss: 1.2535 - val_accuracy: 0.4171

Epoch 03136: val_loss did not improve from 1.24906
Epoch 3137/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4376 - val_loss: 1.2569 - val_accuracy: 0.4250

Epoch 03137: val_loss did not improve from 1.24906
Epoch 3138/10000
12/12 - 0s - loss: 1.2500 - accuracy: 0.4408 - val_loss: 1.2587 - val_accuracy: 0.4234

Epoch 03138: val_loss did not improve from 1.24906
Epoch 3139/10000
12/12 - 0s - loss: 1.2496 - accuracy: 0.4402 - val_loss: 1.2619 - val_accuracy: 0.4290

Epoch 03139: val_loss did not improve from 1.24906
Epoch 3140/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4398 - val_loss: 1.2615 - val_accuracy: 0.4250

Epoch 03140: val_loss did not improve from 1.24906
Epoch 3141/10000
12/12 - 0s - loss: 1.2502 - accuracy: 0.4370 - val_loss: 1.2637 - val_accuracy: 0.4298

Epoch 03141: val_loss did not improve from 1.24906
Epoch 3142/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4384 - val_loss: 1.2590 - val_accuracy: 0.4242

Epoch 03142: val_loss did not improve from 1.24906
Epoch 3143/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4354 - val_loss: 1.2543 - val_accuracy: 0.4211

Epoch 03143: val_loss did not improve from 1.24906
Epoch 3144/10000
12/12 - 0s - loss: 1.2504 - accuracy: 0.4380 - val_loss: 1.2543 - val_accuracy: 0.4290

Epoch 03144: val_loss did not improve from 1.24906
Epoch 3145/10000
12/12 - 0s - loss: 1.2504 - accuracy: 0.4399 - val_loss: 1.2680 - val_accuracy: 0.4282

Epoch 03145: val_loss did not improve from 1.24906
Epoch 3146/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4334 - val_loss: 1.2538 - val_accuracy: 0.4306

Epoch 03146: val_loss did not improve from 1.24906
Epoch 3147/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4357 - val_loss: 1.2527 - val_accuracy: 0.4378

Epoch 03147: val_loss did not improve from 1.24906
Epoch 3148/10000
12/12 - 0s - loss: 1.2511 - accuracy: 0.4407 - val_loss: 1.2558 - val_accuracy: 0.4306

Epoch 03148: val_loss did not improve from 1.24906
Epoch 3149/10000
12/12 - 0s - loss: 1.2502 - accuracy: 0.4381 - val_loss: 1.2536 - val_accuracy: 0.4322

Epoch 03149: val_loss did not improve from 1.24906
Epoch 3150/10000
12/12 - 0s - loss: 1.2540 - accuracy: 0.4391 - val_loss: 1.2532 - val_accuracy: 0.4354

Epoch 03150: val_loss did not improve from 1.24906
Epoch 3151/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4327 - val_loss: 1.2669 - val_accuracy: 0.4250

Epoch 03151: val_loss did not improve from 1.24906
Epoch 3152/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4388 - val_loss: 1.2588 - val_accuracy: 0.4314

Epoch 03152: val_loss did not improve from 1.24906
Epoch 3153/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4411 - val_loss: 1.2579 - val_accuracy: 0.4378

Epoch 03153: val_loss did not improve from 1.24906
Epoch 3154/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4373 - val_loss: 1.2529 - val_accuracy: 0.4354

Epoch 03154: val_loss did not improve from 1.24906
Epoch 3155/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4375 - val_loss: 1.2673 - val_accuracy: 0.4187

Epoch 03155: val_loss did not improve from 1.24906
Epoch 3156/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4359 - val_loss: 1.2706 - val_accuracy: 0.4163

Epoch 03156: val_loss did not improve from 1.24906
Epoch 3157/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4362 - val_loss: 1.2651 - val_accuracy: 0.4171

Epoch 03157: val_loss did not improve from 1.24906
Epoch 3158/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4339 - val_loss: 1.2514 - val_accuracy: 0.4306

Epoch 03158: val_loss did not improve from 1.24906
Epoch 3159/10000
12/12 - 0s - loss: 1.2510 - accuracy: 0.4372 - val_loss: 1.2534 - val_accuracy: 0.4322

Epoch 03159: val_loss did not improve from 1.24906
Epoch 3160/10000
12/12 - 0s - loss: 1.2518 - accuracy: 0.4370 - val_loss: 1.2571 - val_accuracy: 0.4282

Epoch 03160: val_loss did not improve from 1.24906
Epoch 3161/10000
12/12 - 0s - loss: 1.2512 - accuracy: 0.4349 - val_loss: 1.2584 - val_accuracy: 0.4298

Epoch 03161: val_loss did not improve from 1.24906
Epoch 3162/10000
12/12 - 0s - loss: 1.2502 - accuracy: 0.4402 - val_loss: 1.2554 - val_accuracy: 0.4314

Epoch 03162: val_loss did not improve from 1.24906
Epoch 3163/10000
12/12 - 0s - loss: 1.2520 - accuracy: 0.4385 - val_loss: 1.2564 - val_accuracy: 0.4179

Epoch 03163: val_loss did not improve from 1.24906
Epoch 3164/10000
12/12 - 0s - loss: 1.2517 - accuracy: 0.4363 - val_loss: 1.2518 - val_accuracy: 0.4330

Epoch 03164: val_loss did not improve from 1.24906
Epoch 3165/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4405 - val_loss: 1.2523 - val_accuracy: 0.4290

Epoch 03165: val_loss did not improve from 1.24906
Epoch 3166/10000
12/12 - 0s - loss: 1.2505 - accuracy: 0.4398 - val_loss: 1.2516 - val_accuracy: 0.4298

Epoch 03166: val_loss did not improve from 1.24906
Epoch 3167/10000
12/12 - 0s - loss: 1.2508 - accuracy: 0.4418 - val_loss: 1.2563 - val_accuracy: 0.4290

Epoch 03167: val_loss did not improve from 1.24906
Epoch 3168/10000
12/12 - 0s - loss: 1.2495 - accuracy: 0.4414 - val_loss: 1.2609 - val_accuracy: 0.4242

Epoch 03168: val_loss did not improve from 1.24906
Epoch 3169/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4385 - val_loss: 1.2569 - val_accuracy: 0.4242

Epoch 03169: val_loss did not improve from 1.24906
Epoch 3170/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4363 - val_loss: 1.2534 - val_accuracy: 0.4346

Epoch 03170: val_loss did not improve from 1.24906
Epoch 3171/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4385 - val_loss: 1.2586 - val_accuracy: 0.4386

Epoch 03171: val_loss did not improve from 1.24906
Epoch 3172/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4371 - val_loss: 1.2645 - val_accuracy: 0.4234

Epoch 03172: val_loss did not improve from 1.24906
Epoch 3173/10000
12/12 - 0s - loss: 1.2523 - accuracy: 0.4373 - val_loss: 1.2731 - val_accuracy: 0.4147

Epoch 03173: val_loss did not improve from 1.24906
Epoch 3174/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4337 - val_loss: 1.2606 - val_accuracy: 0.4266

Epoch 03174: val_loss did not improve from 1.24906
Epoch 3175/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4378 - val_loss: 1.2551 - val_accuracy: 0.4322

Epoch 03175: val_loss did not improve from 1.24906
Epoch 3176/10000
12/12 - 0s - loss: 1.2511 - accuracy: 0.4407 - val_loss: 1.2603 - val_accuracy: 0.4258

Epoch 03176: val_loss did not improve from 1.24906
Epoch 3177/10000
12/12 - 0s - loss: 1.2491 - accuracy: 0.4404 - val_loss: 1.2535 - val_accuracy: 0.4322

Epoch 03177: val_loss did not improve from 1.24906
Epoch 3178/10000
12/12 - 0s - loss: 1.2501 - accuracy: 0.4386 - val_loss: 1.2546 - val_accuracy: 0.4346

Epoch 03178: val_loss did not improve from 1.24906
Epoch 3179/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4381 - val_loss: 1.2600 - val_accuracy: 0.4282

Epoch 03179: val_loss did not improve from 1.24906
Epoch 3180/10000
12/12 - 0s - loss: 1.2528 - accuracy: 0.4375 - val_loss: 1.2599 - val_accuracy: 0.4274

Epoch 03180: val_loss did not improve from 1.24906
Epoch 3181/10000
12/12 - 0s - loss: 1.2534 - accuracy: 0.4368 - val_loss: 1.2700 - val_accuracy: 0.4147

Epoch 03181: val_loss did not improve from 1.24906
Epoch 3182/10000
12/12 - 0s - loss: 1.2522 - accuracy: 0.4379 - val_loss: 1.2721 - val_accuracy: 0.4171

Epoch 03182: val_loss did not improve from 1.24906
Epoch 3183/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4315 - val_loss: 1.2697 - val_accuracy: 0.4179

Epoch 03183: val_loss did not improve from 1.24906
Epoch 3184/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4350 - val_loss: 1.2526 - val_accuracy: 0.4394

Epoch 03184: val_loss did not improve from 1.24906
Epoch 3185/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4391 - val_loss: 1.2538 - val_accuracy: 0.4434

Epoch 03185: val_loss did not improve from 1.24906
Epoch 3186/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4362 - val_loss: 1.2562 - val_accuracy: 0.4314

Epoch 03186: val_loss did not improve from 1.24906
Epoch 3187/10000
12/12 - 0s - loss: 1.2515 - accuracy: 0.4368 - val_loss: 1.2548 - val_accuracy: 0.4378

Epoch 03187: val_loss did not improve from 1.24906
Epoch 3188/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4369 - val_loss: 1.2578 - val_accuracy: 0.4330

Epoch 03188: val_loss did not improve from 1.24906
Epoch 3189/10000
12/12 - 0s - loss: 1.2505 - accuracy: 0.4400 - val_loss: 1.2565 - val_accuracy: 0.4490

Epoch 03189: val_loss did not improve from 1.24906
Epoch 3190/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4350 - val_loss: 1.2693 - val_accuracy: 0.4226

Epoch 03190: val_loss did not improve from 1.24906
Epoch 3191/10000
12/12 - 0s - loss: 1.2515 - accuracy: 0.4397 - val_loss: 1.2584 - val_accuracy: 0.4314

Epoch 03191: val_loss did not improve from 1.24906
Epoch 3192/10000
12/12 - 0s - loss: 1.2501 - accuracy: 0.4394 - val_loss: 1.2547 - val_accuracy: 0.4322

Epoch 03192: val_loss did not improve from 1.24906
Epoch 3193/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4356 - val_loss: 1.2554 - val_accuracy: 0.4322

Epoch 03193: val_loss did not improve from 1.24906
Epoch 3194/10000
12/12 - 0s - loss: 1.2501 - accuracy: 0.4411 - val_loss: 1.2564 - val_accuracy: 0.4346

Epoch 03194: val_loss did not improve from 1.24906
Epoch 3195/10000
12/12 - 0s - loss: 1.2499 - accuracy: 0.4379 - val_loss: 1.2596 - val_accuracy: 0.4306

Epoch 03195: val_loss did not improve from 1.24906
Epoch 3196/10000
12/12 - 0s - loss: 1.2511 - accuracy: 0.4425 - val_loss: 1.2515 - val_accuracy: 0.4330

Epoch 03196: val_loss did not improve from 1.24906
Epoch 3197/10000
12/12 - 0s - loss: 1.2500 - accuracy: 0.4374 - val_loss: 1.2541 - val_accuracy: 0.4250

Epoch 03197: val_loss did not improve from 1.24906
Epoch 3198/10000
12/12 - 0s - loss: 1.2494 - accuracy: 0.4404 - val_loss: 1.2564 - val_accuracy: 0.4330

Epoch 03198: val_loss did not improve from 1.24906
Epoch 3199/10000
12/12 - 0s - loss: 1.2481 - accuracy: 0.4427 - val_loss: 1.2518 - val_accuracy: 0.4306

Epoch 03199: val_loss did not improve from 1.24906
Epoch 3200/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4371 - val_loss: 1.2635 - val_accuracy: 0.4274

Epoch 03200: val_loss did not improve from 1.24906
Epoch 3201/10000
12/12 - 0s - loss: 1.2498 - accuracy: 0.4408 - val_loss: 1.2565 - val_accuracy: 0.4242

Epoch 03201: val_loss did not improve from 1.24906
Epoch 3202/10000
12/12 - 0s - loss: 1.2504 - accuracy: 0.4413 - val_loss: 1.2589 - val_accuracy: 0.4234

Epoch 03202: val_loss did not improve from 1.24906
Epoch 3203/10000
12/12 - 0s - loss: 1.2512 - accuracy: 0.4376 - val_loss: 1.2646 - val_accuracy: 0.4211

Epoch 03203: val_loss did not improve from 1.24906
Epoch 3204/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4287 - val_loss: 1.2650 - val_accuracy: 0.4282

Epoch 03204: val_loss did not improve from 1.24906
Epoch 3205/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4301 - val_loss: 1.2585 - val_accuracy: 0.4418

Epoch 03205: val_loss did not improve from 1.24906
Epoch 3206/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4386 - val_loss: 1.2520 - val_accuracy: 0.4394

Epoch 03206: val_loss did not improve from 1.24906
Epoch 3207/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4342 - val_loss: 1.2696 - val_accuracy: 0.4179

Epoch 03207: val_loss did not improve from 1.24906
Epoch 3208/10000
12/12 - 0s - loss: 1.2513 - accuracy: 0.4376 - val_loss: 1.2584 - val_accuracy: 0.4274

Epoch 03208: val_loss did not improve from 1.24906
Epoch 3209/10000
12/12 - 0s - loss: 1.2497 - accuracy: 0.4379 - val_loss: 1.2549 - val_accuracy: 0.4282

Epoch 03209: val_loss did not improve from 1.24906
Epoch 3210/10000
12/12 - 0s - loss: 1.2496 - accuracy: 0.4392 - val_loss: 1.2524 - val_accuracy: 0.4242

Epoch 03210: val_loss did not improve from 1.24906
Epoch 3211/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4382 - val_loss: 1.2596 - val_accuracy: 0.4306

Epoch 03211: val_loss did not improve from 1.24906
Epoch 3212/10000
12/12 - 0s - loss: 1.2498 - accuracy: 0.4380 - val_loss: 1.2614 - val_accuracy: 0.4346

Epoch 03212: val_loss did not improve from 1.24906
Epoch 3213/10000
12/12 - 0s - loss: 1.2500 - accuracy: 0.4397 - val_loss: 1.2628 - val_accuracy: 0.4282

Epoch 03213: val_loss did not improve from 1.24906
Epoch 3214/10000
12/12 - 0s - loss: 1.2507 - accuracy: 0.4380 - val_loss: 1.2545 - val_accuracy: 0.4418

Epoch 03214: val_loss did not improve from 1.24906
Epoch 3215/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4411 - val_loss: 1.2577 - val_accuracy: 0.4242

Epoch 03215: val_loss did not improve from 1.24906
Epoch 3216/10000
12/12 - 0s - loss: 1.2494 - accuracy: 0.4399 - val_loss: 1.2601 - val_accuracy: 0.4250

Epoch 03216: val_loss did not improve from 1.24906
Epoch 3217/10000
12/12 - 0s - loss: 1.2513 - accuracy: 0.4347 - val_loss: 1.2579 - val_accuracy: 0.4258

Epoch 03217: val_loss did not improve from 1.24906
Epoch 3218/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4388 - val_loss: 1.2513 - val_accuracy: 0.4322

Epoch 03218: val_loss did not improve from 1.24906
Epoch 3219/10000
12/12 - 0s - loss: 1.2505 - accuracy: 0.4385 - val_loss: 1.2556 - val_accuracy: 0.4179

Epoch 03219: val_loss did not improve from 1.24906
Epoch 3220/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4398 - val_loss: 1.2617 - val_accuracy: 0.4219

Epoch 03220: val_loss did not improve from 1.24906
Epoch 3221/10000
12/12 - 0s - loss: 1.2505 - accuracy: 0.4363 - val_loss: 1.2535 - val_accuracy: 0.4346

Epoch 03221: val_loss did not improve from 1.24906
Epoch 3222/10000
12/12 - 0s - loss: 1.2511 - accuracy: 0.4383 - val_loss: 1.2581 - val_accuracy: 0.4290

Epoch 03222: val_loss did not improve from 1.24906
Epoch 3223/10000
12/12 - 0s - loss: 1.2496 - accuracy: 0.4411 - val_loss: 1.2602 - val_accuracy: 0.4322

Epoch 03223: val_loss did not improve from 1.24906
Epoch 3224/10000
12/12 - 0s - loss: 1.2496 - accuracy: 0.4421 - val_loss: 1.2550 - val_accuracy: 0.4378

Epoch 03224: val_loss did not improve from 1.24906
Epoch 3225/10000
12/12 - 0s - loss: 1.2495 - accuracy: 0.4386 - val_loss: 1.2520 - val_accuracy: 0.4306

Epoch 03225: val_loss did not improve from 1.24906
Epoch 3226/10000
12/12 - 0s - loss: 1.2503 - accuracy: 0.4390 - val_loss: 1.2525 - val_accuracy: 0.4346

Epoch 03226: val_loss did not improve from 1.24906
Epoch 3227/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4335 - val_loss: 1.2631 - val_accuracy: 0.4290

Epoch 03227: val_loss did not improve from 1.24906
Epoch 3228/10000
12/12 - 0s - loss: 1.2500 - accuracy: 0.4406 - val_loss: 1.2600 - val_accuracy: 0.4298

Epoch 03228: val_loss did not improve from 1.24906
Epoch 3229/10000
12/12 - 0s - loss: 1.2495 - accuracy: 0.4385 - val_loss: 1.2575 - val_accuracy: 0.4298

Epoch 03229: val_loss did not improve from 1.24906
Epoch 3230/10000
12/12 - 0s - loss: 1.2519 - accuracy: 0.4375 - val_loss: 1.2552 - val_accuracy: 0.4370

Epoch 03230: val_loss did not improve from 1.24906
Epoch 3231/10000
12/12 - 0s - loss: 1.2509 - accuracy: 0.4409 - val_loss: 1.2532 - val_accuracy: 0.4418

Epoch 03231: val_loss did not improve from 1.24906
Epoch 3232/10000
12/12 - 0s - loss: 1.2503 - accuracy: 0.4400 - val_loss: 1.2549 - val_accuracy: 0.4290

Epoch 03232: val_loss did not improve from 1.24906
Epoch 3233/10000
12/12 - 0s - loss: 1.2491 - accuracy: 0.4413 - val_loss: 1.2532 - val_accuracy: 0.4370

Epoch 03233: val_loss did not improve from 1.24906
Epoch 3234/10000
12/12 - 0s - loss: 1.2487 - accuracy: 0.4427 - val_loss: 1.2608 - val_accuracy: 0.4226

Epoch 03234: val_loss did not improve from 1.24906
Epoch 3235/10000
12/12 - 0s - loss: 1.2516 - accuracy: 0.4407 - val_loss: 1.2566 - val_accuracy: 0.4330

Epoch 03235: val_loss did not improve from 1.24906
Epoch 3236/10000
12/12 - 0s - loss: 1.2499 - accuracy: 0.4373 - val_loss: 1.2627 - val_accuracy: 0.4298

Epoch 03236: val_loss did not improve from 1.24906
Epoch 3237/10000
12/12 - 0s - loss: 1.2514 - accuracy: 0.4382 - val_loss: 1.2591 - val_accuracy: 0.4362

Epoch 03237: val_loss did not improve from 1.24906
Epoch 3238/10000
12/12 - 0s - loss: 1.2502 - accuracy: 0.4402 - val_loss: 1.2517 - val_accuracy: 0.4354

Epoch 03238: val_loss did not improve from 1.24906
Epoch 3239/10000
12/12 - 0s - loss: 1.2487 - accuracy: 0.4415 - val_loss: 1.2527 - val_accuracy: 0.4314

Epoch 03239: val_loss did not improve from 1.24906
Epoch 3240/10000
12/12 - 0s - loss: 1.2487 - accuracy: 0.4396 - val_loss: 1.2601 - val_accuracy: 0.4266

Epoch 03240: val_loss did not improve from 1.24906
Epoch 3241/10000
12/12 - 0s - loss: 1.2499 - accuracy: 0.4405 - val_loss: 1.2567 - val_accuracy: 0.4362

Epoch 03241: val_loss did not improve from 1.24906
Epoch 3242/10000
12/12 - 0s - loss: 1.2479 - accuracy: 0.4426 - val_loss: 1.2562 - val_accuracy: 0.4282

Epoch 03242: val_loss did not improve from 1.24906
Epoch 3243/10000
12/12 - 0s - loss: 1.2486 - accuracy: 0.4433 - val_loss: 1.2535 - val_accuracy: 0.4298

Epoch 03243: val_loss did not improve from 1.24906
Epoch 3244/10000
12/12 - 0s - loss: 1.2512 - accuracy: 0.4389 - val_loss: 1.2609 - val_accuracy: 0.4306

Epoch 03244: val_loss did not improve from 1.24906
Epoch 3245/10000
12/12 - 0s - loss: 1.2507 - accuracy: 0.4418 - val_loss: 1.2584 - val_accuracy: 0.4314

Epoch 03245: val_loss did not improve from 1.24906
Epoch 3246/10000
12/12 - 0s - loss: 1.2497 - accuracy: 0.4408 - val_loss: 1.2609 - val_accuracy: 0.4274

Epoch 03246: val_loss did not improve from 1.24906
Epoch 3247/10000
12/12 - 0s - loss: 1.2506 - accuracy: 0.4409 - val_loss: 1.2570 - val_accuracy: 0.4266

Epoch 03247: val_loss did not improve from 1.24906
Epoch 3248/10000
12/12 - 0s - loss: 1.2497 - accuracy: 0.4410 - val_loss: 1.2527 - val_accuracy: 0.4338

Epoch 03248: val_loss did not improve from 1.24906
Epoch 3249/10000
12/12 - 0s - loss: 1.2499 - accuracy: 0.4389 - val_loss: 1.2601 - val_accuracy: 0.4298

Epoch 03249: val_loss did not improve from 1.24906
Epoch 3250/10000
12/12 - 0s - loss: 1.2507 - accuracy: 0.4401 - val_loss: 1.2532 - val_accuracy: 0.4250

Epoch 03250: val_loss did not improve from 1.24906
Epoch 3251/10000
12/12 - 0s - loss: 1.2508 - accuracy: 0.4396 - val_loss: 1.2575 - val_accuracy: 0.4290

Epoch 03251: val_loss did not improve from 1.24906
Epoch 3252/10000
12/12 - 0s - loss: 1.2498 - accuracy: 0.4362 - val_loss: 1.2559 - val_accuracy: 0.4211

Epoch 03252: val_loss did not improve from 1.24906
Epoch 3253/10000
12/12 - 0s - loss: 1.2486 - accuracy: 0.4413 - val_loss: 1.2656 - val_accuracy: 0.4274

Epoch 03253: val_loss did not improve from 1.24906
Epoch 3254/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4364 - val_loss: 1.2525 - val_accuracy: 0.4211

Epoch 03254: val_loss did not improve from 1.24906
Epoch 3255/10000
12/12 - 0s - loss: 1.2497 - accuracy: 0.4380 - val_loss: 1.2554 - val_accuracy: 0.4219

Epoch 03255: val_loss did not improve from 1.24906
Epoch 3256/10000
12/12 - 0s - loss: 1.2496 - accuracy: 0.4401 - val_loss: 1.2509 - val_accuracy: 0.4314

Epoch 03256: val_loss did not improve from 1.24906
Epoch 3257/10000
12/12 - 0s - loss: 1.2499 - accuracy: 0.4396 - val_loss: 1.2591 - val_accuracy: 0.4354

Epoch 03257: val_loss did not improve from 1.24906
Epoch 3258/10000
12/12 - 0s - loss: 1.2484 - accuracy: 0.4391 - val_loss: 1.2527 - val_accuracy: 0.4242

Epoch 03258: val_loss did not improve from 1.24906
Epoch 3259/10000
12/12 - 0s - loss: 1.2506 - accuracy: 0.4378 - val_loss: 1.2627 - val_accuracy: 0.4274

Epoch 03259: val_loss did not improve from 1.24906
Epoch 3260/10000
12/12 - 0s - loss: 1.2507 - accuracy: 0.4411 - val_loss: 1.2548 - val_accuracy: 0.4250

Epoch 03260: val_loss did not improve from 1.24906
Epoch 3261/10000
12/12 - 0s - loss: 1.2489 - accuracy: 0.4389 - val_loss: 1.2595 - val_accuracy: 0.4322

Epoch 03261: val_loss did not improve from 1.24906
Epoch 3262/10000
12/12 - 0s - loss: 1.2494 - accuracy: 0.4410 - val_loss: 1.2502 - val_accuracy: 0.4314

Epoch 03262: val_loss did not improve from 1.24906
Epoch 3263/10000
12/12 - 0s - loss: 1.2490 - accuracy: 0.4424 - val_loss: 1.2504 - val_accuracy: 0.4386

Epoch 03263: val_loss did not improve from 1.24906
Epoch 3264/10000
12/12 - 0s - loss: 1.2503 - accuracy: 0.4406 - val_loss: 1.2503 - val_accuracy: 0.4322

Epoch 03264: val_loss did not improve from 1.24906
Epoch 3265/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4357 - val_loss: 1.2496 - val_accuracy: 0.4418

Epoch 03265: val_loss did not improve from 1.24906
Epoch 3266/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4343 - val_loss: 1.2537 - val_accuracy: 0.4330

Epoch 03266: val_loss did not improve from 1.24906
Epoch 3267/10000
12/12 - 0s - loss: 1.2525 - accuracy: 0.4402 - val_loss: 1.2536 - val_accuracy: 0.4394

Epoch 03267: val_loss did not improve from 1.24906
Epoch 3268/10000
12/12 - 0s - loss: 1.2501 - accuracy: 0.4427 - val_loss: 1.2554 - val_accuracy: 0.4314

Epoch 03268: val_loss did not improve from 1.24906
Epoch 3269/10000
12/12 - 0s - loss: 1.2486 - accuracy: 0.4433 - val_loss: 1.2904 - val_accuracy: 0.4115

Epoch 03269: val_loss did not improve from 1.24906
Epoch 3270/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4287 - val_loss: 1.2525 - val_accuracy: 0.4266

Epoch 03270: val_loss did not improve from 1.24906
Epoch 3271/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4341 - val_loss: 1.2518 - val_accuracy: 0.4346

Epoch 03271: val_loss did not improve from 1.24906
Epoch 3272/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4365 - val_loss: 1.2516 - val_accuracy: 0.4386

Epoch 03272: val_loss did not improve from 1.24906
Epoch 03272: early stopping
*************************** Fold #: 8 ***************************
Model: "sequential_67"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_268 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_269 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_270 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_271 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6074 - accuracy: 0.1967 - val_loss: 1.6034 - val_accuracy: 0.2033

Epoch 00001: val_loss improved from inf to 1.60343, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2/10000
12/12 - 0s - loss: 1.6005 - accuracy: 0.2018 - val_loss: 1.5984 - val_accuracy: 0.2281

Epoch 00002: val_loss improved from 1.60343 to 1.59839, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 3/10000
12/12 - 0s - loss: 1.5940 - accuracy: 0.2583 - val_loss: 1.5912 - val_accuracy: 0.2919

Epoch 00003: val_loss improved from 1.59839 to 1.59119, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 4/10000
12/12 - 0s - loss: 1.5853 - accuracy: 0.3117 - val_loss: 1.5812 - val_accuracy: 0.3134

Epoch 00004: val_loss improved from 1.59119 to 1.58116, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 5/10000
12/12 - 0s - loss: 1.5725 - accuracy: 0.3204 - val_loss: 1.5662 - val_accuracy: 0.3126

Epoch 00005: val_loss improved from 1.58116 to 1.56624, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 6/10000
12/12 - 0s - loss: 1.5549 - accuracy: 0.3362 - val_loss: 1.5451 - val_accuracy: 0.3254

Epoch 00006: val_loss improved from 1.56624 to 1.54514, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 7/10000
12/12 - 0s - loss: 1.5300 - accuracy: 0.3451 - val_loss: 1.5183 - val_accuracy: 0.3620

Epoch 00007: val_loss improved from 1.54514 to 1.51828, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 8/10000
12/12 - 0s - loss: 1.4996 - accuracy: 0.3597 - val_loss: 1.4855 - val_accuracy: 0.3684

Epoch 00008: val_loss improved from 1.51828 to 1.48546, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 9/10000
12/12 - 0s - loss: 1.4630 - accuracy: 0.3598 - val_loss: 1.4461 - val_accuracy: 0.3596

Epoch 00009: val_loss improved from 1.48546 to 1.44608, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 10/10000
12/12 - 0s - loss: 1.4242 - accuracy: 0.3565 - val_loss: 1.4074 - val_accuracy: 0.3692

Epoch 00010: val_loss improved from 1.44608 to 1.40736, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 11/10000
12/12 - 0s - loss: 1.3914 - accuracy: 0.3701 - val_loss: 1.3821 - val_accuracy: 0.3804

Epoch 00011: val_loss improved from 1.40736 to 1.38207, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 12/10000
12/12 - 0s - loss: 1.3662 - accuracy: 0.3785 - val_loss: 1.3627 - val_accuracy: 0.3923

Epoch 00012: val_loss improved from 1.38207 to 1.36269, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 13/10000
12/12 - 0s - loss: 1.3520 - accuracy: 0.3774 - val_loss: 1.3494 - val_accuracy: 0.4019

Epoch 00013: val_loss improved from 1.36269 to 1.34942, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 14/10000
12/12 - 0s - loss: 1.3430 - accuracy: 0.3801 - val_loss: 1.3478 - val_accuracy: 0.4099

Epoch 00014: val_loss improved from 1.34942 to 1.34784, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 15/10000
12/12 - 0s - loss: 1.3424 - accuracy: 0.3819 - val_loss: 1.3423 - val_accuracy: 0.4091

Epoch 00015: val_loss improved from 1.34784 to 1.34230, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 16/10000
12/12 - 0s - loss: 1.3413 - accuracy: 0.3854 - val_loss: 1.3431 - val_accuracy: 0.4131

Epoch 00016: val_loss did not improve from 1.34230
Epoch 17/10000
12/12 - 0s - loss: 1.3367 - accuracy: 0.3837 - val_loss: 1.3491 - val_accuracy: 0.4011

Epoch 00017: val_loss did not improve from 1.34230
Epoch 18/10000
12/12 - 0s - loss: 1.3372 - accuracy: 0.3808 - val_loss: 1.3396 - val_accuracy: 0.3987

Epoch 00018: val_loss improved from 1.34230 to 1.33962, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 19/10000
12/12 - 0s - loss: 1.3347 - accuracy: 0.3773 - val_loss: 1.3388 - val_accuracy: 0.4099

Epoch 00019: val_loss improved from 1.33962 to 1.33878, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 20/10000
12/12 - 0s - loss: 1.3359 - accuracy: 0.3837 - val_loss: 1.3483 - val_accuracy: 0.4027

Epoch 00020: val_loss did not improve from 1.33878
Epoch 21/10000
12/12 - 0s - loss: 1.3351 - accuracy: 0.3856 - val_loss: 1.3379 - val_accuracy: 0.4250

Epoch 00021: val_loss improved from 1.33878 to 1.33786, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 22/10000
12/12 - 0s - loss: 1.3333 - accuracy: 0.3934 - val_loss: 1.3386 - val_accuracy: 0.4195

Epoch 00022: val_loss did not improve from 1.33786
Epoch 23/10000
12/12 - 0s - loss: 1.3336 - accuracy: 0.3866 - val_loss: 1.3376 - val_accuracy: 0.4075

Epoch 00023: val_loss improved from 1.33786 to 1.33763, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 24/10000
12/12 - 0s - loss: 1.3356 - accuracy: 0.3819 - val_loss: 1.3438 - val_accuracy: 0.3955

Epoch 00024: val_loss did not improve from 1.33763
Epoch 25/10000
12/12 - 0s - loss: 1.3336 - accuracy: 0.3807 - val_loss: 1.3406 - val_accuracy: 0.4163

Epoch 00025: val_loss did not improve from 1.33763
Epoch 26/10000
12/12 - 0s - loss: 1.3337 - accuracy: 0.3882 - val_loss: 1.3367 - val_accuracy: 0.4266

Epoch 00026: val_loss improved from 1.33763 to 1.33666, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 27/10000
12/12 - 0s - loss: 1.3347 - accuracy: 0.3870 - val_loss: 1.3403 - val_accuracy: 0.4099

Epoch 00027: val_loss did not improve from 1.33666
Epoch 28/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.3925 - val_loss: 1.3419 - val_accuracy: 0.3995

Epoch 00028: val_loss did not improve from 1.33666
Epoch 29/10000
12/12 - 0s - loss: 1.3316 - accuracy: 0.3861 - val_loss: 1.3373 - val_accuracy: 0.4083

Epoch 00029: val_loss did not improve from 1.33666
Epoch 30/10000
12/12 - 0s - loss: 1.3341 - accuracy: 0.3862 - val_loss: 1.3353 - val_accuracy: 0.4274

Epoch 00030: val_loss improved from 1.33666 to 1.33528, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 31/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3822 - val_loss: 1.3367 - val_accuracy: 0.4099

Epoch 00031: val_loss did not improve from 1.33528
Epoch 32/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3876 - val_loss: 1.3402 - val_accuracy: 0.4107

Epoch 00032: val_loss did not improve from 1.33528
Epoch 33/10000
12/12 - 0s - loss: 1.3301 - accuracy: 0.3891 - val_loss: 1.3368 - val_accuracy: 0.4187

Epoch 00033: val_loss did not improve from 1.33528
Epoch 34/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3882 - val_loss: 1.3365 - val_accuracy: 0.3931

Epoch 00034: val_loss did not improve from 1.33528
Epoch 35/10000
12/12 - 0s - loss: 1.3304 - accuracy: 0.3861 - val_loss: 1.3358 - val_accuracy: 0.4075

Epoch 00035: val_loss did not improve from 1.33528
Epoch 36/10000
12/12 - 0s - loss: 1.3301 - accuracy: 0.3871 - val_loss: 1.3359 - val_accuracy: 0.4083

Epoch 00036: val_loss did not improve from 1.33528
Epoch 37/10000
12/12 - 0s - loss: 1.3295 - accuracy: 0.3854 - val_loss: 1.3353 - val_accuracy: 0.4211

Epoch 00037: val_loss did not improve from 1.33528
Epoch 38/10000
12/12 - 0s - loss: 1.3301 - accuracy: 0.3916 - val_loss: 1.3355 - val_accuracy: 0.4258

Epoch 00038: val_loss did not improve from 1.33528
Epoch 39/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.3894 - val_loss: 1.3360 - val_accuracy: 0.4187

Epoch 00039: val_loss did not improve from 1.33528
Epoch 40/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3877 - val_loss: 1.3349 - val_accuracy: 0.4203

Epoch 00040: val_loss improved from 1.33528 to 1.33491, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 41/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3925 - val_loss: 1.3409 - val_accuracy: 0.4043

Epoch 00041: val_loss did not improve from 1.33491
Epoch 42/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3891 - val_loss: 1.3336 - val_accuracy: 0.4250

Epoch 00042: val_loss improved from 1.33491 to 1.33361, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 43/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3926 - val_loss: 1.3353 - val_accuracy: 0.4155

Epoch 00043: val_loss did not improve from 1.33361
Epoch 44/10000
12/12 - 0s - loss: 1.3292 - accuracy: 0.3927 - val_loss: 1.3374 - val_accuracy: 0.4203

Epoch 00044: val_loss did not improve from 1.33361
Epoch 45/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3930 - val_loss: 1.3338 - val_accuracy: 0.4139

Epoch 00045: val_loss did not improve from 1.33361
Epoch 46/10000
12/12 - 0s - loss: 1.3299 - accuracy: 0.3808 - val_loss: 1.3348 - val_accuracy: 0.4083

Epoch 00046: val_loss did not improve from 1.33361
Epoch 47/10000
12/12 - 0s - loss: 1.3295 - accuracy: 0.3789 - val_loss: 1.3333 - val_accuracy: 0.4139

Epoch 00047: val_loss improved from 1.33361 to 1.33326, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 48/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.3869 - val_loss: 1.3344 - val_accuracy: 0.4203

Epoch 00048: val_loss did not improve from 1.33326
Epoch 49/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3930 - val_loss: 1.3400 - val_accuracy: 0.4147

Epoch 00049: val_loss did not improve from 1.33326
Epoch 50/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3933 - val_loss: 1.3331 - val_accuracy: 0.4155

Epoch 00050: val_loss improved from 1.33326 to 1.33314, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 51/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3908 - val_loss: 1.3368 - val_accuracy: 0.4147

Epoch 00051: val_loss did not improve from 1.33314
Epoch 52/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3937 - val_loss: 1.3347 - val_accuracy: 0.4115

Epoch 00052: val_loss did not improve from 1.33314
Epoch 53/10000
12/12 - 0s - loss: 1.3310 - accuracy: 0.3910 - val_loss: 1.3443 - val_accuracy: 0.4027

Epoch 00053: val_loss did not improve from 1.33314
Epoch 54/10000
12/12 - 0s - loss: 1.3305 - accuracy: 0.3839 - val_loss: 1.3348 - val_accuracy: 0.4051

Epoch 00054: val_loss did not improve from 1.33314
Epoch 55/10000
12/12 - 0s - loss: 1.3298 - accuracy: 0.3796 - val_loss: 1.3327 - val_accuracy: 0.4171

Epoch 00055: val_loss improved from 1.33314 to 1.33273, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 56/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3922 - val_loss: 1.3439 - val_accuracy: 0.4003

Epoch 00056: val_loss did not improve from 1.33273
Epoch 57/10000
12/12 - 0s - loss: 1.3326 - accuracy: 0.3899 - val_loss: 1.3337 - val_accuracy: 0.3907

Epoch 00057: val_loss did not improve from 1.33273
Epoch 58/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3891 - val_loss: 1.3444 - val_accuracy: 0.4067

Epoch 00058: val_loss did not improve from 1.33273
Epoch 59/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3792 - val_loss: 1.3325 - val_accuracy: 0.4075

Epoch 00059: val_loss improved from 1.33273 to 1.33247, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 60/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3810 - val_loss: 1.3320 - val_accuracy: 0.4131

Epoch 00060: val_loss improved from 1.33247 to 1.33201, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 61/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3927 - val_loss: 1.3349 - val_accuracy: 0.4314

Epoch 00061: val_loss did not improve from 1.33201
Epoch 62/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3938 - val_loss: 1.3313 - val_accuracy: 0.4187

Epoch 00062: val_loss improved from 1.33201 to 1.33129, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 63/10000
12/12 - 0s - loss: 1.3286 - accuracy: 0.3860 - val_loss: 1.3365 - val_accuracy: 0.4035

Epoch 00063: val_loss did not improve from 1.33129
Epoch 64/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3869 - val_loss: 1.3341 - val_accuracy: 0.4171

Epoch 00064: val_loss did not improve from 1.33129
Epoch 65/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3899 - val_loss: 1.3315 - val_accuracy: 0.4155

Epoch 00065: val_loss did not improve from 1.33129
Epoch 66/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3940 - val_loss: 1.3313 - val_accuracy: 0.4234

Epoch 00066: val_loss did not improve from 1.33129
Epoch 67/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3923 - val_loss: 1.3358 - val_accuracy: 0.4179

Epoch 00067: val_loss did not improve from 1.33129
Epoch 68/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3833 - val_loss: 1.3320 - val_accuracy: 0.4115

Epoch 00068: val_loss did not improve from 1.33129
Epoch 69/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3873 - val_loss: 1.3348 - val_accuracy: 0.4091

Epoch 00069: val_loss did not improve from 1.33129
Epoch 70/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3836 - val_loss: 1.3318 - val_accuracy: 0.4203

Epoch 00070: val_loss did not improve from 1.33129
Epoch 71/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3863 - val_loss: 1.3310 - val_accuracy: 0.4274

Epoch 00071: val_loss improved from 1.33129 to 1.33099, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 72/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3940 - val_loss: 1.3306 - val_accuracy: 0.4211

Epoch 00072: val_loss improved from 1.33099 to 1.33057, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 73/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3929 - val_loss: 1.3352 - val_accuracy: 0.4131

Epoch 00073: val_loss did not improve from 1.33057
Epoch 74/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3945 - val_loss: 1.3332 - val_accuracy: 0.4211

Epoch 00074: val_loss did not improve from 1.33057
Epoch 75/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3914 - val_loss: 1.3310 - val_accuracy: 0.4091

Epoch 00075: val_loss did not improve from 1.33057
Epoch 76/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3931 - val_loss: 1.3385 - val_accuracy: 0.4043

Epoch 00076: val_loss did not improve from 1.33057
Epoch 77/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3848 - val_loss: 1.3327 - val_accuracy: 0.4059

Epoch 00077: val_loss did not improve from 1.33057
Epoch 78/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3836 - val_loss: 1.3322 - val_accuracy: 0.4155

Epoch 00078: val_loss did not improve from 1.33057
Epoch 79/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3880 - val_loss: 1.3309 - val_accuracy: 0.4187

Epoch 00079: val_loss did not improve from 1.33057
Epoch 80/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3900 - val_loss: 1.3367 - val_accuracy: 0.4043

Epoch 00080: val_loss did not improve from 1.33057
Epoch 81/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.3830 - val_loss: 1.3307 - val_accuracy: 0.4139

Epoch 00081: val_loss did not improve from 1.33057
Epoch 82/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3939 - val_loss: 1.3322 - val_accuracy: 0.4211

Epoch 00082: val_loss did not improve from 1.33057
Epoch 83/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3896 - val_loss: 1.3324 - val_accuracy: 0.4171

Epoch 00083: val_loss did not improve from 1.33057
Epoch 84/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3859 - val_loss: 1.3300 - val_accuracy: 0.4219

Epoch 00084: val_loss improved from 1.33057 to 1.32999, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 85/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3931 - val_loss: 1.3361 - val_accuracy: 0.4171

Epoch 00085: val_loss did not improve from 1.32999
Epoch 86/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3921 - val_loss: 1.3308 - val_accuracy: 0.4211

Epoch 00086: val_loss did not improve from 1.32999
Epoch 87/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3939 - val_loss: 1.3357 - val_accuracy: 0.4171

Epoch 00087: val_loss did not improve from 1.32999
Epoch 88/10000
12/12 - 0s - loss: 1.3270 - accuracy: 0.3854 - val_loss: 1.3309 - val_accuracy: 0.4242

Epoch 00088: val_loss did not improve from 1.32999
Epoch 89/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3920 - val_loss: 1.3334 - val_accuracy: 0.4187

Epoch 00089: val_loss did not improve from 1.32999
Epoch 90/10000
12/12 - 0s - loss: 1.3257 - accuracy: 0.3916 - val_loss: 1.3316 - val_accuracy: 0.4226

Epoch 00090: val_loss did not improve from 1.32999
Epoch 91/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3914 - val_loss: 1.3321 - val_accuracy: 0.4171

Epoch 00091: val_loss did not improve from 1.32999
Epoch 92/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3947 - val_loss: 1.3308 - val_accuracy: 0.4226

Epoch 00092: val_loss did not improve from 1.32999
Epoch 93/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3912 - val_loss: 1.3348 - val_accuracy: 0.4155

Epoch 00093: val_loss did not improve from 1.32999
Epoch 94/10000
12/12 - 0s - loss: 1.3292 - accuracy: 0.3855 - val_loss: 1.3297 - val_accuracy: 0.4338

Epoch 00094: val_loss improved from 1.32999 to 1.32965, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 95/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3921 - val_loss: 1.3303 - val_accuracy: 0.4211

Epoch 00095: val_loss did not improve from 1.32965
Epoch 96/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3936 - val_loss: 1.3368 - val_accuracy: 0.4051

Epoch 00096: val_loss did not improve from 1.32965
Epoch 97/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3902 - val_loss: 1.3309 - val_accuracy: 0.4107

Epoch 00097: val_loss did not improve from 1.32965
Epoch 98/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3933 - val_loss: 1.3341 - val_accuracy: 0.4203

Epoch 00098: val_loss did not improve from 1.32965
Epoch 99/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3933 - val_loss: 1.3317 - val_accuracy: 0.4155

Epoch 00099: val_loss did not improve from 1.32965
Epoch 100/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3906 - val_loss: 1.3298 - val_accuracy: 0.4250

Epoch 00100: val_loss did not improve from 1.32965
Epoch 101/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3912 - val_loss: 1.3324 - val_accuracy: 0.4163

Epoch 00101: val_loss did not improve from 1.32965
Epoch 102/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3906 - val_loss: 1.3310 - val_accuracy: 0.4226

Epoch 00102: val_loss did not improve from 1.32965
Epoch 103/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3899 - val_loss: 1.3295 - val_accuracy: 0.4163

Epoch 00103: val_loss improved from 1.32965 to 1.32951, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 104/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3875 - val_loss: 1.3317 - val_accuracy: 0.4171

Epoch 00104: val_loss did not improve from 1.32951
Epoch 105/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3902 - val_loss: 1.3324 - val_accuracy: 0.4203

Epoch 00105: val_loss did not improve from 1.32951
Epoch 106/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3942 - val_loss: 1.3322 - val_accuracy: 0.4226

Epoch 00106: val_loss did not improve from 1.32951
Epoch 107/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3930 - val_loss: 1.3288 - val_accuracy: 0.4234

Epoch 00107: val_loss improved from 1.32951 to 1.32884, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 108/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3916 - val_loss: 1.3308 - val_accuracy: 0.4163

Epoch 00108: val_loss did not improve from 1.32884
Epoch 109/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3884 - val_loss: 1.3293 - val_accuracy: 0.4179

Epoch 00109: val_loss did not improve from 1.32884
Epoch 110/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3896 - val_loss: 1.3297 - val_accuracy: 0.4179

Epoch 00110: val_loss did not improve from 1.32884
Epoch 111/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3888 - val_loss: 1.3338 - val_accuracy: 0.4155

Epoch 00111: val_loss did not improve from 1.32884
Epoch 112/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3880 - val_loss: 1.3294 - val_accuracy: 0.4171

Epoch 00112: val_loss did not improve from 1.32884
Epoch 113/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3872 - val_loss: 1.3289 - val_accuracy: 0.4171

Epoch 00113: val_loss did not improve from 1.32884
Epoch 114/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3885 - val_loss: 1.3321 - val_accuracy: 0.4155

Epoch 00114: val_loss did not improve from 1.32884
Epoch 115/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3899 - val_loss: 1.3304 - val_accuracy: 0.4234

Epoch 00115: val_loss did not improve from 1.32884
Epoch 116/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3914 - val_loss: 1.3310 - val_accuracy: 0.4250

Epoch 00116: val_loss did not improve from 1.32884
Epoch 117/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3930 - val_loss: 1.3292 - val_accuracy: 0.4282

Epoch 00117: val_loss did not improve from 1.32884
Epoch 118/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3946 - val_loss: 1.3317 - val_accuracy: 0.4211

Epoch 00118: val_loss did not improve from 1.32884
Epoch 119/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3923 - val_loss: 1.3302 - val_accuracy: 0.4219

Epoch 00119: val_loss did not improve from 1.32884
Epoch 120/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3944 - val_loss: 1.3291 - val_accuracy: 0.4171

Epoch 00120: val_loss did not improve from 1.32884
Epoch 121/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3926 - val_loss: 1.3359 - val_accuracy: 0.4051

Epoch 00121: val_loss did not improve from 1.32884
Epoch 122/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3875 - val_loss: 1.3308 - val_accuracy: 0.4131

Epoch 00122: val_loss did not improve from 1.32884
Epoch 123/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3908 - val_loss: 1.3320 - val_accuracy: 0.4147

Epoch 00123: val_loss did not improve from 1.32884
Epoch 124/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3934 - val_loss: 1.3325 - val_accuracy: 0.4195

Epoch 00124: val_loss did not improve from 1.32884
Epoch 125/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3917 - val_loss: 1.3299 - val_accuracy: 0.4274

Epoch 00125: val_loss did not improve from 1.32884
Epoch 126/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3943 - val_loss: 1.3398 - val_accuracy: 0.4027

Epoch 00126: val_loss did not improve from 1.32884
Epoch 127/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3844 - val_loss: 1.3297 - val_accuracy: 0.4171

Epoch 00127: val_loss did not improve from 1.32884
Epoch 128/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3937 - val_loss: 1.3374 - val_accuracy: 0.4051

Epoch 00128: val_loss did not improve from 1.32884
Epoch 129/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3908 - val_loss: 1.3295 - val_accuracy: 0.4147

Epoch 00129: val_loss did not improve from 1.32884
Epoch 130/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3915 - val_loss: 1.3306 - val_accuracy: 0.4131

Epoch 00130: val_loss did not improve from 1.32884
Epoch 131/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3946 - val_loss: 1.3321 - val_accuracy: 0.4099

Epoch 00131: val_loss did not improve from 1.32884
Epoch 132/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3908 - val_loss: 1.3306 - val_accuracy: 0.4242

Epoch 00132: val_loss did not improve from 1.32884
Epoch 133/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3926 - val_loss: 1.3312 - val_accuracy: 0.4195

Epoch 00133: val_loss did not improve from 1.32884
Epoch 134/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3934 - val_loss: 1.3292 - val_accuracy: 0.4203

Epoch 00134: val_loss did not improve from 1.32884
Epoch 135/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3913 - val_loss: 1.3353 - val_accuracy: 0.4163

Epoch 00135: val_loss did not improve from 1.32884
Epoch 136/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3912 - val_loss: 1.3301 - val_accuracy: 0.4091

Epoch 00136: val_loss did not improve from 1.32884
Epoch 137/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3947 - val_loss: 1.3338 - val_accuracy: 0.4099

Epoch 00137: val_loss did not improve from 1.32884
Epoch 138/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3909 - val_loss: 1.3312 - val_accuracy: 0.4147

Epoch 00138: val_loss did not improve from 1.32884
Epoch 139/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3925 - val_loss: 1.3283 - val_accuracy: 0.4250

Epoch 00139: val_loss improved from 1.32884 to 1.32833, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 140/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3929 - val_loss: 1.3320 - val_accuracy: 0.4107

Epoch 00140: val_loss did not improve from 1.32833
Epoch 141/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3910 - val_loss: 1.3286 - val_accuracy: 0.4187

Epoch 00141: val_loss did not improve from 1.32833
Epoch 142/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3911 - val_loss: 1.3298 - val_accuracy: 0.4219

Epoch 00142: val_loss did not improve from 1.32833
Epoch 143/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3922 - val_loss: 1.3373 - val_accuracy: 0.4059

Epoch 00143: val_loss did not improve from 1.32833
Epoch 144/10000
12/12 - 0s - loss: 1.3273 - accuracy: 0.3865 - val_loss: 1.3296 - val_accuracy: 0.4147

Epoch 00144: val_loss did not improve from 1.32833
Epoch 145/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3931 - val_loss: 1.3317 - val_accuracy: 0.4195

Epoch 00145: val_loss did not improve from 1.32833
Epoch 146/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3928 - val_loss: 1.3317 - val_accuracy: 0.4219

Epoch 00146: val_loss did not improve from 1.32833
Epoch 147/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3939 - val_loss: 1.3306 - val_accuracy: 0.4219

Epoch 00147: val_loss did not improve from 1.32833
Epoch 148/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3890 - val_loss: 1.3323 - val_accuracy: 0.4147

Epoch 00148: val_loss did not improve from 1.32833
Epoch 149/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3913 - val_loss: 1.3305 - val_accuracy: 0.4139

Epoch 00149: val_loss did not improve from 1.32833
Epoch 150/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3923 - val_loss: 1.3321 - val_accuracy: 0.4211

Epoch 00150: val_loss did not improve from 1.32833
Epoch 151/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3878 - val_loss: 1.3295 - val_accuracy: 0.4226

Epoch 00151: val_loss did not improve from 1.32833
Epoch 152/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3939 - val_loss: 1.3336 - val_accuracy: 0.4187

Epoch 00152: val_loss did not improve from 1.32833
Epoch 153/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3950 - val_loss: 1.3305 - val_accuracy: 0.4179

Epoch 00153: val_loss did not improve from 1.32833
Epoch 154/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3922 - val_loss: 1.3308 - val_accuracy: 0.4139

Epoch 00154: val_loss did not improve from 1.32833
Epoch 155/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3942 - val_loss: 1.3313 - val_accuracy: 0.4107

Epoch 00155: val_loss did not improve from 1.32833
Epoch 156/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3933 - val_loss: 1.3307 - val_accuracy: 0.4195

Epoch 00156: val_loss did not improve from 1.32833
Epoch 157/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3958 - val_loss: 1.3286 - val_accuracy: 0.4330

Epoch 00157: val_loss did not improve from 1.32833
Epoch 158/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3939 - val_loss: 1.3364 - val_accuracy: 0.4234

Epoch 00158: val_loss did not improve from 1.32833
Epoch 159/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3908 - val_loss: 1.3289 - val_accuracy: 0.4203

Epoch 00159: val_loss did not improve from 1.32833
Epoch 160/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3916 - val_loss: 1.3291 - val_accuracy: 0.4250

Epoch 00160: val_loss did not improve from 1.32833
Epoch 161/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3930 - val_loss: 1.3343 - val_accuracy: 0.4075

Epoch 00161: val_loss did not improve from 1.32833
Epoch 162/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3942 - val_loss: 1.3295 - val_accuracy: 0.4195

Epoch 00162: val_loss did not improve from 1.32833
Epoch 163/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3919 - val_loss: 1.3297 - val_accuracy: 0.4274

Epoch 00163: val_loss did not improve from 1.32833
Epoch 164/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3939 - val_loss: 1.3296 - val_accuracy: 0.4314

Epoch 00164: val_loss did not improve from 1.32833
Epoch 165/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3927 - val_loss: 1.3306 - val_accuracy: 0.4211

Epoch 00165: val_loss did not improve from 1.32833
Epoch 166/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3931 - val_loss: 1.3306 - val_accuracy: 0.4203

Epoch 00166: val_loss did not improve from 1.32833
Epoch 167/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3912 - val_loss: 1.3304 - val_accuracy: 0.4163

Epoch 00167: val_loss did not improve from 1.32833
Epoch 168/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3908 - val_loss: 1.3313 - val_accuracy: 0.4123

Epoch 00168: val_loss did not improve from 1.32833
Epoch 169/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3917 - val_loss: 1.3353 - val_accuracy: 0.4011

Epoch 00169: val_loss did not improve from 1.32833
Epoch 170/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3930 - val_loss: 1.3312 - val_accuracy: 0.4131

Epoch 00170: val_loss did not improve from 1.32833
Epoch 171/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3931 - val_loss: 1.3304 - val_accuracy: 0.4099

Epoch 00171: val_loss did not improve from 1.32833
Epoch 172/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3929 - val_loss: 1.3335 - val_accuracy: 0.4115

Epoch 00172: val_loss did not improve from 1.32833
Epoch 173/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3919 - val_loss: 1.3292 - val_accuracy: 0.4234

Epoch 00173: val_loss did not improve from 1.32833
Epoch 174/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3923 - val_loss: 1.3308 - val_accuracy: 0.4075

Epoch 00174: val_loss did not improve from 1.32833
Epoch 175/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3949 - val_loss: 1.3309 - val_accuracy: 0.4123

Epoch 00175: val_loss did not improve from 1.32833
Epoch 176/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3942 - val_loss: 1.3290 - val_accuracy: 0.4155

Epoch 00176: val_loss did not improve from 1.32833
Epoch 177/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3911 - val_loss: 1.3282 - val_accuracy: 0.4346

Epoch 00177: val_loss improved from 1.32833 to 1.32820, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 178/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3888 - val_loss: 1.3302 - val_accuracy: 0.4258

Epoch 00178: val_loss did not improve from 1.32820
Epoch 179/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3931 - val_loss: 1.3286 - val_accuracy: 0.4115

Epoch 00179: val_loss did not improve from 1.32820
Epoch 180/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3926 - val_loss: 1.3284 - val_accuracy: 0.4338

Epoch 00180: val_loss did not improve from 1.32820
Epoch 181/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3915 - val_loss: 1.3390 - val_accuracy: 0.4003

Epoch 00181: val_loss did not improve from 1.32820
Epoch 182/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3892 - val_loss: 1.3283 - val_accuracy: 0.4282

Epoch 00182: val_loss did not improve from 1.32820
Epoch 183/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3908 - val_loss: 1.3292 - val_accuracy: 0.4234

Epoch 00183: val_loss did not improve from 1.32820
Epoch 184/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3923 - val_loss: 1.3286 - val_accuracy: 0.4203

Epoch 00184: val_loss did not improve from 1.32820
Epoch 185/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3930 - val_loss: 1.3292 - val_accuracy: 0.4203

Epoch 00185: val_loss did not improve from 1.32820
Epoch 186/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3923 - val_loss: 1.3337 - val_accuracy: 0.4091

Epoch 00186: val_loss did not improve from 1.32820
Epoch 187/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3872 - val_loss: 1.3284 - val_accuracy: 0.4147

Epoch 00187: val_loss did not improve from 1.32820
Epoch 188/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3939 - val_loss: 1.3335 - val_accuracy: 0.4219

Epoch 00188: val_loss did not improve from 1.32820
Epoch 189/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3929 - val_loss: 1.3293 - val_accuracy: 0.4242

Epoch 00189: val_loss did not improve from 1.32820
Epoch 190/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3922 - val_loss: 1.3296 - val_accuracy: 0.4282

Epoch 00190: val_loss did not improve from 1.32820
Epoch 191/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3940 - val_loss: 1.3300 - val_accuracy: 0.4226

Epoch 00191: val_loss did not improve from 1.32820
Epoch 192/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3942 - val_loss: 1.3316 - val_accuracy: 0.4234

Epoch 00192: val_loss did not improve from 1.32820
Epoch 193/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3906 - val_loss: 1.3290 - val_accuracy: 0.4219

Epoch 00193: val_loss did not improve from 1.32820
Epoch 194/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3916 - val_loss: 1.3305 - val_accuracy: 0.4234

Epoch 00194: val_loss did not improve from 1.32820
Epoch 195/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3939 - val_loss: 1.3320 - val_accuracy: 0.4242

Epoch 00195: val_loss did not improve from 1.32820
Epoch 196/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3923 - val_loss: 1.3291 - val_accuracy: 0.4226

Epoch 00196: val_loss did not improve from 1.32820
Epoch 197/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3844 - val_loss: 1.3312 - val_accuracy: 0.4027

Epoch 00197: val_loss did not improve from 1.32820
Epoch 198/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3932 - val_loss: 1.3354 - val_accuracy: 0.4179

Epoch 00198: val_loss did not improve from 1.32820
Epoch 199/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3941 - val_loss: 1.3301 - val_accuracy: 0.4211

Epoch 00199: val_loss did not improve from 1.32820
Epoch 200/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3915 - val_loss: 1.3320 - val_accuracy: 0.4107

Epoch 00200: val_loss did not improve from 1.32820
Epoch 201/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3936 - val_loss: 1.3304 - val_accuracy: 0.4115

Epoch 00201: val_loss did not improve from 1.32820
Epoch 202/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3930 - val_loss: 1.3291 - val_accuracy: 0.4171

Epoch 00202: val_loss did not improve from 1.32820
Epoch 203/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3916 - val_loss: 1.3321 - val_accuracy: 0.4195

Epoch 00203: val_loss did not improve from 1.32820
Epoch 204/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3908 - val_loss: 1.3291 - val_accuracy: 0.4242

Epoch 00204: val_loss did not improve from 1.32820
Epoch 205/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3922 - val_loss: 1.3286 - val_accuracy: 0.4155

Epoch 00205: val_loss did not improve from 1.32820
Epoch 206/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3924 - val_loss: 1.3331 - val_accuracy: 0.4171

Epoch 00206: val_loss did not improve from 1.32820
Epoch 207/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3900 - val_loss: 1.3295 - val_accuracy: 0.4219

Epoch 00207: val_loss did not improve from 1.32820
Epoch 208/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3893 - val_loss: 1.3274 - val_accuracy: 0.4266

Epoch 00208: val_loss improved from 1.32820 to 1.32738, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 209/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3921 - val_loss: 1.3302 - val_accuracy: 0.4266

Epoch 00209: val_loss did not improve from 1.32738
Epoch 210/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3938 - val_loss: 1.3293 - val_accuracy: 0.4274

Epoch 00210: val_loss did not improve from 1.32738
Epoch 211/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3917 - val_loss: 1.3294 - val_accuracy: 0.4179

Epoch 00211: val_loss did not improve from 1.32738
Epoch 212/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3954 - val_loss: 1.3357 - val_accuracy: 0.4131

Epoch 00212: val_loss did not improve from 1.32738
Epoch 213/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3930 - val_loss: 1.3281 - val_accuracy: 0.4131

Epoch 00213: val_loss did not improve from 1.32738
Epoch 214/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3931 - val_loss: 1.3300 - val_accuracy: 0.4171

Epoch 00214: val_loss did not improve from 1.32738
Epoch 215/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3944 - val_loss: 1.3325 - val_accuracy: 0.4091

Epoch 00215: val_loss did not improve from 1.32738
Epoch 216/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3934 - val_loss: 1.3290 - val_accuracy: 0.4219

Epoch 00216: val_loss did not improve from 1.32738
Epoch 217/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3932 - val_loss: 1.3325 - val_accuracy: 0.4226

Epoch 00217: val_loss did not improve from 1.32738
Epoch 218/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3906 - val_loss: 1.3282 - val_accuracy: 0.4274

Epoch 00218: val_loss did not improve from 1.32738
Epoch 219/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3900 - val_loss: 1.3281 - val_accuracy: 0.4195

Epoch 00219: val_loss did not improve from 1.32738
Epoch 220/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3928 - val_loss: 1.3389 - val_accuracy: 0.4051

Epoch 00220: val_loss did not improve from 1.32738
Epoch 221/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3929 - val_loss: 1.3285 - val_accuracy: 0.4226

Epoch 00221: val_loss did not improve from 1.32738
Epoch 222/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3932 - val_loss: 1.3287 - val_accuracy: 0.4282

Epoch 00222: val_loss did not improve from 1.32738
Epoch 223/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3934 - val_loss: 1.3310 - val_accuracy: 0.4203

Epoch 00223: val_loss did not improve from 1.32738
Epoch 224/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3904 - val_loss: 1.3285 - val_accuracy: 0.4179

Epoch 00224: val_loss did not improve from 1.32738
Epoch 225/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3943 - val_loss: 1.3315 - val_accuracy: 0.4163

Epoch 00225: val_loss did not improve from 1.32738
Epoch 226/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3940 - val_loss: 1.3307 - val_accuracy: 0.4131

Epoch 00226: val_loss did not improve from 1.32738
Epoch 227/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3940 - val_loss: 1.3285 - val_accuracy: 0.4266

Epoch 00227: val_loss did not improve from 1.32738
Epoch 228/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3897 - val_loss: 1.3316 - val_accuracy: 0.4115

Epoch 00228: val_loss did not improve from 1.32738
Epoch 229/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3833 - val_loss: 1.3284 - val_accuracy: 0.4219

Epoch 00229: val_loss did not improve from 1.32738
Epoch 230/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3920 - val_loss: 1.3312 - val_accuracy: 0.4203

Epoch 00230: val_loss did not improve from 1.32738
Epoch 231/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3921 - val_loss: 1.3334 - val_accuracy: 0.4195

Epoch 00231: val_loss did not improve from 1.32738
Epoch 232/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3920 - val_loss: 1.3279 - val_accuracy: 0.4187

Epoch 00232: val_loss did not improve from 1.32738
Epoch 233/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3939 - val_loss: 1.3276 - val_accuracy: 0.4234

Epoch 00233: val_loss did not improve from 1.32738
Epoch 234/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3929 - val_loss: 1.3409 - val_accuracy: 0.4051

Epoch 00234: val_loss did not improve from 1.32738
Epoch 235/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3896 - val_loss: 1.3286 - val_accuracy: 0.4123

Epoch 00235: val_loss did not improve from 1.32738
Epoch 236/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3933 - val_loss: 1.3306 - val_accuracy: 0.4147

Epoch 00236: val_loss did not improve from 1.32738
Epoch 237/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3904 - val_loss: 1.3268 - val_accuracy: 0.4234

Epoch 00237: val_loss improved from 1.32738 to 1.32682, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 238/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3873 - val_loss: 1.3275 - val_accuracy: 0.4234

Epoch 00238: val_loss did not improve from 1.32682
Epoch 239/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3922 - val_loss: 1.3271 - val_accuracy: 0.4187

Epoch 00239: val_loss did not improve from 1.32682
Epoch 240/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3902 - val_loss: 1.3311 - val_accuracy: 0.4123

Epoch 00240: val_loss did not improve from 1.32682
Epoch 241/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3928 - val_loss: 1.3269 - val_accuracy: 0.4258

Epoch 00241: val_loss did not improve from 1.32682
Epoch 242/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3897 - val_loss: 1.3260 - val_accuracy: 0.4330

Epoch 00242: val_loss improved from 1.32682 to 1.32598, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 243/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3879 - val_loss: 1.3306 - val_accuracy: 0.4171

Epoch 00243: val_loss did not improve from 1.32598
Epoch 244/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3892 - val_loss: 1.3281 - val_accuracy: 0.4163

Epoch 00244: val_loss did not improve from 1.32598
Epoch 245/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3912 - val_loss: 1.3307 - val_accuracy: 0.4163

Epoch 00245: val_loss did not improve from 1.32598
Epoch 246/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3933 - val_loss: 1.3317 - val_accuracy: 0.4131

Epoch 00246: val_loss did not improve from 1.32598
Epoch 247/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3928 - val_loss: 1.3276 - val_accuracy: 0.4274

Epoch 00247: val_loss did not improve from 1.32598
Epoch 248/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3872 - val_loss: 1.3296 - val_accuracy: 0.4195

Epoch 00248: val_loss did not improve from 1.32598
Epoch 249/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3936 - val_loss: 1.3291 - val_accuracy: 0.4219

Epoch 00249: val_loss did not improve from 1.32598
Epoch 250/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3947 - val_loss: 1.3268 - val_accuracy: 0.4282

Epoch 00250: val_loss did not improve from 1.32598
Epoch 251/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3908 - val_loss: 1.3292 - val_accuracy: 0.4155

Epoch 00251: val_loss did not improve from 1.32598
Epoch 252/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3933 - val_loss: 1.3272 - val_accuracy: 0.4171

Epoch 00252: val_loss did not improve from 1.32598
Epoch 253/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3955 - val_loss: 1.3323 - val_accuracy: 0.4147

Epoch 00253: val_loss did not improve from 1.32598
Epoch 254/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3908 - val_loss: 1.3289 - val_accuracy: 0.4155

Epoch 00254: val_loss did not improve from 1.32598
Epoch 255/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3935 - val_loss: 1.3330 - val_accuracy: 0.4155

Epoch 00255: val_loss did not improve from 1.32598
Epoch 256/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3806 - val_loss: 1.3280 - val_accuracy: 0.4123

Epoch 00256: val_loss did not improve from 1.32598
Epoch 257/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3908 - val_loss: 1.3293 - val_accuracy: 0.4187

Epoch 00257: val_loss did not improve from 1.32598
Epoch 258/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3954 - val_loss: 1.3289 - val_accuracy: 0.4258

Epoch 00258: val_loss did not improve from 1.32598
Epoch 259/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3931 - val_loss: 1.3284 - val_accuracy: 0.4171

Epoch 00259: val_loss did not improve from 1.32598
Epoch 260/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3868 - val_loss: 1.3288 - val_accuracy: 0.4203

Epoch 00260: val_loss did not improve from 1.32598
Epoch 261/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3935 - val_loss: 1.3357 - val_accuracy: 0.4187

Epoch 00261: val_loss did not improve from 1.32598
Epoch 262/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3941 - val_loss: 1.3278 - val_accuracy: 0.4179

Epoch 00262: val_loss did not improve from 1.32598
Epoch 263/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3954 - val_loss: 1.3291 - val_accuracy: 0.4266

Epoch 00263: val_loss did not improve from 1.32598
Epoch 264/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3957 - val_loss: 1.3368 - val_accuracy: 0.4035

Epoch 00264: val_loss did not improve from 1.32598
Epoch 265/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3876 - val_loss: 1.3272 - val_accuracy: 0.4171

Epoch 00265: val_loss did not improve from 1.32598
Epoch 266/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3932 - val_loss: 1.3283 - val_accuracy: 0.4187

Epoch 00266: val_loss did not improve from 1.32598
Epoch 267/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3936 - val_loss: 1.3289 - val_accuracy: 0.4258

Epoch 00267: val_loss did not improve from 1.32598
Epoch 268/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3916 - val_loss: 1.3330 - val_accuracy: 0.4195

Epoch 00268: val_loss did not improve from 1.32598
Epoch 269/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3923 - val_loss: 1.3274 - val_accuracy: 0.4179

Epoch 00269: val_loss did not improve from 1.32598
Epoch 270/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3919 - val_loss: 1.3276 - val_accuracy: 0.4179

Epoch 00270: val_loss did not improve from 1.32598
Epoch 271/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3951 - val_loss: 1.3294 - val_accuracy: 0.4234

Epoch 00271: val_loss did not improve from 1.32598
Epoch 272/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3898 - val_loss: 1.3295 - val_accuracy: 0.4195

Epoch 00272: val_loss did not improve from 1.32598
Epoch 273/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3900 - val_loss: 1.3279 - val_accuracy: 0.4219

Epoch 00273: val_loss did not improve from 1.32598
Epoch 274/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3939 - val_loss: 1.3281 - val_accuracy: 0.4226

Epoch 00274: val_loss did not improve from 1.32598
Epoch 275/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3924 - val_loss: 1.3276 - val_accuracy: 0.4211

Epoch 00275: val_loss did not improve from 1.32598
Epoch 276/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3955 - val_loss: 1.3271 - val_accuracy: 0.4274

Epoch 00276: val_loss did not improve from 1.32598
Epoch 277/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3912 - val_loss: 1.3298 - val_accuracy: 0.4195

Epoch 00277: val_loss did not improve from 1.32598
Epoch 278/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3932 - val_loss: 1.3312 - val_accuracy: 0.4115

Epoch 00278: val_loss did not improve from 1.32598
Epoch 279/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3946 - val_loss: 1.3267 - val_accuracy: 0.4211

Epoch 00279: val_loss did not improve from 1.32598
Epoch 280/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3940 - val_loss: 1.3294 - val_accuracy: 0.4211

Epoch 00280: val_loss did not improve from 1.32598
Epoch 281/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3923 - val_loss: 1.3284 - val_accuracy: 0.4155

Epoch 00281: val_loss did not improve from 1.32598
Epoch 282/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3945 - val_loss: 1.3329 - val_accuracy: 0.4107

Epoch 00282: val_loss did not improve from 1.32598
Epoch 283/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3942 - val_loss: 1.3276 - val_accuracy: 0.4187

Epoch 00283: val_loss did not improve from 1.32598
Epoch 284/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3895 - val_loss: 1.3266 - val_accuracy: 0.4211

Epoch 00284: val_loss did not improve from 1.32598
Epoch 285/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3964 - val_loss: 1.3353 - val_accuracy: 0.4091

Epoch 00285: val_loss did not improve from 1.32598
Epoch 286/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3956 - val_loss: 1.3260 - val_accuracy: 0.4322

Epoch 00286: val_loss did not improve from 1.32598
Epoch 287/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3918 - val_loss: 1.3280 - val_accuracy: 0.4131

Epoch 00287: val_loss did not improve from 1.32598
Epoch 288/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3961 - val_loss: 1.3314 - val_accuracy: 0.4147

Epoch 00288: val_loss did not improve from 1.32598
Epoch 289/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3911 - val_loss: 1.3269 - val_accuracy: 0.4250

Epoch 00289: val_loss did not improve from 1.32598
Epoch 290/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3962 - val_loss: 1.3266 - val_accuracy: 0.4163

Epoch 00290: val_loss did not improve from 1.32598
Epoch 291/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3974 - val_loss: 1.3289 - val_accuracy: 0.4107

Epoch 00291: val_loss did not improve from 1.32598
Epoch 292/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3962 - val_loss: 1.3294 - val_accuracy: 0.4242

Epoch 00292: val_loss did not improve from 1.32598
Epoch 293/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3874 - val_loss: 1.3273 - val_accuracy: 0.4195

Epoch 00293: val_loss did not improve from 1.32598
Epoch 294/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3898 - val_loss: 1.3301 - val_accuracy: 0.4139

Epoch 00294: val_loss did not improve from 1.32598
Epoch 295/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3928 - val_loss: 1.3335 - val_accuracy: 0.4171

Epoch 00295: val_loss did not improve from 1.32598
Epoch 296/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3912 - val_loss: 1.3282 - val_accuracy: 0.4123

Epoch 00296: val_loss did not improve from 1.32598
Epoch 297/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3940 - val_loss: 1.3308 - val_accuracy: 0.4067

Epoch 00297: val_loss did not improve from 1.32598
Epoch 298/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3936 - val_loss: 1.3279 - val_accuracy: 0.4219

Epoch 00298: val_loss did not improve from 1.32598
Epoch 299/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3954 - val_loss: 1.3296 - val_accuracy: 0.4195

Epoch 00299: val_loss did not improve from 1.32598
Epoch 300/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3932 - val_loss: 1.3266 - val_accuracy: 0.4282

Epoch 00300: val_loss did not improve from 1.32598
Epoch 301/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3922 - val_loss: 1.3274 - val_accuracy: 0.4211

Epoch 00301: val_loss did not improve from 1.32598
Epoch 302/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3922 - val_loss: 1.3278 - val_accuracy: 0.4195

Epoch 00302: val_loss did not improve from 1.32598
Epoch 303/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3940 - val_loss: 1.3273 - val_accuracy: 0.4211

Epoch 00303: val_loss did not improve from 1.32598
Epoch 304/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3934 - val_loss: 1.3265 - val_accuracy: 0.4298

Epoch 00304: val_loss did not improve from 1.32598
Epoch 305/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3860 - val_loss: 1.3317 - val_accuracy: 0.4099

Epoch 00305: val_loss did not improve from 1.32598
Epoch 306/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3888 - val_loss: 1.3273 - val_accuracy: 0.4139

Epoch 00306: val_loss did not improve from 1.32598
Epoch 307/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3946 - val_loss: 1.3271 - val_accuracy: 0.4163

Epoch 00307: val_loss did not improve from 1.32598
Epoch 308/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3879 - val_loss: 1.3306 - val_accuracy: 0.4059

Epoch 00308: val_loss did not improve from 1.32598
Epoch 309/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3877 - val_loss: 1.3304 - val_accuracy: 0.4211

Epoch 00309: val_loss did not improve from 1.32598
Epoch 310/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3842 - val_loss: 1.3273 - val_accuracy: 0.4179

Epoch 00310: val_loss did not improve from 1.32598
Epoch 311/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3916 - val_loss: 1.3271 - val_accuracy: 0.4115

Epoch 00311: val_loss did not improve from 1.32598
Epoch 312/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3952 - val_loss: 1.3311 - val_accuracy: 0.4075

Epoch 00312: val_loss did not improve from 1.32598
Epoch 313/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3909 - val_loss: 1.3270 - val_accuracy: 0.4179

Epoch 00313: val_loss did not improve from 1.32598
Epoch 314/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3919 - val_loss: 1.3263 - val_accuracy: 0.4171

Epoch 00314: val_loss did not improve from 1.32598
Epoch 315/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3952 - val_loss: 1.3257 - val_accuracy: 0.4274

Epoch 00315: val_loss improved from 1.32598 to 1.32565, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 316/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3959 - val_loss: 1.3269 - val_accuracy: 0.4187

Epoch 00316: val_loss did not improve from 1.32565
Epoch 317/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3962 - val_loss: 1.3285 - val_accuracy: 0.4219

Epoch 00317: val_loss did not improve from 1.32565
Epoch 318/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3940 - val_loss: 1.3307 - val_accuracy: 0.4115

Epoch 00318: val_loss did not improve from 1.32565
Epoch 319/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3897 - val_loss: 1.3270 - val_accuracy: 0.4242

Epoch 00319: val_loss did not improve from 1.32565
Epoch 320/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3902 - val_loss: 1.3319 - val_accuracy: 0.4067

Epoch 00320: val_loss did not improve from 1.32565
Epoch 321/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3910 - val_loss: 1.3289 - val_accuracy: 0.4219

Epoch 00321: val_loss did not improve from 1.32565
Epoch 322/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3871 - val_loss: 1.3264 - val_accuracy: 0.4242

Epoch 00322: val_loss did not improve from 1.32565
Epoch 323/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3943 - val_loss: 1.3292 - val_accuracy: 0.4242

Epoch 00323: val_loss did not improve from 1.32565
Epoch 324/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3913 - val_loss: 1.3278 - val_accuracy: 0.4139

Epoch 00324: val_loss did not improve from 1.32565
Epoch 325/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3927 - val_loss: 1.3281 - val_accuracy: 0.4099

Epoch 00325: val_loss did not improve from 1.32565
Epoch 326/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3915 - val_loss: 1.3302 - val_accuracy: 0.4131

Epoch 00326: val_loss did not improve from 1.32565
Epoch 327/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3922 - val_loss: 1.3282 - val_accuracy: 0.4187

Epoch 00327: val_loss did not improve from 1.32565
Epoch 328/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3931 - val_loss: 1.3271 - val_accuracy: 0.4195

Epoch 00328: val_loss did not improve from 1.32565
Epoch 329/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3958 - val_loss: 1.3303 - val_accuracy: 0.4179

Epoch 00329: val_loss did not improve from 1.32565
Epoch 330/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3930 - val_loss: 1.3271 - val_accuracy: 0.4282

Epoch 00330: val_loss did not improve from 1.32565
Epoch 331/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3953 - val_loss: 1.3271 - val_accuracy: 0.4203

Epoch 00331: val_loss did not improve from 1.32565
Epoch 332/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3943 - val_loss: 1.3330 - val_accuracy: 0.4147

Epoch 00332: val_loss did not improve from 1.32565
Epoch 333/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3900 - val_loss: 1.3278 - val_accuracy: 0.4155

Epoch 00333: val_loss did not improve from 1.32565
Epoch 334/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3931 - val_loss: 1.3275 - val_accuracy: 0.4155

Epoch 00334: val_loss did not improve from 1.32565
Epoch 335/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3928 - val_loss: 1.3281 - val_accuracy: 0.4203

Epoch 00335: val_loss did not improve from 1.32565
Epoch 336/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3962 - val_loss: 1.3272 - val_accuracy: 0.4195

Epoch 00336: val_loss did not improve from 1.32565
Epoch 337/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3929 - val_loss: 1.3285 - val_accuracy: 0.4234

Epoch 00337: val_loss did not improve from 1.32565
Epoch 338/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3928 - val_loss: 1.3266 - val_accuracy: 0.4234

Epoch 00338: val_loss did not improve from 1.32565
Epoch 339/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3963 - val_loss: 1.3284 - val_accuracy: 0.4211

Epoch 00339: val_loss did not improve from 1.32565
Epoch 340/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3961 - val_loss: 1.3271 - val_accuracy: 0.4187

Epoch 00340: val_loss did not improve from 1.32565
Epoch 341/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3985 - val_loss: 1.3317 - val_accuracy: 0.4099

Epoch 00341: val_loss did not improve from 1.32565
Epoch 342/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3947 - val_loss: 1.3269 - val_accuracy: 0.4195

Epoch 00342: val_loss did not improve from 1.32565
Epoch 343/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3921 - val_loss: 1.3267 - val_accuracy: 0.4219

Epoch 00343: val_loss did not improve from 1.32565
Epoch 344/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3998 - val_loss: 1.3305 - val_accuracy: 0.4155

Epoch 00344: val_loss did not improve from 1.32565
Epoch 345/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3923 - val_loss: 1.3281 - val_accuracy: 0.4219

Epoch 00345: val_loss did not improve from 1.32565
Epoch 346/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3939 - val_loss: 1.3279 - val_accuracy: 0.4211

Epoch 00346: val_loss did not improve from 1.32565
Epoch 347/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3956 - val_loss: 1.3279 - val_accuracy: 0.4187

Epoch 00347: val_loss did not improve from 1.32565
Epoch 348/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3927 - val_loss: 1.3262 - val_accuracy: 0.4250

Epoch 00348: val_loss did not improve from 1.32565
Epoch 349/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3976 - val_loss: 1.3340 - val_accuracy: 0.4179

Epoch 00349: val_loss did not improve from 1.32565
Epoch 350/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3897 - val_loss: 1.3274 - val_accuracy: 0.4219

Epoch 00350: val_loss did not improve from 1.32565
Epoch 351/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3962 - val_loss: 1.3302 - val_accuracy: 0.4179

Epoch 00351: val_loss did not improve from 1.32565
Epoch 352/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3899 - val_loss: 1.3277 - val_accuracy: 0.4123

Epoch 00352: val_loss did not improve from 1.32565
Epoch 353/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3921 - val_loss: 1.3267 - val_accuracy: 0.4211

Epoch 00353: val_loss did not improve from 1.32565
Epoch 354/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3972 - val_loss: 1.3260 - val_accuracy: 0.4282

Epoch 00354: val_loss did not improve from 1.32565
Epoch 355/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3979 - val_loss: 1.3317 - val_accuracy: 0.4219

Epoch 00355: val_loss did not improve from 1.32565
Epoch 356/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3938 - val_loss: 1.3258 - val_accuracy: 0.4274

Epoch 00356: val_loss did not improve from 1.32565
Epoch 357/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3965 - val_loss: 1.3296 - val_accuracy: 0.4219

Epoch 00357: val_loss did not improve from 1.32565
Epoch 358/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3925 - val_loss: 1.3269 - val_accuracy: 0.4179

Epoch 00358: val_loss did not improve from 1.32565
Epoch 359/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3954 - val_loss: 1.3256 - val_accuracy: 0.4211

Epoch 00359: val_loss improved from 1.32565 to 1.32559, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 360/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.3957 - val_loss: 1.3323 - val_accuracy: 0.4107

Epoch 00360: val_loss did not improve from 1.32559
Epoch 361/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3912 - val_loss: 1.3250 - val_accuracy: 0.4290

Epoch 00361: val_loss improved from 1.32559 to 1.32503, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 362/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3986 - val_loss: 1.3279 - val_accuracy: 0.4179

Epoch 00362: val_loss did not improve from 1.32503
Epoch 363/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3969 - val_loss: 1.3254 - val_accuracy: 0.4274

Epoch 00363: val_loss did not improve from 1.32503
Epoch 364/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3959 - val_loss: 1.3287 - val_accuracy: 0.4242

Epoch 00364: val_loss did not improve from 1.32503
Epoch 365/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3932 - val_loss: 1.3258 - val_accuracy: 0.4242

Epoch 00365: val_loss did not improve from 1.32503
Epoch 366/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3920 - val_loss: 1.3260 - val_accuracy: 0.4211

Epoch 00366: val_loss did not improve from 1.32503
Epoch 367/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3957 - val_loss: 1.3274 - val_accuracy: 0.4195

Epoch 00367: val_loss did not improve from 1.32503
Epoch 368/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3957 - val_loss: 1.3265 - val_accuracy: 0.4219

Epoch 00368: val_loss did not improve from 1.32503
Epoch 369/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3987 - val_loss: 1.3310 - val_accuracy: 0.4115

Epoch 00369: val_loss did not improve from 1.32503
Epoch 370/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3961 - val_loss: 1.3273 - val_accuracy: 0.4234

Epoch 00370: val_loss did not improve from 1.32503
Epoch 371/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3907 - val_loss: 1.3260 - val_accuracy: 0.4203

Epoch 00371: val_loss did not improve from 1.32503
Epoch 372/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3938 - val_loss: 1.3270 - val_accuracy: 0.4282

Epoch 00372: val_loss did not improve from 1.32503
Epoch 373/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3986 - val_loss: 1.3256 - val_accuracy: 0.4234

Epoch 00373: val_loss did not improve from 1.32503
Epoch 374/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3970 - val_loss: 1.3258 - val_accuracy: 0.4171

Epoch 00374: val_loss did not improve from 1.32503
Epoch 375/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3939 - val_loss: 1.3262 - val_accuracy: 0.4115

Epoch 00375: val_loss did not improve from 1.32503
Epoch 376/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3967 - val_loss: 1.3278 - val_accuracy: 0.4242

Epoch 00376: val_loss did not improve from 1.32503
Epoch 377/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3918 - val_loss: 1.3245 - val_accuracy: 0.4266

Epoch 00377: val_loss improved from 1.32503 to 1.32448, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 378/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3923 - val_loss: 1.3257 - val_accuracy: 0.4163

Epoch 00378: val_loss did not improve from 1.32448
Epoch 379/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3963 - val_loss: 1.3247 - val_accuracy: 0.4219

Epoch 00379: val_loss did not improve from 1.32448
Epoch 380/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3951 - val_loss: 1.3284 - val_accuracy: 0.4179

Epoch 00380: val_loss did not improve from 1.32448
Epoch 381/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3947 - val_loss: 1.3246 - val_accuracy: 0.4250

Epoch 00381: val_loss did not improve from 1.32448
Epoch 382/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3987 - val_loss: 1.3297 - val_accuracy: 0.4219

Epoch 00382: val_loss did not improve from 1.32448
Epoch 383/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3935 - val_loss: 1.3263 - val_accuracy: 0.4250

Epoch 00383: val_loss did not improve from 1.32448
Epoch 384/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3975 - val_loss: 1.3312 - val_accuracy: 0.4163

Epoch 00384: val_loss did not improve from 1.32448
Epoch 385/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3946 - val_loss: 1.3260 - val_accuracy: 0.4203

Epoch 00385: val_loss did not improve from 1.32448
Epoch 386/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3933 - val_loss: 1.3274 - val_accuracy: 0.4258

Epoch 00386: val_loss did not improve from 1.32448
Epoch 387/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.4000 - val_loss: 1.3327 - val_accuracy: 0.4083

Epoch 00387: val_loss did not improve from 1.32448
Epoch 388/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3923 - val_loss: 1.3262 - val_accuracy: 0.4187

Epoch 00388: val_loss did not improve from 1.32448
Epoch 389/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3923 - val_loss: 1.3279 - val_accuracy: 0.4187

Epoch 00389: val_loss did not improve from 1.32448
Epoch 390/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3909 - val_loss: 1.3269 - val_accuracy: 0.4139

Epoch 00390: val_loss did not improve from 1.32448
Epoch 391/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3938 - val_loss: 1.3267 - val_accuracy: 0.4083

Epoch 00391: val_loss did not improve from 1.32448
Epoch 392/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3947 - val_loss: 1.3256 - val_accuracy: 0.4171

Epoch 00392: val_loss did not improve from 1.32448
Epoch 393/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4003 - val_loss: 1.3322 - val_accuracy: 0.4107

Epoch 00393: val_loss did not improve from 1.32448
Epoch 394/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3889 - val_loss: 1.3262 - val_accuracy: 0.4163

Epoch 00394: val_loss did not improve from 1.32448
Epoch 395/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3901 - val_loss: 1.3268 - val_accuracy: 0.4219

Epoch 00395: val_loss did not improve from 1.32448
Epoch 396/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3973 - val_loss: 1.3308 - val_accuracy: 0.4115

Epoch 00396: val_loss did not improve from 1.32448
Epoch 397/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3912 - val_loss: 1.3256 - val_accuracy: 0.4171

Epoch 00397: val_loss did not improve from 1.32448
Epoch 398/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3962 - val_loss: 1.3250 - val_accuracy: 0.4211

Epoch 00398: val_loss did not improve from 1.32448
Epoch 399/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3995 - val_loss: 1.3278 - val_accuracy: 0.4250

Epoch 00399: val_loss did not improve from 1.32448
Epoch 400/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3954 - val_loss: 1.3273 - val_accuracy: 0.4115

Epoch 00400: val_loss did not improve from 1.32448
Epoch 401/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3956 - val_loss: 1.3256 - val_accuracy: 0.4115

Epoch 00401: val_loss did not improve from 1.32448
Epoch 402/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3965 - val_loss: 1.3263 - val_accuracy: 0.4107

Epoch 00402: val_loss did not improve from 1.32448
Epoch 403/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3955 - val_loss: 1.3267 - val_accuracy: 0.4211

Epoch 00403: val_loss did not improve from 1.32448
Epoch 404/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3956 - val_loss: 1.3259 - val_accuracy: 0.4258

Epoch 00404: val_loss did not improve from 1.32448
Epoch 405/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3943 - val_loss: 1.3256 - val_accuracy: 0.4195

Epoch 00405: val_loss did not improve from 1.32448
Epoch 406/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3998 - val_loss: 1.3271 - val_accuracy: 0.4147

Epoch 00406: val_loss did not improve from 1.32448
Epoch 407/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3989 - val_loss: 1.3278 - val_accuracy: 0.4115

Epoch 00407: val_loss did not improve from 1.32448
Epoch 408/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3947 - val_loss: 1.3272 - val_accuracy: 0.4075

Epoch 00408: val_loss did not improve from 1.32448
Epoch 409/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3902 - val_loss: 1.3259 - val_accuracy: 0.4211

Epoch 00409: val_loss did not improve from 1.32448
Epoch 410/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3945 - val_loss: 1.3271 - val_accuracy: 0.4131

Epoch 00410: val_loss did not improve from 1.32448
Epoch 411/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3990 - val_loss: 1.3298 - val_accuracy: 0.4155

Epoch 00411: val_loss did not improve from 1.32448
Epoch 412/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3938 - val_loss: 1.3271 - val_accuracy: 0.4075

Epoch 00412: val_loss did not improve from 1.32448
Epoch 413/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3948 - val_loss: 1.3249 - val_accuracy: 0.4234

Epoch 00413: val_loss did not improve from 1.32448
Epoch 414/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3974 - val_loss: 1.3271 - val_accuracy: 0.4059

Epoch 00414: val_loss did not improve from 1.32448
Epoch 415/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3995 - val_loss: 1.3259 - val_accuracy: 0.4147

Epoch 00415: val_loss did not improve from 1.32448
Epoch 416/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3978 - val_loss: 1.3252 - val_accuracy: 0.4258

Epoch 00416: val_loss did not improve from 1.32448
Epoch 417/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3983 - val_loss: 1.3275 - val_accuracy: 0.4203

Epoch 00417: val_loss did not improve from 1.32448
Epoch 418/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3955 - val_loss: 1.3244 - val_accuracy: 0.4234

Epoch 00418: val_loss improved from 1.32448 to 1.32436, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 419/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3971 - val_loss: 1.3262 - val_accuracy: 0.4234

Epoch 00419: val_loss did not improve from 1.32436
Epoch 420/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3960 - val_loss: 1.3259 - val_accuracy: 0.4187

Epoch 00420: val_loss did not improve from 1.32436
Epoch 421/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3915 - val_loss: 1.3300 - val_accuracy: 0.4051

Epoch 00421: val_loss did not improve from 1.32436
Epoch 422/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3923 - val_loss: 1.3255 - val_accuracy: 0.4171

Epoch 00422: val_loss did not improve from 1.32436
Epoch 423/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3961 - val_loss: 1.3294 - val_accuracy: 0.4147

Epoch 00423: val_loss did not improve from 1.32436
Epoch 424/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3884 - val_loss: 1.3277 - val_accuracy: 0.4203

Epoch 00424: val_loss did not improve from 1.32436
Epoch 425/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3972 - val_loss: 1.3315 - val_accuracy: 0.4107

Epoch 00425: val_loss did not improve from 1.32436
Epoch 426/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3957 - val_loss: 1.3252 - val_accuracy: 0.4187

Epoch 00426: val_loss did not improve from 1.32436
Epoch 427/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3968 - val_loss: 1.3256 - val_accuracy: 0.4083

Epoch 00427: val_loss did not improve from 1.32436
Epoch 428/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4006 - val_loss: 1.3285 - val_accuracy: 0.4131

Epoch 00428: val_loss did not improve from 1.32436
Epoch 429/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3974 - val_loss: 1.3276 - val_accuracy: 0.4051

Epoch 00429: val_loss did not improve from 1.32436
Epoch 430/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3963 - val_loss: 1.3269 - val_accuracy: 0.4131

Epoch 00430: val_loss did not improve from 1.32436
Epoch 431/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3945 - val_loss: 1.3283 - val_accuracy: 0.4187

Epoch 00431: val_loss did not improve from 1.32436
Epoch 432/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3985 - val_loss: 1.3265 - val_accuracy: 0.4147

Epoch 00432: val_loss did not improve from 1.32436
Epoch 433/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3941 - val_loss: 1.3259 - val_accuracy: 0.4107

Epoch 00433: val_loss did not improve from 1.32436
Epoch 434/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3975 - val_loss: 1.3302 - val_accuracy: 0.4123

Epoch 00434: val_loss did not improve from 1.32436
Epoch 435/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3964 - val_loss: 1.3260 - val_accuracy: 0.4274

Epoch 00435: val_loss did not improve from 1.32436
Epoch 436/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3957 - val_loss: 1.3258 - val_accuracy: 0.4147

Epoch 00436: val_loss did not improve from 1.32436
Epoch 437/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4003 - val_loss: 1.3294 - val_accuracy: 0.4163

Epoch 00437: val_loss did not improve from 1.32436
Epoch 438/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3942 - val_loss: 1.3253 - val_accuracy: 0.4234

Epoch 00438: val_loss did not improve from 1.32436
Epoch 439/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3898 - val_loss: 1.3268 - val_accuracy: 0.4195

Epoch 00439: val_loss did not improve from 1.32436
Epoch 440/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3912 - val_loss: 1.3252 - val_accuracy: 0.4211

Epoch 00440: val_loss did not improve from 1.32436
Epoch 441/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.4032 - val_loss: 1.3299 - val_accuracy: 0.4219

Epoch 00441: val_loss did not improve from 1.32436
Epoch 442/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3976 - val_loss: 1.3247 - val_accuracy: 0.4234

Epoch 00442: val_loss did not improve from 1.32436
Epoch 443/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3947 - val_loss: 1.3251 - val_accuracy: 0.4171

Epoch 00443: val_loss did not improve from 1.32436
Epoch 444/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3970 - val_loss: 1.3290 - val_accuracy: 0.4171

Epoch 00444: val_loss did not improve from 1.32436
Epoch 445/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3992 - val_loss: 1.3265 - val_accuracy: 0.4203

Epoch 00445: val_loss did not improve from 1.32436
Epoch 446/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3897 - val_loss: 1.3247 - val_accuracy: 0.4139

Epoch 00446: val_loss did not improve from 1.32436
Epoch 447/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3997 - val_loss: 1.3257 - val_accuracy: 0.4083

Epoch 00447: val_loss did not improve from 1.32436
Epoch 448/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3931 - val_loss: 1.3259 - val_accuracy: 0.4203

Epoch 00448: val_loss did not improve from 1.32436
Epoch 449/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3961 - val_loss: 1.3239 - val_accuracy: 0.4274

Epoch 00449: val_loss improved from 1.32436 to 1.32393, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 450/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3980 - val_loss: 1.3238 - val_accuracy: 0.4155

Epoch 00450: val_loss improved from 1.32393 to 1.32379, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 451/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4008 - val_loss: 1.3263 - val_accuracy: 0.4242

Epoch 00451: val_loss did not improve from 1.32379
Epoch 452/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3995 - val_loss: 1.3270 - val_accuracy: 0.4131

Epoch 00452: val_loss did not improve from 1.32379
Epoch 453/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3924 - val_loss: 1.3259 - val_accuracy: 0.4171

Epoch 00453: val_loss did not improve from 1.32379
Epoch 454/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3923 - val_loss: 1.3304 - val_accuracy: 0.4019

Epoch 00454: val_loss did not improve from 1.32379
Epoch 455/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3960 - val_loss: 1.3255 - val_accuracy: 0.4179

Epoch 00455: val_loss did not improve from 1.32379
Epoch 456/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4005 - val_loss: 1.3247 - val_accuracy: 0.4187

Epoch 00456: val_loss did not improve from 1.32379
Epoch 457/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3998 - val_loss: 1.3264 - val_accuracy: 0.4219

Epoch 00457: val_loss did not improve from 1.32379
Epoch 458/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3947 - val_loss: 1.3280 - val_accuracy: 0.4195

Epoch 00458: val_loss did not improve from 1.32379
Epoch 459/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3980 - val_loss: 1.3348 - val_accuracy: 0.4051

Epoch 00459: val_loss did not improve from 1.32379
Epoch 460/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3890 - val_loss: 1.3259 - val_accuracy: 0.4115

Epoch 00460: val_loss did not improve from 1.32379
Epoch 461/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3947 - val_loss: 1.3274 - val_accuracy: 0.4091

Epoch 00461: val_loss did not improve from 1.32379
Epoch 462/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3905 - val_loss: 1.3255 - val_accuracy: 0.4203

Epoch 00462: val_loss did not improve from 1.32379
Epoch 463/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3985 - val_loss: 1.3246 - val_accuracy: 0.4250

Epoch 00463: val_loss did not improve from 1.32379
Epoch 464/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3979 - val_loss: 1.3278 - val_accuracy: 0.4163

Epoch 00464: val_loss did not improve from 1.32379
Epoch 465/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3943 - val_loss: 1.3248 - val_accuracy: 0.4163

Epoch 00465: val_loss did not improve from 1.32379
Epoch 466/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3977 - val_loss: 1.3270 - val_accuracy: 0.4147

Epoch 00466: val_loss did not improve from 1.32379
Epoch 467/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3958 - val_loss: 1.3266 - val_accuracy: 0.4139

Epoch 00467: val_loss did not improve from 1.32379
Epoch 468/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3990 - val_loss: 1.3251 - val_accuracy: 0.4226

Epoch 00468: val_loss did not improve from 1.32379
Epoch 469/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3967 - val_loss: 1.3250 - val_accuracy: 0.4187

Epoch 00469: val_loss did not improve from 1.32379
Epoch 470/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3923 - val_loss: 1.3240 - val_accuracy: 0.4211

Epoch 00470: val_loss did not improve from 1.32379
Epoch 471/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3993 - val_loss: 1.3316 - val_accuracy: 0.4115

Epoch 00471: val_loss did not improve from 1.32379
Epoch 472/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3979 - val_loss: 1.3244 - val_accuracy: 0.4250

Epoch 00472: val_loss did not improve from 1.32379
Epoch 473/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3900 - val_loss: 1.3256 - val_accuracy: 0.4187

Epoch 00473: val_loss did not improve from 1.32379
Epoch 474/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3979 - val_loss: 1.3244 - val_accuracy: 0.4179

Epoch 00474: val_loss did not improve from 1.32379
Epoch 475/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3993 - val_loss: 1.3253 - val_accuracy: 0.4250

Epoch 00475: val_loss did not improve from 1.32379
Epoch 476/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3993 - val_loss: 1.3250 - val_accuracy: 0.4195

Epoch 00476: val_loss did not improve from 1.32379
Epoch 477/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3942 - val_loss: 1.3290 - val_accuracy: 0.4171

Epoch 00477: val_loss did not improve from 1.32379
Epoch 478/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3923 - val_loss: 1.3243 - val_accuracy: 0.4147

Epoch 00478: val_loss did not improve from 1.32379
Epoch 479/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4001 - val_loss: 1.3260 - val_accuracy: 0.4234

Epoch 00479: val_loss did not improve from 1.32379
Epoch 480/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3979 - val_loss: 1.3261 - val_accuracy: 0.4131

Epoch 00480: val_loss did not improve from 1.32379
Epoch 481/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4013 - val_loss: 1.3235 - val_accuracy: 0.4219

Epoch 00481: val_loss improved from 1.32379 to 1.32348, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 482/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3970 - val_loss: 1.3243 - val_accuracy: 0.4195

Epoch 00482: val_loss did not improve from 1.32348
Epoch 483/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3953 - val_loss: 1.3233 - val_accuracy: 0.4242

Epoch 00483: val_loss improved from 1.32348 to 1.32334, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 484/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3993 - val_loss: 1.3267 - val_accuracy: 0.4131

Epoch 00484: val_loss did not improve from 1.32334
Epoch 485/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3977 - val_loss: 1.3270 - val_accuracy: 0.4234

Epoch 00485: val_loss did not improve from 1.32334
Epoch 486/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3943 - val_loss: 1.3242 - val_accuracy: 0.4147

Epoch 00486: val_loss did not improve from 1.32334
Epoch 487/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3989 - val_loss: 1.3252 - val_accuracy: 0.4195

Epoch 00487: val_loss did not improve from 1.32334
Epoch 488/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4009 - val_loss: 1.3264 - val_accuracy: 0.4171

Epoch 00488: val_loss did not improve from 1.32334
Epoch 489/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3958 - val_loss: 1.3249 - val_accuracy: 0.4147

Epoch 00489: val_loss did not improve from 1.32334
Epoch 490/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4003 - val_loss: 1.3298 - val_accuracy: 0.4195

Epoch 00490: val_loss did not improve from 1.32334
Epoch 491/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3978 - val_loss: 1.3254 - val_accuracy: 0.4155

Epoch 00491: val_loss did not improve from 1.32334
Epoch 492/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.3974 - val_loss: 1.3271 - val_accuracy: 0.4187

Epoch 00492: val_loss did not improve from 1.32334
Epoch 493/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3981 - val_loss: 1.3229 - val_accuracy: 0.4203

Epoch 00493: val_loss improved from 1.32334 to 1.32293, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 494/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3995 - val_loss: 1.3236 - val_accuracy: 0.4211

Epoch 00494: val_loss did not improve from 1.32293
Epoch 495/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.4007 - val_loss: 1.3280 - val_accuracy: 0.4195

Epoch 00495: val_loss did not improve from 1.32293
Epoch 496/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3984 - val_loss: 1.3226 - val_accuracy: 0.4179

Epoch 00496: val_loss improved from 1.32293 to 1.32259, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 497/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4007 - val_loss: 1.3265 - val_accuracy: 0.4131

Epoch 00497: val_loss did not improve from 1.32259
Epoch 498/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3957 - val_loss: 1.3240 - val_accuracy: 0.4147

Epoch 00498: val_loss did not improve from 1.32259
Epoch 499/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3958 - val_loss: 1.3232 - val_accuracy: 0.4187

Epoch 00499: val_loss did not improve from 1.32259
Epoch 500/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3985 - val_loss: 1.3258 - val_accuracy: 0.4234

Epoch 00500: val_loss did not improve from 1.32259
Epoch 501/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4006 - val_loss: 1.3241 - val_accuracy: 0.4219

Epoch 00501: val_loss did not improve from 1.32259
Epoch 502/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4015 - val_loss: 1.3242 - val_accuracy: 0.4187

Epoch 00502: val_loss did not improve from 1.32259
Epoch 503/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3975 - val_loss: 1.3238 - val_accuracy: 0.4147

Epoch 00503: val_loss did not improve from 1.32259
Epoch 504/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.4009 - val_loss: 1.3284 - val_accuracy: 0.4219

Epoch 00504: val_loss did not improve from 1.32259
Epoch 505/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3989 - val_loss: 1.3243 - val_accuracy: 0.4147

Epoch 00505: val_loss did not improve from 1.32259
Epoch 506/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3971 - val_loss: 1.3232 - val_accuracy: 0.4139

Epoch 00506: val_loss did not improve from 1.32259
Epoch 507/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4016 - val_loss: 1.3249 - val_accuracy: 0.4250

Epoch 00507: val_loss did not improve from 1.32259
Epoch 508/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4004 - val_loss: 1.3248 - val_accuracy: 0.4234

Epoch 00508: val_loss did not improve from 1.32259
Epoch 509/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3957 - val_loss: 1.3231 - val_accuracy: 0.4163

Epoch 00509: val_loss did not improve from 1.32259
Epoch 510/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3996 - val_loss: 1.3234 - val_accuracy: 0.4258

Epoch 00510: val_loss did not improve from 1.32259
Epoch 511/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3992 - val_loss: 1.3239 - val_accuracy: 0.4282

Epoch 00511: val_loss did not improve from 1.32259
Epoch 512/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4032 - val_loss: 1.3251 - val_accuracy: 0.4226

Epoch 00512: val_loss did not improve from 1.32259
Epoch 513/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4030 - val_loss: 1.3297 - val_accuracy: 0.4171

Epoch 00513: val_loss did not improve from 1.32259
Epoch 514/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3890 - val_loss: 1.3242 - val_accuracy: 0.4282

Epoch 00514: val_loss did not improve from 1.32259
Epoch 515/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3958 - val_loss: 1.3234 - val_accuracy: 0.4187

Epoch 00515: val_loss did not improve from 1.32259
Epoch 516/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4012 - val_loss: 1.3316 - val_accuracy: 0.4179

Epoch 00516: val_loss did not improve from 1.32259
Epoch 517/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3962 - val_loss: 1.3236 - val_accuracy: 0.4171

Epoch 00517: val_loss did not improve from 1.32259
Epoch 518/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3986 - val_loss: 1.3228 - val_accuracy: 0.4219

Epoch 00518: val_loss did not improve from 1.32259
Epoch 519/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.4009 - val_loss: 1.3260 - val_accuracy: 0.4187

Epoch 00519: val_loss did not improve from 1.32259
Epoch 520/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3993 - val_loss: 1.3268 - val_accuracy: 0.4187

Epoch 00520: val_loss did not improve from 1.32259
Epoch 521/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3926 - val_loss: 1.3235 - val_accuracy: 0.4195

Epoch 00521: val_loss did not improve from 1.32259
Epoch 522/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4011 - val_loss: 1.3273 - val_accuracy: 0.4203

Epoch 00522: val_loss did not improve from 1.32259
Epoch 523/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3954 - val_loss: 1.3237 - val_accuracy: 0.4195

Epoch 00523: val_loss did not improve from 1.32259
Epoch 524/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4014 - val_loss: 1.3234 - val_accuracy: 0.4219

Epoch 00524: val_loss did not improve from 1.32259
Epoch 525/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4002 - val_loss: 1.3246 - val_accuracy: 0.4282

Epoch 00525: val_loss did not improve from 1.32259
Epoch 526/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4004 - val_loss: 1.3224 - val_accuracy: 0.4234

Epoch 00526: val_loss improved from 1.32259 to 1.32241, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 527/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4039 - val_loss: 1.3243 - val_accuracy: 0.4234

Epoch 00527: val_loss did not improve from 1.32241
Epoch 528/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.3976 - val_loss: 1.3214 - val_accuracy: 0.4187

Epoch 00528: val_loss improved from 1.32241 to 1.32137, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 529/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3999 - val_loss: 1.3252 - val_accuracy: 0.4219

Epoch 00529: val_loss did not improve from 1.32137
Epoch 530/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.3972 - val_loss: 1.3222 - val_accuracy: 0.4147

Epoch 00530: val_loss did not improve from 1.32137
Epoch 531/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4000 - val_loss: 1.3297 - val_accuracy: 0.4139

Epoch 00531: val_loss did not improve from 1.32137
Epoch 532/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3962 - val_loss: 1.3235 - val_accuracy: 0.4147

Epoch 00532: val_loss did not improve from 1.32137
Epoch 533/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3976 - val_loss: 1.3234 - val_accuracy: 0.4155

Epoch 00533: val_loss did not improve from 1.32137
Epoch 534/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3998 - val_loss: 1.3248 - val_accuracy: 0.4219

Epoch 00534: val_loss did not improve from 1.32137
Epoch 535/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3990 - val_loss: 1.3217 - val_accuracy: 0.4163

Epoch 00535: val_loss did not improve from 1.32137
Epoch 536/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3976 - val_loss: 1.3247 - val_accuracy: 0.4242

Epoch 00536: val_loss did not improve from 1.32137
Epoch 537/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3985 - val_loss: 1.3224 - val_accuracy: 0.4115

Epoch 00537: val_loss did not improve from 1.32137
Epoch 538/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4001 - val_loss: 1.3241 - val_accuracy: 0.4219

Epoch 00538: val_loss did not improve from 1.32137
Epoch 539/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.3991 - val_loss: 1.3247 - val_accuracy: 0.4211

Epoch 00539: val_loss did not improve from 1.32137
Epoch 540/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3955 - val_loss: 1.3238 - val_accuracy: 0.4147

Epoch 00540: val_loss did not improve from 1.32137
Epoch 541/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3979 - val_loss: 1.3289 - val_accuracy: 0.4099

Epoch 00541: val_loss did not improve from 1.32137
Epoch 542/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3984 - val_loss: 1.3236 - val_accuracy: 0.4131

Epoch 00542: val_loss did not improve from 1.32137
Epoch 543/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3974 - val_loss: 1.3278 - val_accuracy: 0.4043

Epoch 00543: val_loss did not improve from 1.32137
Epoch 544/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3939 - val_loss: 1.3230 - val_accuracy: 0.4139

Epoch 00544: val_loss did not improve from 1.32137
Epoch 545/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4015 - val_loss: 1.3248 - val_accuracy: 0.4171

Epoch 00545: val_loss did not improve from 1.32137
Epoch 546/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.3987 - val_loss: 1.3213 - val_accuracy: 0.4139

Epoch 00546: val_loss improved from 1.32137 to 1.32134, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 547/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4021 - val_loss: 1.3231 - val_accuracy: 0.4306

Epoch 00547: val_loss did not improve from 1.32134
Epoch 548/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4016 - val_loss: 1.3235 - val_accuracy: 0.4187

Epoch 00548: val_loss did not improve from 1.32134
Epoch 549/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3931 - val_loss: 1.3247 - val_accuracy: 0.4187

Epoch 00549: val_loss did not improve from 1.32134
Epoch 550/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4023 - val_loss: 1.3265 - val_accuracy: 0.4195

Epoch 00550: val_loss did not improve from 1.32134
Epoch 551/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3976 - val_loss: 1.3229 - val_accuracy: 0.4203

Epoch 00551: val_loss did not improve from 1.32134
Epoch 552/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4017 - val_loss: 1.3237 - val_accuracy: 0.4163

Epoch 00552: val_loss did not improve from 1.32134
Epoch 553/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4005 - val_loss: 1.3229 - val_accuracy: 0.4171

Epoch 00553: val_loss did not improve from 1.32134
Epoch 554/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.4014 - val_loss: 1.3236 - val_accuracy: 0.4274

Epoch 00554: val_loss did not improve from 1.32134
Epoch 555/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3993 - val_loss: 1.3230 - val_accuracy: 0.4219

Epoch 00555: val_loss did not improve from 1.32134
Epoch 556/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4002 - val_loss: 1.3232 - val_accuracy: 0.4155

Epoch 00556: val_loss did not improve from 1.32134
Epoch 557/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4016 - val_loss: 1.3319 - val_accuracy: 0.4123

Epoch 00557: val_loss did not improve from 1.32134
Epoch 558/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3989 - val_loss: 1.3236 - val_accuracy: 0.4155

Epoch 00558: val_loss did not improve from 1.32134
Epoch 559/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3996 - val_loss: 1.3241 - val_accuracy: 0.4155

Epoch 00559: val_loss did not improve from 1.32134
Epoch 560/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4011 - val_loss: 1.3235 - val_accuracy: 0.4203

Epoch 00560: val_loss did not improve from 1.32134
Epoch 561/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4028 - val_loss: 1.3235 - val_accuracy: 0.4187

Epoch 00561: val_loss did not improve from 1.32134
Epoch 562/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4019 - val_loss: 1.3243 - val_accuracy: 0.4234

Epoch 00562: val_loss did not improve from 1.32134
Epoch 563/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.3982 - val_loss: 1.3229 - val_accuracy: 0.4139

Epoch 00563: val_loss did not improve from 1.32134
Epoch 564/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4048 - val_loss: 1.3314 - val_accuracy: 0.4083

Epoch 00564: val_loss did not improve from 1.32134
Epoch 565/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3949 - val_loss: 1.3228 - val_accuracy: 0.4203

Epoch 00565: val_loss did not improve from 1.32134
Epoch 566/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4011 - val_loss: 1.3241 - val_accuracy: 0.4163

Epoch 00566: val_loss did not improve from 1.32134
Epoch 567/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4009 - val_loss: 1.3249 - val_accuracy: 0.4211

Epoch 00567: val_loss did not improve from 1.32134
Epoch 568/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3948 - val_loss: 1.3240 - val_accuracy: 0.4171

Epoch 00568: val_loss did not improve from 1.32134
Epoch 569/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4017 - val_loss: 1.3268 - val_accuracy: 0.4187

Epoch 00569: val_loss did not improve from 1.32134
Epoch 570/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3979 - val_loss: 1.3231 - val_accuracy: 0.4107

Epoch 00570: val_loss did not improve from 1.32134
Epoch 571/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.3993 - val_loss: 1.3226 - val_accuracy: 0.4163

Epoch 00571: val_loss did not improve from 1.32134
Epoch 572/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.3993 - val_loss: 1.3251 - val_accuracy: 0.4123

Epoch 00572: val_loss did not improve from 1.32134
Epoch 573/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.3999 - val_loss: 1.3232 - val_accuracy: 0.4083

Epoch 00573: val_loss did not improve from 1.32134
Epoch 574/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3948 - val_loss: 1.3227 - val_accuracy: 0.4163

Epoch 00574: val_loss did not improve from 1.32134
Epoch 575/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4020 - val_loss: 1.3248 - val_accuracy: 0.4266

Epoch 00575: val_loss did not improve from 1.32134
Epoch 576/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4004 - val_loss: 1.3210 - val_accuracy: 0.4147

Epoch 00576: val_loss improved from 1.32134 to 1.32101, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 577/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4005 - val_loss: 1.3224 - val_accuracy: 0.4179

Epoch 00577: val_loss did not improve from 1.32101
Epoch 578/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4036 - val_loss: 1.3266 - val_accuracy: 0.4163

Epoch 00578: val_loss did not improve from 1.32101
Epoch 579/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3988 - val_loss: 1.3229 - val_accuracy: 0.4139

Epoch 00579: val_loss did not improve from 1.32101
Epoch 580/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4041 - val_loss: 1.3238 - val_accuracy: 0.4139

Epoch 00580: val_loss did not improve from 1.32101
Epoch 581/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4049 - val_loss: 1.3233 - val_accuracy: 0.4155

Epoch 00581: val_loss did not improve from 1.32101
Epoch 582/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4002 - val_loss: 1.3227 - val_accuracy: 0.4155

Epoch 00582: val_loss did not improve from 1.32101
Epoch 583/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3962 - val_loss: 1.3215 - val_accuracy: 0.4147

Epoch 00583: val_loss did not improve from 1.32101
Epoch 584/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4009 - val_loss: 1.3250 - val_accuracy: 0.4179

Epoch 00584: val_loss did not improve from 1.32101
Epoch 585/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.3981 - val_loss: 1.3238 - val_accuracy: 0.4123

Epoch 00585: val_loss did not improve from 1.32101
Epoch 586/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3962 - val_loss: 1.3215 - val_accuracy: 0.4131

Epoch 00586: val_loss did not improve from 1.32101
Epoch 587/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4026 - val_loss: 1.3237 - val_accuracy: 0.4075

Epoch 00587: val_loss did not improve from 1.32101
Epoch 588/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4040 - val_loss: 1.3244 - val_accuracy: 0.4250

Epoch 00588: val_loss did not improve from 1.32101
Epoch 589/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.3981 - val_loss: 1.3225 - val_accuracy: 0.4155

Epoch 00589: val_loss did not improve from 1.32101
Epoch 590/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3982 - val_loss: 1.3238 - val_accuracy: 0.4123

Epoch 00590: val_loss did not improve from 1.32101
Epoch 591/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4045 - val_loss: 1.3271 - val_accuracy: 0.4219

Epoch 00591: val_loss did not improve from 1.32101
Epoch 592/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3937 - val_loss: 1.3226 - val_accuracy: 0.4163

Epoch 00592: val_loss did not improve from 1.32101
Epoch 593/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4024 - val_loss: 1.3237 - val_accuracy: 0.4163

Epoch 00593: val_loss did not improve from 1.32101
Epoch 594/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4003 - val_loss: 1.3213 - val_accuracy: 0.4123

Epoch 00594: val_loss did not improve from 1.32101
Epoch 595/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4000 - val_loss: 1.3272 - val_accuracy: 0.4266

Epoch 00595: val_loss did not improve from 1.32101
Epoch 596/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3968 - val_loss: 1.3223 - val_accuracy: 0.4147

Epoch 00596: val_loss did not improve from 1.32101
Epoch 597/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4015 - val_loss: 1.3243 - val_accuracy: 0.4195

Epoch 00597: val_loss did not improve from 1.32101
Epoch 598/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4001 - val_loss: 1.3218 - val_accuracy: 0.4131

Epoch 00598: val_loss did not improve from 1.32101
Epoch 599/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3993 - val_loss: 1.3328 - val_accuracy: 0.4226

Epoch 00599: val_loss did not improve from 1.32101
Epoch 600/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3940 - val_loss: 1.3232 - val_accuracy: 0.4187

Epoch 00600: val_loss did not improve from 1.32101
Epoch 601/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.4049 - val_loss: 1.3262 - val_accuracy: 0.4226

Epoch 00601: val_loss did not improve from 1.32101
Epoch 602/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3979 - val_loss: 1.3214 - val_accuracy: 0.4226

Epoch 00602: val_loss did not improve from 1.32101
Epoch 603/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3993 - val_loss: 1.3221 - val_accuracy: 0.4123

Epoch 00603: val_loss did not improve from 1.32101
Epoch 604/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4010 - val_loss: 1.3230 - val_accuracy: 0.4226

Epoch 00604: val_loss did not improve from 1.32101
Epoch 605/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3995 - val_loss: 1.3215 - val_accuracy: 0.4147

Epoch 00605: val_loss did not improve from 1.32101
Epoch 606/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3990 - val_loss: 1.3230 - val_accuracy: 0.4242

Epoch 00606: val_loss did not improve from 1.32101
Epoch 607/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4005 - val_loss: 1.3205 - val_accuracy: 0.4250

Epoch 00607: val_loss improved from 1.32101 to 1.32050, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 608/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4010 - val_loss: 1.3222 - val_accuracy: 0.4203

Epoch 00608: val_loss did not improve from 1.32050
Epoch 609/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3997 - val_loss: 1.3226 - val_accuracy: 0.4290

Epoch 00609: val_loss did not improve from 1.32050
Epoch 610/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3974 - val_loss: 1.3207 - val_accuracy: 0.4187

Epoch 00610: val_loss did not improve from 1.32050
Epoch 611/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4022 - val_loss: 1.3218 - val_accuracy: 0.4266

Epoch 00611: val_loss did not improve from 1.32050
Epoch 612/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4006 - val_loss: 1.3202 - val_accuracy: 0.4282

Epoch 00612: val_loss improved from 1.32050 to 1.32018, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 613/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4038 - val_loss: 1.3257 - val_accuracy: 0.4123

Epoch 00613: val_loss did not improve from 1.32018
Epoch 614/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4020 - val_loss: 1.3211 - val_accuracy: 0.4139

Epoch 00614: val_loss did not improve from 1.32018
Epoch 615/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3988 - val_loss: 1.3208 - val_accuracy: 0.4155

Epoch 00615: val_loss did not improve from 1.32018
Epoch 616/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.3998 - val_loss: 1.3221 - val_accuracy: 0.4187

Epoch 00616: val_loss did not improve from 1.32018
Epoch 617/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4009 - val_loss: 1.3220 - val_accuracy: 0.4211

Epoch 00617: val_loss did not improve from 1.32018
Epoch 618/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4018 - val_loss: 1.3212 - val_accuracy: 0.4219

Epoch 00618: val_loss did not improve from 1.32018
Epoch 619/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4033 - val_loss: 1.3213 - val_accuracy: 0.4306

Epoch 00619: val_loss did not improve from 1.32018
Epoch 620/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.3995 - val_loss: 1.3247 - val_accuracy: 0.4139

Epoch 00620: val_loss did not improve from 1.32018
Epoch 621/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4026 - val_loss: 1.3212 - val_accuracy: 0.4211

Epoch 00621: val_loss did not improve from 1.32018
Epoch 622/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4024 - val_loss: 1.3239 - val_accuracy: 0.4226

Epoch 00622: val_loss did not improve from 1.32018
Epoch 623/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3998 - val_loss: 1.3223 - val_accuracy: 0.4211

Epoch 00623: val_loss did not improve from 1.32018
Epoch 624/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3953 - val_loss: 1.3219 - val_accuracy: 0.4203

Epoch 00624: val_loss did not improve from 1.32018
Epoch 625/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4036 - val_loss: 1.3283 - val_accuracy: 0.4091

Epoch 00625: val_loss did not improve from 1.32018
Epoch 626/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3993 - val_loss: 1.3220 - val_accuracy: 0.4107

Epoch 00626: val_loss did not improve from 1.32018
Epoch 627/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4006 - val_loss: 1.3263 - val_accuracy: 0.4226

Epoch 00627: val_loss did not improve from 1.32018
Epoch 628/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4003 - val_loss: 1.3208 - val_accuracy: 0.4131

Epoch 00628: val_loss did not improve from 1.32018
Epoch 629/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.3998 - val_loss: 1.3217 - val_accuracy: 0.4171

Epoch 00629: val_loss did not improve from 1.32018
Epoch 630/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.3985 - val_loss: 1.3211 - val_accuracy: 0.4266

Epoch 00630: val_loss did not improve from 1.32018
Epoch 631/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4046 - val_loss: 1.3251 - val_accuracy: 0.4163

Epoch 00631: val_loss did not improve from 1.32018
Epoch 632/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4006 - val_loss: 1.3211 - val_accuracy: 0.4226

Epoch 00632: val_loss did not improve from 1.32018
Epoch 633/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4003 - val_loss: 1.3210 - val_accuracy: 0.4131

Epoch 00633: val_loss did not improve from 1.32018
Epoch 634/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.4036 - val_loss: 1.3217 - val_accuracy: 0.4314

Epoch 00634: val_loss did not improve from 1.32018
Epoch 635/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4002 - val_loss: 1.3216 - val_accuracy: 0.4155

Epoch 00635: val_loss did not improve from 1.32018
Epoch 636/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3999 - val_loss: 1.3220 - val_accuracy: 0.4179

Epoch 00636: val_loss did not improve from 1.32018
Epoch 637/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4020 - val_loss: 1.3224 - val_accuracy: 0.4187

Epoch 00637: val_loss did not improve from 1.32018
Epoch 638/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4023 - val_loss: 1.3250 - val_accuracy: 0.4091

Epoch 00638: val_loss did not improve from 1.32018
Epoch 639/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3997 - val_loss: 1.3235 - val_accuracy: 0.4115

Epoch 00639: val_loss did not improve from 1.32018
Epoch 640/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4027 - val_loss: 1.3238 - val_accuracy: 0.4203

Epoch 00640: val_loss did not improve from 1.32018
Epoch 641/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4022 - val_loss: 1.3222 - val_accuracy: 0.4242

Epoch 00641: val_loss did not improve from 1.32018
Epoch 642/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4013 - val_loss: 1.3257 - val_accuracy: 0.4099

Epoch 00642: val_loss did not improve from 1.32018
Epoch 643/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.3996 - val_loss: 1.3217 - val_accuracy: 0.4242

Epoch 00643: val_loss did not improve from 1.32018
Epoch 644/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4024 - val_loss: 1.3206 - val_accuracy: 0.4203

Epoch 00644: val_loss did not improve from 1.32018
Epoch 645/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4016 - val_loss: 1.3218 - val_accuracy: 0.4107

Epoch 00645: val_loss did not improve from 1.32018
Epoch 646/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4003 - val_loss: 1.3223 - val_accuracy: 0.4226

Epoch 00646: val_loss did not improve from 1.32018
Epoch 647/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4032 - val_loss: 1.3221 - val_accuracy: 0.4139

Epoch 00647: val_loss did not improve from 1.32018
Epoch 648/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4038 - val_loss: 1.3258 - val_accuracy: 0.4195

Epoch 00648: val_loss did not improve from 1.32018
Epoch 649/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3986 - val_loss: 1.3219 - val_accuracy: 0.4179

Epoch 00649: val_loss did not improve from 1.32018
Epoch 650/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3980 - val_loss: 1.3208 - val_accuracy: 0.4171

Epoch 00650: val_loss did not improve from 1.32018
Epoch 651/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4028 - val_loss: 1.3238 - val_accuracy: 0.4250

Epoch 00651: val_loss did not improve from 1.32018
Epoch 652/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3968 - val_loss: 1.3208 - val_accuracy: 0.4123

Epoch 00652: val_loss did not improve from 1.32018
Epoch 653/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.3996 - val_loss: 1.3222 - val_accuracy: 0.4274

Epoch 00653: val_loss did not improve from 1.32018
Epoch 654/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4009 - val_loss: 1.3214 - val_accuracy: 0.4115

Epoch 00654: val_loss did not improve from 1.32018
Epoch 655/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4013 - val_loss: 1.3243 - val_accuracy: 0.4163

Epoch 00655: val_loss did not improve from 1.32018
Epoch 656/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4009 - val_loss: 1.3218 - val_accuracy: 0.4163

Epoch 00656: val_loss did not improve from 1.32018
Epoch 657/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.3990 - val_loss: 1.3217 - val_accuracy: 0.4163

Epoch 00657: val_loss did not improve from 1.32018
Epoch 658/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4028 - val_loss: 1.3241 - val_accuracy: 0.4051

Epoch 00658: val_loss did not improve from 1.32018
Epoch 659/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3962 - val_loss: 1.3229 - val_accuracy: 0.4115

Epoch 00659: val_loss did not improve from 1.32018
Epoch 660/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.3979 - val_loss: 1.3216 - val_accuracy: 0.4139

Epoch 00660: val_loss did not improve from 1.32018
Epoch 661/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4019 - val_loss: 1.3233 - val_accuracy: 0.4290

Epoch 00661: val_loss did not improve from 1.32018
Epoch 662/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4011 - val_loss: 1.3213 - val_accuracy: 0.4163

Epoch 00662: val_loss did not improve from 1.32018
Epoch 663/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4030 - val_loss: 1.3216 - val_accuracy: 0.4115

Epoch 00663: val_loss did not improve from 1.32018
Epoch 664/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4024 - val_loss: 1.3231 - val_accuracy: 0.4139

Epoch 00664: val_loss did not improve from 1.32018
Epoch 665/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4044 - val_loss: 1.3233 - val_accuracy: 0.4195

Epoch 00665: val_loss did not improve from 1.32018
Epoch 666/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4017 - val_loss: 1.3231 - val_accuracy: 0.4155

Epoch 00666: val_loss did not improve from 1.32018
Epoch 667/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4014 - val_loss: 1.3217 - val_accuracy: 0.4234

Epoch 00667: val_loss did not improve from 1.32018
Epoch 668/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.3995 - val_loss: 1.3210 - val_accuracy: 0.4211

Epoch 00668: val_loss did not improve from 1.32018
Epoch 669/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4049 - val_loss: 1.3212 - val_accuracy: 0.4242

Epoch 00669: val_loss did not improve from 1.32018
Epoch 670/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3968 - val_loss: 1.3229 - val_accuracy: 0.4179

Epoch 00670: val_loss did not improve from 1.32018
Epoch 671/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4003 - val_loss: 1.3208 - val_accuracy: 0.4282

Epoch 00671: val_loss did not improve from 1.32018
Epoch 672/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4028 - val_loss: 1.3215 - val_accuracy: 0.4242

Epoch 00672: val_loss did not improve from 1.32018
Epoch 673/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4026 - val_loss: 1.3213 - val_accuracy: 0.4314

Epoch 00673: val_loss did not improve from 1.32018
Epoch 674/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4014 - val_loss: 1.3206 - val_accuracy: 0.4155

Epoch 00674: val_loss did not improve from 1.32018
Epoch 675/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4016 - val_loss: 1.3235 - val_accuracy: 0.4115

Epoch 00675: val_loss did not improve from 1.32018
Epoch 676/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4013 - val_loss: 1.3241 - val_accuracy: 0.4075

Epoch 00676: val_loss did not improve from 1.32018
Epoch 677/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.4052 - val_loss: 1.3266 - val_accuracy: 0.4131

Epoch 00677: val_loss did not improve from 1.32018
Epoch 678/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4023 - val_loss: 1.3265 - val_accuracy: 0.4091

Epoch 00678: val_loss did not improve from 1.32018
Epoch 679/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3983 - val_loss: 1.3213 - val_accuracy: 0.4195

Epoch 00679: val_loss did not improve from 1.32018
Epoch 680/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3985 - val_loss: 1.3214 - val_accuracy: 0.4147

Epoch 00680: val_loss did not improve from 1.32018
Epoch 681/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4016 - val_loss: 1.3245 - val_accuracy: 0.4091

Epoch 00681: val_loss did not improve from 1.32018
Epoch 682/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.3986 - val_loss: 1.3219 - val_accuracy: 0.4139

Epoch 00682: val_loss did not improve from 1.32018
Epoch 683/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4001 - val_loss: 1.3212 - val_accuracy: 0.4147

Epoch 00683: val_loss did not improve from 1.32018
Epoch 684/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4019 - val_loss: 1.3276 - val_accuracy: 0.4234

Epoch 00684: val_loss did not improve from 1.32018
Epoch 685/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4007 - val_loss: 1.3214 - val_accuracy: 0.4195

Epoch 00685: val_loss did not improve from 1.32018
Epoch 686/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4012 - val_loss: 1.3209 - val_accuracy: 0.4250

Epoch 00686: val_loss did not improve from 1.32018
Epoch 687/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4013 - val_loss: 1.3229 - val_accuracy: 0.4258

Epoch 00687: val_loss did not improve from 1.32018
Epoch 688/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4006 - val_loss: 1.3201 - val_accuracy: 0.4163

Epoch 00688: val_loss improved from 1.32018 to 1.32011, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 689/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4015 - val_loss: 1.3220 - val_accuracy: 0.4211

Epoch 00689: val_loss did not improve from 1.32011
Epoch 690/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4001 - val_loss: 1.3214 - val_accuracy: 0.4187

Epoch 00690: val_loss did not improve from 1.32011
Epoch 691/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4029 - val_loss: 1.3205 - val_accuracy: 0.4187

Epoch 00691: val_loss did not improve from 1.32011
Epoch 692/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4039 - val_loss: 1.3237 - val_accuracy: 0.4131

Epoch 00692: val_loss did not improve from 1.32011
Epoch 693/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4025 - val_loss: 1.3197 - val_accuracy: 0.4155

Epoch 00693: val_loss improved from 1.32011 to 1.31970, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 694/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4029 - val_loss: 1.3219 - val_accuracy: 0.4226

Epoch 00694: val_loss did not improve from 1.31970
Epoch 695/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4067 - val_loss: 1.3201 - val_accuracy: 0.4226

Epoch 00695: val_loss did not improve from 1.31970
Epoch 696/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4013 - val_loss: 1.3204 - val_accuracy: 0.4171

Epoch 00696: val_loss did not improve from 1.31970
Epoch 697/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4001 - val_loss: 1.3216 - val_accuracy: 0.4179

Epoch 00697: val_loss did not improve from 1.31970
Epoch 698/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.3997 - val_loss: 1.3223 - val_accuracy: 0.4171

Epoch 00698: val_loss did not improve from 1.31970
Epoch 699/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4028 - val_loss: 1.3225 - val_accuracy: 0.4179

Epoch 00699: val_loss did not improve from 1.31970
Epoch 700/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4027 - val_loss: 1.3209 - val_accuracy: 0.4203

Epoch 00700: val_loss did not improve from 1.31970
Epoch 701/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.3995 - val_loss: 1.3214 - val_accuracy: 0.4234

Epoch 00701: val_loss did not improve from 1.31970
Epoch 702/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4044 - val_loss: 1.3221 - val_accuracy: 0.4338

Epoch 00702: val_loss did not improve from 1.31970
Epoch 703/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4044 - val_loss: 1.3203 - val_accuracy: 0.4250

Epoch 00703: val_loss did not improve from 1.31970
Epoch 704/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.3994 - val_loss: 1.3210 - val_accuracy: 0.4195

Epoch 00704: val_loss did not improve from 1.31970
Epoch 705/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4012 - val_loss: 1.3236 - val_accuracy: 0.4226

Epoch 00705: val_loss did not improve from 1.31970
Epoch 706/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4031 - val_loss: 1.3205 - val_accuracy: 0.4179

Epoch 00706: val_loss did not improve from 1.31970
Epoch 707/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4058 - val_loss: 1.3205 - val_accuracy: 0.4131

Epoch 00707: val_loss did not improve from 1.31970
Epoch 708/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4079 - val_loss: 1.3220 - val_accuracy: 0.4242

Epoch 00708: val_loss did not improve from 1.31970
Epoch 709/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4064 - val_loss: 1.3229 - val_accuracy: 0.4298

Epoch 00709: val_loss did not improve from 1.31970
Epoch 710/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4002 - val_loss: 1.3207 - val_accuracy: 0.4250

Epoch 00710: val_loss did not improve from 1.31970
Epoch 711/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3993 - val_loss: 1.3216 - val_accuracy: 0.4131

Epoch 00711: val_loss did not improve from 1.31970
Epoch 712/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4033 - val_loss: 1.3245 - val_accuracy: 0.4203

Epoch 00712: val_loss did not improve from 1.31970
Epoch 713/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4016 - val_loss: 1.3201 - val_accuracy: 0.4179

Epoch 00713: val_loss did not improve from 1.31970
Epoch 714/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4049 - val_loss: 1.3224 - val_accuracy: 0.4234

Epoch 00714: val_loss did not improve from 1.31970
Epoch 715/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4078 - val_loss: 1.3220 - val_accuracy: 0.4234

Epoch 00715: val_loss did not improve from 1.31970
Epoch 716/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4018 - val_loss: 1.3214 - val_accuracy: 0.4242

Epoch 00716: val_loss did not improve from 1.31970
Epoch 717/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4024 - val_loss: 1.3223 - val_accuracy: 0.4258

Epoch 00717: val_loss did not improve from 1.31970
Epoch 718/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.3993 - val_loss: 1.3203 - val_accuracy: 0.4171

Epoch 00718: val_loss did not improve from 1.31970
Epoch 719/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4018 - val_loss: 1.3236 - val_accuracy: 0.4195

Epoch 00719: val_loss did not improve from 1.31970
Epoch 720/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.3985 - val_loss: 1.3204 - val_accuracy: 0.4250

Epoch 00720: val_loss did not improve from 1.31970
Epoch 721/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.3992 - val_loss: 1.3219 - val_accuracy: 0.4195

Epoch 00721: val_loss did not improve from 1.31970
Epoch 722/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4013 - val_loss: 1.3195 - val_accuracy: 0.4155

Epoch 00722: val_loss improved from 1.31970 to 1.31947, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 723/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4052 - val_loss: 1.3229 - val_accuracy: 0.4211

Epoch 00723: val_loss did not improve from 1.31947
Epoch 724/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4049 - val_loss: 1.3223 - val_accuracy: 0.4179

Epoch 00724: val_loss did not improve from 1.31947
Epoch 725/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4007 - val_loss: 1.3206 - val_accuracy: 0.4226

Epoch 00725: val_loss did not improve from 1.31947
Epoch 726/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4035 - val_loss: 1.3272 - val_accuracy: 0.4258

Epoch 00726: val_loss did not improve from 1.31947
Epoch 727/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4034 - val_loss: 1.3221 - val_accuracy: 0.4163

Epoch 00727: val_loss did not improve from 1.31947
Epoch 728/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4001 - val_loss: 1.3220 - val_accuracy: 0.4171

Epoch 00728: val_loss did not improve from 1.31947
Epoch 729/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4040 - val_loss: 1.3268 - val_accuracy: 0.4203

Epoch 00729: val_loss did not improve from 1.31947
Epoch 730/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4028 - val_loss: 1.3200 - val_accuracy: 0.4187

Epoch 00730: val_loss did not improve from 1.31947
Epoch 731/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4008 - val_loss: 1.3193 - val_accuracy: 0.4187

Epoch 00731: val_loss improved from 1.31947 to 1.31934, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 732/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4035 - val_loss: 1.3239 - val_accuracy: 0.4242

Epoch 00732: val_loss did not improve from 1.31934
Epoch 733/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4025 - val_loss: 1.3210 - val_accuracy: 0.4155

Epoch 00733: val_loss did not improve from 1.31934
Epoch 734/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4022 - val_loss: 1.3228 - val_accuracy: 0.4147

Epoch 00734: val_loss did not improve from 1.31934
Epoch 735/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4012 - val_loss: 1.3198 - val_accuracy: 0.4203

Epoch 00735: val_loss did not improve from 1.31934
Epoch 736/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4027 - val_loss: 1.3192 - val_accuracy: 0.4163

Epoch 00736: val_loss improved from 1.31934 to 1.31916, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 737/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4060 - val_loss: 1.3220 - val_accuracy: 0.4234

Epoch 00737: val_loss did not improve from 1.31916
Epoch 738/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4065 - val_loss: 1.3245 - val_accuracy: 0.4258

Epoch 00738: val_loss did not improve from 1.31916
Epoch 739/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4023 - val_loss: 1.3212 - val_accuracy: 0.4139

Epoch 00739: val_loss did not improve from 1.31916
Epoch 740/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.3995 - val_loss: 1.3241 - val_accuracy: 0.4155

Epoch 00740: val_loss did not improve from 1.31916
Epoch 741/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4031 - val_loss: 1.3197 - val_accuracy: 0.4282

Epoch 00741: val_loss did not improve from 1.31916
Epoch 742/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.3998 - val_loss: 1.3201 - val_accuracy: 0.4250

Epoch 00742: val_loss did not improve from 1.31916
Epoch 743/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4017 - val_loss: 1.3194 - val_accuracy: 0.4203

Epoch 00743: val_loss did not improve from 1.31916
Epoch 744/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4015 - val_loss: 1.3211 - val_accuracy: 0.4155

Epoch 00744: val_loss did not improve from 1.31916
Epoch 745/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.4008 - val_loss: 1.3255 - val_accuracy: 0.4298

Epoch 00745: val_loss did not improve from 1.31916
Epoch 746/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4060 - val_loss: 1.3192 - val_accuracy: 0.4282

Epoch 00746: val_loss improved from 1.31916 to 1.31916, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 747/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4055 - val_loss: 1.3200 - val_accuracy: 0.4099

Epoch 00747: val_loss did not improve from 1.31916
Epoch 748/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4024 - val_loss: 1.3243 - val_accuracy: 0.4107

Epoch 00748: val_loss did not improve from 1.31916
Epoch 749/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4014 - val_loss: 1.3203 - val_accuracy: 0.4250

Epoch 00749: val_loss did not improve from 1.31916
Epoch 750/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4001 - val_loss: 1.3205 - val_accuracy: 0.4187

Epoch 00750: val_loss did not improve from 1.31916
Epoch 751/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4013 - val_loss: 1.3201 - val_accuracy: 0.4211

Epoch 00751: val_loss did not improve from 1.31916
Epoch 752/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4048 - val_loss: 1.3216 - val_accuracy: 0.4234

Epoch 00752: val_loss did not improve from 1.31916
Epoch 753/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3979 - val_loss: 1.3207 - val_accuracy: 0.4179

Epoch 00753: val_loss did not improve from 1.31916
Epoch 754/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4016 - val_loss: 1.3204 - val_accuracy: 0.4195

Epoch 00754: val_loss did not improve from 1.31916
Epoch 755/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4008 - val_loss: 1.3205 - val_accuracy: 0.4187

Epoch 00755: val_loss did not improve from 1.31916
Epoch 756/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.3995 - val_loss: 1.3194 - val_accuracy: 0.4171

Epoch 00756: val_loss did not improve from 1.31916
Epoch 757/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4044 - val_loss: 1.3211 - val_accuracy: 0.4242

Epoch 00757: val_loss did not improve from 1.31916
Epoch 758/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3996 - val_loss: 1.3220 - val_accuracy: 0.4187

Epoch 00758: val_loss did not improve from 1.31916
Epoch 759/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4001 - val_loss: 1.3204 - val_accuracy: 0.4195

Epoch 00759: val_loss did not improve from 1.31916
Epoch 760/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4041 - val_loss: 1.3215 - val_accuracy: 0.4226

Epoch 00760: val_loss did not improve from 1.31916
Epoch 761/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4009 - val_loss: 1.3199 - val_accuracy: 0.4131

Epoch 00761: val_loss did not improve from 1.31916
Epoch 762/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4020 - val_loss: 1.3245 - val_accuracy: 0.4123

Epoch 00762: val_loss did not improve from 1.31916
Epoch 763/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3997 - val_loss: 1.3201 - val_accuracy: 0.4195

Epoch 00763: val_loss did not improve from 1.31916
Epoch 764/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4015 - val_loss: 1.3202 - val_accuracy: 0.4211

Epoch 00764: val_loss did not improve from 1.31916
Epoch 765/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.3984 - val_loss: 1.3227 - val_accuracy: 0.4115

Epoch 00765: val_loss did not improve from 1.31916
Epoch 766/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3997 - val_loss: 1.3218 - val_accuracy: 0.4187

Epoch 00766: val_loss did not improve from 1.31916
Epoch 767/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.3994 - val_loss: 1.3212 - val_accuracy: 0.4155

Epoch 00767: val_loss did not improve from 1.31916
Epoch 768/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4043 - val_loss: 1.3237 - val_accuracy: 0.4250

Epoch 00768: val_loss did not improve from 1.31916
Epoch 769/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4027 - val_loss: 1.3199 - val_accuracy: 0.4234

Epoch 00769: val_loss did not improve from 1.31916
Epoch 770/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4024 - val_loss: 1.3230 - val_accuracy: 0.4258

Epoch 00770: val_loss did not improve from 1.31916
Epoch 771/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4065 - val_loss: 1.3195 - val_accuracy: 0.4115

Epoch 00771: val_loss did not improve from 1.31916
Epoch 772/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4007 - val_loss: 1.3208 - val_accuracy: 0.4115

Epoch 00772: val_loss did not improve from 1.31916
Epoch 773/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4003 - val_loss: 1.3192 - val_accuracy: 0.4195

Epoch 00773: val_loss did not improve from 1.31916
Epoch 774/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4047 - val_loss: 1.3196 - val_accuracy: 0.4258

Epoch 00774: val_loss did not improve from 1.31916
Epoch 775/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4021 - val_loss: 1.3215 - val_accuracy: 0.4147

Epoch 00775: val_loss did not improve from 1.31916
Epoch 776/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4010 - val_loss: 1.3216 - val_accuracy: 0.4187

Epoch 00776: val_loss did not improve from 1.31916
Epoch 777/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.3988 - val_loss: 1.3204 - val_accuracy: 0.4171

Epoch 00777: val_loss did not improve from 1.31916
Epoch 778/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4025 - val_loss: 1.3229 - val_accuracy: 0.4250

Epoch 00778: val_loss did not improve from 1.31916
Epoch 779/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4030 - val_loss: 1.3232 - val_accuracy: 0.4155

Epoch 00779: val_loss did not improve from 1.31916
Epoch 780/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4027 - val_loss: 1.3261 - val_accuracy: 0.4091

Epoch 00780: val_loss did not improve from 1.31916
Epoch 781/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4040 - val_loss: 1.3221 - val_accuracy: 0.4274

Epoch 00781: val_loss did not improve from 1.31916
Epoch 782/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4009 - val_loss: 1.3212 - val_accuracy: 0.4250

Epoch 00782: val_loss did not improve from 1.31916
Epoch 783/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.3989 - val_loss: 1.3215 - val_accuracy: 0.4250

Epoch 00783: val_loss did not improve from 1.31916
Epoch 784/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4044 - val_loss: 1.3223 - val_accuracy: 0.4226

Epoch 00784: val_loss did not improve from 1.31916
Epoch 785/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4054 - val_loss: 1.3205 - val_accuracy: 0.4203

Epoch 00785: val_loss did not improve from 1.31916
Epoch 786/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4047 - val_loss: 1.3196 - val_accuracy: 0.4306

Epoch 00786: val_loss did not improve from 1.31916
Epoch 787/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4047 - val_loss: 1.3226 - val_accuracy: 0.4250

Epoch 00787: val_loss did not improve from 1.31916
Epoch 788/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4006 - val_loss: 1.3197 - val_accuracy: 0.4139

Epoch 00788: val_loss did not improve from 1.31916
Epoch 789/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4019 - val_loss: 1.3212 - val_accuracy: 0.4147

Epoch 00789: val_loss did not improve from 1.31916
Epoch 790/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.4008 - val_loss: 1.3200 - val_accuracy: 0.4163

Epoch 00790: val_loss did not improve from 1.31916
Epoch 791/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4040 - val_loss: 1.3232 - val_accuracy: 0.4179

Epoch 00791: val_loss did not improve from 1.31916
Epoch 792/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.3996 - val_loss: 1.3206 - val_accuracy: 0.4211

Epoch 00792: val_loss did not improve from 1.31916
Epoch 793/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.3991 - val_loss: 1.3223 - val_accuracy: 0.4155

Epoch 00793: val_loss did not improve from 1.31916
Epoch 794/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4029 - val_loss: 1.3269 - val_accuracy: 0.4115

Epoch 00794: val_loss did not improve from 1.31916
Epoch 795/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.3991 - val_loss: 1.3203 - val_accuracy: 0.4179

Epoch 00795: val_loss did not improve from 1.31916
Epoch 796/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4002 - val_loss: 1.3214 - val_accuracy: 0.4219

Epoch 00796: val_loss did not improve from 1.31916
Epoch 797/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4016 - val_loss: 1.3196 - val_accuracy: 0.4242

Epoch 00797: val_loss did not improve from 1.31916
Epoch 798/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4004 - val_loss: 1.3193 - val_accuracy: 0.4163

Epoch 00798: val_loss did not improve from 1.31916
Epoch 799/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4033 - val_loss: 1.3246 - val_accuracy: 0.4266

Epoch 00799: val_loss did not improve from 1.31916
Epoch 800/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4009 - val_loss: 1.3201 - val_accuracy: 0.4179

Epoch 00800: val_loss did not improve from 1.31916
Epoch 801/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.3997 - val_loss: 1.3213 - val_accuracy: 0.4290

Epoch 00801: val_loss did not improve from 1.31916
Epoch 802/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4021 - val_loss: 1.3204 - val_accuracy: 0.4187

Epoch 00802: val_loss did not improve from 1.31916
Epoch 803/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4047 - val_loss: 1.3216 - val_accuracy: 0.4115

Epoch 00803: val_loss did not improve from 1.31916
Epoch 804/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4046 - val_loss: 1.3216 - val_accuracy: 0.4179

Epoch 00804: val_loss did not improve from 1.31916
Epoch 805/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4039 - val_loss: 1.3211 - val_accuracy: 0.4211

Epoch 00805: val_loss did not improve from 1.31916
Epoch 806/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4008 - val_loss: 1.3216 - val_accuracy: 0.4226

Epoch 00806: val_loss did not improve from 1.31916
Epoch 807/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4019 - val_loss: 1.3211 - val_accuracy: 0.4226

Epoch 00807: val_loss did not improve from 1.31916
Epoch 808/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4055 - val_loss: 1.3235 - val_accuracy: 0.4155

Epoch 00808: val_loss did not improve from 1.31916
Epoch 809/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4053 - val_loss: 1.3206 - val_accuracy: 0.4131

Epoch 00809: val_loss did not improve from 1.31916
Epoch 810/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4041 - val_loss: 1.3235 - val_accuracy: 0.4195

Epoch 00810: val_loss did not improve from 1.31916
Epoch 811/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4009 - val_loss: 1.3211 - val_accuracy: 0.4242

Epoch 00811: val_loss did not improve from 1.31916
Epoch 812/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3993 - val_loss: 1.3217 - val_accuracy: 0.4234

Epoch 00812: val_loss did not improve from 1.31916
Epoch 813/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4017 - val_loss: 1.3225 - val_accuracy: 0.4131

Epoch 00813: val_loss did not improve from 1.31916
Epoch 814/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4060 - val_loss: 1.3223 - val_accuracy: 0.4282

Epoch 00814: val_loss did not improve from 1.31916
Epoch 815/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4033 - val_loss: 1.3203 - val_accuracy: 0.4163

Epoch 00815: val_loss did not improve from 1.31916
Epoch 816/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4042 - val_loss: 1.3209 - val_accuracy: 0.4139

Epoch 00816: val_loss did not improve from 1.31916
Epoch 817/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4021 - val_loss: 1.3226 - val_accuracy: 0.4211

Epoch 00817: val_loss did not improve from 1.31916
Epoch 818/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4051 - val_loss: 1.3207 - val_accuracy: 0.4242

Epoch 00818: val_loss did not improve from 1.31916
Epoch 819/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4040 - val_loss: 1.3198 - val_accuracy: 0.4139

Epoch 00819: val_loss did not improve from 1.31916
Epoch 820/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4022 - val_loss: 1.3199 - val_accuracy: 0.4155

Epoch 00820: val_loss did not improve from 1.31916
Epoch 821/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4074 - val_loss: 1.3302 - val_accuracy: 0.4234

Epoch 00821: val_loss did not improve from 1.31916
Epoch 822/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4011 - val_loss: 1.3215 - val_accuracy: 0.4147

Epoch 00822: val_loss did not improve from 1.31916
Epoch 823/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4011 - val_loss: 1.3223 - val_accuracy: 0.4250

Epoch 00823: val_loss did not improve from 1.31916
Epoch 824/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4064 - val_loss: 1.3215 - val_accuracy: 0.4274

Epoch 00824: val_loss did not improve from 1.31916
Epoch 825/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.3997 - val_loss: 1.3201 - val_accuracy: 0.4195

Epoch 00825: val_loss did not improve from 1.31916
Epoch 826/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4050 - val_loss: 1.3249 - val_accuracy: 0.4282

Epoch 00826: val_loss did not improve from 1.31916
Epoch 827/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4027 - val_loss: 1.3208 - val_accuracy: 0.4131

Epoch 00827: val_loss did not improve from 1.31916
Epoch 828/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4021 - val_loss: 1.3248 - val_accuracy: 0.4051

Epoch 00828: val_loss did not improve from 1.31916
Epoch 829/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4019 - val_loss: 1.3209 - val_accuracy: 0.4171

Epoch 00829: val_loss did not improve from 1.31916
Epoch 830/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4012 - val_loss: 1.3199 - val_accuracy: 0.4179

Epoch 00830: val_loss did not improve from 1.31916
Epoch 831/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4003 - val_loss: 1.3214 - val_accuracy: 0.4195

Epoch 00831: val_loss did not improve from 1.31916
Epoch 832/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4011 - val_loss: 1.3209 - val_accuracy: 0.4163

Epoch 00832: val_loss did not improve from 1.31916
Epoch 833/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4038 - val_loss: 1.3236 - val_accuracy: 0.4258

Epoch 00833: val_loss did not improve from 1.31916
Epoch 834/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4049 - val_loss: 1.3211 - val_accuracy: 0.4171

Epoch 00834: val_loss did not improve from 1.31916
Epoch 835/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4043 - val_loss: 1.3201 - val_accuracy: 0.4171

Epoch 00835: val_loss did not improve from 1.31916
Epoch 836/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4035 - val_loss: 1.3195 - val_accuracy: 0.4226

Epoch 00836: val_loss did not improve from 1.31916
Epoch 837/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4060 - val_loss: 1.3192 - val_accuracy: 0.4219

Epoch 00837: val_loss did not improve from 1.31916
Epoch 838/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4043 - val_loss: 1.3210 - val_accuracy: 0.4258

Epoch 00838: val_loss did not improve from 1.31916
Epoch 839/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4050 - val_loss: 1.3210 - val_accuracy: 0.4187

Epoch 00839: val_loss did not improve from 1.31916
Epoch 840/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4025 - val_loss: 1.3280 - val_accuracy: 0.4195

Epoch 00840: val_loss did not improve from 1.31916
Epoch 841/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4024 - val_loss: 1.3222 - val_accuracy: 0.4147

Epoch 00841: val_loss did not improve from 1.31916
Epoch 842/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4044 - val_loss: 1.3285 - val_accuracy: 0.4211

Epoch 00842: val_loss did not improve from 1.31916
Epoch 843/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4015 - val_loss: 1.3214 - val_accuracy: 0.4155

Epoch 00843: val_loss did not improve from 1.31916
Epoch 844/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.3989 - val_loss: 1.3210 - val_accuracy: 0.4171

Epoch 00844: val_loss did not improve from 1.31916
Epoch 845/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4047 - val_loss: 1.3219 - val_accuracy: 0.4195

Epoch 00845: val_loss did not improve from 1.31916
Epoch 846/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4002 - val_loss: 1.3214 - val_accuracy: 0.4131

Epoch 00846: val_loss did not improve from 1.31916
Epoch 847/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4026 - val_loss: 1.3236 - val_accuracy: 0.4171

Epoch 00847: val_loss did not improve from 1.31916
Epoch 848/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4025 - val_loss: 1.3204 - val_accuracy: 0.4211

Epoch 00848: val_loss did not improve from 1.31916
Epoch 849/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4039 - val_loss: 1.3219 - val_accuracy: 0.4171

Epoch 00849: val_loss did not improve from 1.31916
Epoch 850/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4040 - val_loss: 1.3197 - val_accuracy: 0.4187

Epoch 00850: val_loss did not improve from 1.31916
Epoch 851/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4030 - val_loss: 1.3242 - val_accuracy: 0.4163

Epoch 00851: val_loss did not improve from 1.31916
Epoch 852/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4026 - val_loss: 1.3188 - val_accuracy: 0.4266

Epoch 00852: val_loss improved from 1.31916 to 1.31878, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 853/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4020 - val_loss: 1.3195 - val_accuracy: 0.4242

Epoch 00853: val_loss did not improve from 1.31878
Epoch 854/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4032 - val_loss: 1.3225 - val_accuracy: 0.4226

Epoch 00854: val_loss did not improve from 1.31878
Epoch 855/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4026 - val_loss: 1.3203 - val_accuracy: 0.4250

Epoch 00855: val_loss did not improve from 1.31878
Epoch 856/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4081 - val_loss: 1.3227 - val_accuracy: 0.4274

Epoch 00856: val_loss did not improve from 1.31878
Epoch 857/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.3983 - val_loss: 1.3206 - val_accuracy: 0.4219

Epoch 00857: val_loss did not improve from 1.31878
Epoch 858/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.3996 - val_loss: 1.3225 - val_accuracy: 0.4139

Epoch 00858: val_loss did not improve from 1.31878
Epoch 859/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.3994 - val_loss: 1.3224 - val_accuracy: 0.4131

Epoch 00859: val_loss did not improve from 1.31878
Epoch 860/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4027 - val_loss: 1.3221 - val_accuracy: 0.4203

Epoch 00860: val_loss did not improve from 1.31878
Epoch 861/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4041 - val_loss: 1.3210 - val_accuracy: 0.4203

Epoch 00861: val_loss did not improve from 1.31878
Epoch 862/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4045 - val_loss: 1.3197 - val_accuracy: 0.4226

Epoch 00862: val_loss did not improve from 1.31878
Epoch 863/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4034 - val_loss: 1.3208 - val_accuracy: 0.4258

Epoch 00863: val_loss did not improve from 1.31878
Epoch 864/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4031 - val_loss: 1.3215 - val_accuracy: 0.4250

Epoch 00864: val_loss did not improve from 1.31878
Epoch 865/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4016 - val_loss: 1.3210 - val_accuracy: 0.4179

Epoch 00865: val_loss did not improve from 1.31878
Epoch 866/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4028 - val_loss: 1.3234 - val_accuracy: 0.4219

Epoch 00866: val_loss did not improve from 1.31878
Epoch 867/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4053 - val_loss: 1.3214 - val_accuracy: 0.4226

Epoch 00867: val_loss did not improve from 1.31878
Epoch 868/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4047 - val_loss: 1.3257 - val_accuracy: 0.4219

Epoch 00868: val_loss did not improve from 1.31878
Epoch 869/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4024 - val_loss: 1.3197 - val_accuracy: 0.4203

Epoch 00869: val_loss did not improve from 1.31878
Epoch 870/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4052 - val_loss: 1.3206 - val_accuracy: 0.4179

Epoch 00870: val_loss did not improve from 1.31878
Epoch 871/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4009 - val_loss: 1.3198 - val_accuracy: 0.4171

Epoch 00871: val_loss did not improve from 1.31878
Epoch 872/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4024 - val_loss: 1.3223 - val_accuracy: 0.4187

Epoch 00872: val_loss did not improve from 1.31878
Epoch 873/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.4026 - val_loss: 1.3210 - val_accuracy: 0.4219

Epoch 00873: val_loss did not improve from 1.31878
Epoch 874/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4028 - val_loss: 1.3223 - val_accuracy: 0.4075

Epoch 00874: val_loss did not improve from 1.31878
Epoch 875/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4050 - val_loss: 1.3280 - val_accuracy: 0.4171

Epoch 00875: val_loss did not improve from 1.31878
Epoch 876/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4003 - val_loss: 1.3192 - val_accuracy: 0.4266

Epoch 00876: val_loss did not improve from 1.31878
Epoch 877/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4074 - val_loss: 1.3192 - val_accuracy: 0.4322

Epoch 00877: val_loss did not improve from 1.31878
Epoch 878/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4035 - val_loss: 1.3199 - val_accuracy: 0.4274

Epoch 00878: val_loss did not improve from 1.31878
Epoch 879/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4039 - val_loss: 1.3236 - val_accuracy: 0.4219

Epoch 00879: val_loss did not improve from 1.31878
Epoch 880/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4025 - val_loss: 1.3201 - val_accuracy: 0.4211

Epoch 00880: val_loss did not improve from 1.31878
Epoch 881/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4025 - val_loss: 1.3226 - val_accuracy: 0.4203

Epoch 00881: val_loss did not improve from 1.31878
Epoch 882/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4033 - val_loss: 1.3201 - val_accuracy: 0.4266

Epoch 00882: val_loss did not improve from 1.31878
Epoch 883/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4060 - val_loss: 1.3199 - val_accuracy: 0.4187

Epoch 00883: val_loss did not improve from 1.31878
Epoch 884/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4055 - val_loss: 1.3244 - val_accuracy: 0.4242

Epoch 00884: val_loss did not improve from 1.31878
Epoch 885/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4019 - val_loss: 1.3214 - val_accuracy: 0.4099

Epoch 00885: val_loss did not improve from 1.31878
Epoch 886/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4022 - val_loss: 1.3223 - val_accuracy: 0.4139

Epoch 00886: val_loss did not improve from 1.31878
Epoch 887/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4035 - val_loss: 1.3202 - val_accuracy: 0.4195

Epoch 00887: val_loss did not improve from 1.31878
Epoch 888/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.3995 - val_loss: 1.3188 - val_accuracy: 0.4147

Epoch 00888: val_loss did not improve from 1.31878
Epoch 889/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4063 - val_loss: 1.3256 - val_accuracy: 0.4179

Epoch 00889: val_loss did not improve from 1.31878
Epoch 890/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.3960 - val_loss: 1.3199 - val_accuracy: 0.4187

Epoch 00890: val_loss did not improve from 1.31878
Epoch 891/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4019 - val_loss: 1.3195 - val_accuracy: 0.4203

Epoch 00891: val_loss did not improve from 1.31878
Epoch 892/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4055 - val_loss: 1.3208 - val_accuracy: 0.4187

Epoch 00892: val_loss did not improve from 1.31878
Epoch 893/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4055 - val_loss: 1.3227 - val_accuracy: 0.4282

Epoch 00893: val_loss did not improve from 1.31878
Epoch 894/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4032 - val_loss: 1.3201 - val_accuracy: 0.4234

Epoch 00894: val_loss did not improve from 1.31878
Epoch 895/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4013 - val_loss: 1.3193 - val_accuracy: 0.4163

Epoch 00895: val_loss did not improve from 1.31878
Epoch 896/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4045 - val_loss: 1.3204 - val_accuracy: 0.4258

Epoch 00896: val_loss did not improve from 1.31878
Epoch 897/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4048 - val_loss: 1.3231 - val_accuracy: 0.4139

Epoch 00897: val_loss did not improve from 1.31878
Epoch 898/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4013 - val_loss: 1.3203 - val_accuracy: 0.4203

Epoch 00898: val_loss did not improve from 1.31878
Epoch 899/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4060 - val_loss: 1.3186 - val_accuracy: 0.4187

Epoch 00899: val_loss improved from 1.31878 to 1.31859, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 900/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4072 - val_loss: 1.3227 - val_accuracy: 0.4226

Epoch 00900: val_loss did not improve from 1.31859
Epoch 901/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4033 - val_loss: 1.3190 - val_accuracy: 0.4203

Epoch 00901: val_loss did not improve from 1.31859
Epoch 902/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4029 - val_loss: 1.3194 - val_accuracy: 0.4298

Epoch 00902: val_loss did not improve from 1.31859
Epoch 903/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4078 - val_loss: 1.3202 - val_accuracy: 0.4219

Epoch 00903: val_loss did not improve from 1.31859
Epoch 904/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4035 - val_loss: 1.3242 - val_accuracy: 0.4211

Epoch 00904: val_loss did not improve from 1.31859
Epoch 905/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4023 - val_loss: 1.3205 - val_accuracy: 0.4211

Epoch 00905: val_loss did not improve from 1.31859
Epoch 906/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4001 - val_loss: 1.3234 - val_accuracy: 0.4242

Epoch 00906: val_loss did not improve from 1.31859
Epoch 907/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4035 - val_loss: 1.3205 - val_accuracy: 0.4195

Epoch 00907: val_loss did not improve from 1.31859
Epoch 908/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.4050 - val_loss: 1.3209 - val_accuracy: 0.4219

Epoch 00908: val_loss did not improve from 1.31859
Epoch 909/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4026 - val_loss: 1.3237 - val_accuracy: 0.4203

Epoch 00909: val_loss did not improve from 1.31859
Epoch 910/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4009 - val_loss: 1.3197 - val_accuracy: 0.4234

Epoch 00910: val_loss did not improve from 1.31859
Epoch 911/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4016 - val_loss: 1.3196 - val_accuracy: 0.4219

Epoch 00911: val_loss did not improve from 1.31859
Epoch 912/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4032 - val_loss: 1.3195 - val_accuracy: 0.4163

Epoch 00912: val_loss did not improve from 1.31859
Epoch 913/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4041 - val_loss: 1.3278 - val_accuracy: 0.4282

Epoch 00913: val_loss did not improve from 1.31859
Epoch 914/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4056 - val_loss: 1.3209 - val_accuracy: 0.4083

Epoch 00914: val_loss did not improve from 1.31859
Epoch 915/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4065 - val_loss: 1.3219 - val_accuracy: 0.4179

Epoch 00915: val_loss did not improve from 1.31859
Epoch 916/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4055 - val_loss: 1.3203 - val_accuracy: 0.4187

Epoch 00916: val_loss did not improve from 1.31859
Epoch 917/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4047 - val_loss: 1.3221 - val_accuracy: 0.4242

Epoch 00917: val_loss did not improve from 1.31859
Epoch 918/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4055 - val_loss: 1.3196 - val_accuracy: 0.4203

Epoch 00918: val_loss did not improve from 1.31859
Epoch 919/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4031 - val_loss: 1.3246 - val_accuracy: 0.4171

Epoch 00919: val_loss did not improve from 1.31859
Epoch 920/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4027 - val_loss: 1.3190 - val_accuracy: 0.4195

Epoch 00920: val_loss did not improve from 1.31859
Epoch 921/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4063 - val_loss: 1.3210 - val_accuracy: 0.4250

Epoch 00921: val_loss did not improve from 1.31859
Epoch 922/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4033 - val_loss: 1.3205 - val_accuracy: 0.4219

Epoch 00922: val_loss did not improve from 1.31859
Epoch 923/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4061 - val_loss: 1.3195 - val_accuracy: 0.4211

Epoch 00923: val_loss did not improve from 1.31859
Epoch 924/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4012 - val_loss: 1.3200 - val_accuracy: 0.4242

Epoch 00924: val_loss did not improve from 1.31859
Epoch 925/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4046 - val_loss: 1.3242 - val_accuracy: 0.4242

Epoch 00925: val_loss did not improve from 1.31859
Epoch 926/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4024 - val_loss: 1.3206 - val_accuracy: 0.4250

Epoch 00926: val_loss did not improve from 1.31859
Epoch 927/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4004 - val_loss: 1.3192 - val_accuracy: 0.4219

Epoch 00927: val_loss did not improve from 1.31859
Epoch 928/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4015 - val_loss: 1.3202 - val_accuracy: 0.4258

Epoch 00928: val_loss did not improve from 1.31859
Epoch 929/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4030 - val_loss: 1.3195 - val_accuracy: 0.4242

Epoch 00929: val_loss did not improve from 1.31859
Epoch 930/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4046 - val_loss: 1.3272 - val_accuracy: 0.4266

Epoch 00930: val_loss did not improve from 1.31859
Epoch 931/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4028 - val_loss: 1.3211 - val_accuracy: 0.4139

Epoch 00931: val_loss did not improve from 1.31859
Epoch 932/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4058 - val_loss: 1.3220 - val_accuracy: 0.4234

Epoch 00932: val_loss did not improve from 1.31859
Epoch 933/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4024 - val_loss: 1.3227 - val_accuracy: 0.4234

Epoch 00933: val_loss did not improve from 1.31859
Epoch 934/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4003 - val_loss: 1.3197 - val_accuracy: 0.4035

Epoch 00934: val_loss did not improve from 1.31859
Epoch 935/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4042 - val_loss: 1.3201 - val_accuracy: 0.4187

Epoch 00935: val_loss did not improve from 1.31859
Epoch 936/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4061 - val_loss: 1.3241 - val_accuracy: 0.4187

Epoch 00936: val_loss did not improve from 1.31859
Epoch 937/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4019 - val_loss: 1.3194 - val_accuracy: 0.4226

Epoch 00937: val_loss did not improve from 1.31859
Epoch 938/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4049 - val_loss: 1.3185 - val_accuracy: 0.4155

Epoch 00938: val_loss improved from 1.31859 to 1.31854, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 939/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4045 - val_loss: 1.3233 - val_accuracy: 0.4226

Epoch 00939: val_loss did not improve from 1.31854
Epoch 940/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4048 - val_loss: 1.3216 - val_accuracy: 0.4131

Epoch 00940: val_loss did not improve from 1.31854
Epoch 941/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4037 - val_loss: 1.3231 - val_accuracy: 0.4163

Epoch 00941: val_loss did not improve from 1.31854
Epoch 942/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4035 - val_loss: 1.3210 - val_accuracy: 0.4203

Epoch 00942: val_loss did not improve from 1.31854
Epoch 943/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4024 - val_loss: 1.3195 - val_accuracy: 0.4131

Epoch 00943: val_loss did not improve from 1.31854
Epoch 944/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.3989 - val_loss: 1.3213 - val_accuracy: 0.4115

Epoch 00944: val_loss did not improve from 1.31854
Epoch 945/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4054 - val_loss: 1.3247 - val_accuracy: 0.4163

Epoch 00945: val_loss did not improve from 1.31854
Epoch 946/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4040 - val_loss: 1.3205 - val_accuracy: 0.4131

Epoch 00946: val_loss did not improve from 1.31854
Epoch 947/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4057 - val_loss: 1.3238 - val_accuracy: 0.4179

Epoch 00947: val_loss did not improve from 1.31854
Epoch 948/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3990 - val_loss: 1.3188 - val_accuracy: 0.4211

Epoch 00948: val_loss did not improve from 1.31854
Epoch 949/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4066 - val_loss: 1.3189 - val_accuracy: 0.4282

Epoch 00949: val_loss did not improve from 1.31854
Epoch 950/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4043 - val_loss: 1.3183 - val_accuracy: 0.4226

Epoch 00950: val_loss improved from 1.31854 to 1.31827, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 951/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4029 - val_loss: 1.3191 - val_accuracy: 0.4234

Epoch 00951: val_loss did not improve from 1.31827
Epoch 952/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4016 - val_loss: 1.3189 - val_accuracy: 0.4226

Epoch 00952: val_loss did not improve from 1.31827
Epoch 953/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4065 - val_loss: 1.3203 - val_accuracy: 0.4242

Epoch 00953: val_loss did not improve from 1.31827
Epoch 954/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.4008 - val_loss: 1.3186 - val_accuracy: 0.4195

Epoch 00954: val_loss did not improve from 1.31827
Epoch 955/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4029 - val_loss: 1.3216 - val_accuracy: 0.4234

Epoch 00955: val_loss did not improve from 1.31827
Epoch 956/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4002 - val_loss: 1.3211 - val_accuracy: 0.4163

Epoch 00956: val_loss did not improve from 1.31827
Epoch 957/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4040 - val_loss: 1.3242 - val_accuracy: 0.4226

Epoch 00957: val_loss did not improve from 1.31827
Epoch 958/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4008 - val_loss: 1.3204 - val_accuracy: 0.4234

Epoch 00958: val_loss did not improve from 1.31827
Epoch 959/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4026 - val_loss: 1.3190 - val_accuracy: 0.4187

Epoch 00959: val_loss did not improve from 1.31827
Epoch 960/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4023 - val_loss: 1.3189 - val_accuracy: 0.4211

Epoch 00960: val_loss did not improve from 1.31827
Epoch 961/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4044 - val_loss: 1.3216 - val_accuracy: 0.4211

Epoch 00961: val_loss did not improve from 1.31827
Epoch 962/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4069 - val_loss: 1.3208 - val_accuracy: 0.4131

Epoch 00962: val_loss did not improve from 1.31827
Epoch 963/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4030 - val_loss: 1.3183 - val_accuracy: 0.4107

Epoch 00963: val_loss did not improve from 1.31827
Epoch 964/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4032 - val_loss: 1.3252 - val_accuracy: 0.4266

Epoch 00964: val_loss did not improve from 1.31827
Epoch 965/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4045 - val_loss: 1.3196 - val_accuracy: 0.4226

Epoch 00965: val_loss did not improve from 1.31827
Epoch 966/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.3977 - val_loss: 1.3193 - val_accuracy: 0.4211

Epoch 00966: val_loss did not improve from 1.31827
Epoch 967/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.3993 - val_loss: 1.3214 - val_accuracy: 0.4131

Epoch 00967: val_loss did not improve from 1.31827
Epoch 968/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4009 - val_loss: 1.3210 - val_accuracy: 0.4211

Epoch 00968: val_loss did not improve from 1.31827
Epoch 969/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4058 - val_loss: 1.3208 - val_accuracy: 0.4147

Epoch 00969: val_loss did not improve from 1.31827
Epoch 970/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4034 - val_loss: 1.3209 - val_accuracy: 0.4139

Epoch 00970: val_loss did not improve from 1.31827
Epoch 971/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4038 - val_loss: 1.3192 - val_accuracy: 0.4219

Epoch 00971: val_loss did not improve from 1.31827
Epoch 972/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4057 - val_loss: 1.3205 - val_accuracy: 0.4234

Epoch 00972: val_loss did not improve from 1.31827
Epoch 973/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4040 - val_loss: 1.3197 - val_accuracy: 0.4203

Epoch 00973: val_loss did not improve from 1.31827
Epoch 974/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4021 - val_loss: 1.3211 - val_accuracy: 0.4139

Epoch 00974: val_loss did not improve from 1.31827
Epoch 975/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4028 - val_loss: 1.3200 - val_accuracy: 0.4147

Epoch 00975: val_loss did not improve from 1.31827
Epoch 976/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4036 - val_loss: 1.3179 - val_accuracy: 0.4139

Epoch 00976: val_loss improved from 1.31827 to 1.31792, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 977/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4034 - val_loss: 1.3201 - val_accuracy: 0.4195

Epoch 00977: val_loss did not improve from 1.31792
Epoch 978/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4053 - val_loss: 1.3213 - val_accuracy: 0.4219

Epoch 00978: val_loss did not improve from 1.31792
Epoch 979/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4023 - val_loss: 1.3193 - val_accuracy: 0.4219

Epoch 00979: val_loss did not improve from 1.31792
Epoch 980/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4040 - val_loss: 1.3199 - val_accuracy: 0.4203

Epoch 00980: val_loss did not improve from 1.31792
Epoch 981/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4033 - val_loss: 1.3223 - val_accuracy: 0.4131

Epoch 00981: val_loss did not improve from 1.31792
Epoch 982/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4024 - val_loss: 1.3197 - val_accuracy: 0.4211

Epoch 00982: val_loss did not improve from 1.31792
Epoch 983/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4017 - val_loss: 1.3192 - val_accuracy: 0.4147

Epoch 00983: val_loss did not improve from 1.31792
Epoch 984/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4001 - val_loss: 1.3199 - val_accuracy: 0.4171

Epoch 00984: val_loss did not improve from 1.31792
Epoch 985/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4065 - val_loss: 1.3202 - val_accuracy: 0.4219

Epoch 00985: val_loss did not improve from 1.31792
Epoch 986/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4041 - val_loss: 1.3192 - val_accuracy: 0.4203

Epoch 00986: val_loss did not improve from 1.31792
Epoch 987/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4044 - val_loss: 1.3191 - val_accuracy: 0.4187

Epoch 00987: val_loss did not improve from 1.31792
Epoch 988/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4049 - val_loss: 1.3179 - val_accuracy: 0.4298

Epoch 00988: val_loss did not improve from 1.31792
Epoch 989/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4012 - val_loss: 1.3187 - val_accuracy: 0.4290

Epoch 00989: val_loss did not improve from 1.31792
Epoch 990/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4055 - val_loss: 1.3226 - val_accuracy: 0.4290

Epoch 00990: val_loss did not improve from 1.31792
Epoch 991/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4025 - val_loss: 1.3189 - val_accuracy: 0.4171

Epoch 00991: val_loss did not improve from 1.31792
Epoch 992/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4019 - val_loss: 1.3191 - val_accuracy: 0.4155

Epoch 00992: val_loss did not improve from 1.31792
Epoch 993/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4079 - val_loss: 1.3192 - val_accuracy: 0.4234

Epoch 00993: val_loss did not improve from 1.31792
Epoch 994/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4055 - val_loss: 1.3193 - val_accuracy: 0.4131

Epoch 00994: val_loss did not improve from 1.31792
Epoch 995/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4037 - val_loss: 1.3183 - val_accuracy: 0.4195

Epoch 00995: val_loss did not improve from 1.31792
Epoch 996/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4016 - val_loss: 1.3194 - val_accuracy: 0.4195

Epoch 00996: val_loss did not improve from 1.31792
Epoch 997/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4024 - val_loss: 1.3190 - val_accuracy: 0.4187

Epoch 00997: val_loss did not improve from 1.31792
Epoch 998/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4016 - val_loss: 1.3171 - val_accuracy: 0.4139

Epoch 00998: val_loss improved from 1.31792 to 1.31709, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 999/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4038 - val_loss: 1.3227 - val_accuracy: 0.4234

Epoch 00999: val_loss did not improve from 1.31709
Epoch 1000/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4041 - val_loss: 1.3197 - val_accuracy: 0.4203

Epoch 01000: val_loss did not improve from 1.31709
Epoch 1001/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4005 - val_loss: 1.3188 - val_accuracy: 0.4179

Epoch 01001: val_loss did not improve from 1.31709
Epoch 1002/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4037 - val_loss: 1.3198 - val_accuracy: 0.4274

Epoch 01002: val_loss did not improve from 1.31709
Epoch 1003/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4059 - val_loss: 1.3218 - val_accuracy: 0.4250

Epoch 01003: val_loss did not improve from 1.31709
Epoch 1004/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4002 - val_loss: 1.3235 - val_accuracy: 0.4147

Epoch 01004: val_loss did not improve from 1.31709
Epoch 1005/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4064 - val_loss: 1.3218 - val_accuracy: 0.4203

Epoch 01005: val_loss did not improve from 1.31709
Epoch 1006/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4061 - val_loss: 1.3217 - val_accuracy: 0.4155

Epoch 01006: val_loss did not improve from 1.31709
Epoch 1007/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4019 - val_loss: 1.3195 - val_accuracy: 0.4187

Epoch 01007: val_loss did not improve from 1.31709
Epoch 1008/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4069 - val_loss: 1.3211 - val_accuracy: 0.4187

Epoch 01008: val_loss did not improve from 1.31709
Epoch 1009/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4053 - val_loss: 1.3187 - val_accuracy: 0.4211

Epoch 01009: val_loss did not improve from 1.31709
Epoch 1010/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4041 - val_loss: 1.3208 - val_accuracy: 0.4266

Epoch 01010: val_loss did not improve from 1.31709
Epoch 1011/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4039 - val_loss: 1.3179 - val_accuracy: 0.4226

Epoch 01011: val_loss did not improve from 1.31709
Epoch 1012/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4047 - val_loss: 1.3200 - val_accuracy: 0.4115

Epoch 01012: val_loss did not improve from 1.31709
Epoch 1013/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.3987 - val_loss: 1.3203 - val_accuracy: 0.4187

Epoch 01013: val_loss did not improve from 1.31709
Epoch 1014/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4050 - val_loss: 1.3187 - val_accuracy: 0.4250

Epoch 01014: val_loss did not improve from 1.31709
Epoch 1015/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4064 - val_loss: 1.3221 - val_accuracy: 0.4274

Epoch 01015: val_loss did not improve from 1.31709
Epoch 1016/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4036 - val_loss: 1.3201 - val_accuracy: 0.4115

Epoch 01016: val_loss did not improve from 1.31709
Epoch 1017/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4034 - val_loss: 1.3198 - val_accuracy: 0.4115

Epoch 01017: val_loss did not improve from 1.31709
Epoch 1018/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4048 - val_loss: 1.3268 - val_accuracy: 0.4219

Epoch 01018: val_loss did not improve from 1.31709
Epoch 1019/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.3966 - val_loss: 1.3183 - val_accuracy: 0.4163

Epoch 01019: val_loss did not improve from 1.31709
Epoch 1020/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4025 - val_loss: 1.3191 - val_accuracy: 0.4234

Epoch 01020: val_loss did not improve from 1.31709
Epoch 1021/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4024 - val_loss: 1.3178 - val_accuracy: 0.4203

Epoch 01021: val_loss did not improve from 1.31709
Epoch 1022/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4026 - val_loss: 1.3174 - val_accuracy: 0.4163

Epoch 01022: val_loss did not improve from 1.31709
Epoch 1023/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4078 - val_loss: 1.3224 - val_accuracy: 0.4242

Epoch 01023: val_loss did not improve from 1.31709
Epoch 1024/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4057 - val_loss: 1.3194 - val_accuracy: 0.4234

Epoch 01024: val_loss did not improve from 1.31709
Epoch 1025/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4005 - val_loss: 1.3189 - val_accuracy: 0.4203

Epoch 01025: val_loss did not improve from 1.31709
Epoch 1026/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4037 - val_loss: 1.3187 - val_accuracy: 0.4123

Epoch 01026: val_loss did not improve from 1.31709
Epoch 1027/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4082 - val_loss: 1.3231 - val_accuracy: 0.4234

Epoch 01027: val_loss did not improve from 1.31709
Epoch 1028/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4039 - val_loss: 1.3197 - val_accuracy: 0.4155

Epoch 01028: val_loss did not improve from 1.31709
Epoch 1029/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.3987 - val_loss: 1.3235 - val_accuracy: 0.4187

Epoch 01029: val_loss did not improve from 1.31709
Epoch 1030/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4042 - val_loss: 1.3182 - val_accuracy: 0.4242

Epoch 01030: val_loss did not improve from 1.31709
Epoch 1031/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4065 - val_loss: 1.3188 - val_accuracy: 0.4314

Epoch 01031: val_loss did not improve from 1.31709
Epoch 1032/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4043 - val_loss: 1.3187 - val_accuracy: 0.4282

Epoch 01032: val_loss did not improve from 1.31709
Epoch 1033/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4053 - val_loss: 1.3186 - val_accuracy: 0.4171

Epoch 01033: val_loss did not improve from 1.31709
Epoch 1034/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4051 - val_loss: 1.3264 - val_accuracy: 0.4211

Epoch 01034: val_loss did not improve from 1.31709
Epoch 1035/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.3993 - val_loss: 1.3186 - val_accuracy: 0.4171

Epoch 01035: val_loss did not improve from 1.31709
Epoch 1036/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.4035 - val_loss: 1.3193 - val_accuracy: 0.4258

Epoch 01036: val_loss did not improve from 1.31709
Epoch 1037/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4052 - val_loss: 1.3185 - val_accuracy: 0.4211

Epoch 01037: val_loss did not improve from 1.31709
Epoch 1038/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4012 - val_loss: 1.3203 - val_accuracy: 0.4219

Epoch 01038: val_loss did not improve from 1.31709
Epoch 1039/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4024 - val_loss: 1.3190 - val_accuracy: 0.4171

Epoch 01039: val_loss did not improve from 1.31709
Epoch 1040/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4061 - val_loss: 1.3194 - val_accuracy: 0.4147

Epoch 01040: val_loss did not improve from 1.31709
Epoch 1041/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4051 - val_loss: 1.3217 - val_accuracy: 0.4155

Epoch 01041: val_loss did not improve from 1.31709
Epoch 1042/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.3975 - val_loss: 1.3192 - val_accuracy: 0.4179

Epoch 01042: val_loss did not improve from 1.31709
Epoch 1043/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4050 - val_loss: 1.3207 - val_accuracy: 0.4258

Epoch 01043: val_loss did not improve from 1.31709
Epoch 1044/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4059 - val_loss: 1.3197 - val_accuracy: 0.4250

Epoch 01044: val_loss did not improve from 1.31709
Epoch 1045/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4035 - val_loss: 1.3169 - val_accuracy: 0.4195

Epoch 01045: val_loss improved from 1.31709 to 1.31687, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1046/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4035 - val_loss: 1.3174 - val_accuracy: 0.4242

Epoch 01046: val_loss did not improve from 1.31687
Epoch 1047/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4063 - val_loss: 1.3179 - val_accuracy: 0.4274

Epoch 01047: val_loss did not improve from 1.31687
Epoch 1048/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4056 - val_loss: 1.3183 - val_accuracy: 0.4226

Epoch 01048: val_loss did not improve from 1.31687
Epoch 1049/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4044 - val_loss: 1.3194 - val_accuracy: 0.4219

Epoch 01049: val_loss did not improve from 1.31687
Epoch 1050/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4035 - val_loss: 1.3194 - val_accuracy: 0.4219

Epoch 01050: val_loss did not improve from 1.31687
Epoch 1051/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4038 - val_loss: 1.3186 - val_accuracy: 0.4155

Epoch 01051: val_loss did not improve from 1.31687
Epoch 1052/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4072 - val_loss: 1.3200 - val_accuracy: 0.4306

Epoch 01052: val_loss did not improve from 1.31687
Epoch 1053/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4088 - val_loss: 1.3192 - val_accuracy: 0.4211

Epoch 01053: val_loss did not improve from 1.31687
Epoch 1054/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4022 - val_loss: 1.3189 - val_accuracy: 0.4179

Epoch 01054: val_loss did not improve from 1.31687
Epoch 1055/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4018 - val_loss: 1.3181 - val_accuracy: 0.4226

Epoch 01055: val_loss did not improve from 1.31687
Epoch 1056/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4034 - val_loss: 1.3180 - val_accuracy: 0.4250

Epoch 01056: val_loss did not improve from 1.31687
Epoch 1057/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4018 - val_loss: 1.3204 - val_accuracy: 0.4266

Epoch 01057: val_loss did not improve from 1.31687
Epoch 1058/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4021 - val_loss: 1.3197 - val_accuracy: 0.4179

Epoch 01058: val_loss did not improve from 1.31687
Epoch 1059/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4004 - val_loss: 1.3183 - val_accuracy: 0.4242

Epoch 01059: val_loss did not improve from 1.31687
Epoch 1060/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4032 - val_loss: 1.3185 - val_accuracy: 0.4163

Epoch 01060: val_loss did not improve from 1.31687
Epoch 1061/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4055 - val_loss: 1.3210 - val_accuracy: 0.4290

Epoch 01061: val_loss did not improve from 1.31687
Epoch 1062/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4036 - val_loss: 1.3188 - val_accuracy: 0.4330

Epoch 01062: val_loss did not improve from 1.31687
Epoch 1063/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4020 - val_loss: 1.3177 - val_accuracy: 0.4314

Epoch 01063: val_loss did not improve from 1.31687
Epoch 1064/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4021 - val_loss: 1.3185 - val_accuracy: 0.4298

Epoch 01064: val_loss did not improve from 1.31687
Epoch 1065/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4018 - val_loss: 1.3174 - val_accuracy: 0.4234

Epoch 01065: val_loss did not improve from 1.31687
Epoch 1066/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4050 - val_loss: 1.3179 - val_accuracy: 0.4266

Epoch 01066: val_loss did not improve from 1.31687
Epoch 1067/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4076 - val_loss: 1.3187 - val_accuracy: 0.4258

Epoch 01067: val_loss did not improve from 1.31687
Epoch 1068/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4032 - val_loss: 1.3200 - val_accuracy: 0.4171

Epoch 01068: val_loss did not improve from 1.31687
Epoch 1069/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4055 - val_loss: 1.3180 - val_accuracy: 0.4211

Epoch 01069: val_loss did not improve from 1.31687
Epoch 1070/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4066 - val_loss: 1.3182 - val_accuracy: 0.4147

Epoch 01070: val_loss did not improve from 1.31687
Epoch 1071/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4036 - val_loss: 1.3226 - val_accuracy: 0.4274

Epoch 01071: val_loss did not improve from 1.31687
Epoch 1072/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4043 - val_loss: 1.3191 - val_accuracy: 0.4306

Epoch 01072: val_loss did not improve from 1.31687
Epoch 1073/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.3958 - val_loss: 1.3204 - val_accuracy: 0.4242

Epoch 01073: val_loss did not improve from 1.31687
Epoch 1074/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4028 - val_loss: 1.3224 - val_accuracy: 0.4250

Epoch 01074: val_loss did not improve from 1.31687
Epoch 1075/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4067 - val_loss: 1.3216 - val_accuracy: 0.4211

Epoch 01075: val_loss did not improve from 1.31687
Epoch 1076/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4032 - val_loss: 1.3199 - val_accuracy: 0.4187

Epoch 01076: val_loss did not improve from 1.31687
Epoch 1077/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4053 - val_loss: 1.3220 - val_accuracy: 0.4290

Epoch 01077: val_loss did not improve from 1.31687
Epoch 1078/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4094 - val_loss: 1.3221 - val_accuracy: 0.4250

Epoch 01078: val_loss did not improve from 1.31687
Epoch 1079/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4062 - val_loss: 1.3191 - val_accuracy: 0.4163

Epoch 01079: val_loss did not improve from 1.31687
Epoch 1080/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4056 - val_loss: 1.3201 - val_accuracy: 0.4226

Epoch 01080: val_loss did not improve from 1.31687
Epoch 1081/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4049 - val_loss: 1.3193 - val_accuracy: 0.4147

Epoch 01081: val_loss did not improve from 1.31687
Epoch 1082/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4059 - val_loss: 1.3181 - val_accuracy: 0.4139

Epoch 01082: val_loss did not improve from 1.31687
Epoch 1083/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4092 - val_loss: 1.3234 - val_accuracy: 0.4258

Epoch 01083: val_loss did not improve from 1.31687
Epoch 1084/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4029 - val_loss: 1.3172 - val_accuracy: 0.4290

Epoch 01084: val_loss did not improve from 1.31687
Epoch 1085/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4022 - val_loss: 1.3176 - val_accuracy: 0.4266

Epoch 01085: val_loss did not improve from 1.31687
Epoch 1086/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4062 - val_loss: 1.3169 - val_accuracy: 0.4203

Epoch 01086: val_loss did not improve from 1.31687
Epoch 1087/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4044 - val_loss: 1.3180 - val_accuracy: 0.4234

Epoch 01087: val_loss did not improve from 1.31687
Epoch 1088/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4056 - val_loss: 1.3188 - val_accuracy: 0.4282

Epoch 01088: val_loss did not improve from 1.31687
Epoch 1089/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4063 - val_loss: 1.3186 - val_accuracy: 0.4290

Epoch 01089: val_loss did not improve from 1.31687
Epoch 1090/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4063 - val_loss: 1.3194 - val_accuracy: 0.4226

Epoch 01090: val_loss did not improve from 1.31687
Epoch 1091/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4086 - val_loss: 1.3169 - val_accuracy: 0.4266

Epoch 01091: val_loss improved from 1.31687 to 1.31686, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1092/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4077 - val_loss: 1.3171 - val_accuracy: 0.4266

Epoch 01092: val_loss did not improve from 1.31686
Epoch 1093/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4047 - val_loss: 1.3200 - val_accuracy: 0.4179

Epoch 01093: val_loss did not improve from 1.31686
Epoch 1094/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4040 - val_loss: 1.3175 - val_accuracy: 0.4179

Epoch 01094: val_loss did not improve from 1.31686
Epoch 1095/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4061 - val_loss: 1.3197 - val_accuracy: 0.4147

Epoch 01095: val_loss did not improve from 1.31686
Epoch 1096/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4045 - val_loss: 1.3182 - val_accuracy: 0.4139

Epoch 01096: val_loss did not improve from 1.31686
Epoch 1097/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4068 - val_loss: 1.3188 - val_accuracy: 0.4250

Epoch 01097: val_loss did not improve from 1.31686
Epoch 1098/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4051 - val_loss: 1.3194 - val_accuracy: 0.4179

Epoch 01098: val_loss did not improve from 1.31686
Epoch 1099/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4022 - val_loss: 1.3222 - val_accuracy: 0.4123

Epoch 01099: val_loss did not improve from 1.31686
Epoch 1100/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4054 - val_loss: 1.3179 - val_accuracy: 0.4219

Epoch 01100: val_loss did not improve from 1.31686
Epoch 1101/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4085 - val_loss: 1.3180 - val_accuracy: 0.4266

Epoch 01101: val_loss did not improve from 1.31686
Epoch 1102/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4040 - val_loss: 1.3174 - val_accuracy: 0.4139

Epoch 01102: val_loss did not improve from 1.31686
Epoch 1103/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4049 - val_loss: 1.3189 - val_accuracy: 0.4226

Epoch 01103: val_loss did not improve from 1.31686
Epoch 1104/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4077 - val_loss: 1.3177 - val_accuracy: 0.4179

Epoch 01104: val_loss did not improve from 1.31686
Epoch 1105/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4064 - val_loss: 1.3181 - val_accuracy: 0.4187

Epoch 01105: val_loss did not improve from 1.31686
Epoch 1106/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4049 - val_loss: 1.3184 - val_accuracy: 0.4250

Epoch 01106: val_loss did not improve from 1.31686
Epoch 1107/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4063 - val_loss: 1.3168 - val_accuracy: 0.4226

Epoch 01107: val_loss improved from 1.31686 to 1.31685, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1108/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4069 - val_loss: 1.3181 - val_accuracy: 0.4322

Epoch 01108: val_loss did not improve from 1.31685
Epoch 1109/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4015 - val_loss: 1.3173 - val_accuracy: 0.4226

Epoch 01109: val_loss did not improve from 1.31685
Epoch 1110/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4024 - val_loss: 1.3163 - val_accuracy: 0.4147

Epoch 01110: val_loss improved from 1.31685 to 1.31633, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1111/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4047 - val_loss: 1.3185 - val_accuracy: 0.4219

Epoch 01111: val_loss did not improve from 1.31633
Epoch 1112/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4045 - val_loss: 1.3167 - val_accuracy: 0.4282

Epoch 01112: val_loss did not improve from 1.31633
Epoch 1113/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4062 - val_loss: 1.3171 - val_accuracy: 0.4171

Epoch 01113: val_loss did not improve from 1.31633
Epoch 1114/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4061 - val_loss: 1.3213 - val_accuracy: 0.4179

Epoch 01114: val_loss did not improve from 1.31633
Epoch 1115/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4064 - val_loss: 1.3165 - val_accuracy: 0.4107

Epoch 01115: val_loss did not improve from 1.31633
Epoch 1116/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4093 - val_loss: 1.3192 - val_accuracy: 0.4242

Epoch 01116: val_loss did not improve from 1.31633
Epoch 1117/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4009 - val_loss: 1.3158 - val_accuracy: 0.4203

Epoch 01117: val_loss improved from 1.31633 to 1.31578, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1118/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4052 - val_loss: 1.3171 - val_accuracy: 0.4314

Epoch 01118: val_loss did not improve from 1.31578
Epoch 1119/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4013 - val_loss: 1.3159 - val_accuracy: 0.4187

Epoch 01119: val_loss did not improve from 1.31578
Epoch 1120/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4052 - val_loss: 1.3194 - val_accuracy: 0.4266

Epoch 01120: val_loss did not improve from 1.31578
Epoch 1121/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4100 - val_loss: 1.3193 - val_accuracy: 0.4258

Epoch 01121: val_loss did not improve from 1.31578
Epoch 1122/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3941 - val_loss: 1.3200 - val_accuracy: 0.4234

Epoch 01122: val_loss did not improve from 1.31578
Epoch 1123/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4055 - val_loss: 1.3185 - val_accuracy: 0.4226

Epoch 01123: val_loss did not improve from 1.31578
Epoch 1124/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4070 - val_loss: 1.3241 - val_accuracy: 0.4226

Epoch 01124: val_loss did not improve from 1.31578
Epoch 1125/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4035 - val_loss: 1.3179 - val_accuracy: 0.4203

Epoch 01125: val_loss did not improve from 1.31578
Epoch 1126/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4031 - val_loss: 1.3179 - val_accuracy: 0.4211

Epoch 01126: val_loss did not improve from 1.31578
Epoch 1127/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4047 - val_loss: 1.3169 - val_accuracy: 0.4195

Epoch 01127: val_loss did not improve from 1.31578
Epoch 1128/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4070 - val_loss: 1.3158 - val_accuracy: 0.4266

Epoch 01128: val_loss did not improve from 1.31578
Epoch 1129/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4072 - val_loss: 1.3180 - val_accuracy: 0.4234

Epoch 01129: val_loss did not improve from 1.31578
Epoch 1130/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4054 - val_loss: 1.3181 - val_accuracy: 0.4226

Epoch 01130: val_loss did not improve from 1.31578
Epoch 1131/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4029 - val_loss: 1.3173 - val_accuracy: 0.4163

Epoch 01131: val_loss did not improve from 1.31578
Epoch 1132/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4041 - val_loss: 1.3202 - val_accuracy: 0.4258

Epoch 01132: val_loss did not improve from 1.31578
Epoch 1133/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4083 - val_loss: 1.3167 - val_accuracy: 0.4179

Epoch 01133: val_loss did not improve from 1.31578
Epoch 1134/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4062 - val_loss: 1.3190 - val_accuracy: 0.4234

Epoch 01134: val_loss did not improve from 1.31578
Epoch 1135/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4079 - val_loss: 1.3197 - val_accuracy: 0.4234

Epoch 01135: val_loss did not improve from 1.31578
Epoch 1136/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4044 - val_loss: 1.3182 - val_accuracy: 0.4131

Epoch 01136: val_loss did not improve from 1.31578
Epoch 1137/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4069 - val_loss: 1.3223 - val_accuracy: 0.4195

Epoch 01137: val_loss did not improve from 1.31578
Epoch 1138/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4067 - val_loss: 1.3191 - val_accuracy: 0.4226

Epoch 01138: val_loss did not improve from 1.31578
Epoch 1139/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4055 - val_loss: 1.3179 - val_accuracy: 0.4211

Epoch 01139: val_loss did not improve from 1.31578
Epoch 1140/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4078 - val_loss: 1.3158 - val_accuracy: 0.4242

Epoch 01140: val_loss did not improve from 1.31578
Epoch 1141/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4041 - val_loss: 1.3180 - val_accuracy: 0.4219

Epoch 01141: val_loss did not improve from 1.31578
Epoch 1142/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4040 - val_loss: 1.3174 - val_accuracy: 0.4179

Epoch 01142: val_loss did not improve from 1.31578
Epoch 1143/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4013 - val_loss: 1.3173 - val_accuracy: 0.4187

Epoch 01143: val_loss did not improve from 1.31578
Epoch 1144/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4038 - val_loss: 1.3169 - val_accuracy: 0.4226

Epoch 01144: val_loss did not improve from 1.31578
Epoch 1145/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4051 - val_loss: 1.3178 - val_accuracy: 0.4258

Epoch 01145: val_loss did not improve from 1.31578
Epoch 1146/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4105 - val_loss: 1.3199 - val_accuracy: 0.4226

Epoch 01146: val_loss did not improve from 1.31578
Epoch 1147/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4053 - val_loss: 1.3182 - val_accuracy: 0.4211

Epoch 01147: val_loss did not improve from 1.31578
Epoch 1148/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4070 - val_loss: 1.3171 - val_accuracy: 0.4274

Epoch 01148: val_loss did not improve from 1.31578
Epoch 1149/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4032 - val_loss: 1.3204 - val_accuracy: 0.4234

Epoch 01149: val_loss did not improve from 1.31578
Epoch 1150/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4072 - val_loss: 1.3175 - val_accuracy: 0.4250

Epoch 01150: val_loss did not improve from 1.31578
Epoch 1151/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4039 - val_loss: 1.3188 - val_accuracy: 0.4187

Epoch 01151: val_loss did not improve from 1.31578
Epoch 1152/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4026 - val_loss: 1.3177 - val_accuracy: 0.4234

Epoch 01152: val_loss did not improve from 1.31578
Epoch 1153/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4063 - val_loss: 1.3188 - val_accuracy: 0.4314

Epoch 01153: val_loss did not improve from 1.31578
Epoch 1154/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4032 - val_loss: 1.3190 - val_accuracy: 0.4203

Epoch 01154: val_loss did not improve from 1.31578
Epoch 1155/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4016 - val_loss: 1.3163 - val_accuracy: 0.4242

Epoch 01155: val_loss did not improve from 1.31578
Epoch 1156/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4104 - val_loss: 1.3165 - val_accuracy: 0.4250

Epoch 01156: val_loss did not improve from 1.31578
Epoch 1157/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4091 - val_loss: 1.3162 - val_accuracy: 0.4274

Epoch 01157: val_loss did not improve from 1.31578
Epoch 1158/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4086 - val_loss: 1.3173 - val_accuracy: 0.4234

Epoch 01158: val_loss did not improve from 1.31578
Epoch 1159/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4066 - val_loss: 1.3188 - val_accuracy: 0.4219

Epoch 01159: val_loss did not improve from 1.31578
Epoch 1160/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4049 - val_loss: 1.3224 - val_accuracy: 0.4298

Epoch 01160: val_loss did not improve from 1.31578
Epoch 1161/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4056 - val_loss: 1.3188 - val_accuracy: 0.4219

Epoch 01161: val_loss did not improve from 1.31578
Epoch 1162/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4029 - val_loss: 1.3182 - val_accuracy: 0.4226

Epoch 01162: val_loss did not improve from 1.31578
Epoch 1163/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4068 - val_loss: 1.3243 - val_accuracy: 0.4242

Epoch 01163: val_loss did not improve from 1.31578
Epoch 1164/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4040 - val_loss: 1.3189 - val_accuracy: 0.4163

Epoch 01164: val_loss did not improve from 1.31578
Epoch 1165/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4090 - val_loss: 1.3208 - val_accuracy: 0.4195

Epoch 01165: val_loss did not improve from 1.31578
Epoch 1166/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4014 - val_loss: 1.3188 - val_accuracy: 0.4171

Epoch 01166: val_loss did not improve from 1.31578
Epoch 1167/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4060 - val_loss: 1.3192 - val_accuracy: 0.4219

Epoch 01167: val_loss did not improve from 1.31578
Epoch 1168/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4055 - val_loss: 1.3183 - val_accuracy: 0.4203

Epoch 01168: val_loss did not improve from 1.31578
Epoch 1169/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4072 - val_loss: 1.3180 - val_accuracy: 0.4226

Epoch 01169: val_loss did not improve from 1.31578
Epoch 1170/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4048 - val_loss: 1.3183 - val_accuracy: 0.4219

Epoch 01170: val_loss did not improve from 1.31578
Epoch 1171/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4109 - val_loss: 1.3177 - val_accuracy: 0.4171

Epoch 01171: val_loss did not improve from 1.31578
Epoch 1172/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4041 - val_loss: 1.3171 - val_accuracy: 0.4155

Epoch 01172: val_loss did not improve from 1.31578
Epoch 1173/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4063 - val_loss: 1.3165 - val_accuracy: 0.4203

Epoch 01173: val_loss did not improve from 1.31578
Epoch 1174/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4036 - val_loss: 1.3162 - val_accuracy: 0.4226

Epoch 01174: val_loss did not improve from 1.31578
Epoch 1175/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4059 - val_loss: 1.3176 - val_accuracy: 0.4258

Epoch 01175: val_loss did not improve from 1.31578
Epoch 1176/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4070 - val_loss: 1.3175 - val_accuracy: 0.4258

Epoch 01176: val_loss did not improve from 1.31578
Epoch 1177/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4022 - val_loss: 1.3173 - val_accuracy: 0.4179

Epoch 01177: val_loss did not improve from 1.31578
Epoch 1178/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4048 - val_loss: 1.3200 - val_accuracy: 0.4171

Epoch 01178: val_loss did not improve from 1.31578
Epoch 1179/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4038 - val_loss: 1.3206 - val_accuracy: 0.4115

Epoch 01179: val_loss did not improve from 1.31578
Epoch 1180/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4049 - val_loss: 1.3211 - val_accuracy: 0.4242

Epoch 01180: val_loss did not improve from 1.31578
Epoch 1181/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4041 - val_loss: 1.3176 - val_accuracy: 0.4131

Epoch 01181: val_loss did not improve from 1.31578
Epoch 1182/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4075 - val_loss: 1.3196 - val_accuracy: 0.4219

Epoch 01182: val_loss did not improve from 1.31578
Epoch 1183/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4064 - val_loss: 1.3185 - val_accuracy: 0.4131

Epoch 01183: val_loss did not improve from 1.31578
Epoch 1184/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4102 - val_loss: 1.3211 - val_accuracy: 0.4250

Epoch 01184: val_loss did not improve from 1.31578
Epoch 1185/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4063 - val_loss: 1.3173 - val_accuracy: 0.4155

Epoch 01185: val_loss did not improve from 1.31578
Epoch 1186/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4055 - val_loss: 1.3245 - val_accuracy: 0.4211

Epoch 01186: val_loss did not improve from 1.31578
Epoch 1187/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4060 - val_loss: 1.3191 - val_accuracy: 0.4115

Epoch 01187: val_loss did not improve from 1.31578
Epoch 1188/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4033 - val_loss: 1.3262 - val_accuracy: 0.4155

Epoch 01188: val_loss did not improve from 1.31578
Epoch 1189/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4021 - val_loss: 1.3177 - val_accuracy: 0.4115

Epoch 01189: val_loss did not improve from 1.31578
Epoch 1190/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4067 - val_loss: 1.3172 - val_accuracy: 0.4250

Epoch 01190: val_loss did not improve from 1.31578
Epoch 1191/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4112 - val_loss: 1.3170 - val_accuracy: 0.4211

Epoch 01191: val_loss did not improve from 1.31578
Epoch 1192/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4051 - val_loss: 1.3180 - val_accuracy: 0.4226

Epoch 01192: val_loss did not improve from 1.31578
Epoch 1193/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4030 - val_loss: 1.3175 - val_accuracy: 0.4115

Epoch 01193: val_loss did not improve from 1.31578
Epoch 1194/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4057 - val_loss: 1.3164 - val_accuracy: 0.4219

Epoch 01194: val_loss did not improve from 1.31578
Epoch 1195/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4087 - val_loss: 1.3204 - val_accuracy: 0.4155

Epoch 01195: val_loss did not improve from 1.31578
Epoch 1196/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4057 - val_loss: 1.3167 - val_accuracy: 0.4131

Epoch 01196: val_loss did not improve from 1.31578
Epoch 1197/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4068 - val_loss: 1.3165 - val_accuracy: 0.4187

Epoch 01197: val_loss did not improve from 1.31578
Epoch 1198/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4055 - val_loss: 1.3187 - val_accuracy: 0.4187

Epoch 01198: val_loss did not improve from 1.31578
Epoch 1199/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4033 - val_loss: 1.3236 - val_accuracy: 0.4163

Epoch 01199: val_loss did not improve from 1.31578
Epoch 1200/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4051 - val_loss: 1.3304 - val_accuracy: 0.4226

Epoch 01200: val_loss did not improve from 1.31578
Epoch 1201/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4046 - val_loss: 1.3150 - val_accuracy: 0.4322

Epoch 01201: val_loss improved from 1.31578 to 1.31495, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1202/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4060 - val_loss: 1.3176 - val_accuracy: 0.4147

Epoch 01202: val_loss did not improve from 1.31495
Epoch 1203/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4082 - val_loss: 1.3186 - val_accuracy: 0.4211

Epoch 01203: val_loss did not improve from 1.31495
Epoch 1204/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4043 - val_loss: 1.3178 - val_accuracy: 0.4107

Epoch 01204: val_loss did not improve from 1.31495
Epoch 1205/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4067 - val_loss: 1.3193 - val_accuracy: 0.4258

Epoch 01205: val_loss did not improve from 1.31495
Epoch 1206/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4048 - val_loss: 1.3170 - val_accuracy: 0.4123

Epoch 01206: val_loss did not improve from 1.31495
Epoch 1207/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4021 - val_loss: 1.3172 - val_accuracy: 0.4195

Epoch 01207: val_loss did not improve from 1.31495
Epoch 1208/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4068 - val_loss: 1.3156 - val_accuracy: 0.4195

Epoch 01208: val_loss did not improve from 1.31495
Epoch 1209/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4090 - val_loss: 1.3160 - val_accuracy: 0.4131

Epoch 01209: val_loss did not improve from 1.31495
Epoch 1210/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4016 - val_loss: 1.3166 - val_accuracy: 0.4131

Epoch 01210: val_loss did not improve from 1.31495
Epoch 1211/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4058 - val_loss: 1.3168 - val_accuracy: 0.4131

Epoch 01211: val_loss did not improve from 1.31495
Epoch 1212/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4052 - val_loss: 1.3209 - val_accuracy: 0.4147

Epoch 01212: val_loss did not improve from 1.31495
Epoch 1213/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4047 - val_loss: 1.3176 - val_accuracy: 0.4131

Epoch 01213: val_loss did not improve from 1.31495
Epoch 1214/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4038 - val_loss: 1.3178 - val_accuracy: 0.4147

Epoch 01214: val_loss did not improve from 1.31495
Epoch 1215/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4047 - val_loss: 1.3187 - val_accuracy: 0.4171

Epoch 01215: val_loss did not improve from 1.31495
Epoch 1216/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4055 - val_loss: 1.3160 - val_accuracy: 0.4219

Epoch 01216: val_loss did not improve from 1.31495
Epoch 1217/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4070 - val_loss: 1.3183 - val_accuracy: 0.4195

Epoch 01217: val_loss did not improve from 1.31495
Epoch 1218/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4078 - val_loss: 1.3190 - val_accuracy: 0.4211

Epoch 01218: val_loss did not improve from 1.31495
Epoch 1219/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4074 - val_loss: 1.3171 - val_accuracy: 0.4179

Epoch 01219: val_loss did not improve from 1.31495
Epoch 1220/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4076 - val_loss: 1.3169 - val_accuracy: 0.4219

Epoch 01220: val_loss did not improve from 1.31495
Epoch 1221/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4055 - val_loss: 1.3172 - val_accuracy: 0.4147

Epoch 01221: val_loss did not improve from 1.31495
Epoch 1222/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4081 - val_loss: 1.3169 - val_accuracy: 0.4179

Epoch 01222: val_loss did not improve from 1.31495
Epoch 1223/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4090 - val_loss: 1.3182 - val_accuracy: 0.4258

Epoch 01223: val_loss did not improve from 1.31495
Epoch 1224/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4092 - val_loss: 1.3157 - val_accuracy: 0.4258

Epoch 01224: val_loss did not improve from 1.31495
Epoch 1225/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4092 - val_loss: 1.3171 - val_accuracy: 0.4226

Epoch 01225: val_loss did not improve from 1.31495
Epoch 1226/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4056 - val_loss: 1.3153 - val_accuracy: 0.4163

Epoch 01226: val_loss did not improve from 1.31495
Epoch 1227/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4040 - val_loss: 1.3183 - val_accuracy: 0.4250

Epoch 01227: val_loss did not improve from 1.31495
Epoch 1228/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4055 - val_loss: 1.3158 - val_accuracy: 0.4258

Epoch 01228: val_loss did not improve from 1.31495
Epoch 1229/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4040 - val_loss: 1.3175 - val_accuracy: 0.4195

Epoch 01229: val_loss did not improve from 1.31495
Epoch 1230/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4061 - val_loss: 1.3203 - val_accuracy: 0.4147

Epoch 01230: val_loss did not improve from 1.31495
Epoch 1231/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4027 - val_loss: 1.3182 - val_accuracy: 0.4107

Epoch 01231: val_loss did not improve from 1.31495
Epoch 1232/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4018 - val_loss: 1.3174 - val_accuracy: 0.4163

Epoch 01232: val_loss did not improve from 1.31495
Epoch 1233/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4042 - val_loss: 1.3137 - val_accuracy: 0.4258

Epoch 01233: val_loss improved from 1.31495 to 1.31367, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1234/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4055 - val_loss: 1.3158 - val_accuracy: 0.4266

Epoch 01234: val_loss did not improve from 1.31367
Epoch 1235/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4095 - val_loss: 1.3166 - val_accuracy: 0.4187

Epoch 01235: val_loss did not improve from 1.31367
Epoch 1236/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4041 - val_loss: 1.3159 - val_accuracy: 0.4155

Epoch 01236: val_loss did not improve from 1.31367
Epoch 1237/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4048 - val_loss: 1.3165 - val_accuracy: 0.4163

Epoch 01237: val_loss did not improve from 1.31367
Epoch 1238/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4052 - val_loss: 1.3165 - val_accuracy: 0.4234

Epoch 01238: val_loss did not improve from 1.31367
Epoch 1239/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4060 - val_loss: 1.3159 - val_accuracy: 0.4187

Epoch 01239: val_loss did not improve from 1.31367
Epoch 1240/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4049 - val_loss: 1.3181 - val_accuracy: 0.4219

Epoch 01240: val_loss did not improve from 1.31367
Epoch 1241/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4023 - val_loss: 1.3173 - val_accuracy: 0.4179

Epoch 01241: val_loss did not improve from 1.31367
Epoch 1242/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4080 - val_loss: 1.3161 - val_accuracy: 0.4234

Epoch 01242: val_loss did not improve from 1.31367
Epoch 1243/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4094 - val_loss: 1.3149 - val_accuracy: 0.4234

Epoch 01243: val_loss did not improve from 1.31367
Epoch 1244/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4080 - val_loss: 1.3236 - val_accuracy: 0.4250

Epoch 01244: val_loss did not improve from 1.31367
Epoch 1245/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4069 - val_loss: 1.3164 - val_accuracy: 0.4139

Epoch 01245: val_loss did not improve from 1.31367
Epoch 1246/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4016 - val_loss: 1.3169 - val_accuracy: 0.4131

Epoch 01246: val_loss did not improve from 1.31367
Epoch 1247/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4059 - val_loss: 1.3172 - val_accuracy: 0.4131

Epoch 01247: val_loss did not improve from 1.31367
Epoch 1248/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4063 - val_loss: 1.3150 - val_accuracy: 0.4195

Epoch 01248: val_loss did not improve from 1.31367
Epoch 1249/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4101 - val_loss: 1.3182 - val_accuracy: 0.4242

Epoch 01249: val_loss did not improve from 1.31367
Epoch 1250/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4074 - val_loss: 1.3137 - val_accuracy: 0.4203

Epoch 01250: val_loss did not improve from 1.31367
Epoch 1251/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4094 - val_loss: 1.3157 - val_accuracy: 0.4322

Epoch 01251: val_loss did not improve from 1.31367
Epoch 1252/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4093 - val_loss: 1.3142 - val_accuracy: 0.4211

Epoch 01252: val_loss did not improve from 1.31367
Epoch 1253/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4096 - val_loss: 1.3153 - val_accuracy: 0.4171

Epoch 01253: val_loss did not improve from 1.31367
Epoch 1254/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4106 - val_loss: 1.3135 - val_accuracy: 0.4179

Epoch 01254: val_loss improved from 1.31367 to 1.31353, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1255/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4095 - val_loss: 1.3135 - val_accuracy: 0.4226

Epoch 01255: val_loss improved from 1.31353 to 1.31345, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1256/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4109 - val_loss: 1.3145 - val_accuracy: 0.4226

Epoch 01256: val_loss did not improve from 1.31345
Epoch 1257/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4087 - val_loss: 1.3136 - val_accuracy: 0.4155

Epoch 01257: val_loss did not improve from 1.31345
Epoch 1258/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4095 - val_loss: 1.3162 - val_accuracy: 0.4219

Epoch 01258: val_loss did not improve from 1.31345
Epoch 1259/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4132 - val_loss: 1.3128 - val_accuracy: 0.4195

Epoch 01259: val_loss improved from 1.31345 to 1.31276, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1260/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4087 - val_loss: 1.3179 - val_accuracy: 0.4163

Epoch 01260: val_loss did not improve from 1.31276
Epoch 1261/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4076 - val_loss: 1.3148 - val_accuracy: 0.4203

Epoch 01261: val_loss did not improve from 1.31276
Epoch 1262/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4073 - val_loss: 1.3140 - val_accuracy: 0.4115

Epoch 01262: val_loss did not improve from 1.31276
Epoch 1263/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4076 - val_loss: 1.3153 - val_accuracy: 0.4226

Epoch 01263: val_loss did not improve from 1.31276
Epoch 1264/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4083 - val_loss: 1.3168 - val_accuracy: 0.4147

Epoch 01264: val_loss did not improve from 1.31276
Epoch 1265/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4059 - val_loss: 1.3140 - val_accuracy: 0.4179

Epoch 01265: val_loss did not improve from 1.31276
Epoch 1266/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4078 - val_loss: 1.3150 - val_accuracy: 0.4211

Epoch 01266: val_loss did not improve from 1.31276
Epoch 1267/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4014 - val_loss: 1.3155 - val_accuracy: 0.4139

Epoch 01267: val_loss did not improve from 1.31276
Epoch 1268/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4081 - val_loss: 1.3147 - val_accuracy: 0.4219

Epoch 01268: val_loss did not improve from 1.31276
Epoch 1269/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4088 - val_loss: 1.3138 - val_accuracy: 0.4195

Epoch 01269: val_loss did not improve from 1.31276
Epoch 1270/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4073 - val_loss: 1.3155 - val_accuracy: 0.4187

Epoch 01270: val_loss did not improve from 1.31276
Epoch 1271/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4086 - val_loss: 1.3131 - val_accuracy: 0.4266

Epoch 01271: val_loss did not improve from 1.31276
Epoch 1272/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4094 - val_loss: 1.3157 - val_accuracy: 0.4290

Epoch 01272: val_loss did not improve from 1.31276
Epoch 1273/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4088 - val_loss: 1.3151 - val_accuracy: 0.4234

Epoch 01273: val_loss did not improve from 1.31276
Epoch 1274/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4088 - val_loss: 1.3185 - val_accuracy: 0.4203

Epoch 01274: val_loss did not improve from 1.31276
Epoch 1275/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4047 - val_loss: 1.3141 - val_accuracy: 0.4211

Epoch 01275: val_loss did not improve from 1.31276
Epoch 1276/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4089 - val_loss: 1.3157 - val_accuracy: 0.4147

Epoch 01276: val_loss did not improve from 1.31276
Epoch 1277/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4085 - val_loss: 1.3156 - val_accuracy: 0.4211

Epoch 01277: val_loss did not improve from 1.31276
Epoch 1278/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4075 - val_loss: 1.3143 - val_accuracy: 0.4179

Epoch 01278: val_loss did not improve from 1.31276
Epoch 1279/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4080 - val_loss: 1.3166 - val_accuracy: 0.4234

Epoch 01279: val_loss did not improve from 1.31276
Epoch 1280/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4067 - val_loss: 1.3155 - val_accuracy: 0.4219

Epoch 01280: val_loss did not improve from 1.31276
Epoch 1281/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4033 - val_loss: 1.3136 - val_accuracy: 0.4195

Epoch 01281: val_loss did not improve from 1.31276
Epoch 1282/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4106 - val_loss: 1.3160 - val_accuracy: 0.4155

Epoch 01282: val_loss did not improve from 1.31276
Epoch 1283/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4058 - val_loss: 1.3160 - val_accuracy: 0.4131

Epoch 01283: val_loss did not improve from 1.31276
Epoch 1284/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4063 - val_loss: 1.3168 - val_accuracy: 0.4123

Epoch 01284: val_loss did not improve from 1.31276
Epoch 1285/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4065 - val_loss: 1.3141 - val_accuracy: 0.4123

Epoch 01285: val_loss did not improve from 1.31276
Epoch 1286/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4100 - val_loss: 1.3149 - val_accuracy: 0.4179

Epoch 01286: val_loss did not improve from 1.31276
Epoch 1287/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4036 - val_loss: 1.3140 - val_accuracy: 0.4203

Epoch 01287: val_loss did not improve from 1.31276
Epoch 1288/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4069 - val_loss: 1.3151 - val_accuracy: 0.4179

Epoch 01288: val_loss did not improve from 1.31276
Epoch 1289/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4061 - val_loss: 1.3167 - val_accuracy: 0.4219

Epoch 01289: val_loss did not improve from 1.31276
Epoch 1290/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4057 - val_loss: 1.3144 - val_accuracy: 0.4242

Epoch 01290: val_loss did not improve from 1.31276
Epoch 1291/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4047 - val_loss: 1.3150 - val_accuracy: 0.4211

Epoch 01291: val_loss did not improve from 1.31276
Epoch 1292/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4063 - val_loss: 1.3190 - val_accuracy: 0.4211

Epoch 01292: val_loss did not improve from 1.31276
Epoch 1293/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4019 - val_loss: 1.3173 - val_accuracy: 0.4306

Epoch 01293: val_loss did not improve from 1.31276
Epoch 1294/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.3998 - val_loss: 1.3166 - val_accuracy: 0.4139

Epoch 01294: val_loss did not improve from 1.31276
Epoch 1295/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4058 - val_loss: 1.3168 - val_accuracy: 0.4187

Epoch 01295: val_loss did not improve from 1.31276
Epoch 1296/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4058 - val_loss: 1.3150 - val_accuracy: 0.4211

Epoch 01296: val_loss did not improve from 1.31276
Epoch 1297/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4065 - val_loss: 1.3142 - val_accuracy: 0.4139

Epoch 01297: val_loss did not improve from 1.31276
Epoch 1298/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4075 - val_loss: 1.3174 - val_accuracy: 0.4179

Epoch 01298: val_loss did not improve from 1.31276
Epoch 1299/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4033 - val_loss: 1.3146 - val_accuracy: 0.4147

Epoch 01299: val_loss did not improve from 1.31276
Epoch 1300/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4114 - val_loss: 1.3137 - val_accuracy: 0.4211

Epoch 01300: val_loss did not improve from 1.31276
Epoch 1301/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4100 - val_loss: 1.3134 - val_accuracy: 0.4211

Epoch 01301: val_loss did not improve from 1.31276
Epoch 1302/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4090 - val_loss: 1.3155 - val_accuracy: 0.4155

Epoch 01302: val_loss did not improve from 1.31276
Epoch 1303/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4070 - val_loss: 1.3146 - val_accuracy: 0.4226

Epoch 01303: val_loss did not improve from 1.31276
Epoch 1304/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4085 - val_loss: 1.3149 - val_accuracy: 0.4234

Epoch 01304: val_loss did not improve from 1.31276
Epoch 1305/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4028 - val_loss: 1.3161 - val_accuracy: 0.4147

Epoch 01305: val_loss did not improve from 1.31276
Epoch 1306/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4044 - val_loss: 1.3143 - val_accuracy: 0.4171

Epoch 01306: val_loss did not improve from 1.31276
Epoch 1307/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4117 - val_loss: 1.3152 - val_accuracy: 0.4258

Epoch 01307: val_loss did not improve from 1.31276
Epoch 1308/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4102 - val_loss: 1.3126 - val_accuracy: 0.4226

Epoch 01308: val_loss improved from 1.31276 to 1.31260, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1309/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4111 - val_loss: 1.3166 - val_accuracy: 0.4274

Epoch 01309: val_loss did not improve from 1.31260
Epoch 1310/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4070 - val_loss: 1.3128 - val_accuracy: 0.4226

Epoch 01310: val_loss did not improve from 1.31260
Epoch 1311/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4068 - val_loss: 1.3127 - val_accuracy: 0.4131

Epoch 01311: val_loss did not improve from 1.31260
Epoch 1312/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4127 - val_loss: 1.3135 - val_accuracy: 0.4250

Epoch 01312: val_loss did not improve from 1.31260
Epoch 1313/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4087 - val_loss: 1.3142 - val_accuracy: 0.4250

Epoch 01313: val_loss did not improve from 1.31260
Epoch 1314/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4065 - val_loss: 1.3159 - val_accuracy: 0.4155

Epoch 01314: val_loss did not improve from 1.31260
Epoch 1315/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4106 - val_loss: 1.3160 - val_accuracy: 0.4115

Epoch 01315: val_loss did not improve from 1.31260
Epoch 1316/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4069 - val_loss: 1.3166 - val_accuracy: 0.4242

Epoch 01316: val_loss did not improve from 1.31260
Epoch 1317/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4067 - val_loss: 1.3127 - val_accuracy: 0.4163

Epoch 01317: val_loss did not improve from 1.31260
Epoch 1318/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4039 - val_loss: 1.3138 - val_accuracy: 0.4171

Epoch 01318: val_loss did not improve from 1.31260
Epoch 1319/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4140 - val_loss: 1.3172 - val_accuracy: 0.4171

Epoch 01319: val_loss did not improve from 1.31260
Epoch 1320/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4090 - val_loss: 1.3140 - val_accuracy: 0.4091

Epoch 01320: val_loss did not improve from 1.31260
Epoch 1321/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4050 - val_loss: 1.3156 - val_accuracy: 0.4163

Epoch 01321: val_loss did not improve from 1.31260
Epoch 1322/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4119 - val_loss: 1.3138 - val_accuracy: 0.4219

Epoch 01322: val_loss did not improve from 1.31260
Epoch 1323/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4103 - val_loss: 1.3136 - val_accuracy: 0.4234

Epoch 01323: val_loss did not improve from 1.31260
Epoch 1324/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4111 - val_loss: 1.3133 - val_accuracy: 0.4147

Epoch 01324: val_loss did not improve from 1.31260
Epoch 1325/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4094 - val_loss: 1.3139 - val_accuracy: 0.4219

Epoch 01325: val_loss did not improve from 1.31260
Epoch 1326/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4057 - val_loss: 1.3120 - val_accuracy: 0.4234

Epoch 01326: val_loss improved from 1.31260 to 1.31203, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1327/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4099 - val_loss: 1.3171 - val_accuracy: 0.4123

Epoch 01327: val_loss did not improve from 1.31203
Epoch 1328/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4078 - val_loss: 1.3136 - val_accuracy: 0.4179

Epoch 01328: val_loss did not improve from 1.31203
Epoch 1329/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4078 - val_loss: 1.3121 - val_accuracy: 0.4131

Epoch 01329: val_loss did not improve from 1.31203
Epoch 1330/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4093 - val_loss: 1.3201 - val_accuracy: 0.4075

Epoch 01330: val_loss did not improve from 1.31203
Epoch 1331/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4093 - val_loss: 1.3139 - val_accuracy: 0.4226

Epoch 01331: val_loss did not improve from 1.31203
Epoch 1332/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4097 - val_loss: 1.3134 - val_accuracy: 0.4179

Epoch 01332: val_loss did not improve from 1.31203
Epoch 1333/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4096 - val_loss: 1.3229 - val_accuracy: 0.4195

Epoch 01333: val_loss did not improve from 1.31203
Epoch 1334/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4055 - val_loss: 1.3155 - val_accuracy: 0.4195

Epoch 01334: val_loss did not improve from 1.31203
Epoch 1335/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4092 - val_loss: 1.3141 - val_accuracy: 0.4211

Epoch 01335: val_loss did not improve from 1.31203
Epoch 1336/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4059 - val_loss: 1.3129 - val_accuracy: 0.4171

Epoch 01336: val_loss did not improve from 1.31203
Epoch 1337/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4097 - val_loss: 1.3105 - val_accuracy: 0.4203

Epoch 01337: val_loss improved from 1.31203 to 1.31049, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1338/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4088 - val_loss: 1.3118 - val_accuracy: 0.4115

Epoch 01338: val_loss did not improve from 1.31049
Epoch 1339/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4092 - val_loss: 1.3132 - val_accuracy: 0.4163

Epoch 01339: val_loss did not improve from 1.31049
Epoch 1340/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4109 - val_loss: 1.3174 - val_accuracy: 0.4179

Epoch 01340: val_loss did not improve from 1.31049
Epoch 1341/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4087 - val_loss: 1.3146 - val_accuracy: 0.4187

Epoch 01341: val_loss did not improve from 1.31049
Epoch 1342/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4063 - val_loss: 1.3139 - val_accuracy: 0.4123

Epoch 01342: val_loss did not improve from 1.31049
Epoch 1343/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4114 - val_loss: 1.3143 - val_accuracy: 0.4155

Epoch 01343: val_loss did not improve from 1.31049
Epoch 1344/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4083 - val_loss: 1.3126 - val_accuracy: 0.4131

Epoch 01344: val_loss did not improve from 1.31049
Epoch 1345/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4093 - val_loss: 1.3170 - val_accuracy: 0.4147

Epoch 01345: val_loss did not improve from 1.31049
Epoch 1346/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4037 - val_loss: 1.3122 - val_accuracy: 0.4187

Epoch 01346: val_loss did not improve from 1.31049
Epoch 1347/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4073 - val_loss: 1.3128 - val_accuracy: 0.4187

Epoch 01347: val_loss did not improve from 1.31049
Epoch 1348/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4129 - val_loss: 1.3138 - val_accuracy: 0.4187

Epoch 01348: val_loss did not improve from 1.31049
Epoch 1349/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4093 - val_loss: 1.3143 - val_accuracy: 0.4171

Epoch 01349: val_loss did not improve from 1.31049
Epoch 1350/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4048 - val_loss: 1.3132 - val_accuracy: 0.4187

Epoch 01350: val_loss did not improve from 1.31049
Epoch 1351/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4028 - val_loss: 1.3130 - val_accuracy: 0.4211

Epoch 01351: val_loss did not improve from 1.31049
Epoch 1352/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4095 - val_loss: 1.3143 - val_accuracy: 0.4171

Epoch 01352: val_loss did not improve from 1.31049
Epoch 1353/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4041 - val_loss: 1.3104 - val_accuracy: 0.4187

Epoch 01353: val_loss improved from 1.31049 to 1.31042, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1354/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4108 - val_loss: 1.3120 - val_accuracy: 0.4250

Epoch 01354: val_loss did not improve from 1.31042
Epoch 1355/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4052 - val_loss: 1.3126 - val_accuracy: 0.4163

Epoch 01355: val_loss did not improve from 1.31042
Epoch 1356/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4029 - val_loss: 1.3167 - val_accuracy: 0.4163

Epoch 01356: val_loss did not improve from 1.31042
Epoch 1357/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4022 - val_loss: 1.3160 - val_accuracy: 0.4075

Epoch 01357: val_loss did not improve from 1.31042
Epoch 1358/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4083 - val_loss: 1.3144 - val_accuracy: 0.4203

Epoch 01358: val_loss did not improve from 1.31042
Epoch 1359/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4087 - val_loss: 1.3162 - val_accuracy: 0.4187

Epoch 01359: val_loss did not improve from 1.31042
Epoch 1360/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.3993 - val_loss: 1.3138 - val_accuracy: 0.4043

Epoch 01360: val_loss did not improve from 1.31042
Epoch 1361/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4117 - val_loss: 1.3166 - val_accuracy: 0.4258

Epoch 01361: val_loss did not improve from 1.31042
Epoch 1362/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4070 - val_loss: 1.3119 - val_accuracy: 0.4266

Epoch 01362: val_loss did not improve from 1.31042
Epoch 1363/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4063 - val_loss: 1.3115 - val_accuracy: 0.4234

Epoch 01363: val_loss did not improve from 1.31042
Epoch 1364/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4129 - val_loss: 1.3184 - val_accuracy: 0.4258

Epoch 01364: val_loss did not improve from 1.31042
Epoch 1365/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4039 - val_loss: 1.3121 - val_accuracy: 0.4139

Epoch 01365: val_loss did not improve from 1.31042
Epoch 1366/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4047 - val_loss: 1.3100 - val_accuracy: 0.4203

Epoch 01366: val_loss improved from 1.31042 to 1.31000, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1367/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4071 - val_loss: 1.3176 - val_accuracy: 0.4211

Epoch 01367: val_loss did not improve from 1.31000
Epoch 1368/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4031 - val_loss: 1.3116 - val_accuracy: 0.4155

Epoch 01368: val_loss did not improve from 1.31000
Epoch 1369/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4097 - val_loss: 1.3150 - val_accuracy: 0.4163

Epoch 01369: val_loss did not improve from 1.31000
Epoch 1370/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4098 - val_loss: 1.3113 - val_accuracy: 0.4242

Epoch 01370: val_loss did not improve from 1.31000
Epoch 1371/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4104 - val_loss: 1.3141 - val_accuracy: 0.4234

Epoch 01371: val_loss did not improve from 1.31000
Epoch 1372/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4049 - val_loss: 1.3123 - val_accuracy: 0.4203

Epoch 01372: val_loss did not improve from 1.31000
Epoch 1373/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4087 - val_loss: 1.3116 - val_accuracy: 0.4226

Epoch 01373: val_loss did not improve from 1.31000
Epoch 1374/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4094 - val_loss: 1.3106 - val_accuracy: 0.4226

Epoch 01374: val_loss did not improve from 1.31000
Epoch 1375/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4070 - val_loss: 1.3161 - val_accuracy: 0.4179

Epoch 01375: val_loss did not improve from 1.31000
Epoch 1376/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4049 - val_loss: 1.3110 - val_accuracy: 0.4155

Epoch 01376: val_loss did not improve from 1.31000
Epoch 1377/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4086 - val_loss: 1.3112 - val_accuracy: 0.4203

Epoch 01377: val_loss did not improve from 1.31000
Epoch 1378/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4125 - val_loss: 1.3105 - val_accuracy: 0.4219

Epoch 01378: val_loss did not improve from 1.31000
Epoch 1379/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4088 - val_loss: 1.3110 - val_accuracy: 0.4131

Epoch 01379: val_loss did not improve from 1.31000
Epoch 1380/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4091 - val_loss: 1.3121 - val_accuracy: 0.4155

Epoch 01380: val_loss did not improve from 1.31000
Epoch 1381/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4063 - val_loss: 1.3107 - val_accuracy: 0.4147

Epoch 01381: val_loss did not improve from 1.31000
Epoch 1382/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4092 - val_loss: 1.3103 - val_accuracy: 0.4274

Epoch 01382: val_loss did not improve from 1.31000
Epoch 1383/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4101 - val_loss: 1.3109 - val_accuracy: 0.4282

Epoch 01383: val_loss did not improve from 1.31000
Epoch 1384/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4057 - val_loss: 1.3099 - val_accuracy: 0.4195

Epoch 01384: val_loss improved from 1.31000 to 1.30987, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1385/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4098 - val_loss: 1.3188 - val_accuracy: 0.4171

Epoch 01385: val_loss did not improve from 1.30987
Epoch 1386/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.3995 - val_loss: 1.3103 - val_accuracy: 0.4179

Epoch 01386: val_loss did not improve from 1.30987
Epoch 1387/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4059 - val_loss: 1.3123 - val_accuracy: 0.4203

Epoch 01387: val_loss did not improve from 1.30987
Epoch 1388/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4122 - val_loss: 1.3100 - val_accuracy: 0.4155

Epoch 01388: val_loss did not improve from 1.30987
Epoch 1389/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4105 - val_loss: 1.3107 - val_accuracy: 0.4179

Epoch 01389: val_loss did not improve from 1.30987
Epoch 1390/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4033 - val_loss: 1.3102 - val_accuracy: 0.4234

Epoch 01390: val_loss did not improve from 1.30987
Epoch 1391/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4114 - val_loss: 1.3116 - val_accuracy: 0.4266

Epoch 01391: val_loss did not improve from 1.30987
Epoch 1392/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4077 - val_loss: 1.3109 - val_accuracy: 0.4155

Epoch 01392: val_loss did not improve from 1.30987
Epoch 1393/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4100 - val_loss: 1.3109 - val_accuracy: 0.4179

Epoch 01393: val_loss did not improve from 1.30987
Epoch 1394/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4070 - val_loss: 1.3111 - val_accuracy: 0.4179

Epoch 01394: val_loss did not improve from 1.30987
Epoch 1395/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4126 - val_loss: 1.3137 - val_accuracy: 0.4250

Epoch 01395: val_loss did not improve from 1.30987
Epoch 1396/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4013 - val_loss: 1.3097 - val_accuracy: 0.4179

Epoch 01396: val_loss improved from 1.30987 to 1.30968, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1397/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4068 - val_loss: 1.3101 - val_accuracy: 0.4219

Epoch 01397: val_loss did not improve from 1.30968
Epoch 1398/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4110 - val_loss: 1.3134 - val_accuracy: 0.4219

Epoch 01398: val_loss did not improve from 1.30968
Epoch 1399/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4045 - val_loss: 1.3094 - val_accuracy: 0.4195

Epoch 01399: val_loss improved from 1.30968 to 1.30941, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1400/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4076 - val_loss: 1.3104 - val_accuracy: 0.4155

Epoch 01400: val_loss did not improve from 1.30941
Epoch 1401/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4112 - val_loss: 1.3100 - val_accuracy: 0.4242

Epoch 01401: val_loss did not improve from 1.30941
Epoch 1402/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4078 - val_loss: 1.3089 - val_accuracy: 0.4163

Epoch 01402: val_loss improved from 1.30941 to 1.30891, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1403/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4083 - val_loss: 1.3095 - val_accuracy: 0.4179

Epoch 01403: val_loss did not improve from 1.30891
Epoch 1404/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4086 - val_loss: 1.3126 - val_accuracy: 0.4171

Epoch 01404: val_loss did not improve from 1.30891
Epoch 1405/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4058 - val_loss: 1.3091 - val_accuracy: 0.4187

Epoch 01405: val_loss did not improve from 1.30891
Epoch 1406/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4120 - val_loss: 1.3132 - val_accuracy: 0.4179

Epoch 01406: val_loss did not improve from 1.30891
Epoch 1407/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4066 - val_loss: 1.3105 - val_accuracy: 0.4179

Epoch 01407: val_loss did not improve from 1.30891
Epoch 1408/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4104 - val_loss: 1.3119 - val_accuracy: 0.4258

Epoch 01408: val_loss did not improve from 1.30891
Epoch 1409/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4062 - val_loss: 1.3096 - val_accuracy: 0.4187

Epoch 01409: val_loss did not improve from 1.30891
Epoch 1410/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4092 - val_loss: 1.3096 - val_accuracy: 0.4099

Epoch 01410: val_loss did not improve from 1.30891
Epoch 1411/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4099 - val_loss: 1.3103 - val_accuracy: 0.4163

Epoch 01411: val_loss did not improve from 1.30891
Epoch 1412/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4120 - val_loss: 1.3118 - val_accuracy: 0.4163

Epoch 01412: val_loss did not improve from 1.30891
Epoch 1413/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4114 - val_loss: 1.3091 - val_accuracy: 0.4250

Epoch 01413: val_loss did not improve from 1.30891
Epoch 1414/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4043 - val_loss: 1.3122 - val_accuracy: 0.4195

Epoch 01414: val_loss did not improve from 1.30891
Epoch 1415/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4062 - val_loss: 1.3110 - val_accuracy: 0.4179

Epoch 01415: val_loss did not improve from 1.30891
Epoch 1416/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4105 - val_loss: 1.3128 - val_accuracy: 0.4171

Epoch 01416: val_loss did not improve from 1.30891
Epoch 1417/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4070 - val_loss: 1.3120 - val_accuracy: 0.4179

Epoch 01417: val_loss did not improve from 1.30891
Epoch 1418/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4094 - val_loss: 1.3116 - val_accuracy: 0.4219

Epoch 01418: val_loss did not improve from 1.30891
Epoch 1419/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4101 - val_loss: 1.3106 - val_accuracy: 0.4155

Epoch 01419: val_loss did not improve from 1.30891
Epoch 1420/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4066 - val_loss: 1.3112 - val_accuracy: 0.4091

Epoch 01420: val_loss did not improve from 1.30891
Epoch 1421/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4078 - val_loss: 1.3163 - val_accuracy: 0.4123

Epoch 01421: val_loss did not improve from 1.30891
Epoch 1422/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4081 - val_loss: 1.3106 - val_accuracy: 0.4123

Epoch 01422: val_loss did not improve from 1.30891
Epoch 1423/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4110 - val_loss: 1.3111 - val_accuracy: 0.4211

Epoch 01423: val_loss did not improve from 1.30891
Epoch 1424/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4032 - val_loss: 1.3123 - val_accuracy: 0.4163

Epoch 01424: val_loss did not improve from 1.30891
Epoch 1425/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4078 - val_loss: 1.3156 - val_accuracy: 0.4219

Epoch 01425: val_loss did not improve from 1.30891
Epoch 1426/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4083 - val_loss: 1.3111 - val_accuracy: 0.4195

Epoch 01426: val_loss did not improve from 1.30891
Epoch 1427/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4107 - val_loss: 1.3115 - val_accuracy: 0.4211

Epoch 01427: val_loss did not improve from 1.30891
Epoch 1428/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4077 - val_loss: 1.3090 - val_accuracy: 0.4155

Epoch 01428: val_loss did not improve from 1.30891
Epoch 1429/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4117 - val_loss: 1.3124 - val_accuracy: 0.4203

Epoch 01429: val_loss did not improve from 1.30891
Epoch 1430/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4087 - val_loss: 1.3089 - val_accuracy: 0.4163

Epoch 01430: val_loss did not improve from 1.30891
Epoch 1431/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4112 - val_loss: 1.3093 - val_accuracy: 0.4083

Epoch 01431: val_loss did not improve from 1.30891
Epoch 1432/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4070 - val_loss: 1.3116 - val_accuracy: 0.4219

Epoch 01432: val_loss did not improve from 1.30891
Epoch 1433/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4061 - val_loss: 1.3105 - val_accuracy: 0.4163

Epoch 01433: val_loss did not improve from 1.30891
Epoch 1434/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4103 - val_loss: 1.3146 - val_accuracy: 0.4266

Epoch 01434: val_loss did not improve from 1.30891
Epoch 1435/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4062 - val_loss: 1.3086 - val_accuracy: 0.4195

Epoch 01435: val_loss improved from 1.30891 to 1.30863, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1436/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4071 - val_loss: 1.3088 - val_accuracy: 0.4163

Epoch 01436: val_loss did not improve from 1.30863
Epoch 1437/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4092 - val_loss: 1.3079 - val_accuracy: 0.4163

Epoch 01437: val_loss improved from 1.30863 to 1.30793, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1438/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4082 - val_loss: 1.3094 - val_accuracy: 0.4131

Epoch 01438: val_loss did not improve from 1.30793
Epoch 1439/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4077 - val_loss: 1.3104 - val_accuracy: 0.4123

Epoch 01439: val_loss did not improve from 1.30793
Epoch 1440/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4091 - val_loss: 1.3079 - val_accuracy: 0.4219

Epoch 01440: val_loss did not improve from 1.30793
Epoch 1441/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4093 - val_loss: 1.3166 - val_accuracy: 0.4147

Epoch 01441: val_loss did not improve from 1.30793
Epoch 1442/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4070 - val_loss: 1.3110 - val_accuracy: 0.4250

Epoch 01442: val_loss did not improve from 1.30793
Epoch 1443/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4124 - val_loss: 1.3096 - val_accuracy: 0.4171

Epoch 01443: val_loss did not improve from 1.30793
Epoch 1444/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4101 - val_loss: 1.3083 - val_accuracy: 0.4115

Epoch 01444: val_loss did not improve from 1.30793
Epoch 1445/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4115 - val_loss: 1.3150 - val_accuracy: 0.4219

Epoch 01445: val_loss did not improve from 1.30793
Epoch 1446/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4061 - val_loss: 1.3083 - val_accuracy: 0.4203

Epoch 01446: val_loss did not improve from 1.30793
Epoch 1447/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4077 - val_loss: 1.3083 - val_accuracy: 0.4250

Epoch 01447: val_loss did not improve from 1.30793
Epoch 1448/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4087 - val_loss: 1.3104 - val_accuracy: 0.4203

Epoch 01448: val_loss did not improve from 1.30793
Epoch 1449/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4109 - val_loss: 1.3098 - val_accuracy: 0.4163

Epoch 01449: val_loss did not improve from 1.30793
Epoch 1450/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4109 - val_loss: 1.3128 - val_accuracy: 0.4115

Epoch 01450: val_loss did not improve from 1.30793
Epoch 1451/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4047 - val_loss: 1.3099 - val_accuracy: 0.4091

Epoch 01451: val_loss did not improve from 1.30793
Epoch 1452/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4072 - val_loss: 1.3095 - val_accuracy: 0.4123

Epoch 01452: val_loss did not improve from 1.30793
Epoch 1453/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4108 - val_loss: 1.3134 - val_accuracy: 0.4147

Epoch 01453: val_loss did not improve from 1.30793
Epoch 1454/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4044 - val_loss: 1.3097 - val_accuracy: 0.4139

Epoch 01454: val_loss did not improve from 1.30793
Epoch 1455/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4125 - val_loss: 1.3132 - val_accuracy: 0.4163

Epoch 01455: val_loss did not improve from 1.30793
Epoch 1456/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4043 - val_loss: 1.3097 - val_accuracy: 0.4171

Epoch 01456: val_loss did not improve from 1.30793
Epoch 1457/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4059 - val_loss: 1.3107 - val_accuracy: 0.4211

Epoch 01457: val_loss did not improve from 1.30793
Epoch 1458/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4078 - val_loss: 1.3092 - val_accuracy: 0.4219

Epoch 01458: val_loss did not improve from 1.30793
Epoch 1459/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4091 - val_loss: 1.3077 - val_accuracy: 0.4234

Epoch 01459: val_loss improved from 1.30793 to 1.30772, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1460/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4086 - val_loss: 1.3126 - val_accuracy: 0.4155

Epoch 01460: val_loss did not improve from 1.30772
Epoch 1461/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4079 - val_loss: 1.3090 - val_accuracy: 0.4211

Epoch 01461: val_loss did not improve from 1.30772
Epoch 1462/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4072 - val_loss: 1.3100 - val_accuracy: 0.4171

Epoch 01462: val_loss did not improve from 1.30772
Epoch 1463/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4074 - val_loss: 1.3093 - val_accuracy: 0.4155

Epoch 01463: val_loss did not improve from 1.30772
Epoch 1464/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4117 - val_loss: 1.3079 - val_accuracy: 0.4203

Epoch 01464: val_loss did not improve from 1.30772
Epoch 1465/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4072 - val_loss: 1.3090 - val_accuracy: 0.4250

Epoch 01465: val_loss did not improve from 1.30772
Epoch 1466/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4086 - val_loss: 1.3098 - val_accuracy: 0.4091

Epoch 01466: val_loss did not improve from 1.30772
Epoch 1467/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4057 - val_loss: 1.3104 - val_accuracy: 0.4107

Epoch 01467: val_loss did not improve from 1.30772
Epoch 1468/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4047 - val_loss: 1.3092 - val_accuracy: 0.4195

Epoch 01468: val_loss did not improve from 1.30772
Epoch 1469/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4125 - val_loss: 1.3179 - val_accuracy: 0.4131

Epoch 01469: val_loss did not improve from 1.30772
Epoch 1470/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4059 - val_loss: 1.3108 - val_accuracy: 0.4139

Epoch 01470: val_loss did not improve from 1.30772
Epoch 1471/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4069 - val_loss: 1.3082 - val_accuracy: 0.4179

Epoch 01471: val_loss did not improve from 1.30772
Epoch 1472/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4119 - val_loss: 1.3087 - val_accuracy: 0.4179

Epoch 01472: val_loss did not improve from 1.30772
Epoch 1473/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4077 - val_loss: 1.3087 - val_accuracy: 0.4131

Epoch 01473: val_loss did not improve from 1.30772
Epoch 1474/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4113 - val_loss: 1.3084 - val_accuracy: 0.4179

Epoch 01474: val_loss did not improve from 1.30772
Epoch 1475/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4120 - val_loss: 1.3097 - val_accuracy: 0.4242

Epoch 01475: val_loss did not improve from 1.30772
Epoch 1476/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4094 - val_loss: 1.3093 - val_accuracy: 0.4203

Epoch 01476: val_loss did not improve from 1.30772
Epoch 1477/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4089 - val_loss: 1.3092 - val_accuracy: 0.4179

Epoch 01477: val_loss did not improve from 1.30772
Epoch 1478/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4086 - val_loss: 1.3089 - val_accuracy: 0.4187

Epoch 01478: val_loss did not improve from 1.30772
Epoch 1479/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4071 - val_loss: 1.3104 - val_accuracy: 0.4187

Epoch 01479: val_loss did not improve from 1.30772
Epoch 1480/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4076 - val_loss: 1.3090 - val_accuracy: 0.4179

Epoch 01480: val_loss did not improve from 1.30772
Epoch 1481/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4090 - val_loss: 1.3079 - val_accuracy: 0.4187

Epoch 01481: val_loss did not improve from 1.30772
Epoch 1482/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4109 - val_loss: 1.3119 - val_accuracy: 0.4203

Epoch 01482: val_loss did not improve from 1.30772
Epoch 1483/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4070 - val_loss: 1.3086 - val_accuracy: 0.4242

Epoch 01483: val_loss did not improve from 1.30772
Epoch 1484/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4116 - val_loss: 1.3131 - val_accuracy: 0.4219

Epoch 01484: val_loss did not improve from 1.30772
Epoch 1485/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4086 - val_loss: 1.3062 - val_accuracy: 0.4250

Epoch 01485: val_loss improved from 1.30772 to 1.30622, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1486/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4059 - val_loss: 1.3064 - val_accuracy: 0.4226

Epoch 01486: val_loss did not improve from 1.30622
Epoch 1487/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4075 - val_loss: 1.3070 - val_accuracy: 0.4266

Epoch 01487: val_loss did not improve from 1.30622
Epoch 1488/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4094 - val_loss: 1.3053 - val_accuracy: 0.4250

Epoch 01488: val_loss improved from 1.30622 to 1.30535, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1489/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4094 - val_loss: 1.3087 - val_accuracy: 0.4155

Epoch 01489: val_loss did not improve from 1.30535
Epoch 1490/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4087 - val_loss: 1.3097 - val_accuracy: 0.4107

Epoch 01490: val_loss did not improve from 1.30535
Epoch 1491/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4101 - val_loss: 1.3088 - val_accuracy: 0.4179

Epoch 01491: val_loss did not improve from 1.30535
Epoch 1492/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4117 - val_loss: 1.3075 - val_accuracy: 0.4179

Epoch 01492: val_loss did not improve from 1.30535
Epoch 1493/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4107 - val_loss: 1.3100 - val_accuracy: 0.4203

Epoch 01493: val_loss did not improve from 1.30535
Epoch 1494/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4047 - val_loss: 1.3074 - val_accuracy: 0.4163

Epoch 01494: val_loss did not improve from 1.30535
Epoch 1495/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4115 - val_loss: 1.3096 - val_accuracy: 0.4282

Epoch 01495: val_loss did not improve from 1.30535
Epoch 1496/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4110 - val_loss: 1.3105 - val_accuracy: 0.4211

Epoch 01496: val_loss did not improve from 1.30535
Epoch 1497/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4056 - val_loss: 1.3093 - val_accuracy: 0.4131

Epoch 01497: val_loss did not improve from 1.30535
Epoch 1498/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4093 - val_loss: 1.3108 - val_accuracy: 0.4219

Epoch 01498: val_loss did not improve from 1.30535
Epoch 1499/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4067 - val_loss: 1.3102 - val_accuracy: 0.4211

Epoch 01499: val_loss did not improve from 1.30535
Epoch 1500/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4082 - val_loss: 1.3088 - val_accuracy: 0.4139

Epoch 01500: val_loss did not improve from 1.30535
Epoch 1501/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4082 - val_loss: 1.3082 - val_accuracy: 0.4083

Epoch 01501: val_loss did not improve from 1.30535
Epoch 1502/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4125 - val_loss: 1.3093 - val_accuracy: 0.4179

Epoch 01502: val_loss did not improve from 1.30535
Epoch 1503/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4126 - val_loss: 1.3072 - val_accuracy: 0.4179

Epoch 01503: val_loss did not improve from 1.30535
Epoch 1504/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4098 - val_loss: 1.3094 - val_accuracy: 0.4211

Epoch 01504: val_loss did not improve from 1.30535
Epoch 1505/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4066 - val_loss: 1.3048 - val_accuracy: 0.4258

Epoch 01505: val_loss improved from 1.30535 to 1.30482, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1506/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4075 - val_loss: 1.3055 - val_accuracy: 0.4250

Epoch 01506: val_loss did not improve from 1.30482
Epoch 1507/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4107 - val_loss: 1.3059 - val_accuracy: 0.4234

Epoch 01507: val_loss did not improve from 1.30482
Epoch 1508/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4082 - val_loss: 1.3080 - val_accuracy: 0.4242

Epoch 01508: val_loss did not improve from 1.30482
Epoch 1509/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4062 - val_loss: 1.3079 - val_accuracy: 0.4179

Epoch 01509: val_loss did not improve from 1.30482
Epoch 1510/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4095 - val_loss: 1.3067 - val_accuracy: 0.4219

Epoch 01510: val_loss did not improve from 1.30482
Epoch 1511/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4125 - val_loss: 1.3110 - val_accuracy: 0.4219

Epoch 01511: val_loss did not improve from 1.30482
Epoch 1512/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4117 - val_loss: 1.3056 - val_accuracy: 0.4187

Epoch 01512: val_loss did not improve from 1.30482
Epoch 1513/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4086 - val_loss: 1.3062 - val_accuracy: 0.4266

Epoch 01513: val_loss did not improve from 1.30482
Epoch 1514/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4100 - val_loss: 1.3064 - val_accuracy: 0.4203

Epoch 01514: val_loss did not improve from 1.30482
Epoch 1515/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4117 - val_loss: 1.3092 - val_accuracy: 0.4203

Epoch 01515: val_loss did not improve from 1.30482
Epoch 1516/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4092 - val_loss: 1.3065 - val_accuracy: 0.4195

Epoch 01516: val_loss did not improve from 1.30482
Epoch 1517/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4108 - val_loss: 1.3070 - val_accuracy: 0.4274

Epoch 01517: val_loss did not improve from 1.30482
Epoch 1518/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4093 - val_loss: 1.3054 - val_accuracy: 0.4219

Epoch 01518: val_loss did not improve from 1.30482
Epoch 1519/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4081 - val_loss: 1.3070 - val_accuracy: 0.4203

Epoch 01519: val_loss did not improve from 1.30482
Epoch 1520/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4113 - val_loss: 1.3099 - val_accuracy: 0.4139

Epoch 01520: val_loss did not improve from 1.30482
Epoch 1521/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4055 - val_loss: 1.3077 - val_accuracy: 0.4147

Epoch 01521: val_loss did not improve from 1.30482
Epoch 1522/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4098 - val_loss: 1.3078 - val_accuracy: 0.4187

Epoch 01522: val_loss did not improve from 1.30482
Epoch 1523/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4103 - val_loss: 1.3096 - val_accuracy: 0.4139

Epoch 01523: val_loss did not improve from 1.30482
Epoch 1524/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4062 - val_loss: 1.3083 - val_accuracy: 0.4219

Epoch 01524: val_loss did not improve from 1.30482
Epoch 1525/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4122 - val_loss: 1.3107 - val_accuracy: 0.4163

Epoch 01525: val_loss did not improve from 1.30482
Epoch 1526/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4070 - val_loss: 1.3075 - val_accuracy: 0.4219

Epoch 01526: val_loss did not improve from 1.30482
Epoch 1527/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4132 - val_loss: 1.3084 - val_accuracy: 0.4195

Epoch 01527: val_loss did not improve from 1.30482
Epoch 1528/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4100 - val_loss: 1.3074 - val_accuracy: 0.4211

Epoch 01528: val_loss did not improve from 1.30482
Epoch 1529/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4063 - val_loss: 1.3089 - val_accuracy: 0.4250

Epoch 01529: val_loss did not improve from 1.30482
Epoch 1530/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4086 - val_loss: 1.3086 - val_accuracy: 0.4234

Epoch 01530: val_loss did not improve from 1.30482
Epoch 1531/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4094 - val_loss: 1.3080 - val_accuracy: 0.4139

Epoch 01531: val_loss did not improve from 1.30482
Epoch 1532/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4120 - val_loss: 1.3083 - val_accuracy: 0.4123

Epoch 01532: val_loss did not improve from 1.30482
Epoch 1533/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4093 - val_loss: 1.3093 - val_accuracy: 0.4147

Epoch 01533: val_loss did not improve from 1.30482
Epoch 1534/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4127 - val_loss: 1.3102 - val_accuracy: 0.4187

Epoch 01534: val_loss did not improve from 1.30482
Epoch 1535/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4107 - val_loss: 1.3065 - val_accuracy: 0.4250

Epoch 01535: val_loss did not improve from 1.30482
Epoch 1536/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4128 - val_loss: 1.3077 - val_accuracy: 0.4195

Epoch 01536: val_loss did not improve from 1.30482
Epoch 1537/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4130 - val_loss: 1.3068 - val_accuracy: 0.4226

Epoch 01537: val_loss did not improve from 1.30482
Epoch 1538/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4113 - val_loss: 1.3094 - val_accuracy: 0.4195

Epoch 01538: val_loss did not improve from 1.30482
Epoch 1539/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4033 - val_loss: 1.3090 - val_accuracy: 0.4179

Epoch 01539: val_loss did not improve from 1.30482
Epoch 1540/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4094 - val_loss: 1.3071 - val_accuracy: 0.4115

Epoch 01540: val_loss did not improve from 1.30482
Epoch 1541/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4110 - val_loss: 1.3094 - val_accuracy: 0.4219

Epoch 01541: val_loss did not improve from 1.30482
Epoch 1542/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4093 - val_loss: 1.3070 - val_accuracy: 0.4219

Epoch 01542: val_loss did not improve from 1.30482
Epoch 1543/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4059 - val_loss: 1.3064 - val_accuracy: 0.4147

Epoch 01543: val_loss did not improve from 1.30482
Epoch 1544/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4107 - val_loss: 1.3140 - val_accuracy: 0.4187

Epoch 01544: val_loss did not improve from 1.30482
Epoch 1545/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4097 - val_loss: 1.3100 - val_accuracy: 0.4258

Epoch 01545: val_loss did not improve from 1.30482
Epoch 1546/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4099 - val_loss: 1.3107 - val_accuracy: 0.4163

Epoch 01546: val_loss did not improve from 1.30482
Epoch 1547/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4093 - val_loss: 1.3079 - val_accuracy: 0.4219

Epoch 01547: val_loss did not improve from 1.30482
Epoch 1548/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4095 - val_loss: 1.3052 - val_accuracy: 0.4211

Epoch 01548: val_loss did not improve from 1.30482
Epoch 1549/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4097 - val_loss: 1.3059 - val_accuracy: 0.4179

Epoch 01549: val_loss did not improve from 1.30482
Epoch 1550/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4121 - val_loss: 1.3040 - val_accuracy: 0.4211

Epoch 01550: val_loss improved from 1.30482 to 1.30400, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1551/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4124 - val_loss: 1.3084 - val_accuracy: 0.4171

Epoch 01551: val_loss did not improve from 1.30400
Epoch 1552/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4081 - val_loss: 1.3067 - val_accuracy: 0.4234

Epoch 01552: val_loss did not improve from 1.30400
Epoch 1553/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4146 - val_loss: 1.3087 - val_accuracy: 0.4203

Epoch 01553: val_loss did not improve from 1.30400
Epoch 1554/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4077 - val_loss: 1.3063 - val_accuracy: 0.4163

Epoch 01554: val_loss did not improve from 1.30400
Epoch 1555/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4107 - val_loss: 1.3049 - val_accuracy: 0.4187

Epoch 01555: val_loss did not improve from 1.30400
Epoch 1556/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4116 - val_loss: 1.3050 - val_accuracy: 0.4131

Epoch 01556: val_loss did not improve from 1.30400
Epoch 1557/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4123 - val_loss: 1.3093 - val_accuracy: 0.4203

Epoch 01557: val_loss did not improve from 1.30400
Epoch 1558/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4068 - val_loss: 1.3067 - val_accuracy: 0.4035

Epoch 01558: val_loss did not improve from 1.30400
Epoch 1559/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4098 - val_loss: 1.3085 - val_accuracy: 0.4163

Epoch 01559: val_loss did not improve from 1.30400
Epoch 1560/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4066 - val_loss: 1.3059 - val_accuracy: 0.4211

Epoch 01560: val_loss did not improve from 1.30400
Epoch 1561/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4122 - val_loss: 1.3060 - val_accuracy: 0.4211

Epoch 01561: val_loss did not improve from 1.30400
Epoch 1562/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4089 - val_loss: 1.3076 - val_accuracy: 0.4250

Epoch 01562: val_loss did not improve from 1.30400
Epoch 1563/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4101 - val_loss: 1.3089 - val_accuracy: 0.4234

Epoch 01563: val_loss did not improve from 1.30400
Epoch 1564/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4097 - val_loss: 1.3080 - val_accuracy: 0.4242

Epoch 01564: val_loss did not improve from 1.30400
Epoch 1565/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4105 - val_loss: 1.3069 - val_accuracy: 0.4171

Epoch 01565: val_loss did not improve from 1.30400
Epoch 1566/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4094 - val_loss: 1.3072 - val_accuracy: 0.4250

Epoch 01566: val_loss did not improve from 1.30400
Epoch 1567/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4139 - val_loss: 1.3143 - val_accuracy: 0.4219

Epoch 01567: val_loss did not improve from 1.30400
Epoch 1568/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4047 - val_loss: 1.3074 - val_accuracy: 0.4250

Epoch 01568: val_loss did not improve from 1.30400
Epoch 1569/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4101 - val_loss: 1.3083 - val_accuracy: 0.4219

Epoch 01569: val_loss did not improve from 1.30400
Epoch 1570/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4107 - val_loss: 1.3039 - val_accuracy: 0.4179

Epoch 01570: val_loss improved from 1.30400 to 1.30390, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1571/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4054 - val_loss: 1.3041 - val_accuracy: 0.4195

Epoch 01571: val_loss did not improve from 1.30390
Epoch 1572/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4119 - val_loss: 1.3065 - val_accuracy: 0.4195

Epoch 01572: val_loss did not improve from 1.30390
Epoch 1573/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4108 - val_loss: 1.3054 - val_accuracy: 0.4123

Epoch 01573: val_loss did not improve from 1.30390
Epoch 1574/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4118 - val_loss: 1.3062 - val_accuracy: 0.4171

Epoch 01574: val_loss did not improve from 1.30390
Epoch 1575/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4100 - val_loss: 1.3034 - val_accuracy: 0.4179

Epoch 01575: val_loss improved from 1.30390 to 1.30341, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1576/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4136 - val_loss: 1.3053 - val_accuracy: 0.4211

Epoch 01576: val_loss did not improve from 1.30341
Epoch 1577/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4066 - val_loss: 1.3051 - val_accuracy: 0.4258

Epoch 01577: val_loss did not improve from 1.30341
Epoch 1578/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4129 - val_loss: 1.3027 - val_accuracy: 0.4234

Epoch 01578: val_loss improved from 1.30341 to 1.30268, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1579/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4132 - val_loss: 1.3056 - val_accuracy: 0.4171

Epoch 01579: val_loss did not improve from 1.30268
Epoch 1580/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4111 - val_loss: 1.3059 - val_accuracy: 0.4179

Epoch 01580: val_loss did not improve from 1.30268
Epoch 1581/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4125 - val_loss: 1.3054 - val_accuracy: 0.4211

Epoch 01581: val_loss did not improve from 1.30268
Epoch 1582/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4140 - val_loss: 1.3045 - val_accuracy: 0.4219

Epoch 01582: val_loss did not improve from 1.30268
Epoch 1583/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4148 - val_loss: 1.3056 - val_accuracy: 0.4282

Epoch 01583: val_loss did not improve from 1.30268
Epoch 1584/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4109 - val_loss: 1.3048 - val_accuracy: 0.4203

Epoch 01584: val_loss did not improve from 1.30268
Epoch 1585/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4097 - val_loss: 1.3048 - val_accuracy: 0.4147

Epoch 01585: val_loss did not improve from 1.30268
Epoch 1586/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4129 - val_loss: 1.3064 - val_accuracy: 0.4211

Epoch 01586: val_loss did not improve from 1.30268
Epoch 1587/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4124 - val_loss: 1.3074 - val_accuracy: 0.4171

Epoch 01587: val_loss did not improve from 1.30268
Epoch 1588/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4117 - val_loss: 1.3055 - val_accuracy: 0.4139

Epoch 01588: val_loss did not improve from 1.30268
Epoch 1589/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4104 - val_loss: 1.3070 - val_accuracy: 0.4155

Epoch 01589: val_loss did not improve from 1.30268
Epoch 1590/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4125 - val_loss: 1.3049 - val_accuracy: 0.4123

Epoch 01590: val_loss did not improve from 1.30268
Epoch 1591/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4095 - val_loss: 1.3048 - val_accuracy: 0.4187

Epoch 01591: val_loss did not improve from 1.30268
Epoch 1592/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4123 - val_loss: 1.3044 - val_accuracy: 0.4219

Epoch 01592: val_loss did not improve from 1.30268
Epoch 1593/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4124 - val_loss: 1.3045 - val_accuracy: 0.4195

Epoch 01593: val_loss did not improve from 1.30268
Epoch 1594/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4132 - val_loss: 1.3037 - val_accuracy: 0.4219

Epoch 01594: val_loss did not improve from 1.30268
Epoch 1595/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4132 - val_loss: 1.3046 - val_accuracy: 0.4179

Epoch 01595: val_loss did not improve from 1.30268
Epoch 1596/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4111 - val_loss: 1.3060 - val_accuracy: 0.4187

Epoch 01596: val_loss did not improve from 1.30268
Epoch 1597/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4124 - val_loss: 1.3045 - val_accuracy: 0.4219

Epoch 01597: val_loss did not improve from 1.30268
Epoch 1598/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4102 - val_loss: 1.3081 - val_accuracy: 0.4163

Epoch 01598: val_loss did not improve from 1.30268
Epoch 1599/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4066 - val_loss: 1.3059 - val_accuracy: 0.4250

Epoch 01599: val_loss did not improve from 1.30268
Epoch 1600/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4114 - val_loss: 1.3099 - val_accuracy: 0.4266

Epoch 01600: val_loss did not improve from 1.30268
Epoch 1601/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4122 - val_loss: 1.3042 - val_accuracy: 0.4234

Epoch 01601: val_loss did not improve from 1.30268
Epoch 1602/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4140 - val_loss: 1.3027 - val_accuracy: 0.4330

Epoch 01602: val_loss improved from 1.30268 to 1.30266, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1603/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4112 - val_loss: 1.3024 - val_accuracy: 0.4354

Epoch 01603: val_loss improved from 1.30266 to 1.30239, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1604/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4121 - val_loss: 1.3032 - val_accuracy: 0.4330

Epoch 01604: val_loss did not improve from 1.30239
Epoch 1605/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4124 - val_loss: 1.3083 - val_accuracy: 0.4187

Epoch 01605: val_loss did not improve from 1.30239
Epoch 1606/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4110 - val_loss: 1.3024 - val_accuracy: 0.4163

Epoch 01606: val_loss improved from 1.30239 to 1.30236, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1607/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4171 - val_loss: 1.3052 - val_accuracy: 0.4290

Epoch 01607: val_loss did not improve from 1.30236
Epoch 1608/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4138 - val_loss: 1.3038 - val_accuracy: 0.4250

Epoch 01608: val_loss did not improve from 1.30236
Epoch 1609/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4129 - val_loss: 1.3037 - val_accuracy: 0.4211

Epoch 01609: val_loss did not improve from 1.30236
Epoch 1610/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4154 - val_loss: 1.3107 - val_accuracy: 0.4179

Epoch 01610: val_loss did not improve from 1.30236
Epoch 1611/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4067 - val_loss: 1.3073 - val_accuracy: 0.4234

Epoch 01611: val_loss did not improve from 1.30236
Epoch 1612/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4125 - val_loss: 1.3099 - val_accuracy: 0.4171

Epoch 01612: val_loss did not improve from 1.30236
Epoch 1613/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4101 - val_loss: 1.3040 - val_accuracy: 0.4226

Epoch 01613: val_loss did not improve from 1.30236
Epoch 1614/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4110 - val_loss: 1.3021 - val_accuracy: 0.4195

Epoch 01614: val_loss improved from 1.30236 to 1.30208, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1615/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4124 - val_loss: 1.3031 - val_accuracy: 0.4226

Epoch 01615: val_loss did not improve from 1.30208
Epoch 1616/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4133 - val_loss: 1.3058 - val_accuracy: 0.4219

Epoch 01616: val_loss did not improve from 1.30208
Epoch 1617/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4090 - val_loss: 1.3044 - val_accuracy: 0.4195

Epoch 01617: val_loss did not improve from 1.30208
Epoch 1618/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4107 - val_loss: 1.3028 - val_accuracy: 0.4187

Epoch 01618: val_loss did not improve from 1.30208
Epoch 1619/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4164 - val_loss: 1.3049 - val_accuracy: 0.4203

Epoch 01619: val_loss did not improve from 1.30208
Epoch 1620/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4172 - val_loss: 1.3022 - val_accuracy: 0.4147

Epoch 01620: val_loss did not improve from 1.30208
Epoch 1621/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4104 - val_loss: 1.3016 - val_accuracy: 0.4203

Epoch 01621: val_loss improved from 1.30208 to 1.30161, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1622/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4158 - val_loss: 1.3064 - val_accuracy: 0.4171

Epoch 01622: val_loss did not improve from 1.30161
Epoch 1623/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4140 - val_loss: 1.3047 - val_accuracy: 0.4187

Epoch 01623: val_loss did not improve from 1.30161
Epoch 1624/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4125 - val_loss: 1.3035 - val_accuracy: 0.4203

Epoch 01624: val_loss did not improve from 1.30161
Epoch 1625/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4101 - val_loss: 1.3045 - val_accuracy: 0.4290

Epoch 01625: val_loss did not improve from 1.30161
Epoch 1626/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4143 - val_loss: 1.3085 - val_accuracy: 0.4282

Epoch 01626: val_loss did not improve from 1.30161
Epoch 1627/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4085 - val_loss: 1.3075 - val_accuracy: 0.4298

Epoch 01627: val_loss did not improve from 1.30161
Epoch 1628/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4125 - val_loss: 1.3091 - val_accuracy: 0.4211

Epoch 01628: val_loss did not improve from 1.30161
Epoch 1629/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4124 - val_loss: 1.3039 - val_accuracy: 0.4203

Epoch 01629: val_loss did not improve from 1.30161
Epoch 1630/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4111 - val_loss: 1.3061 - val_accuracy: 0.4266

Epoch 01630: val_loss did not improve from 1.30161
Epoch 1631/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4161 - val_loss: 1.3045 - val_accuracy: 0.4234

Epoch 01631: val_loss did not improve from 1.30161
Epoch 1632/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4135 - val_loss: 1.3035 - val_accuracy: 0.4226

Epoch 01632: val_loss did not improve from 1.30161
Epoch 1633/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4140 - val_loss: 1.3038 - val_accuracy: 0.4107

Epoch 01633: val_loss did not improve from 1.30161
Epoch 1634/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4132 - val_loss: 1.3032 - val_accuracy: 0.4123

Epoch 01634: val_loss did not improve from 1.30161
Epoch 1635/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4147 - val_loss: 1.3038 - val_accuracy: 0.4211

Epoch 01635: val_loss did not improve from 1.30161
Epoch 1636/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4140 - val_loss: 1.3028 - val_accuracy: 0.4219

Epoch 01636: val_loss did not improve from 1.30161
Epoch 1637/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4096 - val_loss: 1.3023 - val_accuracy: 0.4306

Epoch 01637: val_loss did not improve from 1.30161
Epoch 1638/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4115 - val_loss: 1.3090 - val_accuracy: 0.4226

Epoch 01638: val_loss did not improve from 1.30161
Epoch 1639/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4036 - val_loss: 1.3063 - val_accuracy: 0.4274

Epoch 01639: val_loss did not improve from 1.30161
Epoch 1640/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4146 - val_loss: 1.3047 - val_accuracy: 0.4203

Epoch 01640: val_loss did not improve from 1.30161
Epoch 1641/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4139 - val_loss: 1.3058 - val_accuracy: 0.4203

Epoch 01641: val_loss did not improve from 1.30161
Epoch 1642/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4092 - val_loss: 1.3033 - val_accuracy: 0.4234

Epoch 01642: val_loss did not improve from 1.30161
Epoch 1643/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4158 - val_loss: 1.3056 - val_accuracy: 0.4195

Epoch 01643: val_loss did not improve from 1.30161
Epoch 1644/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4153 - val_loss: 1.3024 - val_accuracy: 0.4139

Epoch 01644: val_loss did not improve from 1.30161
Epoch 1645/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4082 - val_loss: 1.3052 - val_accuracy: 0.4075

Epoch 01645: val_loss did not improve from 1.30161
Epoch 1646/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4164 - val_loss: 1.3104 - val_accuracy: 0.4226

Epoch 01646: val_loss did not improve from 1.30161
Epoch 1647/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4109 - val_loss: 1.3041 - val_accuracy: 0.4219

Epoch 01647: val_loss did not improve from 1.30161
Epoch 1648/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4130 - val_loss: 1.3027 - val_accuracy: 0.4290

Epoch 01648: val_loss did not improve from 1.30161
Epoch 1649/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4155 - val_loss: 1.3051 - val_accuracy: 0.4195

Epoch 01649: val_loss did not improve from 1.30161
Epoch 1650/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4109 - val_loss: 1.3028 - val_accuracy: 0.4115

Epoch 01650: val_loss did not improve from 1.30161
Epoch 1651/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4138 - val_loss: 1.3083 - val_accuracy: 0.4234

Epoch 01651: val_loss did not improve from 1.30161
Epoch 1652/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4117 - val_loss: 1.3054 - val_accuracy: 0.4282

Epoch 01652: val_loss did not improve from 1.30161
Epoch 1653/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4154 - val_loss: 1.3046 - val_accuracy: 0.4211

Epoch 01653: val_loss did not improve from 1.30161
Epoch 1654/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4136 - val_loss: 1.3038 - val_accuracy: 0.4266

Epoch 01654: val_loss did not improve from 1.30161
Epoch 1655/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4088 - val_loss: 1.3014 - val_accuracy: 0.4211

Epoch 01655: val_loss improved from 1.30161 to 1.30138, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1656/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4174 - val_loss: 1.3050 - val_accuracy: 0.4242

Epoch 01656: val_loss did not improve from 1.30138
Epoch 1657/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4132 - val_loss: 1.3037 - val_accuracy: 0.4211

Epoch 01657: val_loss did not improve from 1.30138
Epoch 1658/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4131 - val_loss: 1.3019 - val_accuracy: 0.4171

Epoch 01658: val_loss did not improve from 1.30138
Epoch 1659/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4136 - val_loss: 1.3018 - val_accuracy: 0.4242

Epoch 01659: val_loss did not improve from 1.30138
Epoch 1660/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4121 - val_loss: 1.3046 - val_accuracy: 0.4123

Epoch 01660: val_loss did not improve from 1.30138
Epoch 1661/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4117 - val_loss: 1.3011 - val_accuracy: 0.4171

Epoch 01661: val_loss improved from 1.30138 to 1.30112, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1662/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4171 - val_loss: 1.3042 - val_accuracy: 0.4211

Epoch 01662: val_loss did not improve from 1.30112
Epoch 1663/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4129 - val_loss: 1.3064 - val_accuracy: 0.4195

Epoch 01663: val_loss did not improve from 1.30112
Epoch 1664/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4117 - val_loss: 1.3036 - val_accuracy: 0.4258

Epoch 01664: val_loss did not improve from 1.30112
Epoch 1665/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4148 - val_loss: 1.3047 - val_accuracy: 0.4234

Epoch 01665: val_loss did not improve from 1.30112
Epoch 1666/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4125 - val_loss: 1.3063 - val_accuracy: 0.4266

Epoch 01666: val_loss did not improve from 1.30112
Epoch 1667/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4111 - val_loss: 1.3010 - val_accuracy: 0.4179

Epoch 01667: val_loss improved from 1.30112 to 1.30096, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1668/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4143 - val_loss: 1.3031 - val_accuracy: 0.4266

Epoch 01668: val_loss did not improve from 1.30096
Epoch 1669/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4152 - val_loss: 1.3060 - val_accuracy: 0.4266

Epoch 01669: val_loss did not improve from 1.30096
Epoch 1670/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4152 - val_loss: 1.3027 - val_accuracy: 0.4219

Epoch 01670: val_loss did not improve from 1.30096
Epoch 1671/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4148 - val_loss: 1.3039 - val_accuracy: 0.4242

Epoch 01671: val_loss did not improve from 1.30096
Epoch 1672/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4116 - val_loss: 1.3027 - val_accuracy: 0.4203

Epoch 01672: val_loss did not improve from 1.30096
Epoch 1673/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4133 - val_loss: 1.3020 - val_accuracy: 0.4211

Epoch 01673: val_loss did not improve from 1.30096
Epoch 1674/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4125 - val_loss: 1.3012 - val_accuracy: 0.4250

Epoch 01674: val_loss did not improve from 1.30096
Epoch 1675/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4160 - val_loss: 1.3040 - val_accuracy: 0.4282

Epoch 01675: val_loss did not improve from 1.30096
Epoch 1676/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4155 - val_loss: 1.3005 - val_accuracy: 0.4258

Epoch 01676: val_loss improved from 1.30096 to 1.30052, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1677/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4148 - val_loss: 1.3015 - val_accuracy: 0.4234

Epoch 01677: val_loss did not improve from 1.30052
Epoch 1678/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4177 - val_loss: 1.3023 - val_accuracy: 0.4163

Epoch 01678: val_loss did not improve from 1.30052
Epoch 1679/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4137 - val_loss: 1.3006 - val_accuracy: 0.4179

Epoch 01679: val_loss did not improve from 1.30052
Epoch 1680/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4117 - val_loss: 1.3010 - val_accuracy: 0.4155

Epoch 01680: val_loss did not improve from 1.30052
Epoch 1681/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4123 - val_loss: 1.3046 - val_accuracy: 0.4171

Epoch 01681: val_loss did not improve from 1.30052
Epoch 1682/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4194 - val_loss: 1.3061 - val_accuracy: 0.4258

Epoch 01682: val_loss did not improve from 1.30052
Epoch 1683/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4136 - val_loss: 1.3038 - val_accuracy: 0.4219

Epoch 01683: val_loss did not improve from 1.30052
Epoch 1684/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4122 - val_loss: 1.3025 - val_accuracy: 0.4219

Epoch 01684: val_loss did not improve from 1.30052
Epoch 1685/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4159 - val_loss: 1.3047 - val_accuracy: 0.4242

Epoch 01685: val_loss did not improve from 1.30052
Epoch 1686/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4157 - val_loss: 1.3039 - val_accuracy: 0.4290

Epoch 01686: val_loss did not improve from 1.30052
Epoch 1687/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4131 - val_loss: 1.3019 - val_accuracy: 0.4290

Epoch 01687: val_loss did not improve from 1.30052
Epoch 1688/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4194 - val_loss: 1.3035 - val_accuracy: 0.4211

Epoch 01688: val_loss did not improve from 1.30052
Epoch 1689/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4134 - val_loss: 1.3021 - val_accuracy: 0.4219

Epoch 01689: val_loss did not improve from 1.30052
Epoch 1690/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4134 - val_loss: 1.2999 - val_accuracy: 0.4226

Epoch 01690: val_loss improved from 1.30052 to 1.29991, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1691/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4174 - val_loss: 1.3008 - val_accuracy: 0.4306

Epoch 01691: val_loss did not improve from 1.29991
Epoch 1692/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4156 - val_loss: 1.3010 - val_accuracy: 0.4203

Epoch 01692: val_loss did not improve from 1.29991
Epoch 1693/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4174 - val_loss: 1.3031 - val_accuracy: 0.4226

Epoch 01693: val_loss did not improve from 1.29991
Epoch 1694/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4121 - val_loss: 1.3030 - val_accuracy: 0.4258

Epoch 01694: val_loss did not improve from 1.29991
Epoch 1695/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4172 - val_loss: 1.3064 - val_accuracy: 0.4234

Epoch 01695: val_loss did not improve from 1.29991
Epoch 1696/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4098 - val_loss: 1.3034 - val_accuracy: 0.4195

Epoch 01696: val_loss did not improve from 1.29991
Epoch 1697/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4177 - val_loss: 1.3037 - val_accuracy: 0.4226

Epoch 01697: val_loss did not improve from 1.29991
Epoch 1698/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4188 - val_loss: 1.3024 - val_accuracy: 0.4226

Epoch 01698: val_loss did not improve from 1.29991
Epoch 1699/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4124 - val_loss: 1.3027 - val_accuracy: 0.4330

Epoch 01699: val_loss did not improve from 1.29991
Epoch 1700/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4166 - val_loss: 1.3012 - val_accuracy: 0.4298

Epoch 01700: val_loss did not improve from 1.29991
Epoch 1701/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4191 - val_loss: 1.3019 - val_accuracy: 0.4306

Epoch 01701: val_loss did not improve from 1.29991
Epoch 1702/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4097 - val_loss: 1.3023 - val_accuracy: 0.4203

Epoch 01702: val_loss did not improve from 1.29991
Epoch 1703/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4150 - val_loss: 1.3055 - val_accuracy: 0.4219

Epoch 01703: val_loss did not improve from 1.29991
Epoch 1704/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4165 - val_loss: 1.3030 - val_accuracy: 0.4187

Epoch 01704: val_loss did not improve from 1.29991
Epoch 1705/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4165 - val_loss: 1.3041 - val_accuracy: 0.4163

Epoch 01705: val_loss did not improve from 1.29991
Epoch 1706/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4155 - val_loss: 1.3030 - val_accuracy: 0.4187

Epoch 01706: val_loss did not improve from 1.29991
Epoch 1707/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4165 - val_loss: 1.3022 - val_accuracy: 0.4187

Epoch 01707: val_loss did not improve from 1.29991
Epoch 1708/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4186 - val_loss: 1.3034 - val_accuracy: 0.4282

Epoch 01708: val_loss did not improve from 1.29991
Epoch 1709/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4180 - val_loss: 1.3015 - val_accuracy: 0.4211

Epoch 01709: val_loss did not improve from 1.29991
Epoch 1710/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4176 - val_loss: 1.3037 - val_accuracy: 0.4091

Epoch 01710: val_loss did not improve from 1.29991
Epoch 1711/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4168 - val_loss: 1.3020 - val_accuracy: 0.4171

Epoch 01711: val_loss did not improve from 1.29991
Epoch 1712/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4150 - val_loss: 1.3008 - val_accuracy: 0.4203

Epoch 01712: val_loss did not improve from 1.29991
Epoch 1713/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4182 - val_loss: 1.3017 - val_accuracy: 0.4362

Epoch 01713: val_loss did not improve from 1.29991
Epoch 1714/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4188 - val_loss: 1.2992 - val_accuracy: 0.4234

Epoch 01714: val_loss improved from 1.29991 to 1.29918, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1715/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4178 - val_loss: 1.3019 - val_accuracy: 0.4187

Epoch 01715: val_loss did not improve from 1.29918
Epoch 1716/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4140 - val_loss: 1.2988 - val_accuracy: 0.4346

Epoch 01716: val_loss improved from 1.29918 to 1.29885, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1717/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4159 - val_loss: 1.3005 - val_accuracy: 0.4187

Epoch 01717: val_loss did not improve from 1.29885
Epoch 1718/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4161 - val_loss: 1.3024 - val_accuracy: 0.4266

Epoch 01718: val_loss did not improve from 1.29885
Epoch 1719/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4173 - val_loss: 1.3019 - val_accuracy: 0.4187

Epoch 01719: val_loss did not improve from 1.29885
Epoch 1720/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4172 - val_loss: 1.3002 - val_accuracy: 0.4314

Epoch 01720: val_loss did not improve from 1.29885
Epoch 1721/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4125 - val_loss: 1.3003 - val_accuracy: 0.4394

Epoch 01721: val_loss did not improve from 1.29885
Epoch 1722/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4202 - val_loss: 1.3011 - val_accuracy: 0.4290

Epoch 01722: val_loss did not improve from 1.29885
Epoch 1723/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4174 - val_loss: 1.3003 - val_accuracy: 0.4211

Epoch 01723: val_loss did not improve from 1.29885
Epoch 1724/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4180 - val_loss: 1.3011 - val_accuracy: 0.4274

Epoch 01724: val_loss did not improve from 1.29885
Epoch 1725/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4198 - val_loss: 1.3061 - val_accuracy: 0.4179

Epoch 01725: val_loss did not improve from 1.29885
Epoch 1726/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4179 - val_loss: 1.2989 - val_accuracy: 0.4211

Epoch 01726: val_loss did not improve from 1.29885
Epoch 1727/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4142 - val_loss: 1.3030 - val_accuracy: 0.4195

Epoch 01727: val_loss did not improve from 1.29885
Epoch 1728/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4192 - val_loss: 1.3065 - val_accuracy: 0.4163

Epoch 01728: val_loss did not improve from 1.29885
Epoch 1729/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4148 - val_loss: 1.3019 - val_accuracy: 0.4226

Epoch 01729: val_loss did not improve from 1.29885
Epoch 1730/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4172 - val_loss: 1.3018 - val_accuracy: 0.4171

Epoch 01730: val_loss did not improve from 1.29885
Epoch 1731/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4207 - val_loss: 1.3044 - val_accuracy: 0.4203

Epoch 01731: val_loss did not improve from 1.29885
Epoch 1732/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4140 - val_loss: 1.3024 - val_accuracy: 0.4171

Epoch 01732: val_loss did not improve from 1.29885
Epoch 1733/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4155 - val_loss: 1.3037 - val_accuracy: 0.4067

Epoch 01733: val_loss did not improve from 1.29885
Epoch 1734/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4149 - val_loss: 1.3018 - val_accuracy: 0.4203

Epoch 01734: val_loss did not improve from 1.29885
Epoch 1735/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4204 - val_loss: 1.3011 - val_accuracy: 0.4187

Epoch 01735: val_loss did not improve from 1.29885
Epoch 1736/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4169 - val_loss: 1.3012 - val_accuracy: 0.4242

Epoch 01736: val_loss did not improve from 1.29885
Epoch 1737/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4154 - val_loss: 1.3019 - val_accuracy: 0.4354

Epoch 01737: val_loss did not improve from 1.29885
Epoch 1738/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4130 - val_loss: 1.3052 - val_accuracy: 0.4250

Epoch 01738: val_loss did not improve from 1.29885
Epoch 1739/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4202 - val_loss: 1.3027 - val_accuracy: 0.4298

Epoch 01739: val_loss did not improve from 1.29885
Epoch 1740/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4216 - val_loss: 1.3031 - val_accuracy: 0.4290

Epoch 01740: val_loss did not improve from 1.29885
Epoch 1741/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4215 - val_loss: 1.3000 - val_accuracy: 0.4274

Epoch 01741: val_loss did not improve from 1.29885
Epoch 1742/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4202 - val_loss: 1.3009 - val_accuracy: 0.4250

Epoch 01742: val_loss did not improve from 1.29885
Epoch 1743/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4171 - val_loss: 1.2992 - val_accuracy: 0.4290

Epoch 01743: val_loss did not improve from 1.29885
Epoch 1744/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4192 - val_loss: 1.3013 - val_accuracy: 0.4354

Epoch 01744: val_loss did not improve from 1.29885
Epoch 1745/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4182 - val_loss: 1.2988 - val_accuracy: 0.4338

Epoch 01745: val_loss improved from 1.29885 to 1.29883, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1746/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4146 - val_loss: 1.3004 - val_accuracy: 0.4203

Epoch 01746: val_loss did not improve from 1.29883
Epoch 1747/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4219 - val_loss: 1.3009 - val_accuracy: 0.4290

Epoch 01747: val_loss did not improve from 1.29883
Epoch 1748/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4210 - val_loss: 1.3005 - val_accuracy: 0.4226

Epoch 01748: val_loss did not improve from 1.29883
Epoch 1749/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4187 - val_loss: 1.2989 - val_accuracy: 0.4346

Epoch 01749: val_loss did not improve from 1.29883
Epoch 1750/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4161 - val_loss: 1.2985 - val_accuracy: 0.4282

Epoch 01750: val_loss improved from 1.29883 to 1.29852, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1751/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4171 - val_loss: 1.2982 - val_accuracy: 0.4322

Epoch 01751: val_loss improved from 1.29852 to 1.29823, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1752/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4187 - val_loss: 1.3005 - val_accuracy: 0.4338

Epoch 01752: val_loss did not improve from 1.29823
Epoch 1753/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4201 - val_loss: 1.2999 - val_accuracy: 0.4346

Epoch 01753: val_loss did not improve from 1.29823
Epoch 1754/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4172 - val_loss: 1.3008 - val_accuracy: 0.4306

Epoch 01754: val_loss did not improve from 1.29823
Epoch 1755/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4164 - val_loss: 1.2994 - val_accuracy: 0.4211

Epoch 01755: val_loss did not improve from 1.29823
Epoch 1756/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4206 - val_loss: 1.3006 - val_accuracy: 0.4322

Epoch 01756: val_loss did not improve from 1.29823
Epoch 1757/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4209 - val_loss: 1.3007 - val_accuracy: 0.4250

Epoch 01757: val_loss did not improve from 1.29823
Epoch 1758/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4225 - val_loss: 1.2983 - val_accuracy: 0.4314

Epoch 01758: val_loss did not improve from 1.29823
Epoch 1759/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4183 - val_loss: 1.3008 - val_accuracy: 0.4226

Epoch 01759: val_loss did not improve from 1.29823
Epoch 1760/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4139 - val_loss: 1.2997 - val_accuracy: 0.4362

Epoch 01760: val_loss did not improve from 1.29823
Epoch 1761/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4208 - val_loss: 1.3033 - val_accuracy: 0.4242

Epoch 01761: val_loss did not improve from 1.29823
Epoch 1762/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4204 - val_loss: 1.2989 - val_accuracy: 0.4250

Epoch 01762: val_loss did not improve from 1.29823
Epoch 1763/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4213 - val_loss: 1.3014 - val_accuracy: 0.4306

Epoch 01763: val_loss did not improve from 1.29823
Epoch 1764/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4201 - val_loss: 1.2993 - val_accuracy: 0.4242

Epoch 01764: val_loss did not improve from 1.29823
Epoch 1765/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4233 - val_loss: 1.3026 - val_accuracy: 0.4250

Epoch 01765: val_loss did not improve from 1.29823
Epoch 1766/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4216 - val_loss: 1.3022 - val_accuracy: 0.4203

Epoch 01766: val_loss did not improve from 1.29823
Epoch 1767/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4229 - val_loss: 1.3083 - val_accuracy: 0.4266

Epoch 01767: val_loss did not improve from 1.29823
Epoch 1768/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4232 - val_loss: 1.3016 - val_accuracy: 0.4203

Epoch 01768: val_loss did not improve from 1.29823
Epoch 1769/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4163 - val_loss: 1.2985 - val_accuracy: 0.4234

Epoch 01769: val_loss did not improve from 1.29823
Epoch 1770/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4211 - val_loss: 1.2994 - val_accuracy: 0.4282

Epoch 01770: val_loss did not improve from 1.29823
Epoch 1771/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4235 - val_loss: 1.2988 - val_accuracy: 0.4274

Epoch 01771: val_loss did not improve from 1.29823
Epoch 1772/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4193 - val_loss: 1.2982 - val_accuracy: 0.4211

Epoch 01772: val_loss improved from 1.29823 to 1.29816, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1773/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4225 - val_loss: 1.3012 - val_accuracy: 0.4219

Epoch 01773: val_loss did not improve from 1.29816
Epoch 1774/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4168 - val_loss: 1.3003 - val_accuracy: 0.4203

Epoch 01774: val_loss did not improve from 1.29816
Epoch 1775/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4191 - val_loss: 1.3030 - val_accuracy: 0.4219

Epoch 01775: val_loss did not improve from 1.29816
Epoch 1776/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4241 - val_loss: 1.2993 - val_accuracy: 0.4203

Epoch 01776: val_loss did not improve from 1.29816
Epoch 1777/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4208 - val_loss: 1.3028 - val_accuracy: 0.4250

Epoch 01777: val_loss did not improve from 1.29816
Epoch 1778/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4205 - val_loss: 1.3020 - val_accuracy: 0.4314

Epoch 01778: val_loss did not improve from 1.29816
Epoch 1779/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4221 - val_loss: 1.3003 - val_accuracy: 0.4282

Epoch 01779: val_loss did not improve from 1.29816
Epoch 1780/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4172 - val_loss: 1.2996 - val_accuracy: 0.4171

Epoch 01780: val_loss did not improve from 1.29816
Epoch 1781/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4205 - val_loss: 1.2981 - val_accuracy: 0.4242

Epoch 01781: val_loss improved from 1.29816 to 1.29809, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1782/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4209 - val_loss: 1.2995 - val_accuracy: 0.4250

Epoch 01782: val_loss did not improve from 1.29809
Epoch 1783/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4235 - val_loss: 1.2994 - val_accuracy: 0.4195

Epoch 01783: val_loss did not improve from 1.29809
Epoch 1784/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4165 - val_loss: 1.3046 - val_accuracy: 0.4219

Epoch 01784: val_loss did not improve from 1.29809
Epoch 1785/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4210 - val_loss: 1.3012 - val_accuracy: 0.4187

Epoch 01785: val_loss did not improve from 1.29809
Epoch 1786/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4222 - val_loss: 1.3009 - val_accuracy: 0.4370

Epoch 01786: val_loss did not improve from 1.29809
Epoch 1787/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4240 - val_loss: 1.3004 - val_accuracy: 0.4219

Epoch 01787: val_loss did not improve from 1.29809
Epoch 1788/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4202 - val_loss: 1.2994 - val_accuracy: 0.4282

Epoch 01788: val_loss did not improve from 1.29809
Epoch 1789/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4220 - val_loss: 1.3019 - val_accuracy: 0.4338

Epoch 01789: val_loss did not improve from 1.29809
Epoch 1790/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4249 - val_loss: 1.3022 - val_accuracy: 0.4234

Epoch 01790: val_loss did not improve from 1.29809
Epoch 1791/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4218 - val_loss: 1.2999 - val_accuracy: 0.4242

Epoch 01791: val_loss did not improve from 1.29809
Epoch 1792/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4202 - val_loss: 1.2996 - val_accuracy: 0.4322

Epoch 01792: val_loss did not improve from 1.29809
Epoch 1793/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4199 - val_loss: 1.3013 - val_accuracy: 0.4203

Epoch 01793: val_loss did not improve from 1.29809
Epoch 1794/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4194 - val_loss: 1.2989 - val_accuracy: 0.4314

Epoch 01794: val_loss did not improve from 1.29809
Epoch 1795/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4258 - val_loss: 1.3008 - val_accuracy: 0.4378

Epoch 01795: val_loss did not improve from 1.29809
Epoch 1796/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4171 - val_loss: 1.3008 - val_accuracy: 0.4234

Epoch 01796: val_loss did not improve from 1.29809
Epoch 1797/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4172 - val_loss: 1.3001 - val_accuracy: 0.4314

Epoch 01797: val_loss did not improve from 1.29809
Epoch 1798/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4204 - val_loss: 1.2987 - val_accuracy: 0.4370

Epoch 01798: val_loss did not improve from 1.29809
Epoch 1799/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4224 - val_loss: 1.2992 - val_accuracy: 0.4386

Epoch 01799: val_loss did not improve from 1.29809
Epoch 1800/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4211 - val_loss: 1.2982 - val_accuracy: 0.4250

Epoch 01800: val_loss did not improve from 1.29809
Epoch 1801/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4261 - val_loss: 1.2993 - val_accuracy: 0.4354

Epoch 01801: val_loss did not improve from 1.29809
Epoch 1802/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4209 - val_loss: 1.2995 - val_accuracy: 0.4322

Epoch 01802: val_loss did not improve from 1.29809
Epoch 1803/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4241 - val_loss: 1.2996 - val_accuracy: 0.4219

Epoch 01803: val_loss did not improve from 1.29809
Epoch 1804/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4246 - val_loss: 1.3011 - val_accuracy: 0.4274

Epoch 01804: val_loss did not improve from 1.29809
Epoch 1805/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4210 - val_loss: 1.2992 - val_accuracy: 0.4306

Epoch 01805: val_loss did not improve from 1.29809
Epoch 1806/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4249 - val_loss: 1.3013 - val_accuracy: 0.4195

Epoch 01806: val_loss did not improve from 1.29809
Epoch 1807/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4245 - val_loss: 1.3003 - val_accuracy: 0.4131

Epoch 01807: val_loss did not improve from 1.29809
Epoch 1808/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4221 - val_loss: 1.3001 - val_accuracy: 0.4274

Epoch 01808: val_loss did not improve from 1.29809
Epoch 1809/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4298 - val_loss: 1.3009 - val_accuracy: 0.4282

Epoch 01809: val_loss did not improve from 1.29809
Epoch 1810/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4240 - val_loss: 1.2979 - val_accuracy: 0.4258

Epoch 01810: val_loss improved from 1.29809 to 1.29793, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1811/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4249 - val_loss: 1.3003 - val_accuracy: 0.4242

Epoch 01811: val_loss did not improve from 1.29793
Epoch 1812/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4217 - val_loss: 1.3011 - val_accuracy: 0.4434

Epoch 01812: val_loss did not improve from 1.29793
Epoch 1813/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4213 - val_loss: 1.3010 - val_accuracy: 0.4219

Epoch 01813: val_loss did not improve from 1.29793
Epoch 1814/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4137 - val_loss: 1.3020 - val_accuracy: 0.4290

Epoch 01814: val_loss did not improve from 1.29793
Epoch 1815/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4217 - val_loss: 1.3001 - val_accuracy: 0.4330

Epoch 01815: val_loss did not improve from 1.29793
Epoch 1816/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4250 - val_loss: 1.3004 - val_accuracy: 0.4203

Epoch 01816: val_loss did not improve from 1.29793
Epoch 1817/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4230 - val_loss: 1.2999 - val_accuracy: 0.4282

Epoch 01817: val_loss did not improve from 1.29793
Epoch 1818/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4143 - val_loss: 1.2991 - val_accuracy: 0.4211

Epoch 01818: val_loss did not improve from 1.29793
Epoch 1819/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4212 - val_loss: 1.2986 - val_accuracy: 0.4346

Epoch 01819: val_loss did not improve from 1.29793
Epoch 1820/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4252 - val_loss: 1.2974 - val_accuracy: 0.4346

Epoch 01820: val_loss improved from 1.29793 to 1.29743, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1821/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4239 - val_loss: 1.2981 - val_accuracy: 0.4402

Epoch 01821: val_loss did not improve from 1.29743
Epoch 1822/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4233 - val_loss: 1.3034 - val_accuracy: 0.4242

Epoch 01822: val_loss did not improve from 1.29743
Epoch 1823/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4213 - val_loss: 1.3015 - val_accuracy: 0.4290

Epoch 01823: val_loss did not improve from 1.29743
Epoch 1824/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4208 - val_loss: 1.2987 - val_accuracy: 0.4290

Epoch 01824: val_loss did not improve from 1.29743
Epoch 1825/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4162 - val_loss: 1.3086 - val_accuracy: 0.4179

Epoch 01825: val_loss did not improve from 1.29743
Epoch 1826/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4168 - val_loss: 1.2998 - val_accuracy: 0.4282

Epoch 01826: val_loss did not improve from 1.29743
Epoch 1827/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4228 - val_loss: 1.2999 - val_accuracy: 0.4203

Epoch 01827: val_loss did not improve from 1.29743
Epoch 1828/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4226 - val_loss: 1.3004 - val_accuracy: 0.4234

Epoch 01828: val_loss did not improve from 1.29743
Epoch 1829/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4218 - val_loss: 1.3006 - val_accuracy: 0.4386

Epoch 01829: val_loss did not improve from 1.29743
Epoch 1830/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4250 - val_loss: 1.3016 - val_accuracy: 0.4306

Epoch 01830: val_loss did not improve from 1.29743
Epoch 1831/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4172 - val_loss: 1.3000 - val_accuracy: 0.4123

Epoch 01831: val_loss did not improve from 1.29743
Epoch 1832/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4238 - val_loss: 1.3006 - val_accuracy: 0.4234

Epoch 01832: val_loss did not improve from 1.29743
Epoch 1833/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4195 - val_loss: 1.3000 - val_accuracy: 0.4306

Epoch 01833: val_loss did not improve from 1.29743
Epoch 1834/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4182 - val_loss: 1.2978 - val_accuracy: 0.4290

Epoch 01834: val_loss did not improve from 1.29743
Epoch 1835/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4194 - val_loss: 1.3012 - val_accuracy: 0.4250

Epoch 01835: val_loss did not improve from 1.29743
Epoch 1836/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4199 - val_loss: 1.2972 - val_accuracy: 0.4290

Epoch 01836: val_loss improved from 1.29743 to 1.29724, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1837/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4237 - val_loss: 1.2963 - val_accuracy: 0.4314

Epoch 01837: val_loss improved from 1.29724 to 1.29631, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1838/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4246 - val_loss: 1.3022 - val_accuracy: 0.4290

Epoch 01838: val_loss did not improve from 1.29631
Epoch 1839/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4178 - val_loss: 1.2990 - val_accuracy: 0.4290

Epoch 01839: val_loss did not improve from 1.29631
Epoch 1840/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4167 - val_loss: 1.3066 - val_accuracy: 0.4266

Epoch 01840: val_loss did not improve from 1.29631
Epoch 1841/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4163 - val_loss: 1.2984 - val_accuracy: 0.4394

Epoch 01841: val_loss did not improve from 1.29631
Epoch 1842/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4228 - val_loss: 1.2984 - val_accuracy: 0.4330

Epoch 01842: val_loss did not improve from 1.29631
Epoch 1843/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4244 - val_loss: 1.2985 - val_accuracy: 0.4155

Epoch 01843: val_loss did not improve from 1.29631
Epoch 1844/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4225 - val_loss: 1.2979 - val_accuracy: 0.4258

Epoch 01844: val_loss did not improve from 1.29631
Epoch 1845/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4203 - val_loss: 1.2973 - val_accuracy: 0.4234

Epoch 01845: val_loss did not improve from 1.29631
Epoch 1846/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4223 - val_loss: 1.2975 - val_accuracy: 0.4314

Epoch 01846: val_loss did not improve from 1.29631
Epoch 1847/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4221 - val_loss: 1.2999 - val_accuracy: 0.4250

Epoch 01847: val_loss did not improve from 1.29631
Epoch 1848/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4175 - val_loss: 1.2975 - val_accuracy: 0.4298

Epoch 01848: val_loss did not improve from 1.29631
Epoch 1849/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4223 - val_loss: 1.2985 - val_accuracy: 0.4234

Epoch 01849: val_loss did not improve from 1.29631
Epoch 1850/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4245 - val_loss: 1.3011 - val_accuracy: 0.4410

Epoch 01850: val_loss did not improve from 1.29631
Epoch 1851/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4242 - val_loss: 1.2991 - val_accuracy: 0.4314

Epoch 01851: val_loss did not improve from 1.29631
Epoch 1852/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4233 - val_loss: 1.2985 - val_accuracy: 0.4426

Epoch 01852: val_loss did not improve from 1.29631
Epoch 1853/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4201 - val_loss: 1.2982 - val_accuracy: 0.4394

Epoch 01853: val_loss did not improve from 1.29631
Epoch 1854/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4206 - val_loss: 1.2978 - val_accuracy: 0.4394

Epoch 01854: val_loss did not improve from 1.29631
Epoch 1855/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4251 - val_loss: 1.3038 - val_accuracy: 0.4306

Epoch 01855: val_loss did not improve from 1.29631
Epoch 1856/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4190 - val_loss: 1.2970 - val_accuracy: 0.4370

Epoch 01856: val_loss did not improve from 1.29631
Epoch 1857/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4217 - val_loss: 1.2986 - val_accuracy: 0.4242

Epoch 01857: val_loss did not improve from 1.29631
Epoch 1858/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4246 - val_loss: 1.2968 - val_accuracy: 0.4298

Epoch 01858: val_loss did not improve from 1.29631
Epoch 1859/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4256 - val_loss: 1.2984 - val_accuracy: 0.4250

Epoch 01859: val_loss did not improve from 1.29631
Epoch 1860/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4219 - val_loss: 1.2978 - val_accuracy: 0.4266

Epoch 01860: val_loss did not improve from 1.29631
Epoch 1861/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4221 - val_loss: 1.2986 - val_accuracy: 0.4258

Epoch 01861: val_loss did not improve from 1.29631
Epoch 1862/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4215 - val_loss: 1.2986 - val_accuracy: 0.4266

Epoch 01862: val_loss did not improve from 1.29631
Epoch 1863/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4241 - val_loss: 1.2988 - val_accuracy: 0.4250

Epoch 01863: val_loss did not improve from 1.29631
Epoch 1864/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4197 - val_loss: 1.3013 - val_accuracy: 0.4258

Epoch 01864: val_loss did not improve from 1.29631
Epoch 1865/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4210 - val_loss: 1.2993 - val_accuracy: 0.4330

Epoch 01865: val_loss did not improve from 1.29631
Epoch 1866/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4217 - val_loss: 1.3005 - val_accuracy: 0.4266

Epoch 01866: val_loss did not improve from 1.29631
Epoch 1867/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4207 - val_loss: 1.2982 - val_accuracy: 0.4330

Epoch 01867: val_loss did not improve from 1.29631
Epoch 1868/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4214 - val_loss: 1.2975 - val_accuracy: 0.4338

Epoch 01868: val_loss did not improve from 1.29631
Epoch 1869/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4185 - val_loss: 1.2986 - val_accuracy: 0.4226

Epoch 01869: val_loss did not improve from 1.29631
Epoch 1870/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4240 - val_loss: 1.2980 - val_accuracy: 0.4211

Epoch 01870: val_loss did not improve from 1.29631
Epoch 1871/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4190 - val_loss: 1.2970 - val_accuracy: 0.4386

Epoch 01871: val_loss did not improve from 1.29631
Epoch 1872/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4241 - val_loss: 1.2986 - val_accuracy: 0.4274

Epoch 01872: val_loss did not improve from 1.29631
Epoch 1873/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4251 - val_loss: 1.2992 - val_accuracy: 0.4290

Epoch 01873: val_loss did not improve from 1.29631
Epoch 1874/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4238 - val_loss: 1.2980 - val_accuracy: 0.4274

Epoch 01874: val_loss did not improve from 1.29631
Epoch 1875/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4228 - val_loss: 1.2984 - val_accuracy: 0.4155

Epoch 01875: val_loss did not improve from 1.29631
Epoch 1876/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4225 - val_loss: 1.2969 - val_accuracy: 0.4282

Epoch 01876: val_loss did not improve from 1.29631
Epoch 1877/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4266 - val_loss: 1.3038 - val_accuracy: 0.4266

Epoch 01877: val_loss did not improve from 1.29631
Epoch 1878/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4210 - val_loss: 1.2960 - val_accuracy: 0.4338

Epoch 01878: val_loss improved from 1.29631 to 1.29598, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1879/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4180 - val_loss: 1.2977 - val_accuracy: 0.4250

Epoch 01879: val_loss did not improve from 1.29598
Epoch 1880/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4272 - val_loss: 1.2976 - val_accuracy: 0.4290

Epoch 01880: val_loss did not improve from 1.29598
Epoch 1881/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4242 - val_loss: 1.2960 - val_accuracy: 0.4330

Epoch 01881: val_loss did not improve from 1.29598
Epoch 1882/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4212 - val_loss: 1.2979 - val_accuracy: 0.4282

Epoch 01882: val_loss did not improve from 1.29598
Epoch 1883/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4237 - val_loss: 1.2979 - val_accuracy: 0.4219

Epoch 01883: val_loss did not improve from 1.29598
Epoch 1884/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4172 - val_loss: 1.2965 - val_accuracy: 0.4290

Epoch 01884: val_loss did not improve from 1.29598
Epoch 1885/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4243 - val_loss: 1.2969 - val_accuracy: 0.4338

Epoch 01885: val_loss did not improve from 1.29598
Epoch 1886/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4246 - val_loss: 1.2985 - val_accuracy: 0.4410

Epoch 01886: val_loss did not improve from 1.29598
Epoch 1887/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4194 - val_loss: 1.2980 - val_accuracy: 0.4330

Epoch 01887: val_loss did not improve from 1.29598
Epoch 1888/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4247 - val_loss: 1.3018 - val_accuracy: 0.4226

Epoch 01888: val_loss did not improve from 1.29598
Epoch 1889/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4151 - val_loss: 1.2978 - val_accuracy: 0.4354

Epoch 01889: val_loss did not improve from 1.29598
Epoch 1890/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4222 - val_loss: 1.2969 - val_accuracy: 0.4282

Epoch 01890: val_loss did not improve from 1.29598
Epoch 1891/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4256 - val_loss: 1.2974 - val_accuracy: 0.4402

Epoch 01891: val_loss did not improve from 1.29598
Epoch 1892/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4202 - val_loss: 1.2967 - val_accuracy: 0.4266

Epoch 01892: val_loss did not improve from 1.29598
Epoch 1893/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4182 - val_loss: 1.2992 - val_accuracy: 0.4131

Epoch 01893: val_loss did not improve from 1.29598
Epoch 1894/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4244 - val_loss: 1.3025 - val_accuracy: 0.4282

Epoch 01894: val_loss did not improve from 1.29598
Epoch 1895/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4214 - val_loss: 1.2973 - val_accuracy: 0.4298

Epoch 01895: val_loss did not improve from 1.29598
Epoch 1896/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4233 - val_loss: 1.2971 - val_accuracy: 0.4187

Epoch 01896: val_loss did not improve from 1.29598
Epoch 1897/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4264 - val_loss: 1.3003 - val_accuracy: 0.4219

Epoch 01897: val_loss did not improve from 1.29598
Epoch 1898/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4275 - val_loss: 1.2977 - val_accuracy: 0.4338

Epoch 01898: val_loss did not improve from 1.29598
Epoch 1899/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4238 - val_loss: 1.3012 - val_accuracy: 0.4226

Epoch 01899: val_loss did not improve from 1.29598
Epoch 1900/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4205 - val_loss: 1.2953 - val_accuracy: 0.4298

Epoch 01900: val_loss improved from 1.29598 to 1.29528, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1901/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4194 - val_loss: 1.2951 - val_accuracy: 0.4226

Epoch 01901: val_loss improved from 1.29528 to 1.29507, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1902/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4197 - val_loss: 1.2970 - val_accuracy: 0.4370

Epoch 01902: val_loss did not improve from 1.29507
Epoch 1903/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4267 - val_loss: 1.2970 - val_accuracy: 0.4354

Epoch 01903: val_loss did not improve from 1.29507
Epoch 1904/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4225 - val_loss: 1.2959 - val_accuracy: 0.4314

Epoch 01904: val_loss did not improve from 1.29507
Epoch 1905/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4235 - val_loss: 1.3001 - val_accuracy: 0.4338

Epoch 01905: val_loss did not improve from 1.29507
Epoch 1906/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4242 - val_loss: 1.2953 - val_accuracy: 0.4306

Epoch 01906: val_loss did not improve from 1.29507
Epoch 1907/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4230 - val_loss: 1.2964 - val_accuracy: 0.4330

Epoch 01907: val_loss did not improve from 1.29507
Epoch 1908/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4254 - val_loss: 1.3020 - val_accuracy: 0.4242

Epoch 01908: val_loss did not improve from 1.29507
Epoch 1909/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4193 - val_loss: 1.2970 - val_accuracy: 0.4282

Epoch 01909: val_loss did not improve from 1.29507
Epoch 1910/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4225 - val_loss: 1.3050 - val_accuracy: 0.4338

Epoch 01910: val_loss did not improve from 1.29507
Epoch 1911/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4208 - val_loss: 1.2984 - val_accuracy: 0.4282

Epoch 01911: val_loss did not improve from 1.29507
Epoch 1912/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4220 - val_loss: 1.3020 - val_accuracy: 0.4338

Epoch 01912: val_loss did not improve from 1.29507
Epoch 1913/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4236 - val_loss: 1.2968 - val_accuracy: 0.4330

Epoch 01913: val_loss did not improve from 1.29507
Epoch 1914/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4254 - val_loss: 1.2966 - val_accuracy: 0.4274

Epoch 01914: val_loss did not improve from 1.29507
Epoch 1915/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4230 - val_loss: 1.2978 - val_accuracy: 0.4338

Epoch 01915: val_loss did not improve from 1.29507
Epoch 1916/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4216 - val_loss: 1.2950 - val_accuracy: 0.4219

Epoch 01916: val_loss improved from 1.29507 to 1.29501, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1917/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4225 - val_loss: 1.2978 - val_accuracy: 0.4298

Epoch 01917: val_loss did not improve from 1.29501
Epoch 1918/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4193 - val_loss: 1.2978 - val_accuracy: 0.4370

Epoch 01918: val_loss did not improve from 1.29501
Epoch 1919/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4222 - val_loss: 1.2961 - val_accuracy: 0.4250

Epoch 01919: val_loss did not improve from 1.29501
Epoch 1920/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4235 - val_loss: 1.2992 - val_accuracy: 0.4370

Epoch 01920: val_loss did not improve from 1.29501
Epoch 1921/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4211 - val_loss: 1.2950 - val_accuracy: 0.4370

Epoch 01921: val_loss improved from 1.29501 to 1.29495, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1922/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4249 - val_loss: 1.2960 - val_accuracy: 0.4346

Epoch 01922: val_loss did not improve from 1.29495
Epoch 1923/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4249 - val_loss: 1.2984 - val_accuracy: 0.4306

Epoch 01923: val_loss did not improve from 1.29495
Epoch 1924/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4239 - val_loss: 1.3002 - val_accuracy: 0.4250

Epoch 01924: val_loss did not improve from 1.29495
Epoch 1925/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4256 - val_loss: 1.2979 - val_accuracy: 0.4306

Epoch 01925: val_loss did not improve from 1.29495
Epoch 1926/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4217 - val_loss: 1.2986 - val_accuracy: 0.4386

Epoch 01926: val_loss did not improve from 1.29495
Epoch 1927/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4216 - val_loss: 1.2975 - val_accuracy: 0.4274

Epoch 01927: val_loss did not improve from 1.29495
Epoch 1928/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4248 - val_loss: 1.3004 - val_accuracy: 0.4322

Epoch 01928: val_loss did not improve from 1.29495
Epoch 1929/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4247 - val_loss: 1.2964 - val_accuracy: 0.4346

Epoch 01929: val_loss did not improve from 1.29495
Epoch 1930/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4230 - val_loss: 1.2948 - val_accuracy: 0.4370

Epoch 01930: val_loss improved from 1.29495 to 1.29476, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1931/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4218 - val_loss: 1.3027 - val_accuracy: 0.4298

Epoch 01931: val_loss did not improve from 1.29476
Epoch 1932/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4248 - val_loss: 1.2959 - val_accuracy: 0.4370

Epoch 01932: val_loss did not improve from 1.29476
Epoch 1933/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4264 - val_loss: 1.2993 - val_accuracy: 0.4298

Epoch 01933: val_loss did not improve from 1.29476
Epoch 1934/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4245 - val_loss: 1.2959 - val_accuracy: 0.4298

Epoch 01934: val_loss did not improve from 1.29476
Epoch 1935/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4232 - val_loss: 1.2952 - val_accuracy: 0.4394

Epoch 01935: val_loss did not improve from 1.29476
Epoch 1936/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4228 - val_loss: 1.2950 - val_accuracy: 0.4394

Epoch 01936: val_loss did not improve from 1.29476
Epoch 1937/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4243 - val_loss: 1.2981 - val_accuracy: 0.4370

Epoch 01937: val_loss did not improve from 1.29476
Epoch 1938/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4257 - val_loss: 1.2957 - val_accuracy: 0.4378

Epoch 01938: val_loss did not improve from 1.29476
Epoch 1939/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4262 - val_loss: 1.2970 - val_accuracy: 0.4266

Epoch 01939: val_loss did not improve from 1.29476
Epoch 1940/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4239 - val_loss: 1.2957 - val_accuracy: 0.4290

Epoch 01940: val_loss did not improve from 1.29476
Epoch 1941/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4232 - val_loss: 1.2962 - val_accuracy: 0.4410

Epoch 01941: val_loss did not improve from 1.29476
Epoch 1942/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4241 - val_loss: 1.2981 - val_accuracy: 0.4250

Epoch 01942: val_loss did not improve from 1.29476
Epoch 1943/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4252 - val_loss: 1.2978 - val_accuracy: 0.4203

Epoch 01943: val_loss did not improve from 1.29476
Epoch 1944/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4222 - val_loss: 1.2948 - val_accuracy: 0.4274

Epoch 01944: val_loss did not improve from 1.29476
Epoch 1945/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4238 - val_loss: 1.2945 - val_accuracy: 0.4298

Epoch 01945: val_loss improved from 1.29476 to 1.29449, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1946/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4227 - val_loss: 1.3009 - val_accuracy: 0.4298

Epoch 01946: val_loss did not improve from 1.29449
Epoch 1947/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4247 - val_loss: 1.2947 - val_accuracy: 0.4211

Epoch 01947: val_loss did not improve from 1.29449
Epoch 1948/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4236 - val_loss: 1.2959 - val_accuracy: 0.4266

Epoch 01948: val_loss did not improve from 1.29449
Epoch 1949/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4250 - val_loss: 1.2954 - val_accuracy: 0.4322

Epoch 01949: val_loss did not improve from 1.29449
Epoch 1950/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4261 - val_loss: 1.2955 - val_accuracy: 0.4434

Epoch 01950: val_loss did not improve from 1.29449
Epoch 1951/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4268 - val_loss: 1.2945 - val_accuracy: 0.4274

Epoch 01951: val_loss did not improve from 1.29449
Epoch 1952/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4241 - val_loss: 1.3000 - val_accuracy: 0.4346

Epoch 01952: val_loss did not improve from 1.29449
Epoch 1953/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4233 - val_loss: 1.2957 - val_accuracy: 0.4458

Epoch 01953: val_loss did not improve from 1.29449
Epoch 1954/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4235 - val_loss: 1.2959 - val_accuracy: 0.4370

Epoch 01954: val_loss did not improve from 1.29449
Epoch 1955/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4268 - val_loss: 1.2950 - val_accuracy: 0.4354

Epoch 01955: val_loss did not improve from 1.29449
Epoch 1956/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4288 - val_loss: 1.3019 - val_accuracy: 0.4282

Epoch 01956: val_loss did not improve from 1.29449
Epoch 1957/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4257 - val_loss: 1.2965 - val_accuracy: 0.4394

Epoch 01957: val_loss did not improve from 1.29449
Epoch 1958/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4210 - val_loss: 1.2992 - val_accuracy: 0.4330

Epoch 01958: val_loss did not improve from 1.29449
Epoch 1959/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4245 - val_loss: 1.3010 - val_accuracy: 0.4322

Epoch 01959: val_loss did not improve from 1.29449
Epoch 1960/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4221 - val_loss: 1.2964 - val_accuracy: 0.4410

Epoch 01960: val_loss did not improve from 1.29449
Epoch 1961/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4207 - val_loss: 1.2974 - val_accuracy: 0.4354

Epoch 01961: val_loss did not improve from 1.29449
Epoch 1962/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4242 - val_loss: 1.2972 - val_accuracy: 0.4226

Epoch 01962: val_loss did not improve from 1.29449
Epoch 1963/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4242 - val_loss: 1.2961 - val_accuracy: 0.4266

Epoch 01963: val_loss did not improve from 1.29449
Epoch 1964/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4226 - val_loss: 1.2964 - val_accuracy: 0.4250

Epoch 01964: val_loss did not improve from 1.29449
Epoch 1965/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4253 - val_loss: 1.2986 - val_accuracy: 0.4306

Epoch 01965: val_loss did not improve from 1.29449
Epoch 1966/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4206 - val_loss: 1.3033 - val_accuracy: 0.4258

Epoch 01966: val_loss did not improve from 1.29449
Epoch 1967/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4207 - val_loss: 1.2952 - val_accuracy: 0.4434

Epoch 01967: val_loss did not improve from 1.29449
Epoch 1968/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4218 - val_loss: 1.2938 - val_accuracy: 0.4282

Epoch 01968: val_loss improved from 1.29449 to 1.29376, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1969/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4258 - val_loss: 1.2938 - val_accuracy: 0.4346

Epoch 01969: val_loss did not improve from 1.29376
Epoch 1970/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4242 - val_loss: 1.2964 - val_accuracy: 0.4298

Epoch 01970: val_loss did not improve from 1.29376
Epoch 1971/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4253 - val_loss: 1.2955 - val_accuracy: 0.4306

Epoch 01971: val_loss did not improve from 1.29376
Epoch 1972/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4248 - val_loss: 1.2943 - val_accuracy: 0.4306

Epoch 01972: val_loss did not improve from 1.29376
Epoch 1973/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4281 - val_loss: 1.2941 - val_accuracy: 0.4338

Epoch 01973: val_loss did not improve from 1.29376
Epoch 1974/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4250 - val_loss: 1.2967 - val_accuracy: 0.4338

Epoch 01974: val_loss did not improve from 1.29376
Epoch 1975/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4261 - val_loss: 1.2971 - val_accuracy: 0.4346

Epoch 01975: val_loss did not improve from 1.29376
Epoch 1976/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4235 - val_loss: 1.2964 - val_accuracy: 0.4258

Epoch 01976: val_loss did not improve from 1.29376
Epoch 1977/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4318 - val_loss: 1.3005 - val_accuracy: 0.4282

Epoch 01977: val_loss did not improve from 1.29376
Epoch 1978/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4259 - val_loss: 1.2945 - val_accuracy: 0.4330

Epoch 01978: val_loss did not improve from 1.29376
Epoch 1979/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4249 - val_loss: 1.2968 - val_accuracy: 0.4386

Epoch 01979: val_loss did not improve from 1.29376
Epoch 1980/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4260 - val_loss: 1.2952 - val_accuracy: 0.4282

Epoch 01980: val_loss did not improve from 1.29376
Epoch 1981/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4264 - val_loss: 1.3005 - val_accuracy: 0.4306

Epoch 01981: val_loss did not improve from 1.29376
Epoch 1982/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4232 - val_loss: 1.2958 - val_accuracy: 0.4362

Epoch 01982: val_loss did not improve from 1.29376
Epoch 1983/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4252 - val_loss: 1.2965 - val_accuracy: 0.4290

Epoch 01983: val_loss did not improve from 1.29376
Epoch 1984/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4236 - val_loss: 1.2944 - val_accuracy: 0.4242

Epoch 01984: val_loss did not improve from 1.29376
Epoch 1985/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4264 - val_loss: 1.2951 - val_accuracy: 0.4322

Epoch 01985: val_loss did not improve from 1.29376
Epoch 1986/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4228 - val_loss: 1.2939 - val_accuracy: 0.4370

Epoch 01986: val_loss did not improve from 1.29376
Epoch 1987/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4249 - val_loss: 1.2961 - val_accuracy: 0.4274

Epoch 01987: val_loss did not improve from 1.29376
Epoch 1988/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4249 - val_loss: 1.2984 - val_accuracy: 0.4274

Epoch 01988: val_loss did not improve from 1.29376
Epoch 1989/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4230 - val_loss: 1.2939 - val_accuracy: 0.4266

Epoch 01989: val_loss did not improve from 1.29376
Epoch 1990/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4255 - val_loss: 1.2938 - val_accuracy: 0.4306

Epoch 01990: val_loss improved from 1.29376 to 1.29375, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1991/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4263 - val_loss: 1.2941 - val_accuracy: 0.4322

Epoch 01991: val_loss did not improve from 1.29375
Epoch 1992/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4224 - val_loss: 1.2942 - val_accuracy: 0.4290

Epoch 01992: val_loss did not improve from 1.29375
Epoch 1993/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4248 - val_loss: 1.2965 - val_accuracy: 0.4306

Epoch 01993: val_loss did not improve from 1.29375
Epoch 1994/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4252 - val_loss: 1.2944 - val_accuracy: 0.4306

Epoch 01994: val_loss did not improve from 1.29375
Epoch 1995/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4246 - val_loss: 1.2960 - val_accuracy: 0.4314

Epoch 01995: val_loss did not improve from 1.29375
Epoch 1996/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4236 - val_loss: 1.2975 - val_accuracy: 0.4274

Epoch 01996: val_loss did not improve from 1.29375
Epoch 1997/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4264 - val_loss: 1.2936 - val_accuracy: 0.4314

Epoch 01997: val_loss improved from 1.29375 to 1.29360, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 1998/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4272 - val_loss: 1.2948 - val_accuracy: 0.4346

Epoch 01998: val_loss did not improve from 1.29360
Epoch 1999/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4240 - val_loss: 1.2949 - val_accuracy: 0.4282

Epoch 01999: val_loss did not improve from 1.29360
Epoch 2000/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4231 - val_loss: 1.2942 - val_accuracy: 0.4274

Epoch 02000: val_loss did not improve from 1.29360
Epoch 2001/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4233 - val_loss: 1.2962 - val_accuracy: 0.4402

Epoch 02001: val_loss did not improve from 1.29360
Epoch 2002/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4255 - val_loss: 1.2939 - val_accuracy: 0.4306

Epoch 02002: val_loss did not improve from 1.29360
Epoch 2003/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4278 - val_loss: 1.2969 - val_accuracy: 0.4378

Epoch 02003: val_loss did not improve from 1.29360
Epoch 2004/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4256 - val_loss: 1.2954 - val_accuracy: 0.4402

Epoch 02004: val_loss did not improve from 1.29360
Epoch 2005/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4272 - val_loss: 1.2944 - val_accuracy: 0.4274

Epoch 02005: val_loss did not improve from 1.29360
Epoch 2006/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4249 - val_loss: 1.2931 - val_accuracy: 0.4346

Epoch 02006: val_loss improved from 1.29360 to 1.29313, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2007/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4287 - val_loss: 1.2968 - val_accuracy: 0.4370

Epoch 02007: val_loss did not improve from 1.29313
Epoch 2008/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4299 - val_loss: 1.2960 - val_accuracy: 0.4266

Epoch 02008: val_loss did not improve from 1.29313
Epoch 2009/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4243 - val_loss: 1.2945 - val_accuracy: 0.4370

Epoch 02009: val_loss did not improve from 1.29313
Epoch 2010/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4246 - val_loss: 1.2944 - val_accuracy: 0.4290

Epoch 02010: val_loss did not improve from 1.29313
Epoch 2011/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4319 - val_loss: 1.2991 - val_accuracy: 0.4211

Epoch 02011: val_loss did not improve from 1.29313
Epoch 2012/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4236 - val_loss: 1.2926 - val_accuracy: 0.4346

Epoch 02012: val_loss improved from 1.29313 to 1.29264, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2013/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4247 - val_loss: 1.2931 - val_accuracy: 0.4282

Epoch 02013: val_loss did not improve from 1.29264
Epoch 2014/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4277 - val_loss: 1.2939 - val_accuracy: 0.4346

Epoch 02014: val_loss did not improve from 1.29264
Epoch 2015/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4302 - val_loss: 1.2969 - val_accuracy: 0.4346

Epoch 02015: val_loss did not improve from 1.29264
Epoch 2016/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4267 - val_loss: 1.2941 - val_accuracy: 0.4330

Epoch 02016: val_loss did not improve from 1.29264
Epoch 2017/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4237 - val_loss: 1.2952 - val_accuracy: 0.4290

Epoch 02017: val_loss did not improve from 1.29264
Epoch 2018/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4292 - val_loss: 1.2933 - val_accuracy: 0.4346

Epoch 02018: val_loss did not improve from 1.29264
Epoch 2019/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4258 - val_loss: 1.2952 - val_accuracy: 0.4282

Epoch 02019: val_loss did not improve from 1.29264
Epoch 2020/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4218 - val_loss: 1.2956 - val_accuracy: 0.4370

Epoch 02020: val_loss did not improve from 1.29264
Epoch 2021/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4261 - val_loss: 1.2966 - val_accuracy: 0.4306

Epoch 02021: val_loss did not improve from 1.29264
Epoch 2022/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4280 - val_loss: 1.2932 - val_accuracy: 0.4370

Epoch 02022: val_loss did not improve from 1.29264
Epoch 2023/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4225 - val_loss: 1.2970 - val_accuracy: 0.4266

Epoch 02023: val_loss did not improve from 1.29264
Epoch 2024/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4267 - val_loss: 1.3070 - val_accuracy: 0.4298

Epoch 02024: val_loss did not improve from 1.29264
Epoch 2025/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4276 - val_loss: 1.2953 - val_accuracy: 0.4402

Epoch 02025: val_loss did not improve from 1.29264
Epoch 2026/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4268 - val_loss: 1.2956 - val_accuracy: 0.4282

Epoch 02026: val_loss did not improve from 1.29264
Epoch 2027/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4225 - val_loss: 1.2965 - val_accuracy: 0.4306

Epoch 02027: val_loss did not improve from 1.29264
Epoch 2028/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4226 - val_loss: 1.2961 - val_accuracy: 0.4250

Epoch 02028: val_loss did not improve from 1.29264
Epoch 2029/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4302 - val_loss: 1.2944 - val_accuracy: 0.4211

Epoch 02029: val_loss did not improve from 1.29264
Epoch 2030/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4263 - val_loss: 1.2941 - val_accuracy: 0.4410

Epoch 02030: val_loss did not improve from 1.29264
Epoch 2031/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4258 - val_loss: 1.2928 - val_accuracy: 0.4298

Epoch 02031: val_loss did not improve from 1.29264
Epoch 2032/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4298 - val_loss: 1.2955 - val_accuracy: 0.4330

Epoch 02032: val_loss did not improve from 1.29264
Epoch 2033/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4239 - val_loss: 1.2932 - val_accuracy: 0.4338

Epoch 02033: val_loss did not improve from 1.29264
Epoch 2034/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4245 - val_loss: 1.2963 - val_accuracy: 0.4234

Epoch 02034: val_loss did not improve from 1.29264
Epoch 2035/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4282 - val_loss: 1.2940 - val_accuracy: 0.4354

Epoch 02035: val_loss did not improve from 1.29264
Epoch 2036/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4256 - val_loss: 1.2959 - val_accuracy: 0.4346

Epoch 02036: val_loss did not improve from 1.29264
Epoch 2037/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4273 - val_loss: 1.2950 - val_accuracy: 0.4410

Epoch 02037: val_loss did not improve from 1.29264
Epoch 2038/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4266 - val_loss: 1.2945 - val_accuracy: 0.4354

Epoch 02038: val_loss did not improve from 1.29264
Epoch 2039/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4293 - val_loss: 1.2961 - val_accuracy: 0.4314

Epoch 02039: val_loss did not improve from 1.29264
Epoch 2040/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4266 - val_loss: 1.2942 - val_accuracy: 0.4282

Epoch 02040: val_loss did not improve from 1.29264
Epoch 2041/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4269 - val_loss: 1.2934 - val_accuracy: 0.4330

Epoch 02041: val_loss did not improve from 1.29264
Epoch 2042/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4287 - val_loss: 1.3014 - val_accuracy: 0.4314

Epoch 02042: val_loss did not improve from 1.29264
Epoch 2043/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4257 - val_loss: 1.2956 - val_accuracy: 0.4290

Epoch 02043: val_loss did not improve from 1.29264
Epoch 2044/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4282 - val_loss: 1.2981 - val_accuracy: 0.4282

Epoch 02044: val_loss did not improve from 1.29264
Epoch 2045/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4311 - val_loss: 1.2942 - val_accuracy: 0.4362

Epoch 02045: val_loss did not improve from 1.29264
Epoch 2046/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4228 - val_loss: 1.2963 - val_accuracy: 0.4346

Epoch 02046: val_loss did not improve from 1.29264
Epoch 2047/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4282 - val_loss: 1.2966 - val_accuracy: 0.4282

Epoch 02047: val_loss did not improve from 1.29264
Epoch 2048/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4263 - val_loss: 1.2948 - val_accuracy: 0.4290

Epoch 02048: val_loss did not improve from 1.29264
Epoch 2049/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4252 - val_loss: 1.2942 - val_accuracy: 0.4306

Epoch 02049: val_loss did not improve from 1.29264
Epoch 2050/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4265 - val_loss: 1.2939 - val_accuracy: 0.4258

Epoch 02050: val_loss did not improve from 1.29264
Epoch 2051/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4259 - val_loss: 1.2946 - val_accuracy: 0.4386

Epoch 02051: val_loss did not improve from 1.29264
Epoch 2052/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4281 - val_loss: 1.2960 - val_accuracy: 0.4386

Epoch 02052: val_loss did not improve from 1.29264
Epoch 2053/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4265 - val_loss: 1.2946 - val_accuracy: 0.4330

Epoch 02053: val_loss did not improve from 1.29264
Epoch 2054/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4299 - val_loss: 1.2922 - val_accuracy: 0.4226

Epoch 02054: val_loss improved from 1.29264 to 1.29223, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2055/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4274 - val_loss: 1.2942 - val_accuracy: 0.4322

Epoch 02055: val_loss did not improve from 1.29223
Epoch 2056/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4273 - val_loss: 1.2955 - val_accuracy: 0.4322

Epoch 02056: val_loss did not improve from 1.29223
Epoch 2057/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4255 - val_loss: 1.2968 - val_accuracy: 0.4274

Epoch 02057: val_loss did not improve from 1.29223
Epoch 2058/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4253 - val_loss: 1.2976 - val_accuracy: 0.4314

Epoch 02058: val_loss did not improve from 1.29223
Epoch 2059/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4295 - val_loss: 1.2950 - val_accuracy: 0.4402

Epoch 02059: val_loss did not improve from 1.29223
Epoch 2060/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4293 - val_loss: 1.2938 - val_accuracy: 0.4354

Epoch 02060: val_loss did not improve from 1.29223
Epoch 2061/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4265 - val_loss: 1.2976 - val_accuracy: 0.4306

Epoch 02061: val_loss did not improve from 1.29223
Epoch 2062/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4294 - val_loss: 1.2956 - val_accuracy: 0.4362

Epoch 02062: val_loss did not improve from 1.29223
Epoch 2063/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4238 - val_loss: 1.2990 - val_accuracy: 0.4322

Epoch 02063: val_loss did not improve from 1.29223
Epoch 2064/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4296 - val_loss: 1.2951 - val_accuracy: 0.4314

Epoch 02064: val_loss did not improve from 1.29223
Epoch 2065/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4257 - val_loss: 1.2952 - val_accuracy: 0.4306

Epoch 02065: val_loss did not improve from 1.29223
Epoch 2066/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4224 - val_loss: 1.2941 - val_accuracy: 0.4330

Epoch 02066: val_loss did not improve from 1.29223
Epoch 2067/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4265 - val_loss: 1.2965 - val_accuracy: 0.4314

Epoch 02067: val_loss did not improve from 1.29223
Epoch 2068/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4287 - val_loss: 1.2939 - val_accuracy: 0.4338

Epoch 02068: val_loss did not improve from 1.29223
Epoch 2069/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4261 - val_loss: 1.2937 - val_accuracy: 0.4330

Epoch 02069: val_loss did not improve from 1.29223
Epoch 2070/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4247 - val_loss: 1.2942 - val_accuracy: 0.4203

Epoch 02070: val_loss did not improve from 1.29223
Epoch 2071/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4239 - val_loss: 1.2972 - val_accuracy: 0.4203

Epoch 02071: val_loss did not improve from 1.29223
Epoch 2072/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4246 - val_loss: 1.3072 - val_accuracy: 0.4234

Epoch 02072: val_loss did not improve from 1.29223
Epoch 2073/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4225 - val_loss: 1.2975 - val_accuracy: 0.4434

Epoch 02073: val_loss did not improve from 1.29223
Epoch 2074/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4270 - val_loss: 1.3022 - val_accuracy: 0.4258

Epoch 02074: val_loss did not improve from 1.29223
Epoch 2075/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4272 - val_loss: 1.2939 - val_accuracy: 0.4314

Epoch 02075: val_loss did not improve from 1.29223
Epoch 2076/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4237 - val_loss: 1.2942 - val_accuracy: 0.4410

Epoch 02076: val_loss did not improve from 1.29223
Epoch 2077/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4252 - val_loss: 1.2937 - val_accuracy: 0.4370

Epoch 02077: val_loss did not improve from 1.29223
Epoch 2078/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4263 - val_loss: 1.2972 - val_accuracy: 0.4418

Epoch 02078: val_loss did not improve from 1.29223
Epoch 2079/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4250 - val_loss: 1.2944 - val_accuracy: 0.4394

Epoch 02079: val_loss did not improve from 1.29223
Epoch 2080/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4289 - val_loss: 1.2941 - val_accuracy: 0.4346

Epoch 02080: val_loss did not improve from 1.29223
Epoch 2081/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4264 - val_loss: 1.2949 - val_accuracy: 0.4346

Epoch 02081: val_loss did not improve from 1.29223
Epoch 2082/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4297 - val_loss: 1.2970 - val_accuracy: 0.4338

Epoch 02082: val_loss did not improve from 1.29223
Epoch 2083/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4246 - val_loss: 1.2958 - val_accuracy: 0.4282

Epoch 02083: val_loss did not improve from 1.29223
Epoch 2084/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4249 - val_loss: 1.2930 - val_accuracy: 0.4322

Epoch 02084: val_loss did not improve from 1.29223
Epoch 2085/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4302 - val_loss: 1.2925 - val_accuracy: 0.4250

Epoch 02085: val_loss did not improve from 1.29223
Epoch 2086/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4242 - val_loss: 1.2956 - val_accuracy: 0.4346

Epoch 02086: val_loss did not improve from 1.29223
Epoch 2087/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4280 - val_loss: 1.2962 - val_accuracy: 0.4234

Epoch 02087: val_loss did not improve from 1.29223
Epoch 2088/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4267 - val_loss: 1.2958 - val_accuracy: 0.4266

Epoch 02088: val_loss did not improve from 1.29223
Epoch 2089/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4280 - val_loss: 1.2937 - val_accuracy: 0.4346

Epoch 02089: val_loss did not improve from 1.29223
Epoch 2090/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4243 - val_loss: 1.2961 - val_accuracy: 0.4378

Epoch 02090: val_loss did not improve from 1.29223
Epoch 2091/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4272 - val_loss: 1.2976 - val_accuracy: 0.4282

Epoch 02091: val_loss did not improve from 1.29223
Epoch 2092/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4293 - val_loss: 1.2953 - val_accuracy: 0.4330

Epoch 02092: val_loss did not improve from 1.29223
Epoch 2093/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4264 - val_loss: 1.2981 - val_accuracy: 0.4258

Epoch 02093: val_loss did not improve from 1.29223
Epoch 2094/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4267 - val_loss: 1.2946 - val_accuracy: 0.4298

Epoch 02094: val_loss did not improve from 1.29223
Epoch 2095/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4280 - val_loss: 1.2980 - val_accuracy: 0.4266

Epoch 02095: val_loss did not improve from 1.29223
Epoch 2096/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4259 - val_loss: 1.2959 - val_accuracy: 0.4322

Epoch 02096: val_loss did not improve from 1.29223
Epoch 2097/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4303 - val_loss: 1.2985 - val_accuracy: 0.4346

Epoch 02097: val_loss did not improve from 1.29223
Epoch 2098/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4283 - val_loss: 1.2935 - val_accuracy: 0.4338

Epoch 02098: val_loss did not improve from 1.29223
Epoch 2099/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4246 - val_loss: 1.2955 - val_accuracy: 0.4298

Epoch 02099: val_loss did not improve from 1.29223
Epoch 2100/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4289 - val_loss: 1.2952 - val_accuracy: 0.4282

Epoch 02100: val_loss did not improve from 1.29223
Epoch 2101/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4321 - val_loss: 1.2937 - val_accuracy: 0.4314

Epoch 02101: val_loss did not improve from 1.29223
Epoch 2102/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4304 - val_loss: 1.2943 - val_accuracy: 0.4274

Epoch 02102: val_loss did not improve from 1.29223
Epoch 2103/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4280 - val_loss: 1.2946 - val_accuracy: 0.4314

Epoch 02103: val_loss did not improve from 1.29223
Epoch 2104/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4285 - val_loss: 1.2998 - val_accuracy: 0.4290

Epoch 02104: val_loss did not improve from 1.29223
Epoch 2105/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4295 - val_loss: 1.2961 - val_accuracy: 0.4346

Epoch 02105: val_loss did not improve from 1.29223
Epoch 2106/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4274 - val_loss: 1.2942 - val_accuracy: 0.4386

Epoch 02106: val_loss did not improve from 1.29223
Epoch 2107/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4265 - val_loss: 1.2967 - val_accuracy: 0.4250

Epoch 02107: val_loss did not improve from 1.29223
Epoch 2108/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4249 - val_loss: 1.2960 - val_accuracy: 0.4306

Epoch 02108: val_loss did not improve from 1.29223
Epoch 2109/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4265 - val_loss: 1.2970 - val_accuracy: 0.4250

Epoch 02109: val_loss did not improve from 1.29223
Epoch 2110/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4250 - val_loss: 1.2946 - val_accuracy: 0.4250

Epoch 02110: val_loss did not improve from 1.29223
Epoch 2111/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4226 - val_loss: 1.2949 - val_accuracy: 0.4378

Epoch 02111: val_loss did not improve from 1.29223
Epoch 2112/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4294 - val_loss: 1.2983 - val_accuracy: 0.4298

Epoch 02112: val_loss did not improve from 1.29223
Epoch 2113/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4230 - val_loss: 1.2932 - val_accuracy: 0.4346

Epoch 02113: val_loss did not improve from 1.29223
Epoch 2114/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4303 - val_loss: 1.2929 - val_accuracy: 0.4370

Epoch 02114: val_loss did not improve from 1.29223
Epoch 2115/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4256 - val_loss: 1.2968 - val_accuracy: 0.4274

Epoch 02115: val_loss did not improve from 1.29223
Epoch 2116/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4327 - val_loss: 1.2921 - val_accuracy: 0.4282

Epoch 02116: val_loss improved from 1.29223 to 1.29210, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2117/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4279 - val_loss: 1.2948 - val_accuracy: 0.4338

Epoch 02117: val_loss did not improve from 1.29210
Epoch 2118/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4232 - val_loss: 1.2973 - val_accuracy: 0.4306

Epoch 02118: val_loss did not improve from 1.29210
Epoch 2119/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4271 - val_loss: 1.2946 - val_accuracy: 0.4282

Epoch 02119: val_loss did not improve from 1.29210
Epoch 2120/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4258 - val_loss: 1.2945 - val_accuracy: 0.4258

Epoch 02120: val_loss did not improve from 1.29210
Epoch 2121/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4252 - val_loss: 1.2926 - val_accuracy: 0.4298

Epoch 02121: val_loss did not improve from 1.29210
Epoch 2122/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4336 - val_loss: 1.2937 - val_accuracy: 0.4306

Epoch 02122: val_loss did not improve from 1.29210
Epoch 2123/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4288 - val_loss: 1.2939 - val_accuracy: 0.4274

Epoch 02123: val_loss did not improve from 1.29210
Epoch 2124/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4280 - val_loss: 1.2965 - val_accuracy: 0.4298

Epoch 02124: val_loss did not improve from 1.29210
Epoch 2125/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4277 - val_loss: 1.2939 - val_accuracy: 0.4298

Epoch 02125: val_loss did not improve from 1.29210
Epoch 2126/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4281 - val_loss: 1.2990 - val_accuracy: 0.4274

Epoch 02126: val_loss did not improve from 1.29210
Epoch 2127/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4329 - val_loss: 1.2971 - val_accuracy: 0.4258

Epoch 02127: val_loss did not improve from 1.29210
Epoch 2128/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4269 - val_loss: 1.2943 - val_accuracy: 0.4322

Epoch 02128: val_loss did not improve from 1.29210
Epoch 2129/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4298 - val_loss: 1.2977 - val_accuracy: 0.4242

Epoch 02129: val_loss did not improve from 1.29210
Epoch 2130/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4303 - val_loss: 1.2934 - val_accuracy: 0.4306

Epoch 02130: val_loss did not improve from 1.29210
Epoch 2131/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4295 - val_loss: 1.2923 - val_accuracy: 0.4266

Epoch 02131: val_loss did not improve from 1.29210
Epoch 2132/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4277 - val_loss: 1.2927 - val_accuracy: 0.4346

Epoch 02132: val_loss did not improve from 1.29210
Epoch 2133/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4320 - val_loss: 1.2919 - val_accuracy: 0.4338

Epoch 02133: val_loss improved from 1.29210 to 1.29188, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2134/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4323 - val_loss: 1.2949 - val_accuracy: 0.4402

Epoch 02134: val_loss did not improve from 1.29188
Epoch 2135/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4318 - val_loss: 1.3035 - val_accuracy: 0.4242

Epoch 02135: val_loss did not improve from 1.29188
Epoch 2136/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4259 - val_loss: 1.2946 - val_accuracy: 0.4266

Epoch 02136: val_loss did not improve from 1.29188
Epoch 2137/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4289 - val_loss: 1.2960 - val_accuracy: 0.4274

Epoch 02137: val_loss did not improve from 1.29188
Epoch 2138/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4272 - val_loss: 1.2961 - val_accuracy: 0.4290

Epoch 02138: val_loss did not improve from 1.29188
Epoch 2139/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4296 - val_loss: 1.2951 - val_accuracy: 0.4370

Epoch 02139: val_loss did not improve from 1.29188
Epoch 2140/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4295 - val_loss: 1.2948 - val_accuracy: 0.4234

Epoch 02140: val_loss did not improve from 1.29188
Epoch 2141/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4269 - val_loss: 1.2973 - val_accuracy: 0.4362

Epoch 02141: val_loss did not improve from 1.29188
Epoch 2142/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4304 - val_loss: 1.2931 - val_accuracy: 0.4338

Epoch 02142: val_loss did not improve from 1.29188
Epoch 2143/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4256 - val_loss: 1.2948 - val_accuracy: 0.4354

Epoch 02143: val_loss did not improve from 1.29188
Epoch 2144/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4282 - val_loss: 1.2929 - val_accuracy: 0.4330

Epoch 02144: val_loss did not improve from 1.29188
Epoch 2145/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4303 - val_loss: 1.2935 - val_accuracy: 0.4386

Epoch 02145: val_loss did not improve from 1.29188
Epoch 2146/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4294 - val_loss: 1.2935 - val_accuracy: 0.4338

Epoch 02146: val_loss did not improve from 1.29188
Epoch 2147/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4296 - val_loss: 1.2962 - val_accuracy: 0.4234

Epoch 02147: val_loss did not improve from 1.29188
Epoch 2148/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4294 - val_loss: 1.2933 - val_accuracy: 0.4386

Epoch 02148: val_loss did not improve from 1.29188
Epoch 2149/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4314 - val_loss: 1.2938 - val_accuracy: 0.4258

Epoch 02149: val_loss did not improve from 1.29188
Epoch 2150/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4271 - val_loss: 1.2924 - val_accuracy: 0.4290

Epoch 02150: val_loss did not improve from 1.29188
Epoch 2151/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4304 - val_loss: 1.2935 - val_accuracy: 0.4282

Epoch 02151: val_loss did not improve from 1.29188
Epoch 2152/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4272 - val_loss: 1.2983 - val_accuracy: 0.4354

Epoch 02152: val_loss did not improve from 1.29188
Epoch 2153/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4266 - val_loss: 1.2938 - val_accuracy: 0.4330

Epoch 02153: val_loss did not improve from 1.29188
Epoch 2154/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4323 - val_loss: 1.2929 - val_accuracy: 0.4386

Epoch 02154: val_loss did not improve from 1.29188
Epoch 2155/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4260 - val_loss: 1.2921 - val_accuracy: 0.4330

Epoch 02155: val_loss did not improve from 1.29188
Epoch 2156/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4295 - val_loss: 1.2928 - val_accuracy: 0.4402

Epoch 02156: val_loss did not improve from 1.29188
Epoch 2157/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4287 - val_loss: 1.2936 - val_accuracy: 0.4298

Epoch 02157: val_loss did not improve from 1.29188
Epoch 2158/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4290 - val_loss: 1.2926 - val_accuracy: 0.4266

Epoch 02158: val_loss did not improve from 1.29188
Epoch 2159/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4303 - val_loss: 1.2941 - val_accuracy: 0.4298

Epoch 02159: val_loss did not improve from 1.29188
Epoch 2160/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4260 - val_loss: 1.2957 - val_accuracy: 0.4274

Epoch 02160: val_loss did not improve from 1.29188
Epoch 2161/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4274 - val_loss: 1.2934 - val_accuracy: 0.4282

Epoch 02161: val_loss did not improve from 1.29188
Epoch 2162/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4306 - val_loss: 1.2940 - val_accuracy: 0.4346

Epoch 02162: val_loss did not improve from 1.29188
Epoch 2163/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4281 - val_loss: 1.2948 - val_accuracy: 0.4250

Epoch 02163: val_loss did not improve from 1.29188
Epoch 2164/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4318 - val_loss: 1.2939 - val_accuracy: 0.4322

Epoch 02164: val_loss did not improve from 1.29188
Epoch 2165/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4318 - val_loss: 1.2908 - val_accuracy: 0.4282

Epoch 02165: val_loss improved from 1.29188 to 1.29084, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2166/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4276 - val_loss: 1.2901 - val_accuracy: 0.4370

Epoch 02166: val_loss improved from 1.29084 to 1.29008, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2167/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4262 - val_loss: 1.2981 - val_accuracy: 0.4346

Epoch 02167: val_loss did not improve from 1.29008
Epoch 2168/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4326 - val_loss: 1.2930 - val_accuracy: 0.4258

Epoch 02168: val_loss did not improve from 1.29008
Epoch 2169/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4270 - val_loss: 1.2938 - val_accuracy: 0.4330

Epoch 02169: val_loss did not improve from 1.29008
Epoch 2170/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4281 - val_loss: 1.2949 - val_accuracy: 0.4338

Epoch 02170: val_loss did not improve from 1.29008
Epoch 2171/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4286 - val_loss: 1.2925 - val_accuracy: 0.4226

Epoch 02171: val_loss did not improve from 1.29008
Epoch 2172/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4317 - val_loss: 1.2985 - val_accuracy: 0.4354

Epoch 02172: val_loss did not improve from 1.29008
Epoch 2173/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4310 - val_loss: 1.2962 - val_accuracy: 0.4338

Epoch 02173: val_loss did not improve from 1.29008
Epoch 2174/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4275 - val_loss: 1.2967 - val_accuracy: 0.4322

Epoch 02174: val_loss did not improve from 1.29008
Epoch 2175/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4298 - val_loss: 1.2940 - val_accuracy: 0.4370

Epoch 02175: val_loss did not improve from 1.29008
Epoch 2176/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4324 - val_loss: 1.2913 - val_accuracy: 0.4322

Epoch 02176: val_loss did not improve from 1.29008
Epoch 2177/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4246 - val_loss: 1.2935 - val_accuracy: 0.4418

Epoch 02177: val_loss did not improve from 1.29008
Epoch 2178/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4267 - val_loss: 1.2950 - val_accuracy: 0.4258

Epoch 02178: val_loss did not improve from 1.29008
Epoch 2179/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4300 - val_loss: 1.3019 - val_accuracy: 0.4346

Epoch 02179: val_loss did not improve from 1.29008
Epoch 2180/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4214 - val_loss: 1.2975 - val_accuracy: 0.4298

Epoch 02180: val_loss did not improve from 1.29008
Epoch 2181/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4292 - val_loss: 1.2964 - val_accuracy: 0.4354

Epoch 02181: val_loss did not improve from 1.29008
Epoch 2182/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4274 - val_loss: 1.2912 - val_accuracy: 0.4330

Epoch 02182: val_loss did not improve from 1.29008
Epoch 2183/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4303 - val_loss: 1.2921 - val_accuracy: 0.4354

Epoch 02183: val_loss did not improve from 1.29008
Epoch 2184/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4310 - val_loss: 1.2947 - val_accuracy: 0.4274

Epoch 02184: val_loss did not improve from 1.29008
Epoch 2185/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4288 - val_loss: 1.2926 - val_accuracy: 0.4370

Epoch 02185: val_loss did not improve from 1.29008
Epoch 2186/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4309 - val_loss: 1.2956 - val_accuracy: 0.4354

Epoch 02186: val_loss did not improve from 1.29008
Epoch 2187/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4318 - val_loss: 1.2956 - val_accuracy: 0.4402

Epoch 02187: val_loss did not improve from 1.29008
Epoch 2188/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4293 - val_loss: 1.2908 - val_accuracy: 0.4354

Epoch 02188: val_loss did not improve from 1.29008
Epoch 2189/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4287 - val_loss: 1.2926 - val_accuracy: 0.4346

Epoch 02189: val_loss did not improve from 1.29008
Epoch 2190/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4319 - val_loss: 1.2931 - val_accuracy: 0.4282

Epoch 02190: val_loss did not improve from 1.29008
Epoch 2191/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4303 - val_loss: 1.2950 - val_accuracy: 0.4378

Epoch 02191: val_loss did not improve from 1.29008
Epoch 2192/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4334 - val_loss: 1.2947 - val_accuracy: 0.4330

Epoch 02192: val_loss did not improve from 1.29008
Epoch 2193/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4284 - val_loss: 1.2926 - val_accuracy: 0.4338

Epoch 02193: val_loss did not improve from 1.29008
Epoch 2194/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4295 - val_loss: 1.2967 - val_accuracy: 0.4314

Epoch 02194: val_loss did not improve from 1.29008
Epoch 2195/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4289 - val_loss: 1.2930 - val_accuracy: 0.4226

Epoch 02195: val_loss did not improve from 1.29008
Epoch 2196/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4293 - val_loss: 1.2926 - val_accuracy: 0.4274

Epoch 02196: val_loss did not improve from 1.29008
Epoch 2197/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4342 - val_loss: 1.2937 - val_accuracy: 0.4330

Epoch 02197: val_loss did not improve from 1.29008
Epoch 2198/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4288 - val_loss: 1.2941 - val_accuracy: 0.4378

Epoch 02198: val_loss did not improve from 1.29008
Epoch 2199/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4314 - val_loss: 1.2957 - val_accuracy: 0.4330

Epoch 02199: val_loss did not improve from 1.29008
Epoch 2200/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4249 - val_loss: 1.2934 - val_accuracy: 0.4354

Epoch 02200: val_loss did not improve from 1.29008
Epoch 2201/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4337 - val_loss: 1.2924 - val_accuracy: 0.4338

Epoch 02201: val_loss did not improve from 1.29008
Epoch 2202/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4295 - val_loss: 1.2930 - val_accuracy: 0.4290

Epoch 02202: val_loss did not improve from 1.29008
Epoch 2203/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4332 - val_loss: 1.2920 - val_accuracy: 0.4338

Epoch 02203: val_loss did not improve from 1.29008
Epoch 2204/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4328 - val_loss: 1.2953 - val_accuracy: 0.4346

Epoch 02204: val_loss did not improve from 1.29008
Epoch 2205/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4322 - val_loss: 1.2976 - val_accuracy: 0.4330

Epoch 02205: val_loss did not improve from 1.29008
Epoch 2206/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4280 - val_loss: 1.3043 - val_accuracy: 0.4282

Epoch 02206: val_loss did not improve from 1.29008
Epoch 2207/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4243 - val_loss: 1.2941 - val_accuracy: 0.4370

Epoch 02207: val_loss did not improve from 1.29008
Epoch 2208/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4255 - val_loss: 1.2909 - val_accuracy: 0.4274

Epoch 02208: val_loss did not improve from 1.29008
Epoch 2209/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4272 - val_loss: 1.2955 - val_accuracy: 0.4402

Epoch 02209: val_loss did not improve from 1.29008
Epoch 2210/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4279 - val_loss: 1.2969 - val_accuracy: 0.4290

Epoch 02210: val_loss did not improve from 1.29008
Epoch 2211/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4318 - val_loss: 1.2950 - val_accuracy: 0.4410

Epoch 02211: val_loss did not improve from 1.29008
Epoch 2212/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4304 - val_loss: 1.2903 - val_accuracy: 0.4362

Epoch 02212: val_loss did not improve from 1.29008
Epoch 2213/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4340 - val_loss: 1.2909 - val_accuracy: 0.4402

Epoch 02213: val_loss did not improve from 1.29008
Epoch 2214/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4318 - val_loss: 1.2906 - val_accuracy: 0.4330

Epoch 02214: val_loss did not improve from 1.29008
Epoch 2215/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4336 - val_loss: 1.2897 - val_accuracy: 0.4346

Epoch 02215: val_loss improved from 1.29008 to 1.28973, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2216/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4329 - val_loss: 1.2903 - val_accuracy: 0.4322

Epoch 02216: val_loss did not improve from 1.28973
Epoch 2217/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4321 - val_loss: 1.2907 - val_accuracy: 0.4370

Epoch 02217: val_loss did not improve from 1.28973
Epoch 2218/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4283 - val_loss: 1.2938 - val_accuracy: 0.4410

Epoch 02218: val_loss did not improve from 1.28973
Epoch 2219/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4302 - val_loss: 1.2901 - val_accuracy: 0.4322

Epoch 02219: val_loss did not improve from 1.28973
Epoch 2220/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4287 - val_loss: 1.2930 - val_accuracy: 0.4322

Epoch 02220: val_loss did not improve from 1.28973
Epoch 2221/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4272 - val_loss: 1.2898 - val_accuracy: 0.4394

Epoch 02221: val_loss did not improve from 1.28973
Epoch 2222/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4303 - val_loss: 1.2918 - val_accuracy: 0.4306

Epoch 02222: val_loss did not improve from 1.28973
Epoch 2223/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4320 - val_loss: 1.2935 - val_accuracy: 0.4330

Epoch 02223: val_loss did not improve from 1.28973
Epoch 2224/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4334 - val_loss: 1.2951 - val_accuracy: 0.4346

Epoch 02224: val_loss did not improve from 1.28973
Epoch 2225/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4304 - val_loss: 1.2935 - val_accuracy: 0.4298

Epoch 02225: val_loss did not improve from 1.28973
Epoch 2226/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4312 - val_loss: 1.2924 - val_accuracy: 0.4346

Epoch 02226: val_loss did not improve from 1.28973
Epoch 2227/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4336 - val_loss: 1.2964 - val_accuracy: 0.4378

Epoch 02227: val_loss did not improve from 1.28973
Epoch 2228/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4274 - val_loss: 1.2924 - val_accuracy: 0.4378

Epoch 02228: val_loss did not improve from 1.28973
Epoch 2229/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4297 - val_loss: 1.2930 - val_accuracy: 0.4330

Epoch 02229: val_loss did not improve from 1.28973
Epoch 2230/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4303 - val_loss: 1.2911 - val_accuracy: 0.4338

Epoch 02230: val_loss did not improve from 1.28973
Epoch 2231/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4308 - val_loss: 1.2912 - val_accuracy: 0.4402

Epoch 02231: val_loss did not improve from 1.28973
Epoch 2232/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4295 - val_loss: 1.2917 - val_accuracy: 0.4370

Epoch 02232: val_loss did not improve from 1.28973
Epoch 2233/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4305 - val_loss: 1.2914 - val_accuracy: 0.4426

Epoch 02233: val_loss did not improve from 1.28973
Epoch 2234/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4322 - val_loss: 1.2972 - val_accuracy: 0.4354

Epoch 02234: val_loss did not improve from 1.28973
Epoch 2235/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4287 - val_loss: 1.2924 - val_accuracy: 0.4370

Epoch 02235: val_loss did not improve from 1.28973
Epoch 2236/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4280 - val_loss: 1.2947 - val_accuracy: 0.4426

Epoch 02236: val_loss did not improve from 1.28973
Epoch 2237/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4295 - val_loss: 1.2901 - val_accuracy: 0.4418

Epoch 02237: val_loss did not improve from 1.28973
Epoch 2238/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4287 - val_loss: 1.2930 - val_accuracy: 0.4338

Epoch 02238: val_loss did not improve from 1.28973
Epoch 2239/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4327 - val_loss: 1.2952 - val_accuracy: 0.4290

Epoch 02239: val_loss did not improve from 1.28973
Epoch 2240/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4275 - val_loss: 1.2929 - val_accuracy: 0.4362

Epoch 02240: val_loss did not improve from 1.28973
Epoch 2241/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4265 - val_loss: 1.2921 - val_accuracy: 0.4258

Epoch 02241: val_loss did not improve from 1.28973
Epoch 2242/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4280 - val_loss: 1.2952 - val_accuracy: 0.4370

Epoch 02242: val_loss did not improve from 1.28973
Epoch 2243/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4300 - val_loss: 1.2923 - val_accuracy: 0.4322

Epoch 02243: val_loss did not improve from 1.28973
Epoch 2244/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4288 - val_loss: 1.2904 - val_accuracy: 0.4322

Epoch 02244: val_loss did not improve from 1.28973
Epoch 2245/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4309 - val_loss: 1.2911 - val_accuracy: 0.4418

Epoch 02245: val_loss did not improve from 1.28973
Epoch 2246/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4349 - val_loss: 1.2896 - val_accuracy: 0.4338

Epoch 02246: val_loss improved from 1.28973 to 1.28957, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2247/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4309 - val_loss: 1.2945 - val_accuracy: 0.4418

Epoch 02247: val_loss did not improve from 1.28957
Epoch 2248/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4353 - val_loss: 1.2943 - val_accuracy: 0.4306

Epoch 02248: val_loss did not improve from 1.28957
Epoch 2249/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4293 - val_loss: 1.2961 - val_accuracy: 0.4426

Epoch 02249: val_loss did not improve from 1.28957
Epoch 2250/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4323 - val_loss: 1.2948 - val_accuracy: 0.4362

Epoch 02250: val_loss did not improve from 1.28957
Epoch 2251/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4250 - val_loss: 1.2911 - val_accuracy: 0.4338

Epoch 02251: val_loss did not improve from 1.28957
Epoch 2252/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4282 - val_loss: 1.2889 - val_accuracy: 0.4418

Epoch 02252: val_loss improved from 1.28957 to 1.28894, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2253/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4280 - val_loss: 1.2905 - val_accuracy: 0.4338

Epoch 02253: val_loss did not improve from 1.28894
Epoch 2254/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4277 - val_loss: 1.2916 - val_accuracy: 0.4418

Epoch 02254: val_loss did not improve from 1.28894
Epoch 2255/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4295 - val_loss: 1.2915 - val_accuracy: 0.4330

Epoch 02255: val_loss did not improve from 1.28894
Epoch 2256/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4286 - val_loss: 1.2920 - val_accuracy: 0.4394

Epoch 02256: val_loss did not improve from 1.28894
Epoch 2257/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4301 - val_loss: 1.2917 - val_accuracy: 0.4322

Epoch 02257: val_loss did not improve from 1.28894
Epoch 2258/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4264 - val_loss: 1.2925 - val_accuracy: 0.4410

Epoch 02258: val_loss did not improve from 1.28894
Epoch 2259/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4280 - val_loss: 1.2918 - val_accuracy: 0.4362

Epoch 02259: val_loss did not improve from 1.28894
Epoch 2260/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4312 - val_loss: 1.2933 - val_accuracy: 0.4402

Epoch 02260: val_loss did not improve from 1.28894
Epoch 2261/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4299 - val_loss: 1.2940 - val_accuracy: 0.4378

Epoch 02261: val_loss did not improve from 1.28894
Epoch 2262/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4298 - val_loss: 1.2928 - val_accuracy: 0.4322

Epoch 02262: val_loss did not improve from 1.28894
Epoch 2263/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4288 - val_loss: 1.2933 - val_accuracy: 0.4258

Epoch 02263: val_loss did not improve from 1.28894
Epoch 2264/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4231 - val_loss: 1.2921 - val_accuracy: 0.4354

Epoch 02264: val_loss did not improve from 1.28894
Epoch 2265/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4293 - val_loss: 1.2935 - val_accuracy: 0.4266

Epoch 02265: val_loss did not improve from 1.28894
Epoch 2266/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4333 - val_loss: 1.2946 - val_accuracy: 0.4370

Epoch 02266: val_loss did not improve from 1.28894
Epoch 2267/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4288 - val_loss: 1.2958 - val_accuracy: 0.4258

Epoch 02267: val_loss did not improve from 1.28894
Epoch 2268/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4272 - val_loss: 1.2910 - val_accuracy: 0.4354

Epoch 02268: val_loss did not improve from 1.28894
Epoch 2269/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4315 - val_loss: 1.2916 - val_accuracy: 0.4394

Epoch 02269: val_loss did not improve from 1.28894
Epoch 2270/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4298 - val_loss: 1.2892 - val_accuracy: 0.4338

Epoch 02270: val_loss did not improve from 1.28894
Epoch 2271/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4295 - val_loss: 1.2889 - val_accuracy: 0.4378

Epoch 02271: val_loss improved from 1.28894 to 1.28887, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2272/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4294 - val_loss: 1.2918 - val_accuracy: 0.4402

Epoch 02272: val_loss did not improve from 1.28887
Epoch 2273/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4348 - val_loss: 1.2936 - val_accuracy: 0.4394

Epoch 02273: val_loss did not improve from 1.28887
Epoch 2274/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4321 - val_loss: 1.2905 - val_accuracy: 0.4314

Epoch 02274: val_loss did not improve from 1.28887
Epoch 2275/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4303 - val_loss: 1.2909 - val_accuracy: 0.4386

Epoch 02275: val_loss did not improve from 1.28887
Epoch 2276/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4299 - val_loss: 1.2911 - val_accuracy: 0.4306

Epoch 02276: val_loss did not improve from 1.28887
Epoch 2277/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4285 - val_loss: 1.2932 - val_accuracy: 0.4354

Epoch 02277: val_loss did not improve from 1.28887
Epoch 2278/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4302 - val_loss: 1.2973 - val_accuracy: 0.4314

Epoch 02278: val_loss did not improve from 1.28887
Epoch 2279/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4303 - val_loss: 1.2946 - val_accuracy: 0.4306

Epoch 02279: val_loss did not improve from 1.28887
Epoch 2280/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4277 - val_loss: 1.2956 - val_accuracy: 0.4386

Epoch 02280: val_loss did not improve from 1.28887
Epoch 2281/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4302 - val_loss: 1.2916 - val_accuracy: 0.4346

Epoch 02281: val_loss did not improve from 1.28887
Epoch 2282/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4341 - val_loss: 1.2921 - val_accuracy: 0.4322

Epoch 02282: val_loss did not improve from 1.28887
Epoch 2283/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4310 - val_loss: 1.2957 - val_accuracy: 0.4378

Epoch 02283: val_loss did not improve from 1.28887
Epoch 2284/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4344 - val_loss: 1.2884 - val_accuracy: 0.4394

Epoch 02284: val_loss improved from 1.28887 to 1.28840, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2285/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4295 - val_loss: 1.2899 - val_accuracy: 0.4322

Epoch 02285: val_loss did not improve from 1.28840
Epoch 2286/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4289 - val_loss: 1.2963 - val_accuracy: 0.4426

Epoch 02286: val_loss did not improve from 1.28840
Epoch 2287/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4279 - val_loss: 1.2889 - val_accuracy: 0.4370

Epoch 02287: val_loss did not improve from 1.28840
Epoch 2288/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4302 - val_loss: 1.2933 - val_accuracy: 0.4306

Epoch 02288: val_loss did not improve from 1.28840
Epoch 2289/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4339 - val_loss: 1.2909 - val_accuracy: 0.4386

Epoch 02289: val_loss did not improve from 1.28840
Epoch 2290/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4302 - val_loss: 1.2913 - val_accuracy: 0.4378

Epoch 02290: val_loss did not improve from 1.28840
Epoch 2291/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4321 - val_loss: 1.2908 - val_accuracy: 0.4394

Epoch 02291: val_loss did not improve from 1.28840
Epoch 2292/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4311 - val_loss: 1.2893 - val_accuracy: 0.4338

Epoch 02292: val_loss did not improve from 1.28840
Epoch 2293/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4292 - val_loss: 1.2926 - val_accuracy: 0.4322

Epoch 02293: val_loss did not improve from 1.28840
Epoch 2294/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4264 - val_loss: 1.2942 - val_accuracy: 0.4362

Epoch 02294: val_loss did not improve from 1.28840
Epoch 2295/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4309 - val_loss: 1.2946 - val_accuracy: 0.4394

Epoch 02295: val_loss did not improve from 1.28840
Epoch 2296/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4333 - val_loss: 1.2924 - val_accuracy: 0.4258

Epoch 02296: val_loss did not improve from 1.28840
Epoch 2297/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4317 - val_loss: 1.2914 - val_accuracy: 0.4346

Epoch 02297: val_loss did not improve from 1.28840
Epoch 2298/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4339 - val_loss: 1.2927 - val_accuracy: 0.4346

Epoch 02298: val_loss did not improve from 1.28840
Epoch 2299/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4334 - val_loss: 1.2928 - val_accuracy: 0.4298

Epoch 02299: val_loss did not improve from 1.28840
Epoch 2300/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4261 - val_loss: 1.2916 - val_accuracy: 0.4322

Epoch 02300: val_loss did not improve from 1.28840
Epoch 2301/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4307 - val_loss: 1.2927 - val_accuracy: 0.4338

Epoch 02301: val_loss did not improve from 1.28840
Epoch 2302/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4290 - val_loss: 1.2912 - val_accuracy: 0.4274

Epoch 02302: val_loss did not improve from 1.28840
Epoch 2303/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4324 - val_loss: 1.2941 - val_accuracy: 0.4306

Epoch 02303: val_loss did not improve from 1.28840
Epoch 2304/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4270 - val_loss: 1.2924 - val_accuracy: 0.4458

Epoch 02304: val_loss did not improve from 1.28840
Epoch 2305/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4284 - val_loss: 1.2909 - val_accuracy: 0.4282

Epoch 02305: val_loss did not improve from 1.28840
Epoch 2306/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4312 - val_loss: 1.2901 - val_accuracy: 0.4338

Epoch 02306: val_loss did not improve from 1.28840
Epoch 2307/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4310 - val_loss: 1.2919 - val_accuracy: 0.4346

Epoch 02307: val_loss did not improve from 1.28840
Epoch 2308/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4356 - val_loss: 1.2905 - val_accuracy: 0.4410

Epoch 02308: val_loss did not improve from 1.28840
Epoch 2309/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4349 - val_loss: 1.2908 - val_accuracy: 0.4378

Epoch 02309: val_loss did not improve from 1.28840
Epoch 2310/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4315 - val_loss: 1.2902 - val_accuracy: 0.4274

Epoch 02310: val_loss did not improve from 1.28840
Epoch 2311/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4324 - val_loss: 1.2944 - val_accuracy: 0.4306

Epoch 02311: val_loss did not improve from 1.28840
Epoch 2312/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4301 - val_loss: 1.2921 - val_accuracy: 0.4442

Epoch 02312: val_loss did not improve from 1.28840
Epoch 2313/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4303 - val_loss: 1.2905 - val_accuracy: 0.4378

Epoch 02313: val_loss did not improve from 1.28840
Epoch 2314/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4309 - val_loss: 1.2886 - val_accuracy: 0.4386

Epoch 02314: val_loss did not improve from 1.28840
Epoch 2315/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4308 - val_loss: 1.2906 - val_accuracy: 0.4378

Epoch 02315: val_loss did not improve from 1.28840
Epoch 2316/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4359 - val_loss: 1.2890 - val_accuracy: 0.4354

Epoch 02316: val_loss did not improve from 1.28840
Epoch 2317/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4296 - val_loss: 1.2944 - val_accuracy: 0.4394

Epoch 02317: val_loss did not improve from 1.28840
Epoch 2318/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4265 - val_loss: 1.2899 - val_accuracy: 0.4306

Epoch 02318: val_loss did not improve from 1.28840
Epoch 2319/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4286 - val_loss: 1.2911 - val_accuracy: 0.4314

Epoch 02319: val_loss did not improve from 1.28840
Epoch 2320/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4328 - val_loss: 1.2930 - val_accuracy: 0.4410

Epoch 02320: val_loss did not improve from 1.28840
Epoch 2321/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4294 - val_loss: 1.2917 - val_accuracy: 0.4346

Epoch 02321: val_loss did not improve from 1.28840
Epoch 2322/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4311 - val_loss: 1.2914 - val_accuracy: 0.4274

Epoch 02322: val_loss did not improve from 1.28840
Epoch 2323/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4290 - val_loss: 1.2925 - val_accuracy: 0.4354

Epoch 02323: val_loss did not improve from 1.28840
Epoch 2324/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4322 - val_loss: 1.2923 - val_accuracy: 0.4322

Epoch 02324: val_loss did not improve from 1.28840
Epoch 2325/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4295 - val_loss: 1.2943 - val_accuracy: 0.4250

Epoch 02325: val_loss did not improve from 1.28840
Epoch 2326/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4334 - val_loss: 1.2932 - val_accuracy: 0.4362

Epoch 02326: val_loss did not improve from 1.28840
Epoch 2327/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4325 - val_loss: 1.2910 - val_accuracy: 0.4362

Epoch 02327: val_loss did not improve from 1.28840
Epoch 2328/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4272 - val_loss: 1.2917 - val_accuracy: 0.4370

Epoch 02328: val_loss did not improve from 1.28840
Epoch 2329/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4337 - val_loss: 1.2917 - val_accuracy: 0.4402

Epoch 02329: val_loss did not improve from 1.28840
Epoch 2330/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4284 - val_loss: 1.2937 - val_accuracy: 0.4362

Epoch 02330: val_loss did not improve from 1.28840
Epoch 2331/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4318 - val_loss: 1.2913 - val_accuracy: 0.4362

Epoch 02331: val_loss did not improve from 1.28840
Epoch 2332/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4311 - val_loss: 1.2911 - val_accuracy: 0.4378

Epoch 02332: val_loss did not improve from 1.28840
Epoch 2333/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4317 - val_loss: 1.2903 - val_accuracy: 0.4330

Epoch 02333: val_loss did not improve from 1.28840
Epoch 2334/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4308 - val_loss: 1.2916 - val_accuracy: 0.4378

Epoch 02334: val_loss did not improve from 1.28840
Epoch 2335/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4316 - val_loss: 1.2940 - val_accuracy: 0.4458

Epoch 02335: val_loss did not improve from 1.28840
Epoch 2336/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4288 - val_loss: 1.2953 - val_accuracy: 0.4346

Epoch 02336: val_loss did not improve from 1.28840
Epoch 2337/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4299 - val_loss: 1.2920 - val_accuracy: 0.4370

Epoch 02337: val_loss did not improve from 1.28840
Epoch 2338/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4289 - val_loss: 1.2921 - val_accuracy: 0.4338

Epoch 02338: val_loss did not improve from 1.28840
Epoch 2339/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4320 - val_loss: 1.2950 - val_accuracy: 0.4362

Epoch 02339: val_loss did not improve from 1.28840
Epoch 2340/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4280 - val_loss: 1.2940 - val_accuracy: 0.4418

Epoch 02340: val_loss did not improve from 1.28840
Epoch 2341/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4308 - val_loss: 1.2923 - val_accuracy: 0.4386

Epoch 02341: val_loss did not improve from 1.28840
Epoch 2342/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4318 - val_loss: 1.2898 - val_accuracy: 0.4306

Epoch 02342: val_loss did not improve from 1.28840
Epoch 2343/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4291 - val_loss: 1.2898 - val_accuracy: 0.4338

Epoch 02343: val_loss did not improve from 1.28840
Epoch 2344/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4296 - val_loss: 1.2930 - val_accuracy: 0.4250

Epoch 02344: val_loss did not improve from 1.28840
Epoch 2345/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4319 - val_loss: 1.2914 - val_accuracy: 0.4306

Epoch 02345: val_loss did not improve from 1.28840
Epoch 2346/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4295 - val_loss: 1.2910 - val_accuracy: 0.4314

Epoch 02346: val_loss did not improve from 1.28840
Epoch 2347/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4260 - val_loss: 1.2962 - val_accuracy: 0.4354

Epoch 02347: val_loss did not improve from 1.28840
Epoch 2348/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4308 - val_loss: 1.2911 - val_accuracy: 0.4274

Epoch 02348: val_loss did not improve from 1.28840
Epoch 2349/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4289 - val_loss: 1.2946 - val_accuracy: 0.4290

Epoch 02349: val_loss did not improve from 1.28840
Epoch 2350/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4295 - val_loss: 1.2950 - val_accuracy: 0.4402

Epoch 02350: val_loss did not improve from 1.28840
Epoch 2351/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4327 - val_loss: 1.2922 - val_accuracy: 0.4266

Epoch 02351: val_loss did not improve from 1.28840
Epoch 2352/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4325 - val_loss: 1.2925 - val_accuracy: 0.4290

Epoch 02352: val_loss did not improve from 1.28840
Epoch 2353/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4330 - val_loss: 1.2914 - val_accuracy: 0.4410

Epoch 02353: val_loss did not improve from 1.28840
Epoch 2354/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4267 - val_loss: 1.2935 - val_accuracy: 0.4434

Epoch 02354: val_loss did not improve from 1.28840
Epoch 2355/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4302 - val_loss: 1.2925 - val_accuracy: 0.4298

Epoch 02355: val_loss did not improve from 1.28840
Epoch 2356/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4284 - val_loss: 1.2947 - val_accuracy: 0.4426

Epoch 02356: val_loss did not improve from 1.28840
Epoch 2357/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4336 - val_loss: 1.2912 - val_accuracy: 0.4354

Epoch 02357: val_loss did not improve from 1.28840
Epoch 2358/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4338 - val_loss: 1.2937 - val_accuracy: 0.4306

Epoch 02358: val_loss did not improve from 1.28840
Epoch 2359/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4299 - val_loss: 1.2917 - val_accuracy: 0.4274

Epoch 02359: val_loss did not improve from 1.28840
Epoch 2360/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4310 - val_loss: 1.2924 - val_accuracy: 0.4362

Epoch 02360: val_loss did not improve from 1.28840
Epoch 2361/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4296 - val_loss: 1.2898 - val_accuracy: 0.4306

Epoch 02361: val_loss did not improve from 1.28840
Epoch 2362/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4292 - val_loss: 1.2913 - val_accuracy: 0.4290

Epoch 02362: val_loss did not improve from 1.28840
Epoch 2363/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4328 - val_loss: 1.2914 - val_accuracy: 0.4386

Epoch 02363: val_loss did not improve from 1.28840
Epoch 2364/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4312 - val_loss: 1.2907 - val_accuracy: 0.4362

Epoch 02364: val_loss did not improve from 1.28840
Epoch 2365/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4327 - val_loss: 1.2918 - val_accuracy: 0.4258

Epoch 02365: val_loss did not improve from 1.28840
Epoch 2366/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4317 - val_loss: 1.2945 - val_accuracy: 0.4458

Epoch 02366: val_loss did not improve from 1.28840
Epoch 2367/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4273 - val_loss: 1.2911 - val_accuracy: 0.4274

Epoch 02367: val_loss did not improve from 1.28840
Epoch 2368/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4286 - val_loss: 1.2933 - val_accuracy: 0.4386

Epoch 02368: val_loss did not improve from 1.28840
Epoch 2369/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4343 - val_loss: 1.2930 - val_accuracy: 0.4370

Epoch 02369: val_loss did not improve from 1.28840
Epoch 2370/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4346 - val_loss: 1.2932 - val_accuracy: 0.4362

Epoch 02370: val_loss did not improve from 1.28840
Epoch 2371/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4270 - val_loss: 1.2914 - val_accuracy: 0.4434

Epoch 02371: val_loss did not improve from 1.28840
Epoch 2372/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4315 - val_loss: 1.2911 - val_accuracy: 0.4394

Epoch 02372: val_loss did not improve from 1.28840
Epoch 2373/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4327 - val_loss: 1.2909 - val_accuracy: 0.4314

Epoch 02373: val_loss did not improve from 1.28840
Epoch 2374/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4291 - val_loss: 1.2932 - val_accuracy: 0.4450

Epoch 02374: val_loss did not improve from 1.28840
Epoch 2375/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4302 - val_loss: 1.2946 - val_accuracy: 0.4274

Epoch 02375: val_loss did not improve from 1.28840
Epoch 2376/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4309 - val_loss: 1.2963 - val_accuracy: 0.4378

Epoch 02376: val_loss did not improve from 1.28840
Epoch 2377/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4293 - val_loss: 1.2903 - val_accuracy: 0.4362

Epoch 02377: val_loss did not improve from 1.28840
Epoch 2378/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4334 - val_loss: 1.2926 - val_accuracy: 0.4418

Epoch 02378: val_loss did not improve from 1.28840
Epoch 2379/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4331 - val_loss: 1.2934 - val_accuracy: 0.4298

Epoch 02379: val_loss did not improve from 1.28840
Epoch 2380/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4305 - val_loss: 1.2910 - val_accuracy: 0.4370

Epoch 02380: val_loss did not improve from 1.28840
Epoch 2381/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4353 - val_loss: 1.2936 - val_accuracy: 0.4274

Epoch 02381: val_loss did not improve from 1.28840
Epoch 2382/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4317 - val_loss: 1.2934 - val_accuracy: 0.4450

Epoch 02382: val_loss did not improve from 1.28840
Epoch 2383/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4319 - val_loss: 1.2932 - val_accuracy: 0.4330

Epoch 02383: val_loss did not improve from 1.28840
Epoch 2384/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4358 - val_loss: 1.2917 - val_accuracy: 0.4330

Epoch 02384: val_loss did not improve from 1.28840
Epoch 2385/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4315 - val_loss: 1.2911 - val_accuracy: 0.4330

Epoch 02385: val_loss did not improve from 1.28840
Epoch 2386/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4305 - val_loss: 1.2924 - val_accuracy: 0.4442

Epoch 02386: val_loss did not improve from 1.28840
Epoch 2387/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4348 - val_loss: 1.2890 - val_accuracy: 0.4282

Epoch 02387: val_loss did not improve from 1.28840
Epoch 2388/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4303 - val_loss: 1.2926 - val_accuracy: 0.4362

Epoch 02388: val_loss did not improve from 1.28840
Epoch 2389/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4354 - val_loss: 1.2910 - val_accuracy: 0.4306

Epoch 02389: val_loss did not improve from 1.28840
Epoch 2390/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4308 - val_loss: 1.2917 - val_accuracy: 0.4338

Epoch 02390: val_loss did not improve from 1.28840
Epoch 2391/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4281 - val_loss: 1.3063 - val_accuracy: 0.4410

Epoch 02391: val_loss did not improve from 1.28840
Epoch 2392/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4304 - val_loss: 1.2942 - val_accuracy: 0.4306

Epoch 02392: val_loss did not improve from 1.28840
Epoch 2393/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4283 - val_loss: 1.2920 - val_accuracy: 0.4290

Epoch 02393: val_loss did not improve from 1.28840
Epoch 2394/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4326 - val_loss: 1.2944 - val_accuracy: 0.4306

Epoch 02394: val_loss did not improve from 1.28840
Epoch 2395/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4320 - val_loss: 1.2969 - val_accuracy: 0.4394

Epoch 02395: val_loss did not improve from 1.28840
Epoch 2396/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4298 - val_loss: 1.2938 - val_accuracy: 0.4378

Epoch 02396: val_loss did not improve from 1.28840
Epoch 2397/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4312 - val_loss: 1.2895 - val_accuracy: 0.4322

Epoch 02397: val_loss did not improve from 1.28840
Epoch 2398/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4349 - val_loss: 1.2897 - val_accuracy: 0.4330

Epoch 02398: val_loss did not improve from 1.28840
Epoch 2399/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4303 - val_loss: 1.2919 - val_accuracy: 0.4466

Epoch 02399: val_loss did not improve from 1.28840
Epoch 2400/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4323 - val_loss: 1.2902 - val_accuracy: 0.4274

Epoch 02400: val_loss did not improve from 1.28840
Epoch 2401/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4352 - val_loss: 1.2894 - val_accuracy: 0.4298

Epoch 02401: val_loss did not improve from 1.28840
Epoch 2402/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4334 - val_loss: 1.2950 - val_accuracy: 0.4330

Epoch 02402: val_loss did not improve from 1.28840
Epoch 2403/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4269 - val_loss: 1.2918 - val_accuracy: 0.4346

Epoch 02403: val_loss did not improve from 1.28840
Epoch 2404/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4357 - val_loss: 1.2935 - val_accuracy: 0.4322

Epoch 02404: val_loss did not improve from 1.28840
Epoch 2405/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4350 - val_loss: 1.2986 - val_accuracy: 0.4442

Epoch 02405: val_loss did not improve from 1.28840
Epoch 2406/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4318 - val_loss: 1.2941 - val_accuracy: 0.4282

Epoch 02406: val_loss did not improve from 1.28840
Epoch 2407/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4305 - val_loss: 1.2932 - val_accuracy: 0.4450

Epoch 02407: val_loss did not improve from 1.28840
Epoch 2408/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4272 - val_loss: 1.2903 - val_accuracy: 0.4314

Epoch 02408: val_loss did not improve from 1.28840
Epoch 2409/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4324 - val_loss: 1.2902 - val_accuracy: 0.4322

Epoch 02409: val_loss did not improve from 1.28840
Epoch 2410/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4318 - val_loss: 1.2900 - val_accuracy: 0.4314

Epoch 02410: val_loss did not improve from 1.28840
Epoch 2411/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4317 - val_loss: 1.2892 - val_accuracy: 0.4306

Epoch 02411: val_loss did not improve from 1.28840
Epoch 2412/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4310 - val_loss: 1.2901 - val_accuracy: 0.4362

Epoch 02412: val_loss did not improve from 1.28840
Epoch 2413/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4312 - val_loss: 1.2905 - val_accuracy: 0.4290

Epoch 02413: val_loss did not improve from 1.28840
Epoch 2414/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4317 - val_loss: 1.2922 - val_accuracy: 0.4378

Epoch 02414: val_loss did not improve from 1.28840
Epoch 2415/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4363 - val_loss: 1.2913 - val_accuracy: 0.4306

Epoch 02415: val_loss did not improve from 1.28840
Epoch 2416/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4345 - val_loss: 1.2904 - val_accuracy: 0.4330

Epoch 02416: val_loss did not improve from 1.28840
Epoch 2417/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4328 - val_loss: 1.2887 - val_accuracy: 0.4314

Epoch 02417: val_loss did not improve from 1.28840
Epoch 2418/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4308 - val_loss: 1.2900 - val_accuracy: 0.4394

Epoch 02418: val_loss did not improve from 1.28840
Epoch 2419/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4336 - val_loss: 1.2941 - val_accuracy: 0.4442

Epoch 02419: val_loss did not improve from 1.28840
Epoch 2420/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4319 - val_loss: 1.2903 - val_accuracy: 0.4370

Epoch 02420: val_loss did not improve from 1.28840
Epoch 2421/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4282 - val_loss: 1.2910 - val_accuracy: 0.4314

Epoch 02421: val_loss did not improve from 1.28840
Epoch 2422/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4370 - val_loss: 1.2947 - val_accuracy: 0.4378

Epoch 02422: val_loss did not improve from 1.28840
Epoch 2423/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4289 - val_loss: 1.2909 - val_accuracy: 0.4426

Epoch 02423: val_loss did not improve from 1.28840
Epoch 2424/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4338 - val_loss: 1.2879 - val_accuracy: 0.4322

Epoch 02424: val_loss improved from 1.28840 to 1.28794, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2425/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4329 - val_loss: 1.2914 - val_accuracy: 0.4386

Epoch 02425: val_loss did not improve from 1.28794
Epoch 2426/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4326 - val_loss: 1.2918 - val_accuracy: 0.4226

Epoch 02426: val_loss did not improve from 1.28794
Epoch 2427/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4326 - val_loss: 1.2968 - val_accuracy: 0.4426

Epoch 02427: val_loss did not improve from 1.28794
Epoch 2428/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4316 - val_loss: 1.2901 - val_accuracy: 0.4330

Epoch 02428: val_loss did not improve from 1.28794
Epoch 2429/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4322 - val_loss: 1.2903 - val_accuracy: 0.4434

Epoch 02429: val_loss did not improve from 1.28794
Epoch 2430/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4304 - val_loss: 1.2923 - val_accuracy: 0.4402

Epoch 02430: val_loss did not improve from 1.28794
Epoch 2431/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4280 - val_loss: 1.2893 - val_accuracy: 0.4386

Epoch 02431: val_loss did not improve from 1.28794
Epoch 2432/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4285 - val_loss: 1.2896 - val_accuracy: 0.4370

Epoch 02432: val_loss did not improve from 1.28794
Epoch 2433/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4318 - val_loss: 1.2924 - val_accuracy: 0.4346

Epoch 02433: val_loss did not improve from 1.28794
Epoch 2434/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4330 - val_loss: 1.2907 - val_accuracy: 0.4290

Epoch 02434: val_loss did not improve from 1.28794
Epoch 2435/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4347 - val_loss: 1.2894 - val_accuracy: 0.4354

Epoch 02435: val_loss did not improve from 1.28794
Epoch 2436/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4308 - val_loss: 1.2898 - val_accuracy: 0.4306

Epoch 02436: val_loss did not improve from 1.28794
Epoch 2437/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4312 - val_loss: 1.2903 - val_accuracy: 0.4322

Epoch 02437: val_loss did not improve from 1.28794
Epoch 2438/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4311 - val_loss: 1.3010 - val_accuracy: 0.4474

Epoch 02438: val_loss did not improve from 1.28794
Epoch 2439/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4338 - val_loss: 1.2913 - val_accuracy: 0.4290

Epoch 02439: val_loss did not improve from 1.28794
Epoch 2440/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4287 - val_loss: 1.2957 - val_accuracy: 0.4346

Epoch 02440: val_loss did not improve from 1.28794
Epoch 2441/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4315 - val_loss: 1.2916 - val_accuracy: 0.4266

Epoch 02441: val_loss did not improve from 1.28794
Epoch 2442/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4341 - val_loss: 1.2931 - val_accuracy: 0.4370

Epoch 02442: val_loss did not improve from 1.28794
Epoch 2443/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4310 - val_loss: 1.2916 - val_accuracy: 0.4306

Epoch 02443: val_loss did not improve from 1.28794
Epoch 2444/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4304 - val_loss: 1.2953 - val_accuracy: 0.4354

Epoch 02444: val_loss did not improve from 1.28794
Epoch 2445/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4278 - val_loss: 1.2944 - val_accuracy: 0.4298

Epoch 02445: val_loss did not improve from 1.28794
Epoch 2446/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4343 - val_loss: 1.2914 - val_accuracy: 0.4378

Epoch 02446: val_loss did not improve from 1.28794
Epoch 2447/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4306 - val_loss: 1.2923 - val_accuracy: 0.4330

Epoch 02447: val_loss did not improve from 1.28794
Epoch 2448/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4357 - val_loss: 1.2910 - val_accuracy: 0.4290

Epoch 02448: val_loss did not improve from 1.28794
Epoch 2449/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4354 - val_loss: 1.2897 - val_accuracy: 0.4274

Epoch 02449: val_loss did not improve from 1.28794
Epoch 2450/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4334 - val_loss: 1.2889 - val_accuracy: 0.4506

Epoch 02450: val_loss did not improve from 1.28794
Epoch 2451/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4342 - val_loss: 1.2903 - val_accuracy: 0.4402

Epoch 02451: val_loss did not improve from 1.28794
Epoch 2452/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4292 - val_loss: 1.2905 - val_accuracy: 0.4370

Epoch 02452: val_loss did not improve from 1.28794
Epoch 2453/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4346 - val_loss: 1.2989 - val_accuracy: 0.4370

Epoch 02453: val_loss did not improve from 1.28794
Epoch 2454/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4306 - val_loss: 1.2898 - val_accuracy: 0.4418

Epoch 02454: val_loss did not improve from 1.28794
Epoch 2455/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4317 - val_loss: 1.2894 - val_accuracy: 0.4274

Epoch 02455: val_loss did not improve from 1.28794
Epoch 2456/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4331 - val_loss: 1.2942 - val_accuracy: 0.4378

Epoch 02456: val_loss did not improve from 1.28794
Epoch 2457/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4357 - val_loss: 1.2919 - val_accuracy: 0.4274

Epoch 02457: val_loss did not improve from 1.28794
Epoch 2458/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4320 - val_loss: 1.2913 - val_accuracy: 0.4306

Epoch 02458: val_loss did not improve from 1.28794
Epoch 2459/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4330 - val_loss: 1.2917 - val_accuracy: 0.4402

Epoch 02459: val_loss did not improve from 1.28794
Epoch 2460/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4329 - val_loss: 1.2928 - val_accuracy: 0.4354

Epoch 02460: val_loss did not improve from 1.28794
Epoch 2461/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4293 - val_loss: 1.2912 - val_accuracy: 0.4410

Epoch 02461: val_loss did not improve from 1.28794
Epoch 2462/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4353 - val_loss: 1.2931 - val_accuracy: 0.4370

Epoch 02462: val_loss did not improve from 1.28794
Epoch 2463/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4365 - val_loss: 1.2922 - val_accuracy: 0.4378

Epoch 02463: val_loss did not improve from 1.28794
Epoch 2464/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4311 - val_loss: 1.2897 - val_accuracy: 0.4378

Epoch 02464: val_loss did not improve from 1.28794
Epoch 2465/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4351 - val_loss: 1.2915 - val_accuracy: 0.4314

Epoch 02465: val_loss did not improve from 1.28794
Epoch 2466/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4355 - val_loss: 1.2930 - val_accuracy: 0.4346

Epoch 02466: val_loss did not improve from 1.28794
Epoch 2467/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4322 - val_loss: 1.2942 - val_accuracy: 0.4410

Epoch 02467: val_loss did not improve from 1.28794
Epoch 2468/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4349 - val_loss: 1.2903 - val_accuracy: 0.4370

Epoch 02468: val_loss did not improve from 1.28794
Epoch 2469/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4291 - val_loss: 1.2901 - val_accuracy: 0.4370

Epoch 02469: val_loss did not improve from 1.28794
Epoch 2470/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4334 - val_loss: 1.2901 - val_accuracy: 0.4290

Epoch 02470: val_loss did not improve from 1.28794
Epoch 2471/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4316 - val_loss: 1.2949 - val_accuracy: 0.4386

Epoch 02471: val_loss did not improve from 1.28794
Epoch 2472/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4365 - val_loss: 1.2909 - val_accuracy: 0.4346

Epoch 02472: val_loss did not improve from 1.28794
Epoch 2473/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4291 - val_loss: 1.2916 - val_accuracy: 0.4418

Epoch 02473: val_loss did not improve from 1.28794
Epoch 2474/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4295 - val_loss: 1.2906 - val_accuracy: 0.4370

Epoch 02474: val_loss did not improve from 1.28794
Epoch 2475/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4314 - val_loss: 1.2916 - val_accuracy: 0.4314

Epoch 02475: val_loss did not improve from 1.28794
Epoch 2476/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4377 - val_loss: 1.2931 - val_accuracy: 0.4450

Epoch 02476: val_loss did not improve from 1.28794
Epoch 2477/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4280 - val_loss: 1.2918 - val_accuracy: 0.4442

Epoch 02477: val_loss did not improve from 1.28794
Epoch 2478/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4335 - val_loss: 1.2899 - val_accuracy: 0.4306

Epoch 02478: val_loss did not improve from 1.28794
Epoch 2479/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4322 - val_loss: 1.2944 - val_accuracy: 0.4402

Epoch 02479: val_loss did not improve from 1.28794
Epoch 2480/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4346 - val_loss: 1.2911 - val_accuracy: 0.4290

Epoch 02480: val_loss did not improve from 1.28794
Epoch 2481/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4332 - val_loss: 1.2917 - val_accuracy: 0.4394

Epoch 02481: val_loss did not improve from 1.28794
Epoch 2482/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4310 - val_loss: 1.2927 - val_accuracy: 0.4402

Epoch 02482: val_loss did not improve from 1.28794
Epoch 2483/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4302 - val_loss: 1.2887 - val_accuracy: 0.4226

Epoch 02483: val_loss did not improve from 1.28794
Epoch 2484/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4342 - val_loss: 1.2906 - val_accuracy: 0.4274

Epoch 02484: val_loss did not improve from 1.28794
Epoch 2485/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4313 - val_loss: 1.2933 - val_accuracy: 0.4394

Epoch 02485: val_loss did not improve from 1.28794
Epoch 2486/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4319 - val_loss: 1.2917 - val_accuracy: 0.4330

Epoch 02486: val_loss did not improve from 1.28794
Epoch 2487/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4356 - val_loss: 1.2895 - val_accuracy: 0.4370

Epoch 02487: val_loss did not improve from 1.28794
Epoch 2488/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4338 - val_loss: 1.2899 - val_accuracy: 0.4290

Epoch 02488: val_loss did not improve from 1.28794
Epoch 2489/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4325 - val_loss: 1.2894 - val_accuracy: 0.4338

Epoch 02489: val_loss did not improve from 1.28794
Epoch 2490/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4318 - val_loss: 1.2883 - val_accuracy: 0.4354

Epoch 02490: val_loss did not improve from 1.28794
Epoch 2491/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4326 - val_loss: 1.2902 - val_accuracy: 0.4290

Epoch 02491: val_loss did not improve from 1.28794
Epoch 2492/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4282 - val_loss: 1.2895 - val_accuracy: 0.4346

Epoch 02492: val_loss did not improve from 1.28794
Epoch 2493/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4336 - val_loss: 1.2911 - val_accuracy: 0.4306

Epoch 02493: val_loss did not improve from 1.28794
Epoch 2494/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4352 - val_loss: 1.2882 - val_accuracy: 0.4282

Epoch 02494: val_loss did not improve from 1.28794
Epoch 2495/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4332 - val_loss: 1.2897 - val_accuracy: 0.4402

Epoch 02495: val_loss did not improve from 1.28794
Epoch 2496/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4313 - val_loss: 1.2898 - val_accuracy: 0.4370

Epoch 02496: val_loss did not improve from 1.28794
Epoch 2497/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4339 - val_loss: 1.2891 - val_accuracy: 0.4402

Epoch 02497: val_loss did not improve from 1.28794
Epoch 2498/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4339 - val_loss: 1.2887 - val_accuracy: 0.4330

Epoch 02498: val_loss did not improve from 1.28794
Epoch 2499/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4334 - val_loss: 1.2881 - val_accuracy: 0.4394

Epoch 02499: val_loss did not improve from 1.28794
Epoch 2500/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4328 - val_loss: 1.2903 - val_accuracy: 0.4466

Epoch 02500: val_loss did not improve from 1.28794
Epoch 2501/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4350 - val_loss: 1.2886 - val_accuracy: 0.4298

Epoch 02501: val_loss did not improve from 1.28794
Epoch 2502/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4318 - val_loss: 1.2924 - val_accuracy: 0.4346

Epoch 02502: val_loss did not improve from 1.28794
Epoch 2503/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4327 - val_loss: 1.2925 - val_accuracy: 0.4410

Epoch 02503: val_loss did not improve from 1.28794
Epoch 2504/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4289 - val_loss: 1.2899 - val_accuracy: 0.4394

Epoch 02504: val_loss did not improve from 1.28794
Epoch 2505/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4336 - val_loss: 1.2921 - val_accuracy: 0.4290

Epoch 02505: val_loss did not improve from 1.28794
Epoch 2506/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4347 - val_loss: 1.2920 - val_accuracy: 0.4394

Epoch 02506: val_loss did not improve from 1.28794
Epoch 2507/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4311 - val_loss: 1.2909 - val_accuracy: 0.4314

Epoch 02507: val_loss did not improve from 1.28794
Epoch 2508/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4308 - val_loss: 1.2956 - val_accuracy: 0.4410

Epoch 02508: val_loss did not improve from 1.28794
Epoch 2509/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4316 - val_loss: 1.2910 - val_accuracy: 0.4338

Epoch 02509: val_loss did not improve from 1.28794
Epoch 2510/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4343 - val_loss: 1.2885 - val_accuracy: 0.4386

Epoch 02510: val_loss did not improve from 1.28794
Epoch 2511/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4341 - val_loss: 1.2928 - val_accuracy: 0.4338

Epoch 02511: val_loss did not improve from 1.28794
Epoch 2512/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4308 - val_loss: 1.2899 - val_accuracy: 0.4370

Epoch 02512: val_loss did not improve from 1.28794
Epoch 2513/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4384 - val_loss: 1.2907 - val_accuracy: 0.4370

Epoch 02513: val_loss did not improve from 1.28794
Epoch 2514/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4345 - val_loss: 1.2900 - val_accuracy: 0.4338

Epoch 02514: val_loss did not improve from 1.28794
Epoch 2515/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4297 - val_loss: 1.2898 - val_accuracy: 0.4322

Epoch 02515: val_loss did not improve from 1.28794
Epoch 2516/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4339 - val_loss: 1.2910 - val_accuracy: 0.4378

Epoch 02516: val_loss did not improve from 1.28794
Epoch 2517/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4327 - val_loss: 1.2937 - val_accuracy: 0.4490

Epoch 02517: val_loss did not improve from 1.28794
Epoch 2518/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4344 - val_loss: 1.2899 - val_accuracy: 0.4322

Epoch 02518: val_loss did not improve from 1.28794
Epoch 2519/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4351 - val_loss: 1.2901 - val_accuracy: 0.4370

Epoch 02519: val_loss did not improve from 1.28794
Epoch 2520/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4334 - val_loss: 1.2894 - val_accuracy: 0.4418

Epoch 02520: val_loss did not improve from 1.28794
Epoch 2521/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4324 - val_loss: 1.2879 - val_accuracy: 0.4378

Epoch 02521: val_loss improved from 1.28794 to 1.28791, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2522/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4319 - val_loss: 1.2931 - val_accuracy: 0.4346

Epoch 02522: val_loss did not improve from 1.28791
Epoch 2523/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4320 - val_loss: 1.2917 - val_accuracy: 0.4298

Epoch 02523: val_loss did not improve from 1.28791
Epoch 2524/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4342 - val_loss: 1.2944 - val_accuracy: 0.4330

Epoch 02524: val_loss did not improve from 1.28791
Epoch 2525/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4350 - val_loss: 1.2908 - val_accuracy: 0.4410

Epoch 02525: val_loss did not improve from 1.28791
Epoch 2526/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4312 - val_loss: 1.2919 - val_accuracy: 0.4258

Epoch 02526: val_loss did not improve from 1.28791
Epoch 2527/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4354 - val_loss: 1.2937 - val_accuracy: 0.4370

Epoch 02527: val_loss did not improve from 1.28791
Epoch 2528/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4309 - val_loss: 1.2918 - val_accuracy: 0.4410

Epoch 02528: val_loss did not improve from 1.28791
Epoch 2529/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4316 - val_loss: 1.2905 - val_accuracy: 0.4362

Epoch 02529: val_loss did not improve from 1.28791
Epoch 2530/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4328 - val_loss: 1.2913 - val_accuracy: 0.4306

Epoch 02530: val_loss did not improve from 1.28791
Epoch 2531/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4366 - val_loss: 1.2909 - val_accuracy: 0.4298

Epoch 02531: val_loss did not improve from 1.28791
Epoch 2532/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4345 - val_loss: 1.2926 - val_accuracy: 0.4378

Epoch 02532: val_loss did not improve from 1.28791
Epoch 2533/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4338 - val_loss: 1.2922 - val_accuracy: 0.4338

Epoch 02533: val_loss did not improve from 1.28791
Epoch 2534/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4339 - val_loss: 1.3026 - val_accuracy: 0.4394

Epoch 02534: val_loss did not improve from 1.28791
Epoch 2535/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4349 - val_loss: 1.2891 - val_accuracy: 0.4378

Epoch 02535: val_loss did not improve from 1.28791
Epoch 2536/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4330 - val_loss: 1.2911 - val_accuracy: 0.4330

Epoch 02536: val_loss did not improve from 1.28791
Epoch 2537/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4321 - val_loss: 1.2962 - val_accuracy: 0.4434

Epoch 02537: val_loss did not improve from 1.28791
Epoch 2538/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4333 - val_loss: 1.2919 - val_accuracy: 0.4282

Epoch 02538: val_loss did not improve from 1.28791
Epoch 2539/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4322 - val_loss: 1.2967 - val_accuracy: 0.4203

Epoch 02539: val_loss did not improve from 1.28791
Epoch 2540/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4295 - val_loss: 1.2994 - val_accuracy: 0.4442

Epoch 02540: val_loss did not improve from 1.28791
Epoch 2541/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4309 - val_loss: 1.2894 - val_accuracy: 0.4378

Epoch 02541: val_loss did not improve from 1.28791
Epoch 2542/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4351 - val_loss: 1.2878 - val_accuracy: 0.4314

Epoch 02542: val_loss improved from 1.28791 to 1.28778, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2543/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4318 - val_loss: 1.2903 - val_accuracy: 0.4322

Epoch 02543: val_loss did not improve from 1.28778
Epoch 2544/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4377 - val_loss: 1.2881 - val_accuracy: 0.4402

Epoch 02544: val_loss did not improve from 1.28778
Epoch 2545/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4341 - val_loss: 1.2894 - val_accuracy: 0.4442

Epoch 02545: val_loss did not improve from 1.28778
Epoch 2546/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4345 - val_loss: 1.2919 - val_accuracy: 0.4266

Epoch 02546: val_loss did not improve from 1.28778
Epoch 2547/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4308 - val_loss: 1.2957 - val_accuracy: 0.4434

Epoch 02547: val_loss did not improve from 1.28778
Epoch 2548/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4326 - val_loss: 1.2891 - val_accuracy: 0.4394

Epoch 02548: val_loss did not improve from 1.28778
Epoch 2549/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4318 - val_loss: 1.2878 - val_accuracy: 0.4346

Epoch 02549: val_loss did not improve from 1.28778
Epoch 2550/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4328 - val_loss: 1.2946 - val_accuracy: 0.4418

Epoch 02550: val_loss did not improve from 1.28778
Epoch 2551/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4331 - val_loss: 1.2901 - val_accuracy: 0.4378

Epoch 02551: val_loss did not improve from 1.28778
Epoch 2552/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4331 - val_loss: 1.2891 - val_accuracy: 0.4450

Epoch 02552: val_loss did not improve from 1.28778
Epoch 2553/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4293 - val_loss: 1.3080 - val_accuracy: 0.4338

Epoch 02553: val_loss did not improve from 1.28778
Epoch 2554/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4311 - val_loss: 1.2936 - val_accuracy: 0.4266

Epoch 02554: val_loss did not improve from 1.28778
Epoch 2555/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4313 - val_loss: 1.2911 - val_accuracy: 0.4378

Epoch 02555: val_loss did not improve from 1.28778
Epoch 2556/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4301 - val_loss: 1.2913 - val_accuracy: 0.4410

Epoch 02556: val_loss did not improve from 1.28778
Epoch 2557/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4323 - val_loss: 1.2938 - val_accuracy: 0.4458

Epoch 02557: val_loss did not improve from 1.28778
Epoch 2558/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4337 - val_loss: 1.2897 - val_accuracy: 0.4338

Epoch 02558: val_loss did not improve from 1.28778
Epoch 2559/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4318 - val_loss: 1.2887 - val_accuracy: 0.4322

Epoch 02559: val_loss did not improve from 1.28778
Epoch 2560/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4339 - val_loss: 1.2889 - val_accuracy: 0.4434

Epoch 02560: val_loss did not improve from 1.28778
Epoch 2561/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4309 - val_loss: 1.2901 - val_accuracy: 0.4410

Epoch 02561: val_loss did not improve from 1.28778
Epoch 2562/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4322 - val_loss: 1.2900 - val_accuracy: 0.4426

Epoch 02562: val_loss did not improve from 1.28778
Epoch 2563/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4346 - val_loss: 1.2872 - val_accuracy: 0.4426

Epoch 02563: val_loss improved from 1.28778 to 1.28716, saving model to ./results/NN_thk_class/aggr_theta/ckpt_8
Epoch 2564/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4347 - val_loss: 1.2884 - val_accuracy: 0.4378

Epoch 02564: val_loss did not improve from 1.28716
Epoch 2565/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4328 - val_loss: 1.2952 - val_accuracy: 0.4426

Epoch 02565: val_loss did not improve from 1.28716
Epoch 2566/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4363 - val_loss: 1.2903 - val_accuracy: 0.4290

Epoch 02566: val_loss did not improve from 1.28716
Epoch 2567/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4336 - val_loss: 1.2930 - val_accuracy: 0.4458

Epoch 02567: val_loss did not improve from 1.28716
Epoch 2568/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4325 - val_loss: 1.2888 - val_accuracy: 0.4458

Epoch 02568: val_loss did not improve from 1.28716
Epoch 2569/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4330 - val_loss: 1.2881 - val_accuracy: 0.4434

Epoch 02569: val_loss did not improve from 1.28716
Epoch 2570/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4337 - val_loss: 1.2889 - val_accuracy: 0.4338

Epoch 02570: val_loss did not improve from 1.28716
Epoch 2571/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4367 - val_loss: 1.2888 - val_accuracy: 0.4370

Epoch 02571: val_loss did not improve from 1.28716
Epoch 2572/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4378 - val_loss: 1.2895 - val_accuracy: 0.4346

Epoch 02572: val_loss did not improve from 1.28716
Epoch 2573/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4338 - val_loss: 1.2882 - val_accuracy: 0.4394

Epoch 02573: val_loss did not improve from 1.28716
Epoch 2574/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4319 - val_loss: 1.2915 - val_accuracy: 0.4418

Epoch 02574: val_loss did not improve from 1.28716
Epoch 2575/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4349 - val_loss: 1.2888 - val_accuracy: 0.4386

Epoch 02575: val_loss did not improve from 1.28716
Epoch 2576/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4355 - val_loss: 1.2890 - val_accuracy: 0.4378

Epoch 02576: val_loss did not improve from 1.28716
Epoch 2577/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4356 - val_loss: 1.2880 - val_accuracy: 0.4402

Epoch 02577: val_loss did not improve from 1.28716
Epoch 2578/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4337 - val_loss: 1.2881 - val_accuracy: 0.4338

Epoch 02578: val_loss did not improve from 1.28716
Epoch 2579/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4357 - val_loss: 1.2898 - val_accuracy: 0.4410

Epoch 02579: val_loss did not improve from 1.28716
Epoch 2580/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4326 - val_loss: 1.2902 - val_accuracy: 0.4314

Epoch 02580: val_loss did not improve from 1.28716
Epoch 2581/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4323 - val_loss: 1.2898 - val_accuracy: 0.4370

Epoch 02581: val_loss did not improve from 1.28716
Epoch 2582/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4380 - val_loss: 1.2889 - val_accuracy: 0.4426

Epoch 02582: val_loss did not improve from 1.28716
Epoch 2583/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4295 - val_loss: 1.2908 - val_accuracy: 0.4418

Epoch 02583: val_loss did not improve from 1.28716
Epoch 2584/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4330 - val_loss: 1.2888 - val_accuracy: 0.4458

Epoch 02584: val_loss did not improve from 1.28716
Epoch 2585/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4330 - val_loss: 1.2888 - val_accuracy: 0.4402

Epoch 02585: val_loss did not improve from 1.28716
Epoch 2586/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4352 - val_loss: 1.2908 - val_accuracy: 0.4314

Epoch 02586: val_loss did not improve from 1.28716
Epoch 2587/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4330 - val_loss: 1.2932 - val_accuracy: 0.4386

Epoch 02587: val_loss did not improve from 1.28716
Epoch 2588/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4343 - val_loss: 1.2903 - val_accuracy: 0.4386

Epoch 02588: val_loss did not improve from 1.28716
Epoch 2589/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4301 - val_loss: 1.2901 - val_accuracy: 0.4418

Epoch 02589: val_loss did not improve from 1.28716
Epoch 2590/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4342 - val_loss: 1.2943 - val_accuracy: 0.4442

Epoch 02590: val_loss did not improve from 1.28716
Epoch 2591/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4303 - val_loss: 1.2882 - val_accuracy: 0.4434

Epoch 02591: val_loss did not improve from 1.28716
Epoch 2592/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4305 - val_loss: 1.2893 - val_accuracy: 0.4490

Epoch 02592: val_loss did not improve from 1.28716
Epoch 2593/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4322 - val_loss: 1.2887 - val_accuracy: 0.4386

Epoch 02593: val_loss did not improve from 1.28716
Epoch 2594/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4333 - val_loss: 1.2900 - val_accuracy: 0.4434

Epoch 02594: val_loss did not improve from 1.28716
Epoch 2595/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4311 - val_loss: 1.2896 - val_accuracy: 0.4354

Epoch 02595: val_loss did not improve from 1.28716
Epoch 2596/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4341 - val_loss: 1.2900 - val_accuracy: 0.4290

Epoch 02596: val_loss did not improve from 1.28716
Epoch 2597/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4376 - val_loss: 1.2904 - val_accuracy: 0.4314

Epoch 02597: val_loss did not improve from 1.28716
Epoch 2598/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4299 - val_loss: 1.2897 - val_accuracy: 0.4474

Epoch 02598: val_loss did not improve from 1.28716
Epoch 2599/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4331 - val_loss: 1.2888 - val_accuracy: 0.4354

Epoch 02599: val_loss did not improve from 1.28716
Epoch 2600/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4373 - val_loss: 1.2886 - val_accuracy: 0.4418

Epoch 02600: val_loss did not improve from 1.28716
Epoch 2601/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4359 - val_loss: 1.2908 - val_accuracy: 0.4442

Epoch 02601: val_loss did not improve from 1.28716
Epoch 2602/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4339 - val_loss: 1.2926 - val_accuracy: 0.4466

Epoch 02602: val_loss did not improve from 1.28716
Epoch 2603/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4328 - val_loss: 1.2897 - val_accuracy: 0.4426

Epoch 02603: val_loss did not improve from 1.28716
Epoch 2604/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4338 - val_loss: 1.2903 - val_accuracy: 0.4338

Epoch 02604: val_loss did not improve from 1.28716
Epoch 2605/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4374 - val_loss: 1.2894 - val_accuracy: 0.4290

Epoch 02605: val_loss did not improve from 1.28716
Epoch 2606/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4333 - val_loss: 1.2981 - val_accuracy: 0.4426

Epoch 02606: val_loss did not improve from 1.28716
Epoch 2607/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4319 - val_loss: 1.2901 - val_accuracy: 0.4370

Epoch 02607: val_loss did not improve from 1.28716
Epoch 2608/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4373 - val_loss: 1.2885 - val_accuracy: 0.4330

Epoch 02608: val_loss did not improve from 1.28716
Epoch 2609/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4318 - val_loss: 1.2910 - val_accuracy: 0.4426

Epoch 02609: val_loss did not improve from 1.28716
Epoch 2610/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4332 - val_loss: 1.2921 - val_accuracy: 0.4354

Epoch 02610: val_loss did not improve from 1.28716
Epoch 2611/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4342 - val_loss: 1.2907 - val_accuracy: 0.4354

Epoch 02611: val_loss did not improve from 1.28716
Epoch 2612/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4354 - val_loss: 1.2911 - val_accuracy: 0.4426

Epoch 02612: val_loss did not improve from 1.28716
Epoch 2613/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4351 - val_loss: 1.2908 - val_accuracy: 0.4314

Epoch 02613: val_loss did not improve from 1.28716
Epoch 2614/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4384 - val_loss: 1.2896 - val_accuracy: 0.4362

Epoch 02614: val_loss did not improve from 1.28716
Epoch 2615/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4327 - val_loss: 1.2901 - val_accuracy: 0.4362

Epoch 02615: val_loss did not improve from 1.28716
Epoch 2616/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4396 - val_loss: 1.2898 - val_accuracy: 0.4330

Epoch 02616: val_loss did not improve from 1.28716
Epoch 2617/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4341 - val_loss: 1.2883 - val_accuracy: 0.4346

Epoch 02617: val_loss did not improve from 1.28716
Epoch 2618/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4351 - val_loss: 1.2889 - val_accuracy: 0.4378

Epoch 02618: val_loss did not improve from 1.28716
Epoch 2619/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4296 - val_loss: 1.2912 - val_accuracy: 0.4394

Epoch 02619: val_loss did not improve from 1.28716
Epoch 2620/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4370 - val_loss: 1.2935 - val_accuracy: 0.4338

Epoch 02620: val_loss did not improve from 1.28716
Epoch 2621/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4350 - val_loss: 1.2901 - val_accuracy: 0.4258

Epoch 02621: val_loss did not improve from 1.28716
Epoch 2622/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4353 - val_loss: 1.2898 - val_accuracy: 0.4362

Epoch 02622: val_loss did not improve from 1.28716
Epoch 2623/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4268 - val_loss: 1.2920 - val_accuracy: 0.4458

Epoch 02623: val_loss did not improve from 1.28716
Epoch 2624/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4303 - val_loss: 1.2905 - val_accuracy: 0.4434

Epoch 02624: val_loss did not improve from 1.28716
Epoch 2625/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4360 - val_loss: 1.2908 - val_accuracy: 0.4370

Epoch 02625: val_loss did not improve from 1.28716
Epoch 2626/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4380 - val_loss: 1.2927 - val_accuracy: 0.4354

Epoch 02626: val_loss did not improve from 1.28716
Epoch 2627/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4339 - val_loss: 1.2916 - val_accuracy: 0.4418

Epoch 02627: val_loss did not improve from 1.28716
Epoch 2628/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4347 - val_loss: 1.2910 - val_accuracy: 0.4266

Epoch 02628: val_loss did not improve from 1.28716
Epoch 2629/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4352 - val_loss: 1.2943 - val_accuracy: 0.4490

Epoch 02629: val_loss did not improve from 1.28716
Epoch 2630/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4367 - val_loss: 1.2899 - val_accuracy: 0.4338

Epoch 02630: val_loss did not improve from 1.28716
Epoch 2631/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4364 - val_loss: 1.2932 - val_accuracy: 0.4410

Epoch 02631: val_loss did not improve from 1.28716
Epoch 2632/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4379 - val_loss: 1.2922 - val_accuracy: 0.4314

Epoch 02632: val_loss did not improve from 1.28716
Epoch 2633/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4372 - val_loss: 1.2918 - val_accuracy: 0.4402

Epoch 02633: val_loss did not improve from 1.28716
Epoch 2634/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4362 - val_loss: 1.2948 - val_accuracy: 0.4258

Epoch 02634: val_loss did not improve from 1.28716
Epoch 2635/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4332 - val_loss: 1.2975 - val_accuracy: 0.4370

Epoch 02635: val_loss did not improve from 1.28716
Epoch 2636/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4395 - val_loss: 1.2921 - val_accuracy: 0.4370

Epoch 02636: val_loss did not improve from 1.28716
Epoch 2637/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4339 - val_loss: 1.2912 - val_accuracy: 0.4314

Epoch 02637: val_loss did not improve from 1.28716
Epoch 2638/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4376 - val_loss: 1.2914 - val_accuracy: 0.4410

Epoch 02638: val_loss did not improve from 1.28716
Epoch 2639/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4317 - val_loss: 1.2931 - val_accuracy: 0.4434

Epoch 02639: val_loss did not improve from 1.28716
Epoch 2640/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4348 - val_loss: 1.2898 - val_accuracy: 0.4362

Epoch 02640: val_loss did not improve from 1.28716
Epoch 2641/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4365 - val_loss: 1.2899 - val_accuracy: 0.4274

Epoch 02641: val_loss did not improve from 1.28716
Epoch 2642/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4304 - val_loss: 1.2920 - val_accuracy: 0.4474

Epoch 02642: val_loss did not improve from 1.28716
Epoch 2643/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4353 - val_loss: 1.2925 - val_accuracy: 0.4322

Epoch 02643: val_loss did not improve from 1.28716
Epoch 2644/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4370 - val_loss: 1.2944 - val_accuracy: 0.4402

Epoch 02644: val_loss did not improve from 1.28716
Epoch 2645/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4310 - val_loss: 1.2912 - val_accuracy: 0.4330

Epoch 02645: val_loss did not improve from 1.28716
Epoch 2646/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4368 - val_loss: 1.2893 - val_accuracy: 0.4322

Epoch 02646: val_loss did not improve from 1.28716
Epoch 2647/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4319 - val_loss: 1.2917 - val_accuracy: 0.4386

Epoch 02647: val_loss did not improve from 1.28716
Epoch 2648/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4349 - val_loss: 1.2910 - val_accuracy: 0.4234

Epoch 02648: val_loss did not improve from 1.28716
Epoch 2649/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4351 - val_loss: 1.2895 - val_accuracy: 0.4466

Epoch 02649: val_loss did not improve from 1.28716
Epoch 2650/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4354 - val_loss: 1.2919 - val_accuracy: 0.4482

Epoch 02650: val_loss did not improve from 1.28716
Epoch 2651/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4330 - val_loss: 1.2913 - val_accuracy: 0.4298

Epoch 02651: val_loss did not improve from 1.28716
Epoch 2652/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4371 - val_loss: 1.2920 - val_accuracy: 0.4338

Epoch 02652: val_loss did not improve from 1.28716
Epoch 2653/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4381 - val_loss: 1.2900 - val_accuracy: 0.4418

Epoch 02653: val_loss did not improve from 1.28716
Epoch 2654/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4358 - val_loss: 1.2935 - val_accuracy: 0.4234

Epoch 02654: val_loss did not improve from 1.28716
Epoch 2655/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4363 - val_loss: 1.2941 - val_accuracy: 0.4370

Epoch 02655: val_loss did not improve from 1.28716
Epoch 2656/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4351 - val_loss: 1.2922 - val_accuracy: 0.4338

Epoch 02656: val_loss did not improve from 1.28716
Epoch 2657/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4348 - val_loss: 1.2890 - val_accuracy: 0.4346

Epoch 02657: val_loss did not improve from 1.28716
Epoch 2658/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4367 - val_loss: 1.2964 - val_accuracy: 0.4434

Epoch 02658: val_loss did not improve from 1.28716
Epoch 2659/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4326 - val_loss: 1.2929 - val_accuracy: 0.4354

Epoch 02659: val_loss did not improve from 1.28716
Epoch 2660/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4339 - val_loss: 1.2906 - val_accuracy: 0.4386

Epoch 02660: val_loss did not improve from 1.28716
Epoch 2661/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4330 - val_loss: 1.2913 - val_accuracy: 0.4450

Epoch 02661: val_loss did not improve from 1.28716
Epoch 2662/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4363 - val_loss: 1.2878 - val_accuracy: 0.4354

Epoch 02662: val_loss did not improve from 1.28716
Epoch 2663/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4342 - val_loss: 1.2896 - val_accuracy: 0.4402

Epoch 02663: val_loss did not improve from 1.28716
Epoch 2664/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4357 - val_loss: 1.2900 - val_accuracy: 0.4458

Epoch 02664: val_loss did not improve from 1.28716
Epoch 2665/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4365 - val_loss: 1.2898 - val_accuracy: 0.4282

Epoch 02665: val_loss did not improve from 1.28716
Epoch 2666/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4352 - val_loss: 1.2937 - val_accuracy: 0.4386

Epoch 02666: val_loss did not improve from 1.28716
Epoch 2667/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4315 - val_loss: 1.2910 - val_accuracy: 0.4338

Epoch 02667: val_loss did not improve from 1.28716
Epoch 2668/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4390 - val_loss: 1.2898 - val_accuracy: 0.4306

Epoch 02668: val_loss did not improve from 1.28716
Epoch 2669/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4365 - val_loss: 1.2962 - val_accuracy: 0.4553

Epoch 02669: val_loss did not improve from 1.28716
Epoch 2670/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4344 - val_loss: 1.2954 - val_accuracy: 0.4322

Epoch 02670: val_loss did not improve from 1.28716
Epoch 2671/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4373 - val_loss: 1.2926 - val_accuracy: 0.4458

Epoch 02671: val_loss did not improve from 1.28716
Epoch 2672/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4338 - val_loss: 1.2882 - val_accuracy: 0.4434

Epoch 02672: val_loss did not improve from 1.28716
Epoch 2673/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4355 - val_loss: 1.2911 - val_accuracy: 0.4354

Epoch 02673: val_loss did not improve from 1.28716
Epoch 2674/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4362 - val_loss: 1.2912 - val_accuracy: 0.4338

Epoch 02674: val_loss did not improve from 1.28716
Epoch 2675/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4364 - val_loss: 1.2916 - val_accuracy: 0.4410

Epoch 02675: val_loss did not improve from 1.28716
Epoch 2676/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4380 - val_loss: 1.2897 - val_accuracy: 0.4306

Epoch 02676: val_loss did not improve from 1.28716
Epoch 2677/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4333 - val_loss: 1.2924 - val_accuracy: 0.4402

Epoch 02677: val_loss did not improve from 1.28716
Epoch 2678/10000
12/12 - 0s - loss: 1.2538 - accuracy: 0.4339 - val_loss: 1.2890 - val_accuracy: 0.4346

Epoch 02678: val_loss did not improve from 1.28716
Epoch 2679/10000
12/12 - 0s - loss: 1.2533 - accuracy: 0.4381 - val_loss: 1.2880 - val_accuracy: 0.4418

Epoch 02679: val_loss did not improve from 1.28716
Epoch 2680/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4403 - val_loss: 1.2950 - val_accuracy: 0.4458

Epoch 02680: val_loss did not improve from 1.28716
Epoch 2681/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4349 - val_loss: 1.2896 - val_accuracy: 0.4394

Epoch 02681: val_loss did not improve from 1.28716
Epoch 2682/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4366 - val_loss: 1.2877 - val_accuracy: 0.4402

Epoch 02682: val_loss did not improve from 1.28716
Epoch 2683/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4345 - val_loss: 1.2927 - val_accuracy: 0.4561

Epoch 02683: val_loss did not improve from 1.28716
Epoch 2684/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4349 - val_loss: 1.2904 - val_accuracy: 0.4346

Epoch 02684: val_loss did not improve from 1.28716
Epoch 2685/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4342 - val_loss: 1.2918 - val_accuracy: 0.4410

Epoch 02685: val_loss did not improve from 1.28716
Epoch 2686/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4395 - val_loss: 1.2883 - val_accuracy: 0.4362

Epoch 02686: val_loss did not improve from 1.28716
Epoch 2687/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4364 - val_loss: 1.2892 - val_accuracy: 0.4266

Epoch 02687: val_loss did not improve from 1.28716
Epoch 2688/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4324 - val_loss: 1.2946 - val_accuracy: 0.4585

Epoch 02688: val_loss did not improve from 1.28716
Epoch 2689/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4392 - val_loss: 1.2895 - val_accuracy: 0.4450

Epoch 02689: val_loss did not improve from 1.28716
Epoch 2690/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4332 - val_loss: 1.2904 - val_accuracy: 0.4282

Epoch 02690: val_loss did not improve from 1.28716
Epoch 2691/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4308 - val_loss: 1.2893 - val_accuracy: 0.4354

Epoch 02691: val_loss did not improve from 1.28716
Epoch 2692/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4389 - val_loss: 1.2898 - val_accuracy: 0.4378

Epoch 02692: val_loss did not improve from 1.28716
Epoch 2693/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4359 - val_loss: 1.2906 - val_accuracy: 0.4370

Epoch 02693: val_loss did not improve from 1.28716
Epoch 2694/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4380 - val_loss: 1.2907 - val_accuracy: 0.4274

Epoch 02694: val_loss did not improve from 1.28716
Epoch 2695/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4335 - val_loss: 1.2940 - val_accuracy: 0.4394

Epoch 02695: val_loss did not improve from 1.28716
Epoch 2696/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4321 - val_loss: 1.2919 - val_accuracy: 0.4266

Epoch 02696: val_loss did not improve from 1.28716
Epoch 2697/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4334 - val_loss: 1.2894 - val_accuracy: 0.4418

Epoch 02697: val_loss did not improve from 1.28716
Epoch 2698/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4347 - val_loss: 1.2933 - val_accuracy: 0.4450

Epoch 02698: val_loss did not improve from 1.28716
Epoch 2699/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4385 - val_loss: 1.2884 - val_accuracy: 0.4354

Epoch 02699: val_loss did not improve from 1.28716
Epoch 2700/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4330 - val_loss: 1.2904 - val_accuracy: 0.4330

Epoch 02700: val_loss did not improve from 1.28716
Epoch 2701/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4360 - val_loss: 1.2919 - val_accuracy: 0.4338

Epoch 02701: val_loss did not improve from 1.28716
Epoch 2702/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4355 - val_loss: 1.2910 - val_accuracy: 0.4330

Epoch 02702: val_loss did not improve from 1.28716
Epoch 2703/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4359 - val_loss: 1.2899 - val_accuracy: 0.4282

Epoch 02703: val_loss did not improve from 1.28716
Epoch 2704/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4386 - val_loss: 1.2900 - val_accuracy: 0.4306

Epoch 02704: val_loss did not improve from 1.28716
Epoch 2705/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4323 - val_loss: 1.2901 - val_accuracy: 0.4306

Epoch 02705: val_loss did not improve from 1.28716
Epoch 2706/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4372 - val_loss: 1.2928 - val_accuracy: 0.4386

Epoch 02706: val_loss did not improve from 1.28716
Epoch 2707/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4338 - val_loss: 1.2898 - val_accuracy: 0.4522

Epoch 02707: val_loss did not improve from 1.28716
Epoch 2708/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4324 - val_loss: 1.2898 - val_accuracy: 0.4402

Epoch 02708: val_loss did not improve from 1.28716
Epoch 2709/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4345 - val_loss: 1.2888 - val_accuracy: 0.4378

Epoch 02709: val_loss did not improve from 1.28716
Epoch 2710/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4388 - val_loss: 1.2889 - val_accuracy: 0.4442

Epoch 02710: val_loss did not improve from 1.28716
Epoch 2711/10000
12/12 - 0s - loss: 1.2545 - accuracy: 0.4380 - val_loss: 1.2935 - val_accuracy: 0.4450

Epoch 02711: val_loss did not improve from 1.28716
Epoch 2712/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4358 - val_loss: 1.2883 - val_accuracy: 0.4370

Epoch 02712: val_loss did not improve from 1.28716
Epoch 2713/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4352 - val_loss: 1.2899 - val_accuracy: 0.4450

Epoch 02713: val_loss did not improve from 1.28716
Epoch 2714/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4359 - val_loss: 1.2899 - val_accuracy: 0.4402

Epoch 02714: val_loss did not improve from 1.28716
Epoch 2715/10000
12/12 - 0s - loss: 1.2530 - accuracy: 0.4384 - val_loss: 1.2884 - val_accuracy: 0.4378

Epoch 02715: val_loss did not improve from 1.28716
Epoch 2716/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4338 - val_loss: 1.2891 - val_accuracy: 0.4362

Epoch 02716: val_loss did not improve from 1.28716
Epoch 2717/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4354 - val_loss: 1.2907 - val_accuracy: 0.4338

Epoch 02717: val_loss did not improve from 1.28716
Epoch 2718/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4371 - val_loss: 1.2916 - val_accuracy: 0.4426

Epoch 02718: val_loss did not improve from 1.28716
Epoch 2719/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4317 - val_loss: 1.2899 - val_accuracy: 0.4298

Epoch 02719: val_loss did not improve from 1.28716
Epoch 2720/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4371 - val_loss: 1.2932 - val_accuracy: 0.4482

Epoch 02720: val_loss did not improve from 1.28716
Epoch 2721/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4334 - val_loss: 1.2916 - val_accuracy: 0.4386

Epoch 02721: val_loss did not improve from 1.28716
Epoch 2722/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4374 - val_loss: 1.2911 - val_accuracy: 0.4298

Epoch 02722: val_loss did not improve from 1.28716
Epoch 2723/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4365 - val_loss: 1.2900 - val_accuracy: 0.4338

Epoch 02723: val_loss did not improve from 1.28716
Epoch 2724/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4342 - val_loss: 1.2907 - val_accuracy: 0.4450

Epoch 02724: val_loss did not improve from 1.28716
Epoch 2725/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4344 - val_loss: 1.2937 - val_accuracy: 0.4370

Epoch 02725: val_loss did not improve from 1.28716
Epoch 2726/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4363 - val_loss: 1.2899 - val_accuracy: 0.4402

Epoch 02726: val_loss did not improve from 1.28716
Epoch 2727/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4367 - val_loss: 1.2880 - val_accuracy: 0.4466

Epoch 02727: val_loss did not improve from 1.28716
Epoch 2728/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4345 - val_loss: 1.2908 - val_accuracy: 0.4386

Epoch 02728: val_loss did not improve from 1.28716
Epoch 2729/10000
12/12 - 0s - loss: 1.2526 - accuracy: 0.4388 - val_loss: 1.2880 - val_accuracy: 0.4474

Epoch 02729: val_loss did not improve from 1.28716
Epoch 2730/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4317 - val_loss: 1.2878 - val_accuracy: 0.4362

Epoch 02730: val_loss did not improve from 1.28716
Epoch 2731/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4388 - val_loss: 1.2925 - val_accuracy: 0.4402

Epoch 02731: val_loss did not improve from 1.28716
Epoch 2732/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4388 - val_loss: 1.2881 - val_accuracy: 0.4370

Epoch 02732: val_loss did not improve from 1.28716
Epoch 2733/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4365 - val_loss: 1.2893 - val_accuracy: 0.4394

Epoch 02733: val_loss did not improve from 1.28716
Epoch 2734/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4381 - val_loss: 1.2896 - val_accuracy: 0.4306

Epoch 02734: val_loss did not improve from 1.28716
Epoch 2735/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4360 - val_loss: 1.2929 - val_accuracy: 0.4426

Epoch 02735: val_loss did not improve from 1.28716
Epoch 2736/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4339 - val_loss: 1.2945 - val_accuracy: 0.4338

Epoch 02736: val_loss did not improve from 1.28716
Epoch 2737/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4348 - val_loss: 1.2908 - val_accuracy: 0.4346

Epoch 02737: val_loss did not improve from 1.28716
Epoch 2738/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4342 - val_loss: 1.2902 - val_accuracy: 0.4378

Epoch 02738: val_loss did not improve from 1.28716
Epoch 2739/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4342 - val_loss: 1.2886 - val_accuracy: 0.4346

Epoch 02739: val_loss did not improve from 1.28716
Epoch 2740/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4382 - val_loss: 1.2900 - val_accuracy: 0.4530

Epoch 02740: val_loss did not improve from 1.28716
Epoch 2741/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4353 - val_loss: 1.2879 - val_accuracy: 0.4394

Epoch 02741: val_loss did not improve from 1.28716
Epoch 2742/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4410 - val_loss: 1.2889 - val_accuracy: 0.4394

Epoch 02742: val_loss did not improve from 1.28716
Epoch 2743/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4319 - val_loss: 1.2967 - val_accuracy: 0.4442

Epoch 02743: val_loss did not improve from 1.28716
Epoch 2744/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4357 - val_loss: 1.2887 - val_accuracy: 0.4370

Epoch 02744: val_loss did not improve from 1.28716
Epoch 2745/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4381 - val_loss: 1.2896 - val_accuracy: 0.4402

Epoch 02745: val_loss did not improve from 1.28716
Epoch 2746/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4408 - val_loss: 1.2917 - val_accuracy: 0.4306

Epoch 02746: val_loss did not improve from 1.28716
Epoch 2747/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4392 - val_loss: 1.2882 - val_accuracy: 0.4370

Epoch 02747: val_loss did not improve from 1.28716
Epoch 2748/10000
12/12 - 0s - loss: 1.2539 - accuracy: 0.4409 - val_loss: 1.2876 - val_accuracy: 0.4330

Epoch 02748: val_loss did not improve from 1.28716
Epoch 2749/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4380 - val_loss: 1.2895 - val_accuracy: 0.4402

Epoch 02749: val_loss did not improve from 1.28716
Epoch 2750/10000
12/12 - 0s - loss: 1.2553 - accuracy: 0.4365 - val_loss: 1.2911 - val_accuracy: 0.4330

Epoch 02750: val_loss did not improve from 1.28716
Epoch 2751/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4388 - val_loss: 1.2936 - val_accuracy: 0.4410

Epoch 02751: val_loss did not improve from 1.28716
Epoch 2752/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4390 - val_loss: 1.2912 - val_accuracy: 0.4250

Epoch 02752: val_loss did not improve from 1.28716
Epoch 2753/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4373 - val_loss: 1.2891 - val_accuracy: 0.4434

Epoch 02753: val_loss did not improve from 1.28716
Epoch 2754/10000
12/12 - 0s - loss: 1.2532 - accuracy: 0.4381 - val_loss: 1.2896 - val_accuracy: 0.4490

Epoch 02754: val_loss did not improve from 1.28716
Epoch 2755/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4378 - val_loss: 1.2885 - val_accuracy: 0.4362

Epoch 02755: val_loss did not improve from 1.28716
Epoch 2756/10000
12/12 - 0s - loss: 1.2531 - accuracy: 0.4388 - val_loss: 1.2889 - val_accuracy: 0.4314

Epoch 02756: val_loss did not improve from 1.28716
Epoch 2757/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4373 - val_loss: 1.2894 - val_accuracy: 0.4370

Epoch 02757: val_loss did not improve from 1.28716
Epoch 2758/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4361 - val_loss: 1.2935 - val_accuracy: 0.4466

Epoch 02758: val_loss did not improve from 1.28716
Epoch 2759/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4388 - val_loss: 1.2907 - val_accuracy: 0.4362

Epoch 02759: val_loss did not improve from 1.28716
Epoch 2760/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4342 - val_loss: 1.2884 - val_accuracy: 0.4418

Epoch 02760: val_loss did not improve from 1.28716
Epoch 2761/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4339 - val_loss: 1.2880 - val_accuracy: 0.4378

Epoch 02761: val_loss did not improve from 1.28716
Epoch 2762/10000
12/12 - 0s - loss: 1.2521 - accuracy: 0.4378 - val_loss: 1.2899 - val_accuracy: 0.4442

Epoch 02762: val_loss did not improve from 1.28716
Epoch 2763/10000
12/12 - 0s - loss: 1.2529 - accuracy: 0.4367 - val_loss: 1.2893 - val_accuracy: 0.4378

Epoch 02763: val_loss did not improve from 1.28716
Epoch 02763: early stopping
*************************** Fold #: 9 ***************************
Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_272 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_273 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_274 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_275 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6159 - accuracy: 0.2275 - val_loss: 1.6067 - val_accuracy: 0.2289

Epoch 00001: val_loss improved from inf to 1.60671, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 2/10000
12/12 - 0s - loss: 1.6026 - accuracy: 0.2363 - val_loss: 1.5969 - val_accuracy: 0.2560

Epoch 00002: val_loss improved from 1.60671 to 1.59687, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 3/10000
12/12 - 0s - loss: 1.5912 - accuracy: 0.2842 - val_loss: 1.5857 - val_accuracy: 0.2990

Epoch 00003: val_loss improved from 1.59687 to 1.58566, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 4/10000
12/12 - 0s - loss: 1.5780 - accuracy: 0.3039 - val_loss: 1.5708 - val_accuracy: 0.3038

Epoch 00004: val_loss improved from 1.58566 to 1.57075, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 5/10000
12/12 - 0s - loss: 1.5599 - accuracy: 0.3120 - val_loss: 1.5510 - val_accuracy: 0.3222

Epoch 00005: val_loss improved from 1.57075 to 1.55104, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 6/10000
12/12 - 0s - loss: 1.5356 - accuracy: 0.3228 - val_loss: 1.5259 - val_accuracy: 0.3206

Epoch 00006: val_loss improved from 1.55104 to 1.52593, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 7/10000
12/12 - 0s - loss: 1.5060 - accuracy: 0.3349 - val_loss: 1.4961 - val_accuracy: 0.3238

Epoch 00007: val_loss improved from 1.52593 to 1.49606, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 8/10000
12/12 - 0s - loss: 1.4704 - accuracy: 0.3446 - val_loss: 1.4609 - val_accuracy: 0.3285

Epoch 00008: val_loss improved from 1.49606 to 1.46088, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 9/10000
12/12 - 0s - loss: 1.4302 - accuracy: 0.3502 - val_loss: 1.4268 - val_accuracy: 0.3421

Epoch 00009: val_loss improved from 1.46088 to 1.42681, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 10/10000
12/12 - 0s - loss: 1.3982 - accuracy: 0.3572 - val_loss: 1.4038 - val_accuracy: 0.3445

Epoch 00010: val_loss improved from 1.42681 to 1.40381, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 11/10000
12/12 - 0s - loss: 1.3718 - accuracy: 0.3745 - val_loss: 1.3855 - val_accuracy: 0.3644

Epoch 00011: val_loss improved from 1.40381 to 1.38548, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 12/10000
12/12 - 0s - loss: 1.3574 - accuracy: 0.3730 - val_loss: 1.3785 - val_accuracy: 0.3581

Epoch 00012: val_loss improved from 1.38548 to 1.37848, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 13/10000
12/12 - 0s - loss: 1.3458 - accuracy: 0.3698 - val_loss: 1.3735 - val_accuracy: 0.3589

Epoch 00013: val_loss improved from 1.37848 to 1.37347, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 14/10000
12/12 - 0s - loss: 1.3410 - accuracy: 0.3873 - val_loss: 1.3668 - val_accuracy: 0.3652

Epoch 00014: val_loss improved from 1.37347 to 1.36677, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 15/10000
12/12 - 0s - loss: 1.3364 - accuracy: 0.3863 - val_loss: 1.3665 - val_accuracy: 0.3724

Epoch 00015: val_loss improved from 1.36677 to 1.36650, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 16/10000
12/12 - 0s - loss: 1.3353 - accuracy: 0.3856 - val_loss: 1.3681 - val_accuracy: 0.3636

Epoch 00016: val_loss did not improve from 1.36650
Epoch 17/10000
12/12 - 0s - loss: 1.3343 - accuracy: 0.3817 - val_loss: 1.3665 - val_accuracy: 0.3724

Epoch 00017: val_loss did not improve from 1.36650
Epoch 18/10000
12/12 - 0s - loss: 1.3375 - accuracy: 0.3817 - val_loss: 1.3653 - val_accuracy: 0.3764

Epoch 00018: val_loss improved from 1.36650 to 1.36526, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 19/10000
12/12 - 0s - loss: 1.3344 - accuracy: 0.3918 - val_loss: 1.3705 - val_accuracy: 0.3692

Epoch 00019: val_loss did not improve from 1.36526
Epoch 20/10000
12/12 - 0s - loss: 1.3404 - accuracy: 0.3829 - val_loss: 1.3645 - val_accuracy: 0.3828

Epoch 00020: val_loss improved from 1.36526 to 1.36448, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 21/10000
12/12 - 0s - loss: 1.3337 - accuracy: 0.3938 - val_loss: 1.3733 - val_accuracy: 0.3644

Epoch 00021: val_loss did not improve from 1.36448
Epoch 22/10000
12/12 - 0s - loss: 1.3363 - accuracy: 0.3840 - val_loss: 1.3647 - val_accuracy: 0.3884

Epoch 00022: val_loss did not improve from 1.36448
Epoch 23/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.3855 - val_loss: 1.3626 - val_accuracy: 0.3668

Epoch 00023: val_loss improved from 1.36448 to 1.36264, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 24/10000
12/12 - 0s - loss: 1.3352 - accuracy: 0.3875 - val_loss: 1.3644 - val_accuracy: 0.3676

Epoch 00024: val_loss did not improve from 1.36264
Epoch 25/10000
12/12 - 0s - loss: 1.3321 - accuracy: 0.3882 - val_loss: 1.3641 - val_accuracy: 0.3644

Epoch 00025: val_loss did not improve from 1.36264
Epoch 26/10000
12/12 - 0s - loss: 1.3316 - accuracy: 0.3918 - val_loss: 1.3630 - val_accuracy: 0.3804

Epoch 00026: val_loss did not improve from 1.36264
Epoch 27/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3885 - val_loss: 1.3611 - val_accuracy: 0.3820

Epoch 00027: val_loss improved from 1.36264 to 1.36107, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 28/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3881 - val_loss: 1.3610 - val_accuracy: 0.3844

Epoch 00028: val_loss improved from 1.36107 to 1.36103, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 29/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3947 - val_loss: 1.3604 - val_accuracy: 0.3876

Epoch 00029: val_loss improved from 1.36103 to 1.36037, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 30/10000
12/12 - 0s - loss: 1.3316 - accuracy: 0.3951 - val_loss: 1.3681 - val_accuracy: 0.3684

Epoch 00030: val_loss did not improve from 1.36037
Epoch 31/10000
12/12 - 0s - loss: 1.3320 - accuracy: 0.3918 - val_loss: 1.3596 - val_accuracy: 0.3844

Epoch 00031: val_loss improved from 1.36037 to 1.35959, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 32/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3900 - val_loss: 1.3595 - val_accuracy: 0.3780

Epoch 00032: val_loss improved from 1.35959 to 1.35952, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 33/10000
12/12 - 0s - loss: 1.3299 - accuracy: 0.3886 - val_loss: 1.3613 - val_accuracy: 0.3724

Epoch 00033: val_loss did not improve from 1.35952
Epoch 34/10000
12/12 - 0s - loss: 1.3282 - accuracy: 0.3871 - val_loss: 1.3592 - val_accuracy: 0.3844

Epoch 00034: val_loss improved from 1.35952 to 1.35916, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 35/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3978 - val_loss: 1.3601 - val_accuracy: 0.3892

Epoch 00035: val_loss did not improve from 1.35916
Epoch 36/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3896 - val_loss: 1.3616 - val_accuracy: 0.3644

Epoch 00036: val_loss did not improve from 1.35916
Epoch 37/10000
12/12 - 0s - loss: 1.3292 - accuracy: 0.3819 - val_loss: 1.3607 - val_accuracy: 0.3692

Epoch 00037: val_loss did not improve from 1.35916
Epoch 38/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3864 - val_loss: 1.3585 - val_accuracy: 0.3923

Epoch 00038: val_loss improved from 1.35916 to 1.35853, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 39/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3970 - val_loss: 1.3582 - val_accuracy: 0.3907

Epoch 00039: val_loss improved from 1.35853 to 1.35817, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 40/10000
12/12 - 0s - loss: 1.3289 - accuracy: 0.3953 - val_loss: 1.3623 - val_accuracy: 0.3900

Epoch 00040: val_loss did not improve from 1.35817
Epoch 41/10000
12/12 - 0s - loss: 1.3276 - accuracy: 0.3918 - val_loss: 1.3581 - val_accuracy: 0.3812

Epoch 00041: val_loss improved from 1.35817 to 1.35815, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 42/10000
12/12 - 0s - loss: 1.3317 - accuracy: 0.3914 - val_loss: 1.3638 - val_accuracy: 0.3628

Epoch 00042: val_loss did not improve from 1.35815
Epoch 43/10000
12/12 - 0s - loss: 1.3274 - accuracy: 0.3898 - val_loss: 1.3597 - val_accuracy: 0.3955

Epoch 00043: val_loss did not improve from 1.35815
Epoch 44/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3976 - val_loss: 1.3652 - val_accuracy: 0.3668

Epoch 00044: val_loss did not improve from 1.35815
Epoch 45/10000
12/12 - 0s - loss: 1.3280 - accuracy: 0.3910 - val_loss: 1.3570 - val_accuracy: 0.3884

Epoch 00045: val_loss improved from 1.35815 to 1.35705, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 46/10000
12/12 - 0s - loss: 1.3287 - accuracy: 0.3931 - val_loss: 1.3587 - val_accuracy: 0.3923

Epoch 00046: val_loss did not improve from 1.35705
Epoch 47/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3942 - val_loss: 1.3589 - val_accuracy: 0.3708

Epoch 00047: val_loss did not improve from 1.35705
Epoch 48/10000
12/12 - 0s - loss: 1.3277 - accuracy: 0.3934 - val_loss: 1.3620 - val_accuracy: 0.3716

Epoch 00048: val_loss did not improve from 1.35705
Epoch 49/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3953 - val_loss: 1.3575 - val_accuracy: 0.3868

Epoch 00049: val_loss did not improve from 1.35705
Epoch 50/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3923 - val_loss: 1.3572 - val_accuracy: 0.3852

Epoch 00050: val_loss did not improve from 1.35705
Epoch 51/10000
12/12 - 0s - loss: 1.3269 - accuracy: 0.3945 - val_loss: 1.3564 - val_accuracy: 0.3900

Epoch 00051: val_loss improved from 1.35705 to 1.35636, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 52/10000
12/12 - 0s - loss: 1.3295 - accuracy: 0.3998 - val_loss: 1.3597 - val_accuracy: 0.3780

Epoch 00052: val_loss did not improve from 1.35636
Epoch 53/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3962 - val_loss: 1.3566 - val_accuracy: 0.3828

Epoch 00053: val_loss did not improve from 1.35636
Epoch 54/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3962 - val_loss: 1.3563 - val_accuracy: 0.3804

Epoch 00054: val_loss improved from 1.35636 to 1.35633, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 55/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3965 - val_loss: 1.3558 - val_accuracy: 0.3852

Epoch 00055: val_loss improved from 1.35633 to 1.35584, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 56/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3931 - val_loss: 1.3563 - val_accuracy: 0.3828

Epoch 00056: val_loss did not improve from 1.35584
Epoch 57/10000
12/12 - 0s - loss: 1.3257 - accuracy: 0.3971 - val_loss: 1.3576 - val_accuracy: 0.3852

Epoch 00057: val_loss did not improve from 1.35584
Epoch 58/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3945 - val_loss: 1.3555 - val_accuracy: 0.3804

Epoch 00058: val_loss improved from 1.35584 to 1.35549, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 59/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3888 - val_loss: 1.3562 - val_accuracy: 0.3708

Epoch 00059: val_loss did not improve from 1.35549
Epoch 60/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3926 - val_loss: 1.3550 - val_accuracy: 0.3868

Epoch 00060: val_loss improved from 1.35549 to 1.35498, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 61/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3978 - val_loss: 1.3553 - val_accuracy: 0.3860

Epoch 00061: val_loss did not improve from 1.35498
Epoch 62/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3995 - val_loss: 1.3584 - val_accuracy: 0.3692

Epoch 00062: val_loss did not improve from 1.35498
Epoch 63/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3950 - val_loss: 1.3560 - val_accuracy: 0.3772

Epoch 00063: val_loss did not improve from 1.35498
Epoch 64/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3944 - val_loss: 1.3551 - val_accuracy: 0.3716

Epoch 00064: val_loss did not improve from 1.35498
Epoch 65/10000
12/12 - 0s - loss: 1.3249 - accuracy: 0.3891 - val_loss: 1.3546 - val_accuracy: 0.3860

Epoch 00065: val_loss improved from 1.35498 to 1.35464, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 66/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3973 - val_loss: 1.3538 - val_accuracy: 0.3788

Epoch 00066: val_loss improved from 1.35464 to 1.35381, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 67/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3949 - val_loss: 1.3531 - val_accuracy: 0.3836

Epoch 00067: val_loss improved from 1.35381 to 1.35315, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 68/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3980 - val_loss: 1.3562 - val_accuracy: 0.3772

Epoch 00068: val_loss did not improve from 1.35315
Epoch 69/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3979 - val_loss: 1.3558 - val_accuracy: 0.3892

Epoch 00069: val_loss did not improve from 1.35315
Epoch 70/10000
12/12 - 0s - loss: 1.3283 - accuracy: 0.3984 - val_loss: 1.3597 - val_accuracy: 0.3708

Epoch 00070: val_loss did not improve from 1.35315
Epoch 71/10000
12/12 - 0s - loss: 1.3247 - accuracy: 0.3978 - val_loss: 1.3570 - val_accuracy: 0.3844

Epoch 00071: val_loss did not improve from 1.35315
Epoch 72/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3915 - val_loss: 1.3531 - val_accuracy: 0.3907

Epoch 00072: val_loss improved from 1.35315 to 1.35306, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 73/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3939 - val_loss: 1.3535 - val_accuracy: 0.3724

Epoch 00073: val_loss did not improve from 1.35306
Epoch 74/10000
12/12 - 0s - loss: 1.3242 - accuracy: 0.3962 - val_loss: 1.3547 - val_accuracy: 0.3780

Epoch 00074: val_loss did not improve from 1.35306
Epoch 75/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3994 - val_loss: 1.3558 - val_accuracy: 0.3828

Epoch 00075: val_loss did not improve from 1.35306
Epoch 76/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3845 - val_loss: 1.3563 - val_accuracy: 0.3780

Epoch 00076: val_loss did not improve from 1.35306
Epoch 77/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.4009 - val_loss: 1.3525 - val_accuracy: 0.3820

Epoch 00077: val_loss improved from 1.35306 to 1.35247, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 78/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3986 - val_loss: 1.3561 - val_accuracy: 0.3892

Epoch 00078: val_loss did not improve from 1.35247
Epoch 79/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3990 - val_loss: 1.3533 - val_accuracy: 0.3780

Epoch 00079: val_loss did not improve from 1.35247
Epoch 80/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3928 - val_loss: 1.3564 - val_accuracy: 0.3788

Epoch 00080: val_loss did not improve from 1.35247
Epoch 81/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3955 - val_loss: 1.3532 - val_accuracy: 0.3884

Epoch 00081: val_loss did not improve from 1.35247
Epoch 82/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3966 - val_loss: 1.3582 - val_accuracy: 0.3884

Epoch 00082: val_loss did not improve from 1.35247
Epoch 83/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3961 - val_loss: 1.3518 - val_accuracy: 0.3780

Epoch 00083: val_loss improved from 1.35247 to 1.35182, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 84/10000
12/12 - 0s - loss: 1.3236 - accuracy: 0.3932 - val_loss: 1.3537 - val_accuracy: 0.3915

Epoch 00084: val_loss did not improve from 1.35182
Epoch 85/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3959 - val_loss: 1.3531 - val_accuracy: 0.3796

Epoch 00085: val_loss did not improve from 1.35182
Epoch 86/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3969 - val_loss: 1.3607 - val_accuracy: 0.3892

Epoch 00086: val_loss did not improve from 1.35182
Epoch 87/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3950 - val_loss: 1.3512 - val_accuracy: 0.3868

Epoch 00087: val_loss improved from 1.35182 to 1.35121, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 88/10000
12/12 - 0s - loss: 1.3224 - accuracy: 0.3986 - val_loss: 1.3527 - val_accuracy: 0.3860

Epoch 00088: val_loss did not improve from 1.35121
Epoch 89/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3978 - val_loss: 1.3525 - val_accuracy: 0.3820

Epoch 00089: val_loss did not improve from 1.35121
Epoch 90/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.4026 - val_loss: 1.3519 - val_accuracy: 0.3931

Epoch 00090: val_loss did not improve from 1.35121
Epoch 91/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3999 - val_loss: 1.3544 - val_accuracy: 0.3828

Epoch 00091: val_loss did not improve from 1.35121
Epoch 92/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3952 - val_loss: 1.3522 - val_accuracy: 0.3804

Epoch 00092: val_loss did not improve from 1.35121
Epoch 93/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3978 - val_loss: 1.3526 - val_accuracy: 0.3812

Epoch 00093: val_loss did not improve from 1.35121
Epoch 94/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.4005 - val_loss: 1.3518 - val_accuracy: 0.3828

Epoch 00094: val_loss did not improve from 1.35121
Epoch 95/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3979 - val_loss: 1.3515 - val_accuracy: 0.3884

Epoch 00095: val_loss did not improve from 1.35121
Epoch 96/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.4017 - val_loss: 1.3540 - val_accuracy: 0.3884

Epoch 00096: val_loss did not improve from 1.35121
Epoch 97/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3973 - val_loss: 1.3520 - val_accuracy: 0.3860

Epoch 00097: val_loss did not improve from 1.35121
Epoch 98/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3963 - val_loss: 1.3508 - val_accuracy: 0.3844

Epoch 00098: val_loss improved from 1.35121 to 1.35082, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 99/10000
12/12 - 0s - loss: 1.3204 - accuracy: 0.4021 - val_loss: 1.3517 - val_accuracy: 0.3772

Epoch 00099: val_loss did not improve from 1.35082
Epoch 100/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3992 - val_loss: 1.3510 - val_accuracy: 0.3852

Epoch 00100: val_loss did not improve from 1.35082
Epoch 101/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.4002 - val_loss: 1.3503 - val_accuracy: 0.3860

Epoch 00101: val_loss improved from 1.35082 to 1.35034, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 102/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3972 - val_loss: 1.3564 - val_accuracy: 0.3844

Epoch 00102: val_loss did not improve from 1.35034
Epoch 103/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3951 - val_loss: 1.3512 - val_accuracy: 0.3836

Epoch 00103: val_loss did not improve from 1.35034
Epoch 104/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3900 - val_loss: 1.3512 - val_accuracy: 0.3860

Epoch 00104: val_loss did not improve from 1.35034
Epoch 105/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.4021 - val_loss: 1.3513 - val_accuracy: 0.3900

Epoch 00105: val_loss did not improve from 1.35034
Epoch 106/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3967 - val_loss: 1.3510 - val_accuracy: 0.3828

Epoch 00106: val_loss did not improve from 1.35034
Epoch 107/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3946 - val_loss: 1.3499 - val_accuracy: 0.3844

Epoch 00107: val_loss improved from 1.35034 to 1.34989, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 108/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3953 - val_loss: 1.3523 - val_accuracy: 0.3860

Epoch 00108: val_loss did not improve from 1.34989
Epoch 109/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3956 - val_loss: 1.3539 - val_accuracy: 0.3740

Epoch 00109: val_loss did not improve from 1.34989
Epoch 110/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3955 - val_loss: 1.3492 - val_accuracy: 0.3884

Epoch 00110: val_loss improved from 1.34989 to 1.34924, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 111/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3971 - val_loss: 1.3488 - val_accuracy: 0.3844

Epoch 00111: val_loss improved from 1.34924 to 1.34878, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 112/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3974 - val_loss: 1.3535 - val_accuracy: 0.3692

Epoch 00112: val_loss did not improve from 1.34878
Epoch 113/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3908 - val_loss: 1.3499 - val_accuracy: 0.3820

Epoch 00113: val_loss did not improve from 1.34878
Epoch 114/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3967 - val_loss: 1.3512 - val_accuracy: 0.3876

Epoch 00114: val_loss did not improve from 1.34878
Epoch 115/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3997 - val_loss: 1.3493 - val_accuracy: 0.3820

Epoch 00115: val_loss did not improve from 1.34878
Epoch 116/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.4021 - val_loss: 1.3501 - val_accuracy: 0.3860

Epoch 00116: val_loss did not improve from 1.34878
Epoch 117/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.4025 - val_loss: 1.3515 - val_accuracy: 0.3796

Epoch 00117: val_loss did not improve from 1.34878
Epoch 118/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3956 - val_loss: 1.3497 - val_accuracy: 0.3836

Epoch 00118: val_loss did not improve from 1.34878
Epoch 119/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3974 - val_loss: 1.3494 - val_accuracy: 0.3788

Epoch 00119: val_loss did not improve from 1.34878
Epoch 120/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.4005 - val_loss: 1.3521 - val_accuracy: 0.3796

Epoch 00120: val_loss did not improve from 1.34878
Epoch 121/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3925 - val_loss: 1.3501 - val_accuracy: 0.3804

Epoch 00121: val_loss did not improve from 1.34878
Epoch 122/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3961 - val_loss: 1.3500 - val_accuracy: 0.3900

Epoch 00122: val_loss did not improve from 1.34878
Epoch 123/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3991 - val_loss: 1.3492 - val_accuracy: 0.3796

Epoch 00123: val_loss did not improve from 1.34878
Epoch 124/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3955 - val_loss: 1.3507 - val_accuracy: 0.3788

Epoch 00124: val_loss did not improve from 1.34878
Epoch 125/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3982 - val_loss: 1.3525 - val_accuracy: 0.3820

Epoch 00125: val_loss did not improve from 1.34878
Epoch 126/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3854 - val_loss: 1.3526 - val_accuracy: 0.3812

Epoch 00126: val_loss did not improve from 1.34878
Epoch 127/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3959 - val_loss: 1.3486 - val_accuracy: 0.3923

Epoch 00127: val_loss improved from 1.34878 to 1.34861, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 128/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.4030 - val_loss: 1.3554 - val_accuracy: 0.3796

Epoch 00128: val_loss did not improve from 1.34861
Epoch 129/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3961 - val_loss: 1.3512 - val_accuracy: 0.3844

Epoch 00129: val_loss did not improve from 1.34861
Epoch 130/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3954 - val_loss: 1.3508 - val_accuracy: 0.3868

Epoch 00130: val_loss did not improve from 1.34861
Epoch 131/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3959 - val_loss: 1.3492 - val_accuracy: 0.3868

Epoch 00131: val_loss did not improve from 1.34861
Epoch 132/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.4023 - val_loss: 1.3492 - val_accuracy: 0.3907

Epoch 00132: val_loss did not improve from 1.34861
Epoch 133/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4010 - val_loss: 1.3492 - val_accuracy: 0.3828

Epoch 00133: val_loss did not improve from 1.34861
Epoch 134/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.4017 - val_loss: 1.3484 - val_accuracy: 0.3923

Epoch 00134: val_loss improved from 1.34861 to 1.34844, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 135/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.4033 - val_loss: 1.3504 - val_accuracy: 0.3955

Epoch 00135: val_loss did not improve from 1.34844
Epoch 136/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.4044 - val_loss: 1.3500 - val_accuracy: 0.3915

Epoch 00136: val_loss did not improve from 1.34844
Epoch 137/10000
12/12 - 0s - loss: 1.3202 - accuracy: 0.3949 - val_loss: 1.3502 - val_accuracy: 0.3860

Epoch 00137: val_loss did not improve from 1.34844
Epoch 138/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3978 - val_loss: 1.3482 - val_accuracy: 0.3939

Epoch 00138: val_loss improved from 1.34844 to 1.34821, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 139/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.4013 - val_loss: 1.3499 - val_accuracy: 0.3844

Epoch 00139: val_loss did not improve from 1.34821
Epoch 140/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.4010 - val_loss: 1.3487 - val_accuracy: 0.3852

Epoch 00140: val_loss did not improve from 1.34821
Epoch 141/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3965 - val_loss: 1.3485 - val_accuracy: 0.3756

Epoch 00141: val_loss did not improve from 1.34821
Epoch 142/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3971 - val_loss: 1.3490 - val_accuracy: 0.3828

Epoch 00142: val_loss did not improve from 1.34821
Epoch 143/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3943 - val_loss: 1.3514 - val_accuracy: 0.3820

Epoch 00143: val_loss did not improve from 1.34821
Epoch 144/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.4006 - val_loss: 1.3481 - val_accuracy: 0.3876

Epoch 00144: val_loss improved from 1.34821 to 1.34810, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 145/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4015 - val_loss: 1.3481 - val_accuracy: 0.3844

Epoch 00145: val_loss improved from 1.34810 to 1.34808, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 146/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3984 - val_loss: 1.3470 - val_accuracy: 0.3860

Epoch 00146: val_loss improved from 1.34808 to 1.34697, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 147/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3984 - val_loss: 1.3501 - val_accuracy: 0.3900

Epoch 00147: val_loss did not improve from 1.34697
Epoch 148/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.4017 - val_loss: 1.3474 - val_accuracy: 0.3939

Epoch 00148: val_loss did not improve from 1.34697
Epoch 149/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3970 - val_loss: 1.3474 - val_accuracy: 0.3740

Epoch 00149: val_loss did not improve from 1.34697
Epoch 150/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3957 - val_loss: 1.3477 - val_accuracy: 0.3828

Epoch 00150: val_loss did not improve from 1.34697
Epoch 151/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3976 - val_loss: 1.3482 - val_accuracy: 0.3955

Epoch 00151: val_loss did not improve from 1.34697
Epoch 152/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3995 - val_loss: 1.3498 - val_accuracy: 0.3812

Epoch 00152: val_loss did not improve from 1.34697
Epoch 153/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.4029 - val_loss: 1.3469 - val_accuracy: 0.3780

Epoch 00153: val_loss improved from 1.34697 to 1.34686, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 154/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.4008 - val_loss: 1.3483 - val_accuracy: 0.3876

Epoch 00154: val_loss did not improve from 1.34686
Epoch 155/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3961 - val_loss: 1.3478 - val_accuracy: 0.3852

Epoch 00155: val_loss did not improve from 1.34686
Epoch 156/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3968 - val_loss: 1.3488 - val_accuracy: 0.3860

Epoch 00156: val_loss did not improve from 1.34686
Epoch 157/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3993 - val_loss: 1.3472 - val_accuracy: 0.3876

Epoch 00157: val_loss did not improve from 1.34686
Epoch 158/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3989 - val_loss: 1.3487 - val_accuracy: 0.3860

Epoch 00158: val_loss did not improve from 1.34686
Epoch 159/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.4020 - val_loss: 1.3535 - val_accuracy: 0.3748

Epoch 00159: val_loss did not improve from 1.34686
Epoch 160/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3932 - val_loss: 1.3486 - val_accuracy: 0.3923

Epoch 00160: val_loss did not improve from 1.34686
Epoch 161/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.4018 - val_loss: 1.3469 - val_accuracy: 0.3836

Epoch 00161: val_loss did not improve from 1.34686
Epoch 162/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.4023 - val_loss: 1.3569 - val_accuracy: 0.3732

Epoch 00162: val_loss did not improve from 1.34686
Epoch 163/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3959 - val_loss: 1.3476 - val_accuracy: 0.3971

Epoch 00163: val_loss did not improve from 1.34686
Epoch 164/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3926 - val_loss: 1.3484 - val_accuracy: 0.3868

Epoch 00164: val_loss did not improve from 1.34686
Epoch 165/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3965 - val_loss: 1.3477 - val_accuracy: 0.3820

Epoch 00165: val_loss did not improve from 1.34686
Epoch 166/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3946 - val_loss: 1.3462 - val_accuracy: 0.3812

Epoch 00166: val_loss improved from 1.34686 to 1.34621, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 167/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3963 - val_loss: 1.3463 - val_accuracy: 0.3844

Epoch 00167: val_loss did not improve from 1.34621
Epoch 168/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3950 - val_loss: 1.3497 - val_accuracy: 0.3884

Epoch 00168: val_loss did not improve from 1.34621
Epoch 169/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3954 - val_loss: 1.3491 - val_accuracy: 0.3820

Epoch 00169: val_loss did not improve from 1.34621
Epoch 170/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3990 - val_loss: 1.3476 - val_accuracy: 0.3860

Epoch 00170: val_loss did not improve from 1.34621
Epoch 171/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3988 - val_loss: 1.3484 - val_accuracy: 0.3907

Epoch 00171: val_loss did not improve from 1.34621
Epoch 172/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3978 - val_loss: 1.3473 - val_accuracy: 0.3884

Epoch 00172: val_loss did not improve from 1.34621
Epoch 173/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4012 - val_loss: 1.3496 - val_accuracy: 0.3836

Epoch 00173: val_loss did not improve from 1.34621
Epoch 174/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3950 - val_loss: 1.3468 - val_accuracy: 0.3780

Epoch 00174: val_loss did not improve from 1.34621
Epoch 175/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.4021 - val_loss: 1.3472 - val_accuracy: 0.3995

Epoch 00175: val_loss did not improve from 1.34621
Epoch 176/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.4017 - val_loss: 1.3470 - val_accuracy: 0.3995

Epoch 00176: val_loss did not improve from 1.34621
Epoch 177/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.4043 - val_loss: 1.3483 - val_accuracy: 0.3812

Epoch 00177: val_loss did not improve from 1.34621
Epoch 178/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3950 - val_loss: 1.3479 - val_accuracy: 0.3868

Epoch 00178: val_loss did not improve from 1.34621
Epoch 179/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3968 - val_loss: 1.3535 - val_accuracy: 0.3860

Epoch 00179: val_loss did not improve from 1.34621
Epoch 180/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3947 - val_loss: 1.3520 - val_accuracy: 0.3812

Epoch 00180: val_loss did not improve from 1.34621
Epoch 181/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.4006 - val_loss: 1.3483 - val_accuracy: 0.3923

Epoch 00181: val_loss did not improve from 1.34621
Epoch 182/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3980 - val_loss: 1.3461 - val_accuracy: 0.3947

Epoch 00182: val_loss improved from 1.34621 to 1.34610, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 183/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3976 - val_loss: 1.3463 - val_accuracy: 0.3939

Epoch 00183: val_loss did not improve from 1.34610
Epoch 184/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3998 - val_loss: 1.3479 - val_accuracy: 0.3995

Epoch 00184: val_loss did not improve from 1.34610
Epoch 185/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4007 - val_loss: 1.3462 - val_accuracy: 0.3868

Epoch 00185: val_loss did not improve from 1.34610
Epoch 186/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4011 - val_loss: 1.3466 - val_accuracy: 0.3868

Epoch 00186: val_loss did not improve from 1.34610
Epoch 187/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4033 - val_loss: 1.3458 - val_accuracy: 0.3923

Epoch 00187: val_loss improved from 1.34610 to 1.34580, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 188/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.4009 - val_loss: 1.3467 - val_accuracy: 0.3915

Epoch 00188: val_loss did not improve from 1.34580
Epoch 189/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3994 - val_loss: 1.3506 - val_accuracy: 0.3900

Epoch 00189: val_loss did not improve from 1.34580
Epoch 190/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3953 - val_loss: 1.3473 - val_accuracy: 0.3836

Epoch 00190: val_loss did not improve from 1.34580
Epoch 191/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3932 - val_loss: 1.3487 - val_accuracy: 0.3844

Epoch 00191: val_loss did not improve from 1.34580
Epoch 192/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3989 - val_loss: 1.3474 - val_accuracy: 0.3915

Epoch 00192: val_loss did not improve from 1.34580
Epoch 193/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.4018 - val_loss: 1.3521 - val_accuracy: 0.3860

Epoch 00193: val_loss did not improve from 1.34580
Epoch 194/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3916 - val_loss: 1.3459 - val_accuracy: 0.3796

Epoch 00194: val_loss did not improve from 1.34580
Epoch 195/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3977 - val_loss: 1.3454 - val_accuracy: 0.3852

Epoch 00195: val_loss improved from 1.34580 to 1.34543, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 196/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4006 - val_loss: 1.3455 - val_accuracy: 0.3884

Epoch 00196: val_loss did not improve from 1.34543
Epoch 197/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4021 - val_loss: 1.3453 - val_accuracy: 0.3884

Epoch 00197: val_loss improved from 1.34543 to 1.34534, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 198/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.4001 - val_loss: 1.3464 - val_accuracy: 0.3892

Epoch 00198: val_loss did not improve from 1.34534
Epoch 199/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3979 - val_loss: 1.3456 - val_accuracy: 0.3900

Epoch 00199: val_loss did not improve from 1.34534
Epoch 200/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3981 - val_loss: 1.3450 - val_accuracy: 0.3907

Epoch 00200: val_loss improved from 1.34534 to 1.34499, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 201/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3967 - val_loss: 1.3457 - val_accuracy: 0.3860

Epoch 00201: val_loss did not improve from 1.34499
Epoch 202/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3971 - val_loss: 1.3451 - val_accuracy: 0.3963

Epoch 00202: val_loss did not improve from 1.34499
Epoch 203/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3977 - val_loss: 1.3489 - val_accuracy: 0.3852

Epoch 00203: val_loss did not improve from 1.34499
Epoch 204/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3958 - val_loss: 1.3467 - val_accuracy: 0.3892

Epoch 00204: val_loss did not improve from 1.34499
Epoch 205/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4017 - val_loss: 1.3460 - val_accuracy: 0.3876

Epoch 00205: val_loss did not improve from 1.34499
Epoch 206/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3977 - val_loss: 1.3454 - val_accuracy: 0.3947

Epoch 00206: val_loss did not improve from 1.34499
Epoch 207/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4051 - val_loss: 1.3447 - val_accuracy: 0.3947

Epoch 00207: val_loss improved from 1.34499 to 1.34472, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 208/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4021 - val_loss: 1.3466 - val_accuracy: 0.3876

Epoch 00208: val_loss did not improve from 1.34472
Epoch 209/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4012 - val_loss: 1.3442 - val_accuracy: 0.3963

Epoch 00209: val_loss improved from 1.34472 to 1.34424, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 210/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4005 - val_loss: 1.3521 - val_accuracy: 0.3820

Epoch 00210: val_loss did not improve from 1.34424
Epoch 211/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3963 - val_loss: 1.3451 - val_accuracy: 0.3915

Epoch 00211: val_loss did not improve from 1.34424
Epoch 212/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4003 - val_loss: 1.3447 - val_accuracy: 0.3955

Epoch 00212: val_loss did not improve from 1.34424
Epoch 213/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4010 - val_loss: 1.3485 - val_accuracy: 0.3828

Epoch 00213: val_loss did not improve from 1.34424
Epoch 214/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3957 - val_loss: 1.3466 - val_accuracy: 0.4027

Epoch 00214: val_loss did not improve from 1.34424
Epoch 215/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3981 - val_loss: 1.3454 - val_accuracy: 0.3947

Epoch 00215: val_loss did not improve from 1.34424
Epoch 216/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4000 - val_loss: 1.3476 - val_accuracy: 0.3852

Epoch 00216: val_loss did not improve from 1.34424
Epoch 217/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4024 - val_loss: 1.3443 - val_accuracy: 0.3915

Epoch 00217: val_loss did not improve from 1.34424
Epoch 218/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.4028 - val_loss: 1.3447 - val_accuracy: 0.3884

Epoch 00218: val_loss did not improve from 1.34424
Epoch 219/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3964 - val_loss: 1.3442 - val_accuracy: 0.3852

Epoch 00219: val_loss improved from 1.34424 to 1.34416, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 220/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3998 - val_loss: 1.3479 - val_accuracy: 0.3876

Epoch 00220: val_loss did not improve from 1.34416
Epoch 221/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3980 - val_loss: 1.3450 - val_accuracy: 0.3971

Epoch 00221: val_loss did not improve from 1.34416
Epoch 222/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3991 - val_loss: 1.3445 - val_accuracy: 0.3939

Epoch 00222: val_loss did not improve from 1.34416
Epoch 223/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3980 - val_loss: 1.3468 - val_accuracy: 0.3844

Epoch 00223: val_loss did not improve from 1.34416
Epoch 224/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3978 - val_loss: 1.3449 - val_accuracy: 0.3884

Epoch 00224: val_loss did not improve from 1.34416
Epoch 225/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4040 - val_loss: 1.3443 - val_accuracy: 0.3955

Epoch 00225: val_loss did not improve from 1.34416
Epoch 226/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3993 - val_loss: 1.3490 - val_accuracy: 0.3844

Epoch 00226: val_loss did not improve from 1.34416
Epoch 227/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.4020 - val_loss: 1.3465 - val_accuracy: 0.3939

Epoch 00227: val_loss did not improve from 1.34416
Epoch 228/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4031 - val_loss: 1.3445 - val_accuracy: 0.3971

Epoch 00228: val_loss did not improve from 1.34416
Epoch 229/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.4000 - val_loss: 1.3441 - val_accuracy: 0.3923

Epoch 00229: val_loss improved from 1.34416 to 1.34413, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 230/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4016 - val_loss: 1.3445 - val_accuracy: 0.3884

Epoch 00230: val_loss did not improve from 1.34413
Epoch 231/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4042 - val_loss: 1.3492 - val_accuracy: 0.3907

Epoch 00231: val_loss did not improve from 1.34413
Epoch 232/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3991 - val_loss: 1.3500 - val_accuracy: 0.3892

Epoch 00232: val_loss did not improve from 1.34413
Epoch 233/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3995 - val_loss: 1.3514 - val_accuracy: 0.3907

Epoch 00233: val_loss did not improve from 1.34413
Epoch 234/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4022 - val_loss: 1.3459 - val_accuracy: 0.3939

Epoch 00234: val_loss did not improve from 1.34413
Epoch 235/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.4009 - val_loss: 1.3439 - val_accuracy: 0.3939

Epoch 00235: val_loss improved from 1.34413 to 1.34387, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 236/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4012 - val_loss: 1.3445 - val_accuracy: 0.3907

Epoch 00236: val_loss did not improve from 1.34387
Epoch 237/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.4039 - val_loss: 1.3457 - val_accuracy: 0.3931

Epoch 00237: val_loss did not improve from 1.34387
Epoch 238/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.4014 - val_loss: 1.3453 - val_accuracy: 0.3852

Epoch 00238: val_loss did not improve from 1.34387
Epoch 239/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3979 - val_loss: 1.3451 - val_accuracy: 0.3907

Epoch 00239: val_loss did not improve from 1.34387
Epoch 240/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3978 - val_loss: 1.3444 - val_accuracy: 0.3844

Epoch 00240: val_loss did not improve from 1.34387
Epoch 241/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4043 - val_loss: 1.3470 - val_accuracy: 0.3923

Epoch 00241: val_loss did not improve from 1.34387
Epoch 242/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3984 - val_loss: 1.3447 - val_accuracy: 0.3907

Epoch 00242: val_loss did not improve from 1.34387
Epoch 243/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.4032 - val_loss: 1.3481 - val_accuracy: 0.3900

Epoch 00243: val_loss did not improve from 1.34387
Epoch 244/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3959 - val_loss: 1.3435 - val_accuracy: 0.3915

Epoch 00244: val_loss improved from 1.34387 to 1.34349, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 245/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3940 - val_loss: 1.3457 - val_accuracy: 0.3915

Epoch 00245: val_loss did not improve from 1.34349
Epoch 246/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4010 - val_loss: 1.3440 - val_accuracy: 0.3907

Epoch 00246: val_loss did not improve from 1.34349
Epoch 247/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3994 - val_loss: 1.3465 - val_accuracy: 0.3852

Epoch 00247: val_loss did not improve from 1.34349
Epoch 248/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.4005 - val_loss: 1.3431 - val_accuracy: 0.3915

Epoch 00248: val_loss improved from 1.34349 to 1.34307, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 249/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4011 - val_loss: 1.3438 - val_accuracy: 0.3868

Epoch 00249: val_loss did not improve from 1.34307
Epoch 250/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3985 - val_loss: 1.3457 - val_accuracy: 0.3868

Epoch 00250: val_loss did not improve from 1.34307
Epoch 251/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.4005 - val_loss: 1.3449 - val_accuracy: 0.3947

Epoch 00251: val_loss did not improve from 1.34307
Epoch 252/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3995 - val_loss: 1.3448 - val_accuracy: 0.3923

Epoch 00252: val_loss did not improve from 1.34307
Epoch 253/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.4041 - val_loss: 1.3460 - val_accuracy: 0.3900

Epoch 00253: val_loss did not improve from 1.34307
Epoch 254/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4036 - val_loss: 1.3444 - val_accuracy: 0.3892

Epoch 00254: val_loss did not improve from 1.34307
Epoch 255/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4018 - val_loss: 1.3436 - val_accuracy: 0.3939

Epoch 00255: val_loss did not improve from 1.34307
Epoch 256/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4055 - val_loss: 1.3495 - val_accuracy: 0.3971

Epoch 00256: val_loss did not improve from 1.34307
Epoch 257/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4021 - val_loss: 1.3489 - val_accuracy: 0.3884

Epoch 00257: val_loss did not improve from 1.34307
Epoch 258/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3996 - val_loss: 1.3514 - val_accuracy: 0.3876

Epoch 00258: val_loss did not improve from 1.34307
Epoch 259/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3938 - val_loss: 1.3453 - val_accuracy: 0.3939

Epoch 00259: val_loss did not improve from 1.34307
Epoch 260/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3946 - val_loss: 1.3474 - val_accuracy: 0.3900

Epoch 00260: val_loss did not improve from 1.34307
Epoch 261/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.4047 - val_loss: 1.3500 - val_accuracy: 0.3868

Epoch 00261: val_loss did not improve from 1.34307
Epoch 262/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4000 - val_loss: 1.3441 - val_accuracy: 0.3860

Epoch 00262: val_loss did not improve from 1.34307
Epoch 263/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4037 - val_loss: 1.3442 - val_accuracy: 0.3892

Epoch 00263: val_loss did not improve from 1.34307
Epoch 264/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4028 - val_loss: 1.3448 - val_accuracy: 0.3892

Epoch 00264: val_loss did not improve from 1.34307
Epoch 265/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3921 - val_loss: 1.3447 - val_accuracy: 0.3907

Epoch 00265: val_loss did not improve from 1.34307
Epoch 266/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4003 - val_loss: 1.3435 - val_accuracy: 0.3931

Epoch 00266: val_loss did not improve from 1.34307
Epoch 267/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.4036 - val_loss: 1.3433 - val_accuracy: 0.3955

Epoch 00267: val_loss did not improve from 1.34307
Epoch 268/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4067 - val_loss: 1.3421 - val_accuracy: 0.3955

Epoch 00268: val_loss improved from 1.34307 to 1.34211, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 269/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4030 - val_loss: 1.3434 - val_accuracy: 0.3995

Epoch 00269: val_loss did not improve from 1.34211
Epoch 270/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3982 - val_loss: 1.3457 - val_accuracy: 0.3884

Epoch 00270: val_loss did not improve from 1.34211
Epoch 271/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.4011 - val_loss: 1.3423 - val_accuracy: 0.3971

Epoch 00271: val_loss did not improve from 1.34211
Epoch 272/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3991 - val_loss: 1.3445 - val_accuracy: 0.3804

Epoch 00272: val_loss did not improve from 1.34211
Epoch 273/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3956 - val_loss: 1.3436 - val_accuracy: 0.3923

Epoch 00273: val_loss did not improve from 1.34211
Epoch 274/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4027 - val_loss: 1.3443 - val_accuracy: 0.3923

Epoch 00274: val_loss did not improve from 1.34211
Epoch 275/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4037 - val_loss: 1.3412 - val_accuracy: 0.3947

Epoch 00275: val_loss improved from 1.34211 to 1.34119, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 276/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4044 - val_loss: 1.3430 - val_accuracy: 0.3939

Epoch 00276: val_loss did not improve from 1.34119
Epoch 277/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4031 - val_loss: 1.3426 - val_accuracy: 0.3995

Epoch 00277: val_loss did not improve from 1.34119
Epoch 278/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4038 - val_loss: 1.3436 - val_accuracy: 0.3868

Epoch 00278: val_loss did not improve from 1.34119
Epoch 279/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3937 - val_loss: 1.3415 - val_accuracy: 0.3868

Epoch 00279: val_loss did not improve from 1.34119
Epoch 280/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4055 - val_loss: 1.3429 - val_accuracy: 0.4027

Epoch 00280: val_loss did not improve from 1.34119
Epoch 281/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4029 - val_loss: 1.3422 - val_accuracy: 0.3939

Epoch 00281: val_loss did not improve from 1.34119
Epoch 282/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4055 - val_loss: 1.3414 - val_accuracy: 0.3987

Epoch 00282: val_loss did not improve from 1.34119
Epoch 283/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4055 - val_loss: 1.3450 - val_accuracy: 0.3860

Epoch 00283: val_loss did not improve from 1.34119
Epoch 284/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3964 - val_loss: 1.3438 - val_accuracy: 0.3947

Epoch 00284: val_loss did not improve from 1.34119
Epoch 285/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3918 - val_loss: 1.3469 - val_accuracy: 0.3884

Epoch 00285: val_loss did not improve from 1.34119
Epoch 286/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.4001 - val_loss: 1.3440 - val_accuracy: 0.3955

Epoch 00286: val_loss did not improve from 1.34119
Epoch 287/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4028 - val_loss: 1.3416 - val_accuracy: 0.3947

Epoch 00287: val_loss did not improve from 1.34119
Epoch 288/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4001 - val_loss: 1.3420 - val_accuracy: 0.3947

Epoch 00288: val_loss did not improve from 1.34119
Epoch 289/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4020 - val_loss: 1.3409 - val_accuracy: 0.3971

Epoch 00289: val_loss improved from 1.34119 to 1.34093, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 290/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4025 - val_loss: 1.3409 - val_accuracy: 0.4043

Epoch 00290: val_loss improved from 1.34093 to 1.34089, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 291/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4030 - val_loss: 1.3421 - val_accuracy: 0.3900

Epoch 00291: val_loss did not improve from 1.34089
Epoch 292/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4037 - val_loss: 1.3423 - val_accuracy: 0.4043

Epoch 00292: val_loss did not improve from 1.34089
Epoch 293/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4060 - val_loss: 1.3404 - val_accuracy: 0.3915

Epoch 00293: val_loss improved from 1.34089 to 1.34039, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 294/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4063 - val_loss: 1.3419 - val_accuracy: 0.3907

Epoch 00294: val_loss did not improve from 1.34039
Epoch 295/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4020 - val_loss: 1.3405 - val_accuracy: 0.3963

Epoch 00295: val_loss did not improve from 1.34039
Epoch 296/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4021 - val_loss: 1.3408 - val_accuracy: 0.3939

Epoch 00296: val_loss did not improve from 1.34039
Epoch 297/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4009 - val_loss: 1.3436 - val_accuracy: 0.3892

Epoch 00297: val_loss did not improve from 1.34039
Epoch 298/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3982 - val_loss: 1.3402 - val_accuracy: 0.3939

Epoch 00298: val_loss improved from 1.34039 to 1.34024, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 299/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.4011 - val_loss: 1.3402 - val_accuracy: 0.3939

Epoch 00299: val_loss improved from 1.34024 to 1.34019, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 300/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4039 - val_loss: 1.3395 - val_accuracy: 0.3923

Epoch 00300: val_loss improved from 1.34019 to 1.33947, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 301/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4025 - val_loss: 1.3409 - val_accuracy: 0.3955

Epoch 00301: val_loss did not improve from 1.33947
Epoch 302/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4036 - val_loss: 1.3420 - val_accuracy: 0.3987

Epoch 00302: val_loss did not improve from 1.33947
Epoch 303/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4025 - val_loss: 1.3406 - val_accuracy: 0.3923

Epoch 00303: val_loss did not improve from 1.33947
Epoch 304/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.4009 - val_loss: 1.3410 - val_accuracy: 0.3979

Epoch 00304: val_loss did not improve from 1.33947
Epoch 305/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4054 - val_loss: 1.3401 - val_accuracy: 0.3979

Epoch 00305: val_loss did not improve from 1.33947
Epoch 306/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4041 - val_loss: 1.3418 - val_accuracy: 0.3987

Epoch 00306: val_loss did not improve from 1.33947
Epoch 307/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4029 - val_loss: 1.3403 - val_accuracy: 0.3931

Epoch 00307: val_loss did not improve from 1.33947
Epoch 308/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4056 - val_loss: 1.3463 - val_accuracy: 0.3915

Epoch 00308: val_loss did not improve from 1.33947
Epoch 309/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3954 - val_loss: 1.3434 - val_accuracy: 0.3995

Epoch 00309: val_loss did not improve from 1.33947
Epoch 310/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.4053 - val_loss: 1.3404 - val_accuracy: 0.3955

Epoch 00310: val_loss did not improve from 1.33947
Epoch 311/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.4021 - val_loss: 1.3466 - val_accuracy: 0.3963

Epoch 00311: val_loss did not improve from 1.33947
Epoch 312/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3986 - val_loss: 1.3466 - val_accuracy: 0.3939

Epoch 00312: val_loss did not improve from 1.33947
Epoch 313/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3987 - val_loss: 1.3474 - val_accuracy: 0.3876

Epoch 00313: val_loss did not improve from 1.33947
Epoch 314/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4017 - val_loss: 1.3403 - val_accuracy: 0.3884

Epoch 00314: val_loss did not improve from 1.33947
Epoch 315/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4023 - val_loss: 1.3411 - val_accuracy: 0.3907

Epoch 00315: val_loss did not improve from 1.33947
Epoch 316/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4041 - val_loss: 1.3407 - val_accuracy: 0.3931

Epoch 00316: val_loss did not improve from 1.33947
Epoch 317/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4052 - val_loss: 1.3398 - val_accuracy: 0.3971

Epoch 00317: val_loss did not improve from 1.33947
Epoch 318/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4017 - val_loss: 1.3389 - val_accuracy: 0.3955

Epoch 00318: val_loss improved from 1.33947 to 1.33891, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 319/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3994 - val_loss: 1.3396 - val_accuracy: 0.3907

Epoch 00319: val_loss did not improve from 1.33891
Epoch 320/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3998 - val_loss: 1.3419 - val_accuracy: 0.3884

Epoch 00320: val_loss did not improve from 1.33891
Epoch 321/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.4008 - val_loss: 1.3484 - val_accuracy: 0.3860

Epoch 00321: val_loss did not improve from 1.33891
Epoch 322/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4026 - val_loss: 1.3444 - val_accuracy: 0.3892

Epoch 00322: val_loss did not improve from 1.33891
Epoch 323/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.4048 - val_loss: 1.3442 - val_accuracy: 0.3900

Epoch 00323: val_loss did not improve from 1.33891
Epoch 324/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4050 - val_loss: 1.3390 - val_accuracy: 0.3939

Epoch 00324: val_loss did not improve from 1.33891
Epoch 325/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4038 - val_loss: 1.3392 - val_accuracy: 0.3987

Epoch 00325: val_loss did not improve from 1.33891
Epoch 326/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4030 - val_loss: 1.3414 - val_accuracy: 0.3963

Epoch 00326: val_loss did not improve from 1.33891
Epoch 327/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4061 - val_loss: 1.3407 - val_accuracy: 0.3923

Epoch 00327: val_loss did not improve from 1.33891
Epoch 328/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4055 - val_loss: 1.3398 - val_accuracy: 0.3979

Epoch 00328: val_loss did not improve from 1.33891
Epoch 329/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4024 - val_loss: 1.3394 - val_accuracy: 0.3987

Epoch 00329: val_loss did not improve from 1.33891
Epoch 330/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4037 - val_loss: 1.3390 - val_accuracy: 0.3915

Epoch 00330: val_loss did not improve from 1.33891
Epoch 331/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.4011 - val_loss: 1.3452 - val_accuracy: 0.3923

Epoch 00331: val_loss did not improve from 1.33891
Epoch 332/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.4026 - val_loss: 1.3396 - val_accuracy: 0.3939

Epoch 00332: val_loss did not improve from 1.33891
Epoch 333/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4012 - val_loss: 1.3401 - val_accuracy: 0.3931

Epoch 00333: val_loss did not improve from 1.33891
Epoch 334/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4042 - val_loss: 1.3393 - val_accuracy: 0.3971

Epoch 00334: val_loss did not improve from 1.33891
Epoch 335/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.4055 - val_loss: 1.3389 - val_accuracy: 0.3963

Epoch 00335: val_loss did not improve from 1.33891
Epoch 336/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4012 - val_loss: 1.3413 - val_accuracy: 0.3907

Epoch 00336: val_loss did not improve from 1.33891
Epoch 337/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4023 - val_loss: 1.3388 - val_accuracy: 0.4003

Epoch 00337: val_loss improved from 1.33891 to 1.33883, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 338/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.4035 - val_loss: 1.3404 - val_accuracy: 0.3931

Epoch 00338: val_loss did not improve from 1.33883
Epoch 339/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4077 - val_loss: 1.3401 - val_accuracy: 0.3995

Epoch 00339: val_loss did not improve from 1.33883
Epoch 340/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.3985 - val_loss: 1.3411 - val_accuracy: 0.3907

Epoch 00340: val_loss did not improve from 1.33883
Epoch 341/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4066 - val_loss: 1.3426 - val_accuracy: 0.3971

Epoch 00341: val_loss did not improve from 1.33883
Epoch 342/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4063 - val_loss: 1.3388 - val_accuracy: 0.3955

Epoch 00342: val_loss improved from 1.33883 to 1.33882, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 343/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4049 - val_loss: 1.3384 - val_accuracy: 0.4059

Epoch 00343: val_loss improved from 1.33882 to 1.33843, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 344/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4042 - val_loss: 1.3414 - val_accuracy: 0.3987

Epoch 00344: val_loss did not improve from 1.33843
Epoch 345/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4044 - val_loss: 1.3401 - val_accuracy: 0.4003

Epoch 00345: val_loss did not improve from 1.33843
Epoch 346/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4018 - val_loss: 1.3377 - val_accuracy: 0.4019

Epoch 00346: val_loss improved from 1.33843 to 1.33768, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 347/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4010 - val_loss: 1.3393 - val_accuracy: 0.3955

Epoch 00347: val_loss did not improve from 1.33768
Epoch 348/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4008 - val_loss: 1.3382 - val_accuracy: 0.3971

Epoch 00348: val_loss did not improve from 1.33768
Epoch 349/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4048 - val_loss: 1.3381 - val_accuracy: 0.3971

Epoch 00349: val_loss did not improve from 1.33768
Epoch 350/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4062 - val_loss: 1.3377 - val_accuracy: 0.3907

Epoch 00350: val_loss did not improve from 1.33768
Epoch 351/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4063 - val_loss: 1.3386 - val_accuracy: 0.3947

Epoch 00351: val_loss did not improve from 1.33768
Epoch 352/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4067 - val_loss: 1.3400 - val_accuracy: 0.3955

Epoch 00352: val_loss did not improve from 1.33768
Epoch 353/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4038 - val_loss: 1.3382 - val_accuracy: 0.4035

Epoch 00353: val_loss did not improve from 1.33768
Epoch 354/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4031 - val_loss: 1.3389 - val_accuracy: 0.3955

Epoch 00354: val_loss did not improve from 1.33768
Epoch 355/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3994 - val_loss: 1.3509 - val_accuracy: 0.3844

Epoch 00355: val_loss did not improve from 1.33768
Epoch 356/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3994 - val_loss: 1.3394 - val_accuracy: 0.3900

Epoch 00356: val_loss did not improve from 1.33768
Epoch 357/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4015 - val_loss: 1.3383 - val_accuracy: 0.3971

Epoch 00357: val_loss did not improve from 1.33768
Epoch 358/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4025 - val_loss: 1.3393 - val_accuracy: 0.3947

Epoch 00358: val_loss did not improve from 1.33768
Epoch 359/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4030 - val_loss: 1.3393 - val_accuracy: 0.3995

Epoch 00359: val_loss did not improve from 1.33768
Epoch 360/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4084 - val_loss: 1.3407 - val_accuracy: 0.3955

Epoch 00360: val_loss did not improve from 1.33768
Epoch 361/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4048 - val_loss: 1.3390 - val_accuracy: 0.4043

Epoch 00361: val_loss did not improve from 1.33768
Epoch 362/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4042 - val_loss: 1.3382 - val_accuracy: 0.3979

Epoch 00362: val_loss did not improve from 1.33768
Epoch 363/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4055 - val_loss: 1.3382 - val_accuracy: 0.3963

Epoch 00363: val_loss did not improve from 1.33768
Epoch 364/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4026 - val_loss: 1.3390 - val_accuracy: 0.4027

Epoch 00364: val_loss did not improve from 1.33768
Epoch 365/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4039 - val_loss: 1.3390 - val_accuracy: 0.3987

Epoch 00365: val_loss did not improve from 1.33768
Epoch 366/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4055 - val_loss: 1.3376 - val_accuracy: 0.3939

Epoch 00366: val_loss improved from 1.33768 to 1.33761, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 367/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4061 - val_loss: 1.3385 - val_accuracy: 0.3955

Epoch 00367: val_loss did not improve from 1.33761
Epoch 368/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4074 - val_loss: 1.3388 - val_accuracy: 0.3979

Epoch 00368: val_loss did not improve from 1.33761
Epoch 369/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.4041 - val_loss: 1.3394 - val_accuracy: 0.3995

Epoch 00369: val_loss did not improve from 1.33761
Epoch 370/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4050 - val_loss: 1.3412 - val_accuracy: 0.3955

Epoch 00370: val_loss did not improve from 1.33761
Epoch 371/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.4024 - val_loss: 1.3404 - val_accuracy: 0.3892

Epoch 00371: val_loss did not improve from 1.33761
Epoch 372/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.4041 - val_loss: 1.3404 - val_accuracy: 0.3955

Epoch 00372: val_loss did not improve from 1.33761
Epoch 373/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4071 - val_loss: 1.3402 - val_accuracy: 0.4027

Epoch 00373: val_loss did not improve from 1.33761
Epoch 374/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4070 - val_loss: 1.3383 - val_accuracy: 0.3987

Epoch 00374: val_loss did not improve from 1.33761
Epoch 375/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4037 - val_loss: 1.3363 - val_accuracy: 0.3987

Epoch 00375: val_loss improved from 1.33761 to 1.33633, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 376/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4062 - val_loss: 1.3430 - val_accuracy: 0.4091

Epoch 00376: val_loss did not improve from 1.33633
Epoch 377/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4045 - val_loss: 1.3423 - val_accuracy: 0.4003

Epoch 00377: val_loss did not improve from 1.33633
Epoch 378/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.4040 - val_loss: 1.3378 - val_accuracy: 0.3923

Epoch 00378: val_loss did not improve from 1.33633
Epoch 379/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4036 - val_loss: 1.3373 - val_accuracy: 0.4003

Epoch 00379: val_loss did not improve from 1.33633
Epoch 380/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4024 - val_loss: 1.3384 - val_accuracy: 0.3955

Epoch 00380: val_loss did not improve from 1.33633
Epoch 381/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4022 - val_loss: 1.3369 - val_accuracy: 0.3971

Epoch 00381: val_loss did not improve from 1.33633
Epoch 382/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4078 - val_loss: 1.3391 - val_accuracy: 0.3971

Epoch 00382: val_loss did not improve from 1.33633
Epoch 383/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4064 - val_loss: 1.3375 - val_accuracy: 0.3995

Epoch 00383: val_loss did not improve from 1.33633
Epoch 384/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4053 - val_loss: 1.3387 - val_accuracy: 0.3979

Epoch 00384: val_loss did not improve from 1.33633
Epoch 385/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4053 - val_loss: 1.3368 - val_accuracy: 0.3995

Epoch 00385: val_loss did not improve from 1.33633
Epoch 386/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4059 - val_loss: 1.3365 - val_accuracy: 0.3947

Epoch 00386: val_loss did not improve from 1.33633
Epoch 387/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4061 - val_loss: 1.3383 - val_accuracy: 0.3923

Epoch 00387: val_loss did not improve from 1.33633
Epoch 388/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4079 - val_loss: 1.3392 - val_accuracy: 0.3955

Epoch 00388: val_loss did not improve from 1.33633
Epoch 389/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.4066 - val_loss: 1.3420 - val_accuracy: 0.3971

Epoch 00389: val_loss did not improve from 1.33633
Epoch 390/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.4044 - val_loss: 1.3427 - val_accuracy: 0.3947

Epoch 00390: val_loss did not improve from 1.33633
Epoch 391/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4038 - val_loss: 1.3371 - val_accuracy: 0.3963

Epoch 00391: val_loss did not improve from 1.33633
Epoch 392/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4001 - val_loss: 1.3443 - val_accuracy: 0.3868

Epoch 00392: val_loss did not improve from 1.33633
Epoch 393/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4021 - val_loss: 1.3474 - val_accuracy: 0.3892

Epoch 00393: val_loss did not improve from 1.33633
Epoch 394/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.4012 - val_loss: 1.3371 - val_accuracy: 0.3931

Epoch 00394: val_loss did not improve from 1.33633
Epoch 395/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4040 - val_loss: 1.3368 - val_accuracy: 0.3987

Epoch 00395: val_loss did not improve from 1.33633
Epoch 396/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4039 - val_loss: 1.3389 - val_accuracy: 0.4003

Epoch 00396: val_loss did not improve from 1.33633
Epoch 397/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4045 - val_loss: 1.3375 - val_accuracy: 0.3900

Epoch 00397: val_loss did not improve from 1.33633
Epoch 398/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4063 - val_loss: 1.3357 - val_accuracy: 0.3939

Epoch 00398: val_loss improved from 1.33633 to 1.33574, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 399/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4034 - val_loss: 1.3386 - val_accuracy: 0.3939

Epoch 00399: val_loss did not improve from 1.33574
Epoch 400/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4017 - val_loss: 1.3374 - val_accuracy: 0.4003

Epoch 00400: val_loss did not improve from 1.33574
Epoch 401/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4016 - val_loss: 1.3357 - val_accuracy: 0.3995

Epoch 00401: val_loss improved from 1.33574 to 1.33570, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 402/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4057 - val_loss: 1.3386 - val_accuracy: 0.3923

Epoch 00402: val_loss did not improve from 1.33570
Epoch 403/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4016 - val_loss: 1.3358 - val_accuracy: 0.3979

Epoch 00403: val_loss did not improve from 1.33570
Epoch 404/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4060 - val_loss: 1.3389 - val_accuracy: 0.3963

Epoch 00404: val_loss did not improve from 1.33570
Epoch 405/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4098 - val_loss: 1.3373 - val_accuracy: 0.3987

Epoch 00405: val_loss did not improve from 1.33570
Epoch 406/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4052 - val_loss: 1.3354 - val_accuracy: 0.4035

Epoch 00406: val_loss improved from 1.33570 to 1.33544, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 407/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4049 - val_loss: 1.3356 - val_accuracy: 0.3923

Epoch 00407: val_loss did not improve from 1.33544
Epoch 408/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4024 - val_loss: 1.3378 - val_accuracy: 0.3931

Epoch 00408: val_loss did not improve from 1.33544
Epoch 409/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4053 - val_loss: 1.3372 - val_accuracy: 0.3939

Epoch 00409: val_loss did not improve from 1.33544
Epoch 410/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4056 - val_loss: 1.3385 - val_accuracy: 0.4043

Epoch 00410: val_loss did not improve from 1.33544
Epoch 411/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4038 - val_loss: 1.3346 - val_accuracy: 0.4035

Epoch 00411: val_loss improved from 1.33544 to 1.33456, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 412/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4079 - val_loss: 1.3353 - val_accuracy: 0.3995

Epoch 00412: val_loss did not improve from 1.33456
Epoch 413/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4084 - val_loss: 1.3356 - val_accuracy: 0.4075

Epoch 00413: val_loss did not improve from 1.33456
Epoch 414/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4043 - val_loss: 1.3357 - val_accuracy: 0.3971

Epoch 00414: val_loss did not improve from 1.33456
Epoch 415/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4030 - val_loss: 1.3380 - val_accuracy: 0.3987

Epoch 00415: val_loss did not improve from 1.33456
Epoch 416/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.4040 - val_loss: 1.3355 - val_accuracy: 0.3963

Epoch 00416: val_loss did not improve from 1.33456
Epoch 417/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4075 - val_loss: 1.3355 - val_accuracy: 0.4011

Epoch 00417: val_loss did not improve from 1.33456
Epoch 418/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4052 - val_loss: 1.3375 - val_accuracy: 0.3820

Epoch 00418: val_loss did not improve from 1.33456
Epoch 419/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4062 - val_loss: 1.3407 - val_accuracy: 0.3979

Epoch 00419: val_loss did not improve from 1.33456
Epoch 420/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4057 - val_loss: 1.3342 - val_accuracy: 0.3923

Epoch 00420: val_loss improved from 1.33456 to 1.33417, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 421/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4007 - val_loss: 1.3354 - val_accuracy: 0.3844

Epoch 00421: val_loss did not improve from 1.33417
Epoch 422/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4042 - val_loss: 1.3391 - val_accuracy: 0.3892

Epoch 00422: val_loss did not improve from 1.33417
Epoch 423/10000
12/12 - 0s - loss: 1.3063 - accuracy: 0.3994 - val_loss: 1.3370 - val_accuracy: 0.3995

Epoch 00423: val_loss did not improve from 1.33417
Epoch 424/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4053 - val_loss: 1.3395 - val_accuracy: 0.4027

Epoch 00424: val_loss did not improve from 1.33417
Epoch 425/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4030 - val_loss: 1.3331 - val_accuracy: 0.4035

Epoch 00425: val_loss improved from 1.33417 to 1.33309, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 426/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4048 - val_loss: 1.3325 - val_accuracy: 0.3963

Epoch 00426: val_loss improved from 1.33309 to 1.33250, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 427/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4032 - val_loss: 1.3355 - val_accuracy: 0.3892

Epoch 00427: val_loss did not improve from 1.33250
Epoch 428/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.4045 - val_loss: 1.3368 - val_accuracy: 0.3931

Epoch 00428: val_loss did not improve from 1.33250
Epoch 429/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4024 - val_loss: 1.3364 - val_accuracy: 0.4011

Epoch 00429: val_loss did not improve from 1.33250
Epoch 430/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4026 - val_loss: 1.3366 - val_accuracy: 0.3987

Epoch 00430: val_loss did not improve from 1.33250
Epoch 431/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4058 - val_loss: 1.3334 - val_accuracy: 0.3971

Epoch 00431: val_loss did not improve from 1.33250
Epoch 432/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4068 - val_loss: 1.3361 - val_accuracy: 0.4011

Epoch 00432: val_loss did not improve from 1.33250
Epoch 433/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4030 - val_loss: 1.3327 - val_accuracy: 0.3907

Epoch 00433: val_loss did not improve from 1.33250
Epoch 434/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4060 - val_loss: 1.3342 - val_accuracy: 0.3963

Epoch 00434: val_loss did not improve from 1.33250
Epoch 435/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4074 - val_loss: 1.3330 - val_accuracy: 0.3939

Epoch 00435: val_loss did not improve from 1.33250
Epoch 436/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4055 - val_loss: 1.3375 - val_accuracy: 0.3915

Epoch 00436: val_loss did not improve from 1.33250
Epoch 437/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4022 - val_loss: 1.3337 - val_accuracy: 0.3963

Epoch 00437: val_loss did not improve from 1.33250
Epoch 438/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4091 - val_loss: 1.3322 - val_accuracy: 0.3955

Epoch 00438: val_loss improved from 1.33250 to 1.33217, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 439/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4088 - val_loss: 1.3341 - val_accuracy: 0.4011

Epoch 00439: val_loss did not improve from 1.33217
Epoch 440/10000
12/12 - 0s - loss: 1.3041 - accuracy: 0.4032 - val_loss: 1.3355 - val_accuracy: 0.3987

Epoch 00440: val_loss did not improve from 1.33217
Epoch 441/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4029 - val_loss: 1.3351 - val_accuracy: 0.4019

Epoch 00441: val_loss did not improve from 1.33217
Epoch 442/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4030 - val_loss: 1.3327 - val_accuracy: 0.3963

Epoch 00442: val_loss did not improve from 1.33217
Epoch 443/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4051 - val_loss: 1.3331 - val_accuracy: 0.3939

Epoch 00443: val_loss did not improve from 1.33217
Epoch 444/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.4098 - val_loss: 1.3352 - val_accuracy: 0.4027

Epoch 00444: val_loss did not improve from 1.33217
Epoch 445/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4076 - val_loss: 1.3343 - val_accuracy: 0.4051

Epoch 00445: val_loss did not improve from 1.33217
Epoch 446/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4039 - val_loss: 1.3337 - val_accuracy: 0.4003

Epoch 00446: val_loss did not improve from 1.33217
Epoch 447/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4030 - val_loss: 1.3352 - val_accuracy: 0.3955

Epoch 00447: val_loss did not improve from 1.33217
Epoch 448/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4036 - val_loss: 1.3336 - val_accuracy: 0.3955

Epoch 00448: val_loss did not improve from 1.33217
Epoch 449/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4055 - val_loss: 1.3376 - val_accuracy: 0.3907

Epoch 00449: val_loss did not improve from 1.33217
Epoch 450/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4047 - val_loss: 1.3340 - val_accuracy: 0.3931

Epoch 00450: val_loss did not improve from 1.33217
Epoch 451/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4050 - val_loss: 1.3341 - val_accuracy: 0.3963

Epoch 00451: val_loss did not improve from 1.33217
Epoch 452/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4077 - val_loss: 1.3333 - val_accuracy: 0.4067

Epoch 00452: val_loss did not improve from 1.33217
Epoch 453/10000
12/12 - 0s - loss: 1.3034 - accuracy: 0.4093 - val_loss: 1.3339 - val_accuracy: 0.3987

Epoch 00453: val_loss did not improve from 1.33217
Epoch 454/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4094 - val_loss: 1.3354 - val_accuracy: 0.4043

Epoch 00454: val_loss did not improve from 1.33217
Epoch 455/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4049 - val_loss: 1.3379 - val_accuracy: 0.3939

Epoch 00455: val_loss did not improve from 1.33217
Epoch 456/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.3997 - val_loss: 1.3351 - val_accuracy: 0.3947

Epoch 00456: val_loss did not improve from 1.33217
Epoch 457/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4051 - val_loss: 1.3361 - val_accuracy: 0.3995

Epoch 00457: val_loss did not improve from 1.33217
Epoch 458/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4078 - val_loss: 1.3351 - val_accuracy: 0.3979

Epoch 00458: val_loss did not improve from 1.33217
Epoch 459/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4090 - val_loss: 1.3377 - val_accuracy: 0.3915

Epoch 00459: val_loss did not improve from 1.33217
Epoch 460/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4102 - val_loss: 1.3340 - val_accuracy: 0.3979

Epoch 00460: val_loss did not improve from 1.33217
Epoch 461/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4078 - val_loss: 1.3347 - val_accuracy: 0.3995

Epoch 00461: val_loss did not improve from 1.33217
Epoch 462/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4065 - val_loss: 1.3349 - val_accuracy: 0.3947

Epoch 00462: val_loss did not improve from 1.33217
Epoch 463/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4088 - val_loss: 1.3357 - val_accuracy: 0.3900

Epoch 00463: val_loss did not improve from 1.33217
Epoch 464/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4079 - val_loss: 1.3345 - val_accuracy: 0.3923

Epoch 00464: val_loss did not improve from 1.33217
Epoch 465/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4069 - val_loss: 1.3329 - val_accuracy: 0.3995

Epoch 00465: val_loss did not improve from 1.33217
Epoch 466/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4057 - val_loss: 1.3351 - val_accuracy: 0.3987

Epoch 00466: val_loss did not improve from 1.33217
Epoch 467/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4036 - val_loss: 1.3326 - val_accuracy: 0.3987

Epoch 00467: val_loss did not improve from 1.33217
Epoch 468/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4033 - val_loss: 1.3339 - val_accuracy: 0.3923

Epoch 00468: val_loss did not improve from 1.33217
Epoch 469/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4056 - val_loss: 1.3342 - val_accuracy: 0.3995

Epoch 00469: val_loss did not improve from 1.33217
Epoch 470/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4101 - val_loss: 1.3327 - val_accuracy: 0.4003

Epoch 00470: val_loss did not improve from 1.33217
Epoch 471/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4048 - val_loss: 1.3345 - val_accuracy: 0.4051

Epoch 00471: val_loss did not improve from 1.33217
Epoch 472/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4065 - val_loss: 1.3322 - val_accuracy: 0.4051

Epoch 00472: val_loss did not improve from 1.33217
Epoch 473/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4031 - val_loss: 1.3349 - val_accuracy: 0.3947

Epoch 00473: val_loss did not improve from 1.33217
Epoch 474/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4037 - val_loss: 1.3321 - val_accuracy: 0.4027

Epoch 00474: val_loss improved from 1.33217 to 1.33213, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 475/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.4078 - val_loss: 1.3320 - val_accuracy: 0.4067

Epoch 00475: val_loss improved from 1.33213 to 1.33203, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 476/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4049 - val_loss: 1.3357 - val_accuracy: 0.3884

Epoch 00476: val_loss did not improve from 1.33203
Epoch 477/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4047 - val_loss: 1.3332 - val_accuracy: 0.3939

Epoch 00477: val_loss did not improve from 1.33203
Epoch 478/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4074 - val_loss: 1.3329 - val_accuracy: 0.4003

Epoch 00478: val_loss did not improve from 1.33203
Epoch 479/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4072 - val_loss: 1.3323 - val_accuracy: 0.3963

Epoch 00479: val_loss did not improve from 1.33203
Epoch 480/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4087 - val_loss: 1.3327 - val_accuracy: 0.3963

Epoch 00480: val_loss did not improve from 1.33203
Epoch 481/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4027 - val_loss: 1.3345 - val_accuracy: 0.3995

Epoch 00481: val_loss did not improve from 1.33203
Epoch 482/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4039 - val_loss: 1.3336 - val_accuracy: 0.3987

Epoch 00482: val_loss did not improve from 1.33203
Epoch 483/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4057 - val_loss: 1.3314 - val_accuracy: 0.3987

Epoch 00483: val_loss improved from 1.33203 to 1.33137, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 484/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4080 - val_loss: 1.3347 - val_accuracy: 0.3955

Epoch 00484: val_loss did not improve from 1.33137
Epoch 485/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4069 - val_loss: 1.3321 - val_accuracy: 0.3995

Epoch 00485: val_loss did not improve from 1.33137
Epoch 486/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4106 - val_loss: 1.3337 - val_accuracy: 0.3963

Epoch 00486: val_loss did not improve from 1.33137
Epoch 487/10000
12/12 - 0s - loss: 1.3031 - accuracy: 0.4034 - val_loss: 1.3315 - val_accuracy: 0.4011

Epoch 00487: val_loss did not improve from 1.33137
Epoch 488/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4069 - val_loss: 1.3317 - val_accuracy: 0.4011

Epoch 00488: val_loss did not improve from 1.33137
Epoch 489/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4079 - val_loss: 1.3341 - val_accuracy: 0.4011

Epoch 00489: val_loss did not improve from 1.33137
Epoch 490/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4050 - val_loss: 1.3303 - val_accuracy: 0.4019

Epoch 00490: val_loss improved from 1.33137 to 1.33034, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 491/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4056 - val_loss: 1.3346 - val_accuracy: 0.4011

Epoch 00491: val_loss did not improve from 1.33034
Epoch 492/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4064 - val_loss: 1.3307 - val_accuracy: 0.3971

Epoch 00492: val_loss did not improve from 1.33034
Epoch 493/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4036 - val_loss: 1.3313 - val_accuracy: 0.3955

Epoch 00493: val_loss did not improve from 1.33034
Epoch 494/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4100 - val_loss: 1.3351 - val_accuracy: 0.3995

Epoch 00494: val_loss did not improve from 1.33034
Epoch 495/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4083 - val_loss: 1.3311 - val_accuracy: 0.3995

Epoch 00495: val_loss did not improve from 1.33034
Epoch 496/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4119 - val_loss: 1.3348 - val_accuracy: 0.4019

Epoch 00496: val_loss did not improve from 1.33034
Epoch 497/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4074 - val_loss: 1.3342 - val_accuracy: 0.3939

Epoch 00497: val_loss did not improve from 1.33034
Epoch 498/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.4096 - val_loss: 1.3347 - val_accuracy: 0.4019

Epoch 00498: val_loss did not improve from 1.33034
Epoch 499/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4100 - val_loss: 1.3352 - val_accuracy: 0.3995

Epoch 00499: val_loss did not improve from 1.33034
Epoch 500/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4042 - val_loss: 1.3308 - val_accuracy: 0.3971

Epoch 00500: val_loss did not improve from 1.33034
Epoch 501/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4110 - val_loss: 1.3304 - val_accuracy: 0.3995

Epoch 00501: val_loss did not improve from 1.33034
Epoch 502/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4078 - val_loss: 1.3367 - val_accuracy: 0.3987

Epoch 00502: val_loss did not improve from 1.33034
Epoch 503/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4046 - val_loss: 1.3304 - val_accuracy: 0.4003

Epoch 00503: val_loss did not improve from 1.33034
Epoch 504/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4046 - val_loss: 1.3301 - val_accuracy: 0.3947

Epoch 00504: val_loss improved from 1.33034 to 1.33008, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 505/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.4079 - val_loss: 1.3369 - val_accuracy: 0.4019

Epoch 00505: val_loss did not improve from 1.33008
Epoch 506/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4069 - val_loss: 1.3328 - val_accuracy: 0.3931

Epoch 00506: val_loss did not improve from 1.33008
Epoch 507/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4097 - val_loss: 1.3313 - val_accuracy: 0.4011

Epoch 00507: val_loss did not improve from 1.33008
Epoch 508/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4104 - val_loss: 1.3302 - val_accuracy: 0.3963

Epoch 00508: val_loss did not improve from 1.33008
Epoch 509/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4064 - val_loss: 1.3317 - val_accuracy: 0.3995

Epoch 00509: val_loss did not improve from 1.33008
Epoch 510/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4104 - val_loss: 1.3308 - val_accuracy: 0.4051

Epoch 00510: val_loss did not improve from 1.33008
Epoch 511/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4111 - val_loss: 1.3367 - val_accuracy: 0.4019

Epoch 00511: val_loss did not improve from 1.33008
Epoch 512/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4058 - val_loss: 1.3302 - val_accuracy: 0.3955

Epoch 00512: val_loss did not improve from 1.33008
Epoch 513/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4104 - val_loss: 1.3347 - val_accuracy: 0.4003

Epoch 00513: val_loss did not improve from 1.33008
Epoch 514/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4043 - val_loss: 1.3317 - val_accuracy: 0.3979

Epoch 00514: val_loss did not improve from 1.33008
Epoch 515/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4076 - val_loss: 1.3319 - val_accuracy: 0.3963

Epoch 00515: val_loss did not improve from 1.33008
Epoch 516/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4093 - val_loss: 1.3297 - val_accuracy: 0.3939

Epoch 00516: val_loss improved from 1.33008 to 1.32965, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 517/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4104 - val_loss: 1.3324 - val_accuracy: 0.4011

Epoch 00517: val_loss did not improve from 1.32965
Epoch 518/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4060 - val_loss: 1.3299 - val_accuracy: 0.3915

Epoch 00518: val_loss did not improve from 1.32965
Epoch 519/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4041 - val_loss: 1.3313 - val_accuracy: 0.4011

Epoch 00519: val_loss did not improve from 1.32965
Epoch 520/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4074 - val_loss: 1.3307 - val_accuracy: 0.3987

Epoch 00520: val_loss did not improve from 1.32965
Epoch 521/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4115 - val_loss: 1.3292 - val_accuracy: 0.4003

Epoch 00521: val_loss improved from 1.32965 to 1.32917, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 522/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4111 - val_loss: 1.3307 - val_accuracy: 0.4019

Epoch 00522: val_loss did not improve from 1.32917
Epoch 523/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4148 - val_loss: 1.3302 - val_accuracy: 0.4011

Epoch 00523: val_loss did not improve from 1.32917
Epoch 524/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4092 - val_loss: 1.3342 - val_accuracy: 0.3971

Epoch 00524: val_loss did not improve from 1.32917
Epoch 525/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4051 - val_loss: 1.3313 - val_accuracy: 0.3963

Epoch 00525: val_loss did not improve from 1.32917
Epoch 526/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4055 - val_loss: 1.3287 - val_accuracy: 0.3955

Epoch 00526: val_loss improved from 1.32917 to 1.32875, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 527/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4088 - val_loss: 1.3316 - val_accuracy: 0.4043

Epoch 00527: val_loss did not improve from 1.32875
Epoch 528/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4063 - val_loss: 1.3299 - val_accuracy: 0.3995

Epoch 00528: val_loss did not improve from 1.32875
Epoch 529/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4083 - val_loss: 1.3290 - val_accuracy: 0.4067

Epoch 00529: val_loss did not improve from 1.32875
Epoch 530/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4055 - val_loss: 1.3294 - val_accuracy: 0.4027

Epoch 00530: val_loss did not improve from 1.32875
Epoch 531/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4094 - val_loss: 1.3283 - val_accuracy: 0.3955

Epoch 00531: val_loss improved from 1.32875 to 1.32834, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 532/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4070 - val_loss: 1.3316 - val_accuracy: 0.3995

Epoch 00532: val_loss did not improve from 1.32834
Epoch 533/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4098 - val_loss: 1.3309 - val_accuracy: 0.4003

Epoch 00533: val_loss did not improve from 1.32834
Epoch 534/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4079 - val_loss: 1.3294 - val_accuracy: 0.3971

Epoch 00534: val_loss did not improve from 1.32834
Epoch 535/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4106 - val_loss: 1.3284 - val_accuracy: 0.4011

Epoch 00535: val_loss did not improve from 1.32834
Epoch 536/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4092 - val_loss: 1.3288 - val_accuracy: 0.3987

Epoch 00536: val_loss did not improve from 1.32834
Epoch 537/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4079 - val_loss: 1.3286 - val_accuracy: 0.3939

Epoch 00537: val_loss did not improve from 1.32834
Epoch 538/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4122 - val_loss: 1.3274 - val_accuracy: 0.4027

Epoch 00538: val_loss improved from 1.32834 to 1.32735, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 539/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4114 - val_loss: 1.3280 - val_accuracy: 0.4011

Epoch 00539: val_loss did not improve from 1.32735
Epoch 540/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4078 - val_loss: 1.3317 - val_accuracy: 0.3979

Epoch 00540: val_loss did not improve from 1.32735
Epoch 541/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4106 - val_loss: 1.3288 - val_accuracy: 0.4011

Epoch 00541: val_loss did not improve from 1.32735
Epoch 542/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4099 - val_loss: 1.3301 - val_accuracy: 0.4075

Epoch 00542: val_loss did not improve from 1.32735
Epoch 543/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4123 - val_loss: 1.3290 - val_accuracy: 0.4019

Epoch 00543: val_loss did not improve from 1.32735
Epoch 544/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4126 - val_loss: 1.3296 - val_accuracy: 0.4003

Epoch 00544: val_loss did not improve from 1.32735
Epoch 545/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4057 - val_loss: 1.3289 - val_accuracy: 0.4059

Epoch 00545: val_loss did not improve from 1.32735
Epoch 546/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4087 - val_loss: 1.3281 - val_accuracy: 0.4003

Epoch 00546: val_loss did not improve from 1.32735
Epoch 547/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4084 - val_loss: 1.3283 - val_accuracy: 0.4035

Epoch 00547: val_loss did not improve from 1.32735
Epoch 548/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4080 - val_loss: 1.3364 - val_accuracy: 0.4011

Epoch 00548: val_loss did not improve from 1.32735
Epoch 549/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4098 - val_loss: 1.3328 - val_accuracy: 0.3884

Epoch 00549: val_loss did not improve from 1.32735
Epoch 550/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4094 - val_loss: 1.3274 - val_accuracy: 0.4027

Epoch 00550: val_loss did not improve from 1.32735
Epoch 551/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4109 - val_loss: 1.3330 - val_accuracy: 0.3971

Epoch 00551: val_loss did not improve from 1.32735
Epoch 552/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4098 - val_loss: 1.3284 - val_accuracy: 0.3947

Epoch 00552: val_loss did not improve from 1.32735
Epoch 553/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4076 - val_loss: 1.3280 - val_accuracy: 0.3939

Epoch 00553: val_loss did not improve from 1.32735
Epoch 554/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4132 - val_loss: 1.3337 - val_accuracy: 0.3955

Epoch 00554: val_loss did not improve from 1.32735
Epoch 555/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4047 - val_loss: 1.3295 - val_accuracy: 0.3979

Epoch 00555: val_loss did not improve from 1.32735
Epoch 556/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4078 - val_loss: 1.3292 - val_accuracy: 0.4011

Epoch 00556: val_loss did not improve from 1.32735
Epoch 557/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4099 - val_loss: 1.3283 - val_accuracy: 0.4075

Epoch 00557: val_loss did not improve from 1.32735
Epoch 558/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4126 - val_loss: 1.3278 - val_accuracy: 0.4027

Epoch 00558: val_loss did not improve from 1.32735
Epoch 559/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4123 - val_loss: 1.3306 - val_accuracy: 0.4019

Epoch 00559: val_loss did not improve from 1.32735
Epoch 560/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4092 - val_loss: 1.3303 - val_accuracy: 0.3987

Epoch 00560: val_loss did not improve from 1.32735
Epoch 561/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4082 - val_loss: 1.3300 - val_accuracy: 0.4035

Epoch 00561: val_loss did not improve from 1.32735
Epoch 562/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4069 - val_loss: 1.3289 - val_accuracy: 0.3963

Epoch 00562: val_loss did not improve from 1.32735
Epoch 563/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4101 - val_loss: 1.3288 - val_accuracy: 0.4003

Epoch 00563: val_loss did not improve from 1.32735
Epoch 564/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4089 - val_loss: 1.3309 - val_accuracy: 0.4067

Epoch 00564: val_loss did not improve from 1.32735
Epoch 565/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4070 - val_loss: 1.3284 - val_accuracy: 0.3971

Epoch 00565: val_loss did not improve from 1.32735
Epoch 566/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4045 - val_loss: 1.3300 - val_accuracy: 0.3995

Epoch 00566: val_loss did not improve from 1.32735
Epoch 567/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4073 - val_loss: 1.3331 - val_accuracy: 0.3923

Epoch 00567: val_loss did not improve from 1.32735
Epoch 568/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4087 - val_loss: 1.3263 - val_accuracy: 0.3995

Epoch 00568: val_loss improved from 1.32735 to 1.32632, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 569/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4103 - val_loss: 1.3274 - val_accuracy: 0.3995

Epoch 00569: val_loss did not improve from 1.32632
Epoch 570/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4077 - val_loss: 1.3313 - val_accuracy: 0.3963

Epoch 00570: val_loss did not improve from 1.32632
Epoch 571/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4081 - val_loss: 1.3263 - val_accuracy: 0.4011

Epoch 00571: val_loss improved from 1.32632 to 1.32628, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 572/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4103 - val_loss: 1.3255 - val_accuracy: 0.4035

Epoch 00572: val_loss improved from 1.32628 to 1.32555, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 573/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4109 - val_loss: 1.3275 - val_accuracy: 0.3971

Epoch 00573: val_loss did not improve from 1.32555
Epoch 574/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4095 - val_loss: 1.3292 - val_accuracy: 0.4011

Epoch 00574: val_loss did not improve from 1.32555
Epoch 575/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4109 - val_loss: 1.3311 - val_accuracy: 0.4003

Epoch 00575: val_loss did not improve from 1.32555
Epoch 576/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4068 - val_loss: 1.3285 - val_accuracy: 0.3971

Epoch 00576: val_loss did not improve from 1.32555
Epoch 577/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4110 - val_loss: 1.3316 - val_accuracy: 0.4051

Epoch 00577: val_loss did not improve from 1.32555
Epoch 578/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4086 - val_loss: 1.3296 - val_accuracy: 0.3979

Epoch 00578: val_loss did not improve from 1.32555
Epoch 579/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4090 - val_loss: 1.3303 - val_accuracy: 0.3923

Epoch 00579: val_loss did not improve from 1.32555
Epoch 580/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4081 - val_loss: 1.3284 - val_accuracy: 0.3971

Epoch 00580: val_loss did not improve from 1.32555
Epoch 581/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4068 - val_loss: 1.3320 - val_accuracy: 0.4035

Epoch 00581: val_loss did not improve from 1.32555
Epoch 582/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4070 - val_loss: 1.3255 - val_accuracy: 0.3955

Epoch 00582: val_loss improved from 1.32555 to 1.32546, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 583/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4100 - val_loss: 1.3285 - val_accuracy: 0.4051

Epoch 00583: val_loss did not improve from 1.32546
Epoch 584/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4119 - val_loss: 1.3284 - val_accuracy: 0.4099

Epoch 00584: val_loss did not improve from 1.32546
Epoch 585/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4092 - val_loss: 1.3272 - val_accuracy: 0.4011

Epoch 00585: val_loss did not improve from 1.32546
Epoch 586/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4119 - val_loss: 1.3291 - val_accuracy: 0.4059

Epoch 00586: val_loss did not improve from 1.32546
Epoch 587/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4125 - val_loss: 1.3256 - val_accuracy: 0.4027

Epoch 00587: val_loss did not improve from 1.32546
Epoch 588/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4071 - val_loss: 1.3282 - val_accuracy: 0.3955

Epoch 00588: val_loss did not improve from 1.32546
Epoch 589/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4099 - val_loss: 1.3262 - val_accuracy: 0.4083

Epoch 00589: val_loss did not improve from 1.32546
Epoch 590/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4116 - val_loss: 1.3270 - val_accuracy: 0.4051

Epoch 00590: val_loss did not improve from 1.32546
Epoch 591/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4094 - val_loss: 1.3270 - val_accuracy: 0.3987

Epoch 00591: val_loss did not improve from 1.32546
Epoch 592/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4094 - val_loss: 1.3249 - val_accuracy: 0.4011

Epoch 00592: val_loss improved from 1.32546 to 1.32492, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 593/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4126 - val_loss: 1.3251 - val_accuracy: 0.4003

Epoch 00593: val_loss did not improve from 1.32492
Epoch 594/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4113 - val_loss: 1.3283 - val_accuracy: 0.3979

Epoch 00594: val_loss did not improve from 1.32492
Epoch 595/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4096 - val_loss: 1.3290 - val_accuracy: 0.4019

Epoch 00595: val_loss did not improve from 1.32492
Epoch 596/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4094 - val_loss: 1.3267 - val_accuracy: 0.3995

Epoch 00596: val_loss did not improve from 1.32492
Epoch 597/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4106 - val_loss: 1.3273 - val_accuracy: 0.3987

Epoch 00597: val_loss did not improve from 1.32492
Epoch 598/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4072 - val_loss: 1.3274 - val_accuracy: 0.3939

Epoch 00598: val_loss did not improve from 1.32492
Epoch 599/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4115 - val_loss: 1.3323 - val_accuracy: 0.4051

Epoch 00599: val_loss did not improve from 1.32492
Epoch 600/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4089 - val_loss: 1.3262 - val_accuracy: 0.4019

Epoch 00600: val_loss did not improve from 1.32492
Epoch 601/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4087 - val_loss: 1.3264 - val_accuracy: 0.4043

Epoch 00601: val_loss did not improve from 1.32492
Epoch 602/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4129 - val_loss: 1.3307 - val_accuracy: 0.4027

Epoch 00602: val_loss did not improve from 1.32492
Epoch 603/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4096 - val_loss: 1.3260 - val_accuracy: 0.4035

Epoch 00603: val_loss did not improve from 1.32492
Epoch 604/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4110 - val_loss: 1.3270 - val_accuracy: 0.4019

Epoch 00604: val_loss did not improve from 1.32492
Epoch 605/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4096 - val_loss: 1.3266 - val_accuracy: 0.4019

Epoch 00605: val_loss did not improve from 1.32492
Epoch 606/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4120 - val_loss: 1.3251 - val_accuracy: 0.4011

Epoch 00606: val_loss did not improve from 1.32492
Epoch 607/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4072 - val_loss: 1.3322 - val_accuracy: 0.3947

Epoch 00607: val_loss did not improve from 1.32492
Epoch 608/10000
12/12 - 0s - loss: 1.2980 - accuracy: 0.4094 - val_loss: 1.3279 - val_accuracy: 0.3971

Epoch 00608: val_loss did not improve from 1.32492
Epoch 609/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4104 - val_loss: 1.3284 - val_accuracy: 0.4011

Epoch 00609: val_loss did not improve from 1.32492
Epoch 610/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4114 - val_loss: 1.3267 - val_accuracy: 0.4027

Epoch 00610: val_loss did not improve from 1.32492
Epoch 611/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4106 - val_loss: 1.3270 - val_accuracy: 0.3971

Epoch 00611: val_loss did not improve from 1.32492
Epoch 612/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4128 - val_loss: 1.3285 - val_accuracy: 0.4035

Epoch 00612: val_loss did not improve from 1.32492
Epoch 613/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4111 - val_loss: 1.3270 - val_accuracy: 0.4083

Epoch 00613: val_loss did not improve from 1.32492
Epoch 614/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4120 - val_loss: 1.3265 - val_accuracy: 0.4051

Epoch 00614: val_loss did not improve from 1.32492
Epoch 615/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4108 - val_loss: 1.3255 - val_accuracy: 0.4003

Epoch 00615: val_loss did not improve from 1.32492
Epoch 616/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4078 - val_loss: 1.3287 - val_accuracy: 0.4067

Epoch 00616: val_loss did not improve from 1.32492
Epoch 617/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4085 - val_loss: 1.3260 - val_accuracy: 0.4115

Epoch 00617: val_loss did not improve from 1.32492
Epoch 618/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4073 - val_loss: 1.3330 - val_accuracy: 0.4043

Epoch 00618: val_loss did not improve from 1.32492
Epoch 619/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4117 - val_loss: 1.3311 - val_accuracy: 0.4051

Epoch 00619: val_loss did not improve from 1.32492
Epoch 620/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4126 - val_loss: 1.3263 - val_accuracy: 0.4043

Epoch 00620: val_loss did not improve from 1.32492
Epoch 621/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4094 - val_loss: 1.3275 - val_accuracy: 0.4075

Epoch 00621: val_loss did not improve from 1.32492
Epoch 622/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4097 - val_loss: 1.3266 - val_accuracy: 0.4043

Epoch 00622: val_loss did not improve from 1.32492
Epoch 623/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4120 - val_loss: 1.3268 - val_accuracy: 0.4027

Epoch 00623: val_loss did not improve from 1.32492
Epoch 624/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4101 - val_loss: 1.3267 - val_accuracy: 0.4067

Epoch 00624: val_loss did not improve from 1.32492
Epoch 625/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4097 - val_loss: 1.3250 - val_accuracy: 0.4019

Epoch 00625: val_loss did not improve from 1.32492
Epoch 626/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4070 - val_loss: 1.3306 - val_accuracy: 0.3987

Epoch 00626: val_loss did not improve from 1.32492
Epoch 627/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4086 - val_loss: 1.3305 - val_accuracy: 0.4051

Epoch 00627: val_loss did not improve from 1.32492
Epoch 628/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4077 - val_loss: 1.3359 - val_accuracy: 0.3963

Epoch 00628: val_loss did not improve from 1.32492
Epoch 629/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4082 - val_loss: 1.3272 - val_accuracy: 0.4011

Epoch 00629: val_loss did not improve from 1.32492
Epoch 630/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4110 - val_loss: 1.3280 - val_accuracy: 0.4083

Epoch 00630: val_loss did not improve from 1.32492
Epoch 631/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4091 - val_loss: 1.3283 - val_accuracy: 0.4003

Epoch 00631: val_loss did not improve from 1.32492
Epoch 632/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4092 - val_loss: 1.3281 - val_accuracy: 0.3931

Epoch 00632: val_loss did not improve from 1.32492
Epoch 633/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4078 - val_loss: 1.3271 - val_accuracy: 0.4035

Epoch 00633: val_loss did not improve from 1.32492
Epoch 634/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4092 - val_loss: 1.3258 - val_accuracy: 0.3955

Epoch 00634: val_loss did not improve from 1.32492
Epoch 635/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4101 - val_loss: 1.3304 - val_accuracy: 0.4115

Epoch 00635: val_loss did not improve from 1.32492
Epoch 636/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4098 - val_loss: 1.3247 - val_accuracy: 0.4027

Epoch 00636: val_loss improved from 1.32492 to 1.32466, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 637/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4108 - val_loss: 1.3251 - val_accuracy: 0.3947

Epoch 00637: val_loss did not improve from 1.32466
Epoch 638/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4101 - val_loss: 1.3280 - val_accuracy: 0.4107

Epoch 00638: val_loss did not improve from 1.32466
Epoch 639/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4125 - val_loss: 1.3257 - val_accuracy: 0.3995

Epoch 00639: val_loss did not improve from 1.32466
Epoch 640/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4126 - val_loss: 1.3275 - val_accuracy: 0.3955

Epoch 00640: val_loss did not improve from 1.32466
Epoch 641/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4065 - val_loss: 1.3245 - val_accuracy: 0.4035

Epoch 00641: val_loss improved from 1.32466 to 1.32447, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 642/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4134 - val_loss: 1.3251 - val_accuracy: 0.4035

Epoch 00642: val_loss did not improve from 1.32447
Epoch 643/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4108 - val_loss: 1.3263 - val_accuracy: 0.4011

Epoch 00643: val_loss did not improve from 1.32447
Epoch 644/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4132 - val_loss: 1.3255 - val_accuracy: 0.4003

Epoch 00644: val_loss did not improve from 1.32447
Epoch 645/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4107 - val_loss: 1.3246 - val_accuracy: 0.4067

Epoch 00645: val_loss did not improve from 1.32447
Epoch 646/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4134 - val_loss: 1.3263 - val_accuracy: 0.4099

Epoch 00646: val_loss did not improve from 1.32447
Epoch 647/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4100 - val_loss: 1.3254 - val_accuracy: 0.4043

Epoch 00647: val_loss did not improve from 1.32447
Epoch 648/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4123 - val_loss: 1.3239 - val_accuracy: 0.3995

Epoch 00648: val_loss improved from 1.32447 to 1.32387, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 649/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4127 - val_loss: 1.3276 - val_accuracy: 0.3955

Epoch 00649: val_loss did not improve from 1.32387
Epoch 650/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4144 - val_loss: 1.3283 - val_accuracy: 0.4083

Epoch 00650: val_loss did not improve from 1.32387
Epoch 651/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4135 - val_loss: 1.3258 - val_accuracy: 0.3971

Epoch 00651: val_loss did not improve from 1.32387
Epoch 652/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4129 - val_loss: 1.3273 - val_accuracy: 0.4043

Epoch 00652: val_loss did not improve from 1.32387
Epoch 653/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4143 - val_loss: 1.3322 - val_accuracy: 0.4003

Epoch 00653: val_loss did not improve from 1.32387
Epoch 654/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4125 - val_loss: 1.3250 - val_accuracy: 0.4091

Epoch 00654: val_loss did not improve from 1.32387
Epoch 655/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4109 - val_loss: 1.3281 - val_accuracy: 0.4011

Epoch 00655: val_loss did not improve from 1.32387
Epoch 656/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4115 - val_loss: 1.3310 - val_accuracy: 0.4003

Epoch 00656: val_loss did not improve from 1.32387
Epoch 657/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4097 - val_loss: 1.3239 - val_accuracy: 0.4035

Epoch 00657: val_loss improved from 1.32387 to 1.32386, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 658/10000
12/12 - 0s - loss: 1.2952 - accuracy: 0.4119 - val_loss: 1.3236 - val_accuracy: 0.4107

Epoch 00658: val_loss improved from 1.32386 to 1.32360, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 659/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4095 - val_loss: 1.3236 - val_accuracy: 0.4019

Epoch 00659: val_loss did not improve from 1.32360
Epoch 660/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4088 - val_loss: 1.3257 - val_accuracy: 0.4075

Epoch 00660: val_loss did not improve from 1.32360
Epoch 661/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4079 - val_loss: 1.3263 - val_accuracy: 0.4027

Epoch 00661: val_loss did not improve from 1.32360
Epoch 662/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4118 - val_loss: 1.3253 - val_accuracy: 0.3979

Epoch 00662: val_loss did not improve from 1.32360
Epoch 663/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4119 - val_loss: 1.3260 - val_accuracy: 0.4059

Epoch 00663: val_loss did not improve from 1.32360
Epoch 664/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4115 - val_loss: 1.3244 - val_accuracy: 0.4139

Epoch 00664: val_loss did not improve from 1.32360
Epoch 665/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4117 - val_loss: 1.3254 - val_accuracy: 0.4027

Epoch 00665: val_loss did not improve from 1.32360
Epoch 666/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4120 - val_loss: 1.3289 - val_accuracy: 0.4115

Epoch 00666: val_loss did not improve from 1.32360
Epoch 667/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4120 - val_loss: 1.3213 - val_accuracy: 0.4019

Epoch 00667: val_loss improved from 1.32360 to 1.32127, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 668/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4121 - val_loss: 1.3241 - val_accuracy: 0.3995

Epoch 00668: val_loss did not improve from 1.32127
Epoch 669/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4127 - val_loss: 1.3260 - val_accuracy: 0.4067

Epoch 00669: val_loss did not improve from 1.32127
Epoch 670/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4108 - val_loss: 1.3262 - val_accuracy: 0.4043

Epoch 00670: val_loss did not improve from 1.32127
Epoch 671/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4107 - val_loss: 1.3222 - val_accuracy: 0.4083

Epoch 00671: val_loss did not improve from 1.32127
Epoch 672/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4097 - val_loss: 1.3251 - val_accuracy: 0.4059

Epoch 00672: val_loss did not improve from 1.32127
Epoch 673/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4110 - val_loss: 1.3236 - val_accuracy: 0.4083

Epoch 00673: val_loss did not improve from 1.32127
Epoch 674/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4138 - val_loss: 1.3282 - val_accuracy: 0.4035

Epoch 00674: val_loss did not improve from 1.32127
Epoch 675/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4087 - val_loss: 1.3238 - val_accuracy: 0.4107

Epoch 00675: val_loss did not improve from 1.32127
Epoch 676/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4120 - val_loss: 1.3228 - val_accuracy: 0.4091

Epoch 00676: val_loss did not improve from 1.32127
Epoch 677/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4109 - val_loss: 1.3241 - val_accuracy: 0.4115

Epoch 00677: val_loss did not improve from 1.32127
Epoch 678/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4108 - val_loss: 1.3238 - val_accuracy: 0.4099

Epoch 00678: val_loss did not improve from 1.32127
Epoch 679/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4108 - val_loss: 1.3237 - val_accuracy: 0.3995

Epoch 00679: val_loss did not improve from 1.32127
Epoch 680/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4095 - val_loss: 1.3227 - val_accuracy: 0.4059

Epoch 00680: val_loss did not improve from 1.32127
Epoch 681/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4156 - val_loss: 1.3265 - val_accuracy: 0.4075

Epoch 00681: val_loss did not improve from 1.32127
Epoch 682/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4105 - val_loss: 1.3230 - val_accuracy: 0.4075

Epoch 00682: val_loss did not improve from 1.32127
Epoch 683/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4099 - val_loss: 1.3238 - val_accuracy: 0.4027

Epoch 00683: val_loss did not improve from 1.32127
Epoch 684/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4155 - val_loss: 1.3303 - val_accuracy: 0.4027

Epoch 00684: val_loss did not improve from 1.32127
Epoch 685/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4082 - val_loss: 1.3232 - val_accuracy: 0.4155

Epoch 00685: val_loss did not improve from 1.32127
Epoch 686/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4102 - val_loss: 1.3252 - val_accuracy: 0.4083

Epoch 00686: val_loss did not improve from 1.32127
Epoch 687/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4146 - val_loss: 1.3254 - val_accuracy: 0.4107

Epoch 00687: val_loss did not improve from 1.32127
Epoch 688/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4118 - val_loss: 1.3254 - val_accuracy: 0.4091

Epoch 00688: val_loss did not improve from 1.32127
Epoch 689/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4094 - val_loss: 1.3242 - val_accuracy: 0.4027

Epoch 00689: val_loss did not improve from 1.32127
Epoch 690/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4122 - val_loss: 1.3249 - val_accuracy: 0.4043

Epoch 00690: val_loss did not improve from 1.32127
Epoch 691/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4075 - val_loss: 1.3230 - val_accuracy: 0.4027

Epoch 00691: val_loss did not improve from 1.32127
Epoch 692/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4088 - val_loss: 1.3225 - val_accuracy: 0.3931

Epoch 00692: val_loss did not improve from 1.32127
Epoch 693/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4082 - val_loss: 1.3238 - val_accuracy: 0.4011

Epoch 00693: val_loss did not improve from 1.32127
Epoch 694/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4130 - val_loss: 1.3220 - val_accuracy: 0.4107

Epoch 00694: val_loss did not improve from 1.32127
Epoch 695/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4140 - val_loss: 1.3319 - val_accuracy: 0.4067

Epoch 00695: val_loss did not improve from 1.32127
Epoch 696/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4087 - val_loss: 1.3273 - val_accuracy: 0.4011

Epoch 00696: val_loss did not improve from 1.32127
Epoch 697/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4116 - val_loss: 1.3216 - val_accuracy: 0.4115

Epoch 00697: val_loss did not improve from 1.32127
Epoch 698/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4143 - val_loss: 1.3239 - val_accuracy: 0.4163

Epoch 00698: val_loss did not improve from 1.32127
Epoch 699/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4111 - val_loss: 1.3262 - val_accuracy: 0.3995

Epoch 00699: val_loss did not improve from 1.32127
Epoch 700/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4106 - val_loss: 1.3238 - val_accuracy: 0.3987

Epoch 00700: val_loss did not improve from 1.32127
Epoch 701/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4140 - val_loss: 1.3226 - val_accuracy: 0.3971

Epoch 00701: val_loss did not improve from 1.32127
Epoch 702/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4141 - val_loss: 1.3233 - val_accuracy: 0.4035

Epoch 00702: val_loss did not improve from 1.32127
Epoch 703/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4124 - val_loss: 1.3245 - val_accuracy: 0.3963

Epoch 00703: val_loss did not improve from 1.32127
Epoch 704/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4140 - val_loss: 1.3237 - val_accuracy: 0.4067

Epoch 00704: val_loss did not improve from 1.32127
Epoch 705/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4113 - val_loss: 1.3266 - val_accuracy: 0.4043

Epoch 00705: val_loss did not improve from 1.32127
Epoch 706/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4112 - val_loss: 1.3342 - val_accuracy: 0.4027

Epoch 00706: val_loss did not improve from 1.32127
Epoch 707/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4082 - val_loss: 1.3280 - val_accuracy: 0.4107

Epoch 00707: val_loss did not improve from 1.32127
Epoch 708/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4122 - val_loss: 1.3229 - val_accuracy: 0.4027

Epoch 00708: val_loss did not improve from 1.32127
Epoch 709/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4150 - val_loss: 1.3231 - val_accuracy: 0.4075

Epoch 00709: val_loss did not improve from 1.32127
Epoch 710/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4168 - val_loss: 1.3276 - val_accuracy: 0.4123

Epoch 00710: val_loss did not improve from 1.32127
Epoch 711/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4078 - val_loss: 1.3238 - val_accuracy: 0.4003

Epoch 00711: val_loss did not improve from 1.32127
Epoch 712/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4112 - val_loss: 1.3237 - val_accuracy: 0.4019

Epoch 00712: val_loss did not improve from 1.32127
Epoch 713/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4140 - val_loss: 1.3313 - val_accuracy: 0.4043

Epoch 00713: val_loss did not improve from 1.32127
Epoch 714/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4122 - val_loss: 1.3237 - val_accuracy: 0.4051

Epoch 00714: val_loss did not improve from 1.32127
Epoch 715/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4119 - val_loss: 1.3235 - val_accuracy: 0.4003

Epoch 00715: val_loss did not improve from 1.32127
Epoch 716/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4149 - val_loss: 1.3248 - val_accuracy: 0.4107

Epoch 00716: val_loss did not improve from 1.32127
Epoch 717/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4155 - val_loss: 1.3235 - val_accuracy: 0.4075

Epoch 00717: val_loss did not improve from 1.32127
Epoch 718/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4077 - val_loss: 1.3239 - val_accuracy: 0.4051

Epoch 00718: val_loss did not improve from 1.32127
Epoch 719/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4129 - val_loss: 1.3247 - val_accuracy: 0.4051

Epoch 00719: val_loss did not improve from 1.32127
Epoch 720/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4136 - val_loss: 1.3264 - val_accuracy: 0.4075

Epoch 00720: val_loss did not improve from 1.32127
Epoch 721/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4119 - val_loss: 1.3223 - val_accuracy: 0.4011

Epoch 00721: val_loss did not improve from 1.32127
Epoch 722/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4128 - val_loss: 1.3230 - val_accuracy: 0.4067

Epoch 00722: val_loss did not improve from 1.32127
Epoch 723/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4148 - val_loss: 1.3248 - val_accuracy: 0.4067

Epoch 00723: val_loss did not improve from 1.32127
Epoch 724/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4123 - val_loss: 1.3237 - val_accuracy: 0.4083

Epoch 00724: val_loss did not improve from 1.32127
Epoch 725/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4139 - val_loss: 1.3249 - val_accuracy: 0.4091

Epoch 00725: val_loss did not improve from 1.32127
Epoch 726/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4146 - val_loss: 1.3233 - val_accuracy: 0.4083

Epoch 00726: val_loss did not improve from 1.32127
Epoch 727/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4140 - val_loss: 1.3234 - val_accuracy: 0.4075

Epoch 00727: val_loss did not improve from 1.32127
Epoch 728/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4133 - val_loss: 1.3213 - val_accuracy: 0.4035

Epoch 00728: val_loss did not improve from 1.32127
Epoch 729/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4154 - val_loss: 1.3242 - val_accuracy: 0.4067

Epoch 00729: val_loss did not improve from 1.32127
Epoch 730/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4113 - val_loss: 1.3241 - val_accuracy: 0.4011

Epoch 00730: val_loss did not improve from 1.32127
Epoch 731/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4123 - val_loss: 1.3214 - val_accuracy: 0.4051

Epoch 00731: val_loss did not improve from 1.32127
Epoch 732/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4113 - val_loss: 1.3230 - val_accuracy: 0.4035

Epoch 00732: val_loss did not improve from 1.32127
Epoch 733/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4133 - val_loss: 1.3275 - val_accuracy: 0.4171

Epoch 00733: val_loss did not improve from 1.32127
Epoch 734/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4096 - val_loss: 1.3230 - val_accuracy: 0.3955

Epoch 00734: val_loss did not improve from 1.32127
Epoch 735/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4133 - val_loss: 1.3286 - val_accuracy: 0.4027

Epoch 00735: val_loss did not improve from 1.32127
Epoch 736/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4061 - val_loss: 1.3237 - val_accuracy: 0.4027

Epoch 00736: val_loss did not improve from 1.32127
Epoch 737/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4120 - val_loss: 1.3228 - val_accuracy: 0.3955

Epoch 00737: val_loss did not improve from 1.32127
Epoch 738/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4126 - val_loss: 1.3224 - val_accuracy: 0.4115

Epoch 00738: val_loss did not improve from 1.32127
Epoch 739/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4152 - val_loss: 1.3234 - val_accuracy: 0.4027

Epoch 00739: val_loss did not improve from 1.32127
Epoch 740/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4109 - val_loss: 1.3239 - val_accuracy: 0.3987

Epoch 00740: val_loss did not improve from 1.32127
Epoch 741/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4163 - val_loss: 1.3290 - val_accuracy: 0.4027

Epoch 00741: val_loss did not improve from 1.32127
Epoch 742/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4132 - val_loss: 1.3227 - val_accuracy: 0.4051

Epoch 00742: val_loss did not improve from 1.32127
Epoch 743/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4135 - val_loss: 1.3229 - val_accuracy: 0.4051

Epoch 00743: val_loss did not improve from 1.32127
Epoch 744/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4149 - val_loss: 1.3249 - val_accuracy: 0.4115

Epoch 00744: val_loss did not improve from 1.32127
Epoch 745/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4152 - val_loss: 1.3221 - val_accuracy: 0.4027

Epoch 00745: val_loss did not improve from 1.32127
Epoch 746/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4132 - val_loss: 1.3232 - val_accuracy: 0.4075

Epoch 00746: val_loss did not improve from 1.32127
Epoch 747/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4118 - val_loss: 1.3275 - val_accuracy: 0.4091

Epoch 00747: val_loss did not improve from 1.32127
Epoch 748/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4119 - val_loss: 1.3257 - val_accuracy: 0.3987

Epoch 00748: val_loss did not improve from 1.32127
Epoch 749/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4156 - val_loss: 1.3228 - val_accuracy: 0.4043

Epoch 00749: val_loss did not improve from 1.32127
Epoch 750/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4153 - val_loss: 1.3221 - val_accuracy: 0.4059

Epoch 00750: val_loss did not improve from 1.32127
Epoch 751/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4131 - val_loss: 1.3238 - val_accuracy: 0.4043

Epoch 00751: val_loss did not improve from 1.32127
Epoch 752/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4122 - val_loss: 1.3231 - val_accuracy: 0.4035

Epoch 00752: val_loss did not improve from 1.32127
Epoch 753/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4140 - val_loss: 1.3220 - val_accuracy: 0.4075

Epoch 00753: val_loss did not improve from 1.32127
Epoch 754/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4122 - val_loss: 1.3212 - val_accuracy: 0.3979

Epoch 00754: val_loss improved from 1.32127 to 1.32124, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 755/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4137 - val_loss: 1.3211 - val_accuracy: 0.4091

Epoch 00755: val_loss improved from 1.32124 to 1.32110, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 756/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4129 - val_loss: 1.3229 - val_accuracy: 0.4147

Epoch 00756: val_loss did not improve from 1.32110
Epoch 757/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4128 - val_loss: 1.3238 - val_accuracy: 0.4059

Epoch 00757: val_loss did not improve from 1.32110
Epoch 758/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4110 - val_loss: 1.3232 - val_accuracy: 0.4115

Epoch 00758: val_loss did not improve from 1.32110
Epoch 759/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4134 - val_loss: 1.3272 - val_accuracy: 0.4123

Epoch 00759: val_loss did not improve from 1.32110
Epoch 760/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4118 - val_loss: 1.3205 - val_accuracy: 0.3995

Epoch 00760: val_loss improved from 1.32110 to 1.32046, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 761/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4096 - val_loss: 1.3207 - val_accuracy: 0.4067

Epoch 00761: val_loss did not improve from 1.32046
Epoch 762/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4150 - val_loss: 1.3236 - val_accuracy: 0.4083

Epoch 00762: val_loss did not improve from 1.32046
Epoch 763/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4141 - val_loss: 1.3233 - val_accuracy: 0.4043

Epoch 00763: val_loss did not improve from 1.32046
Epoch 764/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4103 - val_loss: 1.3262 - val_accuracy: 0.3955

Epoch 00764: val_loss did not improve from 1.32046
Epoch 765/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4140 - val_loss: 1.3232 - val_accuracy: 0.4075

Epoch 00765: val_loss did not improve from 1.32046
Epoch 766/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4140 - val_loss: 1.3224 - val_accuracy: 0.4083

Epoch 00766: val_loss did not improve from 1.32046
Epoch 767/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4137 - val_loss: 1.3253 - val_accuracy: 0.4115

Epoch 00767: val_loss did not improve from 1.32046
Epoch 768/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4156 - val_loss: 1.3229 - val_accuracy: 0.3955

Epoch 00768: val_loss did not improve from 1.32046
Epoch 769/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4128 - val_loss: 1.3217 - val_accuracy: 0.4107

Epoch 00769: val_loss did not improve from 1.32046
Epoch 770/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4136 - val_loss: 1.3207 - val_accuracy: 0.4139

Epoch 00770: val_loss did not improve from 1.32046
Epoch 771/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4141 - val_loss: 1.3224 - val_accuracy: 0.4131

Epoch 00771: val_loss did not improve from 1.32046
Epoch 772/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4132 - val_loss: 1.3233 - val_accuracy: 0.4139

Epoch 00772: val_loss did not improve from 1.32046
Epoch 773/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4132 - val_loss: 1.3236 - val_accuracy: 0.4075

Epoch 00773: val_loss did not improve from 1.32046
Epoch 774/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4145 - val_loss: 1.3247 - val_accuracy: 0.4155

Epoch 00774: val_loss did not improve from 1.32046
Epoch 775/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4128 - val_loss: 1.3236 - val_accuracy: 0.4043

Epoch 00775: val_loss did not improve from 1.32046
Epoch 776/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4105 - val_loss: 1.3199 - val_accuracy: 0.4051

Epoch 00776: val_loss improved from 1.32046 to 1.31992, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 777/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4150 - val_loss: 1.3204 - val_accuracy: 0.4131

Epoch 00777: val_loss did not improve from 1.31992
Epoch 778/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4174 - val_loss: 1.3187 - val_accuracy: 0.4099

Epoch 00778: val_loss improved from 1.31992 to 1.31868, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 779/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4163 - val_loss: 1.3257 - val_accuracy: 0.4075

Epoch 00779: val_loss did not improve from 1.31868
Epoch 780/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4148 - val_loss: 1.3201 - val_accuracy: 0.4075

Epoch 00780: val_loss did not improve from 1.31868
Epoch 781/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4149 - val_loss: 1.3214 - val_accuracy: 0.4083

Epoch 00781: val_loss did not improve from 1.31868
Epoch 782/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4166 - val_loss: 1.3243 - val_accuracy: 0.4163

Epoch 00782: val_loss did not improve from 1.31868
Epoch 783/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4139 - val_loss: 1.3205 - val_accuracy: 0.4067

Epoch 00783: val_loss did not improve from 1.31868
Epoch 784/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4125 - val_loss: 1.3211 - val_accuracy: 0.4043

Epoch 00784: val_loss did not improve from 1.31868
Epoch 785/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4138 - val_loss: 1.3221 - val_accuracy: 0.4099

Epoch 00785: val_loss did not improve from 1.31868
Epoch 786/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4154 - val_loss: 1.3218 - val_accuracy: 0.4059

Epoch 00786: val_loss did not improve from 1.31868
Epoch 787/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4147 - val_loss: 1.3198 - val_accuracy: 0.4051

Epoch 00787: val_loss did not improve from 1.31868
Epoch 788/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4113 - val_loss: 1.3187 - val_accuracy: 0.4059

Epoch 00788: val_loss improved from 1.31868 to 1.31865, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 789/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4174 - val_loss: 1.3244 - val_accuracy: 0.4083

Epoch 00789: val_loss did not improve from 1.31865
Epoch 790/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4113 - val_loss: 1.3209 - val_accuracy: 0.4019

Epoch 00790: val_loss did not improve from 1.31865
Epoch 791/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4137 - val_loss: 1.3227 - val_accuracy: 0.4051

Epoch 00791: val_loss did not improve from 1.31865
Epoch 792/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4149 - val_loss: 1.3383 - val_accuracy: 0.3979

Epoch 00792: val_loss did not improve from 1.31865
Epoch 793/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4091 - val_loss: 1.3264 - val_accuracy: 0.3939

Epoch 00793: val_loss did not improve from 1.31865
Epoch 794/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4120 - val_loss: 1.3203 - val_accuracy: 0.4019

Epoch 00794: val_loss did not improve from 1.31865
Epoch 795/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4145 - val_loss: 1.3307 - val_accuracy: 0.4027

Epoch 00795: val_loss did not improve from 1.31865
Epoch 796/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4163 - val_loss: 1.3210 - val_accuracy: 0.4043

Epoch 00796: val_loss did not improve from 1.31865
Epoch 797/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4129 - val_loss: 1.3218 - val_accuracy: 0.4043

Epoch 00797: val_loss did not improve from 1.31865
Epoch 798/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4144 - val_loss: 1.3236 - val_accuracy: 0.4091

Epoch 00798: val_loss did not improve from 1.31865
Epoch 799/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4144 - val_loss: 1.3200 - val_accuracy: 0.4083

Epoch 00799: val_loss did not improve from 1.31865
Epoch 800/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4153 - val_loss: 1.3182 - val_accuracy: 0.4115

Epoch 00800: val_loss improved from 1.31865 to 1.31823, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 801/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4177 - val_loss: 1.3263 - val_accuracy: 0.4067

Epoch 00801: val_loss did not improve from 1.31823
Epoch 802/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4161 - val_loss: 1.3224 - val_accuracy: 0.4115

Epoch 00802: val_loss did not improve from 1.31823
Epoch 803/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4163 - val_loss: 1.3206 - val_accuracy: 0.4123

Epoch 00803: val_loss did not improve from 1.31823
Epoch 804/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4148 - val_loss: 1.3188 - val_accuracy: 0.4051

Epoch 00804: val_loss did not improve from 1.31823
Epoch 805/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4167 - val_loss: 1.3205 - val_accuracy: 0.4155

Epoch 00805: val_loss did not improve from 1.31823
Epoch 806/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4145 - val_loss: 1.3221 - val_accuracy: 0.4123

Epoch 00806: val_loss did not improve from 1.31823
Epoch 807/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4151 - val_loss: 1.3223 - val_accuracy: 0.4027

Epoch 00807: val_loss did not improve from 1.31823
Epoch 808/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4131 - val_loss: 1.3256 - val_accuracy: 0.4107

Epoch 00808: val_loss did not improve from 1.31823
Epoch 809/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4160 - val_loss: 1.3198 - val_accuracy: 0.4099

Epoch 00809: val_loss did not improve from 1.31823
Epoch 810/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4101 - val_loss: 1.3206 - val_accuracy: 0.4067

Epoch 00810: val_loss did not improve from 1.31823
Epoch 811/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4148 - val_loss: 1.3218 - val_accuracy: 0.4075

Epoch 00811: val_loss did not improve from 1.31823
Epoch 812/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4142 - val_loss: 1.3246 - val_accuracy: 0.4131

Epoch 00812: val_loss did not improve from 1.31823
Epoch 813/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4135 - val_loss: 1.3257 - val_accuracy: 0.4067

Epoch 00813: val_loss did not improve from 1.31823
Epoch 814/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4148 - val_loss: 1.3216 - val_accuracy: 0.3995

Epoch 00814: val_loss did not improve from 1.31823
Epoch 815/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4155 - val_loss: 1.3204 - val_accuracy: 0.4051

Epoch 00815: val_loss did not improve from 1.31823
Epoch 816/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4157 - val_loss: 1.3250 - val_accuracy: 0.4147

Epoch 00816: val_loss did not improve from 1.31823
Epoch 817/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4143 - val_loss: 1.3209 - val_accuracy: 0.4011

Epoch 00817: val_loss did not improve from 1.31823
Epoch 818/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4170 - val_loss: 1.3221 - val_accuracy: 0.4011

Epoch 00818: val_loss did not improve from 1.31823
Epoch 819/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4135 - val_loss: 1.3238 - val_accuracy: 0.4107

Epoch 00819: val_loss did not improve from 1.31823
Epoch 820/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4190 - val_loss: 1.3231 - val_accuracy: 0.3963

Epoch 00820: val_loss did not improve from 1.31823
Epoch 821/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4118 - val_loss: 1.3248 - val_accuracy: 0.4075

Epoch 00821: val_loss did not improve from 1.31823
Epoch 822/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4158 - val_loss: 1.3173 - val_accuracy: 0.4019

Epoch 00822: val_loss improved from 1.31823 to 1.31735, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 823/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4133 - val_loss: 1.3176 - val_accuracy: 0.4067

Epoch 00823: val_loss did not improve from 1.31735
Epoch 824/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4157 - val_loss: 1.3187 - val_accuracy: 0.4091

Epoch 00824: val_loss did not improve from 1.31735
Epoch 825/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4140 - val_loss: 1.3201 - val_accuracy: 0.3979

Epoch 00825: val_loss did not improve from 1.31735
Epoch 826/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4145 - val_loss: 1.3184 - val_accuracy: 0.4051

Epoch 00826: val_loss did not improve from 1.31735
Epoch 827/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4154 - val_loss: 1.3205 - val_accuracy: 0.4115

Epoch 00827: val_loss did not improve from 1.31735
Epoch 828/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4151 - val_loss: 1.3233 - val_accuracy: 0.4027

Epoch 00828: val_loss did not improve from 1.31735
Epoch 829/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4159 - val_loss: 1.3186 - val_accuracy: 0.4131

Epoch 00829: val_loss did not improve from 1.31735
Epoch 830/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4170 - val_loss: 1.3198 - val_accuracy: 0.4131

Epoch 00830: val_loss did not improve from 1.31735
Epoch 831/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4145 - val_loss: 1.3182 - val_accuracy: 0.4083

Epoch 00831: val_loss did not improve from 1.31735
Epoch 832/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4154 - val_loss: 1.3189 - val_accuracy: 0.4123

Epoch 00832: val_loss did not improve from 1.31735
Epoch 833/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4177 - val_loss: 1.3204 - val_accuracy: 0.4051

Epoch 00833: val_loss did not improve from 1.31735
Epoch 834/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4148 - val_loss: 1.3242 - val_accuracy: 0.4011

Epoch 00834: val_loss did not improve from 1.31735
Epoch 835/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4156 - val_loss: 1.3212 - val_accuracy: 0.4011

Epoch 00835: val_loss did not improve from 1.31735
Epoch 836/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4194 - val_loss: 1.3252 - val_accuracy: 0.4091

Epoch 00836: val_loss did not improve from 1.31735
Epoch 837/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4183 - val_loss: 1.3255 - val_accuracy: 0.4147

Epoch 00837: val_loss did not improve from 1.31735
Epoch 838/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4094 - val_loss: 1.3205 - val_accuracy: 0.4011

Epoch 00838: val_loss did not improve from 1.31735
Epoch 839/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4162 - val_loss: 1.3168 - val_accuracy: 0.4083

Epoch 00839: val_loss improved from 1.31735 to 1.31685, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 840/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4129 - val_loss: 1.3185 - val_accuracy: 0.4019

Epoch 00840: val_loss did not improve from 1.31685
Epoch 841/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4164 - val_loss: 1.3243 - val_accuracy: 0.4107

Epoch 00841: val_loss did not improve from 1.31685
Epoch 842/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4140 - val_loss: 1.3204 - val_accuracy: 0.4179

Epoch 00842: val_loss did not improve from 1.31685
Epoch 843/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4159 - val_loss: 1.3198 - val_accuracy: 0.4051

Epoch 00843: val_loss did not improve from 1.31685
Epoch 844/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4129 - val_loss: 1.3187 - val_accuracy: 0.4123

Epoch 00844: val_loss did not improve from 1.31685
Epoch 845/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4198 - val_loss: 1.3179 - val_accuracy: 0.4075

Epoch 00845: val_loss did not improve from 1.31685
Epoch 846/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4160 - val_loss: 1.3181 - val_accuracy: 0.4043

Epoch 00846: val_loss did not improve from 1.31685
Epoch 847/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4187 - val_loss: 1.3236 - val_accuracy: 0.4147

Epoch 00847: val_loss did not improve from 1.31685
Epoch 848/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4122 - val_loss: 1.3177 - val_accuracy: 0.4019

Epoch 00848: val_loss did not improve from 1.31685
Epoch 849/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4080 - val_loss: 1.3197 - val_accuracy: 0.4075

Epoch 00849: val_loss did not improve from 1.31685
Epoch 850/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4175 - val_loss: 1.3183 - val_accuracy: 0.4011

Epoch 00850: val_loss did not improve from 1.31685
Epoch 851/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4175 - val_loss: 1.3219 - val_accuracy: 0.4035

Epoch 00851: val_loss did not improve from 1.31685
Epoch 852/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4172 - val_loss: 1.3259 - val_accuracy: 0.4043

Epoch 00852: val_loss did not improve from 1.31685
Epoch 853/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4167 - val_loss: 1.3184 - val_accuracy: 0.4115

Epoch 00853: val_loss did not improve from 1.31685
Epoch 854/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4176 - val_loss: 1.3167 - val_accuracy: 0.4083

Epoch 00854: val_loss improved from 1.31685 to 1.31670, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 855/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4167 - val_loss: 1.3236 - val_accuracy: 0.4131

Epoch 00855: val_loss did not improve from 1.31670
Epoch 856/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4180 - val_loss: 1.3184 - val_accuracy: 0.4179

Epoch 00856: val_loss did not improve from 1.31670
Epoch 857/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4178 - val_loss: 1.3171 - val_accuracy: 0.4123

Epoch 00857: val_loss did not improve from 1.31670
Epoch 858/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4151 - val_loss: 1.3166 - val_accuracy: 0.4107

Epoch 00858: val_loss improved from 1.31670 to 1.31657, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 859/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4187 - val_loss: 1.3213 - val_accuracy: 0.4147

Epoch 00859: val_loss did not improve from 1.31657
Epoch 860/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4154 - val_loss: 1.3172 - val_accuracy: 0.4059

Epoch 00860: val_loss did not improve from 1.31657
Epoch 861/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4124 - val_loss: 1.3167 - val_accuracy: 0.4067

Epoch 00861: val_loss did not improve from 1.31657
Epoch 862/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4151 - val_loss: 1.3189 - val_accuracy: 0.4011

Epoch 00862: val_loss did not improve from 1.31657
Epoch 863/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4173 - val_loss: 1.3211 - val_accuracy: 0.4139

Epoch 00863: val_loss did not improve from 1.31657
Epoch 864/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4184 - val_loss: 1.3186 - val_accuracy: 0.4043

Epoch 00864: val_loss did not improve from 1.31657
Epoch 865/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4157 - val_loss: 1.3196 - val_accuracy: 0.4027

Epoch 00865: val_loss did not improve from 1.31657
Epoch 866/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4131 - val_loss: 1.3210 - val_accuracy: 0.4083

Epoch 00866: val_loss did not improve from 1.31657
Epoch 867/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4151 - val_loss: 1.3200 - val_accuracy: 0.4075

Epoch 00867: val_loss did not improve from 1.31657
Epoch 868/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4076 - val_loss: 1.3210 - val_accuracy: 0.4083

Epoch 00868: val_loss did not improve from 1.31657
Epoch 869/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4148 - val_loss: 1.3204 - val_accuracy: 0.4075

Epoch 00869: val_loss did not improve from 1.31657
Epoch 870/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4154 - val_loss: 1.3180 - val_accuracy: 0.4147

Epoch 00870: val_loss did not improve from 1.31657
Epoch 871/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4166 - val_loss: 1.3152 - val_accuracy: 0.4147

Epoch 00871: val_loss improved from 1.31657 to 1.31524, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 872/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4158 - val_loss: 1.3163 - val_accuracy: 0.4035

Epoch 00872: val_loss did not improve from 1.31524
Epoch 873/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4179 - val_loss: 1.3184 - val_accuracy: 0.4131

Epoch 00873: val_loss did not improve from 1.31524
Epoch 874/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4148 - val_loss: 1.3188 - val_accuracy: 0.4115

Epoch 00874: val_loss did not improve from 1.31524
Epoch 875/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4156 - val_loss: 1.3212 - val_accuracy: 0.4163

Epoch 00875: val_loss did not improve from 1.31524
Epoch 876/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4163 - val_loss: 1.3172 - val_accuracy: 0.4067

Epoch 00876: val_loss did not improve from 1.31524
Epoch 877/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4169 - val_loss: 1.3163 - val_accuracy: 0.4035

Epoch 00877: val_loss did not improve from 1.31524
Epoch 878/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4208 - val_loss: 1.3181 - val_accuracy: 0.4123

Epoch 00878: val_loss did not improve from 1.31524
Epoch 879/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4163 - val_loss: 1.3192 - val_accuracy: 0.4123

Epoch 00879: val_loss did not improve from 1.31524
Epoch 880/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4174 - val_loss: 1.3188 - val_accuracy: 0.4187

Epoch 00880: val_loss did not improve from 1.31524
Epoch 881/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4167 - val_loss: 1.3209 - val_accuracy: 0.3963

Epoch 00881: val_loss did not improve from 1.31524
Epoch 882/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4172 - val_loss: 1.3181 - val_accuracy: 0.4171

Epoch 00882: val_loss did not improve from 1.31524
Epoch 883/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4182 - val_loss: 1.3236 - val_accuracy: 0.4067

Epoch 00883: val_loss did not improve from 1.31524
Epoch 884/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4114 - val_loss: 1.3206 - val_accuracy: 0.4043

Epoch 00884: val_loss did not improve from 1.31524
Epoch 885/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4177 - val_loss: 1.3263 - val_accuracy: 0.4043

Epoch 00885: val_loss did not improve from 1.31524
Epoch 886/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4173 - val_loss: 1.3175 - val_accuracy: 0.4035

Epoch 00886: val_loss did not improve from 1.31524
Epoch 887/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4148 - val_loss: 1.3178 - val_accuracy: 0.4075

Epoch 00887: val_loss did not improve from 1.31524
Epoch 888/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4208 - val_loss: 1.3209 - val_accuracy: 0.4083

Epoch 00888: val_loss did not improve from 1.31524
Epoch 889/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4153 - val_loss: 1.3188 - val_accuracy: 0.4027

Epoch 00889: val_loss did not improve from 1.31524
Epoch 890/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4165 - val_loss: 1.3165 - val_accuracy: 0.4083

Epoch 00890: val_loss did not improve from 1.31524
Epoch 891/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4193 - val_loss: 1.3177 - val_accuracy: 0.4139

Epoch 00891: val_loss did not improve from 1.31524
Epoch 892/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4180 - val_loss: 1.3190 - val_accuracy: 0.4011

Epoch 00892: val_loss did not improve from 1.31524
Epoch 893/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4182 - val_loss: 1.3185 - val_accuracy: 0.4171

Epoch 00893: val_loss did not improve from 1.31524
Epoch 894/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4193 - val_loss: 1.3235 - val_accuracy: 0.4083

Epoch 00894: val_loss did not improve from 1.31524
Epoch 895/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4150 - val_loss: 1.3184 - val_accuracy: 0.4115

Epoch 00895: val_loss did not improve from 1.31524
Epoch 896/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4163 - val_loss: 1.3168 - val_accuracy: 0.4067

Epoch 00896: val_loss did not improve from 1.31524
Epoch 897/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4165 - val_loss: 1.3183 - val_accuracy: 0.4099

Epoch 00897: val_loss did not improve from 1.31524
Epoch 898/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4154 - val_loss: 1.3180 - val_accuracy: 0.4115

Epoch 00898: val_loss did not improve from 1.31524
Epoch 899/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4167 - val_loss: 1.3207 - val_accuracy: 0.4059

Epoch 00899: val_loss did not improve from 1.31524
Epoch 900/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4171 - val_loss: 1.3181 - val_accuracy: 0.4091

Epoch 00900: val_loss did not improve from 1.31524
Epoch 901/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4200 - val_loss: 1.3152 - val_accuracy: 0.4139

Epoch 00901: val_loss improved from 1.31524 to 1.31520, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 902/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4202 - val_loss: 1.3190 - val_accuracy: 0.4011

Epoch 00902: val_loss did not improve from 1.31520
Epoch 903/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4182 - val_loss: 1.3210 - val_accuracy: 0.4043

Epoch 00903: val_loss did not improve from 1.31520
Epoch 904/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4171 - val_loss: 1.3186 - val_accuracy: 0.4123

Epoch 00904: val_loss did not improve from 1.31520
Epoch 905/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4094 - val_loss: 1.3266 - val_accuracy: 0.4131

Epoch 00905: val_loss did not improve from 1.31520
Epoch 906/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4189 - val_loss: 1.3195 - val_accuracy: 0.4003

Epoch 00906: val_loss did not improve from 1.31520
Epoch 907/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4167 - val_loss: 1.3226 - val_accuracy: 0.4019

Epoch 00907: val_loss did not improve from 1.31520
Epoch 908/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4157 - val_loss: 1.3193 - val_accuracy: 0.4043

Epoch 00908: val_loss did not improve from 1.31520
Epoch 909/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4155 - val_loss: 1.3160 - val_accuracy: 0.4051

Epoch 00909: val_loss did not improve from 1.31520
Epoch 910/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4185 - val_loss: 1.3146 - val_accuracy: 0.4131

Epoch 00910: val_loss improved from 1.31520 to 1.31465, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 911/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4197 - val_loss: 1.3207 - val_accuracy: 0.4131

Epoch 00911: val_loss did not improve from 1.31465
Epoch 912/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4162 - val_loss: 1.3159 - val_accuracy: 0.4075

Epoch 00912: val_loss did not improve from 1.31465
Epoch 913/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4202 - val_loss: 1.3184 - val_accuracy: 0.4091

Epoch 00913: val_loss did not improve from 1.31465
Epoch 914/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4180 - val_loss: 1.3168 - val_accuracy: 0.4123

Epoch 00914: val_loss did not improve from 1.31465
Epoch 915/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4189 - val_loss: 1.3173 - val_accuracy: 0.4067

Epoch 00915: val_loss did not improve from 1.31465
Epoch 916/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4227 - val_loss: 1.3183 - val_accuracy: 0.4155

Epoch 00916: val_loss did not improve from 1.31465
Epoch 917/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4161 - val_loss: 1.3141 - val_accuracy: 0.4131

Epoch 00917: val_loss improved from 1.31465 to 1.31414, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 918/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4187 - val_loss: 1.3158 - val_accuracy: 0.4115

Epoch 00918: val_loss did not improve from 1.31414
Epoch 919/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4160 - val_loss: 1.3178 - val_accuracy: 0.4115

Epoch 00919: val_loss did not improve from 1.31414
Epoch 920/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4174 - val_loss: 1.3182 - val_accuracy: 0.4107

Epoch 00920: val_loss did not improve from 1.31414
Epoch 921/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4200 - val_loss: 1.3159 - val_accuracy: 0.4179

Epoch 00921: val_loss did not improve from 1.31414
Epoch 922/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4163 - val_loss: 1.3173 - val_accuracy: 0.4171

Epoch 00922: val_loss did not improve from 1.31414
Epoch 923/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4142 - val_loss: 1.3204 - val_accuracy: 0.4035

Epoch 00923: val_loss did not improve from 1.31414
Epoch 924/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4172 - val_loss: 1.3155 - val_accuracy: 0.4099

Epoch 00924: val_loss did not improve from 1.31414
Epoch 925/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4219 - val_loss: 1.3167 - val_accuracy: 0.4155

Epoch 00925: val_loss did not improve from 1.31414
Epoch 926/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4187 - val_loss: 1.3166 - val_accuracy: 0.4163

Epoch 00926: val_loss did not improve from 1.31414
Epoch 927/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4157 - val_loss: 1.3163 - val_accuracy: 0.4075

Epoch 00927: val_loss did not improve from 1.31414
Epoch 928/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4179 - val_loss: 1.3197 - val_accuracy: 0.4035

Epoch 00928: val_loss did not improve from 1.31414
Epoch 929/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4194 - val_loss: 1.3181 - val_accuracy: 0.4187

Epoch 00929: val_loss did not improve from 1.31414
Epoch 930/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4198 - val_loss: 1.3163 - val_accuracy: 0.4091

Epoch 00930: val_loss did not improve from 1.31414
Epoch 931/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4155 - val_loss: 1.3177 - val_accuracy: 0.4139

Epoch 00931: val_loss did not improve from 1.31414
Epoch 932/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4149 - val_loss: 1.3145 - val_accuracy: 0.4107

Epoch 00932: val_loss did not improve from 1.31414
Epoch 933/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4190 - val_loss: 1.3164 - val_accuracy: 0.4115

Epoch 00933: val_loss did not improve from 1.31414
Epoch 934/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4178 - val_loss: 1.3232 - val_accuracy: 0.4083

Epoch 00934: val_loss did not improve from 1.31414
Epoch 935/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4208 - val_loss: 1.3162 - val_accuracy: 0.4075

Epoch 00935: val_loss did not improve from 1.31414
Epoch 936/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4194 - val_loss: 1.3163 - val_accuracy: 0.4107

Epoch 00936: val_loss did not improve from 1.31414
Epoch 937/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4149 - val_loss: 1.3159 - val_accuracy: 0.4139

Epoch 00937: val_loss did not improve from 1.31414
Epoch 938/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4177 - val_loss: 1.3152 - val_accuracy: 0.4059

Epoch 00938: val_loss did not improve from 1.31414
Epoch 939/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4196 - val_loss: 1.3147 - val_accuracy: 0.4123

Epoch 00939: val_loss did not improve from 1.31414
Epoch 940/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4173 - val_loss: 1.3261 - val_accuracy: 0.3987

Epoch 00940: val_loss did not improve from 1.31414
Epoch 941/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4179 - val_loss: 1.3181 - val_accuracy: 0.4091

Epoch 00941: val_loss did not improve from 1.31414
Epoch 942/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4184 - val_loss: 1.3146 - val_accuracy: 0.4075

Epoch 00942: val_loss did not improve from 1.31414
Epoch 943/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4215 - val_loss: 1.3149 - val_accuracy: 0.4147

Epoch 00943: val_loss did not improve from 1.31414
Epoch 944/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4231 - val_loss: 1.3144 - val_accuracy: 0.4147

Epoch 00944: val_loss did not improve from 1.31414
Epoch 945/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4208 - val_loss: 1.3160 - val_accuracy: 0.4123

Epoch 00945: val_loss did not improve from 1.31414
Epoch 946/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4174 - val_loss: 1.3174 - val_accuracy: 0.4003

Epoch 00946: val_loss did not improve from 1.31414
Epoch 947/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4205 - val_loss: 1.3167 - val_accuracy: 0.4075

Epoch 00947: val_loss did not improve from 1.31414
Epoch 948/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4173 - val_loss: 1.3169 - val_accuracy: 0.4147

Epoch 00948: val_loss did not improve from 1.31414
Epoch 949/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4181 - val_loss: 1.3116 - val_accuracy: 0.4091

Epoch 00949: val_loss improved from 1.31414 to 1.31156, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 950/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4167 - val_loss: 1.3191 - val_accuracy: 0.4067

Epoch 00950: val_loss did not improve from 1.31156
Epoch 951/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4189 - val_loss: 1.3151 - val_accuracy: 0.4107

Epoch 00951: val_loss did not improve from 1.31156
Epoch 952/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4162 - val_loss: 1.3162 - val_accuracy: 0.4059

Epoch 00952: val_loss did not improve from 1.31156
Epoch 953/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4184 - val_loss: 1.3147 - val_accuracy: 0.4131

Epoch 00953: val_loss did not improve from 1.31156
Epoch 954/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4190 - val_loss: 1.3177 - val_accuracy: 0.4123

Epoch 00954: val_loss did not improve from 1.31156
Epoch 955/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4212 - val_loss: 1.3156 - val_accuracy: 0.4051

Epoch 00955: val_loss did not improve from 1.31156
Epoch 956/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4202 - val_loss: 1.3160 - val_accuracy: 0.4107

Epoch 00956: val_loss did not improve from 1.31156
Epoch 957/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4174 - val_loss: 1.3169 - val_accuracy: 0.4139

Epoch 00957: val_loss did not improve from 1.31156
Epoch 958/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4207 - val_loss: 1.3149 - val_accuracy: 0.4123

Epoch 00958: val_loss did not improve from 1.31156
Epoch 959/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4183 - val_loss: 1.3171 - val_accuracy: 0.4035

Epoch 00959: val_loss did not improve from 1.31156
Epoch 960/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4218 - val_loss: 1.3166 - val_accuracy: 0.4195

Epoch 00960: val_loss did not improve from 1.31156
Epoch 961/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4189 - val_loss: 1.3175 - val_accuracy: 0.4187

Epoch 00961: val_loss did not improve from 1.31156
Epoch 962/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4181 - val_loss: 1.3145 - val_accuracy: 0.4067

Epoch 00962: val_loss did not improve from 1.31156
Epoch 963/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4193 - val_loss: 1.3153 - val_accuracy: 0.4147

Epoch 00963: val_loss did not improve from 1.31156
Epoch 964/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4203 - val_loss: 1.3163 - val_accuracy: 0.4099

Epoch 00964: val_loss did not improve from 1.31156
Epoch 965/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4205 - val_loss: 1.3152 - val_accuracy: 0.4027

Epoch 00965: val_loss did not improve from 1.31156
Epoch 966/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4196 - val_loss: 1.3135 - val_accuracy: 0.4083

Epoch 00966: val_loss did not improve from 1.31156
Epoch 967/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4188 - val_loss: 1.3152 - val_accuracy: 0.4091

Epoch 00967: val_loss did not improve from 1.31156
Epoch 968/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4195 - val_loss: 1.3173 - val_accuracy: 0.4075

Epoch 00968: val_loss did not improve from 1.31156
Epoch 969/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4203 - val_loss: 1.3162 - val_accuracy: 0.4139

Epoch 00969: val_loss did not improve from 1.31156
Epoch 970/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4211 - val_loss: 1.3146 - val_accuracy: 0.4083

Epoch 00970: val_loss did not improve from 1.31156
Epoch 971/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4240 - val_loss: 1.3140 - val_accuracy: 0.4075

Epoch 00971: val_loss did not improve from 1.31156
Epoch 972/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4219 - val_loss: 1.3189 - val_accuracy: 0.4035

Epoch 00972: val_loss did not improve from 1.31156
Epoch 973/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4163 - val_loss: 1.3186 - val_accuracy: 0.4147

Epoch 00973: val_loss did not improve from 1.31156
Epoch 974/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4213 - val_loss: 1.3185 - val_accuracy: 0.4091

Epoch 00974: val_loss did not improve from 1.31156
Epoch 975/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4224 - val_loss: 1.3155 - val_accuracy: 0.4147

Epoch 00975: val_loss did not improve from 1.31156
Epoch 976/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4165 - val_loss: 1.3138 - val_accuracy: 0.4067

Epoch 00976: val_loss did not improve from 1.31156
Epoch 977/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4223 - val_loss: 1.3145 - val_accuracy: 0.4075

Epoch 00977: val_loss did not improve from 1.31156
Epoch 978/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4142 - val_loss: 1.3165 - val_accuracy: 0.4099

Epoch 00978: val_loss did not improve from 1.31156
Epoch 979/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4172 - val_loss: 1.3159 - val_accuracy: 0.4099

Epoch 00979: val_loss did not improve from 1.31156
Epoch 980/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4184 - val_loss: 1.3174 - val_accuracy: 0.4003

Epoch 00980: val_loss did not improve from 1.31156
Epoch 981/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4156 - val_loss: 1.3149 - val_accuracy: 0.4131

Epoch 00981: val_loss did not improve from 1.31156
Epoch 982/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4228 - val_loss: 1.3129 - val_accuracy: 0.4139

Epoch 00982: val_loss did not improve from 1.31156
Epoch 983/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4227 - val_loss: 1.3237 - val_accuracy: 0.4115

Epoch 00983: val_loss did not improve from 1.31156
Epoch 984/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4138 - val_loss: 1.3135 - val_accuracy: 0.4067

Epoch 00984: val_loss did not improve from 1.31156
Epoch 985/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4190 - val_loss: 1.3145 - val_accuracy: 0.4075

Epoch 00985: val_loss did not improve from 1.31156
Epoch 986/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4217 - val_loss: 1.3208 - val_accuracy: 0.4067

Epoch 00986: val_loss did not improve from 1.31156
Epoch 987/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4211 - val_loss: 1.3158 - val_accuracy: 0.4083

Epoch 00987: val_loss did not improve from 1.31156
Epoch 988/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4190 - val_loss: 1.3152 - val_accuracy: 0.4019

Epoch 00988: val_loss did not improve from 1.31156
Epoch 989/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4179 - val_loss: 1.3128 - val_accuracy: 0.4099

Epoch 00989: val_loss did not improve from 1.31156
Epoch 990/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4236 - val_loss: 1.3152 - val_accuracy: 0.4187

Epoch 00990: val_loss did not improve from 1.31156
Epoch 991/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4206 - val_loss: 1.3163 - val_accuracy: 0.4019

Epoch 00991: val_loss did not improve from 1.31156
Epoch 992/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4249 - val_loss: 1.3188 - val_accuracy: 0.4027

Epoch 00992: val_loss did not improve from 1.31156
Epoch 993/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4225 - val_loss: 1.3132 - val_accuracy: 0.4203

Epoch 00993: val_loss did not improve from 1.31156
Epoch 994/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4204 - val_loss: 1.3117 - val_accuracy: 0.4115

Epoch 00994: val_loss did not improve from 1.31156
Epoch 995/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4238 - val_loss: 1.3145 - val_accuracy: 0.4155

Epoch 00995: val_loss did not improve from 1.31156
Epoch 996/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4219 - val_loss: 1.3143 - val_accuracy: 0.4123

Epoch 00996: val_loss did not improve from 1.31156
Epoch 997/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4155 - val_loss: 1.3147 - val_accuracy: 0.4083

Epoch 00997: val_loss did not improve from 1.31156
Epoch 998/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4159 - val_loss: 1.3161 - val_accuracy: 0.4107

Epoch 00998: val_loss did not improve from 1.31156
Epoch 999/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4165 - val_loss: 1.3163 - val_accuracy: 0.4147

Epoch 00999: val_loss did not improve from 1.31156
Epoch 1000/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4173 - val_loss: 1.3166 - val_accuracy: 0.3923

Epoch 01000: val_loss did not improve from 1.31156
Epoch 1001/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4163 - val_loss: 1.3131 - val_accuracy: 0.4083

Epoch 01001: val_loss did not improve from 1.31156
Epoch 1002/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4189 - val_loss: 1.3121 - val_accuracy: 0.4091

Epoch 01002: val_loss did not improve from 1.31156
Epoch 1003/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4229 - val_loss: 1.3163 - val_accuracy: 0.4099

Epoch 01003: val_loss did not improve from 1.31156
Epoch 1004/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4205 - val_loss: 1.3158 - val_accuracy: 0.4067

Epoch 01004: val_loss did not improve from 1.31156
Epoch 1005/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4210 - val_loss: 1.3147 - val_accuracy: 0.4171

Epoch 01005: val_loss did not improve from 1.31156
Epoch 1006/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4213 - val_loss: 1.3153 - val_accuracy: 0.4067

Epoch 01006: val_loss did not improve from 1.31156
Epoch 1007/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4215 - val_loss: 1.3153 - val_accuracy: 0.4099

Epoch 01007: val_loss did not improve from 1.31156
Epoch 1008/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4224 - val_loss: 1.3128 - val_accuracy: 0.4051

Epoch 01008: val_loss did not improve from 1.31156
Epoch 1009/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4209 - val_loss: 1.3117 - val_accuracy: 0.4147

Epoch 01009: val_loss did not improve from 1.31156
Epoch 1010/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4242 - val_loss: 1.3155 - val_accuracy: 0.4195

Epoch 01010: val_loss did not improve from 1.31156
Epoch 1011/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4188 - val_loss: 1.3166 - val_accuracy: 0.3995

Epoch 01011: val_loss did not improve from 1.31156
Epoch 1012/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4253 - val_loss: 1.3193 - val_accuracy: 0.4051

Epoch 01012: val_loss did not improve from 1.31156
Epoch 1013/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4219 - val_loss: 1.3150 - val_accuracy: 0.4091

Epoch 01013: val_loss did not improve from 1.31156
Epoch 1014/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4228 - val_loss: 1.3134 - val_accuracy: 0.4139

Epoch 01014: val_loss did not improve from 1.31156
Epoch 1015/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4225 - val_loss: 1.3157 - val_accuracy: 0.4115

Epoch 01015: val_loss did not improve from 1.31156
Epoch 1016/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4176 - val_loss: 1.3142 - val_accuracy: 0.4099

Epoch 01016: val_loss did not improve from 1.31156
Epoch 1017/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4219 - val_loss: 1.3165 - val_accuracy: 0.4051

Epoch 01017: val_loss did not improve from 1.31156
Epoch 1018/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4181 - val_loss: 1.3156 - val_accuracy: 0.4107

Epoch 01018: val_loss did not improve from 1.31156
Epoch 1019/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4185 - val_loss: 1.3149 - val_accuracy: 0.4075

Epoch 01019: val_loss did not improve from 1.31156
Epoch 1020/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4202 - val_loss: 1.3124 - val_accuracy: 0.4083

Epoch 01020: val_loss did not improve from 1.31156
Epoch 1021/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4207 - val_loss: 1.3163 - val_accuracy: 0.4107

Epoch 01021: val_loss did not improve from 1.31156
Epoch 1022/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4240 - val_loss: 1.3186 - val_accuracy: 0.4035

Epoch 01022: val_loss did not improve from 1.31156
Epoch 1023/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4178 - val_loss: 1.3136 - val_accuracy: 0.4059

Epoch 01023: val_loss did not improve from 1.31156
Epoch 1024/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4172 - val_loss: 1.3141 - val_accuracy: 0.4123

Epoch 01024: val_loss did not improve from 1.31156
Epoch 1025/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4205 - val_loss: 1.3127 - val_accuracy: 0.4059

Epoch 01025: val_loss did not improve from 1.31156
Epoch 1026/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4225 - val_loss: 1.3151 - val_accuracy: 0.4123

Epoch 01026: val_loss did not improve from 1.31156
Epoch 1027/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4225 - val_loss: 1.3140 - val_accuracy: 0.4155

Epoch 01027: val_loss did not improve from 1.31156
Epoch 1028/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4208 - val_loss: 1.3161 - val_accuracy: 0.4075

Epoch 01028: val_loss did not improve from 1.31156
Epoch 1029/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4225 - val_loss: 1.3149 - val_accuracy: 0.4163

Epoch 01029: val_loss did not improve from 1.31156
Epoch 1030/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4204 - val_loss: 1.3169 - val_accuracy: 0.4139

Epoch 01030: val_loss did not improve from 1.31156
Epoch 1031/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4196 - val_loss: 1.3145 - val_accuracy: 0.4107

Epoch 01031: val_loss did not improve from 1.31156
Epoch 1032/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4189 - val_loss: 1.3149 - val_accuracy: 0.4179

Epoch 01032: val_loss did not improve from 1.31156
Epoch 1033/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4221 - val_loss: 1.3163 - val_accuracy: 0.4139

Epoch 01033: val_loss did not improve from 1.31156
Epoch 1034/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4191 - val_loss: 1.3149 - val_accuracy: 0.4075

Epoch 01034: val_loss did not improve from 1.31156
Epoch 1035/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4222 - val_loss: 1.3130 - val_accuracy: 0.4131

Epoch 01035: val_loss did not improve from 1.31156
Epoch 1036/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4187 - val_loss: 1.3133 - val_accuracy: 0.4051

Epoch 01036: val_loss did not improve from 1.31156
Epoch 1037/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4209 - val_loss: 1.3172 - val_accuracy: 0.4131

Epoch 01037: val_loss did not improve from 1.31156
Epoch 1038/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4228 - val_loss: 1.3145 - val_accuracy: 0.4131

Epoch 01038: val_loss did not improve from 1.31156
Epoch 1039/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4250 - val_loss: 1.3182 - val_accuracy: 0.4067

Epoch 01039: val_loss did not improve from 1.31156
Epoch 1040/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4160 - val_loss: 1.3152 - val_accuracy: 0.4075

Epoch 01040: val_loss did not improve from 1.31156
Epoch 1041/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4228 - val_loss: 1.3204 - val_accuracy: 0.4091

Epoch 01041: val_loss did not improve from 1.31156
Epoch 1042/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4212 - val_loss: 1.3127 - val_accuracy: 0.4091

Epoch 01042: val_loss did not improve from 1.31156
Epoch 1043/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4252 - val_loss: 1.3160 - val_accuracy: 0.4091

Epoch 01043: val_loss did not improve from 1.31156
Epoch 1044/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4200 - val_loss: 1.3154 - val_accuracy: 0.4171

Epoch 01044: val_loss did not improve from 1.31156
Epoch 1045/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4256 - val_loss: 1.3121 - val_accuracy: 0.4115

Epoch 01045: val_loss did not improve from 1.31156
Epoch 1046/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4212 - val_loss: 1.3182 - val_accuracy: 0.4067

Epoch 01046: val_loss did not improve from 1.31156
Epoch 1047/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4179 - val_loss: 1.3179 - val_accuracy: 0.4115

Epoch 01047: val_loss did not improve from 1.31156
Epoch 1048/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4179 - val_loss: 1.3141 - val_accuracy: 0.4203

Epoch 01048: val_loss did not improve from 1.31156
Epoch 1049/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4203 - val_loss: 1.3132 - val_accuracy: 0.4099

Epoch 01049: val_loss did not improve from 1.31156
Epoch 1050/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4211 - val_loss: 1.3145 - val_accuracy: 0.4083

Epoch 01050: val_loss did not improve from 1.31156
Epoch 1051/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4218 - val_loss: 1.3199 - val_accuracy: 0.3995

Epoch 01051: val_loss did not improve from 1.31156
Epoch 1052/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4185 - val_loss: 1.3153 - val_accuracy: 0.4051

Epoch 01052: val_loss did not improve from 1.31156
Epoch 1053/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4210 - val_loss: 1.3152 - val_accuracy: 0.4059

Epoch 01053: val_loss did not improve from 1.31156
Epoch 1054/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4191 - val_loss: 1.3140 - val_accuracy: 0.4147

Epoch 01054: val_loss did not improve from 1.31156
Epoch 1055/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4187 - val_loss: 1.3161 - val_accuracy: 0.4203

Epoch 01055: val_loss did not improve from 1.31156
Epoch 1056/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4210 - val_loss: 1.3136 - val_accuracy: 0.4099

Epoch 01056: val_loss did not improve from 1.31156
Epoch 1057/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4201 - val_loss: 1.3174 - val_accuracy: 0.4075

Epoch 01057: val_loss did not improve from 1.31156
Epoch 1058/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4241 - val_loss: 1.3138 - val_accuracy: 0.4139

Epoch 01058: val_loss did not improve from 1.31156
Epoch 1059/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4252 - val_loss: 1.3207 - val_accuracy: 0.4099

Epoch 01059: val_loss did not improve from 1.31156
Epoch 1060/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4239 - val_loss: 1.3165 - val_accuracy: 0.4163

Epoch 01060: val_loss did not improve from 1.31156
Epoch 1061/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4213 - val_loss: 1.3131 - val_accuracy: 0.4139

Epoch 01061: val_loss did not improve from 1.31156
Epoch 1062/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4276 - val_loss: 1.3126 - val_accuracy: 0.4091

Epoch 01062: val_loss did not improve from 1.31156
Epoch 1063/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4202 - val_loss: 1.3118 - val_accuracy: 0.4139

Epoch 01063: val_loss did not improve from 1.31156
Epoch 1064/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4205 - val_loss: 1.3145 - val_accuracy: 0.4187

Epoch 01064: val_loss did not improve from 1.31156
Epoch 1065/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4149 - val_loss: 1.3160 - val_accuracy: 0.4147

Epoch 01065: val_loss did not improve from 1.31156
Epoch 1066/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4184 - val_loss: 1.3135 - val_accuracy: 0.4075

Epoch 01066: val_loss did not improve from 1.31156
Epoch 1067/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4209 - val_loss: 1.3118 - val_accuracy: 0.4179

Epoch 01067: val_loss did not improve from 1.31156
Epoch 1068/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4228 - val_loss: 1.3110 - val_accuracy: 0.4139

Epoch 01068: val_loss improved from 1.31156 to 1.31102, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1069/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4243 - val_loss: 1.3135 - val_accuracy: 0.4099

Epoch 01069: val_loss did not improve from 1.31102
Epoch 1070/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4194 - val_loss: 1.3147 - val_accuracy: 0.4123

Epoch 01070: val_loss did not improve from 1.31102
Epoch 1071/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4210 - val_loss: 1.3141 - val_accuracy: 0.4139

Epoch 01071: val_loss did not improve from 1.31102
Epoch 1072/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4184 - val_loss: 1.3120 - val_accuracy: 0.4051

Epoch 01072: val_loss did not improve from 1.31102
Epoch 1073/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4196 - val_loss: 1.3117 - val_accuracy: 0.4195

Epoch 01073: val_loss did not improve from 1.31102
Epoch 1074/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4185 - val_loss: 1.3205 - val_accuracy: 0.4043

Epoch 01074: val_loss did not improve from 1.31102
Epoch 1075/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4224 - val_loss: 1.3139 - val_accuracy: 0.4123

Epoch 01075: val_loss did not improve from 1.31102
Epoch 1076/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4208 - val_loss: 1.3145 - val_accuracy: 0.4067

Epoch 01076: val_loss did not improve from 1.31102
Epoch 1077/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4225 - val_loss: 1.3139 - val_accuracy: 0.4187

Epoch 01077: val_loss did not improve from 1.31102
Epoch 1078/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4233 - val_loss: 1.3137 - val_accuracy: 0.4147

Epoch 01078: val_loss did not improve from 1.31102
Epoch 1079/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4179 - val_loss: 1.3167 - val_accuracy: 0.4171

Epoch 01079: val_loss did not improve from 1.31102
Epoch 1080/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4204 - val_loss: 1.3116 - val_accuracy: 0.4147

Epoch 01080: val_loss did not improve from 1.31102
Epoch 1081/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4228 - val_loss: 1.3122 - val_accuracy: 0.4171

Epoch 01081: val_loss did not improve from 1.31102
Epoch 1082/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4226 - val_loss: 1.3121 - val_accuracy: 0.4163

Epoch 01082: val_loss did not improve from 1.31102
Epoch 1083/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4228 - val_loss: 1.3155 - val_accuracy: 0.4091

Epoch 01083: val_loss did not improve from 1.31102
Epoch 1084/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4205 - val_loss: 1.3127 - val_accuracy: 0.4171

Epoch 01084: val_loss did not improve from 1.31102
Epoch 1085/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4218 - val_loss: 1.3092 - val_accuracy: 0.4203

Epoch 01085: val_loss improved from 1.31102 to 1.30918, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1086/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4243 - val_loss: 1.3094 - val_accuracy: 0.4179

Epoch 01086: val_loss did not improve from 1.30918
Epoch 1087/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4210 - val_loss: 1.3131 - val_accuracy: 0.4163

Epoch 01087: val_loss did not improve from 1.30918
Epoch 1088/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4229 - val_loss: 1.3151 - val_accuracy: 0.4163

Epoch 01088: val_loss did not improve from 1.30918
Epoch 1089/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4237 - val_loss: 1.3123 - val_accuracy: 0.4171

Epoch 01089: val_loss did not improve from 1.30918
Epoch 1090/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4230 - val_loss: 1.3139 - val_accuracy: 0.4179

Epoch 01090: val_loss did not improve from 1.30918
Epoch 1091/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4237 - val_loss: 1.3127 - val_accuracy: 0.4211

Epoch 01091: val_loss did not improve from 1.30918
Epoch 1092/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4200 - val_loss: 1.3140 - val_accuracy: 0.4067

Epoch 01092: val_loss did not improve from 1.30918
Epoch 1093/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4169 - val_loss: 1.3149 - val_accuracy: 0.4115

Epoch 01093: val_loss did not improve from 1.30918
Epoch 1094/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4196 - val_loss: 1.3129 - val_accuracy: 0.4107

Epoch 01094: val_loss did not improve from 1.30918
Epoch 1095/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4224 - val_loss: 1.3118 - val_accuracy: 0.4115

Epoch 01095: val_loss did not improve from 1.30918
Epoch 1096/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4194 - val_loss: 1.3113 - val_accuracy: 0.4131

Epoch 01096: val_loss did not improve from 1.30918
Epoch 1097/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4237 - val_loss: 1.3134 - val_accuracy: 0.4123

Epoch 01097: val_loss did not improve from 1.30918
Epoch 1098/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4236 - val_loss: 1.3127 - val_accuracy: 0.4155

Epoch 01098: val_loss did not improve from 1.30918
Epoch 1099/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4252 - val_loss: 1.3171 - val_accuracy: 0.4043

Epoch 01099: val_loss did not improve from 1.30918
Epoch 1100/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4202 - val_loss: 1.3172 - val_accuracy: 0.4059

Epoch 01100: val_loss did not improve from 1.30918
Epoch 1101/10000
12/12 - 0s - loss: 1.2786 - accuracy: 0.4171 - val_loss: 1.3107 - val_accuracy: 0.4203

Epoch 01101: val_loss did not improve from 1.30918
Epoch 1102/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4251 - val_loss: 1.3112 - val_accuracy: 0.4123

Epoch 01102: val_loss did not improve from 1.30918
Epoch 1103/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4227 - val_loss: 1.3123 - val_accuracy: 0.4195

Epoch 01103: val_loss did not improve from 1.30918
Epoch 1104/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4250 - val_loss: 1.3133 - val_accuracy: 0.4195

Epoch 01104: val_loss did not improve from 1.30918
Epoch 1105/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4258 - val_loss: 1.3137 - val_accuracy: 0.4179

Epoch 01105: val_loss did not improve from 1.30918
Epoch 1106/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4244 - val_loss: 1.3131 - val_accuracy: 0.4107

Epoch 01106: val_loss did not improve from 1.30918
Epoch 1107/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4225 - val_loss: 1.3199 - val_accuracy: 0.4051

Epoch 01107: val_loss did not improve from 1.30918
Epoch 1108/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4185 - val_loss: 1.3154 - val_accuracy: 0.4107

Epoch 01108: val_loss did not improve from 1.30918
Epoch 1109/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4225 - val_loss: 1.3115 - val_accuracy: 0.4187

Epoch 01109: val_loss did not improve from 1.30918
Epoch 1110/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4242 - val_loss: 1.3130 - val_accuracy: 0.4179

Epoch 01110: val_loss did not improve from 1.30918
Epoch 1111/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4224 - val_loss: 1.3160 - val_accuracy: 0.4139

Epoch 01111: val_loss did not improve from 1.30918
Epoch 1112/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4234 - val_loss: 1.3130 - val_accuracy: 0.4187

Epoch 01112: val_loss did not improve from 1.30918
Epoch 1113/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4255 - val_loss: 1.3124 - val_accuracy: 0.4171

Epoch 01113: val_loss did not improve from 1.30918
Epoch 1114/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4226 - val_loss: 1.3131 - val_accuracy: 0.4075

Epoch 01114: val_loss did not improve from 1.30918
Epoch 1115/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4249 - val_loss: 1.3159 - val_accuracy: 0.4139

Epoch 01115: val_loss did not improve from 1.30918
Epoch 1116/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4217 - val_loss: 1.3119 - val_accuracy: 0.4250

Epoch 01116: val_loss did not improve from 1.30918
Epoch 1117/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4260 - val_loss: 1.3115 - val_accuracy: 0.4179

Epoch 01117: val_loss did not improve from 1.30918
Epoch 1118/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4217 - val_loss: 1.3149 - val_accuracy: 0.4099

Epoch 01118: val_loss did not improve from 1.30918
Epoch 1119/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4218 - val_loss: 1.3139 - val_accuracy: 0.4139

Epoch 01119: val_loss did not improve from 1.30918
Epoch 1120/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4241 - val_loss: 1.3088 - val_accuracy: 0.4123

Epoch 01120: val_loss improved from 1.30918 to 1.30884, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1121/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4248 - val_loss: 1.3067 - val_accuracy: 0.4219

Epoch 01121: val_loss improved from 1.30884 to 1.30672, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1122/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4211 - val_loss: 1.3123 - val_accuracy: 0.4075

Epoch 01122: val_loss did not improve from 1.30672
Epoch 1123/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4225 - val_loss: 1.3094 - val_accuracy: 0.4250

Epoch 01123: val_loss did not improve from 1.30672
Epoch 1124/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4210 - val_loss: 1.3074 - val_accuracy: 0.4163

Epoch 01124: val_loss did not improve from 1.30672
Epoch 1125/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4249 - val_loss: 1.3112 - val_accuracy: 0.4195

Epoch 01125: val_loss did not improve from 1.30672
Epoch 1126/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4249 - val_loss: 1.3117 - val_accuracy: 0.4211

Epoch 01126: val_loss did not improve from 1.30672
Epoch 1127/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4238 - val_loss: 1.3135 - val_accuracy: 0.4195

Epoch 01127: val_loss did not improve from 1.30672
Epoch 1128/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4252 - val_loss: 1.3107 - val_accuracy: 0.4203

Epoch 01128: val_loss did not improve from 1.30672
Epoch 1129/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4282 - val_loss: 1.3122 - val_accuracy: 0.4187

Epoch 01129: val_loss did not improve from 1.30672
Epoch 1130/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4233 - val_loss: 1.3124 - val_accuracy: 0.4258

Epoch 01130: val_loss did not improve from 1.30672
Epoch 1131/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4253 - val_loss: 1.3107 - val_accuracy: 0.4155

Epoch 01131: val_loss did not improve from 1.30672
Epoch 1132/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4258 - val_loss: 1.3096 - val_accuracy: 0.4171

Epoch 01132: val_loss did not improve from 1.30672
Epoch 1133/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4193 - val_loss: 1.3112 - val_accuracy: 0.4226

Epoch 01133: val_loss did not improve from 1.30672
Epoch 1134/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4241 - val_loss: 1.3093 - val_accuracy: 0.4219

Epoch 01134: val_loss did not improve from 1.30672
Epoch 1135/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4257 - val_loss: 1.3110 - val_accuracy: 0.4171

Epoch 01135: val_loss did not improve from 1.30672
Epoch 1136/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4253 - val_loss: 1.3132 - val_accuracy: 0.4226

Epoch 01136: val_loss did not improve from 1.30672
Epoch 1137/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4251 - val_loss: 1.3096 - val_accuracy: 0.4203

Epoch 01137: val_loss did not improve from 1.30672
Epoch 1138/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4229 - val_loss: 1.3123 - val_accuracy: 0.4147

Epoch 01138: val_loss did not improve from 1.30672
Epoch 1139/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4236 - val_loss: 1.3115 - val_accuracy: 0.4139

Epoch 01139: val_loss did not improve from 1.30672
Epoch 1140/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4228 - val_loss: 1.3128 - val_accuracy: 0.4155

Epoch 01140: val_loss did not improve from 1.30672
Epoch 1141/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4239 - val_loss: 1.3125 - val_accuracy: 0.4179

Epoch 01141: val_loss did not improve from 1.30672
Epoch 1142/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4258 - val_loss: 1.3117 - val_accuracy: 0.4171

Epoch 01142: val_loss did not improve from 1.30672
Epoch 1143/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4174 - val_loss: 1.3135 - val_accuracy: 0.4171

Epoch 01143: val_loss did not improve from 1.30672
Epoch 1144/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4225 - val_loss: 1.3117 - val_accuracy: 0.4051

Epoch 01144: val_loss did not improve from 1.30672
Epoch 1145/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4251 - val_loss: 1.3148 - val_accuracy: 0.4107

Epoch 01145: val_loss did not improve from 1.30672
Epoch 1146/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4242 - val_loss: 1.3174 - val_accuracy: 0.4115

Epoch 01146: val_loss did not improve from 1.30672
Epoch 1147/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4259 - val_loss: 1.3121 - val_accuracy: 0.4250

Epoch 01147: val_loss did not improve from 1.30672
Epoch 1148/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4210 - val_loss: 1.3095 - val_accuracy: 0.4115

Epoch 01148: val_loss did not improve from 1.30672
Epoch 1149/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4187 - val_loss: 1.3103 - val_accuracy: 0.4147

Epoch 01149: val_loss did not improve from 1.30672
Epoch 1150/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4232 - val_loss: 1.3119 - val_accuracy: 0.4155

Epoch 01150: val_loss did not improve from 1.30672
Epoch 1151/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4266 - val_loss: 1.3125 - val_accuracy: 0.4195

Epoch 01151: val_loss did not improve from 1.30672
Epoch 1152/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4255 - val_loss: 1.3108 - val_accuracy: 0.4131

Epoch 01152: val_loss did not improve from 1.30672
Epoch 1153/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4243 - val_loss: 1.3109 - val_accuracy: 0.4115

Epoch 01153: val_loss did not improve from 1.30672
Epoch 1154/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4238 - val_loss: 1.3201 - val_accuracy: 0.4107

Epoch 01154: val_loss did not improve from 1.30672
Epoch 1155/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4205 - val_loss: 1.3107 - val_accuracy: 0.4139

Epoch 01155: val_loss did not improve from 1.30672
Epoch 1156/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4232 - val_loss: 1.3078 - val_accuracy: 0.4083

Epoch 01156: val_loss did not improve from 1.30672
Epoch 1157/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4233 - val_loss: 1.3091 - val_accuracy: 0.4147

Epoch 01157: val_loss did not improve from 1.30672
Epoch 1158/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4202 - val_loss: 1.3084 - val_accuracy: 0.4163

Epoch 01158: val_loss did not improve from 1.30672
Epoch 1159/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4217 - val_loss: 1.3143 - val_accuracy: 0.4067

Epoch 01159: val_loss did not improve from 1.30672
Epoch 1160/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4217 - val_loss: 1.3151 - val_accuracy: 0.4115

Epoch 01160: val_loss did not improve from 1.30672
Epoch 1161/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4218 - val_loss: 1.3117 - val_accuracy: 0.4139

Epoch 01161: val_loss did not improve from 1.30672
Epoch 1162/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4218 - val_loss: 1.3120 - val_accuracy: 0.4075

Epoch 01162: val_loss did not improve from 1.30672
Epoch 1163/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4257 - val_loss: 1.3206 - val_accuracy: 0.4123

Epoch 01163: val_loss did not improve from 1.30672
Epoch 1164/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4223 - val_loss: 1.3125 - val_accuracy: 0.4131

Epoch 01164: val_loss did not improve from 1.30672
Epoch 1165/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4262 - val_loss: 1.3115 - val_accuracy: 0.4083

Epoch 01165: val_loss did not improve from 1.30672
Epoch 1166/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4207 - val_loss: 1.3100 - val_accuracy: 0.4163

Epoch 01166: val_loss did not improve from 1.30672
Epoch 1167/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4243 - val_loss: 1.3120 - val_accuracy: 0.4163

Epoch 01167: val_loss did not improve from 1.30672
Epoch 1168/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4258 - val_loss: 1.3093 - val_accuracy: 0.4195

Epoch 01168: val_loss did not improve from 1.30672
Epoch 1169/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4240 - val_loss: 1.3178 - val_accuracy: 0.4139

Epoch 01169: val_loss did not improve from 1.30672
Epoch 1170/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4234 - val_loss: 1.3107 - val_accuracy: 0.4171

Epoch 01170: val_loss did not improve from 1.30672
Epoch 1171/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4238 - val_loss: 1.3110 - val_accuracy: 0.4115

Epoch 01171: val_loss did not improve from 1.30672
Epoch 1172/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4241 - val_loss: 1.3113 - val_accuracy: 0.4059

Epoch 01172: val_loss did not improve from 1.30672
Epoch 1173/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4256 - val_loss: 1.3111 - val_accuracy: 0.4091

Epoch 01173: val_loss did not improve from 1.30672
Epoch 1174/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4233 - val_loss: 1.3118 - val_accuracy: 0.4107

Epoch 01174: val_loss did not improve from 1.30672
Epoch 1175/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4269 - val_loss: 1.3099 - val_accuracy: 0.4226

Epoch 01175: val_loss did not improve from 1.30672
Epoch 1176/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4277 - val_loss: 1.3139 - val_accuracy: 0.4123

Epoch 01176: val_loss did not improve from 1.30672
Epoch 1177/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4215 - val_loss: 1.3146 - val_accuracy: 0.4131

Epoch 01177: val_loss did not improve from 1.30672
Epoch 1178/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4239 - val_loss: 1.3118 - val_accuracy: 0.4107

Epoch 01178: val_loss did not improve from 1.30672
Epoch 1179/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4241 - val_loss: 1.3086 - val_accuracy: 0.4211

Epoch 01179: val_loss did not improve from 1.30672
Epoch 1180/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4194 - val_loss: 1.3126 - val_accuracy: 0.4067

Epoch 01180: val_loss did not improve from 1.30672
Epoch 1181/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4172 - val_loss: 1.3116 - val_accuracy: 0.4099

Epoch 01181: val_loss did not improve from 1.30672
Epoch 1182/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4280 - val_loss: 1.3082 - val_accuracy: 0.4171

Epoch 01182: val_loss did not improve from 1.30672
Epoch 1183/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4262 - val_loss: 1.3080 - val_accuracy: 0.4258

Epoch 01183: val_loss did not improve from 1.30672
Epoch 1184/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4264 - val_loss: 1.3100 - val_accuracy: 0.4274

Epoch 01184: val_loss did not improve from 1.30672
Epoch 1185/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4237 - val_loss: 1.3119 - val_accuracy: 0.4083

Epoch 01185: val_loss did not improve from 1.30672
Epoch 1186/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4243 - val_loss: 1.3094 - val_accuracy: 0.4187

Epoch 01186: val_loss did not improve from 1.30672
Epoch 1187/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4249 - val_loss: 1.3059 - val_accuracy: 0.4131

Epoch 01187: val_loss improved from 1.30672 to 1.30590, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1188/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4222 - val_loss: 1.3094 - val_accuracy: 0.4187

Epoch 01188: val_loss did not improve from 1.30590
Epoch 1189/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4249 - val_loss: 1.3082 - val_accuracy: 0.4211

Epoch 01189: val_loss did not improve from 1.30590
Epoch 1190/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4237 - val_loss: 1.3096 - val_accuracy: 0.4123

Epoch 01190: val_loss did not improve from 1.30590
Epoch 1191/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4242 - val_loss: 1.3074 - val_accuracy: 0.4234

Epoch 01191: val_loss did not improve from 1.30590
Epoch 1192/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4256 - val_loss: 1.3110 - val_accuracy: 0.4171

Epoch 01192: val_loss did not improve from 1.30590
Epoch 1193/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4221 - val_loss: 1.3088 - val_accuracy: 0.4258

Epoch 01193: val_loss did not improve from 1.30590
Epoch 1194/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4263 - val_loss: 1.3106 - val_accuracy: 0.4115

Epoch 01194: val_loss did not improve from 1.30590
Epoch 1195/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4220 - val_loss: 1.3099 - val_accuracy: 0.4155

Epoch 01195: val_loss did not improve from 1.30590
Epoch 1196/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4256 - val_loss: 1.3083 - val_accuracy: 0.4266

Epoch 01196: val_loss did not improve from 1.30590
Epoch 1197/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4246 - val_loss: 1.3074 - val_accuracy: 0.4171

Epoch 01197: val_loss did not improve from 1.30590
Epoch 1198/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4295 - val_loss: 1.3121 - val_accuracy: 0.4155

Epoch 01198: val_loss did not improve from 1.30590
Epoch 1199/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4280 - val_loss: 1.3119 - val_accuracy: 0.4195

Epoch 01199: val_loss did not improve from 1.30590
Epoch 1200/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4241 - val_loss: 1.3090 - val_accuracy: 0.4163

Epoch 01200: val_loss did not improve from 1.30590
Epoch 1201/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4224 - val_loss: 1.3087 - val_accuracy: 0.4139

Epoch 01201: val_loss did not improve from 1.30590
Epoch 1202/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4254 - val_loss: 1.3175 - val_accuracy: 0.4075

Epoch 01202: val_loss did not improve from 1.30590
Epoch 1203/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4218 - val_loss: 1.3187 - val_accuracy: 0.4155

Epoch 01203: val_loss did not improve from 1.30590
Epoch 1204/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4262 - val_loss: 1.3087 - val_accuracy: 0.4195

Epoch 01204: val_loss did not improve from 1.30590
Epoch 1205/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4265 - val_loss: 1.3093 - val_accuracy: 0.4123

Epoch 01205: val_loss did not improve from 1.30590
Epoch 1206/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4201 - val_loss: 1.3096 - val_accuracy: 0.4131

Epoch 01206: val_loss did not improve from 1.30590
Epoch 1207/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4259 - val_loss: 1.3086 - val_accuracy: 0.4195

Epoch 01207: val_loss did not improve from 1.30590
Epoch 1208/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4252 - val_loss: 1.3113 - val_accuracy: 0.4163

Epoch 01208: val_loss did not improve from 1.30590
Epoch 1209/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4256 - val_loss: 1.3124 - val_accuracy: 0.4123

Epoch 01209: val_loss did not improve from 1.30590
Epoch 1210/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4258 - val_loss: 1.3088 - val_accuracy: 0.4187

Epoch 01210: val_loss did not improve from 1.30590
Epoch 1211/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4268 - val_loss: 1.3087 - val_accuracy: 0.4179

Epoch 01211: val_loss did not improve from 1.30590
Epoch 1212/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4247 - val_loss: 1.3087 - val_accuracy: 0.4171

Epoch 01212: val_loss did not improve from 1.30590
Epoch 1213/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4206 - val_loss: 1.3117 - val_accuracy: 0.4179

Epoch 01213: val_loss did not improve from 1.30590
Epoch 1214/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4240 - val_loss: 1.3084 - val_accuracy: 0.4250

Epoch 01214: val_loss did not improve from 1.30590
Epoch 1215/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4266 - val_loss: 1.3079 - val_accuracy: 0.4179

Epoch 01215: val_loss did not improve from 1.30590
Epoch 1216/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4274 - val_loss: 1.3086 - val_accuracy: 0.4163

Epoch 01216: val_loss did not improve from 1.30590
Epoch 1217/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4286 - val_loss: 1.3083 - val_accuracy: 0.4115

Epoch 01217: val_loss did not improve from 1.30590
Epoch 1218/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4251 - val_loss: 1.3162 - val_accuracy: 0.4139

Epoch 01218: val_loss did not improve from 1.30590
Epoch 1219/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4203 - val_loss: 1.3087 - val_accuracy: 0.4171

Epoch 01219: val_loss did not improve from 1.30590
Epoch 1220/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4253 - val_loss: 1.3094 - val_accuracy: 0.4131

Epoch 01220: val_loss did not improve from 1.30590
Epoch 1221/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4257 - val_loss: 1.3086 - val_accuracy: 0.4195

Epoch 01221: val_loss did not improve from 1.30590
Epoch 1222/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4291 - val_loss: 1.3118 - val_accuracy: 0.4163

Epoch 01222: val_loss did not improve from 1.30590
Epoch 1223/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4241 - val_loss: 1.3098 - val_accuracy: 0.4219

Epoch 01223: val_loss did not improve from 1.30590
Epoch 1224/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4249 - val_loss: 1.3122 - val_accuracy: 0.4139

Epoch 01224: val_loss did not improve from 1.30590
Epoch 1225/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4236 - val_loss: 1.3084 - val_accuracy: 0.4171

Epoch 01225: val_loss did not improve from 1.30590
Epoch 1226/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4248 - val_loss: 1.3053 - val_accuracy: 0.4203

Epoch 01226: val_loss improved from 1.30590 to 1.30531, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1227/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4249 - val_loss: 1.3141 - val_accuracy: 0.4147

Epoch 01227: val_loss did not improve from 1.30531
Epoch 1228/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4248 - val_loss: 1.3088 - val_accuracy: 0.4266

Epoch 01228: val_loss did not improve from 1.30531
Epoch 1229/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4257 - val_loss: 1.3083 - val_accuracy: 0.4195

Epoch 01229: val_loss did not improve from 1.30531
Epoch 1230/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4242 - val_loss: 1.3156 - val_accuracy: 0.4107

Epoch 01230: val_loss did not improve from 1.30531
Epoch 1231/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4257 - val_loss: 1.3080 - val_accuracy: 0.4195

Epoch 01231: val_loss did not improve from 1.30531
Epoch 1232/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4274 - val_loss: 1.3057 - val_accuracy: 0.4203

Epoch 01232: val_loss did not improve from 1.30531
Epoch 1233/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4249 - val_loss: 1.3083 - val_accuracy: 0.4171

Epoch 01233: val_loss did not improve from 1.30531
Epoch 1234/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4216 - val_loss: 1.3127 - val_accuracy: 0.4163

Epoch 01234: val_loss did not improve from 1.30531
Epoch 1235/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4286 - val_loss: 1.3079 - val_accuracy: 0.4226

Epoch 01235: val_loss did not improve from 1.30531
Epoch 1236/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4256 - val_loss: 1.3078 - val_accuracy: 0.4123

Epoch 01236: val_loss did not improve from 1.30531
Epoch 1237/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4245 - val_loss: 1.3097 - val_accuracy: 0.4155

Epoch 01237: val_loss did not improve from 1.30531
Epoch 1238/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4203 - val_loss: 1.3085 - val_accuracy: 0.4155

Epoch 01238: val_loss did not improve from 1.30531
Epoch 1239/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4228 - val_loss: 1.3074 - val_accuracy: 0.4091

Epoch 01239: val_loss did not improve from 1.30531
Epoch 1240/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4275 - val_loss: 1.3126 - val_accuracy: 0.4131

Epoch 01240: val_loss did not improve from 1.30531
Epoch 1241/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4292 - val_loss: 1.3104 - val_accuracy: 0.4131

Epoch 01241: val_loss did not improve from 1.30531
Epoch 1242/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4260 - val_loss: 1.3102 - val_accuracy: 0.4171

Epoch 01242: val_loss did not improve from 1.30531
Epoch 1243/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4278 - val_loss: 1.3128 - val_accuracy: 0.4179

Epoch 01243: val_loss did not improve from 1.30531
Epoch 1244/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4193 - val_loss: 1.3098 - val_accuracy: 0.4155

Epoch 01244: val_loss did not improve from 1.30531
Epoch 1245/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4266 - val_loss: 1.3070 - val_accuracy: 0.4219

Epoch 01245: val_loss did not improve from 1.30531
Epoch 1246/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4320 - val_loss: 1.3178 - val_accuracy: 0.4155

Epoch 01246: val_loss did not improve from 1.30531
Epoch 1247/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4261 - val_loss: 1.3082 - val_accuracy: 0.4219

Epoch 01247: val_loss did not improve from 1.30531
Epoch 1248/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4239 - val_loss: 1.3087 - val_accuracy: 0.4187

Epoch 01248: val_loss did not improve from 1.30531
Epoch 1249/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4275 - val_loss: 1.3098 - val_accuracy: 0.4163

Epoch 01249: val_loss did not improve from 1.30531
Epoch 1250/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4278 - val_loss: 1.3105 - val_accuracy: 0.4163

Epoch 01250: val_loss did not improve from 1.30531
Epoch 1251/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4257 - val_loss: 1.3093 - val_accuracy: 0.4250

Epoch 01251: val_loss did not improve from 1.30531
Epoch 1252/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4251 - val_loss: 1.3081 - val_accuracy: 0.4115

Epoch 01252: val_loss did not improve from 1.30531
Epoch 1253/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4229 - val_loss: 1.3175 - val_accuracy: 0.4059

Epoch 01253: val_loss did not improve from 1.30531
Epoch 1254/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4252 - val_loss: 1.3086 - val_accuracy: 0.4226

Epoch 01254: val_loss did not improve from 1.30531
Epoch 1255/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4263 - val_loss: 1.3063 - val_accuracy: 0.4147

Epoch 01255: val_loss did not improve from 1.30531
Epoch 1256/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4260 - val_loss: 1.3089 - val_accuracy: 0.4163

Epoch 01256: val_loss did not improve from 1.30531
Epoch 1257/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4262 - val_loss: 1.3076 - val_accuracy: 0.4091

Epoch 01257: val_loss did not improve from 1.30531
Epoch 1258/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4245 - val_loss: 1.3082 - val_accuracy: 0.4219

Epoch 01258: val_loss did not improve from 1.30531
Epoch 1259/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4253 - val_loss: 1.3113 - val_accuracy: 0.4155

Epoch 01259: val_loss did not improve from 1.30531
Epoch 1260/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4291 - val_loss: 1.3089 - val_accuracy: 0.4226

Epoch 01260: val_loss did not improve from 1.30531
Epoch 1261/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4293 - val_loss: 1.3077 - val_accuracy: 0.4139

Epoch 01261: val_loss did not improve from 1.30531
Epoch 1262/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4214 - val_loss: 1.3104 - val_accuracy: 0.4163

Epoch 01262: val_loss did not improve from 1.30531
Epoch 1263/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4240 - val_loss: 1.3082 - val_accuracy: 0.4211

Epoch 01263: val_loss did not improve from 1.30531
Epoch 1264/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4257 - val_loss: 1.3106 - val_accuracy: 0.4115

Epoch 01264: val_loss did not improve from 1.30531
Epoch 1265/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4295 - val_loss: 1.3093 - val_accuracy: 0.4179

Epoch 01265: val_loss did not improve from 1.30531
Epoch 1266/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4292 - val_loss: 1.3083 - val_accuracy: 0.4219

Epoch 01266: val_loss did not improve from 1.30531
Epoch 1267/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4275 - val_loss: 1.3159 - val_accuracy: 0.4139

Epoch 01267: val_loss did not improve from 1.30531
Epoch 1268/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4193 - val_loss: 1.3055 - val_accuracy: 0.4250

Epoch 01268: val_loss did not improve from 1.30531
Epoch 1269/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4216 - val_loss: 1.3110 - val_accuracy: 0.4187

Epoch 01269: val_loss did not improve from 1.30531
Epoch 1270/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4223 - val_loss: 1.3097 - val_accuracy: 0.4139

Epoch 01270: val_loss did not improve from 1.30531
Epoch 1271/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4249 - val_loss: 1.3084 - val_accuracy: 0.4187

Epoch 01271: val_loss did not improve from 1.30531
Epoch 1272/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4269 - val_loss: 1.3070 - val_accuracy: 0.4226

Epoch 01272: val_loss did not improve from 1.30531
Epoch 1273/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4275 - val_loss: 1.3084 - val_accuracy: 0.4163

Epoch 01273: val_loss did not improve from 1.30531
Epoch 1274/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4252 - val_loss: 1.3145 - val_accuracy: 0.4139

Epoch 01274: val_loss did not improve from 1.30531
Epoch 1275/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4275 - val_loss: 1.3069 - val_accuracy: 0.4266

Epoch 01275: val_loss did not improve from 1.30531
Epoch 1276/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4213 - val_loss: 1.3079 - val_accuracy: 0.4123

Epoch 01276: val_loss did not improve from 1.30531
Epoch 1277/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4268 - val_loss: 1.3124 - val_accuracy: 0.4107

Epoch 01277: val_loss did not improve from 1.30531
Epoch 1278/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4224 - val_loss: 1.3094 - val_accuracy: 0.4155

Epoch 01278: val_loss did not improve from 1.30531
Epoch 1279/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4286 - val_loss: 1.3071 - val_accuracy: 0.4163

Epoch 01279: val_loss did not improve from 1.30531
Epoch 1280/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4243 - val_loss: 1.3150 - val_accuracy: 0.4171

Epoch 01280: val_loss did not improve from 1.30531
Epoch 1281/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4261 - val_loss: 1.3110 - val_accuracy: 0.4147

Epoch 01281: val_loss did not improve from 1.30531
Epoch 1282/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4268 - val_loss: 1.3078 - val_accuracy: 0.4250

Epoch 01282: val_loss did not improve from 1.30531
Epoch 1283/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4268 - val_loss: 1.3129 - val_accuracy: 0.4187

Epoch 01283: val_loss did not improve from 1.30531
Epoch 1284/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4297 - val_loss: 1.3132 - val_accuracy: 0.4187

Epoch 01284: val_loss did not improve from 1.30531
Epoch 1285/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4280 - val_loss: 1.3062 - val_accuracy: 0.4147

Epoch 01285: val_loss did not improve from 1.30531
Epoch 1286/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4255 - val_loss: 1.3112 - val_accuracy: 0.4123

Epoch 01286: val_loss did not improve from 1.30531
Epoch 1287/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4235 - val_loss: 1.3100 - val_accuracy: 0.4139

Epoch 01287: val_loss did not improve from 1.30531
Epoch 1288/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4246 - val_loss: 1.3092 - val_accuracy: 0.4179

Epoch 01288: val_loss did not improve from 1.30531
Epoch 1289/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4276 - val_loss: 1.3090 - val_accuracy: 0.4203

Epoch 01289: val_loss did not improve from 1.30531
Epoch 1290/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4280 - val_loss: 1.3066 - val_accuracy: 0.4226

Epoch 01290: val_loss did not improve from 1.30531
Epoch 1291/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4238 - val_loss: 1.3066 - val_accuracy: 0.4179

Epoch 01291: val_loss did not improve from 1.30531
Epoch 1292/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4251 - val_loss: 1.3087 - val_accuracy: 0.4131

Epoch 01292: val_loss did not improve from 1.30531
Epoch 1293/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4277 - val_loss: 1.3078 - val_accuracy: 0.4234

Epoch 01293: val_loss did not improve from 1.30531
Epoch 1294/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4248 - val_loss: 1.3048 - val_accuracy: 0.4203

Epoch 01294: val_loss improved from 1.30531 to 1.30479, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1295/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4262 - val_loss: 1.3071 - val_accuracy: 0.4250

Epoch 01295: val_loss did not improve from 1.30479
Epoch 1296/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4295 - val_loss: 1.3070 - val_accuracy: 0.4195

Epoch 01296: val_loss did not improve from 1.30479
Epoch 1297/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4251 - val_loss: 1.3084 - val_accuracy: 0.4131

Epoch 01297: val_loss did not improve from 1.30479
Epoch 1298/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4244 - val_loss: 1.3081 - val_accuracy: 0.4171

Epoch 01298: val_loss did not improve from 1.30479
Epoch 1299/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4279 - val_loss: 1.3082 - val_accuracy: 0.4163

Epoch 01299: val_loss did not improve from 1.30479
Epoch 1300/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4256 - val_loss: 1.3076 - val_accuracy: 0.4147

Epoch 01300: val_loss did not improve from 1.30479
Epoch 1301/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4279 - val_loss: 1.3086 - val_accuracy: 0.4179

Epoch 01301: val_loss did not improve from 1.30479
Epoch 1302/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4258 - val_loss: 1.3088 - val_accuracy: 0.4187

Epoch 01302: val_loss did not improve from 1.30479
Epoch 1303/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4288 - val_loss: 1.3095 - val_accuracy: 0.4107

Epoch 01303: val_loss did not improve from 1.30479
Epoch 1304/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4256 - val_loss: 1.3083 - val_accuracy: 0.4171

Epoch 01304: val_loss did not improve from 1.30479
Epoch 1305/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4221 - val_loss: 1.3054 - val_accuracy: 0.4258

Epoch 01305: val_loss did not improve from 1.30479
Epoch 1306/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4241 - val_loss: 1.3058 - val_accuracy: 0.4242

Epoch 01306: val_loss did not improve from 1.30479
Epoch 1307/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4245 - val_loss: 1.3061 - val_accuracy: 0.4242

Epoch 01307: val_loss did not improve from 1.30479
Epoch 1308/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4264 - val_loss: 1.3153 - val_accuracy: 0.4123

Epoch 01308: val_loss did not improve from 1.30479
Epoch 1309/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4247 - val_loss: 1.3062 - val_accuracy: 0.4211

Epoch 01309: val_loss did not improve from 1.30479
Epoch 1310/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4286 - val_loss: 1.3100 - val_accuracy: 0.4139

Epoch 01310: val_loss did not improve from 1.30479
Epoch 1311/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4231 - val_loss: 1.3103 - val_accuracy: 0.4171

Epoch 01311: val_loss did not improve from 1.30479
Epoch 1312/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4235 - val_loss: 1.3045 - val_accuracy: 0.4211

Epoch 01312: val_loss improved from 1.30479 to 1.30448, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1313/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4252 - val_loss: 1.3099 - val_accuracy: 0.4099

Epoch 01313: val_loss did not improve from 1.30448
Epoch 1314/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4249 - val_loss: 1.3075 - val_accuracy: 0.4179

Epoch 01314: val_loss did not improve from 1.30448
Epoch 1315/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4263 - val_loss: 1.3078 - val_accuracy: 0.4139

Epoch 01315: val_loss did not improve from 1.30448
Epoch 1316/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4285 - val_loss: 1.3052 - val_accuracy: 0.4282

Epoch 01316: val_loss did not improve from 1.30448
Epoch 1317/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4276 - val_loss: 1.3091 - val_accuracy: 0.4139

Epoch 01317: val_loss did not improve from 1.30448
Epoch 1318/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4280 - val_loss: 1.3061 - val_accuracy: 0.4226

Epoch 01318: val_loss did not improve from 1.30448
Epoch 1319/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4293 - val_loss: 1.3084 - val_accuracy: 0.4187

Epoch 01319: val_loss did not improve from 1.30448
Epoch 1320/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4282 - val_loss: 1.3047 - val_accuracy: 0.4131

Epoch 01320: val_loss did not improve from 1.30448
Epoch 1321/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4225 - val_loss: 1.3055 - val_accuracy: 0.4147

Epoch 01321: val_loss did not improve from 1.30448
Epoch 1322/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4289 - val_loss: 1.3068 - val_accuracy: 0.4290

Epoch 01322: val_loss did not improve from 1.30448
Epoch 1323/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4258 - val_loss: 1.3066 - val_accuracy: 0.4211

Epoch 01323: val_loss did not improve from 1.30448
Epoch 1324/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4300 - val_loss: 1.3081 - val_accuracy: 0.4234

Epoch 01324: val_loss did not improve from 1.30448
Epoch 1325/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4286 - val_loss: 1.3104 - val_accuracy: 0.4147

Epoch 01325: val_loss did not improve from 1.30448
Epoch 1326/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4267 - val_loss: 1.3037 - val_accuracy: 0.4211

Epoch 01326: val_loss improved from 1.30448 to 1.30373, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1327/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4216 - val_loss: 1.3049 - val_accuracy: 0.4258

Epoch 01327: val_loss did not improve from 1.30373
Epoch 1328/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4320 - val_loss: 1.3088 - val_accuracy: 0.4203

Epoch 01328: val_loss did not improve from 1.30373
Epoch 1329/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4271 - val_loss: 1.3066 - val_accuracy: 0.4171

Epoch 01329: val_loss did not improve from 1.30373
Epoch 1330/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4286 - val_loss: 1.3042 - val_accuracy: 0.4171

Epoch 01330: val_loss did not improve from 1.30373
Epoch 1331/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4305 - val_loss: 1.3073 - val_accuracy: 0.4219

Epoch 01331: val_loss did not improve from 1.30373
Epoch 1332/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4256 - val_loss: 1.3071 - val_accuracy: 0.4203

Epoch 01332: val_loss did not improve from 1.30373
Epoch 1333/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4303 - val_loss: 1.3059 - val_accuracy: 0.4187

Epoch 01333: val_loss did not improve from 1.30373
Epoch 1334/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4261 - val_loss: 1.3061 - val_accuracy: 0.4258

Epoch 01334: val_loss did not improve from 1.30373
Epoch 1335/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4242 - val_loss: 1.3083 - val_accuracy: 0.4219

Epoch 01335: val_loss did not improve from 1.30373
Epoch 1336/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4308 - val_loss: 1.3105 - val_accuracy: 0.4234

Epoch 01336: val_loss did not improve from 1.30373
Epoch 1337/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4308 - val_loss: 1.3058 - val_accuracy: 0.4314

Epoch 01337: val_loss did not improve from 1.30373
Epoch 1338/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4323 - val_loss: 1.3104 - val_accuracy: 0.4155

Epoch 01338: val_loss did not improve from 1.30373
Epoch 1339/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4255 - val_loss: 1.3075 - val_accuracy: 0.4187

Epoch 01339: val_loss did not improve from 1.30373
Epoch 1340/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4299 - val_loss: 1.3077 - val_accuracy: 0.4179

Epoch 01340: val_loss did not improve from 1.30373
Epoch 1341/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4256 - val_loss: 1.3077 - val_accuracy: 0.4250

Epoch 01341: val_loss did not improve from 1.30373
Epoch 1342/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4250 - val_loss: 1.3057 - val_accuracy: 0.4171

Epoch 01342: val_loss did not improve from 1.30373
Epoch 1343/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4303 - val_loss: 1.3047 - val_accuracy: 0.4226

Epoch 01343: val_loss did not improve from 1.30373
Epoch 1344/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4285 - val_loss: 1.3064 - val_accuracy: 0.4234

Epoch 01344: val_loss did not improve from 1.30373
Epoch 1345/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4275 - val_loss: 1.3103 - val_accuracy: 0.4115

Epoch 01345: val_loss did not improve from 1.30373
Epoch 1346/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4284 - val_loss: 1.3080 - val_accuracy: 0.4226

Epoch 01346: val_loss did not improve from 1.30373
Epoch 1347/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4296 - val_loss: 1.3102 - val_accuracy: 0.4226

Epoch 01347: val_loss did not improve from 1.30373
Epoch 1348/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4303 - val_loss: 1.3060 - val_accuracy: 0.4274

Epoch 01348: val_loss did not improve from 1.30373
Epoch 1349/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4280 - val_loss: 1.3046 - val_accuracy: 0.4171

Epoch 01349: val_loss did not improve from 1.30373
Epoch 1350/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4282 - val_loss: 1.3036 - val_accuracy: 0.4242

Epoch 01350: val_loss improved from 1.30373 to 1.30362, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1351/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4284 - val_loss: 1.3051 - val_accuracy: 0.4139

Epoch 01351: val_loss did not improve from 1.30362
Epoch 1352/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4225 - val_loss: 1.3046 - val_accuracy: 0.4234

Epoch 01352: val_loss did not improve from 1.30362
Epoch 1353/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4261 - val_loss: 1.3050 - val_accuracy: 0.4242

Epoch 01353: val_loss did not improve from 1.30362
Epoch 1354/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4271 - val_loss: 1.3068 - val_accuracy: 0.4147

Epoch 01354: val_loss did not improve from 1.30362
Epoch 1355/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4254 - val_loss: 1.3068 - val_accuracy: 0.4187

Epoch 01355: val_loss did not improve from 1.30362
Epoch 1356/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4292 - val_loss: 1.3117 - val_accuracy: 0.4083

Epoch 01356: val_loss did not improve from 1.30362
Epoch 1357/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4259 - val_loss: 1.3058 - val_accuracy: 0.4226

Epoch 01357: val_loss did not improve from 1.30362
Epoch 1358/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4252 - val_loss: 1.3047 - val_accuracy: 0.4242

Epoch 01358: val_loss did not improve from 1.30362
Epoch 1359/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4300 - val_loss: 1.3085 - val_accuracy: 0.4203

Epoch 01359: val_loss did not improve from 1.30362
Epoch 1360/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4280 - val_loss: 1.3043 - val_accuracy: 0.4219

Epoch 01360: val_loss did not improve from 1.30362
Epoch 1361/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4266 - val_loss: 1.3045 - val_accuracy: 0.4163

Epoch 01361: val_loss did not improve from 1.30362
Epoch 1362/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4272 - val_loss: 1.3060 - val_accuracy: 0.4195

Epoch 01362: val_loss did not improve from 1.30362
Epoch 1363/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4294 - val_loss: 1.3082 - val_accuracy: 0.4107

Epoch 01363: val_loss did not improve from 1.30362
Epoch 1364/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4311 - val_loss: 1.3058 - val_accuracy: 0.4195

Epoch 01364: val_loss did not improve from 1.30362
Epoch 1365/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4266 - val_loss: 1.3090 - val_accuracy: 0.4234

Epoch 01365: val_loss did not improve from 1.30362
Epoch 1366/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4300 - val_loss: 1.3062 - val_accuracy: 0.4219

Epoch 01366: val_loss did not improve from 1.30362
Epoch 1367/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4226 - val_loss: 1.3079 - val_accuracy: 0.4187

Epoch 01367: val_loss did not improve from 1.30362
Epoch 1368/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4286 - val_loss: 1.3087 - val_accuracy: 0.4179

Epoch 01368: val_loss did not improve from 1.30362
Epoch 1369/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4294 - val_loss: 1.3084 - val_accuracy: 0.4234

Epoch 01369: val_loss did not improve from 1.30362
Epoch 1370/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4254 - val_loss: 1.3052 - val_accuracy: 0.4226

Epoch 01370: val_loss did not improve from 1.30362
Epoch 1371/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4221 - val_loss: 1.3058 - val_accuracy: 0.4195

Epoch 01371: val_loss did not improve from 1.30362
Epoch 1372/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4287 - val_loss: 1.3035 - val_accuracy: 0.4258

Epoch 01372: val_loss improved from 1.30362 to 1.30354, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1373/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4271 - val_loss: 1.3078 - val_accuracy: 0.4242

Epoch 01373: val_loss did not improve from 1.30354
Epoch 1374/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4264 - val_loss: 1.3051 - val_accuracy: 0.4203

Epoch 01374: val_loss did not improve from 1.30354
Epoch 1375/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4295 - val_loss: 1.3056 - val_accuracy: 0.4250

Epoch 01375: val_loss did not improve from 1.30354
Epoch 1376/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4318 - val_loss: 1.3055 - val_accuracy: 0.4179

Epoch 01376: val_loss did not improve from 1.30354
Epoch 1377/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4245 - val_loss: 1.3048 - val_accuracy: 0.4099

Epoch 01377: val_loss did not improve from 1.30354
Epoch 1378/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4278 - val_loss: 1.3080 - val_accuracy: 0.4250

Epoch 01378: val_loss did not improve from 1.30354
Epoch 1379/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4277 - val_loss: 1.3046 - val_accuracy: 0.4115

Epoch 01379: val_loss did not improve from 1.30354
Epoch 1380/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4228 - val_loss: 1.3038 - val_accuracy: 0.4242

Epoch 01380: val_loss did not improve from 1.30354
Epoch 1381/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4299 - val_loss: 1.3055 - val_accuracy: 0.4155

Epoch 01381: val_loss did not improve from 1.30354
Epoch 1382/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4284 - val_loss: 1.3044 - val_accuracy: 0.4147

Epoch 01382: val_loss did not improve from 1.30354
Epoch 1383/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4292 - val_loss: 1.3043 - val_accuracy: 0.4203

Epoch 01383: val_loss did not improve from 1.30354
Epoch 1384/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4258 - val_loss: 1.3051 - val_accuracy: 0.4179

Epoch 01384: val_loss did not improve from 1.30354
Epoch 1385/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4276 - val_loss: 1.3062 - val_accuracy: 0.4219

Epoch 01385: val_loss did not improve from 1.30354
Epoch 1386/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4241 - val_loss: 1.3029 - val_accuracy: 0.4187

Epoch 01386: val_loss improved from 1.30354 to 1.30287, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1387/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4296 - val_loss: 1.3069 - val_accuracy: 0.4226

Epoch 01387: val_loss did not improve from 1.30287
Epoch 1388/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4277 - val_loss: 1.3059 - val_accuracy: 0.4171

Epoch 01388: val_loss did not improve from 1.30287
Epoch 1389/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4294 - val_loss: 1.3068 - val_accuracy: 0.4211

Epoch 01389: val_loss did not improve from 1.30287
Epoch 1390/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4271 - val_loss: 1.3088 - val_accuracy: 0.4139

Epoch 01390: val_loss did not improve from 1.30287
Epoch 1391/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4271 - val_loss: 1.3120 - val_accuracy: 0.4187

Epoch 01391: val_loss did not improve from 1.30287
Epoch 1392/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4289 - val_loss: 1.3161 - val_accuracy: 0.4107

Epoch 01392: val_loss did not improve from 1.30287
Epoch 1393/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4229 - val_loss: 1.3065 - val_accuracy: 0.4155

Epoch 01393: val_loss did not improve from 1.30287
Epoch 1394/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4292 - val_loss: 1.3069 - val_accuracy: 0.4203

Epoch 01394: val_loss did not improve from 1.30287
Epoch 1395/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4277 - val_loss: 1.3097 - val_accuracy: 0.4187

Epoch 01395: val_loss did not improve from 1.30287
Epoch 1396/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4284 - val_loss: 1.3043 - val_accuracy: 0.4219

Epoch 01396: val_loss did not improve from 1.30287
Epoch 1397/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4288 - val_loss: 1.3083 - val_accuracy: 0.4242

Epoch 01397: val_loss did not improve from 1.30287
Epoch 1398/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4211 - val_loss: 1.3049 - val_accuracy: 0.4187

Epoch 01398: val_loss did not improve from 1.30287
Epoch 1399/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4273 - val_loss: 1.3053 - val_accuracy: 0.4290

Epoch 01399: val_loss did not improve from 1.30287
Epoch 1400/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4269 - val_loss: 1.3028 - val_accuracy: 0.4234

Epoch 01400: val_loss improved from 1.30287 to 1.30279, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1401/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4263 - val_loss: 1.3073 - val_accuracy: 0.4258

Epoch 01401: val_loss did not improve from 1.30279
Epoch 1402/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4313 - val_loss: 1.3169 - val_accuracy: 0.4139

Epoch 01402: val_loss did not improve from 1.30279
Epoch 1403/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4261 - val_loss: 1.3057 - val_accuracy: 0.4147

Epoch 01403: val_loss did not improve from 1.30279
Epoch 1404/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4210 - val_loss: 1.3066 - val_accuracy: 0.4123

Epoch 01404: val_loss did not improve from 1.30279
Epoch 1405/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4273 - val_loss: 1.3026 - val_accuracy: 0.4187

Epoch 01405: val_loss improved from 1.30279 to 1.30263, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1406/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4298 - val_loss: 1.3076 - val_accuracy: 0.4091

Epoch 01406: val_loss did not improve from 1.30263
Epoch 1407/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4263 - val_loss: 1.3100 - val_accuracy: 0.4091

Epoch 01407: val_loss did not improve from 1.30263
Epoch 1408/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4288 - val_loss: 1.3045 - val_accuracy: 0.4163

Epoch 01408: val_loss did not improve from 1.30263
Epoch 1409/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4278 - val_loss: 1.3038 - val_accuracy: 0.4203

Epoch 01409: val_loss did not improve from 1.30263
Epoch 1410/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4305 - val_loss: 1.3042 - val_accuracy: 0.4171

Epoch 01410: val_loss did not improve from 1.30263
Epoch 1411/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4280 - val_loss: 1.3093 - val_accuracy: 0.4266

Epoch 01411: val_loss did not improve from 1.30263
Epoch 1412/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4256 - val_loss: 1.3074 - val_accuracy: 0.4187

Epoch 01412: val_loss did not improve from 1.30263
Epoch 1413/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4204 - val_loss: 1.3086 - val_accuracy: 0.4123

Epoch 01413: val_loss did not improve from 1.30263
Epoch 1414/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4271 - val_loss: 1.3056 - val_accuracy: 0.4163

Epoch 01414: val_loss did not improve from 1.30263
Epoch 1415/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4296 - val_loss: 1.3052 - val_accuracy: 0.4179

Epoch 01415: val_loss did not improve from 1.30263
Epoch 1416/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4286 - val_loss: 1.3080 - val_accuracy: 0.4139

Epoch 01416: val_loss did not improve from 1.30263
Epoch 1417/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4263 - val_loss: 1.3048 - val_accuracy: 0.4234

Epoch 01417: val_loss did not improve from 1.30263
Epoch 1418/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4312 - val_loss: 1.3058 - val_accuracy: 0.4250

Epoch 01418: val_loss did not improve from 1.30263
Epoch 1419/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4294 - val_loss: 1.3090 - val_accuracy: 0.4147

Epoch 01419: val_loss did not improve from 1.30263
Epoch 1420/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4269 - val_loss: 1.3068 - val_accuracy: 0.4195

Epoch 01420: val_loss did not improve from 1.30263
Epoch 1421/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4336 - val_loss: 1.3073 - val_accuracy: 0.4219

Epoch 01421: val_loss did not improve from 1.30263
Epoch 1422/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4298 - val_loss: 1.3050 - val_accuracy: 0.4234

Epoch 01422: val_loss did not improve from 1.30263
Epoch 1423/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4299 - val_loss: 1.3038 - val_accuracy: 0.4115

Epoch 01423: val_loss did not improve from 1.30263
Epoch 1424/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4219 - val_loss: 1.3088 - val_accuracy: 0.4067

Epoch 01424: val_loss did not improve from 1.30263
Epoch 1425/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4275 - val_loss: 1.3109 - val_accuracy: 0.4187

Epoch 01425: val_loss did not improve from 1.30263
Epoch 1426/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4280 - val_loss: 1.3079 - val_accuracy: 0.4226

Epoch 01426: val_loss did not improve from 1.30263
Epoch 1427/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4303 - val_loss: 1.3072 - val_accuracy: 0.4163

Epoch 01427: val_loss did not improve from 1.30263
Epoch 1428/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4281 - val_loss: 1.3073 - val_accuracy: 0.4123

Epoch 01428: val_loss did not improve from 1.30263
Epoch 1429/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4288 - val_loss: 1.3069 - val_accuracy: 0.4234

Epoch 01429: val_loss did not improve from 1.30263
Epoch 1430/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4289 - val_loss: 1.3047 - val_accuracy: 0.4195

Epoch 01430: val_loss did not improve from 1.30263
Epoch 1431/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4309 - val_loss: 1.3058 - val_accuracy: 0.4226

Epoch 01431: val_loss did not improve from 1.30263
Epoch 1432/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4316 - val_loss: 1.3035 - val_accuracy: 0.4266

Epoch 01432: val_loss did not improve from 1.30263
Epoch 1433/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4303 - val_loss: 1.3059 - val_accuracy: 0.4266

Epoch 01433: val_loss did not improve from 1.30263
Epoch 1434/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4278 - val_loss: 1.3068 - val_accuracy: 0.4155

Epoch 01434: val_loss did not improve from 1.30263
Epoch 1435/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4240 - val_loss: 1.3035 - val_accuracy: 0.4242

Epoch 01435: val_loss did not improve from 1.30263
Epoch 1436/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4317 - val_loss: 1.3046 - val_accuracy: 0.4163

Epoch 01436: val_loss did not improve from 1.30263
Epoch 1437/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4309 - val_loss: 1.3035 - val_accuracy: 0.4266

Epoch 01437: val_loss did not improve from 1.30263
Epoch 1438/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4279 - val_loss: 1.3029 - val_accuracy: 0.4282

Epoch 01438: val_loss did not improve from 1.30263
Epoch 1439/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4259 - val_loss: 1.3089 - val_accuracy: 0.4250

Epoch 01439: val_loss did not improve from 1.30263
Epoch 1440/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4267 - val_loss: 1.3048 - val_accuracy: 0.4131

Epoch 01440: val_loss did not improve from 1.30263
Epoch 1441/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4303 - val_loss: 1.3053 - val_accuracy: 0.4203

Epoch 01441: val_loss did not improve from 1.30263
Epoch 1442/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4282 - val_loss: 1.3116 - val_accuracy: 0.4131

Epoch 01442: val_loss did not improve from 1.30263
Epoch 1443/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4267 - val_loss: 1.3076 - val_accuracy: 0.4219

Epoch 01443: val_loss did not improve from 1.30263
Epoch 1444/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4310 - val_loss: 1.3037 - val_accuracy: 0.4306

Epoch 01444: val_loss did not improve from 1.30263
Epoch 1445/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4296 - val_loss: 1.3082 - val_accuracy: 0.4187

Epoch 01445: val_loss did not improve from 1.30263
Epoch 1446/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4274 - val_loss: 1.3030 - val_accuracy: 0.4290

Epoch 01446: val_loss did not improve from 1.30263
Epoch 1447/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4287 - val_loss: 1.3041 - val_accuracy: 0.4195

Epoch 01447: val_loss did not improve from 1.30263
Epoch 1448/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4270 - val_loss: 1.3057 - val_accuracy: 0.4250

Epoch 01448: val_loss did not improve from 1.30263
Epoch 1449/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4303 - val_loss: 1.3070 - val_accuracy: 0.4179

Epoch 01449: val_loss did not improve from 1.30263
Epoch 1450/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4302 - val_loss: 1.3050 - val_accuracy: 0.4187

Epoch 01450: val_loss did not improve from 1.30263
Epoch 1451/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4318 - val_loss: 1.3081 - val_accuracy: 0.4219

Epoch 01451: val_loss did not improve from 1.30263
Epoch 1452/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4264 - val_loss: 1.3047 - val_accuracy: 0.4187

Epoch 01452: val_loss did not improve from 1.30263
Epoch 1453/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4257 - val_loss: 1.3126 - val_accuracy: 0.4171

Epoch 01453: val_loss did not improve from 1.30263
Epoch 1454/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4285 - val_loss: 1.3066 - val_accuracy: 0.4330

Epoch 01454: val_loss did not improve from 1.30263
Epoch 1455/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4246 - val_loss: 1.3036 - val_accuracy: 0.4242

Epoch 01455: val_loss did not improve from 1.30263
Epoch 1456/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4315 - val_loss: 1.3069 - val_accuracy: 0.4219

Epoch 01456: val_loss did not improve from 1.30263
Epoch 1457/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4251 - val_loss: 1.3069 - val_accuracy: 0.4195

Epoch 01457: val_loss did not improve from 1.30263
Epoch 1458/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4291 - val_loss: 1.3038 - val_accuracy: 0.4187

Epoch 01458: val_loss did not improve from 1.30263
Epoch 1459/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4284 - val_loss: 1.3070 - val_accuracy: 0.4203

Epoch 01459: val_loss did not improve from 1.30263
Epoch 1460/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4220 - val_loss: 1.3032 - val_accuracy: 0.4147

Epoch 01460: val_loss did not improve from 1.30263
Epoch 1461/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4291 - val_loss: 1.3039 - val_accuracy: 0.4258

Epoch 01461: val_loss did not improve from 1.30263
Epoch 1462/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4295 - val_loss: 1.3090 - val_accuracy: 0.4187

Epoch 01462: val_loss did not improve from 1.30263
Epoch 1463/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4309 - val_loss: 1.3014 - val_accuracy: 0.4266

Epoch 01463: val_loss improved from 1.30263 to 1.30141, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1464/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4299 - val_loss: 1.3073 - val_accuracy: 0.4211

Epoch 01464: val_loss did not improve from 1.30141
Epoch 1465/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4298 - val_loss: 1.3064 - val_accuracy: 0.4234

Epoch 01465: val_loss did not improve from 1.30141
Epoch 1466/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4276 - val_loss: 1.3040 - val_accuracy: 0.4107

Epoch 01466: val_loss did not improve from 1.30141
Epoch 1467/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4233 - val_loss: 1.3162 - val_accuracy: 0.4115

Epoch 01467: val_loss did not improve from 1.30141
Epoch 1468/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4253 - val_loss: 1.3146 - val_accuracy: 0.4139

Epoch 01468: val_loss did not improve from 1.30141
Epoch 1469/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4287 - val_loss: 1.3044 - val_accuracy: 0.4155

Epoch 01469: val_loss did not improve from 1.30141
Epoch 1470/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4305 - val_loss: 1.3049 - val_accuracy: 0.4290

Epoch 01470: val_loss did not improve from 1.30141
Epoch 1471/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4297 - val_loss: 1.3038 - val_accuracy: 0.4203

Epoch 01471: val_loss did not improve from 1.30141
Epoch 1472/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4273 - val_loss: 1.3030 - val_accuracy: 0.4242

Epoch 01472: val_loss did not improve from 1.30141
Epoch 1473/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4270 - val_loss: 1.3102 - val_accuracy: 0.4242

Epoch 01473: val_loss did not improve from 1.30141
Epoch 1474/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4291 - val_loss: 1.3079 - val_accuracy: 0.4147

Epoch 01474: val_loss did not improve from 1.30141
Epoch 1475/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4257 - val_loss: 1.3073 - val_accuracy: 0.4131

Epoch 01475: val_loss did not improve from 1.30141
Epoch 1476/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4272 - val_loss: 1.3043 - val_accuracy: 0.4258

Epoch 01476: val_loss did not improve from 1.30141
Epoch 1477/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4261 - val_loss: 1.3057 - val_accuracy: 0.4147

Epoch 01477: val_loss did not improve from 1.30141
Epoch 1478/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4280 - val_loss: 1.3105 - val_accuracy: 0.4203

Epoch 01478: val_loss did not improve from 1.30141
Epoch 1479/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4233 - val_loss: 1.3050 - val_accuracy: 0.4274

Epoch 01479: val_loss did not improve from 1.30141
Epoch 1480/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4268 - val_loss: 1.3032 - val_accuracy: 0.4195

Epoch 01480: val_loss did not improve from 1.30141
Epoch 1481/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4240 - val_loss: 1.3044 - val_accuracy: 0.4179

Epoch 01481: val_loss did not improve from 1.30141
Epoch 1482/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4270 - val_loss: 1.3054 - val_accuracy: 0.4195

Epoch 01482: val_loss did not improve from 1.30141
Epoch 1483/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4232 - val_loss: 1.3043 - val_accuracy: 0.4250

Epoch 01483: val_loss did not improve from 1.30141
Epoch 1484/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4264 - val_loss: 1.3030 - val_accuracy: 0.4195

Epoch 01484: val_loss did not improve from 1.30141
Epoch 1485/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4276 - val_loss: 1.3052 - val_accuracy: 0.4250

Epoch 01485: val_loss did not improve from 1.30141
Epoch 1486/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4307 - val_loss: 1.3039 - val_accuracy: 0.4234

Epoch 01486: val_loss did not improve from 1.30141
Epoch 1487/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4287 - val_loss: 1.3044 - val_accuracy: 0.4155

Epoch 01487: val_loss did not improve from 1.30141
Epoch 1488/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4245 - val_loss: 1.3028 - val_accuracy: 0.4258

Epoch 01488: val_loss did not improve from 1.30141
Epoch 1489/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4308 - val_loss: 1.3034 - val_accuracy: 0.4250

Epoch 01489: val_loss did not improve from 1.30141
Epoch 1490/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4246 - val_loss: 1.3056 - val_accuracy: 0.4155

Epoch 01490: val_loss did not improve from 1.30141
Epoch 1491/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4219 - val_loss: 1.3060 - val_accuracy: 0.4131

Epoch 01491: val_loss did not improve from 1.30141
Epoch 1492/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4275 - val_loss: 1.3077 - val_accuracy: 0.4131

Epoch 01492: val_loss did not improve from 1.30141
Epoch 1493/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4270 - val_loss: 1.3071 - val_accuracy: 0.4187

Epoch 01493: val_loss did not improve from 1.30141
Epoch 1494/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4275 - val_loss: 1.3045 - val_accuracy: 0.4203

Epoch 01494: val_loss did not improve from 1.30141
Epoch 1495/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4283 - val_loss: 1.3026 - val_accuracy: 0.4155

Epoch 01495: val_loss did not improve from 1.30141
Epoch 1496/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4260 - val_loss: 1.3042 - val_accuracy: 0.4226

Epoch 01496: val_loss did not improve from 1.30141
Epoch 1497/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4270 - val_loss: 1.3025 - val_accuracy: 0.4211

Epoch 01497: val_loss did not improve from 1.30141
Epoch 1498/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4280 - val_loss: 1.3205 - val_accuracy: 0.4099

Epoch 01498: val_loss did not improve from 1.30141
Epoch 1499/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4241 - val_loss: 1.3038 - val_accuracy: 0.4219

Epoch 01499: val_loss did not improve from 1.30141
Epoch 1500/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4264 - val_loss: 1.3028 - val_accuracy: 0.4195

Epoch 01500: val_loss did not improve from 1.30141
Epoch 1501/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4290 - val_loss: 1.3062 - val_accuracy: 0.4171

Epoch 01501: val_loss did not improve from 1.30141
Epoch 1502/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4264 - val_loss: 1.3068 - val_accuracy: 0.4250

Epoch 01502: val_loss did not improve from 1.30141
Epoch 1503/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4270 - val_loss: 1.3035 - val_accuracy: 0.4171

Epoch 01503: val_loss did not improve from 1.30141
Epoch 1504/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4298 - val_loss: 1.3027 - val_accuracy: 0.4226

Epoch 01504: val_loss did not improve from 1.30141
Epoch 1505/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4292 - val_loss: 1.3030 - val_accuracy: 0.4274

Epoch 01505: val_loss did not improve from 1.30141
Epoch 1506/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4308 - val_loss: 1.3030 - val_accuracy: 0.4330

Epoch 01506: val_loss did not improve from 1.30141
Epoch 1507/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4287 - val_loss: 1.3036 - val_accuracy: 0.4195

Epoch 01507: val_loss did not improve from 1.30141
Epoch 1508/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4302 - val_loss: 1.3007 - val_accuracy: 0.4306

Epoch 01508: val_loss improved from 1.30141 to 1.30065, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1509/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4301 - val_loss: 1.3039 - val_accuracy: 0.4306

Epoch 01509: val_loss did not improve from 1.30065
Epoch 1510/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4293 - val_loss: 1.3047 - val_accuracy: 0.4123

Epoch 01510: val_loss did not improve from 1.30065
Epoch 1511/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4264 - val_loss: 1.3032 - val_accuracy: 0.4211

Epoch 01511: val_loss did not improve from 1.30065
Epoch 1512/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4250 - val_loss: 1.3036 - val_accuracy: 0.4211

Epoch 01512: val_loss did not improve from 1.30065
Epoch 1513/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4277 - val_loss: 1.3019 - val_accuracy: 0.4211

Epoch 01513: val_loss did not improve from 1.30065
Epoch 1514/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4325 - val_loss: 1.3025 - val_accuracy: 0.4155

Epoch 01514: val_loss did not improve from 1.30065
Epoch 1515/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4260 - val_loss: 1.3044 - val_accuracy: 0.4107

Epoch 01515: val_loss did not improve from 1.30065
Epoch 1516/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4245 - val_loss: 1.3059 - val_accuracy: 0.4091

Epoch 01516: val_loss did not improve from 1.30065
Epoch 1517/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4249 - val_loss: 1.3031 - val_accuracy: 0.4203

Epoch 01517: val_loss did not improve from 1.30065
Epoch 1518/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4295 - val_loss: 1.3024 - val_accuracy: 0.4195

Epoch 01518: val_loss did not improve from 1.30065
Epoch 1519/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4261 - val_loss: 1.3009 - val_accuracy: 0.4266

Epoch 01519: val_loss did not improve from 1.30065
Epoch 1520/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4292 - val_loss: 1.3059 - val_accuracy: 0.4155

Epoch 01520: val_loss did not improve from 1.30065
Epoch 1521/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4295 - val_loss: 1.3044 - val_accuracy: 0.4234

Epoch 01521: val_loss did not improve from 1.30065
Epoch 1522/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4268 - val_loss: 1.3048 - val_accuracy: 0.4155

Epoch 01522: val_loss did not improve from 1.30065
Epoch 1523/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4280 - val_loss: 1.3045 - val_accuracy: 0.4226

Epoch 01523: val_loss did not improve from 1.30065
Epoch 1524/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4323 - val_loss: 1.3065 - val_accuracy: 0.4179

Epoch 01524: val_loss did not improve from 1.30065
Epoch 1525/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4286 - val_loss: 1.3031 - val_accuracy: 0.4242

Epoch 01525: val_loss did not improve from 1.30065
Epoch 1526/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4268 - val_loss: 1.3041 - val_accuracy: 0.4354

Epoch 01526: val_loss did not improve from 1.30065
Epoch 1527/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4299 - val_loss: 1.3019 - val_accuracy: 0.4314

Epoch 01527: val_loss did not improve from 1.30065
Epoch 1528/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4259 - val_loss: 1.3019 - val_accuracy: 0.4234

Epoch 01528: val_loss did not improve from 1.30065
Epoch 1529/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4290 - val_loss: 1.3056 - val_accuracy: 0.4203

Epoch 01529: val_loss did not improve from 1.30065
Epoch 1530/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4242 - val_loss: 1.3025 - val_accuracy: 0.4187

Epoch 01530: val_loss did not improve from 1.30065
Epoch 1531/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4303 - val_loss: 1.3041 - val_accuracy: 0.4219

Epoch 01531: val_loss did not improve from 1.30065
Epoch 1532/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4267 - val_loss: 1.3055 - val_accuracy: 0.4250

Epoch 01532: val_loss did not improve from 1.30065
Epoch 1533/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4267 - val_loss: 1.3096 - val_accuracy: 0.4051

Epoch 01533: val_loss did not improve from 1.30065
Epoch 1534/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4270 - val_loss: 1.3057 - val_accuracy: 0.4139

Epoch 01534: val_loss did not improve from 1.30065
Epoch 1535/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4280 - val_loss: 1.3038 - val_accuracy: 0.4155

Epoch 01535: val_loss did not improve from 1.30065
Epoch 1536/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4262 - val_loss: 1.3058 - val_accuracy: 0.4155

Epoch 01536: val_loss did not improve from 1.30065
Epoch 1537/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4197 - val_loss: 1.3077 - val_accuracy: 0.4163

Epoch 01537: val_loss did not improve from 1.30065
Epoch 1538/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4281 - val_loss: 1.3042 - val_accuracy: 0.4242

Epoch 01538: val_loss did not improve from 1.30065
Epoch 1539/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4269 - val_loss: 1.3043 - val_accuracy: 0.4195

Epoch 01539: val_loss did not improve from 1.30065
Epoch 1540/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4305 - val_loss: 1.3060 - val_accuracy: 0.4155

Epoch 01540: val_loss did not improve from 1.30065
Epoch 1541/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4295 - val_loss: 1.3052 - val_accuracy: 0.4187

Epoch 01541: val_loss did not improve from 1.30065
Epoch 1542/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4228 - val_loss: 1.3016 - val_accuracy: 0.4234

Epoch 01542: val_loss did not improve from 1.30065
Epoch 1543/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4283 - val_loss: 1.3014 - val_accuracy: 0.4266

Epoch 01543: val_loss did not improve from 1.30065
Epoch 1544/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4286 - val_loss: 1.3100 - val_accuracy: 0.4147

Epoch 01544: val_loss did not improve from 1.30065
Epoch 1545/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4276 - val_loss: 1.3021 - val_accuracy: 0.4123

Epoch 01545: val_loss did not improve from 1.30065
Epoch 1546/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4287 - val_loss: 1.3063 - val_accuracy: 0.4091

Epoch 01546: val_loss did not improve from 1.30065
Epoch 1547/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4243 - val_loss: 1.3030 - val_accuracy: 0.4139

Epoch 01547: val_loss did not improve from 1.30065
Epoch 1548/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4259 - val_loss: 1.3051 - val_accuracy: 0.4067

Epoch 01548: val_loss did not improve from 1.30065
Epoch 1549/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4296 - val_loss: 1.3085 - val_accuracy: 0.4187

Epoch 01549: val_loss did not improve from 1.30065
Epoch 1550/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4222 - val_loss: 1.3171 - val_accuracy: 0.4107

Epoch 01550: val_loss did not improve from 1.30065
Epoch 1551/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4244 - val_loss: 1.3058 - val_accuracy: 0.4203

Epoch 01551: val_loss did not improve from 1.30065
Epoch 1552/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4293 - val_loss: 1.3039 - val_accuracy: 0.4298

Epoch 01552: val_loss did not improve from 1.30065
Epoch 1553/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4295 - val_loss: 1.3036 - val_accuracy: 0.4211

Epoch 01553: val_loss did not improve from 1.30065
Epoch 1554/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4267 - val_loss: 1.3106 - val_accuracy: 0.4147

Epoch 01554: val_loss did not improve from 1.30065
Epoch 1555/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4292 - val_loss: 1.3059 - val_accuracy: 0.4203

Epoch 01555: val_loss did not improve from 1.30065
Epoch 1556/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4272 - val_loss: 1.3048 - val_accuracy: 0.4211

Epoch 01556: val_loss did not improve from 1.30065
Epoch 1557/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4318 - val_loss: 1.3058 - val_accuracy: 0.4139

Epoch 01557: val_loss did not improve from 1.30065
Epoch 1558/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4268 - val_loss: 1.3022 - val_accuracy: 0.4258

Epoch 01558: val_loss did not improve from 1.30065
Epoch 1559/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4348 - val_loss: 1.3055 - val_accuracy: 0.4282

Epoch 01559: val_loss did not improve from 1.30065
Epoch 1560/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4283 - val_loss: 1.3025 - val_accuracy: 0.4187

Epoch 01560: val_loss did not improve from 1.30065
Epoch 1561/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4266 - val_loss: 1.3065 - val_accuracy: 0.4195

Epoch 01561: val_loss did not improve from 1.30065
Epoch 1562/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4273 - val_loss: 1.3054 - val_accuracy: 0.4091

Epoch 01562: val_loss did not improve from 1.30065
Epoch 1563/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4269 - val_loss: 1.3059 - val_accuracy: 0.4219

Epoch 01563: val_loss did not improve from 1.30065
Epoch 1564/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4290 - val_loss: 1.3054 - val_accuracy: 0.4298

Epoch 01564: val_loss did not improve from 1.30065
Epoch 1565/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4280 - val_loss: 1.3018 - val_accuracy: 0.4242

Epoch 01565: val_loss did not improve from 1.30065
Epoch 1566/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4271 - val_loss: 1.3054 - val_accuracy: 0.4163

Epoch 01566: val_loss did not improve from 1.30065
Epoch 1567/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4298 - val_loss: 1.3057 - val_accuracy: 0.4187

Epoch 01567: val_loss did not improve from 1.30065
Epoch 1568/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4293 - val_loss: 1.3060 - val_accuracy: 0.4282

Epoch 01568: val_loss did not improve from 1.30065
Epoch 1569/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4218 - val_loss: 1.3076 - val_accuracy: 0.4147

Epoch 01569: val_loss did not improve from 1.30065
Epoch 1570/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4251 - val_loss: 1.3053 - val_accuracy: 0.4107

Epoch 01570: val_loss did not improve from 1.30065
Epoch 1571/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4306 - val_loss: 1.3043 - val_accuracy: 0.4187

Epoch 01571: val_loss did not improve from 1.30065
Epoch 1572/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4326 - val_loss: 1.3062 - val_accuracy: 0.4187

Epoch 01572: val_loss did not improve from 1.30065
Epoch 1573/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4280 - val_loss: 1.3067 - val_accuracy: 0.4179

Epoch 01573: val_loss did not improve from 1.30065
Epoch 1574/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4280 - val_loss: 1.3055 - val_accuracy: 0.4163

Epoch 01574: val_loss did not improve from 1.30065
Epoch 1575/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4279 - val_loss: 1.3045 - val_accuracy: 0.4155

Epoch 01575: val_loss did not improve from 1.30065
Epoch 1576/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4290 - val_loss: 1.3015 - val_accuracy: 0.4234

Epoch 01576: val_loss did not improve from 1.30065
Epoch 1577/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4295 - val_loss: 1.3058 - val_accuracy: 0.4258

Epoch 01577: val_loss did not improve from 1.30065
Epoch 1578/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4309 - val_loss: 1.3055 - val_accuracy: 0.4203

Epoch 01578: val_loss did not improve from 1.30065
Epoch 1579/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4251 - val_loss: 1.3022 - val_accuracy: 0.4258

Epoch 01579: val_loss did not improve from 1.30065
Epoch 1580/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4283 - val_loss: 1.3022 - val_accuracy: 0.4242

Epoch 01580: val_loss did not improve from 1.30065
Epoch 1581/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4283 - val_loss: 1.3003 - val_accuracy: 0.4242

Epoch 01581: val_loss improved from 1.30065 to 1.30028, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1582/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4278 - val_loss: 1.3019 - val_accuracy: 0.4179

Epoch 01582: val_loss did not improve from 1.30028
Epoch 1583/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4326 - val_loss: 1.3083 - val_accuracy: 0.4131

Epoch 01583: val_loss did not improve from 1.30028
Epoch 1584/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4271 - val_loss: 1.3045 - val_accuracy: 0.4195

Epoch 01584: val_loss did not improve from 1.30028
Epoch 1585/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4241 - val_loss: 1.3114 - val_accuracy: 0.4163

Epoch 01585: val_loss did not improve from 1.30028
Epoch 1586/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4279 - val_loss: 1.3031 - val_accuracy: 0.4179

Epoch 01586: val_loss did not improve from 1.30028
Epoch 1587/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4295 - val_loss: 1.3053 - val_accuracy: 0.4211

Epoch 01587: val_loss did not improve from 1.30028
Epoch 1588/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4272 - val_loss: 1.3010 - val_accuracy: 0.4226

Epoch 01588: val_loss did not improve from 1.30028
Epoch 1589/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4241 - val_loss: 1.3057 - val_accuracy: 0.4219

Epoch 01589: val_loss did not improve from 1.30028
Epoch 1590/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4286 - val_loss: 1.3005 - val_accuracy: 0.4234

Epoch 01590: val_loss did not improve from 1.30028
Epoch 1591/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4270 - val_loss: 1.3121 - val_accuracy: 0.4187

Epoch 01591: val_loss did not improve from 1.30028
Epoch 1592/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4308 - val_loss: 1.3058 - val_accuracy: 0.4195

Epoch 01592: val_loss did not improve from 1.30028
Epoch 1593/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4287 - val_loss: 1.3000 - val_accuracy: 0.4322

Epoch 01593: val_loss improved from 1.30028 to 1.29998, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1594/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4282 - val_loss: 1.2993 - val_accuracy: 0.4322

Epoch 01594: val_loss improved from 1.29998 to 1.29926, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1595/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4326 - val_loss: 1.3010 - val_accuracy: 0.4234

Epoch 01595: val_loss did not improve from 1.29926
Epoch 1596/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4264 - val_loss: 1.3069 - val_accuracy: 0.4282

Epoch 01596: val_loss did not improve from 1.29926
Epoch 1597/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4308 - val_loss: 1.3066 - val_accuracy: 0.4298

Epoch 01597: val_loss did not improve from 1.29926
Epoch 1598/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4256 - val_loss: 1.3018 - val_accuracy: 0.4258

Epoch 01598: val_loss did not improve from 1.29926
Epoch 1599/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4255 - val_loss: 1.3027 - val_accuracy: 0.4171

Epoch 01599: val_loss did not improve from 1.29926
Epoch 1600/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4221 - val_loss: 1.3038 - val_accuracy: 0.4163

Epoch 01600: val_loss did not improve from 1.29926
Epoch 1601/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4285 - val_loss: 1.3062 - val_accuracy: 0.4266

Epoch 01601: val_loss did not improve from 1.29926
Epoch 1602/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4332 - val_loss: 1.3124 - val_accuracy: 0.4131

Epoch 01602: val_loss did not improve from 1.29926
Epoch 1603/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4284 - val_loss: 1.3030 - val_accuracy: 0.4195

Epoch 01603: val_loss did not improve from 1.29926
Epoch 1604/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4280 - val_loss: 1.3062 - val_accuracy: 0.4051

Epoch 01604: val_loss did not improve from 1.29926
Epoch 1605/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4318 - val_loss: 1.3020 - val_accuracy: 0.4123

Epoch 01605: val_loss did not improve from 1.29926
Epoch 1606/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4252 - val_loss: 1.3051 - val_accuracy: 0.4258

Epoch 01606: val_loss did not improve from 1.29926
Epoch 1607/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4318 - val_loss: 1.3060 - val_accuracy: 0.4211

Epoch 01607: val_loss did not improve from 1.29926
Epoch 1608/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4285 - val_loss: 1.3034 - val_accuracy: 0.4163

Epoch 01608: val_loss did not improve from 1.29926
Epoch 1609/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4323 - val_loss: 1.3135 - val_accuracy: 0.4107

Epoch 01609: val_loss did not improve from 1.29926
Epoch 1610/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4260 - val_loss: 1.3031 - val_accuracy: 0.4115

Epoch 01610: val_loss did not improve from 1.29926
Epoch 1611/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4250 - val_loss: 1.3064 - val_accuracy: 0.4115

Epoch 01611: val_loss did not improve from 1.29926
Epoch 1612/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4265 - val_loss: 1.3039 - val_accuracy: 0.4139

Epoch 01612: val_loss did not improve from 1.29926
Epoch 1613/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4284 - val_loss: 1.3050 - val_accuracy: 0.4187

Epoch 01613: val_loss did not improve from 1.29926
Epoch 1614/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4280 - val_loss: 1.3044 - val_accuracy: 0.4258

Epoch 01614: val_loss did not improve from 1.29926
Epoch 1615/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4337 - val_loss: 1.3113 - val_accuracy: 0.4139

Epoch 01615: val_loss did not improve from 1.29926
Epoch 1616/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4252 - val_loss: 1.3048 - val_accuracy: 0.4250

Epoch 01616: val_loss did not improve from 1.29926
Epoch 1617/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4293 - val_loss: 1.3008 - val_accuracy: 0.4195

Epoch 01617: val_loss did not improve from 1.29926
Epoch 1618/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4258 - val_loss: 1.3049 - val_accuracy: 0.4195

Epoch 01618: val_loss did not improve from 1.29926
Epoch 1619/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4244 - val_loss: 1.3063 - val_accuracy: 0.4179

Epoch 01619: val_loss did not improve from 1.29926
Epoch 1620/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4287 - val_loss: 1.3033 - val_accuracy: 0.4187

Epoch 01620: val_loss did not improve from 1.29926
Epoch 1621/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4301 - val_loss: 1.3017 - val_accuracy: 0.4226

Epoch 01621: val_loss did not improve from 1.29926
Epoch 1622/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4290 - val_loss: 1.3023 - val_accuracy: 0.4187

Epoch 01622: val_loss did not improve from 1.29926
Epoch 1623/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4299 - val_loss: 1.3020 - val_accuracy: 0.4147

Epoch 01623: val_loss did not improve from 1.29926
Epoch 1624/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4266 - val_loss: 1.3011 - val_accuracy: 0.4211

Epoch 01624: val_loss did not improve from 1.29926
Epoch 1625/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4325 - val_loss: 1.3095 - val_accuracy: 0.4107

Epoch 01625: val_loss did not improve from 1.29926
Epoch 1626/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4255 - val_loss: 1.3024 - val_accuracy: 0.4195

Epoch 01626: val_loss did not improve from 1.29926
Epoch 1627/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4346 - val_loss: 1.2997 - val_accuracy: 0.4203

Epoch 01627: val_loss did not improve from 1.29926
Epoch 1628/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4333 - val_loss: 1.3020 - val_accuracy: 0.4234

Epoch 01628: val_loss did not improve from 1.29926
Epoch 1629/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4351 - val_loss: 1.3007 - val_accuracy: 0.4234

Epoch 01629: val_loss did not improve from 1.29926
Epoch 1630/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4348 - val_loss: 1.3100 - val_accuracy: 0.4123

Epoch 01630: val_loss did not improve from 1.29926
Epoch 1631/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4295 - val_loss: 1.3005 - val_accuracy: 0.4195

Epoch 01631: val_loss did not improve from 1.29926
Epoch 1632/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4260 - val_loss: 1.3062 - val_accuracy: 0.4091

Epoch 01632: val_loss did not improve from 1.29926
Epoch 1633/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4294 - val_loss: 1.3058 - val_accuracy: 0.4195

Epoch 01633: val_loss did not improve from 1.29926
Epoch 1634/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4264 - val_loss: 1.3037 - val_accuracy: 0.4274

Epoch 01634: val_loss did not improve from 1.29926
Epoch 1635/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4293 - val_loss: 1.3041 - val_accuracy: 0.4234

Epoch 01635: val_loss did not improve from 1.29926
Epoch 1636/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4280 - val_loss: 1.3059 - val_accuracy: 0.4155

Epoch 01636: val_loss did not improve from 1.29926
Epoch 1637/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4298 - val_loss: 1.3029 - val_accuracy: 0.4147

Epoch 01637: val_loss did not improve from 1.29926
Epoch 1638/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4279 - val_loss: 1.3071 - val_accuracy: 0.4195

Epoch 01638: val_loss did not improve from 1.29926
Epoch 1639/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4349 - val_loss: 1.3009 - val_accuracy: 0.4242

Epoch 01639: val_loss did not improve from 1.29926
Epoch 1640/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4303 - val_loss: 1.3001 - val_accuracy: 0.4179

Epoch 01640: val_loss did not improve from 1.29926
Epoch 1641/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4301 - val_loss: 1.3024 - val_accuracy: 0.4171

Epoch 01641: val_loss did not improve from 1.29926
Epoch 1642/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4303 - val_loss: 1.3046 - val_accuracy: 0.4203

Epoch 01642: val_loss did not improve from 1.29926
Epoch 1643/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4300 - val_loss: 1.3012 - val_accuracy: 0.4266

Epoch 01643: val_loss did not improve from 1.29926
Epoch 1644/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4265 - val_loss: 1.3064 - val_accuracy: 0.4234

Epoch 01644: val_loss did not improve from 1.29926
Epoch 1645/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4315 - val_loss: 1.3015 - val_accuracy: 0.4211

Epoch 01645: val_loss did not improve from 1.29926
Epoch 1646/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4291 - val_loss: 1.2993 - val_accuracy: 0.4195

Epoch 01646: val_loss did not improve from 1.29926
Epoch 1647/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4286 - val_loss: 1.3036 - val_accuracy: 0.4187

Epoch 01647: val_loss did not improve from 1.29926
Epoch 1648/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4276 - val_loss: 1.2999 - val_accuracy: 0.4171

Epoch 01648: val_loss did not improve from 1.29926
Epoch 1649/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4261 - val_loss: 1.3066 - val_accuracy: 0.4147

Epoch 01649: val_loss did not improve from 1.29926
Epoch 1650/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4272 - val_loss: 1.3125 - val_accuracy: 0.4091

Epoch 01650: val_loss did not improve from 1.29926
Epoch 1651/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4295 - val_loss: 1.3021 - val_accuracy: 0.4211

Epoch 01651: val_loss did not improve from 1.29926
Epoch 1652/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4280 - val_loss: 1.3068 - val_accuracy: 0.4147

Epoch 01652: val_loss did not improve from 1.29926
Epoch 1653/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4287 - val_loss: 1.2996 - val_accuracy: 0.4322

Epoch 01653: val_loss did not improve from 1.29926
Epoch 1654/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4295 - val_loss: 1.3001 - val_accuracy: 0.4203

Epoch 01654: val_loss did not improve from 1.29926
Epoch 1655/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4271 - val_loss: 1.3104 - val_accuracy: 0.4226

Epoch 01655: val_loss did not improve from 1.29926
Epoch 1656/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4317 - val_loss: 1.3004 - val_accuracy: 0.4203

Epoch 01656: val_loss did not improve from 1.29926
Epoch 1657/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4300 - val_loss: 1.3062 - val_accuracy: 0.4147

Epoch 01657: val_loss did not improve from 1.29926
Epoch 1658/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4278 - val_loss: 1.3031 - val_accuracy: 0.4179

Epoch 01658: val_loss did not improve from 1.29926
Epoch 1659/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4325 - val_loss: 1.3030 - val_accuracy: 0.4226

Epoch 01659: val_loss did not improve from 1.29926
Epoch 1660/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4311 - val_loss: 1.3044 - val_accuracy: 0.4179

Epoch 01660: val_loss did not improve from 1.29926
Epoch 1661/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4292 - val_loss: 1.3004 - val_accuracy: 0.4163

Epoch 01661: val_loss did not improve from 1.29926
Epoch 1662/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4323 - val_loss: 1.3002 - val_accuracy: 0.4219

Epoch 01662: val_loss did not improve from 1.29926
Epoch 1663/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4337 - val_loss: 1.3000 - val_accuracy: 0.4226

Epoch 01663: val_loss did not improve from 1.29926
Epoch 1664/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4279 - val_loss: 1.3003 - val_accuracy: 0.4274

Epoch 01664: val_loss did not improve from 1.29926
Epoch 1665/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4334 - val_loss: 1.3055 - val_accuracy: 0.4219

Epoch 01665: val_loss did not improve from 1.29926
Epoch 1666/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4300 - val_loss: 1.3064 - val_accuracy: 0.4171

Epoch 01666: val_loss did not improve from 1.29926
Epoch 1667/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4264 - val_loss: 1.3035 - val_accuracy: 0.4131

Epoch 01667: val_loss did not improve from 1.29926
Epoch 1668/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4295 - val_loss: 1.3049 - val_accuracy: 0.4266

Epoch 01668: val_loss did not improve from 1.29926
Epoch 1669/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4312 - val_loss: 1.3071 - val_accuracy: 0.4258

Epoch 01669: val_loss did not improve from 1.29926
Epoch 1670/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4299 - val_loss: 1.3033 - val_accuracy: 0.4282

Epoch 01670: val_loss did not improve from 1.29926
Epoch 1671/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4272 - val_loss: 1.2993 - val_accuracy: 0.4163

Epoch 01671: val_loss did not improve from 1.29926
Epoch 1672/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4310 - val_loss: 1.2992 - val_accuracy: 0.4242

Epoch 01672: val_loss improved from 1.29926 to 1.29924, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1673/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4294 - val_loss: 1.3052 - val_accuracy: 0.4179

Epoch 01673: val_loss did not improve from 1.29924
Epoch 1674/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4342 - val_loss: 1.3039 - val_accuracy: 0.4234

Epoch 01674: val_loss did not improve from 1.29924
Epoch 1675/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4264 - val_loss: 1.3046 - val_accuracy: 0.4123

Epoch 01675: val_loss did not improve from 1.29924
Epoch 1676/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4304 - val_loss: 1.3020 - val_accuracy: 0.4131

Epoch 01676: val_loss did not improve from 1.29924
Epoch 1677/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4299 - val_loss: 1.3017 - val_accuracy: 0.4123

Epoch 01677: val_loss did not improve from 1.29924
Epoch 1678/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4291 - val_loss: 1.3007 - val_accuracy: 0.4187

Epoch 01678: val_loss did not improve from 1.29924
Epoch 1679/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4301 - val_loss: 1.3116 - val_accuracy: 0.4099

Epoch 01679: val_loss did not improve from 1.29924
Epoch 1680/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4256 - val_loss: 1.3040 - val_accuracy: 0.4179

Epoch 01680: val_loss did not improve from 1.29924
Epoch 1681/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4318 - val_loss: 1.3116 - val_accuracy: 0.4115

Epoch 01681: val_loss did not improve from 1.29924
Epoch 1682/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4270 - val_loss: 1.3028 - val_accuracy: 0.4147

Epoch 01682: val_loss did not improve from 1.29924
Epoch 1683/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4361 - val_loss: 1.3027 - val_accuracy: 0.4282

Epoch 01683: val_loss did not improve from 1.29924
Epoch 1684/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4318 - val_loss: 1.3015 - val_accuracy: 0.4147

Epoch 01684: val_loss did not improve from 1.29924
Epoch 1685/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4350 - val_loss: 1.2999 - val_accuracy: 0.4290

Epoch 01685: val_loss did not improve from 1.29924
Epoch 1686/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4315 - val_loss: 1.3009 - val_accuracy: 0.4195

Epoch 01686: val_loss did not improve from 1.29924
Epoch 1687/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4262 - val_loss: 1.3175 - val_accuracy: 0.4083

Epoch 01687: val_loss did not improve from 1.29924
Epoch 1688/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4307 - val_loss: 1.3041 - val_accuracy: 0.4258

Epoch 01688: val_loss did not improve from 1.29924
Epoch 1689/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4343 - val_loss: 1.3039 - val_accuracy: 0.4258

Epoch 01689: val_loss did not improve from 1.29924
Epoch 1690/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4312 - val_loss: 1.3005 - val_accuracy: 0.4290

Epoch 01690: val_loss did not improve from 1.29924
Epoch 1691/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4305 - val_loss: 1.3013 - val_accuracy: 0.4258

Epoch 01691: val_loss did not improve from 1.29924
Epoch 1692/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4270 - val_loss: 1.3034 - val_accuracy: 0.4203

Epoch 01692: val_loss did not improve from 1.29924
Epoch 1693/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4296 - val_loss: 1.3087 - val_accuracy: 0.4179

Epoch 01693: val_loss did not improve from 1.29924
Epoch 1694/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4299 - val_loss: 1.3048 - val_accuracy: 0.4187

Epoch 01694: val_loss did not improve from 1.29924
Epoch 1695/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4307 - val_loss: 1.2997 - val_accuracy: 0.4242

Epoch 01695: val_loss did not improve from 1.29924
Epoch 1696/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4324 - val_loss: 1.3051 - val_accuracy: 0.4258

Epoch 01696: val_loss did not improve from 1.29924
Epoch 1697/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4318 - val_loss: 1.3121 - val_accuracy: 0.4123

Epoch 01697: val_loss did not improve from 1.29924
Epoch 1698/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4295 - val_loss: 1.3017 - val_accuracy: 0.4266

Epoch 01698: val_loss did not improve from 1.29924
Epoch 1699/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4337 - val_loss: 1.3025 - val_accuracy: 0.4171

Epoch 01699: val_loss did not improve from 1.29924
Epoch 1700/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4306 - val_loss: 1.3047 - val_accuracy: 0.4219

Epoch 01700: val_loss did not improve from 1.29924
Epoch 1701/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4316 - val_loss: 1.3003 - val_accuracy: 0.4250

Epoch 01701: val_loss did not improve from 1.29924
Epoch 1702/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4323 - val_loss: 1.3001 - val_accuracy: 0.4179

Epoch 01702: val_loss did not improve from 1.29924
Epoch 1703/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4338 - val_loss: 1.3047 - val_accuracy: 0.4203

Epoch 01703: val_loss did not improve from 1.29924
Epoch 1704/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4337 - val_loss: 1.3026 - val_accuracy: 0.4195

Epoch 01704: val_loss did not improve from 1.29924
Epoch 1705/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4306 - val_loss: 1.3034 - val_accuracy: 0.4250

Epoch 01705: val_loss did not improve from 1.29924
Epoch 1706/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4348 - val_loss: 1.3027 - val_accuracy: 0.4179

Epoch 01706: val_loss did not improve from 1.29924
Epoch 1707/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4312 - val_loss: 1.3005 - val_accuracy: 0.4234

Epoch 01707: val_loss did not improve from 1.29924
Epoch 1708/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4337 - val_loss: 1.3027 - val_accuracy: 0.4282

Epoch 01708: val_loss did not improve from 1.29924
Epoch 1709/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4295 - val_loss: 1.3059 - val_accuracy: 0.4226

Epoch 01709: val_loss did not improve from 1.29924
Epoch 1710/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4313 - val_loss: 1.3021 - val_accuracy: 0.4155

Epoch 01710: val_loss did not improve from 1.29924
Epoch 1711/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4341 - val_loss: 1.3045 - val_accuracy: 0.4211

Epoch 01711: val_loss did not improve from 1.29924
Epoch 1712/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4320 - val_loss: 1.3120 - val_accuracy: 0.4219

Epoch 01712: val_loss did not improve from 1.29924
Epoch 1713/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4317 - val_loss: 1.3067 - val_accuracy: 0.4211

Epoch 01713: val_loss did not improve from 1.29924
Epoch 1714/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4283 - val_loss: 1.3059 - val_accuracy: 0.4163

Epoch 01714: val_loss did not improve from 1.29924
Epoch 1715/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4302 - val_loss: 1.3042 - val_accuracy: 0.4187

Epoch 01715: val_loss did not improve from 1.29924
Epoch 1716/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4289 - val_loss: 1.3058 - val_accuracy: 0.4250

Epoch 01716: val_loss did not improve from 1.29924
Epoch 1717/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4314 - val_loss: 1.3016 - val_accuracy: 0.4179

Epoch 01717: val_loss did not improve from 1.29924
Epoch 1718/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4288 - val_loss: 1.3019 - val_accuracy: 0.4179

Epoch 01718: val_loss did not improve from 1.29924
Epoch 1719/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4331 - val_loss: 1.3053 - val_accuracy: 0.4258

Epoch 01719: val_loss did not improve from 1.29924
Epoch 1720/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4317 - val_loss: 1.3008 - val_accuracy: 0.4219

Epoch 01720: val_loss did not improve from 1.29924
Epoch 1721/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4285 - val_loss: 1.3039 - val_accuracy: 0.4091

Epoch 01721: val_loss did not improve from 1.29924
Epoch 1722/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4297 - val_loss: 1.3037 - val_accuracy: 0.4187

Epoch 01722: val_loss did not improve from 1.29924
Epoch 1723/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4306 - val_loss: 1.3027 - val_accuracy: 0.4147

Epoch 01723: val_loss did not improve from 1.29924
Epoch 1724/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4290 - val_loss: 1.3026 - val_accuracy: 0.4234

Epoch 01724: val_loss did not improve from 1.29924
Epoch 1725/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4326 - val_loss: 1.3032 - val_accuracy: 0.4226

Epoch 01725: val_loss did not improve from 1.29924
Epoch 1726/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4381 - val_loss: 1.3001 - val_accuracy: 0.4139

Epoch 01726: val_loss did not improve from 1.29924
Epoch 1727/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4288 - val_loss: 1.3026 - val_accuracy: 0.4234

Epoch 01727: val_loss did not improve from 1.29924
Epoch 1728/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4284 - val_loss: 1.3070 - val_accuracy: 0.4195

Epoch 01728: val_loss did not improve from 1.29924
Epoch 1729/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4294 - val_loss: 1.3010 - val_accuracy: 0.4234

Epoch 01729: val_loss did not improve from 1.29924
Epoch 1730/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4287 - val_loss: 1.3017 - val_accuracy: 0.4203

Epoch 01730: val_loss did not improve from 1.29924
Epoch 1731/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4287 - val_loss: 1.3043 - val_accuracy: 0.4155

Epoch 01731: val_loss did not improve from 1.29924
Epoch 1732/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4303 - val_loss: 1.3059 - val_accuracy: 0.4187

Epoch 01732: val_loss did not improve from 1.29924
Epoch 1733/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4289 - val_loss: 1.3020 - val_accuracy: 0.4211

Epoch 01733: val_loss did not improve from 1.29924
Epoch 1734/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4334 - val_loss: 1.3012 - val_accuracy: 0.4187

Epoch 01734: val_loss did not improve from 1.29924
Epoch 1735/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4324 - val_loss: 1.3007 - val_accuracy: 0.4131

Epoch 01735: val_loss did not improve from 1.29924
Epoch 1736/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4324 - val_loss: 1.3003 - val_accuracy: 0.4282

Epoch 01736: val_loss did not improve from 1.29924
Epoch 1737/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4303 - val_loss: 1.3004 - val_accuracy: 0.4242

Epoch 01737: val_loss did not improve from 1.29924
Epoch 1738/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4342 - val_loss: 1.2992 - val_accuracy: 0.4282

Epoch 01738: val_loss improved from 1.29924 to 1.29916, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1739/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4373 - val_loss: 1.3034 - val_accuracy: 0.4219

Epoch 01739: val_loss did not improve from 1.29916
Epoch 1740/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4280 - val_loss: 1.3071 - val_accuracy: 0.4187

Epoch 01740: val_loss did not improve from 1.29916
Epoch 1741/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4287 - val_loss: 1.3070 - val_accuracy: 0.4266

Epoch 01741: val_loss did not improve from 1.29916
Epoch 1742/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4319 - val_loss: 1.2995 - val_accuracy: 0.4322

Epoch 01742: val_loss did not improve from 1.29916
Epoch 1743/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4312 - val_loss: 1.3003 - val_accuracy: 0.4219

Epoch 01743: val_loss did not improve from 1.29916
Epoch 1744/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4280 - val_loss: 1.3015 - val_accuracy: 0.4171

Epoch 01744: val_loss did not improve from 1.29916
Epoch 1745/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4334 - val_loss: 1.3026 - val_accuracy: 0.4322

Epoch 01745: val_loss did not improve from 1.29916
Epoch 1746/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4314 - val_loss: 1.3034 - val_accuracy: 0.4187

Epoch 01746: val_loss did not improve from 1.29916
Epoch 1747/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4321 - val_loss: 1.3139 - val_accuracy: 0.4123

Epoch 01747: val_loss did not improve from 1.29916
Epoch 1748/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4316 - val_loss: 1.3093 - val_accuracy: 0.4219

Epoch 01748: val_loss did not improve from 1.29916
Epoch 1749/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4285 - val_loss: 1.3002 - val_accuracy: 0.4266

Epoch 01749: val_loss did not improve from 1.29916
Epoch 1750/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4295 - val_loss: 1.3059 - val_accuracy: 0.4250

Epoch 01750: val_loss did not improve from 1.29916
Epoch 1751/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4359 - val_loss: 1.2988 - val_accuracy: 0.4219

Epoch 01751: val_loss improved from 1.29916 to 1.29880, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1752/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4295 - val_loss: 1.3069 - val_accuracy: 0.4123

Epoch 01752: val_loss did not improve from 1.29880
Epoch 1753/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4315 - val_loss: 1.3052 - val_accuracy: 0.4179

Epoch 01753: val_loss did not improve from 1.29880
Epoch 1754/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4334 - val_loss: 1.3050 - val_accuracy: 0.4187

Epoch 01754: val_loss did not improve from 1.29880
Epoch 1755/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4264 - val_loss: 1.3046 - val_accuracy: 0.4179

Epoch 01755: val_loss did not improve from 1.29880
Epoch 1756/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4270 - val_loss: 1.2998 - val_accuracy: 0.4282

Epoch 01756: val_loss did not improve from 1.29880
Epoch 1757/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4295 - val_loss: 1.3028 - val_accuracy: 0.4219

Epoch 01757: val_loss did not improve from 1.29880
Epoch 1758/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4308 - val_loss: 1.3049 - val_accuracy: 0.4179

Epoch 01758: val_loss did not improve from 1.29880
Epoch 1759/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4307 - val_loss: 1.3044 - val_accuracy: 0.4107

Epoch 01759: val_loss did not improve from 1.29880
Epoch 1760/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4316 - val_loss: 1.3009 - val_accuracy: 0.4234

Epoch 01760: val_loss did not improve from 1.29880
Epoch 1761/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4338 - val_loss: 1.3005 - val_accuracy: 0.4314

Epoch 01761: val_loss did not improve from 1.29880
Epoch 1762/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4335 - val_loss: 1.3046 - val_accuracy: 0.4163

Epoch 01762: val_loss did not improve from 1.29880
Epoch 1763/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4317 - val_loss: 1.3045 - val_accuracy: 0.4187

Epoch 01763: val_loss did not improve from 1.29880
Epoch 1764/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4322 - val_loss: 1.2989 - val_accuracy: 0.4258

Epoch 01764: val_loss did not improve from 1.29880
Epoch 1765/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4318 - val_loss: 1.3034 - val_accuracy: 0.4266

Epoch 01765: val_loss did not improve from 1.29880
Epoch 1766/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4280 - val_loss: 1.3038 - val_accuracy: 0.4139

Epoch 01766: val_loss did not improve from 1.29880
Epoch 1767/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4280 - val_loss: 1.3037 - val_accuracy: 0.4203

Epoch 01767: val_loss did not improve from 1.29880
Epoch 1768/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4304 - val_loss: 1.3069 - val_accuracy: 0.4250

Epoch 01768: val_loss did not improve from 1.29880
Epoch 1769/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4302 - val_loss: 1.3059 - val_accuracy: 0.4115

Epoch 01769: val_loss did not improve from 1.29880
Epoch 1770/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4308 - val_loss: 1.3060 - val_accuracy: 0.4115

Epoch 01770: val_loss did not improve from 1.29880
Epoch 1771/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4212 - val_loss: 1.3033 - val_accuracy: 0.4163

Epoch 01771: val_loss did not improve from 1.29880
Epoch 1772/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4333 - val_loss: 1.3141 - val_accuracy: 0.4107

Epoch 01772: val_loss did not improve from 1.29880
Epoch 1773/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4310 - val_loss: 1.3019 - val_accuracy: 0.4179

Epoch 01773: val_loss did not improve from 1.29880
Epoch 1774/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4354 - val_loss: 1.3007 - val_accuracy: 0.4155

Epoch 01774: val_loss did not improve from 1.29880
Epoch 1775/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4338 - val_loss: 1.3013 - val_accuracy: 0.4115

Epoch 01775: val_loss did not improve from 1.29880
Epoch 1776/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4352 - val_loss: 1.3009 - val_accuracy: 0.4226

Epoch 01776: val_loss did not improve from 1.29880
Epoch 1777/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4301 - val_loss: 1.3023 - val_accuracy: 0.4242

Epoch 01777: val_loss did not improve from 1.29880
Epoch 1778/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4241 - val_loss: 1.2996 - val_accuracy: 0.4226

Epoch 01778: val_loss did not improve from 1.29880
Epoch 1779/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4310 - val_loss: 1.3018 - val_accuracy: 0.4211

Epoch 01779: val_loss did not improve from 1.29880
Epoch 1780/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4347 - val_loss: 1.3054 - val_accuracy: 0.4226

Epoch 01780: val_loss did not improve from 1.29880
Epoch 1781/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4328 - val_loss: 1.3042 - val_accuracy: 0.4219

Epoch 01781: val_loss did not improve from 1.29880
Epoch 1782/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4293 - val_loss: 1.3033 - val_accuracy: 0.4155

Epoch 01782: val_loss did not improve from 1.29880
Epoch 1783/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4310 - val_loss: 1.3035 - val_accuracy: 0.4179

Epoch 01783: val_loss did not improve from 1.29880
Epoch 1784/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4318 - val_loss: 1.3017 - val_accuracy: 0.4266

Epoch 01784: val_loss did not improve from 1.29880
Epoch 1785/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4289 - val_loss: 1.3006 - val_accuracy: 0.4266

Epoch 01785: val_loss did not improve from 1.29880
Epoch 1786/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4316 - val_loss: 1.3024 - val_accuracy: 0.4195

Epoch 01786: val_loss did not improve from 1.29880
Epoch 1787/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4295 - val_loss: 1.3022 - val_accuracy: 0.4211

Epoch 01787: val_loss did not improve from 1.29880
Epoch 1788/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4305 - val_loss: 1.2994 - val_accuracy: 0.4203

Epoch 01788: val_loss did not improve from 1.29880
Epoch 1789/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4306 - val_loss: 1.3044 - val_accuracy: 0.4338

Epoch 01789: val_loss did not improve from 1.29880
Epoch 1790/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4330 - val_loss: 1.3045 - val_accuracy: 0.4234

Epoch 01790: val_loss did not improve from 1.29880
Epoch 1791/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4359 - val_loss: 1.3166 - val_accuracy: 0.4147

Epoch 01791: val_loss did not improve from 1.29880
Epoch 1792/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4218 - val_loss: 1.3035 - val_accuracy: 0.4250

Epoch 01792: val_loss did not improve from 1.29880
Epoch 1793/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4280 - val_loss: 1.3063 - val_accuracy: 0.4179

Epoch 01793: val_loss did not improve from 1.29880
Epoch 1794/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4288 - val_loss: 1.3047 - val_accuracy: 0.4219

Epoch 01794: val_loss did not improve from 1.29880
Epoch 1795/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4327 - val_loss: 1.3012 - val_accuracy: 0.4187

Epoch 01795: val_loss did not improve from 1.29880
Epoch 1796/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4329 - val_loss: 1.3011 - val_accuracy: 0.4266

Epoch 01796: val_loss did not improve from 1.29880
Epoch 1797/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4311 - val_loss: 1.3041 - val_accuracy: 0.4258

Epoch 01797: val_loss did not improve from 1.29880
Epoch 1798/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4313 - val_loss: 1.3075 - val_accuracy: 0.4226

Epoch 01798: val_loss did not improve from 1.29880
Epoch 1799/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4267 - val_loss: 1.3057 - val_accuracy: 0.4123

Epoch 01799: val_loss did not improve from 1.29880
Epoch 1800/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4330 - val_loss: 1.3051 - val_accuracy: 0.4274

Epoch 01800: val_loss did not improve from 1.29880
Epoch 1801/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4373 - val_loss: 1.3024 - val_accuracy: 0.4226

Epoch 01801: val_loss did not improve from 1.29880
Epoch 1802/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4313 - val_loss: 1.3039 - val_accuracy: 0.4195

Epoch 01802: val_loss did not improve from 1.29880
Epoch 1803/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4282 - val_loss: 1.3012 - val_accuracy: 0.4258

Epoch 01803: val_loss did not improve from 1.29880
Epoch 1804/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4318 - val_loss: 1.3011 - val_accuracy: 0.4234

Epoch 01804: val_loss did not improve from 1.29880
Epoch 1805/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4317 - val_loss: 1.3009 - val_accuracy: 0.4155

Epoch 01805: val_loss did not improve from 1.29880
Epoch 1806/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4305 - val_loss: 1.3026 - val_accuracy: 0.4203

Epoch 01806: val_loss did not improve from 1.29880
Epoch 1807/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4325 - val_loss: 1.3024 - val_accuracy: 0.4314

Epoch 01807: val_loss did not improve from 1.29880
Epoch 1808/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4337 - val_loss: 1.3012 - val_accuracy: 0.4306

Epoch 01808: val_loss did not improve from 1.29880
Epoch 1809/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4362 - val_loss: 1.3010 - val_accuracy: 0.4266

Epoch 01809: val_loss did not improve from 1.29880
Epoch 1810/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4376 - val_loss: 1.3043 - val_accuracy: 0.4298

Epoch 01810: val_loss did not improve from 1.29880
Epoch 1811/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4319 - val_loss: 1.3031 - val_accuracy: 0.4266

Epoch 01811: val_loss did not improve from 1.29880
Epoch 1812/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4306 - val_loss: 1.3022 - val_accuracy: 0.4211

Epoch 01812: val_loss did not improve from 1.29880
Epoch 1813/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4302 - val_loss: 1.3002 - val_accuracy: 0.4242

Epoch 01813: val_loss did not improve from 1.29880
Epoch 1814/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4251 - val_loss: 1.3034 - val_accuracy: 0.4195

Epoch 01814: val_loss did not improve from 1.29880
Epoch 1815/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4323 - val_loss: 1.3039 - val_accuracy: 0.4139

Epoch 01815: val_loss did not improve from 1.29880
Epoch 1816/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4293 - val_loss: 1.3028 - val_accuracy: 0.4290

Epoch 01816: val_loss did not improve from 1.29880
Epoch 1817/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4317 - val_loss: 1.3012 - val_accuracy: 0.4250

Epoch 01817: val_loss did not improve from 1.29880
Epoch 1818/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4303 - val_loss: 1.3009 - val_accuracy: 0.4234

Epoch 01818: val_loss did not improve from 1.29880
Epoch 1819/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4329 - val_loss: 1.2994 - val_accuracy: 0.4211

Epoch 01819: val_loss did not improve from 1.29880
Epoch 1820/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4312 - val_loss: 1.3011 - val_accuracy: 0.4219

Epoch 01820: val_loss did not improve from 1.29880
Epoch 1821/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4310 - val_loss: 1.3025 - val_accuracy: 0.4203

Epoch 01821: val_loss did not improve from 1.29880
Epoch 1822/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4303 - val_loss: 1.3000 - val_accuracy: 0.4187

Epoch 01822: val_loss did not improve from 1.29880
Epoch 1823/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4303 - val_loss: 1.3020 - val_accuracy: 0.4155

Epoch 01823: val_loss did not improve from 1.29880
Epoch 1824/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4339 - val_loss: 1.3035 - val_accuracy: 0.4203

Epoch 01824: val_loss did not improve from 1.29880
Epoch 1825/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4324 - val_loss: 1.3111 - val_accuracy: 0.4226

Epoch 01825: val_loss did not improve from 1.29880
Epoch 1826/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4332 - val_loss: 1.3026 - val_accuracy: 0.4203

Epoch 01826: val_loss did not improve from 1.29880
Epoch 1827/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4327 - val_loss: 1.3041 - val_accuracy: 0.4211

Epoch 01827: val_loss did not improve from 1.29880
Epoch 1828/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4329 - val_loss: 1.2988 - val_accuracy: 0.4266

Epoch 01828: val_loss improved from 1.29880 to 1.29876, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1829/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4357 - val_loss: 1.3008 - val_accuracy: 0.4234

Epoch 01829: val_loss did not improve from 1.29876
Epoch 1830/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4279 - val_loss: 1.3062 - val_accuracy: 0.4203

Epoch 01830: val_loss did not improve from 1.29876
Epoch 1831/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4348 - val_loss: 1.3068 - val_accuracy: 0.4242

Epoch 01831: val_loss did not improve from 1.29876
Epoch 1832/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4354 - val_loss: 1.3036 - val_accuracy: 0.4203

Epoch 01832: val_loss did not improve from 1.29876
Epoch 1833/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4326 - val_loss: 1.3051 - val_accuracy: 0.4147

Epoch 01833: val_loss did not improve from 1.29876
Epoch 1834/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4274 - val_loss: 1.3033 - val_accuracy: 0.4203

Epoch 01834: val_loss did not improve from 1.29876
Epoch 1835/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4277 - val_loss: 1.3060 - val_accuracy: 0.4219

Epoch 01835: val_loss did not improve from 1.29876
Epoch 1836/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4348 - val_loss: 1.3038 - val_accuracy: 0.4219

Epoch 01836: val_loss did not improve from 1.29876
Epoch 1837/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4339 - val_loss: 1.3030 - val_accuracy: 0.4266

Epoch 01837: val_loss did not improve from 1.29876
Epoch 1838/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4325 - val_loss: 1.3051 - val_accuracy: 0.4242

Epoch 01838: val_loss did not improve from 1.29876
Epoch 1839/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4311 - val_loss: 1.3024 - val_accuracy: 0.4226

Epoch 01839: val_loss did not improve from 1.29876
Epoch 1840/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4317 - val_loss: 1.2994 - val_accuracy: 0.4226

Epoch 01840: val_loss did not improve from 1.29876
Epoch 1841/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4309 - val_loss: 1.3007 - val_accuracy: 0.4226

Epoch 01841: val_loss did not improve from 1.29876
Epoch 1842/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4370 - val_loss: 1.2988 - val_accuracy: 0.4203

Epoch 01842: val_loss did not improve from 1.29876
Epoch 1843/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4342 - val_loss: 1.3041 - val_accuracy: 0.4226

Epoch 01843: val_loss did not improve from 1.29876
Epoch 1844/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4370 - val_loss: 1.3037 - val_accuracy: 0.4187

Epoch 01844: val_loss did not improve from 1.29876
Epoch 1845/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4306 - val_loss: 1.3007 - val_accuracy: 0.4242

Epoch 01845: val_loss did not improve from 1.29876
Epoch 1846/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4342 - val_loss: 1.3028 - val_accuracy: 0.4155

Epoch 01846: val_loss did not improve from 1.29876
Epoch 1847/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4332 - val_loss: 1.2998 - val_accuracy: 0.4171

Epoch 01847: val_loss did not improve from 1.29876
Epoch 1848/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4359 - val_loss: 1.3011 - val_accuracy: 0.4083

Epoch 01848: val_loss did not improve from 1.29876
Epoch 1849/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4325 - val_loss: 1.3014 - val_accuracy: 0.4219

Epoch 01849: val_loss did not improve from 1.29876
Epoch 1850/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4356 - val_loss: 1.3009 - val_accuracy: 0.4195

Epoch 01850: val_loss did not improve from 1.29876
Epoch 1851/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4331 - val_loss: 1.3041 - val_accuracy: 0.4187

Epoch 01851: val_loss did not improve from 1.29876
Epoch 1852/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4308 - val_loss: 1.3028 - val_accuracy: 0.4155

Epoch 01852: val_loss did not improve from 1.29876
Epoch 1853/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4322 - val_loss: 1.3136 - val_accuracy: 0.4171

Epoch 01853: val_loss did not improve from 1.29876
Epoch 1854/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4288 - val_loss: 1.3105 - val_accuracy: 0.4242

Epoch 01854: val_loss did not improve from 1.29876
Epoch 1855/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4253 - val_loss: 1.3013 - val_accuracy: 0.4250

Epoch 01855: val_loss did not improve from 1.29876
Epoch 1856/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4288 - val_loss: 1.3013 - val_accuracy: 0.4123

Epoch 01856: val_loss did not improve from 1.29876
Epoch 1857/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4265 - val_loss: 1.3029 - val_accuracy: 0.4234

Epoch 01857: val_loss did not improve from 1.29876
Epoch 1858/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4348 - val_loss: 1.2993 - val_accuracy: 0.4242

Epoch 01858: val_loss did not improve from 1.29876
Epoch 1859/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4331 - val_loss: 1.3032 - val_accuracy: 0.4075

Epoch 01859: val_loss did not improve from 1.29876
Epoch 1860/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4317 - val_loss: 1.3005 - val_accuracy: 0.4226

Epoch 01860: val_loss did not improve from 1.29876
Epoch 1861/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4345 - val_loss: 1.3012 - val_accuracy: 0.4155

Epoch 01861: val_loss did not improve from 1.29876
Epoch 1862/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4347 - val_loss: 1.3038 - val_accuracy: 0.4322

Epoch 01862: val_loss did not improve from 1.29876
Epoch 1863/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4317 - val_loss: 1.2980 - val_accuracy: 0.4258

Epoch 01863: val_loss improved from 1.29876 to 1.29795, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1864/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4342 - val_loss: 1.3007 - val_accuracy: 0.4274

Epoch 01864: val_loss did not improve from 1.29795
Epoch 1865/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4350 - val_loss: 1.3004 - val_accuracy: 0.4195

Epoch 01865: val_loss did not improve from 1.29795
Epoch 1866/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4342 - val_loss: 1.3030 - val_accuracy: 0.4226

Epoch 01866: val_loss did not improve from 1.29795
Epoch 1867/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4330 - val_loss: 1.3012 - val_accuracy: 0.4187

Epoch 01867: val_loss did not improve from 1.29795
Epoch 1868/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4320 - val_loss: 1.3059 - val_accuracy: 0.4250

Epoch 01868: val_loss did not improve from 1.29795
Epoch 1869/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4369 - val_loss: 1.3017 - val_accuracy: 0.4226

Epoch 01869: val_loss did not improve from 1.29795
Epoch 1870/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4306 - val_loss: 1.3010 - val_accuracy: 0.4195

Epoch 01870: val_loss did not improve from 1.29795
Epoch 1871/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4294 - val_loss: 1.3009 - val_accuracy: 0.4290

Epoch 01871: val_loss did not improve from 1.29795
Epoch 1872/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4319 - val_loss: 1.2975 - val_accuracy: 0.4306

Epoch 01872: val_loss improved from 1.29795 to 1.29754, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 1873/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4315 - val_loss: 1.3002 - val_accuracy: 0.4266

Epoch 01873: val_loss did not improve from 1.29754
Epoch 1874/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4297 - val_loss: 1.2992 - val_accuracy: 0.4338

Epoch 01874: val_loss did not improve from 1.29754
Epoch 1875/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4301 - val_loss: 1.3027 - val_accuracy: 0.4234

Epoch 01875: val_loss did not improve from 1.29754
Epoch 1876/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4303 - val_loss: 1.3001 - val_accuracy: 0.4306

Epoch 01876: val_loss did not improve from 1.29754
Epoch 1877/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4310 - val_loss: 1.2988 - val_accuracy: 0.4226

Epoch 01877: val_loss did not improve from 1.29754
Epoch 1878/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4365 - val_loss: 1.3049 - val_accuracy: 0.4226

Epoch 01878: val_loss did not improve from 1.29754
Epoch 1879/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4357 - val_loss: 1.2995 - val_accuracy: 0.4298

Epoch 01879: val_loss did not improve from 1.29754
Epoch 1880/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4350 - val_loss: 1.2997 - val_accuracy: 0.4163

Epoch 01880: val_loss did not improve from 1.29754
Epoch 1881/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4319 - val_loss: 1.3010 - val_accuracy: 0.4211

Epoch 01881: val_loss did not improve from 1.29754
Epoch 1882/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4334 - val_loss: 1.2994 - val_accuracy: 0.4226

Epoch 01882: val_loss did not improve from 1.29754
Epoch 1883/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4328 - val_loss: 1.3004 - val_accuracy: 0.4274

Epoch 01883: val_loss did not improve from 1.29754
Epoch 1884/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4307 - val_loss: 1.3018 - val_accuracy: 0.4179

Epoch 01884: val_loss did not improve from 1.29754
Epoch 1885/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4300 - val_loss: 1.2996 - val_accuracy: 0.4290

Epoch 01885: val_loss did not improve from 1.29754
Epoch 1886/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4367 - val_loss: 1.2997 - val_accuracy: 0.4282

Epoch 01886: val_loss did not improve from 1.29754
Epoch 1887/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4326 - val_loss: 1.3012 - val_accuracy: 0.4179

Epoch 01887: val_loss did not improve from 1.29754
Epoch 1888/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4233 - val_loss: 1.3046 - val_accuracy: 0.4266

Epoch 01888: val_loss did not improve from 1.29754
Epoch 1889/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4321 - val_loss: 1.3024 - val_accuracy: 0.4274

Epoch 01889: val_loss did not improve from 1.29754
Epoch 1890/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4288 - val_loss: 1.3120 - val_accuracy: 0.4091

Epoch 01890: val_loss did not improve from 1.29754
Epoch 1891/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4307 - val_loss: 1.3074 - val_accuracy: 0.4234

Epoch 01891: val_loss did not improve from 1.29754
Epoch 1892/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4311 - val_loss: 1.3004 - val_accuracy: 0.4203

Epoch 01892: val_loss did not improve from 1.29754
Epoch 1893/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4327 - val_loss: 1.2989 - val_accuracy: 0.4290

Epoch 01893: val_loss did not improve from 1.29754
Epoch 1894/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4322 - val_loss: 1.3001 - val_accuracy: 0.4226

Epoch 01894: val_loss did not improve from 1.29754
Epoch 1895/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4343 - val_loss: 1.2983 - val_accuracy: 0.4179

Epoch 01895: val_loss did not improve from 1.29754
Epoch 1896/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4326 - val_loss: 1.3000 - val_accuracy: 0.4234

Epoch 01896: val_loss did not improve from 1.29754
Epoch 1897/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4326 - val_loss: 1.3034 - val_accuracy: 0.4203

Epoch 01897: val_loss did not improve from 1.29754
Epoch 1898/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4359 - val_loss: 1.3019 - val_accuracy: 0.4242

Epoch 01898: val_loss did not improve from 1.29754
Epoch 1899/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4325 - val_loss: 1.3097 - val_accuracy: 0.4139

Epoch 01899: val_loss did not improve from 1.29754
Epoch 1900/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4306 - val_loss: 1.3022 - val_accuracy: 0.4139

Epoch 01900: val_loss did not improve from 1.29754
Epoch 1901/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4281 - val_loss: 1.3006 - val_accuracy: 0.4139

Epoch 01901: val_loss did not improve from 1.29754
Epoch 1902/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4318 - val_loss: 1.3024 - val_accuracy: 0.4155

Epoch 01902: val_loss did not improve from 1.29754
Epoch 1903/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4290 - val_loss: 1.3002 - val_accuracy: 0.4195

Epoch 01903: val_loss did not improve from 1.29754
Epoch 1904/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4334 - val_loss: 1.3003 - val_accuracy: 0.4266

Epoch 01904: val_loss did not improve from 1.29754
Epoch 1905/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4334 - val_loss: 1.3059 - val_accuracy: 0.4298

Epoch 01905: val_loss did not improve from 1.29754
Epoch 1906/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4310 - val_loss: 1.3001 - val_accuracy: 0.4282

Epoch 01906: val_loss did not improve from 1.29754
Epoch 1907/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4331 - val_loss: 1.3030 - val_accuracy: 0.4163

Epoch 01907: val_loss did not improve from 1.29754
Epoch 1908/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4302 - val_loss: 1.2998 - val_accuracy: 0.4115

Epoch 01908: val_loss did not improve from 1.29754
Epoch 1909/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4253 - val_loss: 1.3132 - val_accuracy: 0.4107

Epoch 01909: val_loss did not improve from 1.29754
Epoch 1910/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4307 - val_loss: 1.3050 - val_accuracy: 0.4147

Epoch 01910: val_loss did not improve from 1.29754
Epoch 1911/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4306 - val_loss: 1.3010 - val_accuracy: 0.4298

Epoch 01911: val_loss did not improve from 1.29754
Epoch 1912/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4319 - val_loss: 1.3015 - val_accuracy: 0.4274

Epoch 01912: val_loss did not improve from 1.29754
Epoch 1913/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4337 - val_loss: 1.3010 - val_accuracy: 0.4179

Epoch 01913: val_loss did not improve from 1.29754
Epoch 1914/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4361 - val_loss: 1.3070 - val_accuracy: 0.4250

Epoch 01914: val_loss did not improve from 1.29754
Epoch 1915/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4356 - val_loss: 1.3006 - val_accuracy: 0.4203

Epoch 01915: val_loss did not improve from 1.29754
Epoch 1916/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4317 - val_loss: 1.3000 - val_accuracy: 0.4139

Epoch 01916: val_loss did not improve from 1.29754
Epoch 1917/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4297 - val_loss: 1.2994 - val_accuracy: 0.4155

Epoch 01917: val_loss did not improve from 1.29754
Epoch 1918/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4370 - val_loss: 1.3066 - val_accuracy: 0.4195

Epoch 01918: val_loss did not improve from 1.29754
Epoch 1919/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4327 - val_loss: 1.3064 - val_accuracy: 0.4179

Epoch 01919: val_loss did not improve from 1.29754
Epoch 1920/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4279 - val_loss: 1.3035 - val_accuracy: 0.4219

Epoch 01920: val_loss did not improve from 1.29754
Epoch 1921/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4288 - val_loss: 1.3015 - val_accuracy: 0.4163

Epoch 01921: val_loss did not improve from 1.29754
Epoch 1922/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4325 - val_loss: 1.3027 - val_accuracy: 0.4195

Epoch 01922: val_loss did not improve from 1.29754
Epoch 1923/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4288 - val_loss: 1.3227 - val_accuracy: 0.4075

Epoch 01923: val_loss did not improve from 1.29754
Epoch 1924/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4357 - val_loss: 1.3032 - val_accuracy: 0.4258

Epoch 01924: val_loss did not improve from 1.29754
Epoch 1925/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4302 - val_loss: 1.3015 - val_accuracy: 0.4219

Epoch 01925: val_loss did not improve from 1.29754
Epoch 1926/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4326 - val_loss: 1.3026 - val_accuracy: 0.4163

Epoch 01926: val_loss did not improve from 1.29754
Epoch 1927/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4365 - val_loss: 1.2987 - val_accuracy: 0.4203

Epoch 01927: val_loss did not improve from 1.29754
Epoch 1928/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4349 - val_loss: 1.3012 - val_accuracy: 0.4274

Epoch 01928: val_loss did not improve from 1.29754
Epoch 1929/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4357 - val_loss: 1.3003 - val_accuracy: 0.4211

Epoch 01929: val_loss did not improve from 1.29754
Epoch 1930/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4351 - val_loss: 1.3054 - val_accuracy: 0.4179

Epoch 01930: val_loss did not improve from 1.29754
Epoch 1931/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4331 - val_loss: 1.2999 - val_accuracy: 0.4219

Epoch 01931: val_loss did not improve from 1.29754
Epoch 1932/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4309 - val_loss: 1.3042 - val_accuracy: 0.4226

Epoch 01932: val_loss did not improve from 1.29754
Epoch 1933/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4332 - val_loss: 1.3018 - val_accuracy: 0.4203

Epoch 01933: val_loss did not improve from 1.29754
Epoch 1934/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4326 - val_loss: 1.2989 - val_accuracy: 0.4234

Epoch 01934: val_loss did not improve from 1.29754
Epoch 1935/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4304 - val_loss: 1.2989 - val_accuracy: 0.4219

Epoch 01935: val_loss did not improve from 1.29754
Epoch 1936/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4382 - val_loss: 1.3022 - val_accuracy: 0.4282

Epoch 01936: val_loss did not improve from 1.29754
Epoch 1937/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4333 - val_loss: 1.2995 - val_accuracy: 0.4203

Epoch 01937: val_loss did not improve from 1.29754
Epoch 1938/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4297 - val_loss: 1.3010 - val_accuracy: 0.4179

Epoch 01938: val_loss did not improve from 1.29754
Epoch 1939/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4338 - val_loss: 1.3064 - val_accuracy: 0.4171

Epoch 01939: val_loss did not improve from 1.29754
Epoch 1940/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4344 - val_loss: 1.2995 - val_accuracy: 0.4091

Epoch 01940: val_loss did not improve from 1.29754
Epoch 1941/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4334 - val_loss: 1.3062 - val_accuracy: 0.4147

Epoch 01941: val_loss did not improve from 1.29754
Epoch 1942/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4319 - val_loss: 1.3002 - val_accuracy: 0.4075

Epoch 01942: val_loss did not improve from 1.29754
Epoch 1943/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4327 - val_loss: 1.2994 - val_accuracy: 0.4250

Epoch 01943: val_loss did not improve from 1.29754
Epoch 1944/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4365 - val_loss: 1.3037 - val_accuracy: 0.4242

Epoch 01944: val_loss did not improve from 1.29754
Epoch 1945/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4351 - val_loss: 1.3015 - val_accuracy: 0.4282

Epoch 01945: val_loss did not improve from 1.29754
Epoch 1946/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4318 - val_loss: 1.3025 - val_accuracy: 0.4282

Epoch 01946: val_loss did not improve from 1.29754
Epoch 1947/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4346 - val_loss: 1.2986 - val_accuracy: 0.4258

Epoch 01947: val_loss did not improve from 1.29754
Epoch 1948/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4324 - val_loss: 1.3028 - val_accuracy: 0.4203

Epoch 01948: val_loss did not improve from 1.29754
Epoch 1949/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4355 - val_loss: 1.3015 - val_accuracy: 0.4211

Epoch 01949: val_loss did not improve from 1.29754
Epoch 1950/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4385 - val_loss: 1.3028 - val_accuracy: 0.4195

Epoch 01950: val_loss did not improve from 1.29754
Epoch 1951/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4298 - val_loss: 1.3022 - val_accuracy: 0.4131

Epoch 01951: val_loss did not improve from 1.29754
Epoch 1952/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4315 - val_loss: 1.3029 - val_accuracy: 0.4147

Epoch 01952: val_loss did not improve from 1.29754
Epoch 1953/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4324 - val_loss: 1.3089 - val_accuracy: 0.4219

Epoch 01953: val_loss did not improve from 1.29754
Epoch 1954/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4368 - val_loss: 1.3003 - val_accuracy: 0.4147

Epoch 01954: val_loss did not improve from 1.29754
Epoch 1955/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4355 - val_loss: 1.3012 - val_accuracy: 0.4250

Epoch 01955: val_loss did not improve from 1.29754
Epoch 1956/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4350 - val_loss: 1.2993 - val_accuracy: 0.4155

Epoch 01956: val_loss did not improve from 1.29754
Epoch 1957/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4336 - val_loss: 1.3023 - val_accuracy: 0.4163

Epoch 01957: val_loss did not improve from 1.29754
Epoch 1958/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4326 - val_loss: 1.3199 - val_accuracy: 0.4051

Epoch 01958: val_loss did not improve from 1.29754
Epoch 1959/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4296 - val_loss: 1.3017 - val_accuracy: 0.4147

Epoch 01959: val_loss did not improve from 1.29754
Epoch 1960/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4327 - val_loss: 1.2996 - val_accuracy: 0.4131

Epoch 01960: val_loss did not improve from 1.29754
Epoch 1961/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4319 - val_loss: 1.3002 - val_accuracy: 0.4195

Epoch 01961: val_loss did not improve from 1.29754
Epoch 1962/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4281 - val_loss: 1.3093 - val_accuracy: 0.4131

Epoch 01962: val_loss did not improve from 1.29754
Epoch 1963/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4340 - val_loss: 1.3092 - val_accuracy: 0.4155

Epoch 01963: val_loss did not improve from 1.29754
Epoch 1964/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4325 - val_loss: 1.3009 - val_accuracy: 0.4203

Epoch 01964: val_loss did not improve from 1.29754
Epoch 1965/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4326 - val_loss: 1.2990 - val_accuracy: 0.4290

Epoch 01965: val_loss did not improve from 1.29754
Epoch 1966/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4357 - val_loss: 1.3050 - val_accuracy: 0.4274

Epoch 01966: val_loss did not improve from 1.29754
Epoch 1967/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4392 - val_loss: 1.3024 - val_accuracy: 0.4258

Epoch 01967: val_loss did not improve from 1.29754
Epoch 1968/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4313 - val_loss: 1.3029 - val_accuracy: 0.4179

Epoch 01968: val_loss did not improve from 1.29754
Epoch 1969/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4292 - val_loss: 1.3038 - val_accuracy: 0.4338

Epoch 01969: val_loss did not improve from 1.29754
Epoch 1970/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4375 - val_loss: 1.3005 - val_accuracy: 0.4179

Epoch 01970: val_loss did not improve from 1.29754
Epoch 1971/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4352 - val_loss: 1.3026 - val_accuracy: 0.4099

Epoch 01971: val_loss did not improve from 1.29754
Epoch 1972/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4338 - val_loss: 1.3003 - val_accuracy: 0.4203

Epoch 01972: val_loss did not improve from 1.29754
Epoch 1973/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4313 - val_loss: 1.3068 - val_accuracy: 0.4179

Epoch 01973: val_loss did not improve from 1.29754
Epoch 1974/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4272 - val_loss: 1.3066 - val_accuracy: 0.4123

Epoch 01974: val_loss did not improve from 1.29754
Epoch 1975/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4300 - val_loss: 1.3056 - val_accuracy: 0.4187

Epoch 01975: val_loss did not improve from 1.29754
Epoch 1976/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4351 - val_loss: 1.2987 - val_accuracy: 0.4274

Epoch 01976: val_loss did not improve from 1.29754
Epoch 1977/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4381 - val_loss: 1.3007 - val_accuracy: 0.4203

Epoch 01977: val_loss did not improve from 1.29754
Epoch 1978/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4349 - val_loss: 1.3111 - val_accuracy: 0.4107

Epoch 01978: val_loss did not improve from 1.29754
Epoch 1979/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4385 - val_loss: 1.3011 - val_accuracy: 0.4211

Epoch 01979: val_loss did not improve from 1.29754
Epoch 1980/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4344 - val_loss: 1.2977 - val_accuracy: 0.4234

Epoch 01980: val_loss did not improve from 1.29754
Epoch 1981/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4340 - val_loss: 1.3065 - val_accuracy: 0.4226

Epoch 01981: val_loss did not improve from 1.29754
Epoch 1982/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4359 - val_loss: 1.2984 - val_accuracy: 0.4211

Epoch 01982: val_loss did not improve from 1.29754
Epoch 1983/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4362 - val_loss: 1.2986 - val_accuracy: 0.4203

Epoch 01983: val_loss did not improve from 1.29754
Epoch 1984/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4324 - val_loss: 1.3007 - val_accuracy: 0.4203

Epoch 01984: val_loss did not improve from 1.29754
Epoch 1985/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4320 - val_loss: 1.3101 - val_accuracy: 0.4139

Epoch 01985: val_loss did not improve from 1.29754
Epoch 1986/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4289 - val_loss: 1.3008 - val_accuracy: 0.4147

Epoch 01986: val_loss did not improve from 1.29754
Epoch 1987/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4343 - val_loss: 1.3016 - val_accuracy: 0.4099

Epoch 01987: val_loss did not improve from 1.29754
Epoch 1988/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4339 - val_loss: 1.3021 - val_accuracy: 0.4163

Epoch 01988: val_loss did not improve from 1.29754
Epoch 1989/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4356 - val_loss: 1.2995 - val_accuracy: 0.4171

Epoch 01989: val_loss did not improve from 1.29754
Epoch 1990/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4344 - val_loss: 1.3009 - val_accuracy: 0.4250

Epoch 01990: val_loss did not improve from 1.29754
Epoch 1991/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4340 - val_loss: 1.3009 - val_accuracy: 0.4298

Epoch 01991: val_loss did not improve from 1.29754
Epoch 1992/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4317 - val_loss: 1.3043 - val_accuracy: 0.4115

Epoch 01992: val_loss did not improve from 1.29754
Epoch 1993/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4268 - val_loss: 1.3059 - val_accuracy: 0.4179

Epoch 01993: val_loss did not improve from 1.29754
Epoch 1994/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4323 - val_loss: 1.3011 - val_accuracy: 0.4131

Epoch 01994: val_loss did not improve from 1.29754
Epoch 1995/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4360 - val_loss: 1.3105 - val_accuracy: 0.4123

Epoch 01995: val_loss did not improve from 1.29754
Epoch 1996/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4289 - val_loss: 1.3001 - val_accuracy: 0.4203

Epoch 01996: val_loss did not improve from 1.29754
Epoch 1997/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4308 - val_loss: 1.2993 - val_accuracy: 0.4123

Epoch 01997: val_loss did not improve from 1.29754
Epoch 1998/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4316 - val_loss: 1.3003 - val_accuracy: 0.4147

Epoch 01998: val_loss did not improve from 1.29754
Epoch 1999/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4326 - val_loss: 1.3025 - val_accuracy: 0.4211

Epoch 01999: val_loss did not improve from 1.29754
Epoch 2000/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4294 - val_loss: 1.3001 - val_accuracy: 0.4131

Epoch 02000: val_loss did not improve from 1.29754
Epoch 2001/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4330 - val_loss: 1.3011 - val_accuracy: 0.4219

Epoch 02001: val_loss did not improve from 1.29754
Epoch 2002/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4334 - val_loss: 1.2988 - val_accuracy: 0.4075

Epoch 02002: val_loss did not improve from 1.29754
Epoch 2003/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4322 - val_loss: 1.3069 - val_accuracy: 0.4314

Epoch 02003: val_loss did not improve from 1.29754
Epoch 2004/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4335 - val_loss: 1.3012 - val_accuracy: 0.4171

Epoch 02004: val_loss did not improve from 1.29754
Epoch 2005/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4296 - val_loss: 1.2989 - val_accuracy: 0.4171

Epoch 02005: val_loss did not improve from 1.29754
Epoch 2006/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4332 - val_loss: 1.3002 - val_accuracy: 0.4195

Epoch 02006: val_loss did not improve from 1.29754
Epoch 2007/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4333 - val_loss: 1.2962 - val_accuracy: 0.4179

Epoch 02007: val_loss improved from 1.29754 to 1.29615, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 2008/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4323 - val_loss: 1.3103 - val_accuracy: 0.4139

Epoch 02008: val_loss did not improve from 1.29615
Epoch 2009/10000
12/12 - 0s - loss: 1.2591 - accuracy: 0.4361 - val_loss: 1.3003 - val_accuracy: 0.4250

Epoch 02009: val_loss did not improve from 1.29615
Epoch 2010/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4393 - val_loss: 1.2973 - val_accuracy: 0.4195

Epoch 02010: val_loss did not improve from 1.29615
Epoch 2011/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4352 - val_loss: 1.2959 - val_accuracy: 0.4195

Epoch 02011: val_loss improved from 1.29615 to 1.29589, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 2012/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4351 - val_loss: 1.2973 - val_accuracy: 0.4274

Epoch 02012: val_loss did not improve from 1.29589
Epoch 2013/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4349 - val_loss: 1.2963 - val_accuracy: 0.4266

Epoch 02013: val_loss did not improve from 1.29589
Epoch 2014/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4368 - val_loss: 1.3043 - val_accuracy: 0.4234

Epoch 02014: val_loss did not improve from 1.29589
Epoch 2015/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4348 - val_loss: 1.3094 - val_accuracy: 0.4187

Epoch 02015: val_loss did not improve from 1.29589
Epoch 2016/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4320 - val_loss: 1.2994 - val_accuracy: 0.4203

Epoch 02016: val_loss did not improve from 1.29589
Epoch 2017/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4330 - val_loss: 1.3026 - val_accuracy: 0.4131

Epoch 02017: val_loss did not improve from 1.29589
Epoch 2018/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4312 - val_loss: 1.3018 - val_accuracy: 0.4083

Epoch 02018: val_loss did not improve from 1.29589
Epoch 2019/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4329 - val_loss: 1.3010 - val_accuracy: 0.4290

Epoch 02019: val_loss did not improve from 1.29589
Epoch 2020/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4335 - val_loss: 1.3069 - val_accuracy: 0.4195

Epoch 02020: val_loss did not improve from 1.29589
Epoch 2021/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4357 - val_loss: 1.2995 - val_accuracy: 0.4219

Epoch 02021: val_loss did not improve from 1.29589
Epoch 2022/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4330 - val_loss: 1.3019 - val_accuracy: 0.4250

Epoch 02022: val_loss did not improve from 1.29589
Epoch 2023/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4391 - val_loss: 1.3035 - val_accuracy: 0.4187

Epoch 02023: val_loss did not improve from 1.29589
Epoch 2024/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4359 - val_loss: 1.2983 - val_accuracy: 0.4179

Epoch 02024: val_loss did not improve from 1.29589
Epoch 2025/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4308 - val_loss: 1.2995 - val_accuracy: 0.4226

Epoch 02025: val_loss did not improve from 1.29589
Epoch 2026/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4363 - val_loss: 1.2994 - val_accuracy: 0.4195

Epoch 02026: val_loss did not improve from 1.29589
Epoch 2027/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4329 - val_loss: 1.2979 - val_accuracy: 0.4258

Epoch 02027: val_loss did not improve from 1.29589
Epoch 2028/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4299 - val_loss: 1.3076 - val_accuracy: 0.4282

Epoch 02028: val_loss did not improve from 1.29589
Epoch 2029/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4303 - val_loss: 1.3024 - val_accuracy: 0.4187

Epoch 02029: val_loss did not improve from 1.29589
Epoch 2030/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4293 - val_loss: 1.2951 - val_accuracy: 0.4219

Epoch 02030: val_loss improved from 1.29589 to 1.29511, saving model to ./results/NN_thk_class/aggr_theta/ckpt_9
Epoch 2031/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4357 - val_loss: 1.2988 - val_accuracy: 0.4203

Epoch 02031: val_loss did not improve from 1.29511
Epoch 2032/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4328 - val_loss: 1.3035 - val_accuracy: 0.4179

Epoch 02032: val_loss did not improve from 1.29511
Epoch 2033/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4372 - val_loss: 1.2984 - val_accuracy: 0.4203

Epoch 02033: val_loss did not improve from 1.29511
Epoch 2034/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4388 - val_loss: 1.3024 - val_accuracy: 0.4242

Epoch 02034: val_loss did not improve from 1.29511
Epoch 2035/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4340 - val_loss: 1.2972 - val_accuracy: 0.4203

Epoch 02035: val_loss did not improve from 1.29511
Epoch 2036/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4302 - val_loss: 1.3058 - val_accuracy: 0.4035

Epoch 02036: val_loss did not improve from 1.29511
Epoch 2037/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4305 - val_loss: 1.3023 - val_accuracy: 0.4139

Epoch 02037: val_loss did not improve from 1.29511
Epoch 2038/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4345 - val_loss: 1.2981 - val_accuracy: 0.4211

Epoch 02038: val_loss did not improve from 1.29511
Epoch 2039/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4309 - val_loss: 1.3030 - val_accuracy: 0.4226

Epoch 02039: val_loss did not improve from 1.29511
Epoch 2040/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4365 - val_loss: 1.3091 - val_accuracy: 0.4171

Epoch 02040: val_loss did not improve from 1.29511
Epoch 2041/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4287 - val_loss: 1.2995 - val_accuracy: 0.4155

Epoch 02041: val_loss did not improve from 1.29511
Epoch 2042/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4260 - val_loss: 1.3007 - val_accuracy: 0.4171

Epoch 02042: val_loss did not improve from 1.29511
Epoch 2043/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4380 - val_loss: 1.2993 - val_accuracy: 0.4219

Epoch 02043: val_loss did not improve from 1.29511
Epoch 2044/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4392 - val_loss: 1.2987 - val_accuracy: 0.4234

Epoch 02044: val_loss did not improve from 1.29511
Epoch 2045/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4323 - val_loss: 1.3067 - val_accuracy: 0.4203

Epoch 02045: val_loss did not improve from 1.29511
Epoch 2046/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4311 - val_loss: 1.2963 - val_accuracy: 0.4171

Epoch 02046: val_loss did not improve from 1.29511
Epoch 2047/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4342 - val_loss: 1.2971 - val_accuracy: 0.4203

Epoch 02047: val_loss did not improve from 1.29511
Epoch 2048/10000
12/12 - 0s - loss: 1.2593 - accuracy: 0.4349 - val_loss: 1.3029 - val_accuracy: 0.4115

Epoch 02048: val_loss did not improve from 1.29511
Epoch 2049/10000
12/12 - 0s - loss: 1.2585 - accuracy: 0.4329 - val_loss: 1.3024 - val_accuracy: 0.4234

Epoch 02049: val_loss did not improve from 1.29511
Epoch 2050/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4335 - val_loss: 1.3048 - val_accuracy: 0.4155

Epoch 02050: val_loss did not improve from 1.29511
Epoch 2051/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4323 - val_loss: 1.3003 - val_accuracy: 0.4099

Epoch 02051: val_loss did not improve from 1.29511
Epoch 2052/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4311 - val_loss: 1.3024 - val_accuracy: 0.4195

Epoch 02052: val_loss did not improve from 1.29511
Epoch 2053/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4339 - val_loss: 1.3108 - val_accuracy: 0.4123

Epoch 02053: val_loss did not improve from 1.29511
Epoch 2054/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4341 - val_loss: 1.2999 - val_accuracy: 0.4187

Epoch 02054: val_loss did not improve from 1.29511
Epoch 2055/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4347 - val_loss: 1.2986 - val_accuracy: 0.4147

Epoch 02055: val_loss did not improve from 1.29511
Epoch 2056/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4312 - val_loss: 1.2993 - val_accuracy: 0.4274

Epoch 02056: val_loss did not improve from 1.29511
Epoch 2057/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4344 - val_loss: 1.3069 - val_accuracy: 0.4266

Epoch 02057: val_loss did not improve from 1.29511
Epoch 2058/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4318 - val_loss: 1.3054 - val_accuracy: 0.4219

Epoch 02058: val_loss did not improve from 1.29511
Epoch 2059/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4347 - val_loss: 1.2997 - val_accuracy: 0.4250

Epoch 02059: val_loss did not improve from 1.29511
Epoch 2060/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4350 - val_loss: 1.2995 - val_accuracy: 0.4179

Epoch 02060: val_loss did not improve from 1.29511
Epoch 2061/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4314 - val_loss: 1.3029 - val_accuracy: 0.4195

Epoch 02061: val_loss did not improve from 1.29511
Epoch 2062/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4364 - val_loss: 1.2993 - val_accuracy: 0.4139

Epoch 02062: val_loss did not improve from 1.29511
Epoch 2063/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4363 - val_loss: 1.2994 - val_accuracy: 0.4067

Epoch 02063: val_loss did not improve from 1.29511
Epoch 2064/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4279 - val_loss: 1.3030 - val_accuracy: 0.4282

Epoch 02064: val_loss did not improve from 1.29511
Epoch 2065/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4348 - val_loss: 1.3111 - val_accuracy: 0.4242

Epoch 02065: val_loss did not improve from 1.29511
Epoch 2066/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4350 - val_loss: 1.3003 - val_accuracy: 0.4171

Epoch 02066: val_loss did not improve from 1.29511
Epoch 2067/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4295 - val_loss: 1.3021 - val_accuracy: 0.4179

Epoch 02067: val_loss did not improve from 1.29511
Epoch 2068/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4344 - val_loss: 1.2962 - val_accuracy: 0.4187

Epoch 02068: val_loss did not improve from 1.29511
Epoch 2069/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4331 - val_loss: 1.3014 - val_accuracy: 0.4187

Epoch 02069: val_loss did not improve from 1.29511
Epoch 2070/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4341 - val_loss: 1.3025 - val_accuracy: 0.4115

Epoch 02070: val_loss did not improve from 1.29511
Epoch 2071/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4383 - val_loss: 1.3003 - val_accuracy: 0.4226

Epoch 02071: val_loss did not improve from 1.29511
Epoch 2072/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4365 - val_loss: 1.3008 - val_accuracy: 0.4274

Epoch 02072: val_loss did not improve from 1.29511
Epoch 2073/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4368 - val_loss: 1.3022 - val_accuracy: 0.4211

Epoch 02073: val_loss did not improve from 1.29511
Epoch 2074/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4325 - val_loss: 1.3031 - val_accuracy: 0.4211

Epoch 02074: val_loss did not improve from 1.29511
Epoch 2075/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4360 - val_loss: 1.2998 - val_accuracy: 0.4258

Epoch 02075: val_loss did not improve from 1.29511
Epoch 2076/10000
12/12 - 0s - loss: 1.2571 - accuracy: 0.4386 - val_loss: 1.3025 - val_accuracy: 0.4226

Epoch 02076: val_loss did not improve from 1.29511
Epoch 2077/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4325 - val_loss: 1.3039 - val_accuracy: 0.4234

Epoch 02077: val_loss did not improve from 1.29511
Epoch 2078/10000
12/12 - 0s - loss: 1.2574 - accuracy: 0.4304 - val_loss: 1.2997 - val_accuracy: 0.4211

Epoch 02078: val_loss did not improve from 1.29511
Epoch 2079/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4346 - val_loss: 1.3076 - val_accuracy: 0.4258

Epoch 02079: val_loss did not improve from 1.29511
Epoch 2080/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4342 - val_loss: 1.2994 - val_accuracy: 0.4226

Epoch 02080: val_loss did not improve from 1.29511
Epoch 2081/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4339 - val_loss: 1.2988 - val_accuracy: 0.4139

Epoch 02081: val_loss did not improve from 1.29511
Epoch 2082/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4349 - val_loss: 1.2975 - val_accuracy: 0.4242

Epoch 02082: val_loss did not improve from 1.29511
Epoch 2083/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4372 - val_loss: 1.3029 - val_accuracy: 0.4282

Epoch 02083: val_loss did not improve from 1.29511
Epoch 2084/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4348 - val_loss: 1.3083 - val_accuracy: 0.4107

Epoch 02084: val_loss did not improve from 1.29511
Epoch 2085/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4321 - val_loss: 1.2984 - val_accuracy: 0.4187

Epoch 02085: val_loss did not improve from 1.29511
Epoch 2086/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4322 - val_loss: 1.3025 - val_accuracy: 0.4123

Epoch 02086: val_loss did not improve from 1.29511
Epoch 2087/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4308 - val_loss: 1.3029 - val_accuracy: 0.4195

Epoch 02087: val_loss did not improve from 1.29511
Epoch 2088/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4276 - val_loss: 1.3031 - val_accuracy: 0.4211

Epoch 02088: val_loss did not improve from 1.29511
Epoch 2089/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4330 - val_loss: 1.3045 - val_accuracy: 0.4147

Epoch 02089: val_loss did not improve from 1.29511
Epoch 2090/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4333 - val_loss: 1.2989 - val_accuracy: 0.4187

Epoch 02090: val_loss did not improve from 1.29511
Epoch 2091/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4372 - val_loss: 1.2979 - val_accuracy: 0.4107

Epoch 02091: val_loss did not improve from 1.29511
Epoch 2092/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4365 - val_loss: 1.3026 - val_accuracy: 0.4282

Epoch 02092: val_loss did not improve from 1.29511
Epoch 2093/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4334 - val_loss: 1.2996 - val_accuracy: 0.4187

Epoch 02093: val_loss did not improve from 1.29511
Epoch 2094/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4349 - val_loss: 1.3013 - val_accuracy: 0.4107

Epoch 02094: val_loss did not improve from 1.29511
Epoch 2095/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4309 - val_loss: 1.3040 - val_accuracy: 0.4139

Epoch 02095: val_loss did not improve from 1.29511
Epoch 2096/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4318 - val_loss: 1.3048 - val_accuracy: 0.4139

Epoch 02096: val_loss did not improve from 1.29511
Epoch 2097/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4335 - val_loss: 1.3000 - val_accuracy: 0.4258

Epoch 02097: val_loss did not improve from 1.29511
Epoch 2098/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4352 - val_loss: 1.3002 - val_accuracy: 0.4226

Epoch 02098: val_loss did not improve from 1.29511
Epoch 2099/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4360 - val_loss: 1.3057 - val_accuracy: 0.4274

Epoch 02099: val_loss did not improve from 1.29511
Epoch 2100/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4342 - val_loss: 1.2970 - val_accuracy: 0.4171

Epoch 02100: val_loss did not improve from 1.29511
Epoch 2101/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4327 - val_loss: 1.3013 - val_accuracy: 0.4203

Epoch 02101: val_loss did not improve from 1.29511
Epoch 2102/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4363 - val_loss: 1.3001 - val_accuracy: 0.4163

Epoch 02102: val_loss did not improve from 1.29511
Epoch 2103/10000
12/12 - 0s - loss: 1.2563 - accuracy: 0.4368 - val_loss: 1.2982 - val_accuracy: 0.4211

Epoch 02103: val_loss did not improve from 1.29511
Epoch 2104/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4317 - val_loss: 1.3105 - val_accuracy: 0.4187

Epoch 02104: val_loss did not improve from 1.29511
Epoch 2105/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4349 - val_loss: 1.3006 - val_accuracy: 0.4266

Epoch 02105: val_loss did not improve from 1.29511
Epoch 2106/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4341 - val_loss: 1.2983 - val_accuracy: 0.4266

Epoch 02106: val_loss did not improve from 1.29511
Epoch 2107/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4331 - val_loss: 1.2985 - val_accuracy: 0.4147

Epoch 02107: val_loss did not improve from 1.29511
Epoch 2108/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4346 - val_loss: 1.3023 - val_accuracy: 0.4211

Epoch 02108: val_loss did not improve from 1.29511
Epoch 2109/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4350 - val_loss: 1.3023 - val_accuracy: 0.4258

Epoch 02109: val_loss did not improve from 1.29511
Epoch 2110/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4342 - val_loss: 1.2999 - val_accuracy: 0.4211

Epoch 02110: val_loss did not improve from 1.29511
Epoch 2111/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4359 - val_loss: 1.2996 - val_accuracy: 0.4234

Epoch 02111: val_loss did not improve from 1.29511
Epoch 2112/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4395 - val_loss: 1.2977 - val_accuracy: 0.4171

Epoch 02112: val_loss did not improve from 1.29511
Epoch 2113/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4371 - val_loss: 1.3002 - val_accuracy: 0.4123

Epoch 02113: val_loss did not improve from 1.29511
Epoch 2114/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4326 - val_loss: 1.3086 - val_accuracy: 0.4163

Epoch 02114: val_loss did not improve from 1.29511
Epoch 2115/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4349 - val_loss: 1.3000 - val_accuracy: 0.4250

Epoch 02115: val_loss did not improve from 1.29511
Epoch 2116/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4349 - val_loss: 1.2991 - val_accuracy: 0.4226

Epoch 02116: val_loss did not improve from 1.29511
Epoch 2117/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4384 - val_loss: 1.2971 - val_accuracy: 0.4219

Epoch 02117: val_loss did not improve from 1.29511
Epoch 2118/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4362 - val_loss: 1.3003 - val_accuracy: 0.4147

Epoch 02118: val_loss did not improve from 1.29511
Epoch 2119/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4393 - val_loss: 1.2999 - val_accuracy: 0.4179

Epoch 02119: val_loss did not improve from 1.29511
Epoch 2120/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4380 - val_loss: 1.2975 - val_accuracy: 0.4155

Epoch 02120: val_loss did not improve from 1.29511
Epoch 2121/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4366 - val_loss: 1.2998 - val_accuracy: 0.4195

Epoch 02121: val_loss did not improve from 1.29511
Epoch 2122/10000
12/12 - 0s - loss: 1.2586 - accuracy: 0.4373 - val_loss: 1.3013 - val_accuracy: 0.4219

Epoch 02122: val_loss did not improve from 1.29511
Epoch 2123/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4339 - val_loss: 1.3059 - val_accuracy: 0.4226

Epoch 02123: val_loss did not improve from 1.29511
Epoch 2124/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4336 - val_loss: 1.3002 - val_accuracy: 0.4258

Epoch 02124: val_loss did not improve from 1.29511
Epoch 2125/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4312 - val_loss: 1.3002 - val_accuracy: 0.4211

Epoch 02125: val_loss did not improve from 1.29511
Epoch 2126/10000
12/12 - 0s - loss: 1.2567 - accuracy: 0.4315 - val_loss: 1.3009 - val_accuracy: 0.4203

Epoch 02126: val_loss did not improve from 1.29511
Epoch 2127/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4339 - val_loss: 1.2994 - val_accuracy: 0.4195

Epoch 02127: val_loss did not improve from 1.29511
Epoch 2128/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4342 - val_loss: 1.2992 - val_accuracy: 0.4163

Epoch 02128: val_loss did not improve from 1.29511
Epoch 2129/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4315 - val_loss: 1.2984 - val_accuracy: 0.4187

Epoch 02129: val_loss did not improve from 1.29511
Epoch 2130/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4388 - val_loss: 1.2992 - val_accuracy: 0.4266

Epoch 02130: val_loss did not improve from 1.29511
Epoch 2131/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4360 - val_loss: 1.3005 - val_accuracy: 0.4179

Epoch 02131: val_loss did not improve from 1.29511
Epoch 2132/10000
12/12 - 0s - loss: 1.2584 - accuracy: 0.4334 - val_loss: 1.2993 - val_accuracy: 0.4107

Epoch 02132: val_loss did not improve from 1.29511
Epoch 2133/10000
12/12 - 0s - loss: 1.2568 - accuracy: 0.4389 - val_loss: 1.3070 - val_accuracy: 0.4107

Epoch 02133: val_loss did not improve from 1.29511
Epoch 2134/10000
12/12 - 0s - loss: 1.2577 - accuracy: 0.4374 - val_loss: 1.2995 - val_accuracy: 0.4219

Epoch 02134: val_loss did not improve from 1.29511
Epoch 2135/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4351 - val_loss: 1.3002 - val_accuracy: 0.4274

Epoch 02135: val_loss did not improve from 1.29511
Epoch 2136/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4318 - val_loss: 1.3021 - val_accuracy: 0.4274

Epoch 02136: val_loss did not improve from 1.29511
Epoch 2137/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4353 - val_loss: 1.3037 - val_accuracy: 0.4123

Epoch 02137: val_loss did not improve from 1.29511
Epoch 2138/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4382 - val_loss: 1.3034 - val_accuracy: 0.4179

Epoch 02138: val_loss did not improve from 1.29511
Epoch 2139/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4300 - val_loss: 1.3005 - val_accuracy: 0.4187

Epoch 02139: val_loss did not improve from 1.29511
Epoch 2140/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4367 - val_loss: 1.2996 - val_accuracy: 0.4147

Epoch 02140: val_loss did not improve from 1.29511
Epoch 2141/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4334 - val_loss: 1.3044 - val_accuracy: 0.4139

Epoch 02141: val_loss did not improve from 1.29511
Epoch 2142/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4362 - val_loss: 1.3049 - val_accuracy: 0.4139

Epoch 02142: val_loss did not improve from 1.29511
Epoch 2143/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4388 - val_loss: 1.2998 - val_accuracy: 0.4147

Epoch 02143: val_loss did not improve from 1.29511
Epoch 2144/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4353 - val_loss: 1.3020 - val_accuracy: 0.4115

Epoch 02144: val_loss did not improve from 1.29511
Epoch 2145/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4365 - val_loss: 1.3000 - val_accuracy: 0.4139

Epoch 02145: val_loss did not improve from 1.29511
Epoch 2146/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4323 - val_loss: 1.3048 - val_accuracy: 0.4242

Epoch 02146: val_loss did not improve from 1.29511
Epoch 2147/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4358 - val_loss: 1.3076 - val_accuracy: 0.4242

Epoch 02147: val_loss did not improve from 1.29511
Epoch 2148/10000
12/12 - 0s - loss: 1.2564 - accuracy: 0.4349 - val_loss: 1.3004 - val_accuracy: 0.4219

Epoch 02148: val_loss did not improve from 1.29511
Epoch 2149/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4309 - val_loss: 1.2993 - val_accuracy: 0.4147

Epoch 02149: val_loss did not improve from 1.29511
Epoch 2150/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4339 - val_loss: 1.2985 - val_accuracy: 0.4123

Epoch 02150: val_loss did not improve from 1.29511
Epoch 2151/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4301 - val_loss: 1.3045 - val_accuracy: 0.4274

Epoch 02151: val_loss did not improve from 1.29511
Epoch 2152/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4341 - val_loss: 1.2984 - val_accuracy: 0.4298

Epoch 02152: val_loss did not improve from 1.29511
Epoch 2153/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4352 - val_loss: 1.3004 - val_accuracy: 0.4226

Epoch 02153: val_loss did not improve from 1.29511
Epoch 2154/10000
12/12 - 0s - loss: 1.2579 - accuracy: 0.4367 - val_loss: 1.3021 - val_accuracy: 0.4298

Epoch 02154: val_loss did not improve from 1.29511
Epoch 2155/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4324 - val_loss: 1.2966 - val_accuracy: 0.4250

Epoch 02155: val_loss did not improve from 1.29511
Epoch 2156/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4380 - val_loss: 1.2966 - val_accuracy: 0.4258

Epoch 02156: val_loss did not improve from 1.29511
Epoch 2157/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4377 - val_loss: 1.2991 - val_accuracy: 0.4226

Epoch 02157: val_loss did not improve from 1.29511
Epoch 2158/10000
12/12 - 0s - loss: 1.2554 - accuracy: 0.4388 - val_loss: 1.3048 - val_accuracy: 0.4306

Epoch 02158: val_loss did not improve from 1.29511
Epoch 2159/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4345 - val_loss: 1.2989 - val_accuracy: 0.4115

Epoch 02159: val_loss did not improve from 1.29511
Epoch 2160/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4324 - val_loss: 1.2999 - val_accuracy: 0.4123

Epoch 02160: val_loss did not improve from 1.29511
Epoch 2161/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4341 - val_loss: 1.3043 - val_accuracy: 0.4226

Epoch 02161: val_loss did not improve from 1.29511
Epoch 2162/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4401 - val_loss: 1.3059 - val_accuracy: 0.4219

Epoch 02162: val_loss did not improve from 1.29511
Epoch 2163/10000
12/12 - 0s - loss: 1.2573 - accuracy: 0.4367 - val_loss: 1.3043 - val_accuracy: 0.4211

Epoch 02163: val_loss did not improve from 1.29511
Epoch 2164/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4311 - val_loss: 1.3070 - val_accuracy: 0.4075

Epoch 02164: val_loss did not improve from 1.29511
Epoch 2165/10000
12/12 - 0s - loss: 1.2599 - accuracy: 0.4344 - val_loss: 1.2971 - val_accuracy: 0.4131

Epoch 02165: val_loss did not improve from 1.29511
Epoch 2166/10000
12/12 - 0s - loss: 1.2572 - accuracy: 0.4368 - val_loss: 1.3078 - val_accuracy: 0.4242

Epoch 02166: val_loss did not improve from 1.29511
Epoch 2167/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4343 - val_loss: 1.2998 - val_accuracy: 0.4131

Epoch 02167: val_loss did not improve from 1.29511
Epoch 2168/10000
12/12 - 0s - loss: 1.2562 - accuracy: 0.4327 - val_loss: 1.2990 - val_accuracy: 0.4139

Epoch 02168: val_loss did not improve from 1.29511
Epoch 2169/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4290 - val_loss: 1.3026 - val_accuracy: 0.4131

Epoch 02169: val_loss did not improve from 1.29511
Epoch 2170/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4348 - val_loss: 1.2994 - val_accuracy: 0.4211

Epoch 02170: val_loss did not improve from 1.29511
Epoch 2171/10000
12/12 - 0s - loss: 1.2548 - accuracy: 0.4369 - val_loss: 1.2979 - val_accuracy: 0.4171

Epoch 02171: val_loss did not improve from 1.29511
Epoch 2172/10000
12/12 - 0s - loss: 1.2555 - accuracy: 0.4335 - val_loss: 1.3006 - val_accuracy: 0.4211

Epoch 02172: val_loss did not improve from 1.29511
Epoch 2173/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4367 - val_loss: 1.2970 - val_accuracy: 0.4226

Epoch 02173: val_loss did not improve from 1.29511
Epoch 2174/10000
12/12 - 0s - loss: 1.2559 - accuracy: 0.4359 - val_loss: 1.2995 - val_accuracy: 0.4163

Epoch 02174: val_loss did not improve from 1.29511
Epoch 2175/10000
12/12 - 0s - loss: 1.2581 - accuracy: 0.4312 - val_loss: 1.3009 - val_accuracy: 0.4147

Epoch 02175: val_loss did not improve from 1.29511
Epoch 2176/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4340 - val_loss: 1.3021 - val_accuracy: 0.4115

Epoch 02176: val_loss did not improve from 1.29511
Epoch 2177/10000
12/12 - 0s - loss: 1.2557 - accuracy: 0.4376 - val_loss: 1.3029 - val_accuracy: 0.4242

Epoch 02177: val_loss did not improve from 1.29511
Epoch 2178/10000
12/12 - 0s - loss: 1.2578 - accuracy: 0.4339 - val_loss: 1.3041 - val_accuracy: 0.4330

Epoch 02178: val_loss did not improve from 1.29511
Epoch 2179/10000
12/12 - 0s - loss: 1.2570 - accuracy: 0.4349 - val_loss: 1.3072 - val_accuracy: 0.4187

Epoch 02179: val_loss did not improve from 1.29511
Epoch 2180/10000
12/12 - 0s - loss: 1.2576 - accuracy: 0.4344 - val_loss: 1.3006 - val_accuracy: 0.4155

Epoch 02180: val_loss did not improve from 1.29511
Epoch 2181/10000
12/12 - 0s - loss: 1.2547 - accuracy: 0.4357 - val_loss: 1.2979 - val_accuracy: 0.4234

Epoch 02181: val_loss did not improve from 1.29511
Epoch 2182/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4349 - val_loss: 1.2990 - val_accuracy: 0.4211

Epoch 02182: val_loss did not improve from 1.29511
Epoch 2183/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4378 - val_loss: 1.2983 - val_accuracy: 0.4107

Epoch 02183: val_loss did not improve from 1.29511
Epoch 2184/10000
12/12 - 0s - loss: 1.2583 - accuracy: 0.4362 - val_loss: 1.2984 - val_accuracy: 0.4155

Epoch 02184: val_loss did not improve from 1.29511
Epoch 2185/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4356 - val_loss: 1.3070 - val_accuracy: 0.4139

Epoch 02185: val_loss did not improve from 1.29511
Epoch 2186/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4322 - val_loss: 1.3026 - val_accuracy: 0.4211

Epoch 02186: val_loss did not improve from 1.29511
Epoch 2187/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4333 - val_loss: 1.3009 - val_accuracy: 0.4171

Epoch 02187: val_loss did not improve from 1.29511
Epoch 2188/10000
12/12 - 0s - loss: 1.2546 - accuracy: 0.4367 - val_loss: 1.2990 - val_accuracy: 0.4147

Epoch 02188: val_loss did not improve from 1.29511
Epoch 2189/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4372 - val_loss: 1.2981 - val_accuracy: 0.4171

Epoch 02189: val_loss did not improve from 1.29511
Epoch 2190/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4316 - val_loss: 1.3005 - val_accuracy: 0.4155

Epoch 02190: val_loss did not improve from 1.29511
Epoch 2191/10000
12/12 - 0s - loss: 1.2560 - accuracy: 0.4355 - val_loss: 1.3023 - val_accuracy: 0.4171

Epoch 02191: val_loss did not improve from 1.29511
Epoch 2192/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4326 - val_loss: 1.3079 - val_accuracy: 0.4314

Epoch 02192: val_loss did not improve from 1.29511
Epoch 2193/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4341 - val_loss: 1.3011 - val_accuracy: 0.4179

Epoch 02193: val_loss did not improve from 1.29511
Epoch 2194/10000
12/12 - 0s - loss: 1.2566 - accuracy: 0.4349 - val_loss: 1.2977 - val_accuracy: 0.4115

Epoch 02194: val_loss did not improve from 1.29511
Epoch 2195/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4342 - val_loss: 1.2973 - val_accuracy: 0.4123

Epoch 02195: val_loss did not improve from 1.29511
Epoch 2196/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4359 - val_loss: 1.3047 - val_accuracy: 0.4242

Epoch 02196: val_loss did not improve from 1.29511
Epoch 2197/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4316 - val_loss: 1.2981 - val_accuracy: 0.4219

Epoch 02197: val_loss did not improve from 1.29511
Epoch 2198/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4299 - val_loss: 1.2992 - val_accuracy: 0.4226

Epoch 02198: val_loss did not improve from 1.29511
Epoch 2199/10000
12/12 - 0s - loss: 1.2544 - accuracy: 0.4370 - val_loss: 1.2998 - val_accuracy: 0.4171

Epoch 02199: val_loss did not improve from 1.29511
Epoch 2200/10000
12/12 - 0s - loss: 1.2535 - accuracy: 0.4342 - val_loss: 1.3027 - val_accuracy: 0.4131

Epoch 02200: val_loss did not improve from 1.29511
Epoch 2201/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4355 - val_loss: 1.3042 - val_accuracy: 0.4242

Epoch 02201: val_loss did not improve from 1.29511
Epoch 2202/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4317 - val_loss: 1.2981 - val_accuracy: 0.4219

Epoch 02202: val_loss did not improve from 1.29511
Epoch 2203/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4371 - val_loss: 1.2978 - val_accuracy: 0.4203

Epoch 02203: val_loss did not improve from 1.29511
Epoch 2204/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4329 - val_loss: 1.2973 - val_accuracy: 0.4187

Epoch 02204: val_loss did not improve from 1.29511
Epoch 2205/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4291 - val_loss: 1.2994 - val_accuracy: 0.4131

Epoch 02205: val_loss did not improve from 1.29511
Epoch 2206/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4373 - val_loss: 1.2955 - val_accuracy: 0.4250

Epoch 02206: val_loss did not improve from 1.29511
Epoch 2207/10000
12/12 - 0s - loss: 1.2561 - accuracy: 0.4349 - val_loss: 1.2990 - val_accuracy: 0.4282

Epoch 02207: val_loss did not improve from 1.29511
Epoch 2208/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4324 - val_loss: 1.2987 - val_accuracy: 0.4195

Epoch 02208: val_loss did not improve from 1.29511
Epoch 2209/10000
12/12 - 0s - loss: 1.2565 - accuracy: 0.4394 - val_loss: 1.3002 - val_accuracy: 0.4203

Epoch 02209: val_loss did not improve from 1.29511
Epoch 2210/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4373 - val_loss: 1.3004 - val_accuracy: 0.4171

Epoch 02210: val_loss did not improve from 1.29511
Epoch 2211/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4341 - val_loss: 1.3000 - val_accuracy: 0.4179

Epoch 02211: val_loss did not improve from 1.29511
Epoch 2212/10000
12/12 - 0s - loss: 1.2543 - accuracy: 0.4371 - val_loss: 1.2973 - val_accuracy: 0.4147

Epoch 02212: val_loss did not improve from 1.29511
Epoch 2213/10000
12/12 - 0s - loss: 1.2537 - accuracy: 0.4377 - val_loss: 1.2986 - val_accuracy: 0.4163

Epoch 02213: val_loss did not improve from 1.29511
Epoch 2214/10000
12/12 - 0s - loss: 1.2551 - accuracy: 0.4371 - val_loss: 1.3008 - val_accuracy: 0.4219

Epoch 02214: val_loss did not improve from 1.29511
Epoch 2215/10000
12/12 - 0s - loss: 1.2542 - accuracy: 0.4389 - val_loss: 1.3002 - val_accuracy: 0.4274

Epoch 02215: val_loss did not improve from 1.29511
Epoch 2216/10000
12/12 - 0s - loss: 1.2536 - accuracy: 0.4395 - val_loss: 1.2973 - val_accuracy: 0.4266

Epoch 02216: val_loss did not improve from 1.29511
Epoch 2217/10000
12/12 - 0s - loss: 1.2558 - accuracy: 0.4347 - val_loss: 1.2984 - val_accuracy: 0.4219

Epoch 02217: val_loss did not improve from 1.29511
Epoch 2218/10000
12/12 - 0s - loss: 1.2556 - accuracy: 0.4371 - val_loss: 1.3035 - val_accuracy: 0.4179

Epoch 02218: val_loss did not improve from 1.29511
Epoch 2219/10000
12/12 - 0s - loss: 1.2550 - accuracy: 0.4354 - val_loss: 1.2990 - val_accuracy: 0.4234

Epoch 02219: val_loss did not improve from 1.29511
Epoch 2220/10000
12/12 - 0s - loss: 1.2552 - accuracy: 0.4387 - val_loss: 1.3014 - val_accuracy: 0.4211

Epoch 02220: val_loss did not improve from 1.29511
Epoch 2221/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4346 - val_loss: 1.2982 - val_accuracy: 0.4123

Epoch 02221: val_loss did not improve from 1.29511
Epoch 2222/10000
12/12 - 0s - loss: 1.2575 - accuracy: 0.4357 - val_loss: 1.3068 - val_accuracy: 0.4179

Epoch 02222: val_loss did not improve from 1.29511
Epoch 2223/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4353 - val_loss: 1.2984 - val_accuracy: 0.4211

Epoch 02223: val_loss did not improve from 1.29511
Epoch 2224/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4378 - val_loss: 1.3034 - val_accuracy: 0.4338

Epoch 02224: val_loss did not improve from 1.29511
Epoch 2225/10000
12/12 - 0s - loss: 1.2569 - accuracy: 0.4378 - val_loss: 1.2986 - val_accuracy: 0.4250

Epoch 02225: val_loss did not improve from 1.29511
Epoch 2226/10000
12/12 - 0s - loss: 1.2580 - accuracy: 0.4360 - val_loss: 1.3034 - val_accuracy: 0.4139

Epoch 02226: val_loss did not improve from 1.29511
Epoch 2227/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4323 - val_loss: 1.3018 - val_accuracy: 0.4139

Epoch 02227: val_loss did not improve from 1.29511
Epoch 2228/10000
12/12 - 0s - loss: 1.2587 - accuracy: 0.4329 - val_loss: 1.3017 - val_accuracy: 0.4250

Epoch 02228: val_loss did not improve from 1.29511
Epoch 2229/10000
12/12 - 0s - loss: 1.2549 - accuracy: 0.4371 - val_loss: 1.3006 - val_accuracy: 0.4282

Epoch 02229: val_loss did not improve from 1.29511
Epoch 2230/10000
12/12 - 0s - loss: 1.2582 - accuracy: 0.4354 - val_loss: 1.2994 - val_accuracy: 0.4163

Epoch 02230: val_loss did not improve from 1.29511
Epoch 02230: early stopping
*************************** Fold #: 10 ***************************
Model: "sequential_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_276 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_277 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_278 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_279 (Dense)            (None, 5)                 155       
=================================================================
Total params: 2,165
Trainable params: 2,165
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
12/12 - 0s - loss: 1.6118 - accuracy: 0.2014 - val_loss: 1.6052 - val_accuracy: 0.2145

Epoch 00001: val_loss improved from inf to 1.60517, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2/10000
12/12 - 0s - loss: 1.6015 - accuracy: 0.2262 - val_loss: 1.5956 - val_accuracy: 0.2217

Epoch 00002: val_loss improved from 1.60517 to 1.59555, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3/10000
12/12 - 0s - loss: 1.5927 - accuracy: 0.2467 - val_loss: 1.5854 - val_accuracy: 0.2560

Epoch 00003: val_loss improved from 1.59555 to 1.58541, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 4/10000
12/12 - 0s - loss: 1.5822 - accuracy: 0.2610 - val_loss: 1.5720 - val_accuracy: 0.2791

Epoch 00004: val_loss improved from 1.58541 to 1.57198, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 5/10000
12/12 - 0s - loss: 1.5669 - accuracy: 0.2898 - val_loss: 1.5552 - val_accuracy: 0.2935

Epoch 00005: val_loss improved from 1.57198 to 1.55517, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 6/10000
12/12 - 0s - loss: 1.5483 - accuracy: 0.3195 - val_loss: 1.5346 - val_accuracy: 0.3453

Epoch 00006: val_loss improved from 1.55517 to 1.53462, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 7/10000
12/12 - 0s - loss: 1.5263 - accuracy: 0.3429 - val_loss: 1.5092 - val_accuracy: 0.3541

Epoch 00007: val_loss improved from 1.53462 to 1.50917, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 8/10000
12/12 - 0s - loss: 1.5011 - accuracy: 0.3532 - val_loss: 1.4826 - val_accuracy: 0.3844

Epoch 00008: val_loss improved from 1.50917 to 1.48260, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 9/10000
12/12 - 0s - loss: 1.4739 - accuracy: 0.3538 - val_loss: 1.4550 - val_accuracy: 0.3684

Epoch 00009: val_loss improved from 1.48260 to 1.45504, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 10/10000
12/12 - 0s - loss: 1.4438 - accuracy: 0.3668 - val_loss: 1.4244 - val_accuracy: 0.3868

Epoch 00010: val_loss improved from 1.45504 to 1.42442, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 11/10000
12/12 - 0s - loss: 1.4143 - accuracy: 0.3827 - val_loss: 1.4003 - val_accuracy: 0.3876

Epoch 00011: val_loss improved from 1.42442 to 1.40035, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 12/10000
12/12 - 0s - loss: 1.3892 - accuracy: 0.3767 - val_loss: 1.3783 - val_accuracy: 0.3931

Epoch 00012: val_loss improved from 1.40035 to 1.37834, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 13/10000
12/12 - 0s - loss: 1.3683 - accuracy: 0.3825 - val_loss: 1.3646 - val_accuracy: 0.3923

Epoch 00013: val_loss improved from 1.37834 to 1.36457, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 14/10000
12/12 - 0s - loss: 1.3545 - accuracy: 0.3900 - val_loss: 1.3547 - val_accuracy: 0.3852

Epoch 00014: val_loss improved from 1.36457 to 1.35473, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 15/10000
12/12 - 0s - loss: 1.3469 - accuracy: 0.3899 - val_loss: 1.3501 - val_accuracy: 0.3907

Epoch 00015: val_loss improved from 1.35473 to 1.35008, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 16/10000
12/12 - 0s - loss: 1.3420 - accuracy: 0.3926 - val_loss: 1.3474 - val_accuracy: 0.3844

Epoch 00016: val_loss improved from 1.35008 to 1.34736, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 17/10000
12/12 - 0s - loss: 1.3421 - accuracy: 0.3927 - val_loss: 1.3466 - val_accuracy: 0.3971

Epoch 00017: val_loss improved from 1.34736 to 1.34661, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 18/10000
12/12 - 0s - loss: 1.3421 - accuracy: 0.3903 - val_loss: 1.3470 - val_accuracy: 0.3876

Epoch 00018: val_loss did not improve from 1.34661
Epoch 19/10000
12/12 - 0s - loss: 1.3383 - accuracy: 0.3863 - val_loss: 1.3455 - val_accuracy: 0.3915

Epoch 00019: val_loss improved from 1.34661 to 1.34553, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 20/10000
12/12 - 0s - loss: 1.3364 - accuracy: 0.3897 - val_loss: 1.3444 - val_accuracy: 0.3915

Epoch 00020: val_loss improved from 1.34553 to 1.34438, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 21/10000
12/12 - 0s - loss: 1.3364 - accuracy: 0.3883 - val_loss: 1.3438 - val_accuracy: 0.3979

Epoch 00021: val_loss improved from 1.34438 to 1.34379, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 22/10000
12/12 - 0s - loss: 1.3372 - accuracy: 0.3864 - val_loss: 1.3461 - val_accuracy: 0.3716

Epoch 00022: val_loss did not improve from 1.34379
Epoch 23/10000
12/12 - 0s - loss: 1.3392 - accuracy: 0.3927 - val_loss: 1.3427 - val_accuracy: 0.3971

Epoch 00023: val_loss improved from 1.34379 to 1.34266, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 24/10000
12/12 - 0s - loss: 1.3357 - accuracy: 0.3946 - val_loss: 1.3445 - val_accuracy: 0.4043

Epoch 00024: val_loss did not improve from 1.34266
Epoch 25/10000
12/12 - 0s - loss: 1.3341 - accuracy: 0.4002 - val_loss: 1.3435 - val_accuracy: 0.3900

Epoch 00025: val_loss did not improve from 1.34266
Epoch 26/10000
12/12 - 0s - loss: 1.3344 - accuracy: 0.3882 - val_loss: 1.3442 - val_accuracy: 0.3939

Epoch 00026: val_loss did not improve from 1.34266
Epoch 27/10000
12/12 - 0s - loss: 1.3338 - accuracy: 0.3939 - val_loss: 1.3425 - val_accuracy: 0.3915

Epoch 00027: val_loss improved from 1.34266 to 1.34253, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 28/10000
12/12 - 0s - loss: 1.3330 - accuracy: 0.3975 - val_loss: 1.3463 - val_accuracy: 0.4011

Epoch 00028: val_loss did not improve from 1.34253
Epoch 29/10000
12/12 - 0s - loss: 1.3367 - accuracy: 0.3951 - val_loss: 1.3464 - val_accuracy: 0.3860

Epoch 00029: val_loss did not improve from 1.34253
Epoch 30/10000
12/12 - 0s - loss: 1.3353 - accuracy: 0.3984 - val_loss: 1.3438 - val_accuracy: 0.4067

Epoch 00030: val_loss did not improve from 1.34253
Epoch 31/10000
12/12 - 0s - loss: 1.3337 - accuracy: 0.3933 - val_loss: 1.3451 - val_accuracy: 0.3915

Epoch 00031: val_loss did not improve from 1.34253
Epoch 32/10000
12/12 - 0s - loss: 1.3345 - accuracy: 0.3897 - val_loss: 1.3420 - val_accuracy: 0.3939

Epoch 00032: val_loss improved from 1.34253 to 1.34195, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 33/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3909 - val_loss: 1.3414 - val_accuracy: 0.4019

Epoch 00033: val_loss improved from 1.34195 to 1.34136, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 34/10000
12/12 - 0s - loss: 1.3328 - accuracy: 0.3928 - val_loss: 1.3414 - val_accuracy: 0.3900

Epoch 00034: val_loss did not improve from 1.34136
Epoch 35/10000
12/12 - 0s - loss: 1.3356 - accuracy: 0.3906 - val_loss: 1.3426 - val_accuracy: 0.4067

Epoch 00035: val_loss did not improve from 1.34136
Epoch 36/10000
12/12 - 0s - loss: 1.3331 - accuracy: 0.3897 - val_loss: 1.3398 - val_accuracy: 0.3892

Epoch 00036: val_loss improved from 1.34136 to 1.33976, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 37/10000
12/12 - 0s - loss: 1.3325 - accuracy: 0.3960 - val_loss: 1.3426 - val_accuracy: 0.4099

Epoch 00037: val_loss did not improve from 1.33976
Epoch 38/10000
12/12 - 0s - loss: 1.3349 - accuracy: 0.3952 - val_loss: 1.3427 - val_accuracy: 0.3852

Epoch 00038: val_loss did not improve from 1.33976
Epoch 39/10000
12/12 - 0s - loss: 1.3333 - accuracy: 0.3944 - val_loss: 1.3408 - val_accuracy: 0.4011

Epoch 00039: val_loss did not improve from 1.33976
Epoch 40/10000
12/12 - 0s - loss: 1.3310 - accuracy: 0.3950 - val_loss: 1.3398 - val_accuracy: 0.4003

Epoch 00040: val_loss did not improve from 1.33976
Epoch 41/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3955 - val_loss: 1.3401 - val_accuracy: 0.4011

Epoch 00041: val_loss did not improve from 1.33976
Epoch 42/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3939 - val_loss: 1.3405 - val_accuracy: 0.4059

Epoch 00042: val_loss did not improve from 1.33976
Epoch 43/10000
12/12 - 0s - loss: 1.3316 - accuracy: 0.3939 - val_loss: 1.3408 - val_accuracy: 0.3907

Epoch 00043: val_loss did not improve from 1.33976
Epoch 44/10000
12/12 - 0s - loss: 1.3339 - accuracy: 0.3936 - val_loss: 1.3401 - val_accuracy: 0.4011

Epoch 00044: val_loss did not improve from 1.33976
Epoch 45/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3933 - val_loss: 1.3419 - val_accuracy: 0.4051

Epoch 00045: val_loss did not improve from 1.33976
Epoch 46/10000
12/12 - 0s - loss: 1.3312 - accuracy: 0.3947 - val_loss: 1.3402 - val_accuracy: 0.3915

Epoch 00046: val_loss did not improve from 1.33976
Epoch 47/10000
12/12 - 0s - loss: 1.3309 - accuracy: 0.3955 - val_loss: 1.3396 - val_accuracy: 0.3931

Epoch 00047: val_loss improved from 1.33976 to 1.33964, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 48/10000
12/12 - 0s - loss: 1.3298 - accuracy: 0.3947 - val_loss: 1.3393 - val_accuracy: 0.3971

Epoch 00048: val_loss improved from 1.33964 to 1.33932, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 49/10000
12/12 - 0s - loss: 1.3307 - accuracy: 0.3938 - val_loss: 1.3395 - val_accuracy: 0.4019

Epoch 00049: val_loss did not improve from 1.33932
Epoch 50/10000
12/12 - 0s - loss: 1.3305 - accuracy: 0.3956 - val_loss: 1.3396 - val_accuracy: 0.3892

Epoch 00050: val_loss did not improve from 1.33932
Epoch 51/10000
12/12 - 0s - loss: 1.3298 - accuracy: 0.3947 - val_loss: 1.3386 - val_accuracy: 0.4019

Epoch 00051: val_loss improved from 1.33932 to 1.33859, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 52/10000
12/12 - 0s - loss: 1.3299 - accuracy: 0.3969 - val_loss: 1.3381 - val_accuracy: 0.4035

Epoch 00052: val_loss improved from 1.33859 to 1.33807, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 53/10000
12/12 - 0s - loss: 1.3294 - accuracy: 0.3960 - val_loss: 1.3400 - val_accuracy: 0.3939

Epoch 00053: val_loss did not improve from 1.33807
Epoch 54/10000
12/12 - 0s - loss: 1.3324 - accuracy: 0.3908 - val_loss: 1.3382 - val_accuracy: 0.3971

Epoch 00054: val_loss did not improve from 1.33807
Epoch 55/10000
12/12 - 0s - loss: 1.3348 - accuracy: 0.3913 - val_loss: 1.3444 - val_accuracy: 0.3979

Epoch 00055: val_loss did not improve from 1.33807
Epoch 56/10000
12/12 - 0s - loss: 1.3315 - accuracy: 0.3932 - val_loss: 1.3384 - val_accuracy: 0.3915

Epoch 00056: val_loss did not improve from 1.33807
Epoch 57/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.3960 - val_loss: 1.3385 - val_accuracy: 0.3915

Epoch 00057: val_loss did not improve from 1.33807
Epoch 58/10000
12/12 - 0s - loss: 1.3308 - accuracy: 0.3924 - val_loss: 1.3403 - val_accuracy: 0.3876

Epoch 00058: val_loss did not improve from 1.33807
Epoch 59/10000
12/12 - 0s - loss: 1.3302 - accuracy: 0.3951 - val_loss: 1.3393 - val_accuracy: 0.3995

Epoch 00059: val_loss did not improve from 1.33807
Epoch 60/10000
12/12 - 0s - loss: 1.3296 - accuracy: 0.3938 - val_loss: 1.3379 - val_accuracy: 0.3971

Epoch 00060: val_loss improved from 1.33807 to 1.33794, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 61/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3927 - val_loss: 1.3382 - val_accuracy: 0.4099

Epoch 00061: val_loss did not improve from 1.33794
Epoch 62/10000
12/12 - 0s - loss: 1.3291 - accuracy: 0.3959 - val_loss: 1.3376 - val_accuracy: 0.4035

Epoch 00062: val_loss improved from 1.33794 to 1.33758, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 63/10000
12/12 - 0s - loss: 1.3284 - accuracy: 0.3963 - val_loss: 1.3370 - val_accuracy: 0.3979

Epoch 00063: val_loss improved from 1.33758 to 1.33699, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 64/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3979 - val_loss: 1.3381 - val_accuracy: 0.4075

Epoch 00064: val_loss did not improve from 1.33699
Epoch 65/10000
12/12 - 0s - loss: 1.3292 - accuracy: 0.3957 - val_loss: 1.3375 - val_accuracy: 0.3900

Epoch 00065: val_loss did not improve from 1.33699
Epoch 66/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3939 - val_loss: 1.3373 - val_accuracy: 0.3915

Epoch 00066: val_loss did not improve from 1.33699
Epoch 67/10000
12/12 - 0s - loss: 1.3323 - accuracy: 0.3900 - val_loss: 1.3470 - val_accuracy: 0.3923

Epoch 00067: val_loss did not improve from 1.33699
Epoch 68/10000
12/12 - 0s - loss: 1.3330 - accuracy: 0.3943 - val_loss: 1.3368 - val_accuracy: 0.3947

Epoch 00068: val_loss improved from 1.33699 to 1.33682, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 69/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.3889 - val_loss: 1.3379 - val_accuracy: 0.3876

Epoch 00069: val_loss did not improve from 1.33682
Epoch 70/10000
12/12 - 0s - loss: 1.3301 - accuracy: 0.3872 - val_loss: 1.3384 - val_accuracy: 0.3931

Epoch 00070: val_loss did not improve from 1.33682
Epoch 71/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3940 - val_loss: 1.3363 - val_accuracy: 0.3955

Epoch 00071: val_loss improved from 1.33682 to 1.33633, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 72/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3970 - val_loss: 1.3380 - val_accuracy: 0.3907

Epoch 00072: val_loss did not improve from 1.33633
Epoch 73/10000
12/12 - 0s - loss: 1.3293 - accuracy: 0.3831 - val_loss: 1.3383 - val_accuracy: 0.3868

Epoch 00073: val_loss did not improve from 1.33633
Epoch 74/10000
12/12 - 0s - loss: 1.3272 - accuracy: 0.3927 - val_loss: 1.3372 - val_accuracy: 0.3915

Epoch 00074: val_loss did not improve from 1.33633
Epoch 75/10000
12/12 - 0s - loss: 1.3304 - accuracy: 0.3929 - val_loss: 1.3451 - val_accuracy: 0.4059

Epoch 00075: val_loss did not improve from 1.33633
Epoch 76/10000
12/12 - 0s - loss: 1.3303 - accuracy: 0.4013 - val_loss: 1.3402 - val_accuracy: 0.3876

Epoch 00076: val_loss did not improve from 1.33633
Epoch 77/10000
12/12 - 0s - loss: 1.3288 - accuracy: 0.3884 - val_loss: 1.3376 - val_accuracy: 0.3939

Epoch 00077: val_loss did not improve from 1.33633
Epoch 78/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3944 - val_loss: 1.3376 - val_accuracy: 0.3979

Epoch 00078: val_loss did not improve from 1.33633
Epoch 79/10000
12/12 - 0s - loss: 1.3281 - accuracy: 0.3961 - val_loss: 1.3358 - val_accuracy: 0.4075

Epoch 00079: val_loss improved from 1.33633 to 1.33576, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 80/10000
12/12 - 0s - loss: 1.3275 - accuracy: 0.3883 - val_loss: 1.3395 - val_accuracy: 0.3876

Epoch 00080: val_loss did not improve from 1.33576
Epoch 81/10000
12/12 - 0s - loss: 1.3290 - accuracy: 0.3883 - val_loss: 1.3409 - val_accuracy: 0.3963

Epoch 00081: val_loss did not improve from 1.33576
Epoch 82/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3956 - val_loss: 1.3372 - val_accuracy: 0.3915

Epoch 00082: val_loss did not improve from 1.33576
Epoch 83/10000
12/12 - 0s - loss: 1.3285 - accuracy: 0.3939 - val_loss: 1.3386 - val_accuracy: 0.4035

Epoch 00083: val_loss did not improve from 1.33576
Epoch 84/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3975 - val_loss: 1.3377 - val_accuracy: 0.3923

Epoch 00084: val_loss did not improve from 1.33576
Epoch 85/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3958 - val_loss: 1.3362 - val_accuracy: 0.3915

Epoch 00085: val_loss did not improve from 1.33576
Epoch 86/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3968 - val_loss: 1.3380 - val_accuracy: 0.4107

Epoch 00086: val_loss did not improve from 1.33576
Epoch 87/10000
12/12 - 0s - loss: 1.3282 - accuracy: 0.3985 - val_loss: 1.3365 - val_accuracy: 0.3971

Epoch 00087: val_loss did not improve from 1.33576
Epoch 88/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3977 - val_loss: 1.3363 - val_accuracy: 0.3931

Epoch 00088: val_loss did not improve from 1.33576
Epoch 89/10000
12/12 - 0s - loss: 1.3261 - accuracy: 0.3914 - val_loss: 1.3378 - val_accuracy: 0.3979

Epoch 00089: val_loss did not improve from 1.33576
Epoch 90/10000
12/12 - 0s - loss: 1.3297 - accuracy: 0.4004 - val_loss: 1.3453 - val_accuracy: 0.4019

Epoch 00090: val_loss did not improve from 1.33576
Epoch 91/10000
12/12 - 0s - loss: 1.3313 - accuracy: 0.3921 - val_loss: 1.3365 - val_accuracy: 0.3939

Epoch 00091: val_loss did not improve from 1.33576
Epoch 92/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3924 - val_loss: 1.3360 - val_accuracy: 0.3860

Epoch 00092: val_loss did not improve from 1.33576
Epoch 93/10000
12/12 - 0s - loss: 1.3262 - accuracy: 0.3982 - val_loss: 1.3354 - val_accuracy: 0.4027

Epoch 00093: val_loss improved from 1.33576 to 1.33541, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 94/10000
12/12 - 0s - loss: 1.3264 - accuracy: 0.3956 - val_loss: 1.3366 - val_accuracy: 0.3796

Epoch 00094: val_loss did not improve from 1.33541
Epoch 95/10000
12/12 - 0s - loss: 1.3265 - accuracy: 0.3984 - val_loss: 1.3364 - val_accuracy: 0.4075

Epoch 00095: val_loss did not improve from 1.33541
Epoch 96/10000
12/12 - 0s - loss: 1.3259 - accuracy: 0.3978 - val_loss: 1.3340 - val_accuracy: 0.3955

Epoch 00096: val_loss improved from 1.33541 to 1.33398, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 97/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3958 - val_loss: 1.3343 - val_accuracy: 0.3931

Epoch 00097: val_loss did not improve from 1.33398
Epoch 98/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3932 - val_loss: 1.3360 - val_accuracy: 0.3947

Epoch 00098: val_loss did not improve from 1.33398
Epoch 99/10000
12/12 - 0s - loss: 1.3254 - accuracy: 0.3964 - val_loss: 1.3354 - val_accuracy: 0.3963

Epoch 00099: val_loss did not improve from 1.33398
Epoch 100/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3969 - val_loss: 1.3357 - val_accuracy: 0.3995

Epoch 00100: val_loss did not improve from 1.33398
Epoch 101/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3957 - val_loss: 1.3342 - val_accuracy: 0.4059

Epoch 00101: val_loss did not improve from 1.33398
Epoch 102/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3945 - val_loss: 1.3349 - val_accuracy: 0.4035

Epoch 00102: val_loss did not improve from 1.33398
Epoch 103/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.4003 - val_loss: 1.3351 - val_accuracy: 0.3971

Epoch 00103: val_loss did not improve from 1.33398
Epoch 104/10000
12/12 - 0s - loss: 1.3268 - accuracy: 0.3965 - val_loss: 1.3336 - val_accuracy: 0.3987

Epoch 00104: val_loss improved from 1.33398 to 1.33363, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 105/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3996 - val_loss: 1.3383 - val_accuracy: 0.4035

Epoch 00105: val_loss did not improve from 1.33363
Epoch 106/10000
12/12 - 0s - loss: 1.3257 - accuracy: 0.3947 - val_loss: 1.3370 - val_accuracy: 0.3860

Epoch 00106: val_loss did not improve from 1.33363
Epoch 107/10000
12/12 - 0s - loss: 1.3267 - accuracy: 0.3916 - val_loss: 1.3363 - val_accuracy: 0.3836

Epoch 00107: val_loss did not improve from 1.33363
Epoch 108/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3854 - val_loss: 1.3355 - val_accuracy: 0.3892

Epoch 00108: val_loss did not improve from 1.33363
Epoch 109/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3969 - val_loss: 1.3332 - val_accuracy: 0.3995

Epoch 00109: val_loss improved from 1.33363 to 1.33316, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 110/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3991 - val_loss: 1.3390 - val_accuracy: 0.4059

Epoch 00110: val_loss did not improve from 1.33316
Epoch 111/10000
12/12 - 0s - loss: 1.3279 - accuracy: 0.3978 - val_loss: 1.3333 - val_accuracy: 0.4011

Epoch 00111: val_loss did not improve from 1.33316
Epoch 112/10000
12/12 - 0s - loss: 1.3253 - accuracy: 0.3963 - val_loss: 1.3330 - val_accuracy: 0.4091

Epoch 00112: val_loss improved from 1.33316 to 1.33303, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 113/10000
12/12 - 0s - loss: 1.3248 - accuracy: 0.3983 - val_loss: 1.3333 - val_accuracy: 0.4019

Epoch 00113: val_loss did not improve from 1.33303
Epoch 114/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3982 - val_loss: 1.3331 - val_accuracy: 0.4107

Epoch 00114: val_loss did not improve from 1.33303
Epoch 115/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3957 - val_loss: 1.3338 - val_accuracy: 0.3947

Epoch 00115: val_loss did not improve from 1.33303
Epoch 116/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3953 - val_loss: 1.3341 - val_accuracy: 0.3987

Epoch 00116: val_loss did not improve from 1.33303
Epoch 117/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3945 - val_loss: 1.3338 - val_accuracy: 0.4027

Epoch 00117: val_loss did not improve from 1.33303
Epoch 118/10000
12/12 - 0s - loss: 1.3252 - accuracy: 0.3955 - val_loss: 1.3331 - val_accuracy: 0.3995

Epoch 00118: val_loss did not improve from 1.33303
Epoch 119/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3976 - val_loss: 1.3330 - val_accuracy: 0.4075

Epoch 00119: val_loss improved from 1.33303 to 1.33297, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 120/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3973 - val_loss: 1.3332 - val_accuracy: 0.3907

Epoch 00120: val_loss did not improve from 1.33297
Epoch 121/10000
12/12 - 0s - loss: 1.3239 - accuracy: 0.3988 - val_loss: 1.3326 - val_accuracy: 0.4011

Epoch 00121: val_loss improved from 1.33297 to 1.33256, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 122/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3960 - val_loss: 1.3342 - val_accuracy: 0.4035

Epoch 00122: val_loss did not improve from 1.33256
Epoch 123/10000
12/12 - 0s - loss: 1.3243 - accuracy: 0.3944 - val_loss: 1.3324 - val_accuracy: 0.3947

Epoch 00123: val_loss improved from 1.33256 to 1.33240, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 124/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3970 - val_loss: 1.3329 - val_accuracy: 0.3979

Epoch 00124: val_loss did not improve from 1.33240
Epoch 125/10000
12/12 - 0s - loss: 1.3237 - accuracy: 0.3907 - val_loss: 1.3332 - val_accuracy: 0.3923

Epoch 00125: val_loss did not improve from 1.33240
Epoch 126/10000
12/12 - 0s - loss: 1.3230 - accuracy: 0.3918 - val_loss: 1.3324 - val_accuracy: 0.3939

Epoch 00126: val_loss did not improve from 1.33240
Epoch 127/10000
12/12 - 0s - loss: 1.3233 - accuracy: 0.3944 - val_loss: 1.3323 - val_accuracy: 0.4051

Epoch 00127: val_loss improved from 1.33240 to 1.33232, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 128/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3990 - val_loss: 1.3320 - val_accuracy: 0.4075

Epoch 00128: val_loss improved from 1.33232 to 1.33197, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 129/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3966 - val_loss: 1.3317 - val_accuracy: 0.4019

Epoch 00129: val_loss improved from 1.33197 to 1.33168, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 130/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3963 - val_loss: 1.3317 - val_accuracy: 0.4035

Epoch 00130: val_loss improved from 1.33168 to 1.33166, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 131/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3908 - val_loss: 1.3383 - val_accuracy: 0.3955

Epoch 00131: val_loss did not improve from 1.33166
Epoch 132/10000
12/12 - 0s - loss: 1.3278 - accuracy: 0.3919 - val_loss: 1.3361 - val_accuracy: 0.3931

Epoch 00132: val_loss did not improve from 1.33166
Epoch 133/10000
12/12 - 0s - loss: 1.3258 - accuracy: 0.3967 - val_loss: 1.3337 - val_accuracy: 0.4091

Epoch 00133: val_loss did not improve from 1.33166
Epoch 134/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3915 - val_loss: 1.3316 - val_accuracy: 0.4027

Epoch 00134: val_loss improved from 1.33166 to 1.33161, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 135/10000
12/12 - 0s - loss: 1.3222 - accuracy: 0.3991 - val_loss: 1.3306 - val_accuracy: 0.3979

Epoch 00135: val_loss improved from 1.33161 to 1.33063, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 136/10000
12/12 - 0s - loss: 1.3228 - accuracy: 0.3945 - val_loss: 1.3316 - val_accuracy: 0.3971

Epoch 00136: val_loss did not improve from 1.33063
Epoch 137/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3899 - val_loss: 1.3365 - val_accuracy: 0.3931

Epoch 00137: val_loss did not improve from 1.33063
Epoch 138/10000
12/12 - 0s - loss: 1.3250 - accuracy: 0.3900 - val_loss: 1.3358 - val_accuracy: 0.4011

Epoch 00138: val_loss did not improve from 1.33063
Epoch 139/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3973 - val_loss: 1.3339 - val_accuracy: 0.4075

Epoch 00139: val_loss did not improve from 1.33063
Epoch 140/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3963 - val_loss: 1.3320 - val_accuracy: 0.4043

Epoch 00140: val_loss did not improve from 1.33063
Epoch 141/10000
12/12 - 0s - loss: 1.3260 - accuracy: 0.3953 - val_loss: 1.3372 - val_accuracy: 0.3947

Epoch 00141: val_loss did not improve from 1.33063
Epoch 142/10000
12/12 - 0s - loss: 1.3240 - accuracy: 0.3895 - val_loss: 1.3322 - val_accuracy: 0.4027

Epoch 00142: val_loss did not improve from 1.33063
Epoch 143/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3947 - val_loss: 1.3327 - val_accuracy: 0.4075

Epoch 00143: val_loss did not improve from 1.33063
Epoch 144/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3967 - val_loss: 1.3330 - val_accuracy: 0.4035

Epoch 00144: val_loss did not improve from 1.33063
Epoch 145/10000
12/12 - 0s - loss: 1.3227 - accuracy: 0.3947 - val_loss: 1.3317 - val_accuracy: 0.4059

Epoch 00145: val_loss did not improve from 1.33063
Epoch 146/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3958 - val_loss: 1.3335 - val_accuracy: 0.3979

Epoch 00146: val_loss did not improve from 1.33063
Epoch 147/10000
12/12 - 0s - loss: 1.3238 - accuracy: 0.3963 - val_loss: 1.3309 - val_accuracy: 0.3987

Epoch 00147: val_loss did not improve from 1.33063
Epoch 148/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3960 - val_loss: 1.3323 - val_accuracy: 0.4019

Epoch 00148: val_loss did not improve from 1.33063
Epoch 149/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3939 - val_loss: 1.3305 - val_accuracy: 0.4027

Epoch 00149: val_loss improved from 1.33063 to 1.33054, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 150/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3969 - val_loss: 1.3337 - val_accuracy: 0.3939

Epoch 00150: val_loss did not improve from 1.33054
Epoch 151/10000
12/12 - 0s - loss: 1.3244 - accuracy: 0.3947 - val_loss: 1.3346 - val_accuracy: 0.3947

Epoch 00151: val_loss did not improve from 1.33054
Epoch 152/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3947 - val_loss: 1.3306 - val_accuracy: 0.3979

Epoch 00152: val_loss did not improve from 1.33054
Epoch 153/10000
12/12 - 0s - loss: 1.3271 - accuracy: 0.3916 - val_loss: 1.3340 - val_accuracy: 0.3915

Epoch 00153: val_loss did not improve from 1.33054
Epoch 154/10000
12/12 - 0s - loss: 1.3217 - accuracy: 0.3952 - val_loss: 1.3298 - val_accuracy: 0.4011

Epoch 00154: val_loss improved from 1.33054 to 1.32978, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 155/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3927 - val_loss: 1.3319 - val_accuracy: 0.4011

Epoch 00155: val_loss did not improve from 1.32978
Epoch 156/10000
12/12 - 0s - loss: 1.3225 - accuracy: 0.3962 - val_loss: 1.3357 - val_accuracy: 0.3955

Epoch 00156: val_loss did not improve from 1.32978
Epoch 157/10000
12/12 - 0s - loss: 1.3251 - accuracy: 0.3885 - val_loss: 1.3349 - val_accuracy: 0.3915

Epoch 00157: val_loss did not improve from 1.32978
Epoch 158/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.3997 - val_loss: 1.3306 - val_accuracy: 0.3963

Epoch 00158: val_loss did not improve from 1.32978
Epoch 159/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3958 - val_loss: 1.3363 - val_accuracy: 0.3955

Epoch 00159: val_loss did not improve from 1.32978
Epoch 160/10000
12/12 - 0s - loss: 1.3256 - accuracy: 0.3958 - val_loss: 1.3384 - val_accuracy: 0.3939

Epoch 00160: val_loss did not improve from 1.32978
Epoch 161/10000
12/12 - 0s - loss: 1.3246 - accuracy: 0.3965 - val_loss: 1.3349 - val_accuracy: 0.4019

Epoch 00161: val_loss did not improve from 1.32978
Epoch 162/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3959 - val_loss: 1.3299 - val_accuracy: 0.4027

Epoch 00162: val_loss did not improve from 1.32978
Epoch 163/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3941 - val_loss: 1.3295 - val_accuracy: 0.4003

Epoch 00163: val_loss improved from 1.32978 to 1.32946, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 164/10000
12/12 - 0s - loss: 1.3214 - accuracy: 0.3982 - val_loss: 1.3298 - val_accuracy: 0.4027

Epoch 00164: val_loss did not improve from 1.32946
Epoch 165/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3970 - val_loss: 1.3315 - val_accuracy: 0.4091

Epoch 00165: val_loss did not improve from 1.32946
Epoch 166/10000
12/12 - 0s - loss: 1.3235 - accuracy: 0.3942 - val_loss: 1.3326 - val_accuracy: 0.3931

Epoch 00166: val_loss did not improve from 1.32946
Epoch 167/10000
12/12 - 0s - loss: 1.3263 - accuracy: 0.3948 - val_loss: 1.3372 - val_accuracy: 0.4019

Epoch 00167: val_loss did not improve from 1.32946
Epoch 168/10000
12/12 - 0s - loss: 1.3234 - accuracy: 0.3966 - val_loss: 1.3292 - val_accuracy: 0.4011

Epoch 00168: val_loss improved from 1.32946 to 1.32917, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 169/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3975 - val_loss: 1.3297 - val_accuracy: 0.4027

Epoch 00169: val_loss did not improve from 1.32917
Epoch 170/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3931 - val_loss: 1.3293 - val_accuracy: 0.4067

Epoch 00170: val_loss did not improve from 1.32917
Epoch 171/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3970 - val_loss: 1.3293 - val_accuracy: 0.4019

Epoch 00171: val_loss did not improve from 1.32917
Epoch 172/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3949 - val_loss: 1.3315 - val_accuracy: 0.3995

Epoch 00172: val_loss did not improve from 1.32917
Epoch 173/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3941 - val_loss: 1.3305 - val_accuracy: 0.3963

Epoch 00173: val_loss did not improve from 1.32917
Epoch 174/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.4007 - val_loss: 1.3310 - val_accuracy: 0.4003

Epoch 00174: val_loss did not improve from 1.32917
Epoch 175/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3931 - val_loss: 1.3307 - val_accuracy: 0.3955

Epoch 00175: val_loss did not improve from 1.32917
Epoch 176/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3968 - val_loss: 1.3306 - val_accuracy: 0.3907

Epoch 00176: val_loss did not improve from 1.32917
Epoch 177/10000
12/12 - 0s - loss: 1.3210 - accuracy: 0.3893 - val_loss: 1.3306 - val_accuracy: 0.3971

Epoch 00177: val_loss did not improve from 1.32917
Epoch 178/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3963 - val_loss: 1.3303 - val_accuracy: 0.3987

Epoch 00178: val_loss did not improve from 1.32917
Epoch 179/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3979 - val_loss: 1.3292 - val_accuracy: 0.3979

Epoch 00179: val_loss did not improve from 1.32917
Epoch 180/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3929 - val_loss: 1.3313 - val_accuracy: 0.3852

Epoch 00180: val_loss did not improve from 1.32917
Epoch 181/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3900 - val_loss: 1.3284 - val_accuracy: 0.4043

Epoch 00181: val_loss improved from 1.32917 to 1.32841, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 182/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3968 - val_loss: 1.3286 - val_accuracy: 0.4075

Epoch 00182: val_loss did not improve from 1.32841
Epoch 183/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3945 - val_loss: 1.3290 - val_accuracy: 0.3995

Epoch 00183: val_loss did not improve from 1.32841
Epoch 184/10000
12/12 - 0s - loss: 1.3218 - accuracy: 0.3931 - val_loss: 1.3290 - val_accuracy: 0.4043

Epoch 00184: val_loss did not improve from 1.32841
Epoch 185/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3947 - val_loss: 1.3293 - val_accuracy: 0.4003

Epoch 00185: val_loss did not improve from 1.32841
Epoch 186/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3942 - val_loss: 1.3284 - val_accuracy: 0.4003

Epoch 00186: val_loss did not improve from 1.32841
Epoch 187/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3949 - val_loss: 1.3286 - val_accuracy: 0.4019

Epoch 00187: val_loss did not improve from 1.32841
Epoch 188/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3958 - val_loss: 1.3292 - val_accuracy: 0.3955

Epoch 00188: val_loss did not improve from 1.32841
Epoch 189/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3976 - val_loss: 1.3293 - val_accuracy: 0.4075

Epoch 00189: val_loss did not improve from 1.32841
Epoch 190/10000
12/12 - 0s - loss: 1.3215 - accuracy: 0.3938 - val_loss: 1.3285 - val_accuracy: 0.4107

Epoch 00190: val_loss did not improve from 1.32841
Epoch 191/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3920 - val_loss: 1.3323 - val_accuracy: 0.3931

Epoch 00191: val_loss did not improve from 1.32841
Epoch 192/10000
12/12 - 0s - loss: 1.3232 - accuracy: 0.3960 - val_loss: 1.3342 - val_accuracy: 0.3931

Epoch 00192: val_loss did not improve from 1.32841
Epoch 193/10000
12/12 - 0s - loss: 1.3219 - accuracy: 0.3942 - val_loss: 1.3293 - val_accuracy: 0.3955

Epoch 00193: val_loss did not improve from 1.32841
Epoch 194/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.3939 - val_loss: 1.3296 - val_accuracy: 0.4011

Epoch 00194: val_loss did not improve from 1.32841
Epoch 195/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3950 - val_loss: 1.3306 - val_accuracy: 0.4083

Epoch 00195: val_loss did not improve from 1.32841
Epoch 196/10000
12/12 - 0s - loss: 1.3213 - accuracy: 0.3953 - val_loss: 1.3289 - val_accuracy: 0.4003

Epoch 00196: val_loss did not improve from 1.32841
Epoch 197/10000
12/12 - 0s - loss: 1.3201 - accuracy: 0.3921 - val_loss: 1.3287 - val_accuracy: 0.4011

Epoch 00197: val_loss did not improve from 1.32841
Epoch 198/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3947 - val_loss: 1.3285 - val_accuracy: 0.3939

Epoch 00198: val_loss did not improve from 1.32841
Epoch 199/10000
12/12 - 0s - loss: 1.3200 - accuracy: 0.3947 - val_loss: 1.3279 - val_accuracy: 0.3979

Epoch 00199: val_loss improved from 1.32841 to 1.32788, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 200/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3941 - val_loss: 1.3297 - val_accuracy: 0.3923

Epoch 00200: val_loss did not improve from 1.32788
Epoch 201/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3915 - val_loss: 1.3276 - val_accuracy: 0.3979

Epoch 00201: val_loss improved from 1.32788 to 1.32756, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 202/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3946 - val_loss: 1.3281 - val_accuracy: 0.4091

Epoch 00202: val_loss did not improve from 1.32756
Epoch 203/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3970 - val_loss: 1.3293 - val_accuracy: 0.4051

Epoch 00203: val_loss did not improve from 1.32756
Epoch 204/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3874 - val_loss: 1.3301 - val_accuracy: 0.3907

Epoch 00204: val_loss did not improve from 1.32756
Epoch 205/10000
12/12 - 0s - loss: 1.3199 - accuracy: 0.3925 - val_loss: 1.3283 - val_accuracy: 0.4067

Epoch 00205: val_loss did not improve from 1.32756
Epoch 206/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3940 - val_loss: 1.3287 - val_accuracy: 0.4067

Epoch 00206: val_loss did not improve from 1.32756
Epoch 207/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3916 - val_loss: 1.3291 - val_accuracy: 0.4051

Epoch 00207: val_loss did not improve from 1.32756
Epoch 208/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3962 - val_loss: 1.3291 - val_accuracy: 0.3931

Epoch 00208: val_loss did not improve from 1.32756
Epoch 209/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3947 - val_loss: 1.3289 - val_accuracy: 0.4019

Epoch 00209: val_loss did not improve from 1.32756
Epoch 210/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3892 - val_loss: 1.3293 - val_accuracy: 0.3947

Epoch 00210: val_loss did not improve from 1.32756
Epoch 211/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3948 - val_loss: 1.3277 - val_accuracy: 0.3987

Epoch 00211: val_loss did not improve from 1.32756
Epoch 212/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3965 - val_loss: 1.3272 - val_accuracy: 0.3971

Epoch 00212: val_loss improved from 1.32756 to 1.32724, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 213/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3956 - val_loss: 1.3272 - val_accuracy: 0.4027

Epoch 00213: val_loss improved from 1.32724 to 1.32718, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 214/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3921 - val_loss: 1.3301 - val_accuracy: 0.3987

Epoch 00214: val_loss did not improve from 1.32718
Epoch 215/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3951 - val_loss: 1.3278 - val_accuracy: 0.4059

Epoch 00215: val_loss did not improve from 1.32718
Epoch 216/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3937 - val_loss: 1.3271 - val_accuracy: 0.4003

Epoch 00216: val_loss improved from 1.32718 to 1.32713, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 217/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3957 - val_loss: 1.3269 - val_accuracy: 0.3987

Epoch 00217: val_loss improved from 1.32713 to 1.32690, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 218/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3899 - val_loss: 1.3284 - val_accuracy: 0.3947

Epoch 00218: val_loss did not improve from 1.32690
Epoch 219/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3929 - val_loss: 1.3281 - val_accuracy: 0.4027

Epoch 00219: val_loss did not improve from 1.32690
Epoch 220/10000
12/12 - 0s - loss: 1.3207 - accuracy: 0.3963 - val_loss: 1.3364 - val_accuracy: 0.3876

Epoch 00220: val_loss did not improve from 1.32690
Epoch 221/10000
12/12 - 0s - loss: 1.3266 - accuracy: 0.3892 - val_loss: 1.3277 - val_accuracy: 0.4019

Epoch 00221: val_loss did not improve from 1.32690
Epoch 222/10000
12/12 - 0s - loss: 1.3223 - accuracy: 0.4000 - val_loss: 1.3303 - val_accuracy: 0.3979

Epoch 00222: val_loss did not improve from 1.32690
Epoch 223/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3943 - val_loss: 1.3296 - val_accuracy: 0.3963

Epoch 00223: val_loss did not improve from 1.32690
Epoch 224/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3903 - val_loss: 1.3268 - val_accuracy: 0.4019

Epoch 00224: val_loss improved from 1.32690 to 1.32677, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 225/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3963 - val_loss: 1.3268 - val_accuracy: 0.3971

Epoch 00225: val_loss did not improve from 1.32677
Epoch 226/10000
12/12 - 0s - loss: 1.3197 - accuracy: 0.3954 - val_loss: 1.3272 - val_accuracy: 0.4083

Epoch 00226: val_loss did not improve from 1.32677
Epoch 227/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3903 - val_loss: 1.3288 - val_accuracy: 0.3892

Epoch 00227: val_loss did not improve from 1.32677
Epoch 228/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3926 - val_loss: 1.3267 - val_accuracy: 0.4051

Epoch 00228: val_loss improved from 1.32677 to 1.32674, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 229/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3950 - val_loss: 1.3265 - val_accuracy: 0.3963

Epoch 00229: val_loss improved from 1.32674 to 1.32647, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 230/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3940 - val_loss: 1.3289 - val_accuracy: 0.4035

Epoch 00230: val_loss did not improve from 1.32647
Epoch 231/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3930 - val_loss: 1.3290 - val_accuracy: 0.3971

Epoch 00231: val_loss did not improve from 1.32647
Epoch 232/10000
12/12 - 0s - loss: 1.3190 - accuracy: 0.3954 - val_loss: 1.3271 - val_accuracy: 0.4035

Epoch 00232: val_loss did not improve from 1.32647
Epoch 233/10000
12/12 - 0s - loss: 1.3191 - accuracy: 0.3954 - val_loss: 1.3284 - val_accuracy: 0.4067

Epoch 00233: val_loss did not improve from 1.32647
Epoch 234/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3916 - val_loss: 1.3273 - val_accuracy: 0.4075

Epoch 00234: val_loss did not improve from 1.32647
Epoch 235/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3965 - val_loss: 1.3279 - val_accuracy: 0.3963

Epoch 00235: val_loss did not improve from 1.32647
Epoch 236/10000
12/12 - 0s - loss: 1.3194 - accuracy: 0.3964 - val_loss: 1.3285 - val_accuracy: 0.3979

Epoch 00236: val_loss did not improve from 1.32647
Epoch 237/10000
12/12 - 0s - loss: 1.3209 - accuracy: 0.3936 - val_loss: 1.3281 - val_accuracy: 0.3971

Epoch 00237: val_loss did not improve from 1.32647
Epoch 238/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3905 - val_loss: 1.3262 - val_accuracy: 0.4067

Epoch 00238: val_loss improved from 1.32647 to 1.32620, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 239/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3941 - val_loss: 1.3260 - val_accuracy: 0.4051

Epoch 00239: val_loss improved from 1.32620 to 1.32595, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 240/10000
12/12 - 0s - loss: 1.3183 - accuracy: 0.3889 - val_loss: 1.3274 - val_accuracy: 0.3955

Epoch 00240: val_loss did not improve from 1.32595
Epoch 241/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3970 - val_loss: 1.3283 - val_accuracy: 0.3931

Epoch 00241: val_loss did not improve from 1.32595
Epoch 242/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3983 - val_loss: 1.3323 - val_accuracy: 0.3987

Epoch 00242: val_loss did not improve from 1.32595
Epoch 243/10000
12/12 - 0s - loss: 1.3229 - accuracy: 0.3875 - val_loss: 1.3323 - val_accuracy: 0.3907

Epoch 00243: val_loss did not improve from 1.32595
Epoch 244/10000
12/12 - 0s - loss: 1.3198 - accuracy: 0.3891 - val_loss: 1.3300 - val_accuracy: 0.3963

Epoch 00244: val_loss did not improve from 1.32595
Epoch 245/10000
12/12 - 0s - loss: 1.3196 - accuracy: 0.3946 - val_loss: 1.3264 - val_accuracy: 0.3963

Epoch 00245: val_loss did not improve from 1.32595
Epoch 246/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3908 - val_loss: 1.3269 - val_accuracy: 0.4011

Epoch 00246: val_loss did not improve from 1.32595
Epoch 247/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3956 - val_loss: 1.3281 - val_accuracy: 0.3995

Epoch 00247: val_loss did not improve from 1.32595
Epoch 248/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3874 - val_loss: 1.3271 - val_accuracy: 0.3947

Epoch 00248: val_loss did not improve from 1.32595
Epoch 249/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3953 - val_loss: 1.3253 - val_accuracy: 0.4035

Epoch 00249: val_loss improved from 1.32595 to 1.32531, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 250/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3931 - val_loss: 1.3270 - val_accuracy: 0.3963

Epoch 00250: val_loss did not improve from 1.32531
Epoch 251/10000
12/12 - 0s - loss: 1.3187 - accuracy: 0.3956 - val_loss: 1.3263 - val_accuracy: 0.4035

Epoch 00251: val_loss did not improve from 1.32531
Epoch 252/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3970 - val_loss: 1.3256 - val_accuracy: 0.4011

Epoch 00252: val_loss did not improve from 1.32531
Epoch 253/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3963 - val_loss: 1.3277 - val_accuracy: 0.4011

Epoch 00253: val_loss did not improve from 1.32531
Epoch 254/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3926 - val_loss: 1.3264 - val_accuracy: 0.4011

Epoch 00254: val_loss did not improve from 1.32531
Epoch 255/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3980 - val_loss: 1.3258 - val_accuracy: 0.4035

Epoch 00255: val_loss did not improve from 1.32531
Epoch 256/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3915 - val_loss: 1.3268 - val_accuracy: 0.3955

Epoch 00256: val_loss did not improve from 1.32531
Epoch 257/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3942 - val_loss: 1.3276 - val_accuracy: 0.4011

Epoch 00257: val_loss did not improve from 1.32531
Epoch 258/10000
12/12 - 0s - loss: 1.3216 - accuracy: 0.3891 - val_loss: 1.3326 - val_accuracy: 0.3915

Epoch 00258: val_loss did not improve from 1.32531
Epoch 259/10000
12/12 - 0s - loss: 1.3203 - accuracy: 0.3872 - val_loss: 1.3268 - val_accuracy: 0.3995

Epoch 00259: val_loss did not improve from 1.32531
Epoch 260/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3944 - val_loss: 1.3264 - val_accuracy: 0.4027

Epoch 00260: val_loss did not improve from 1.32531
Epoch 261/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3936 - val_loss: 1.3297 - val_accuracy: 0.4003

Epoch 00261: val_loss did not improve from 1.32531
Epoch 262/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3956 - val_loss: 1.3259 - val_accuracy: 0.4091

Epoch 00262: val_loss did not improve from 1.32531
Epoch 263/10000
12/12 - 0s - loss: 1.3188 - accuracy: 0.3941 - val_loss: 1.3259 - val_accuracy: 0.4067

Epoch 00263: val_loss did not improve from 1.32531
Epoch 264/10000
12/12 - 0s - loss: 1.3205 - accuracy: 0.3945 - val_loss: 1.3276 - val_accuracy: 0.4019

Epoch 00264: val_loss did not improve from 1.32531
Epoch 265/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3921 - val_loss: 1.3268 - val_accuracy: 0.3995

Epoch 00265: val_loss did not improve from 1.32531
Epoch 266/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3968 - val_loss: 1.3241 - val_accuracy: 0.4075

Epoch 00266: val_loss improved from 1.32531 to 1.32406, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 267/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3954 - val_loss: 1.3241 - val_accuracy: 0.4027

Epoch 00267: val_loss improved from 1.32406 to 1.32405, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 268/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3962 - val_loss: 1.3241 - val_accuracy: 0.4035

Epoch 00268: val_loss did not improve from 1.32405
Epoch 269/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3934 - val_loss: 1.3243 - val_accuracy: 0.4067

Epoch 00269: val_loss did not improve from 1.32405
Epoch 270/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3947 - val_loss: 1.3246 - val_accuracy: 0.3971

Epoch 00270: val_loss did not improve from 1.32405
Epoch 271/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3954 - val_loss: 1.3256 - val_accuracy: 0.4011

Epoch 00271: val_loss did not improve from 1.32405
Epoch 272/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3926 - val_loss: 1.3243 - val_accuracy: 0.4091

Epoch 00272: val_loss did not improve from 1.32405
Epoch 273/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3947 - val_loss: 1.3240 - val_accuracy: 0.4059

Epoch 00273: val_loss improved from 1.32405 to 1.32403, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 274/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3949 - val_loss: 1.3246 - val_accuracy: 0.3979

Epoch 00274: val_loss did not improve from 1.32403
Epoch 275/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3922 - val_loss: 1.3246 - val_accuracy: 0.4003

Epoch 00275: val_loss did not improve from 1.32403
Epoch 276/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3958 - val_loss: 1.3257 - val_accuracy: 0.4043

Epoch 00276: val_loss did not improve from 1.32403
Epoch 277/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3929 - val_loss: 1.3260 - val_accuracy: 0.3995

Epoch 00277: val_loss did not improve from 1.32403
Epoch 278/10000
12/12 - 0s - loss: 1.3195 - accuracy: 0.3979 - val_loss: 1.3289 - val_accuracy: 0.3987

Epoch 00278: val_loss did not improve from 1.32403
Epoch 279/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3963 - val_loss: 1.3257 - val_accuracy: 0.3987

Epoch 00279: val_loss did not improve from 1.32403
Epoch 280/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3976 - val_loss: 1.3237 - val_accuracy: 0.4067

Epoch 00280: val_loss improved from 1.32403 to 1.32367, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 281/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3957 - val_loss: 1.3239 - val_accuracy: 0.4091

Epoch 00281: val_loss did not improve from 1.32367
Epoch 282/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3947 - val_loss: 1.3243 - val_accuracy: 0.4067

Epoch 00282: val_loss did not improve from 1.32367
Epoch 283/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3908 - val_loss: 1.3245 - val_accuracy: 0.4051

Epoch 00283: val_loss did not improve from 1.32367
Epoch 284/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3978 - val_loss: 1.3239 - val_accuracy: 0.4011

Epoch 00284: val_loss did not improve from 1.32367
Epoch 285/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3979 - val_loss: 1.3244 - val_accuracy: 0.4019

Epoch 00285: val_loss did not improve from 1.32367
Epoch 286/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3949 - val_loss: 1.3252 - val_accuracy: 0.4131

Epoch 00286: val_loss did not improve from 1.32367
Epoch 287/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3942 - val_loss: 1.3239 - val_accuracy: 0.4051

Epoch 00287: val_loss did not improve from 1.32367
Epoch 288/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3938 - val_loss: 1.3244 - val_accuracy: 0.4043

Epoch 00288: val_loss did not improve from 1.32367
Epoch 289/10000
12/12 - 0s - loss: 1.3192 - accuracy: 0.3944 - val_loss: 1.3269 - val_accuracy: 0.4115

Epoch 00289: val_loss did not improve from 1.32367
Epoch 290/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3967 - val_loss: 1.3233 - val_accuracy: 0.4091

Epoch 00290: val_loss improved from 1.32367 to 1.32332, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 291/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3885 - val_loss: 1.3274 - val_accuracy: 0.3923

Epoch 00291: val_loss did not improve from 1.32332
Epoch 292/10000
12/12 - 0s - loss: 1.3245 - accuracy: 0.3984 - val_loss: 1.3405 - val_accuracy: 0.3844

Epoch 00292: val_loss did not improve from 1.32332
Epoch 293/10000
12/12 - 0s - loss: 1.3255 - accuracy: 0.3956 - val_loss: 1.3314 - val_accuracy: 0.3971

Epoch 00293: val_loss did not improve from 1.32332
Epoch 294/10000
12/12 - 0s - loss: 1.3193 - accuracy: 0.3925 - val_loss: 1.3243 - val_accuracy: 0.4059

Epoch 00294: val_loss did not improve from 1.32332
Epoch 295/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3943 - val_loss: 1.3243 - val_accuracy: 0.4035

Epoch 00295: val_loss did not improve from 1.32332
Epoch 296/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3929 - val_loss: 1.3307 - val_accuracy: 0.3971

Epoch 00296: val_loss did not improve from 1.32332
Epoch 297/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3966 - val_loss: 1.3353 - val_accuracy: 0.3884

Epoch 00297: val_loss did not improve from 1.32332
Epoch 298/10000
12/12 - 0s - loss: 1.3241 - accuracy: 0.3936 - val_loss: 1.3244 - val_accuracy: 0.3971

Epoch 00298: val_loss did not improve from 1.32332
Epoch 299/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3893 - val_loss: 1.3244 - val_accuracy: 0.4043

Epoch 00299: val_loss did not improve from 1.32332
Epoch 300/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3910 - val_loss: 1.3250 - val_accuracy: 0.3995

Epoch 00300: val_loss did not improve from 1.32332
Epoch 301/10000
12/12 - 0s - loss: 1.3186 - accuracy: 0.3950 - val_loss: 1.3244 - val_accuracy: 0.4059

Epoch 00301: val_loss did not improve from 1.32332
Epoch 302/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3954 - val_loss: 1.3242 - val_accuracy: 0.4051

Epoch 00302: val_loss did not improve from 1.32332
Epoch 303/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3920 - val_loss: 1.3267 - val_accuracy: 0.4051

Epoch 00303: val_loss did not improve from 1.32332
Epoch 304/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3883 - val_loss: 1.3237 - val_accuracy: 0.4083

Epoch 00304: val_loss did not improve from 1.32332
Epoch 305/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3908 - val_loss: 1.3230 - val_accuracy: 0.4051

Epoch 00305: val_loss improved from 1.32332 to 1.32305, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 306/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3939 - val_loss: 1.3249 - val_accuracy: 0.4115

Epoch 00306: val_loss did not improve from 1.32305
Epoch 307/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3936 - val_loss: 1.3245 - val_accuracy: 0.4035

Epoch 00307: val_loss did not improve from 1.32305
Epoch 308/10000
12/12 - 0s - loss: 1.3175 - accuracy: 0.3922 - val_loss: 1.3274 - val_accuracy: 0.4051

Epoch 00308: val_loss did not improve from 1.32305
Epoch 309/10000
12/12 - 0s - loss: 1.3226 - accuracy: 0.3925 - val_loss: 1.3285 - val_accuracy: 0.4003

Epoch 00309: val_loss did not improve from 1.32305
Epoch 310/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3943 - val_loss: 1.3247 - val_accuracy: 0.4027

Epoch 00310: val_loss did not improve from 1.32305
Epoch 311/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3841 - val_loss: 1.3250 - val_accuracy: 0.3963

Epoch 00311: val_loss did not improve from 1.32305
Epoch 312/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3920 - val_loss: 1.3234 - val_accuracy: 0.4091

Epoch 00312: val_loss did not improve from 1.32305
Epoch 313/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3926 - val_loss: 1.3243 - val_accuracy: 0.4019

Epoch 00313: val_loss did not improve from 1.32305
Epoch 314/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3970 - val_loss: 1.3240 - val_accuracy: 0.4019

Epoch 00314: val_loss did not improve from 1.32305
Epoch 315/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3952 - val_loss: 1.3228 - val_accuracy: 0.4067

Epoch 00315: val_loss improved from 1.32305 to 1.32282, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 316/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3901 - val_loss: 1.3227 - val_accuracy: 0.4067

Epoch 00316: val_loss improved from 1.32282 to 1.32275, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 317/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3916 - val_loss: 1.3225 - val_accuracy: 0.4067

Epoch 00317: val_loss improved from 1.32275 to 1.32253, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 318/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3952 - val_loss: 1.3234 - val_accuracy: 0.4075

Epoch 00318: val_loss did not improve from 1.32253
Epoch 319/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3928 - val_loss: 1.3246 - val_accuracy: 0.3979

Epoch 00319: val_loss did not improve from 1.32253
Epoch 320/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3892 - val_loss: 1.3251 - val_accuracy: 0.3987

Epoch 00320: val_loss did not improve from 1.32253
Epoch 321/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3982 - val_loss: 1.3230 - val_accuracy: 0.4051

Epoch 00321: val_loss did not improve from 1.32253
Epoch 322/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3931 - val_loss: 1.3243 - val_accuracy: 0.4027

Epoch 00322: val_loss did not improve from 1.32253
Epoch 323/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3942 - val_loss: 1.3232 - val_accuracy: 0.3979

Epoch 00323: val_loss did not improve from 1.32253
Epoch 324/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3975 - val_loss: 1.3231 - val_accuracy: 0.4067

Epoch 00324: val_loss did not improve from 1.32253
Epoch 325/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3947 - val_loss: 1.3243 - val_accuracy: 0.4115

Epoch 00325: val_loss did not improve from 1.32253
Epoch 326/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3923 - val_loss: 1.3235 - val_accuracy: 0.4027

Epoch 00326: val_loss did not improve from 1.32253
Epoch 327/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3967 - val_loss: 1.3254 - val_accuracy: 0.4123

Epoch 00327: val_loss did not improve from 1.32253
Epoch 328/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3924 - val_loss: 1.3244 - val_accuracy: 0.4051

Epoch 00328: val_loss did not improve from 1.32253
Epoch 329/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3947 - val_loss: 1.3235 - val_accuracy: 0.4067

Epoch 00329: val_loss did not improve from 1.32253
Epoch 330/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3953 - val_loss: 1.3233 - val_accuracy: 0.4131

Epoch 00330: val_loss did not improve from 1.32253
Epoch 331/10000
12/12 - 0s - loss: 1.3180 - accuracy: 0.3958 - val_loss: 1.3236 - val_accuracy: 0.4067

Epoch 00331: val_loss did not improve from 1.32253
Epoch 332/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3984 - val_loss: 1.3232 - val_accuracy: 0.4035

Epoch 00332: val_loss did not improve from 1.32253
Epoch 333/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3945 - val_loss: 1.3292 - val_accuracy: 0.3900

Epoch 00333: val_loss did not improve from 1.32253
Epoch 334/10000
12/12 - 0s - loss: 1.3221 - accuracy: 0.3848 - val_loss: 1.3319 - val_accuracy: 0.3971

Epoch 00334: val_loss did not improve from 1.32253
Epoch 335/10000
12/12 - 0s - loss: 1.3211 - accuracy: 0.4001 - val_loss: 1.3259 - val_accuracy: 0.3971

Epoch 00335: val_loss did not improve from 1.32253
Epoch 336/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3967 - val_loss: 1.3247 - val_accuracy: 0.3907

Epoch 00336: val_loss did not improve from 1.32253
Epoch 337/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3909 - val_loss: 1.3228 - val_accuracy: 0.4035

Epoch 00337: val_loss did not improve from 1.32253
Epoch 338/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3997 - val_loss: 1.3245 - val_accuracy: 0.3987

Epoch 00338: val_loss did not improve from 1.32253
Epoch 339/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3979 - val_loss: 1.3231 - val_accuracy: 0.4051

Epoch 00339: val_loss did not improve from 1.32253
Epoch 340/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.3889 - val_loss: 1.3249 - val_accuracy: 0.3995

Epoch 00340: val_loss did not improve from 1.32253
Epoch 341/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3986 - val_loss: 1.3234 - val_accuracy: 0.4067

Epoch 00341: val_loss did not improve from 1.32253
Epoch 342/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3965 - val_loss: 1.3260 - val_accuracy: 0.4043

Epoch 00342: val_loss did not improve from 1.32253
Epoch 343/10000
12/12 - 0s - loss: 1.3179 - accuracy: 0.3958 - val_loss: 1.3231 - val_accuracy: 0.4043

Epoch 00343: val_loss did not improve from 1.32253
Epoch 344/10000
12/12 - 0s - loss: 1.3165 - accuracy: 0.3968 - val_loss: 1.3226 - val_accuracy: 0.4075

Epoch 00344: val_loss did not improve from 1.32253
Epoch 345/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3924 - val_loss: 1.3245 - val_accuracy: 0.4091

Epoch 00345: val_loss did not improve from 1.32253
Epoch 346/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3943 - val_loss: 1.3244 - val_accuracy: 0.3979

Epoch 00346: val_loss did not improve from 1.32253
Epoch 347/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3977 - val_loss: 1.3245 - val_accuracy: 0.4019

Epoch 00347: val_loss did not improve from 1.32253
Epoch 348/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3988 - val_loss: 1.3227 - val_accuracy: 0.4043

Epoch 00348: val_loss did not improve from 1.32253
Epoch 349/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3912 - val_loss: 1.3232 - val_accuracy: 0.4027

Epoch 00349: val_loss did not improve from 1.32253
Epoch 350/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3931 - val_loss: 1.3231 - val_accuracy: 0.4035

Epoch 00350: val_loss did not improve from 1.32253
Epoch 351/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3934 - val_loss: 1.3226 - val_accuracy: 0.3971

Epoch 00351: val_loss did not improve from 1.32253
Epoch 352/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3961 - val_loss: 1.3223 - val_accuracy: 0.4067

Epoch 00352: val_loss improved from 1.32253 to 1.32233, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 353/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3951 - val_loss: 1.3225 - val_accuracy: 0.4083

Epoch 00353: val_loss did not improve from 1.32233
Epoch 354/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3933 - val_loss: 1.3231 - val_accuracy: 0.4091

Epoch 00354: val_loss did not improve from 1.32233
Epoch 355/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3972 - val_loss: 1.3230 - val_accuracy: 0.4019

Epoch 00355: val_loss did not improve from 1.32233
Epoch 356/10000
12/12 - 0s - loss: 1.3166 - accuracy: 0.3918 - val_loss: 1.3281 - val_accuracy: 0.3900

Epoch 00356: val_loss did not improve from 1.32233
Epoch 357/10000
12/12 - 0s - loss: 1.3220 - accuracy: 0.3839 - val_loss: 1.3337 - val_accuracy: 0.3939

Epoch 00357: val_loss did not improve from 1.32233
Epoch 358/10000
12/12 - 0s - loss: 1.3231 - accuracy: 0.3973 - val_loss: 1.3237 - val_accuracy: 0.4035

Epoch 00358: val_loss did not improve from 1.32233
Epoch 359/10000
12/12 - 0s - loss: 1.3171 - accuracy: 0.3941 - val_loss: 1.3228 - val_accuracy: 0.4083

Epoch 00359: val_loss did not improve from 1.32233
Epoch 360/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3970 - val_loss: 1.3230 - val_accuracy: 0.4123

Epoch 00360: val_loss did not improve from 1.32233
Epoch 361/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3945 - val_loss: 1.3225 - val_accuracy: 0.4059

Epoch 00361: val_loss did not improve from 1.32233
Epoch 362/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3969 - val_loss: 1.3227 - val_accuracy: 0.4115

Epoch 00362: val_loss did not improve from 1.32233
Epoch 363/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3893 - val_loss: 1.3250 - val_accuracy: 0.3955

Epoch 00363: val_loss did not improve from 1.32233
Epoch 364/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3917 - val_loss: 1.3219 - val_accuracy: 0.4115

Epoch 00364: val_loss improved from 1.32233 to 1.32190, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 365/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3909 - val_loss: 1.3238 - val_accuracy: 0.4067

Epoch 00365: val_loss did not improve from 1.32190
Epoch 366/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.4004 - val_loss: 1.3261 - val_accuracy: 0.4051

Epoch 00366: val_loss did not improve from 1.32190
Epoch 367/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3912 - val_loss: 1.3274 - val_accuracy: 0.4019

Epoch 00367: val_loss did not improve from 1.32190
Epoch 368/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3956 - val_loss: 1.3231 - val_accuracy: 0.4051

Epoch 00368: val_loss did not improve from 1.32190
Epoch 369/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3960 - val_loss: 1.3232 - val_accuracy: 0.4123

Epoch 00369: val_loss did not improve from 1.32190
Epoch 370/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3959 - val_loss: 1.3241 - val_accuracy: 0.3995

Epoch 00370: val_loss did not improve from 1.32190
Epoch 371/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3927 - val_loss: 1.3238 - val_accuracy: 0.4123

Epoch 00371: val_loss did not improve from 1.32190
Epoch 372/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3929 - val_loss: 1.3231 - val_accuracy: 0.4035

Epoch 00372: val_loss did not improve from 1.32190
Epoch 373/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3978 - val_loss: 1.3222 - val_accuracy: 0.4091

Epoch 00373: val_loss did not improve from 1.32190
Epoch 374/10000
12/12 - 0s - loss: 1.3162 - accuracy: 0.3962 - val_loss: 1.3234 - val_accuracy: 0.4043

Epoch 00374: val_loss did not improve from 1.32190
Epoch 375/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3928 - val_loss: 1.3225 - val_accuracy: 0.4083

Epoch 00375: val_loss did not improve from 1.32190
Epoch 376/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3950 - val_loss: 1.3237 - val_accuracy: 0.4043

Epoch 00376: val_loss did not improve from 1.32190
Epoch 377/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3960 - val_loss: 1.3224 - val_accuracy: 0.4051

Epoch 00377: val_loss did not improve from 1.32190
Epoch 378/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3983 - val_loss: 1.3246 - val_accuracy: 0.4107

Epoch 00378: val_loss did not improve from 1.32190
Epoch 379/10000
12/12 - 0s - loss: 1.3167 - accuracy: 0.3901 - val_loss: 1.3236 - val_accuracy: 0.4043

Epoch 00379: val_loss did not improve from 1.32190
Epoch 380/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.4001 - val_loss: 1.3247 - val_accuracy: 0.4067

Epoch 00380: val_loss did not improve from 1.32190
Epoch 381/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3940 - val_loss: 1.3229 - val_accuracy: 0.4027

Epoch 00381: val_loss did not improve from 1.32190
Epoch 382/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3931 - val_loss: 1.3223 - val_accuracy: 0.4027

Epoch 00382: val_loss did not improve from 1.32190
Epoch 383/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3941 - val_loss: 1.3232 - val_accuracy: 0.4043

Epoch 00383: val_loss did not improve from 1.32190
Epoch 384/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3969 - val_loss: 1.3225 - val_accuracy: 0.4059

Epoch 00384: val_loss did not improve from 1.32190
Epoch 385/10000
12/12 - 0s - loss: 1.3181 - accuracy: 0.3989 - val_loss: 1.3237 - val_accuracy: 0.4043

Epoch 00385: val_loss did not improve from 1.32190
Epoch 386/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3980 - val_loss: 1.3235 - val_accuracy: 0.3955

Epoch 00386: val_loss did not improve from 1.32190
Epoch 387/10000
12/12 - 0s - loss: 1.3178 - accuracy: 0.3879 - val_loss: 1.3224 - val_accuracy: 0.4115

Epoch 00387: val_loss did not improve from 1.32190
Epoch 388/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3988 - val_loss: 1.3219 - val_accuracy: 0.4035

Epoch 00388: val_loss improved from 1.32190 to 1.32186, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 389/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.4007 - val_loss: 1.3225 - val_accuracy: 0.4019

Epoch 00389: val_loss did not improve from 1.32186
Epoch 390/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3993 - val_loss: 1.3224 - val_accuracy: 0.4059

Epoch 00390: val_loss did not improve from 1.32186
Epoch 391/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3967 - val_loss: 1.3226 - val_accuracy: 0.4067

Epoch 00391: val_loss did not improve from 1.32186
Epoch 392/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3938 - val_loss: 1.3218 - val_accuracy: 0.4003

Epoch 00392: val_loss improved from 1.32186 to 1.32178, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 393/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3956 - val_loss: 1.3223 - val_accuracy: 0.4075

Epoch 00393: val_loss did not improve from 1.32178
Epoch 394/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3930 - val_loss: 1.3238 - val_accuracy: 0.4115

Epoch 00394: val_loss did not improve from 1.32178
Epoch 395/10000
12/12 - 0s - loss: 1.3152 - accuracy: 0.3934 - val_loss: 1.3221 - val_accuracy: 0.4075

Epoch 00395: val_loss did not improve from 1.32178
Epoch 396/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3951 - val_loss: 1.3222 - val_accuracy: 0.4035

Epoch 00396: val_loss did not improve from 1.32178
Epoch 397/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3946 - val_loss: 1.3222 - val_accuracy: 0.4059

Epoch 00397: val_loss did not improve from 1.32178
Epoch 398/10000
12/12 - 0s - loss: 1.3176 - accuracy: 0.3927 - val_loss: 1.3245 - val_accuracy: 0.3995

Epoch 00398: val_loss did not improve from 1.32178
Epoch 399/10000
12/12 - 0s - loss: 1.3184 - accuracy: 0.3974 - val_loss: 1.3230 - val_accuracy: 0.4123

Epoch 00399: val_loss did not improve from 1.32178
Epoch 400/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3889 - val_loss: 1.3231 - val_accuracy: 0.4011

Epoch 00400: val_loss did not improve from 1.32178
Epoch 401/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3933 - val_loss: 1.3217 - val_accuracy: 0.4107

Epoch 00401: val_loss improved from 1.32178 to 1.32173, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 402/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3962 - val_loss: 1.3237 - val_accuracy: 0.4051

Epoch 00402: val_loss did not improve from 1.32173
Epoch 403/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3910 - val_loss: 1.3227 - val_accuracy: 0.4123

Epoch 00403: val_loss did not improve from 1.32173
Epoch 404/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3990 - val_loss: 1.3241 - val_accuracy: 0.4043

Epoch 00404: val_loss did not improve from 1.32173
Epoch 405/10000
12/12 - 0s - loss: 1.3170 - accuracy: 0.3932 - val_loss: 1.3294 - val_accuracy: 0.4035

Epoch 00405: val_loss did not improve from 1.32173
Epoch 406/10000
12/12 - 0s - loss: 1.3212 - accuracy: 0.3969 - val_loss: 1.3251 - val_accuracy: 0.4035

Epoch 00406: val_loss did not improve from 1.32173
Epoch 407/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3947 - val_loss: 1.3222 - val_accuracy: 0.4051

Epoch 00407: val_loss did not improve from 1.32173
Epoch 408/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3943 - val_loss: 1.3216 - val_accuracy: 0.4123

Epoch 00408: val_loss improved from 1.32173 to 1.32160, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 409/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3949 - val_loss: 1.3221 - val_accuracy: 0.4155

Epoch 00409: val_loss did not improve from 1.32160
Epoch 410/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3954 - val_loss: 1.3213 - val_accuracy: 0.4099

Epoch 00410: val_loss improved from 1.32160 to 1.32129, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 411/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3899 - val_loss: 1.3222 - val_accuracy: 0.4043

Epoch 00411: val_loss did not improve from 1.32129
Epoch 412/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3965 - val_loss: 1.3222 - val_accuracy: 0.4059

Epoch 00412: val_loss did not improve from 1.32129
Epoch 413/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3970 - val_loss: 1.3219 - val_accuracy: 0.4107

Epoch 00413: val_loss did not improve from 1.32129
Epoch 414/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3976 - val_loss: 1.3217 - val_accuracy: 0.4115

Epoch 00414: val_loss did not improve from 1.32129
Epoch 415/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3947 - val_loss: 1.3224 - val_accuracy: 0.4091

Epoch 00415: val_loss did not improve from 1.32129
Epoch 416/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3954 - val_loss: 1.3210 - val_accuracy: 0.4115

Epoch 00416: val_loss improved from 1.32129 to 1.32099, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 417/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3970 - val_loss: 1.3207 - val_accuracy: 0.4051

Epoch 00417: val_loss improved from 1.32099 to 1.32067, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 418/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3897 - val_loss: 1.3222 - val_accuracy: 0.4051

Epoch 00418: val_loss did not improve from 1.32067
Epoch 419/10000
12/12 - 0s - loss: 1.3169 - accuracy: 0.3960 - val_loss: 1.3244 - val_accuracy: 0.3995

Epoch 00419: val_loss did not improve from 1.32067
Epoch 420/10000
12/12 - 0s - loss: 1.3173 - accuracy: 0.3913 - val_loss: 1.3227 - val_accuracy: 0.3955

Epoch 00420: val_loss did not improve from 1.32067
Epoch 421/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3954 - val_loss: 1.3219 - val_accuracy: 0.4099

Epoch 00421: val_loss did not improve from 1.32067
Epoch 422/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3948 - val_loss: 1.3210 - val_accuracy: 0.4099

Epoch 00422: val_loss did not improve from 1.32067
Epoch 423/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3947 - val_loss: 1.3238 - val_accuracy: 0.4011

Epoch 00423: val_loss did not improve from 1.32067
Epoch 424/10000
12/12 - 0s - loss: 1.3206 - accuracy: 0.3990 - val_loss: 1.3277 - val_accuracy: 0.3971

Epoch 00424: val_loss did not improve from 1.32067
Epoch 425/10000
12/12 - 0s - loss: 1.3185 - accuracy: 0.3938 - val_loss: 1.3220 - val_accuracy: 0.4043

Epoch 00425: val_loss did not improve from 1.32067
Epoch 426/10000
12/12 - 0s - loss: 1.3154 - accuracy: 0.3973 - val_loss: 1.3215 - val_accuracy: 0.4099

Epoch 00426: val_loss did not improve from 1.32067
Epoch 427/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3939 - val_loss: 1.3231 - val_accuracy: 0.4195

Epoch 00427: val_loss did not improve from 1.32067
Epoch 428/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3943 - val_loss: 1.3207 - val_accuracy: 0.4115

Epoch 00428: val_loss did not improve from 1.32067
Epoch 429/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3958 - val_loss: 1.3201 - val_accuracy: 0.4059

Epoch 00429: val_loss improved from 1.32067 to 1.32008, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 430/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3975 - val_loss: 1.3204 - val_accuracy: 0.4075

Epoch 00430: val_loss did not improve from 1.32008
Epoch 431/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3918 - val_loss: 1.3202 - val_accuracy: 0.4107

Epoch 00431: val_loss did not improve from 1.32008
Epoch 432/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3927 - val_loss: 1.3203 - val_accuracy: 0.4075

Epoch 00432: val_loss did not improve from 1.32008
Epoch 433/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3936 - val_loss: 1.3204 - val_accuracy: 0.4003

Epoch 00433: val_loss did not improve from 1.32008
Epoch 434/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3986 - val_loss: 1.3219 - val_accuracy: 0.3987

Epoch 00434: val_loss did not improve from 1.32008
Epoch 435/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3997 - val_loss: 1.3212 - val_accuracy: 0.4131

Epoch 00435: val_loss did not improve from 1.32008
Epoch 436/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3949 - val_loss: 1.3210 - val_accuracy: 0.4075

Epoch 00436: val_loss did not improve from 1.32008
Epoch 437/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3957 - val_loss: 1.3216 - val_accuracy: 0.4067

Epoch 00437: val_loss did not improve from 1.32008
Epoch 438/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3962 - val_loss: 1.3226 - val_accuracy: 0.4091

Epoch 00438: val_loss did not improve from 1.32008
Epoch 439/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3931 - val_loss: 1.3211 - val_accuracy: 0.4051

Epoch 00439: val_loss did not improve from 1.32008
Epoch 440/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3950 - val_loss: 1.3207 - val_accuracy: 0.4083

Epoch 00440: val_loss did not improve from 1.32008
Epoch 441/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3961 - val_loss: 1.3218 - val_accuracy: 0.4099

Epoch 00441: val_loss did not improve from 1.32008
Epoch 442/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3908 - val_loss: 1.3219 - val_accuracy: 0.4163

Epoch 00442: val_loss did not improve from 1.32008
Epoch 443/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3954 - val_loss: 1.3212 - val_accuracy: 0.4075

Epoch 00443: val_loss did not improve from 1.32008
Epoch 444/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3936 - val_loss: 1.3207 - val_accuracy: 0.4099

Epoch 00444: val_loss did not improve from 1.32008
Epoch 445/10000
12/12 - 0s - loss: 1.3158 - accuracy: 0.3970 - val_loss: 1.3248 - val_accuracy: 0.3971

Epoch 00445: val_loss did not improve from 1.32008
Epoch 446/10000
12/12 - 0s - loss: 1.3177 - accuracy: 0.3969 - val_loss: 1.3225 - val_accuracy: 0.4035

Epoch 00446: val_loss did not improve from 1.32008
Epoch 447/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3978 - val_loss: 1.3204 - val_accuracy: 0.4139

Epoch 00447: val_loss did not improve from 1.32008
Epoch 448/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3963 - val_loss: 1.3203 - val_accuracy: 0.4099

Epoch 00448: val_loss did not improve from 1.32008
Epoch 449/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3947 - val_loss: 1.3200 - val_accuracy: 0.4107

Epoch 00449: val_loss improved from 1.32008 to 1.32002, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 450/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3985 - val_loss: 1.3215 - val_accuracy: 0.4027

Epoch 00450: val_loss did not improve from 1.32002
Epoch 451/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3931 - val_loss: 1.3223 - val_accuracy: 0.4003

Epoch 00451: val_loss did not improve from 1.32002
Epoch 452/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3954 - val_loss: 1.3221 - val_accuracy: 0.4107

Epoch 00452: val_loss did not improve from 1.32002
Epoch 453/10000
12/12 - 0s - loss: 1.3157 - accuracy: 0.3920 - val_loss: 1.3217 - val_accuracy: 0.4067

Epoch 00453: val_loss did not improve from 1.32002
Epoch 454/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3964 - val_loss: 1.3204 - val_accuracy: 0.4083

Epoch 00454: val_loss did not improve from 1.32002
Epoch 455/10000
12/12 - 0s - loss: 1.3144 - accuracy: 0.3996 - val_loss: 1.3229 - val_accuracy: 0.3931

Epoch 00455: val_loss did not improve from 1.32002
Epoch 456/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3912 - val_loss: 1.3211 - val_accuracy: 0.4107

Epoch 00456: val_loss did not improve from 1.32002
Epoch 457/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3967 - val_loss: 1.3201 - val_accuracy: 0.4171

Epoch 00457: val_loss did not improve from 1.32002
Epoch 458/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3949 - val_loss: 1.3193 - val_accuracy: 0.4099

Epoch 00458: val_loss improved from 1.32002 to 1.31929, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 459/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3920 - val_loss: 1.3205 - val_accuracy: 0.4099

Epoch 00459: val_loss did not improve from 1.31929
Epoch 460/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3953 - val_loss: 1.3208 - val_accuracy: 0.4067

Epoch 00460: val_loss did not improve from 1.31929
Epoch 461/10000
12/12 - 0s - loss: 1.3149 - accuracy: 0.3954 - val_loss: 1.3193 - val_accuracy: 0.4091

Epoch 00461: val_loss did not improve from 1.31929
Epoch 462/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3946 - val_loss: 1.3213 - val_accuracy: 0.4155

Epoch 00462: val_loss did not improve from 1.31929
Epoch 463/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.3962 - val_loss: 1.3214 - val_accuracy: 0.3987

Epoch 00463: val_loss did not improve from 1.31929
Epoch 464/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3983 - val_loss: 1.3222 - val_accuracy: 0.4035

Epoch 00464: val_loss did not improve from 1.31929
Epoch 465/10000
12/12 - 0s - loss: 1.3174 - accuracy: 0.3970 - val_loss: 1.3251 - val_accuracy: 0.4051

Epoch 00465: val_loss did not improve from 1.31929
Epoch 466/10000
12/12 - 0s - loss: 1.3208 - accuracy: 0.3892 - val_loss: 1.3224 - val_accuracy: 0.4123

Epoch 00466: val_loss did not improve from 1.31929
Epoch 467/10000
12/12 - 0s - loss: 1.3161 - accuracy: 0.3970 - val_loss: 1.3207 - val_accuracy: 0.4075

Epoch 00467: val_loss did not improve from 1.31929
Epoch 468/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3978 - val_loss: 1.3205 - val_accuracy: 0.4179

Epoch 00468: val_loss did not improve from 1.31929
Epoch 469/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3953 - val_loss: 1.3199 - val_accuracy: 0.4123

Epoch 00469: val_loss did not improve from 1.31929
Epoch 470/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3983 - val_loss: 1.3225 - val_accuracy: 0.4083

Epoch 00470: val_loss did not improve from 1.31929
Epoch 471/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3940 - val_loss: 1.3210 - val_accuracy: 0.4019

Epoch 00471: val_loss did not improve from 1.31929
Epoch 472/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3934 - val_loss: 1.3207 - val_accuracy: 0.4091

Epoch 00472: val_loss did not improve from 1.31929
Epoch 473/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3998 - val_loss: 1.3197 - val_accuracy: 0.4035

Epoch 00473: val_loss did not improve from 1.31929
Epoch 474/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3951 - val_loss: 1.3203 - val_accuracy: 0.4075

Epoch 00474: val_loss did not improve from 1.31929
Epoch 475/10000
12/12 - 0s - loss: 1.3147 - accuracy: 0.3969 - val_loss: 1.3201 - val_accuracy: 0.4011

Epoch 00475: val_loss did not improve from 1.31929
Epoch 476/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3972 - val_loss: 1.3206 - val_accuracy: 0.4075

Epoch 00476: val_loss did not improve from 1.31929
Epoch 477/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.3997 - val_loss: 1.3208 - val_accuracy: 0.4035

Epoch 00477: val_loss did not improve from 1.31929
Epoch 478/10000
12/12 - 0s - loss: 1.3168 - accuracy: 0.3995 - val_loss: 1.3204 - val_accuracy: 0.4035

Epoch 00478: val_loss did not improve from 1.31929
Epoch 479/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3960 - val_loss: 1.3201 - val_accuracy: 0.4059

Epoch 00479: val_loss did not improve from 1.31929
Epoch 480/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3939 - val_loss: 1.3200 - val_accuracy: 0.4075

Epoch 00480: val_loss did not improve from 1.31929
Epoch 481/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3958 - val_loss: 1.3201 - val_accuracy: 0.4155

Epoch 00481: val_loss did not improve from 1.31929
Epoch 482/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3975 - val_loss: 1.3207 - val_accuracy: 0.4035

Epoch 00482: val_loss did not improve from 1.31929
Epoch 483/10000
12/12 - 0s - loss: 1.3164 - accuracy: 0.3989 - val_loss: 1.3212 - val_accuracy: 0.4107

Epoch 00483: val_loss did not improve from 1.31929
Epoch 484/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3901 - val_loss: 1.3196 - val_accuracy: 0.4035

Epoch 00484: val_loss did not improve from 1.31929
Epoch 485/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3950 - val_loss: 1.3192 - val_accuracy: 0.4131

Epoch 00485: val_loss improved from 1.31929 to 1.31918, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 486/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3974 - val_loss: 1.3213 - val_accuracy: 0.4131

Epoch 00486: val_loss did not improve from 1.31918
Epoch 487/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3926 - val_loss: 1.3209 - val_accuracy: 0.4075

Epoch 00487: val_loss did not improve from 1.31918
Epoch 488/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3982 - val_loss: 1.3211 - val_accuracy: 0.4067

Epoch 00488: val_loss did not improve from 1.31918
Epoch 489/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3987 - val_loss: 1.3201 - val_accuracy: 0.4059

Epoch 00489: val_loss did not improve from 1.31918
Epoch 490/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3931 - val_loss: 1.3200 - val_accuracy: 0.4107

Epoch 00490: val_loss did not improve from 1.31918
Epoch 491/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3970 - val_loss: 1.3188 - val_accuracy: 0.4083

Epoch 00491: val_loss improved from 1.31918 to 1.31884, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 492/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3953 - val_loss: 1.3192 - val_accuracy: 0.4067

Epoch 00492: val_loss did not improve from 1.31884
Epoch 493/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3973 - val_loss: 1.3205 - val_accuracy: 0.4147

Epoch 00493: val_loss did not improve from 1.31884
Epoch 494/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3922 - val_loss: 1.3206 - val_accuracy: 0.4027

Epoch 00494: val_loss did not improve from 1.31884
Epoch 495/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3966 - val_loss: 1.3210 - val_accuracy: 0.4115

Epoch 00495: val_loss did not improve from 1.31884
Epoch 496/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4001 - val_loss: 1.3213 - val_accuracy: 0.4067

Epoch 00496: val_loss did not improve from 1.31884
Epoch 497/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4031 - val_loss: 1.3200 - val_accuracy: 0.4067

Epoch 00497: val_loss did not improve from 1.31884
Epoch 498/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.4003 - val_loss: 1.3217 - val_accuracy: 0.3971

Epoch 00498: val_loss did not improve from 1.31884
Epoch 499/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3917 - val_loss: 1.3193 - val_accuracy: 0.4059

Epoch 00499: val_loss did not improve from 1.31884
Epoch 500/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.4014 - val_loss: 1.3205 - val_accuracy: 0.4083

Epoch 00500: val_loss did not improve from 1.31884
Epoch 501/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3944 - val_loss: 1.3212 - val_accuracy: 0.4139

Epoch 00501: val_loss did not improve from 1.31884
Epoch 502/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3917 - val_loss: 1.3211 - val_accuracy: 0.4043

Epoch 00502: val_loss did not improve from 1.31884
Epoch 503/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3965 - val_loss: 1.3201 - val_accuracy: 0.4075

Epoch 00503: val_loss did not improve from 1.31884
Epoch 504/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3944 - val_loss: 1.3211 - val_accuracy: 0.4027

Epoch 00504: val_loss did not improve from 1.31884
Epoch 505/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3962 - val_loss: 1.3226 - val_accuracy: 0.4123

Epoch 00505: val_loss did not improve from 1.31884
Epoch 506/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3971 - val_loss: 1.3207 - val_accuracy: 0.4067

Epoch 00506: val_loss did not improve from 1.31884
Epoch 507/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3977 - val_loss: 1.3205 - val_accuracy: 0.4123

Epoch 00507: val_loss did not improve from 1.31884
Epoch 508/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3950 - val_loss: 1.3197 - val_accuracy: 0.4051

Epoch 00508: val_loss did not improve from 1.31884
Epoch 509/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3956 - val_loss: 1.3212 - val_accuracy: 0.4067

Epoch 00509: val_loss did not improve from 1.31884
Epoch 510/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3963 - val_loss: 1.3197 - val_accuracy: 0.4099

Epoch 00510: val_loss did not improve from 1.31884
Epoch 511/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3940 - val_loss: 1.3199 - val_accuracy: 0.4019

Epoch 00511: val_loss did not improve from 1.31884
Epoch 512/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3989 - val_loss: 1.3186 - val_accuracy: 0.4099

Epoch 00512: val_loss improved from 1.31884 to 1.31861, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 513/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4009 - val_loss: 1.3195 - val_accuracy: 0.4107

Epoch 00513: val_loss did not improve from 1.31861
Epoch 514/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3968 - val_loss: 1.3208 - val_accuracy: 0.4075

Epoch 00514: val_loss did not improve from 1.31861
Epoch 515/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3959 - val_loss: 1.3189 - val_accuracy: 0.4139

Epoch 00515: val_loss did not improve from 1.31861
Epoch 516/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3967 - val_loss: 1.3187 - val_accuracy: 0.4075

Epoch 00516: val_loss did not improve from 1.31861
Epoch 517/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.4006 - val_loss: 1.3215 - val_accuracy: 0.4035

Epoch 00517: val_loss did not improve from 1.31861
Epoch 518/10000
12/12 - 0s - loss: 1.3182 - accuracy: 0.3970 - val_loss: 1.3205 - val_accuracy: 0.4083

Epoch 00518: val_loss did not improve from 1.31861
Epoch 519/10000
12/12 - 0s - loss: 1.3163 - accuracy: 0.3968 - val_loss: 1.3213 - val_accuracy: 0.4115

Epoch 00519: val_loss did not improve from 1.31861
Epoch 520/10000
12/12 - 0s - loss: 1.3151 - accuracy: 0.3919 - val_loss: 1.3258 - val_accuracy: 0.4035

Epoch 00520: val_loss did not improve from 1.31861
Epoch 521/10000
12/12 - 0s - loss: 1.3189 - accuracy: 0.4003 - val_loss: 1.3202 - val_accuracy: 0.4051

Epoch 00521: val_loss did not improve from 1.31861
Epoch 522/10000
12/12 - 0s - loss: 1.3140 - accuracy: 0.3983 - val_loss: 1.3190 - val_accuracy: 0.4147

Epoch 00522: val_loss did not improve from 1.31861
Epoch 523/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.4001 - val_loss: 1.3189 - val_accuracy: 0.4099

Epoch 00523: val_loss did not improve from 1.31861
Epoch 524/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3971 - val_loss: 1.3186 - val_accuracy: 0.4083

Epoch 00524: val_loss improved from 1.31861 to 1.31855, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 525/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3959 - val_loss: 1.3202 - val_accuracy: 0.4115

Epoch 00525: val_loss did not improve from 1.31855
Epoch 526/10000
12/12 - 0s - loss: 1.3159 - accuracy: 0.3964 - val_loss: 1.3208 - val_accuracy: 0.4099

Epoch 00526: val_loss did not improve from 1.31855
Epoch 527/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3942 - val_loss: 1.3199 - val_accuracy: 0.4099

Epoch 00527: val_loss did not improve from 1.31855
Epoch 528/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3931 - val_loss: 1.3202 - val_accuracy: 0.4091

Epoch 00528: val_loss did not improve from 1.31855
Epoch 529/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3978 - val_loss: 1.3188 - val_accuracy: 0.4123

Epoch 00529: val_loss did not improve from 1.31855
Epoch 530/10000
12/12 - 0s - loss: 1.3145 - accuracy: 0.4007 - val_loss: 1.3215 - val_accuracy: 0.3995

Epoch 00530: val_loss did not improve from 1.31855
Epoch 531/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3976 - val_loss: 1.3202 - val_accuracy: 0.4171

Epoch 00531: val_loss did not improve from 1.31855
Epoch 532/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3929 - val_loss: 1.3199 - val_accuracy: 0.4091

Epoch 00532: val_loss did not improve from 1.31855
Epoch 533/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.4016 - val_loss: 1.3190 - val_accuracy: 0.4099

Epoch 00533: val_loss did not improve from 1.31855
Epoch 534/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3940 - val_loss: 1.3203 - val_accuracy: 0.4139

Epoch 00534: val_loss did not improve from 1.31855
Epoch 535/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3960 - val_loss: 1.3191 - val_accuracy: 0.4163

Epoch 00535: val_loss did not improve from 1.31855
Epoch 536/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.4008 - val_loss: 1.3216 - val_accuracy: 0.4099

Epoch 00536: val_loss did not improve from 1.31855
Epoch 537/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3972 - val_loss: 1.3215 - val_accuracy: 0.4043

Epoch 00537: val_loss did not improve from 1.31855
Epoch 538/10000
12/12 - 0s - loss: 1.3148 - accuracy: 0.3983 - val_loss: 1.3192 - val_accuracy: 0.4107

Epoch 00538: val_loss did not improve from 1.31855
Epoch 539/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3991 - val_loss: 1.3183 - val_accuracy: 0.4035

Epoch 00539: val_loss improved from 1.31855 to 1.31826, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 540/10000
12/12 - 0s - loss: 1.3125 - accuracy: 0.3970 - val_loss: 1.3191 - val_accuracy: 0.4067

Epoch 00540: val_loss did not improve from 1.31826
Epoch 541/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3939 - val_loss: 1.3222 - val_accuracy: 0.4139

Epoch 00541: val_loss did not improve from 1.31826
Epoch 542/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3955 - val_loss: 1.3248 - val_accuracy: 0.4043

Epoch 00542: val_loss did not improve from 1.31826
Epoch 543/10000
12/12 - 0s - loss: 1.3160 - accuracy: 0.3979 - val_loss: 1.3196 - val_accuracy: 0.4099

Epoch 00543: val_loss did not improve from 1.31826
Epoch 544/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3998 - val_loss: 1.3195 - val_accuracy: 0.4115

Epoch 00544: val_loss did not improve from 1.31826
Epoch 545/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.3947 - val_loss: 1.3192 - val_accuracy: 0.4019

Epoch 00545: val_loss did not improve from 1.31826
Epoch 546/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3986 - val_loss: 1.3203 - val_accuracy: 0.4083

Epoch 00546: val_loss did not improve from 1.31826
Epoch 547/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3967 - val_loss: 1.3186 - val_accuracy: 0.4027

Epoch 00547: val_loss did not improve from 1.31826
Epoch 548/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3968 - val_loss: 1.3191 - val_accuracy: 0.4131

Epoch 00548: val_loss did not improve from 1.31826
Epoch 549/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.3985 - val_loss: 1.3195 - val_accuracy: 0.4059

Epoch 00549: val_loss did not improve from 1.31826
Epoch 550/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.3951 - val_loss: 1.3194 - val_accuracy: 0.4067

Epoch 00550: val_loss did not improve from 1.31826
Epoch 551/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3945 - val_loss: 1.3184 - val_accuracy: 0.4115

Epoch 00551: val_loss did not improve from 1.31826
Epoch 552/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3978 - val_loss: 1.3204 - val_accuracy: 0.4051

Epoch 00552: val_loss did not improve from 1.31826
Epoch 553/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3936 - val_loss: 1.3207 - val_accuracy: 0.4123

Epoch 00553: val_loss did not improve from 1.31826
Epoch 554/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3958 - val_loss: 1.3183 - val_accuracy: 0.4083

Epoch 00554: val_loss did not improve from 1.31826
Epoch 555/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3970 - val_loss: 1.3189 - val_accuracy: 0.4139

Epoch 00555: val_loss did not improve from 1.31826
Epoch 556/10000
12/12 - 0s - loss: 1.3139 - accuracy: 0.3975 - val_loss: 1.3219 - val_accuracy: 0.4019

Epoch 00556: val_loss did not improve from 1.31826
Epoch 557/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3981 - val_loss: 1.3180 - val_accuracy: 0.4123

Epoch 00557: val_loss improved from 1.31826 to 1.31801, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 558/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3980 - val_loss: 1.3198 - val_accuracy: 0.4115

Epoch 00558: val_loss did not improve from 1.31801
Epoch 559/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3972 - val_loss: 1.3185 - val_accuracy: 0.4115

Epoch 00559: val_loss did not improve from 1.31801
Epoch 560/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3996 - val_loss: 1.3200 - val_accuracy: 0.3995

Epoch 00560: val_loss did not improve from 1.31801
Epoch 561/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3928 - val_loss: 1.3184 - val_accuracy: 0.4059

Epoch 00561: val_loss did not improve from 1.31801
Epoch 562/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3999 - val_loss: 1.3201 - val_accuracy: 0.4099

Epoch 00562: val_loss did not improve from 1.31801
Epoch 563/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3954 - val_loss: 1.3198 - val_accuracy: 0.4043

Epoch 00563: val_loss did not improve from 1.31801
Epoch 564/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.3965 - val_loss: 1.3188 - val_accuracy: 0.4067

Epoch 00564: val_loss did not improve from 1.31801
Epoch 565/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3976 - val_loss: 1.3187 - val_accuracy: 0.4083

Epoch 00565: val_loss did not improve from 1.31801
Epoch 566/10000
12/12 - 0s - loss: 1.3133 - accuracy: 0.3945 - val_loss: 1.3189 - val_accuracy: 0.4019

Epoch 00566: val_loss did not improve from 1.31801
Epoch 567/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3970 - val_loss: 1.3206 - val_accuracy: 0.4051

Epoch 00567: val_loss did not improve from 1.31801
Epoch 568/10000
12/12 - 0s - loss: 1.3156 - accuracy: 0.3946 - val_loss: 1.3204 - val_accuracy: 0.4099

Epoch 00568: val_loss did not improve from 1.31801
Epoch 569/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3995 - val_loss: 1.3193 - val_accuracy: 0.4123

Epoch 00569: val_loss did not improve from 1.31801
Epoch 570/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4019 - val_loss: 1.3218 - val_accuracy: 0.4035

Epoch 00570: val_loss did not improve from 1.31801
Epoch 571/10000
12/12 - 0s - loss: 1.3150 - accuracy: 0.3983 - val_loss: 1.3216 - val_accuracy: 0.3995

Epoch 00571: val_loss did not improve from 1.31801
Epoch 572/10000
12/12 - 0s - loss: 1.3129 - accuracy: 0.4001 - val_loss: 1.3206 - val_accuracy: 0.4099

Epoch 00572: val_loss did not improve from 1.31801
Epoch 573/10000
12/12 - 0s - loss: 1.3122 - accuracy: 0.3970 - val_loss: 1.3188 - val_accuracy: 0.4123

Epoch 00573: val_loss did not improve from 1.31801
Epoch 574/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3939 - val_loss: 1.3213 - val_accuracy: 0.3995

Epoch 00574: val_loss did not improve from 1.31801
Epoch 575/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.4000 - val_loss: 1.3185 - val_accuracy: 0.4059

Epoch 00575: val_loss did not improve from 1.31801
Epoch 576/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3987 - val_loss: 1.3192 - val_accuracy: 0.4083

Epoch 00576: val_loss did not improve from 1.31801
Epoch 577/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.4010 - val_loss: 1.3177 - val_accuracy: 0.4091

Epoch 00577: val_loss improved from 1.31801 to 1.31766, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 578/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3974 - val_loss: 1.3194 - val_accuracy: 0.4107

Epoch 00578: val_loss did not improve from 1.31766
Epoch 579/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3919 - val_loss: 1.3195 - val_accuracy: 0.4099

Epoch 00579: val_loss did not improve from 1.31766
Epoch 580/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3960 - val_loss: 1.3217 - val_accuracy: 0.4011

Epoch 00580: val_loss did not improve from 1.31766
Epoch 581/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3962 - val_loss: 1.3205 - val_accuracy: 0.4155

Epoch 00581: val_loss did not improve from 1.31766
Epoch 582/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3934 - val_loss: 1.3183 - val_accuracy: 0.4147

Epoch 00582: val_loss did not improve from 1.31766
Epoch 583/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3967 - val_loss: 1.3182 - val_accuracy: 0.4107

Epoch 00583: val_loss did not improve from 1.31766
Epoch 584/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.3977 - val_loss: 1.3186 - val_accuracy: 0.4179

Epoch 00584: val_loss did not improve from 1.31766
Epoch 585/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3971 - val_loss: 1.3216 - val_accuracy: 0.4083

Epoch 00585: val_loss did not improve from 1.31766
Epoch 586/10000
12/12 - 0s - loss: 1.3155 - accuracy: 0.3978 - val_loss: 1.3211 - val_accuracy: 0.4051

Epoch 00586: val_loss did not improve from 1.31766
Epoch 587/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.3952 - val_loss: 1.3171 - val_accuracy: 0.4011

Epoch 00587: val_loss improved from 1.31766 to 1.31711, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 588/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.3988 - val_loss: 1.3181 - val_accuracy: 0.4027

Epoch 00588: val_loss did not improve from 1.31711
Epoch 589/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3967 - val_loss: 1.3172 - val_accuracy: 0.4075

Epoch 00589: val_loss did not improve from 1.31711
Epoch 590/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3971 - val_loss: 1.3194 - val_accuracy: 0.4131

Epoch 00590: val_loss did not improve from 1.31711
Epoch 591/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3982 - val_loss: 1.3217 - val_accuracy: 0.4011

Epoch 00591: val_loss did not improve from 1.31711
Epoch 592/10000
12/12 - 0s - loss: 1.3153 - accuracy: 0.3998 - val_loss: 1.3193 - val_accuracy: 0.4123

Epoch 00592: val_loss did not improve from 1.31711
Epoch 593/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3988 - val_loss: 1.3182 - val_accuracy: 0.4067

Epoch 00593: val_loss did not improve from 1.31711
Epoch 594/10000
12/12 - 0s - loss: 1.3136 - accuracy: 0.3958 - val_loss: 1.3215 - val_accuracy: 0.3987

Epoch 00594: val_loss did not improve from 1.31711
Epoch 595/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3991 - val_loss: 1.3169 - val_accuracy: 0.4163

Epoch 00595: val_loss improved from 1.31711 to 1.31691, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 596/10000
12/12 - 0s - loss: 1.3138 - accuracy: 0.3966 - val_loss: 1.3203 - val_accuracy: 0.4051

Epoch 00596: val_loss did not improve from 1.31691
Epoch 597/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3957 - val_loss: 1.3189 - val_accuracy: 0.4067

Epoch 00597: val_loss did not improve from 1.31691
Epoch 598/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.3975 - val_loss: 1.3188 - val_accuracy: 0.4075

Epoch 00598: val_loss did not improve from 1.31691
Epoch 599/10000
12/12 - 0s - loss: 1.3124 - accuracy: 0.3965 - val_loss: 1.3175 - val_accuracy: 0.4099

Epoch 00599: val_loss did not improve from 1.31691
Epoch 600/10000
12/12 - 0s - loss: 1.3127 - accuracy: 0.3971 - val_loss: 1.3187 - val_accuracy: 0.4083

Epoch 00600: val_loss did not improve from 1.31691
Epoch 601/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3977 - val_loss: 1.3202 - val_accuracy: 0.4075

Epoch 00601: val_loss did not improve from 1.31691
Epoch 602/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.3958 - val_loss: 1.3181 - val_accuracy: 0.4139

Epoch 00602: val_loss did not improve from 1.31691
Epoch 603/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.3973 - val_loss: 1.3178 - val_accuracy: 0.4115

Epoch 00603: val_loss did not improve from 1.31691
Epoch 604/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3977 - val_loss: 1.3201 - val_accuracy: 0.4019

Epoch 00604: val_loss did not improve from 1.31691
Epoch 605/10000
12/12 - 0s - loss: 1.3130 - accuracy: 0.3969 - val_loss: 1.3224 - val_accuracy: 0.4019

Epoch 00605: val_loss did not improve from 1.31691
Epoch 606/10000
12/12 - 0s - loss: 1.3128 - accuracy: 0.3990 - val_loss: 1.3197 - val_accuracy: 0.4003

Epoch 00606: val_loss did not improve from 1.31691
Epoch 607/10000
12/12 - 0s - loss: 1.3146 - accuracy: 0.3888 - val_loss: 1.3177 - val_accuracy: 0.4075

Epoch 00607: val_loss did not improve from 1.31691
Epoch 608/10000
12/12 - 0s - loss: 1.3123 - accuracy: 0.4035 - val_loss: 1.3201 - val_accuracy: 0.4075

Epoch 00608: val_loss did not improve from 1.31691
Epoch 609/10000
12/12 - 0s - loss: 1.3137 - accuracy: 0.3945 - val_loss: 1.3194 - val_accuracy: 0.4043

Epoch 00609: val_loss did not improve from 1.31691
Epoch 610/10000
12/12 - 0s - loss: 1.3120 - accuracy: 0.3982 - val_loss: 1.3170 - val_accuracy: 0.4067

Epoch 00610: val_loss did not improve from 1.31691
Epoch 611/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3980 - val_loss: 1.3192 - val_accuracy: 0.4075

Epoch 00611: val_loss did not improve from 1.31691
Epoch 612/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.3936 - val_loss: 1.3180 - val_accuracy: 0.4083

Epoch 00612: val_loss did not improve from 1.31691
Epoch 613/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3958 - val_loss: 1.3170 - val_accuracy: 0.4075

Epoch 00613: val_loss did not improve from 1.31691
Epoch 614/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3978 - val_loss: 1.3167 - val_accuracy: 0.4171

Epoch 00614: val_loss improved from 1.31691 to 1.31670, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 615/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.3979 - val_loss: 1.3179 - val_accuracy: 0.4123

Epoch 00615: val_loss did not improve from 1.31670
Epoch 616/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.3939 - val_loss: 1.3196 - val_accuracy: 0.4043

Epoch 00616: val_loss did not improve from 1.31670
Epoch 617/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.3965 - val_loss: 1.3172 - val_accuracy: 0.4035

Epoch 00617: val_loss did not improve from 1.31670
Epoch 618/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3998 - val_loss: 1.3168 - val_accuracy: 0.4075

Epoch 00618: val_loss did not improve from 1.31670
Epoch 619/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3985 - val_loss: 1.3180 - val_accuracy: 0.4051

Epoch 00619: val_loss did not improve from 1.31670
Epoch 620/10000
12/12 - 0s - loss: 1.3142 - accuracy: 0.3995 - val_loss: 1.3191 - val_accuracy: 0.4067

Epoch 00620: val_loss did not improve from 1.31670
Epoch 621/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3982 - val_loss: 1.3174 - val_accuracy: 0.4083

Epoch 00621: val_loss did not improve from 1.31670
Epoch 622/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3938 - val_loss: 1.3174 - val_accuracy: 0.4163

Epoch 00622: val_loss did not improve from 1.31670
Epoch 623/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.3977 - val_loss: 1.3182 - val_accuracy: 0.4027

Epoch 00623: val_loss did not improve from 1.31670
Epoch 624/10000
12/12 - 0s - loss: 1.3126 - accuracy: 0.3986 - val_loss: 1.3181 - val_accuracy: 0.4075

Epoch 00624: val_loss did not improve from 1.31670
Epoch 625/10000
12/12 - 0s - loss: 1.3135 - accuracy: 0.4002 - val_loss: 1.3210 - val_accuracy: 0.4083

Epoch 00625: val_loss did not improve from 1.31670
Epoch 626/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3941 - val_loss: 1.3166 - val_accuracy: 0.4083

Epoch 00626: val_loss improved from 1.31670 to 1.31658, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 627/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3973 - val_loss: 1.3157 - val_accuracy: 0.4099

Epoch 00627: val_loss improved from 1.31658 to 1.31569, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 628/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.3949 - val_loss: 1.3186 - val_accuracy: 0.4115

Epoch 00628: val_loss did not improve from 1.31569
Epoch 629/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3954 - val_loss: 1.3172 - val_accuracy: 0.4043

Epoch 00629: val_loss did not improve from 1.31569
Epoch 630/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3948 - val_loss: 1.3175 - val_accuracy: 0.4083

Epoch 00630: val_loss did not improve from 1.31569
Epoch 631/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3987 - val_loss: 1.3168 - val_accuracy: 0.4091

Epoch 00631: val_loss did not improve from 1.31569
Epoch 632/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.3976 - val_loss: 1.3168 - val_accuracy: 0.4011

Epoch 00632: val_loss did not improve from 1.31569
Epoch 633/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3999 - val_loss: 1.3177 - val_accuracy: 0.4059

Epoch 00633: val_loss did not improve from 1.31569
Epoch 634/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3983 - val_loss: 1.3156 - val_accuracy: 0.4099

Epoch 00634: val_loss improved from 1.31569 to 1.31557, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 635/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.3978 - val_loss: 1.3151 - val_accuracy: 0.4067

Epoch 00635: val_loss improved from 1.31557 to 1.31508, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 636/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.3982 - val_loss: 1.3181 - val_accuracy: 0.4059

Epoch 00636: val_loss did not improve from 1.31508
Epoch 637/10000
12/12 - 0s - loss: 1.3132 - accuracy: 0.3939 - val_loss: 1.3172 - val_accuracy: 0.4043

Epoch 00637: val_loss did not improve from 1.31508
Epoch 638/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3978 - val_loss: 1.3154 - val_accuracy: 0.4099

Epoch 00638: val_loss did not improve from 1.31508
Epoch 639/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4001 - val_loss: 1.3179 - val_accuracy: 0.4059

Epoch 00639: val_loss did not improve from 1.31508
Epoch 640/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3988 - val_loss: 1.3166 - val_accuracy: 0.4051

Epoch 00640: val_loss did not improve from 1.31508
Epoch 641/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3985 - val_loss: 1.3153 - val_accuracy: 0.4099

Epoch 00641: val_loss did not improve from 1.31508
Epoch 642/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3959 - val_loss: 1.3172 - val_accuracy: 0.4131

Epoch 00642: val_loss did not improve from 1.31508
Epoch 643/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.3967 - val_loss: 1.3167 - val_accuracy: 0.4003

Epoch 00643: val_loss did not improve from 1.31508
Epoch 644/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3985 - val_loss: 1.3154 - val_accuracy: 0.4075

Epoch 00644: val_loss did not improve from 1.31508
Epoch 645/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.4011 - val_loss: 1.3153 - val_accuracy: 0.4099

Epoch 00645: val_loss did not improve from 1.31508
Epoch 646/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.3979 - val_loss: 1.3157 - val_accuracy: 0.4019

Epoch 00646: val_loss did not improve from 1.31508
Epoch 647/10000
12/12 - 0s - loss: 1.3112 - accuracy: 0.4002 - val_loss: 1.3177 - val_accuracy: 0.4027

Epoch 00647: val_loss did not improve from 1.31508
Epoch 648/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3969 - val_loss: 1.3165 - val_accuracy: 0.4099

Epoch 00648: val_loss did not improve from 1.31508
Epoch 649/10000
12/12 - 0s - loss: 1.3134 - accuracy: 0.3993 - val_loss: 1.3155 - val_accuracy: 0.4091

Epoch 00649: val_loss did not improve from 1.31508
Epoch 650/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3947 - val_loss: 1.3172 - val_accuracy: 0.4099

Epoch 00650: val_loss did not improve from 1.31508
Epoch 651/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.3976 - val_loss: 1.3178 - val_accuracy: 0.3995

Epoch 00651: val_loss did not improve from 1.31508
Epoch 652/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.3968 - val_loss: 1.3154 - val_accuracy: 0.4179

Epoch 00652: val_loss did not improve from 1.31508
Epoch 653/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.3970 - val_loss: 1.3191 - val_accuracy: 0.4059

Epoch 00653: val_loss did not improve from 1.31508
Epoch 654/10000
12/12 - 0s - loss: 1.3143 - accuracy: 0.3922 - val_loss: 1.3190 - val_accuracy: 0.4083

Epoch 00654: val_loss did not improve from 1.31508
Epoch 655/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4008 - val_loss: 1.3163 - val_accuracy: 0.4083

Epoch 00655: val_loss did not improve from 1.31508
Epoch 656/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3998 - val_loss: 1.3174 - val_accuracy: 0.4099

Epoch 00656: val_loss did not improve from 1.31508
Epoch 657/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3955 - val_loss: 1.3159 - val_accuracy: 0.4051

Epoch 00657: val_loss did not improve from 1.31508
Epoch 658/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.3976 - val_loss: 1.3163 - val_accuracy: 0.4035

Epoch 00658: val_loss did not improve from 1.31508
Epoch 659/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3997 - val_loss: 1.3165 - val_accuracy: 0.4115

Epoch 00659: val_loss did not improve from 1.31508
Epoch 660/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.3982 - val_loss: 1.3161 - val_accuracy: 0.4067

Epoch 00660: val_loss did not improve from 1.31508
Epoch 661/10000
12/12 - 0s - loss: 1.3114 - accuracy: 0.3945 - val_loss: 1.3167 - val_accuracy: 0.4075

Epoch 00661: val_loss did not improve from 1.31508
Epoch 662/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.4019 - val_loss: 1.3156 - val_accuracy: 0.4067

Epoch 00662: val_loss did not improve from 1.31508
Epoch 663/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.3978 - val_loss: 1.3154 - val_accuracy: 0.4067

Epoch 00663: val_loss did not improve from 1.31508
Epoch 664/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3980 - val_loss: 1.3153 - val_accuracy: 0.4067

Epoch 00664: val_loss did not improve from 1.31508
Epoch 665/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3968 - val_loss: 1.3157 - val_accuracy: 0.4067

Epoch 00665: val_loss did not improve from 1.31508
Epoch 666/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3978 - val_loss: 1.3146 - val_accuracy: 0.4115

Epoch 00666: val_loss improved from 1.31508 to 1.31459, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 667/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3994 - val_loss: 1.3157 - val_accuracy: 0.4155

Epoch 00667: val_loss did not improve from 1.31459
Epoch 668/10000
12/12 - 0s - loss: 1.3102 - accuracy: 0.3977 - val_loss: 1.3186 - val_accuracy: 0.4011

Epoch 00668: val_loss did not improve from 1.31459
Epoch 669/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.3965 - val_loss: 1.3156 - val_accuracy: 0.4115

Epoch 00669: val_loss did not improve from 1.31459
Epoch 670/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3978 - val_loss: 1.3159 - val_accuracy: 0.4075

Epoch 00670: val_loss did not improve from 1.31459
Epoch 671/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.3954 - val_loss: 1.3140 - val_accuracy: 0.4107

Epoch 00671: val_loss improved from 1.31459 to 1.31400, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 672/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3995 - val_loss: 1.3129 - val_accuracy: 0.4107

Epoch 00672: val_loss improved from 1.31400 to 1.31288, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 673/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.3958 - val_loss: 1.3146 - val_accuracy: 0.4091

Epoch 00673: val_loss did not improve from 1.31288
Epoch 674/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4027 - val_loss: 1.3145 - val_accuracy: 0.4107

Epoch 00674: val_loss did not improve from 1.31288
Epoch 675/10000
12/12 - 0s - loss: 1.3096 - accuracy: 0.4003 - val_loss: 1.3149 - val_accuracy: 0.4155

Epoch 00675: val_loss did not improve from 1.31288
Epoch 676/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4028 - val_loss: 1.3164 - val_accuracy: 0.4035

Epoch 00676: val_loss did not improve from 1.31288
Epoch 677/10000
12/12 - 0s - loss: 1.3118 - accuracy: 0.3987 - val_loss: 1.3172 - val_accuracy: 0.4051

Epoch 00677: val_loss did not improve from 1.31288
Epoch 678/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3954 - val_loss: 1.3152 - val_accuracy: 0.4091

Epoch 00678: val_loss did not improve from 1.31288
Epoch 679/10000
12/12 - 0s - loss: 1.3117 - accuracy: 0.4009 - val_loss: 1.3153 - val_accuracy: 0.4075

Epoch 00679: val_loss did not improve from 1.31288
Epoch 680/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3954 - val_loss: 1.3141 - val_accuracy: 0.4211

Epoch 00680: val_loss did not improve from 1.31288
Epoch 681/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3962 - val_loss: 1.3141 - val_accuracy: 0.4107

Epoch 00681: val_loss did not improve from 1.31288
Epoch 682/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.3948 - val_loss: 1.3138 - val_accuracy: 0.4075

Epoch 00682: val_loss did not improve from 1.31288
Epoch 683/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4009 - val_loss: 1.3153 - val_accuracy: 0.4067

Epoch 00683: val_loss did not improve from 1.31288
Epoch 684/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3951 - val_loss: 1.3150 - val_accuracy: 0.4067

Epoch 00684: val_loss did not improve from 1.31288
Epoch 685/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3931 - val_loss: 1.3146 - val_accuracy: 0.4027

Epoch 00685: val_loss did not improve from 1.31288
Epoch 686/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3979 - val_loss: 1.3161 - val_accuracy: 0.4083

Epoch 00686: val_loss did not improve from 1.31288
Epoch 687/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4005 - val_loss: 1.3132 - val_accuracy: 0.4067

Epoch 00687: val_loss did not improve from 1.31288
Epoch 688/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.3982 - val_loss: 1.3128 - val_accuracy: 0.4107

Epoch 00688: val_loss improved from 1.31288 to 1.31277, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 689/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4002 - val_loss: 1.3129 - val_accuracy: 0.4051

Epoch 00689: val_loss did not improve from 1.31277
Epoch 690/10000
12/12 - 0s - loss: 1.3116 - accuracy: 0.3971 - val_loss: 1.3155 - val_accuracy: 0.4019

Epoch 00690: val_loss did not improve from 1.31277
Epoch 691/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4011 - val_loss: 1.3137 - val_accuracy: 0.4091

Epoch 00691: val_loss did not improve from 1.31277
Epoch 692/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3985 - val_loss: 1.3137 - val_accuracy: 0.4083

Epoch 00692: val_loss did not improve from 1.31277
Epoch 693/10000
12/12 - 0s - loss: 1.3085 - accuracy: 0.3964 - val_loss: 1.3136 - val_accuracy: 0.4051

Epoch 00693: val_loss did not improve from 1.31277
Epoch 694/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3993 - val_loss: 1.3127 - val_accuracy: 0.4115

Epoch 00694: val_loss improved from 1.31277 to 1.31266, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 695/10000
12/12 - 0s - loss: 1.3105 - accuracy: 0.4005 - val_loss: 1.3180 - val_accuracy: 0.4035

Epoch 00695: val_loss did not improve from 1.31266
Epoch 696/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.3955 - val_loss: 1.3150 - val_accuracy: 0.4059

Epoch 00696: val_loss did not improve from 1.31266
Epoch 697/10000
12/12 - 0s - loss: 1.3100 - accuracy: 0.3943 - val_loss: 1.3151 - val_accuracy: 0.4075

Epoch 00697: val_loss did not improve from 1.31266
Epoch 698/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.3989 - val_loss: 1.3148 - val_accuracy: 0.4091

Epoch 00698: val_loss did not improve from 1.31266
Epoch 699/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3979 - val_loss: 1.3141 - val_accuracy: 0.4059

Epoch 00699: val_loss did not improve from 1.31266
Epoch 700/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3962 - val_loss: 1.3127 - val_accuracy: 0.4099

Epoch 00700: val_loss did not improve from 1.31266
Epoch 701/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.3963 - val_loss: 1.3129 - val_accuracy: 0.4067

Epoch 00701: val_loss did not improve from 1.31266
Epoch 702/10000
12/12 - 0s - loss: 1.3104 - accuracy: 0.3989 - val_loss: 1.3169 - val_accuracy: 0.4139

Epoch 00702: val_loss did not improve from 1.31266
Epoch 703/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.3969 - val_loss: 1.3169 - val_accuracy: 0.4027

Epoch 00703: val_loss did not improve from 1.31266
Epoch 704/10000
12/12 - 0s - loss: 1.3119 - accuracy: 0.3978 - val_loss: 1.3166 - val_accuracy: 0.3995

Epoch 00704: val_loss did not improve from 1.31266
Epoch 705/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.3970 - val_loss: 1.3150 - val_accuracy: 0.4115

Epoch 00705: val_loss did not improve from 1.31266
Epoch 706/10000
12/12 - 0s - loss: 1.3172 - accuracy: 0.3965 - val_loss: 1.3182 - val_accuracy: 0.4083

Epoch 00706: val_loss did not improve from 1.31266
Epoch 707/10000
12/12 - 0s - loss: 1.3097 - accuracy: 0.3978 - val_loss: 1.3127 - val_accuracy: 0.4099

Epoch 00707: val_loss did not improve from 1.31266
Epoch 708/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3993 - val_loss: 1.3131 - val_accuracy: 0.4043

Epoch 00708: val_loss did not improve from 1.31266
Epoch 709/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.3993 - val_loss: 1.3157 - val_accuracy: 0.4099

Epoch 00709: val_loss did not improve from 1.31266
Epoch 710/10000
12/12 - 0s - loss: 1.3095 - accuracy: 0.3969 - val_loss: 1.3144 - val_accuracy: 0.4059

Epoch 00710: val_loss did not improve from 1.31266
Epoch 711/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.3969 - val_loss: 1.3138 - val_accuracy: 0.4067

Epoch 00711: val_loss did not improve from 1.31266
Epoch 712/10000
12/12 - 0s - loss: 1.3090 - accuracy: 0.3978 - val_loss: 1.3134 - val_accuracy: 0.4131

Epoch 00712: val_loss did not improve from 1.31266
Epoch 713/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4027 - val_loss: 1.3128 - val_accuracy: 0.4139

Epoch 00713: val_loss did not improve from 1.31266
Epoch 714/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4002 - val_loss: 1.3121 - val_accuracy: 0.4115

Epoch 00714: val_loss improved from 1.31266 to 1.31213, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 715/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.3985 - val_loss: 1.3138 - val_accuracy: 0.4067

Epoch 00715: val_loss did not improve from 1.31213
Epoch 716/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.4035 - val_loss: 1.3155 - val_accuracy: 0.4115

Epoch 00716: val_loss did not improve from 1.31213
Epoch 717/10000
12/12 - 0s - loss: 1.3131 - accuracy: 0.3955 - val_loss: 1.3155 - val_accuracy: 0.4115

Epoch 00717: val_loss did not improve from 1.31213
Epoch 718/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.4025 - val_loss: 1.3122 - val_accuracy: 0.4115

Epoch 00718: val_loss did not improve from 1.31213
Epoch 719/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.3972 - val_loss: 1.3122 - val_accuracy: 0.4115

Epoch 00719: val_loss did not improve from 1.31213
Epoch 720/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.3988 - val_loss: 1.3131 - val_accuracy: 0.4131

Epoch 00720: val_loss did not improve from 1.31213
Epoch 721/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.4028 - val_loss: 1.3138 - val_accuracy: 0.4147

Epoch 00721: val_loss did not improve from 1.31213
Epoch 722/10000
12/12 - 0s - loss: 1.3110 - accuracy: 0.4001 - val_loss: 1.3161 - val_accuracy: 0.4043

Epoch 00722: val_loss did not improve from 1.31213
Epoch 723/10000
12/12 - 0s - loss: 1.3099 - accuracy: 0.4016 - val_loss: 1.3156 - val_accuracy: 0.4099

Epoch 00723: val_loss did not improve from 1.31213
Epoch 724/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4011 - val_loss: 1.3128 - val_accuracy: 0.4139

Epoch 00724: val_loss did not improve from 1.31213
Epoch 725/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.3994 - val_loss: 1.3139 - val_accuracy: 0.4091

Epoch 00725: val_loss did not improve from 1.31213
Epoch 726/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.4047 - val_loss: 1.3128 - val_accuracy: 0.4091

Epoch 00726: val_loss did not improve from 1.31213
Epoch 727/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3984 - val_loss: 1.3166 - val_accuracy: 0.4035

Epoch 00727: val_loss did not improve from 1.31213
Epoch 728/10000
12/12 - 0s - loss: 1.3109 - accuracy: 0.3966 - val_loss: 1.3125 - val_accuracy: 0.4091

Epoch 00728: val_loss did not improve from 1.31213
Epoch 729/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.3994 - val_loss: 1.3121 - val_accuracy: 0.4123

Epoch 00729: val_loss improved from 1.31213 to 1.31208, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 730/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4011 - val_loss: 1.3126 - val_accuracy: 0.4115

Epoch 00730: val_loss did not improve from 1.31208
Epoch 731/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.4044 - val_loss: 1.3136 - val_accuracy: 0.4091

Epoch 00731: val_loss did not improve from 1.31208
Epoch 732/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3979 - val_loss: 1.3156 - val_accuracy: 0.4075

Epoch 00732: val_loss did not improve from 1.31208
Epoch 733/10000
12/12 - 0s - loss: 1.3101 - accuracy: 0.3982 - val_loss: 1.3128 - val_accuracy: 0.4067

Epoch 00733: val_loss did not improve from 1.31208
Epoch 734/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4018 - val_loss: 1.3134 - val_accuracy: 0.4051

Epoch 00734: val_loss did not improve from 1.31208
Epoch 735/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.4030 - val_loss: 1.3164 - val_accuracy: 0.4003

Epoch 00735: val_loss did not improve from 1.31208
Epoch 736/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.3977 - val_loss: 1.3164 - val_accuracy: 0.4059

Epoch 00736: val_loss did not improve from 1.31208
Epoch 737/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.3998 - val_loss: 1.3122 - val_accuracy: 0.4035

Epoch 00737: val_loss did not improve from 1.31208
Epoch 738/10000
12/12 - 0s - loss: 1.3092 - accuracy: 0.4010 - val_loss: 1.3133 - val_accuracy: 0.4027

Epoch 00738: val_loss did not improve from 1.31208
Epoch 739/10000
12/12 - 0s - loss: 1.3091 - accuracy: 0.3973 - val_loss: 1.3154 - val_accuracy: 0.4099

Epoch 00739: val_loss did not improve from 1.31208
Epoch 740/10000
12/12 - 0s - loss: 1.3093 - accuracy: 0.4000 - val_loss: 1.3114 - val_accuracy: 0.4099

Epoch 00740: val_loss improved from 1.31208 to 1.31137, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 741/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.3989 - val_loss: 1.3136 - val_accuracy: 0.4067

Epoch 00741: val_loss did not improve from 1.31137
Epoch 742/10000
12/12 - 0s - loss: 1.3103 - accuracy: 0.3954 - val_loss: 1.3132 - val_accuracy: 0.4091

Epoch 00742: val_loss did not improve from 1.31137
Epoch 743/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.3964 - val_loss: 1.3144 - val_accuracy: 0.4059

Epoch 00743: val_loss did not improve from 1.31137
Epoch 744/10000
12/12 - 0s - loss: 1.3098 - accuracy: 0.3992 - val_loss: 1.3115 - val_accuracy: 0.4059

Epoch 00744: val_loss did not improve from 1.31137
Epoch 745/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.3984 - val_loss: 1.3118 - val_accuracy: 0.4075

Epoch 00745: val_loss did not improve from 1.31137
Epoch 746/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.3980 - val_loss: 1.3115 - val_accuracy: 0.4139

Epoch 00746: val_loss did not improve from 1.31137
Epoch 747/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3973 - val_loss: 1.3153 - val_accuracy: 0.4035

Epoch 00747: val_loss did not improve from 1.31137
Epoch 748/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4024 - val_loss: 1.3136 - val_accuracy: 0.4091

Epoch 00748: val_loss did not improve from 1.31137
Epoch 749/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.3999 - val_loss: 1.3111 - val_accuracy: 0.4075

Epoch 00749: val_loss improved from 1.31137 to 1.31109, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 750/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.3962 - val_loss: 1.3116 - val_accuracy: 0.4067

Epoch 00750: val_loss did not improve from 1.31109
Epoch 751/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.3985 - val_loss: 1.3114 - val_accuracy: 0.4123

Epoch 00751: val_loss did not improve from 1.31109
Epoch 752/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.3983 - val_loss: 1.3113 - val_accuracy: 0.4123

Epoch 00752: val_loss did not improve from 1.31109
Epoch 753/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.3978 - val_loss: 1.3118 - val_accuracy: 0.4051

Epoch 00753: val_loss did not improve from 1.31109
Epoch 754/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3962 - val_loss: 1.3127 - val_accuracy: 0.4051

Epoch 00754: val_loss did not improve from 1.31109
Epoch 755/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.3998 - val_loss: 1.3117 - val_accuracy: 0.4147

Epoch 00755: val_loss did not improve from 1.31109
Epoch 756/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.3992 - val_loss: 1.3156 - val_accuracy: 0.4099

Epoch 00756: val_loss did not improve from 1.31109
Epoch 757/10000
12/12 - 0s - loss: 1.3121 - accuracy: 0.3999 - val_loss: 1.3153 - val_accuracy: 0.4011

Epoch 00757: val_loss did not improve from 1.31109
Epoch 758/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.3988 - val_loss: 1.3145 - val_accuracy: 0.4059

Epoch 00758: val_loss did not improve from 1.31109
Epoch 759/10000
12/12 - 0s - loss: 1.3083 - accuracy: 0.3976 - val_loss: 1.3127 - val_accuracy: 0.4115

Epoch 00759: val_loss did not improve from 1.31109
Epoch 760/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.3961 - val_loss: 1.3127 - val_accuracy: 0.4091

Epoch 00760: val_loss did not improve from 1.31109
Epoch 761/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.3985 - val_loss: 1.3126 - val_accuracy: 0.4115

Epoch 00761: val_loss did not improve from 1.31109
Epoch 762/10000
12/12 - 0s - loss: 1.3087 - accuracy: 0.3953 - val_loss: 1.3119 - val_accuracy: 0.4075

Epoch 00762: val_loss did not improve from 1.31109
Epoch 763/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.3993 - val_loss: 1.3135 - val_accuracy: 0.4091

Epoch 00763: val_loss did not improve from 1.31109
Epoch 764/10000
12/12 - 0s - loss: 1.3076 - accuracy: 0.4004 - val_loss: 1.3123 - val_accuracy: 0.4075

Epoch 00764: val_loss did not improve from 1.31109
Epoch 765/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.3962 - val_loss: 1.3113 - val_accuracy: 0.4083

Epoch 00765: val_loss did not improve from 1.31109
Epoch 766/10000
12/12 - 0s - loss: 1.3079 - accuracy: 0.3963 - val_loss: 1.3114 - val_accuracy: 0.4171

Epoch 00766: val_loss did not improve from 1.31109
Epoch 767/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4026 - val_loss: 1.3126 - val_accuracy: 0.4099

Epoch 00767: val_loss did not improve from 1.31109
Epoch 768/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4038 - val_loss: 1.3122 - val_accuracy: 0.4131

Epoch 00768: val_loss did not improve from 1.31109
Epoch 769/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.4004 - val_loss: 1.3126 - val_accuracy: 0.4083

Epoch 00769: val_loss did not improve from 1.31109
Epoch 770/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4001 - val_loss: 1.3105 - val_accuracy: 0.4115

Epoch 00770: val_loss improved from 1.31109 to 1.31048, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 771/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.3988 - val_loss: 1.3100 - val_accuracy: 0.4155

Epoch 00771: val_loss improved from 1.31048 to 1.31003, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 772/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.4012 - val_loss: 1.3126 - val_accuracy: 0.4035

Epoch 00772: val_loss did not improve from 1.31003
Epoch 773/10000
12/12 - 0s - loss: 1.3111 - accuracy: 0.4028 - val_loss: 1.3143 - val_accuracy: 0.3987

Epoch 00773: val_loss did not improve from 1.31003
Epoch 774/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4003 - val_loss: 1.3114 - val_accuracy: 0.4115

Epoch 00774: val_loss did not improve from 1.31003
Epoch 775/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.3978 - val_loss: 1.3130 - val_accuracy: 0.4059

Epoch 00775: val_loss did not improve from 1.31003
Epoch 776/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.3986 - val_loss: 1.3110 - val_accuracy: 0.4123

Epoch 00776: val_loss did not improve from 1.31003
Epoch 777/10000
12/12 - 0s - loss: 1.3070 - accuracy: 0.4029 - val_loss: 1.3105 - val_accuracy: 0.4107

Epoch 00777: val_loss did not improve from 1.31003
Epoch 778/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4018 - val_loss: 1.3149 - val_accuracy: 0.4011

Epoch 00778: val_loss did not improve from 1.31003
Epoch 779/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.3954 - val_loss: 1.3124 - val_accuracy: 0.4067

Epoch 00779: val_loss did not improve from 1.31003
Epoch 780/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.4016 - val_loss: 1.3107 - val_accuracy: 0.4139

Epoch 00780: val_loss did not improve from 1.31003
Epoch 781/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4007 - val_loss: 1.3115 - val_accuracy: 0.4091

Epoch 00781: val_loss did not improve from 1.31003
Epoch 782/10000
12/12 - 0s - loss: 1.3075 - accuracy: 0.3975 - val_loss: 1.3103 - val_accuracy: 0.4099

Epoch 00782: val_loss did not improve from 1.31003
Epoch 783/10000
12/12 - 0s - loss: 1.3058 - accuracy: 0.4015 - val_loss: 1.3105 - val_accuracy: 0.4099

Epoch 00783: val_loss did not improve from 1.31003
Epoch 784/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.3968 - val_loss: 1.3147 - val_accuracy: 0.4051

Epoch 00784: val_loss did not improve from 1.31003
Epoch 785/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.3962 - val_loss: 1.3117 - val_accuracy: 0.4043

Epoch 00785: val_loss did not improve from 1.31003
Epoch 786/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.3983 - val_loss: 1.3110 - val_accuracy: 0.4131

Epoch 00786: val_loss did not improve from 1.31003
Epoch 787/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.3989 - val_loss: 1.3143 - val_accuracy: 0.4075

Epoch 00787: val_loss did not improve from 1.31003
Epoch 788/10000
12/12 - 0s - loss: 1.3082 - accuracy: 0.4021 - val_loss: 1.3145 - val_accuracy: 0.4067

Epoch 00788: val_loss did not improve from 1.31003
Epoch 789/10000
12/12 - 0s - loss: 1.3071 - accuracy: 0.3985 - val_loss: 1.3117 - val_accuracy: 0.4107

Epoch 00789: val_loss did not improve from 1.31003
Epoch 790/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.3990 - val_loss: 1.3102 - val_accuracy: 0.4115

Epoch 00790: val_loss did not improve from 1.31003
Epoch 791/10000
12/12 - 0s - loss: 1.3067 - accuracy: 0.3988 - val_loss: 1.3119 - val_accuracy: 0.4067

Epoch 00791: val_loss did not improve from 1.31003
Epoch 792/10000
12/12 - 0s - loss: 1.3073 - accuracy: 0.3994 - val_loss: 1.3098 - val_accuracy: 0.4171

Epoch 00792: val_loss improved from 1.31003 to 1.30984, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 793/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4035 - val_loss: 1.3109 - val_accuracy: 0.4139

Epoch 00793: val_loss did not improve from 1.30984
Epoch 794/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4010 - val_loss: 1.3102 - val_accuracy: 0.4091

Epoch 00794: val_loss did not improve from 1.30984
Epoch 795/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4001 - val_loss: 1.3108 - val_accuracy: 0.4067

Epoch 00795: val_loss did not improve from 1.30984
Epoch 796/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.3989 - val_loss: 1.3113 - val_accuracy: 0.4107

Epoch 00796: val_loss did not improve from 1.30984
Epoch 797/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.3991 - val_loss: 1.3102 - val_accuracy: 0.4139

Epoch 00797: val_loss did not improve from 1.30984
Epoch 798/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.3996 - val_loss: 1.3099 - val_accuracy: 0.4139

Epoch 00798: val_loss did not improve from 1.30984
Epoch 799/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.3990 - val_loss: 1.3105 - val_accuracy: 0.4139

Epoch 00799: val_loss did not improve from 1.30984
Epoch 800/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3986 - val_loss: 1.3102 - val_accuracy: 0.4115

Epoch 00800: val_loss did not improve from 1.30984
Epoch 801/10000
12/12 - 0s - loss: 1.3077 - accuracy: 0.4001 - val_loss: 1.3112 - val_accuracy: 0.4123

Epoch 00801: val_loss did not improve from 1.30984
Epoch 802/10000
12/12 - 0s - loss: 1.3088 - accuracy: 0.3972 - val_loss: 1.3093 - val_accuracy: 0.4043

Epoch 00802: val_loss improved from 1.30984 to 1.30933, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 803/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4001 - val_loss: 1.3096 - val_accuracy: 0.4115

Epoch 00803: val_loss did not improve from 1.30933
Epoch 804/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3985 - val_loss: 1.3105 - val_accuracy: 0.4107

Epoch 00804: val_loss did not improve from 1.30933
Epoch 805/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.3990 - val_loss: 1.3113 - val_accuracy: 0.4091

Epoch 00805: val_loss did not improve from 1.30933
Epoch 806/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4036 - val_loss: 1.3097 - val_accuracy: 0.4059

Epoch 00806: val_loss did not improve from 1.30933
Epoch 807/10000
12/12 - 0s - loss: 1.3072 - accuracy: 0.4010 - val_loss: 1.3102 - val_accuracy: 0.4083

Epoch 00807: val_loss did not improve from 1.30933
Epoch 808/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4006 - val_loss: 1.3094 - val_accuracy: 0.4083

Epoch 00808: val_loss did not improve from 1.30933
Epoch 809/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.4007 - val_loss: 1.3103 - val_accuracy: 0.4099

Epoch 00809: val_loss did not improve from 1.30933
Epoch 810/10000
12/12 - 0s - loss: 1.3074 - accuracy: 0.3962 - val_loss: 1.3108 - val_accuracy: 0.4083

Epoch 00810: val_loss did not improve from 1.30933
Epoch 811/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.3996 - val_loss: 1.3124 - val_accuracy: 0.4059

Epoch 00811: val_loss did not improve from 1.30933
Epoch 812/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3978 - val_loss: 1.3098 - val_accuracy: 0.4035

Epoch 00812: val_loss did not improve from 1.30933
Epoch 813/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4002 - val_loss: 1.3110 - val_accuracy: 0.4099

Epoch 00813: val_loss did not improve from 1.30933
Epoch 814/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.4036 - val_loss: 1.3152 - val_accuracy: 0.4003

Epoch 00814: val_loss did not improve from 1.30933
Epoch 815/10000
12/12 - 0s - loss: 1.3141 - accuracy: 0.3970 - val_loss: 1.3149 - val_accuracy: 0.4075

Epoch 00815: val_loss did not improve from 1.30933
Epoch 816/10000
12/12 - 0s - loss: 1.3106 - accuracy: 0.3966 - val_loss: 1.3176 - val_accuracy: 0.4011

Epoch 00816: val_loss did not improve from 1.30933
Epoch 817/10000
12/12 - 0s - loss: 1.3115 - accuracy: 0.4024 - val_loss: 1.3117 - val_accuracy: 0.4059

Epoch 00817: val_loss did not improve from 1.30933
Epoch 818/10000
12/12 - 0s - loss: 1.3108 - accuracy: 0.4030 - val_loss: 1.3117 - val_accuracy: 0.4131

Epoch 00818: val_loss did not improve from 1.30933
Epoch 819/10000
12/12 - 0s - loss: 1.3094 - accuracy: 0.4008 - val_loss: 1.3114 - val_accuracy: 0.4107

Epoch 00819: val_loss did not improve from 1.30933
Epoch 820/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.3961 - val_loss: 1.3181 - val_accuracy: 0.4019

Epoch 00820: val_loss did not improve from 1.30933
Epoch 821/10000
12/12 - 0s - loss: 1.3089 - accuracy: 0.4045 - val_loss: 1.3121 - val_accuracy: 0.4099

Epoch 00821: val_loss did not improve from 1.30933
Epoch 822/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.3976 - val_loss: 1.3110 - val_accuracy: 0.4067

Epoch 00822: val_loss did not improve from 1.30933
Epoch 823/10000
12/12 - 0s - loss: 1.3068 - accuracy: 0.3936 - val_loss: 1.3128 - val_accuracy: 0.4075

Epoch 00823: val_loss did not improve from 1.30933
Epoch 824/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3991 - val_loss: 1.3116 - val_accuracy: 0.4083

Epoch 00824: val_loss did not improve from 1.30933
Epoch 825/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.3999 - val_loss: 1.3101 - val_accuracy: 0.4195

Epoch 00825: val_loss did not improve from 1.30933
Epoch 826/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.3966 - val_loss: 1.3112 - val_accuracy: 0.4107

Epoch 00826: val_loss did not improve from 1.30933
Epoch 827/10000
12/12 - 0s - loss: 1.3080 - accuracy: 0.4022 - val_loss: 1.3098 - val_accuracy: 0.4107

Epoch 00827: val_loss did not improve from 1.30933
Epoch 828/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.3999 - val_loss: 1.3105 - val_accuracy: 0.4091

Epoch 00828: val_loss did not improve from 1.30933
Epoch 829/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.4012 - val_loss: 1.3099 - val_accuracy: 0.4027

Epoch 00829: val_loss did not improve from 1.30933
Epoch 830/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.3998 - val_loss: 1.3104 - val_accuracy: 0.4115

Epoch 00830: val_loss did not improve from 1.30933
Epoch 831/10000
12/12 - 0s - loss: 1.3048 - accuracy: 0.4000 - val_loss: 1.3097 - val_accuracy: 0.4115

Epoch 00831: val_loss did not improve from 1.30933
Epoch 832/10000
12/12 - 0s - loss: 1.3061 - accuracy: 0.4008 - val_loss: 1.3096 - val_accuracy: 0.4099

Epoch 00832: val_loss did not improve from 1.30933
Epoch 833/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.4025 - val_loss: 1.3108 - val_accuracy: 0.4051

Epoch 00833: val_loss did not improve from 1.30933
Epoch 834/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4004 - val_loss: 1.3104 - val_accuracy: 0.4187

Epoch 00834: val_loss did not improve from 1.30933
Epoch 835/10000
12/12 - 0s - loss: 1.3066 - accuracy: 0.4006 - val_loss: 1.3085 - val_accuracy: 0.4131

Epoch 00835: val_loss improved from 1.30933 to 1.30853, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 836/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.3997 - val_loss: 1.3093 - val_accuracy: 0.4107

Epoch 00836: val_loss did not improve from 1.30853
Epoch 837/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.3989 - val_loss: 1.3118 - val_accuracy: 0.4059

Epoch 00837: val_loss did not improve from 1.30853
Epoch 838/10000
12/12 - 0s - loss: 1.3078 - accuracy: 0.3979 - val_loss: 1.3169 - val_accuracy: 0.4019

Epoch 00838: val_loss did not improve from 1.30853
Epoch 839/10000
12/12 - 0s - loss: 1.3113 - accuracy: 0.4011 - val_loss: 1.3141 - val_accuracy: 0.4083

Epoch 00839: val_loss did not improve from 1.30853
Epoch 840/10000
12/12 - 0s - loss: 1.3051 - accuracy: 0.3997 - val_loss: 1.3083 - val_accuracy: 0.4139

Epoch 00840: val_loss improved from 1.30853 to 1.30828, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 841/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4018 - val_loss: 1.3089 - val_accuracy: 0.4123

Epoch 00841: val_loss did not improve from 1.30828
Epoch 842/10000
12/12 - 0s - loss: 1.3060 - accuracy: 0.3988 - val_loss: 1.3099 - val_accuracy: 0.4091

Epoch 00842: val_loss did not improve from 1.30828
Epoch 843/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.3994 - val_loss: 1.3097 - val_accuracy: 0.4043

Epoch 00843: val_loss did not improve from 1.30828
Epoch 844/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4001 - val_loss: 1.3105 - val_accuracy: 0.4059

Epoch 00844: val_loss did not improve from 1.30828
Epoch 845/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.3963 - val_loss: 1.3092 - val_accuracy: 0.4075

Epoch 00845: val_loss did not improve from 1.30828
Epoch 846/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.3983 - val_loss: 1.3100 - val_accuracy: 0.4051

Epoch 00846: val_loss did not improve from 1.30828
Epoch 847/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3989 - val_loss: 1.3097 - val_accuracy: 0.4083

Epoch 00847: val_loss did not improve from 1.30828
Epoch 848/10000
12/12 - 0s - loss: 1.3056 - accuracy: 0.4039 - val_loss: 1.3082 - val_accuracy: 0.4091

Epoch 00848: val_loss improved from 1.30828 to 1.30818, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 849/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3966 - val_loss: 1.3102 - val_accuracy: 0.4067

Epoch 00849: val_loss did not improve from 1.30818
Epoch 850/10000
12/12 - 0s - loss: 1.3059 - accuracy: 0.4016 - val_loss: 1.3103 - val_accuracy: 0.4123

Epoch 00850: val_loss did not improve from 1.30818
Epoch 851/10000
12/12 - 0s - loss: 1.3065 - accuracy: 0.4004 - val_loss: 1.3107 - val_accuracy: 0.4115

Epoch 00851: val_loss did not improve from 1.30818
Epoch 852/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.4015 - val_loss: 1.3078 - val_accuracy: 0.4179

Epoch 00852: val_loss improved from 1.30818 to 1.30781, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 853/10000
12/12 - 0s - loss: 1.3053 - accuracy: 0.3995 - val_loss: 1.3098 - val_accuracy: 0.4139

Epoch 00853: val_loss did not improve from 1.30781
Epoch 854/10000
12/12 - 0s - loss: 1.3049 - accuracy: 0.4032 - val_loss: 1.3081 - val_accuracy: 0.4147

Epoch 00854: val_loss did not improve from 1.30781
Epoch 855/10000
12/12 - 0s - loss: 1.3042 - accuracy: 0.4028 - val_loss: 1.3108 - val_accuracy: 0.4075

Epoch 00855: val_loss did not improve from 1.30781
Epoch 856/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.3971 - val_loss: 1.3095 - val_accuracy: 0.4115

Epoch 00856: val_loss did not improve from 1.30781
Epoch 857/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4003 - val_loss: 1.3078 - val_accuracy: 0.4131

Epoch 00857: val_loss improved from 1.30781 to 1.30776, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 858/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4017 - val_loss: 1.3078 - val_accuracy: 0.4123

Epoch 00858: val_loss did not improve from 1.30776
Epoch 859/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.3997 - val_loss: 1.3110 - val_accuracy: 0.4123

Epoch 00859: val_loss did not improve from 1.30776
Epoch 860/10000
12/12 - 0s - loss: 1.3062 - accuracy: 0.3950 - val_loss: 1.3127 - val_accuracy: 0.4051

Epoch 00860: val_loss did not improve from 1.30776
Epoch 861/10000
12/12 - 0s - loss: 1.3069 - accuracy: 0.3997 - val_loss: 1.3090 - val_accuracy: 0.4123

Epoch 00861: val_loss did not improve from 1.30776
Epoch 862/10000
12/12 - 0s - loss: 1.3052 - accuracy: 0.4005 - val_loss: 1.3159 - val_accuracy: 0.4067

Epoch 00862: val_loss did not improve from 1.30776
Epoch 863/10000
12/12 - 0s - loss: 1.3084 - accuracy: 0.3995 - val_loss: 1.3140 - val_accuracy: 0.4107

Epoch 00863: val_loss did not improve from 1.30776
Epoch 864/10000
12/12 - 0s - loss: 1.3081 - accuracy: 0.4011 - val_loss: 1.3100 - val_accuracy: 0.4123

Epoch 00864: val_loss did not improve from 1.30776
Epoch 865/10000
12/12 - 0s - loss: 1.3047 - accuracy: 0.3985 - val_loss: 1.3113 - val_accuracy: 0.4123

Epoch 00865: val_loss did not improve from 1.30776
Epoch 866/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.3983 - val_loss: 1.3099 - val_accuracy: 0.4091

Epoch 00866: val_loss did not improve from 1.30776
Epoch 867/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4006 - val_loss: 1.3082 - val_accuracy: 0.4075

Epoch 00867: val_loss did not improve from 1.30776
Epoch 868/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4016 - val_loss: 1.3095 - val_accuracy: 0.4099

Epoch 00868: val_loss did not improve from 1.30776
Epoch 869/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.4009 - val_loss: 1.3076 - val_accuracy: 0.4107

Epoch 00869: val_loss improved from 1.30776 to 1.30759, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 870/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4035 - val_loss: 1.3077 - val_accuracy: 0.4107

Epoch 00870: val_loss did not improve from 1.30759
Epoch 871/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4013 - val_loss: 1.3092 - val_accuracy: 0.4147

Epoch 00871: val_loss did not improve from 1.30759
Epoch 872/10000
12/12 - 0s - loss: 1.3043 - accuracy: 0.4001 - val_loss: 1.3107 - val_accuracy: 0.4075

Epoch 00872: val_loss did not improve from 1.30759
Epoch 873/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4000 - val_loss: 1.3075 - val_accuracy: 0.4059

Epoch 00873: val_loss improved from 1.30759 to 1.30745, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 874/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4029 - val_loss: 1.3100 - val_accuracy: 0.4155

Epoch 00874: val_loss did not improve from 1.30745
Epoch 875/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4020 - val_loss: 1.3092 - val_accuracy: 0.4147

Epoch 00875: val_loss did not improve from 1.30745
Epoch 876/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4053 - val_loss: 1.3095 - val_accuracy: 0.4131

Epoch 00876: val_loss did not improve from 1.30745
Epoch 877/10000
12/12 - 0s - loss: 1.3039 - accuracy: 0.4035 - val_loss: 1.3076 - val_accuracy: 0.4123

Epoch 00877: val_loss did not improve from 1.30745
Epoch 878/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4006 - val_loss: 1.3068 - val_accuracy: 0.4075

Epoch 00878: val_loss improved from 1.30745 to 1.30679, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 879/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.3994 - val_loss: 1.3068 - val_accuracy: 0.4067

Epoch 00879: val_loss did not improve from 1.30679
Epoch 880/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4017 - val_loss: 1.3076 - val_accuracy: 0.4107

Epoch 00880: val_loss did not improve from 1.30679
Epoch 881/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4019 - val_loss: 1.3093 - val_accuracy: 0.4115

Epoch 00881: val_loss did not improve from 1.30679
Epoch 882/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.3992 - val_loss: 1.3094 - val_accuracy: 0.4091

Epoch 00882: val_loss did not improve from 1.30679
Epoch 883/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4013 - val_loss: 1.3078 - val_accuracy: 0.4091

Epoch 00883: val_loss did not improve from 1.30679
Epoch 884/10000
12/12 - 0s - loss: 1.3024 - accuracy: 0.3986 - val_loss: 1.3079 - val_accuracy: 0.4139

Epoch 00884: val_loss did not improve from 1.30679
Epoch 885/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4001 - val_loss: 1.3098 - val_accuracy: 0.4187

Epoch 00885: val_loss did not improve from 1.30679
Epoch 886/10000
12/12 - 0s - loss: 1.3107 - accuracy: 0.4005 - val_loss: 1.3097 - val_accuracy: 0.4091

Epoch 00886: val_loss did not improve from 1.30679
Epoch 887/10000
12/12 - 0s - loss: 1.3044 - accuracy: 0.3987 - val_loss: 1.3086 - val_accuracy: 0.4051

Epoch 00887: val_loss did not improve from 1.30679
Epoch 888/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.3997 - val_loss: 1.3116 - val_accuracy: 0.4083

Epoch 00888: val_loss did not improve from 1.30679
Epoch 889/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4003 - val_loss: 1.3076 - val_accuracy: 0.4131

Epoch 00889: val_loss did not improve from 1.30679
Epoch 890/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.4032 - val_loss: 1.3084 - val_accuracy: 0.4051

Epoch 00890: val_loss did not improve from 1.30679
Epoch 891/10000
12/12 - 0s - loss: 1.3045 - accuracy: 0.3973 - val_loss: 1.3119 - val_accuracy: 0.4059

Epoch 00891: val_loss did not improve from 1.30679
Epoch 892/10000
12/12 - 0s - loss: 1.3086 - accuracy: 0.4002 - val_loss: 1.3093 - val_accuracy: 0.4139

Epoch 00892: val_loss did not improve from 1.30679
Epoch 893/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4022 - val_loss: 1.3067 - val_accuracy: 0.4123

Epoch 00893: val_loss improved from 1.30679 to 1.30672, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 894/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4005 - val_loss: 1.3089 - val_accuracy: 0.4091

Epoch 00894: val_loss did not improve from 1.30672
Epoch 895/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4010 - val_loss: 1.3066 - val_accuracy: 0.4155

Epoch 00895: val_loss improved from 1.30672 to 1.30661, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 896/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4051 - val_loss: 1.3063 - val_accuracy: 0.4131

Epoch 00896: val_loss improved from 1.30661 to 1.30625, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 897/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4010 - val_loss: 1.3075 - val_accuracy: 0.4123

Epoch 00897: val_loss did not improve from 1.30625
Epoch 898/10000
12/12 - 0s - loss: 1.3030 - accuracy: 0.4023 - val_loss: 1.3091 - val_accuracy: 0.4115

Epoch 00898: val_loss did not improve from 1.30625
Epoch 899/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4001 - val_loss: 1.3067 - val_accuracy: 0.4147

Epoch 00899: val_loss did not improve from 1.30625
Epoch 900/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4041 - val_loss: 1.3059 - val_accuracy: 0.4139

Epoch 00900: val_loss improved from 1.30625 to 1.30590, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 901/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4013 - val_loss: 1.3084 - val_accuracy: 0.4107

Epoch 00901: val_loss did not improve from 1.30590
Epoch 902/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4020 - val_loss: 1.3071 - val_accuracy: 0.4091

Epoch 00902: val_loss did not improve from 1.30590
Epoch 903/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4025 - val_loss: 1.3072 - val_accuracy: 0.4059

Epoch 00903: val_loss did not improve from 1.30590
Epoch 904/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4016 - val_loss: 1.3071 - val_accuracy: 0.4107

Epoch 00904: val_loss did not improve from 1.30590
Epoch 905/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4044 - val_loss: 1.3099 - val_accuracy: 0.4123

Epoch 00905: val_loss did not improve from 1.30590
Epoch 906/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4057 - val_loss: 1.3110 - val_accuracy: 0.4075

Epoch 00906: val_loss did not improve from 1.30590
Epoch 907/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.4015 - val_loss: 1.3087 - val_accuracy: 0.4131

Epoch 00907: val_loss did not improve from 1.30590
Epoch 908/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4010 - val_loss: 1.3088 - val_accuracy: 0.4147

Epoch 00908: val_loss did not improve from 1.30590
Epoch 909/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.3987 - val_loss: 1.3124 - val_accuracy: 0.4051

Epoch 00909: val_loss did not improve from 1.30590
Epoch 910/10000
12/12 - 0s - loss: 1.3033 - accuracy: 0.4045 - val_loss: 1.3060 - val_accuracy: 0.4147

Epoch 00910: val_loss did not improve from 1.30590
Epoch 911/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4065 - val_loss: 1.3074 - val_accuracy: 0.4107

Epoch 00911: val_loss did not improve from 1.30590
Epoch 912/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4015 - val_loss: 1.3083 - val_accuracy: 0.4107

Epoch 00912: val_loss did not improve from 1.30590
Epoch 913/10000
12/12 - 0s - loss: 1.3040 - accuracy: 0.4021 - val_loss: 1.3064 - val_accuracy: 0.4091

Epoch 00913: val_loss did not improve from 1.30590
Epoch 914/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4001 - val_loss: 1.3087 - val_accuracy: 0.4107

Epoch 00914: val_loss did not improve from 1.30590
Epoch 915/10000
12/12 - 0s - loss: 1.3021 - accuracy: 0.4032 - val_loss: 1.3107 - val_accuracy: 0.4051

Epoch 00915: val_loss did not improve from 1.30590
Epoch 916/10000
12/12 - 0s - loss: 1.3055 - accuracy: 0.4060 - val_loss: 1.3114 - val_accuracy: 0.4171

Epoch 00916: val_loss did not improve from 1.30590
Epoch 917/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4047 - val_loss: 1.3067 - val_accuracy: 0.4139

Epoch 00917: val_loss did not improve from 1.30590
Epoch 918/10000
12/12 - 0s - loss: 1.3050 - accuracy: 0.4042 - val_loss: 1.3149 - val_accuracy: 0.4035

Epoch 00918: val_loss did not improve from 1.30590
Epoch 919/10000
12/12 - 0s - loss: 1.3038 - accuracy: 0.4032 - val_loss: 1.3067 - val_accuracy: 0.4115

Epoch 00919: val_loss did not improve from 1.30590
Epoch 920/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4003 - val_loss: 1.3068 - val_accuracy: 0.4107

Epoch 00920: val_loss did not improve from 1.30590
Epoch 921/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4000 - val_loss: 1.3056 - val_accuracy: 0.4155

Epoch 00921: val_loss improved from 1.30590 to 1.30557, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 922/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4006 - val_loss: 1.3086 - val_accuracy: 0.4131

Epoch 00922: val_loss did not improve from 1.30557
Epoch 923/10000
12/12 - 0s - loss: 1.3020 - accuracy: 0.4001 - val_loss: 1.3074 - val_accuracy: 0.4067

Epoch 00923: val_loss did not improve from 1.30557
Epoch 924/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4038 - val_loss: 1.3113 - val_accuracy: 0.4091

Epoch 00924: val_loss did not improve from 1.30557
Epoch 925/10000
12/12 - 0s - loss: 1.3035 - accuracy: 0.4032 - val_loss: 1.3057 - val_accuracy: 0.4187

Epoch 00925: val_loss did not improve from 1.30557
Epoch 926/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.3999 - val_loss: 1.3092 - val_accuracy: 0.4123

Epoch 00926: val_loss did not improve from 1.30557
Epoch 927/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4037 - val_loss: 1.3062 - val_accuracy: 0.4163

Epoch 00927: val_loss did not improve from 1.30557
Epoch 928/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.3981 - val_loss: 1.3066 - val_accuracy: 0.4147

Epoch 00928: val_loss did not improve from 1.30557
Epoch 929/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.3996 - val_loss: 1.3080 - val_accuracy: 0.4099

Epoch 00929: val_loss did not improve from 1.30557
Epoch 930/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.3986 - val_loss: 1.3046 - val_accuracy: 0.4123

Epoch 00930: val_loss improved from 1.30557 to 1.30455, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 931/10000
12/12 - 0s - loss: 1.3046 - accuracy: 0.3993 - val_loss: 1.3084 - val_accuracy: 0.4091

Epoch 00931: val_loss did not improve from 1.30455
Epoch 932/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4019 - val_loss: 1.3042 - val_accuracy: 0.4131

Epoch 00932: val_loss improved from 1.30455 to 1.30418, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 933/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.3997 - val_loss: 1.3054 - val_accuracy: 0.4195

Epoch 00933: val_loss did not improve from 1.30418
Epoch 934/10000
12/12 - 0s - loss: 1.3036 - accuracy: 0.3972 - val_loss: 1.3049 - val_accuracy: 0.4115

Epoch 00934: val_loss did not improve from 1.30418
Epoch 935/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4027 - val_loss: 1.3057 - val_accuracy: 0.4115

Epoch 00935: val_loss did not improve from 1.30418
Epoch 936/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.4002 - val_loss: 1.3060 - val_accuracy: 0.4219

Epoch 00936: val_loss did not improve from 1.30418
Epoch 937/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4024 - val_loss: 1.3058 - val_accuracy: 0.4203

Epoch 00937: val_loss did not improve from 1.30418
Epoch 938/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.3995 - val_loss: 1.3077 - val_accuracy: 0.4123

Epoch 00938: val_loss did not improve from 1.30418
Epoch 939/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4031 - val_loss: 1.3061 - val_accuracy: 0.4163

Epoch 00939: val_loss did not improve from 1.30418
Epoch 940/10000
12/12 - 0s - loss: 1.3032 - accuracy: 0.4013 - val_loss: 1.3089 - val_accuracy: 0.4179

Epoch 00940: val_loss did not improve from 1.30418
Epoch 941/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4022 - val_loss: 1.3060 - val_accuracy: 0.4139

Epoch 00941: val_loss did not improve from 1.30418
Epoch 942/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4031 - val_loss: 1.3080 - val_accuracy: 0.4091

Epoch 00942: val_loss did not improve from 1.30418
Epoch 943/10000
12/12 - 0s - loss: 1.3057 - accuracy: 0.4029 - val_loss: 1.3164 - val_accuracy: 0.4091

Epoch 00943: val_loss did not improve from 1.30418
Epoch 944/10000
12/12 - 0s - loss: 1.3054 - accuracy: 0.3984 - val_loss: 1.3063 - val_accuracy: 0.4195

Epoch 00944: val_loss did not improve from 1.30418
Epoch 945/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4016 - val_loss: 1.3077 - val_accuracy: 0.4219

Epoch 00945: val_loss did not improve from 1.30418
Epoch 946/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4040 - val_loss: 1.3081 - val_accuracy: 0.4226

Epoch 00946: val_loss did not improve from 1.30418
Epoch 947/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4049 - val_loss: 1.3078 - val_accuracy: 0.4179

Epoch 00947: val_loss did not improve from 1.30418
Epoch 948/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4022 - val_loss: 1.3075 - val_accuracy: 0.4219

Epoch 00948: val_loss did not improve from 1.30418
Epoch 949/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4013 - val_loss: 1.3065 - val_accuracy: 0.4123

Epoch 00949: val_loss did not improve from 1.30418
Epoch 950/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.3991 - val_loss: 1.3073 - val_accuracy: 0.4139

Epoch 00950: val_loss did not improve from 1.30418
Epoch 951/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4004 - val_loss: 1.3075 - val_accuracy: 0.4187

Epoch 00951: val_loss did not improve from 1.30418
Epoch 952/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.3993 - val_loss: 1.3099 - val_accuracy: 0.4051

Epoch 00952: val_loss did not improve from 1.30418
Epoch 953/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4013 - val_loss: 1.3053 - val_accuracy: 0.4179

Epoch 00953: val_loss did not improve from 1.30418
Epoch 954/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.3985 - val_loss: 1.3060 - val_accuracy: 0.4179

Epoch 00954: val_loss did not improve from 1.30418
Epoch 955/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4014 - val_loss: 1.3062 - val_accuracy: 0.4211

Epoch 00955: val_loss did not improve from 1.30418
Epoch 956/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4024 - val_loss: 1.3086 - val_accuracy: 0.4123

Epoch 00956: val_loss did not improve from 1.30418
Epoch 957/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4044 - val_loss: 1.3059 - val_accuracy: 0.4195

Epoch 00957: val_loss did not improve from 1.30418
Epoch 958/10000
12/12 - 0s - loss: 1.2997 - accuracy: 0.4032 - val_loss: 1.3073 - val_accuracy: 0.4155

Epoch 00958: val_loss did not improve from 1.30418
Epoch 959/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4033 - val_loss: 1.3059 - val_accuracy: 0.4123

Epoch 00959: val_loss did not improve from 1.30418
Epoch 960/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4033 - val_loss: 1.3043 - val_accuracy: 0.4115

Epoch 00960: val_loss did not improve from 1.30418
Epoch 961/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4024 - val_loss: 1.3074 - val_accuracy: 0.4171

Epoch 00961: val_loss did not improve from 1.30418
Epoch 962/10000
12/12 - 0s - loss: 1.3018 - accuracy: 0.4032 - val_loss: 1.3048 - val_accuracy: 0.4171

Epoch 00962: val_loss did not improve from 1.30418
Epoch 963/10000
12/12 - 0s - loss: 1.3000 - accuracy: 0.4046 - val_loss: 1.3066 - val_accuracy: 0.4131

Epoch 00963: val_loss did not improve from 1.30418
Epoch 964/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4051 - val_loss: 1.3051 - val_accuracy: 0.4115

Epoch 00964: val_loss did not improve from 1.30418
Epoch 965/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4013 - val_loss: 1.3054 - val_accuracy: 0.4171

Epoch 00965: val_loss did not improve from 1.30418
Epoch 966/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4002 - val_loss: 1.3075 - val_accuracy: 0.4083

Epoch 00966: val_loss did not improve from 1.30418
Epoch 967/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4032 - val_loss: 1.3055 - val_accuracy: 0.4171

Epoch 00967: val_loss did not improve from 1.30418
Epoch 968/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4038 - val_loss: 1.3046 - val_accuracy: 0.4179

Epoch 00968: val_loss did not improve from 1.30418
Epoch 969/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4047 - val_loss: 1.3037 - val_accuracy: 0.4155

Epoch 00969: val_loss improved from 1.30418 to 1.30370, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 970/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4028 - val_loss: 1.3064 - val_accuracy: 0.4067

Epoch 00970: val_loss did not improve from 1.30370
Epoch 971/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4032 - val_loss: 1.3097 - val_accuracy: 0.4171

Epoch 00971: val_loss did not improve from 1.30370
Epoch 972/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4004 - val_loss: 1.3065 - val_accuracy: 0.4139

Epoch 00972: val_loss did not improve from 1.30370
Epoch 973/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4003 - val_loss: 1.3042 - val_accuracy: 0.4179

Epoch 00973: val_loss did not improve from 1.30370
Epoch 974/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4040 - val_loss: 1.3040 - val_accuracy: 0.4179

Epoch 00974: val_loss did not improve from 1.30370
Epoch 975/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4018 - val_loss: 1.3093 - val_accuracy: 0.4099

Epoch 00975: val_loss did not improve from 1.30370
Epoch 976/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.3993 - val_loss: 1.3067 - val_accuracy: 0.4155

Epoch 00976: val_loss did not improve from 1.30370
Epoch 977/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4036 - val_loss: 1.3068 - val_accuracy: 0.4179

Epoch 00977: val_loss did not improve from 1.30370
Epoch 978/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.4040 - val_loss: 1.3069 - val_accuracy: 0.4179

Epoch 00978: val_loss did not improve from 1.30370
Epoch 979/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4030 - val_loss: 1.3064 - val_accuracy: 0.4147

Epoch 00979: val_loss did not improve from 1.30370
Epoch 980/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.3978 - val_loss: 1.3087 - val_accuracy: 0.4091

Epoch 00980: val_loss did not improve from 1.30370
Epoch 981/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.3951 - val_loss: 1.3062 - val_accuracy: 0.4115

Epoch 00981: val_loss did not improve from 1.30370
Epoch 982/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4015 - val_loss: 1.3037 - val_accuracy: 0.4274

Epoch 00982: val_loss did not improve from 1.30370
Epoch 983/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4035 - val_loss: 1.3043 - val_accuracy: 0.4219

Epoch 00983: val_loss did not improve from 1.30370
Epoch 984/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.3988 - val_loss: 1.3069 - val_accuracy: 0.4123

Epoch 00984: val_loss did not improve from 1.30370
Epoch 985/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4005 - val_loss: 1.3038 - val_accuracy: 0.4226

Epoch 00985: val_loss did not improve from 1.30370
Epoch 986/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4016 - val_loss: 1.3053 - val_accuracy: 0.4195

Epoch 00986: val_loss did not improve from 1.30370
Epoch 987/10000
12/12 - 0s - loss: 1.3004 - accuracy: 0.3994 - val_loss: 1.3063 - val_accuracy: 0.4163

Epoch 00987: val_loss did not improve from 1.30370
Epoch 988/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4027 - val_loss: 1.3068 - val_accuracy: 0.4123

Epoch 00988: val_loss did not improve from 1.30370
Epoch 989/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4041 - val_loss: 1.3056 - val_accuracy: 0.4179

Epoch 00989: val_loss did not improve from 1.30370
Epoch 990/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4027 - val_loss: 1.3076 - val_accuracy: 0.4242

Epoch 00990: val_loss did not improve from 1.30370
Epoch 991/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4043 - val_loss: 1.3048 - val_accuracy: 0.4234

Epoch 00991: val_loss did not improve from 1.30370
Epoch 992/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4040 - val_loss: 1.3068 - val_accuracy: 0.4211

Epoch 00992: val_loss did not improve from 1.30370
Epoch 993/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4016 - val_loss: 1.3070 - val_accuracy: 0.4171

Epoch 00993: val_loss did not improve from 1.30370
Epoch 994/10000
12/12 - 0s - loss: 1.3001 - accuracy: 0.4027 - val_loss: 1.3042 - val_accuracy: 0.4195

Epoch 00994: val_loss did not improve from 1.30370
Epoch 995/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4004 - val_loss: 1.3072 - val_accuracy: 0.4123

Epoch 00995: val_loss did not improve from 1.30370
Epoch 996/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4003 - val_loss: 1.3053 - val_accuracy: 0.4211

Epoch 00996: val_loss did not improve from 1.30370
Epoch 997/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4041 - val_loss: 1.3054 - val_accuracy: 0.4179

Epoch 00997: val_loss did not improve from 1.30370
Epoch 998/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4024 - val_loss: 1.3047 - val_accuracy: 0.4219

Epoch 00998: val_loss did not improve from 1.30370
Epoch 999/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4055 - val_loss: 1.3039 - val_accuracy: 0.4211

Epoch 00999: val_loss did not improve from 1.30370
Epoch 1000/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4040 - val_loss: 1.3038 - val_accuracy: 0.4131

Epoch 01000: val_loss did not improve from 1.30370
Epoch 1001/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.3993 - val_loss: 1.3048 - val_accuracy: 0.4123

Epoch 01001: val_loss did not improve from 1.30370
Epoch 1002/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4022 - val_loss: 1.3033 - val_accuracy: 0.4171

Epoch 01002: val_loss improved from 1.30370 to 1.30332, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1003/10000
12/12 - 0s - loss: 1.3008 - accuracy: 0.4011 - val_loss: 1.3044 - val_accuracy: 0.4226

Epoch 01003: val_loss did not improve from 1.30332
Epoch 1004/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4036 - val_loss: 1.3058 - val_accuracy: 0.4155

Epoch 01004: val_loss did not improve from 1.30332
Epoch 1005/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4024 - val_loss: 1.3044 - val_accuracy: 0.4171

Epoch 01005: val_loss did not improve from 1.30332
Epoch 1006/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4052 - val_loss: 1.3040 - val_accuracy: 0.4139

Epoch 01006: val_loss did not improve from 1.30332
Epoch 1007/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4047 - val_loss: 1.3047 - val_accuracy: 0.4163

Epoch 01007: val_loss did not improve from 1.30332
Epoch 1008/10000
12/12 - 0s - loss: 1.3010 - accuracy: 0.4034 - val_loss: 1.3082 - val_accuracy: 0.4115

Epoch 01008: val_loss did not improve from 1.30332
Epoch 1009/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4000 - val_loss: 1.3065 - val_accuracy: 0.4171

Epoch 01009: val_loss did not improve from 1.30332
Epoch 1010/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4047 - val_loss: 1.3050 - val_accuracy: 0.4147

Epoch 01010: val_loss did not improve from 1.30332
Epoch 1011/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4010 - val_loss: 1.3055 - val_accuracy: 0.4147

Epoch 01011: val_loss did not improve from 1.30332
Epoch 1012/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4020 - val_loss: 1.3054 - val_accuracy: 0.4219

Epoch 01012: val_loss did not improve from 1.30332
Epoch 1013/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4027 - val_loss: 1.3048 - val_accuracy: 0.4139

Epoch 01013: val_loss did not improve from 1.30332
Epoch 1014/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4054 - val_loss: 1.3043 - val_accuracy: 0.4203

Epoch 01014: val_loss did not improve from 1.30332
Epoch 1015/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4045 - val_loss: 1.3057 - val_accuracy: 0.4195

Epoch 01015: val_loss did not improve from 1.30332
Epoch 1016/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4016 - val_loss: 1.3033 - val_accuracy: 0.4115

Epoch 01016: val_loss improved from 1.30332 to 1.30332, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1017/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4016 - val_loss: 1.3036 - val_accuracy: 0.4147

Epoch 01017: val_loss did not improve from 1.30332
Epoch 1018/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.3994 - val_loss: 1.3034 - val_accuracy: 0.4211

Epoch 01018: val_loss did not improve from 1.30332
Epoch 1019/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4002 - val_loss: 1.3031 - val_accuracy: 0.4203

Epoch 01019: val_loss improved from 1.30332 to 1.30313, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1020/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4036 - val_loss: 1.3027 - val_accuracy: 0.4179

Epoch 01020: val_loss improved from 1.30313 to 1.30269, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1021/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4016 - val_loss: 1.3091 - val_accuracy: 0.4099

Epoch 01021: val_loss did not improve from 1.30269
Epoch 1022/10000
12/12 - 0s - loss: 1.3009 - accuracy: 0.4031 - val_loss: 1.3042 - val_accuracy: 0.4187

Epoch 01022: val_loss did not improve from 1.30269
Epoch 1023/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4014 - val_loss: 1.3027 - val_accuracy: 0.4179

Epoch 01023: val_loss did not improve from 1.30269
Epoch 1024/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4032 - val_loss: 1.3022 - val_accuracy: 0.4226

Epoch 01024: val_loss improved from 1.30269 to 1.30216, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1025/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4019 - val_loss: 1.3033 - val_accuracy: 0.4203

Epoch 01025: val_loss did not improve from 1.30216
Epoch 1026/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4025 - val_loss: 1.3048 - val_accuracy: 0.4195

Epoch 01026: val_loss did not improve from 1.30216
Epoch 1027/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4042 - val_loss: 1.3047 - val_accuracy: 0.4155

Epoch 01027: val_loss did not improve from 1.30216
Epoch 1028/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4047 - val_loss: 1.3044 - val_accuracy: 0.4226

Epoch 01028: val_loss did not improve from 1.30216
Epoch 1029/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4024 - val_loss: 1.3073 - val_accuracy: 0.4147

Epoch 01029: val_loss did not improve from 1.30216
Epoch 1030/10000
12/12 - 0s - loss: 1.3026 - accuracy: 0.4024 - val_loss: 1.3056 - val_accuracy: 0.4147

Epoch 01030: val_loss did not improve from 1.30216
Epoch 1031/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4016 - val_loss: 1.3069 - val_accuracy: 0.4147

Epoch 01031: val_loss did not improve from 1.30216
Epoch 1032/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4039 - val_loss: 1.3072 - val_accuracy: 0.4219

Epoch 01032: val_loss did not improve from 1.30216
Epoch 1033/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4009 - val_loss: 1.3038 - val_accuracy: 0.4139

Epoch 01033: val_loss did not improve from 1.30216
Epoch 1034/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4032 - val_loss: 1.3097 - val_accuracy: 0.4195

Epoch 01034: val_loss did not improve from 1.30216
Epoch 1035/10000
12/12 - 0s - loss: 1.3027 - accuracy: 0.4030 - val_loss: 1.3063 - val_accuracy: 0.4219

Epoch 01035: val_loss did not improve from 1.30216
Epoch 1036/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4031 - val_loss: 1.3053 - val_accuracy: 0.4139

Epoch 01036: val_loss did not improve from 1.30216
Epoch 1037/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4016 - val_loss: 1.3054 - val_accuracy: 0.4155

Epoch 01037: val_loss did not improve from 1.30216
Epoch 1038/10000
12/12 - 0s - loss: 1.2992 - accuracy: 0.4007 - val_loss: 1.3062 - val_accuracy: 0.4163

Epoch 01038: val_loss did not improve from 1.30216
Epoch 1039/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4040 - val_loss: 1.3052 - val_accuracy: 0.4187

Epoch 01039: val_loss did not improve from 1.30216
Epoch 1040/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4002 - val_loss: 1.3054 - val_accuracy: 0.4147

Epoch 01040: val_loss did not improve from 1.30216
Epoch 1041/10000
12/12 - 0s - loss: 1.2987 - accuracy: 0.4042 - val_loss: 1.3036 - val_accuracy: 0.4091

Epoch 01041: val_loss did not improve from 1.30216
Epoch 1042/10000
12/12 - 0s - loss: 1.3023 - accuracy: 0.4005 - val_loss: 1.3049 - val_accuracy: 0.4171

Epoch 01042: val_loss did not improve from 1.30216
Epoch 1043/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4035 - val_loss: 1.3050 - val_accuracy: 0.4187

Epoch 01043: val_loss did not improve from 1.30216
Epoch 1044/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.3998 - val_loss: 1.3067 - val_accuracy: 0.4115

Epoch 01044: val_loss did not improve from 1.30216
Epoch 1045/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4023 - val_loss: 1.3069 - val_accuracy: 0.4043

Epoch 01045: val_loss did not improve from 1.30216
Epoch 1046/10000
12/12 - 0s - loss: 1.2993 - accuracy: 0.4006 - val_loss: 1.3039 - val_accuracy: 0.4211

Epoch 01046: val_loss did not improve from 1.30216
Epoch 1047/10000
12/12 - 0s - loss: 1.2999 - accuracy: 0.4035 - val_loss: 1.3130 - val_accuracy: 0.4155

Epoch 01047: val_loss did not improve from 1.30216
Epoch 1048/10000
12/12 - 0s - loss: 1.3015 - accuracy: 0.4007 - val_loss: 1.3063 - val_accuracy: 0.4155

Epoch 01048: val_loss did not improve from 1.30216
Epoch 1049/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4002 - val_loss: 1.3047 - val_accuracy: 0.4131

Epoch 01049: val_loss did not improve from 1.30216
Epoch 1050/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4060 - val_loss: 1.3061 - val_accuracy: 0.4163

Epoch 01050: val_loss did not improve from 1.30216
Epoch 1051/10000
12/12 - 0s - loss: 1.3014 - accuracy: 0.4026 - val_loss: 1.3063 - val_accuracy: 0.4219

Epoch 01051: val_loss did not improve from 1.30216
Epoch 1052/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4018 - val_loss: 1.3045 - val_accuracy: 0.4171

Epoch 01052: val_loss did not improve from 1.30216
Epoch 1053/10000
12/12 - 0s - loss: 1.3022 - accuracy: 0.3994 - val_loss: 1.3121 - val_accuracy: 0.4139

Epoch 01053: val_loss did not improve from 1.30216
Epoch 1054/10000
12/12 - 0s - loss: 1.3037 - accuracy: 0.4050 - val_loss: 1.3020 - val_accuracy: 0.4219

Epoch 01054: val_loss improved from 1.30216 to 1.30204, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1055/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4020 - val_loss: 1.3051 - val_accuracy: 0.4250

Epoch 01055: val_loss did not improve from 1.30204
Epoch 1056/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4013 - val_loss: 1.3040 - val_accuracy: 0.4203

Epoch 01056: val_loss did not improve from 1.30204
Epoch 1057/10000
12/12 - 0s - loss: 1.2977 - accuracy: 0.4028 - val_loss: 1.3048 - val_accuracy: 0.4211

Epoch 01057: val_loss did not improve from 1.30204
Epoch 1058/10000
12/12 - 0s - loss: 1.2988 - accuracy: 0.4014 - val_loss: 1.3017 - val_accuracy: 0.4226

Epoch 01058: val_loss improved from 1.30204 to 1.30166, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1059/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4032 - val_loss: 1.3016 - val_accuracy: 0.4226

Epoch 01059: val_loss improved from 1.30166 to 1.30161, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1060/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4055 - val_loss: 1.3036 - val_accuracy: 0.4211

Epoch 01060: val_loss did not improve from 1.30161
Epoch 1061/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4023 - val_loss: 1.3027 - val_accuracy: 0.4211

Epoch 01061: val_loss did not improve from 1.30161
Epoch 1062/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4006 - val_loss: 1.3060 - val_accuracy: 0.4115

Epoch 01062: val_loss did not improve from 1.30161
Epoch 1063/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4038 - val_loss: 1.3054 - val_accuracy: 0.4203

Epoch 01063: val_loss did not improve from 1.30161
Epoch 1064/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4056 - val_loss: 1.3026 - val_accuracy: 0.4219

Epoch 01064: val_loss did not improve from 1.30161
Epoch 1065/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4010 - val_loss: 1.3037 - val_accuracy: 0.4203

Epoch 01065: val_loss did not improve from 1.30161
Epoch 1066/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4040 - val_loss: 1.3040 - val_accuracy: 0.4179

Epoch 01066: val_loss did not improve from 1.30161
Epoch 1067/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4040 - val_loss: 1.3025 - val_accuracy: 0.4250

Epoch 01067: val_loss did not improve from 1.30161
Epoch 1068/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4040 - val_loss: 1.3031 - val_accuracy: 0.4250

Epoch 01068: val_loss did not improve from 1.30161
Epoch 1069/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4030 - val_loss: 1.3072 - val_accuracy: 0.4131

Epoch 01069: val_loss did not improve from 1.30161
Epoch 1070/10000
12/12 - 0s - loss: 1.3007 - accuracy: 0.4067 - val_loss: 1.3041 - val_accuracy: 0.4179

Epoch 01070: val_loss did not improve from 1.30161
Epoch 1071/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4029 - val_loss: 1.3032 - val_accuracy: 0.4219

Epoch 01071: val_loss did not improve from 1.30161
Epoch 1072/10000
12/12 - 0s - loss: 1.2989 - accuracy: 0.4050 - val_loss: 1.3020 - val_accuracy: 0.4274

Epoch 01072: val_loss did not improve from 1.30161
Epoch 1073/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.3985 - val_loss: 1.3040 - val_accuracy: 0.4171

Epoch 01073: val_loss did not improve from 1.30161
Epoch 1074/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4060 - val_loss: 1.3033 - val_accuracy: 0.4171

Epoch 01074: val_loss did not improve from 1.30161
Epoch 1075/10000
12/12 - 0s - loss: 1.2968 - accuracy: 0.4051 - val_loss: 1.3014 - val_accuracy: 0.4195

Epoch 01075: val_loss improved from 1.30161 to 1.30143, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1076/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4032 - val_loss: 1.3015 - val_accuracy: 0.4219

Epoch 01076: val_loss did not improve from 1.30143
Epoch 1077/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4040 - val_loss: 1.3028 - val_accuracy: 0.4266

Epoch 01077: val_loss did not improve from 1.30143
Epoch 1078/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4026 - val_loss: 1.3055 - val_accuracy: 0.4258

Epoch 01078: val_loss did not improve from 1.30143
Epoch 1079/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4068 - val_loss: 1.3015 - val_accuracy: 0.4282

Epoch 01079: val_loss did not improve from 1.30143
Epoch 1080/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4029 - val_loss: 1.3039 - val_accuracy: 0.4250

Epoch 01080: val_loss did not improve from 1.30143
Epoch 1081/10000
12/12 - 0s - loss: 1.2995 - accuracy: 0.4012 - val_loss: 1.3065 - val_accuracy: 0.4187

Epoch 01081: val_loss did not improve from 1.30143
Epoch 1082/10000
12/12 - 0s - loss: 1.3028 - accuracy: 0.4015 - val_loss: 1.3015 - val_accuracy: 0.4187

Epoch 01082: val_loss did not improve from 1.30143
Epoch 1083/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4030 - val_loss: 1.3022 - val_accuracy: 0.4187

Epoch 01083: val_loss did not improve from 1.30143
Epoch 1084/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4014 - val_loss: 1.3018 - val_accuracy: 0.4266

Epoch 01084: val_loss did not improve from 1.30143
Epoch 1085/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4011 - val_loss: 1.3025 - val_accuracy: 0.4234

Epoch 01085: val_loss did not improve from 1.30143
Epoch 1086/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4084 - val_loss: 1.3014 - val_accuracy: 0.4242

Epoch 01086: val_loss improved from 1.30143 to 1.30141, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1087/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4016 - val_loss: 1.3027 - val_accuracy: 0.4163

Epoch 01087: val_loss did not improve from 1.30141
Epoch 1088/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4019 - val_loss: 1.3019 - val_accuracy: 0.4250

Epoch 01088: val_loss did not improve from 1.30141
Epoch 1089/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4009 - val_loss: 1.3021 - val_accuracy: 0.4211

Epoch 01089: val_loss did not improve from 1.30141
Epoch 1090/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4034 - val_loss: 1.3015 - val_accuracy: 0.4203

Epoch 01090: val_loss did not improve from 1.30141
Epoch 1091/10000
12/12 - 0s - loss: 1.2979 - accuracy: 0.4038 - val_loss: 1.3005 - val_accuracy: 0.4234

Epoch 01091: val_loss improved from 1.30141 to 1.30049, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1092/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4026 - val_loss: 1.3023 - val_accuracy: 0.4187

Epoch 01092: val_loss did not improve from 1.30049
Epoch 1093/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4062 - val_loss: 1.3020 - val_accuracy: 0.4211

Epoch 01093: val_loss did not improve from 1.30049
Epoch 1094/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4046 - val_loss: 1.3036 - val_accuracy: 0.4234

Epoch 01094: val_loss did not improve from 1.30049
Epoch 1095/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.3978 - val_loss: 1.3050 - val_accuracy: 0.4179

Epoch 01095: val_loss did not improve from 1.30049
Epoch 1096/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4047 - val_loss: 1.3061 - val_accuracy: 0.4282

Epoch 01096: val_loss did not improve from 1.30049
Epoch 1097/10000
12/12 - 0s - loss: 1.3029 - accuracy: 0.3953 - val_loss: 1.3039 - val_accuracy: 0.4139

Epoch 01097: val_loss did not improve from 1.30049
Epoch 1098/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4004 - val_loss: 1.3028 - val_accuracy: 0.4234

Epoch 01098: val_loss did not improve from 1.30049
Epoch 1099/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4061 - val_loss: 1.3016 - val_accuracy: 0.4203

Epoch 01099: val_loss did not improve from 1.30049
Epoch 1100/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4036 - val_loss: 1.3008 - val_accuracy: 0.4226

Epoch 01100: val_loss did not improve from 1.30049
Epoch 1101/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4029 - val_loss: 1.3033 - val_accuracy: 0.4203

Epoch 01101: val_loss did not improve from 1.30049
Epoch 1102/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4031 - val_loss: 1.3021 - val_accuracy: 0.4203

Epoch 01102: val_loss did not improve from 1.30049
Epoch 1103/10000
12/12 - 0s - loss: 1.3019 - accuracy: 0.4000 - val_loss: 1.3032 - val_accuracy: 0.4226

Epoch 01103: val_loss did not improve from 1.30049
Epoch 1104/10000
12/12 - 0s - loss: 1.2983 - accuracy: 0.4017 - val_loss: 1.3064 - val_accuracy: 0.4171

Epoch 01104: val_loss did not improve from 1.30049
Epoch 1105/10000
12/12 - 0s - loss: 1.3011 - accuracy: 0.4031 - val_loss: 1.3008 - val_accuracy: 0.4195

Epoch 01105: val_loss did not improve from 1.30049
Epoch 1106/10000
12/12 - 0s - loss: 1.2985 - accuracy: 0.4037 - val_loss: 1.3051 - val_accuracy: 0.4187

Epoch 01106: val_loss did not improve from 1.30049
Epoch 1107/10000
12/12 - 0s - loss: 1.2996 - accuracy: 0.4012 - val_loss: 1.3037 - val_accuracy: 0.4195

Epoch 01107: val_loss did not improve from 1.30049
Epoch 1108/10000
12/12 - 0s - loss: 1.2991 - accuracy: 0.4033 - val_loss: 1.3028 - val_accuracy: 0.4242

Epoch 01108: val_loss did not improve from 1.30049
Epoch 1109/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4007 - val_loss: 1.3041 - val_accuracy: 0.4147

Epoch 01109: val_loss did not improve from 1.30049
Epoch 1110/10000
12/12 - 0s - loss: 1.2971 - accuracy: 0.4055 - val_loss: 1.3016 - val_accuracy: 0.4203

Epoch 01110: val_loss did not improve from 1.30049
Epoch 1111/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4012 - val_loss: 1.3027 - val_accuracy: 0.4187

Epoch 01111: val_loss did not improve from 1.30049
Epoch 1112/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4014 - val_loss: 1.3083 - val_accuracy: 0.4187

Epoch 01112: val_loss did not improve from 1.30049
Epoch 1113/10000
12/12 - 0s - loss: 1.3064 - accuracy: 0.4016 - val_loss: 1.3074 - val_accuracy: 0.4139

Epoch 01113: val_loss did not improve from 1.30049
Epoch 1114/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4022 - val_loss: 1.3017 - val_accuracy: 0.4187

Epoch 01114: val_loss did not improve from 1.30049
Epoch 1115/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4011 - val_loss: 1.3029 - val_accuracy: 0.4211

Epoch 01115: val_loss did not improve from 1.30049
Epoch 1116/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4001 - val_loss: 1.3017 - val_accuracy: 0.4242

Epoch 01116: val_loss did not improve from 1.30049
Epoch 1117/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4045 - val_loss: 1.3015 - val_accuracy: 0.4211

Epoch 01117: val_loss did not improve from 1.30049
Epoch 1118/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4023 - val_loss: 1.3012 - val_accuracy: 0.4195

Epoch 01118: val_loss did not improve from 1.30049
Epoch 1119/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4047 - val_loss: 1.3011 - val_accuracy: 0.4234

Epoch 01119: val_loss did not improve from 1.30049
Epoch 1120/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4032 - val_loss: 1.3065 - val_accuracy: 0.4195

Epoch 01120: val_loss did not improve from 1.30049
Epoch 1121/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4036 - val_loss: 1.3072 - val_accuracy: 0.4155

Epoch 01121: val_loss did not improve from 1.30049
Epoch 1122/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4045 - val_loss: 1.3026 - val_accuracy: 0.4234

Epoch 01122: val_loss did not improve from 1.30049
Epoch 1123/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4043 - val_loss: 1.3029 - val_accuracy: 0.4234

Epoch 01123: val_loss did not improve from 1.30049
Epoch 1124/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4072 - val_loss: 1.3023 - val_accuracy: 0.4195

Epoch 01124: val_loss did not improve from 1.30049
Epoch 1125/10000
12/12 - 0s - loss: 1.2961 - accuracy: 0.4039 - val_loss: 1.3036 - val_accuracy: 0.4155

Epoch 01125: val_loss did not improve from 1.30049
Epoch 1126/10000
12/12 - 0s - loss: 1.2986 - accuracy: 0.4049 - val_loss: 1.3062 - val_accuracy: 0.4179

Epoch 01126: val_loss did not improve from 1.30049
Epoch 1127/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4064 - val_loss: 1.3042 - val_accuracy: 0.4226

Epoch 01127: val_loss did not improve from 1.30049
Epoch 1128/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4071 - val_loss: 1.3024 - val_accuracy: 0.4242

Epoch 01128: val_loss did not improve from 1.30049
Epoch 1129/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4077 - val_loss: 1.3017 - val_accuracy: 0.4155

Epoch 01129: val_loss did not improve from 1.30049
Epoch 1130/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4027 - val_loss: 1.3012 - val_accuracy: 0.4234

Epoch 01130: val_loss did not improve from 1.30049
Epoch 1131/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4043 - val_loss: 1.3030 - val_accuracy: 0.4155

Epoch 01131: val_loss did not improve from 1.30049
Epoch 1132/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4040 - val_loss: 1.3018 - val_accuracy: 0.4226

Epoch 01132: val_loss did not improve from 1.30049
Epoch 1133/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4032 - val_loss: 1.3010 - val_accuracy: 0.4306

Epoch 01133: val_loss did not improve from 1.30049
Epoch 1134/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4022 - val_loss: 1.3009 - val_accuracy: 0.4314

Epoch 01134: val_loss did not improve from 1.30049
Epoch 1135/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4058 - val_loss: 1.3026 - val_accuracy: 0.4195

Epoch 01135: val_loss did not improve from 1.30049
Epoch 1136/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4067 - val_loss: 1.3013 - val_accuracy: 0.4250

Epoch 01136: val_loss did not improve from 1.30049
Epoch 1137/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4010 - val_loss: 1.3011 - val_accuracy: 0.4203

Epoch 01137: val_loss did not improve from 1.30049
Epoch 1138/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4041 - val_loss: 1.3031 - val_accuracy: 0.4163

Epoch 01138: val_loss did not improve from 1.30049
Epoch 1139/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4044 - val_loss: 1.3036 - val_accuracy: 0.4171

Epoch 01139: val_loss did not improve from 1.30049
Epoch 1140/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4057 - val_loss: 1.3020 - val_accuracy: 0.4211

Epoch 01140: val_loss did not improve from 1.30049
Epoch 1141/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4055 - val_loss: 1.3040 - val_accuracy: 0.4250

Epoch 01141: val_loss did not improve from 1.30049
Epoch 1142/10000
12/12 - 0s - loss: 1.3005 - accuracy: 0.4019 - val_loss: 1.3006 - val_accuracy: 0.4203

Epoch 01142: val_loss did not improve from 1.30049
Epoch 1143/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4048 - val_loss: 1.3013 - val_accuracy: 0.4195

Epoch 01143: val_loss did not improve from 1.30049
Epoch 1144/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4041 - val_loss: 1.3020 - val_accuracy: 0.4203

Epoch 01144: val_loss did not improve from 1.30049
Epoch 1145/10000
12/12 - 0s - loss: 1.2974 - accuracy: 0.4065 - val_loss: 1.3006 - val_accuracy: 0.4187

Epoch 01145: val_loss did not improve from 1.30049
Epoch 1146/10000
12/12 - 0s - loss: 1.2981 - accuracy: 0.4032 - val_loss: 1.3009 - val_accuracy: 0.4242

Epoch 01146: val_loss did not improve from 1.30049
Epoch 1147/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4020 - val_loss: 1.3000 - val_accuracy: 0.4234

Epoch 01147: val_loss improved from 1.30049 to 1.30000, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1148/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4078 - val_loss: 1.3017 - val_accuracy: 0.4115

Epoch 01148: val_loss did not improve from 1.30000
Epoch 1149/10000
12/12 - 0s - loss: 1.2973 - accuracy: 0.4030 - val_loss: 1.3004 - val_accuracy: 0.4195

Epoch 01149: val_loss did not improve from 1.30000
Epoch 1150/10000
12/12 - 0s - loss: 1.3002 - accuracy: 0.4003 - val_loss: 1.3034 - val_accuracy: 0.4131

Epoch 01150: val_loss did not improve from 1.30000
Epoch 1151/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4022 - val_loss: 1.3012 - val_accuracy: 0.4171

Epoch 01151: val_loss did not improve from 1.30000
Epoch 1152/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4058 - val_loss: 1.3008 - val_accuracy: 0.4211

Epoch 01152: val_loss did not improve from 1.30000
Epoch 1153/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4066 - val_loss: 1.2996 - val_accuracy: 0.4258

Epoch 01153: val_loss improved from 1.30000 to 1.29965, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1154/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4051 - val_loss: 1.3002 - val_accuracy: 0.4242

Epoch 01154: val_loss did not improve from 1.29965
Epoch 1155/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4003 - val_loss: 1.3015 - val_accuracy: 0.4234

Epoch 01155: val_loss did not improve from 1.29965
Epoch 1156/10000
12/12 - 0s - loss: 1.2972 - accuracy: 0.4059 - val_loss: 1.3018 - val_accuracy: 0.4219

Epoch 01156: val_loss did not improve from 1.29965
Epoch 1157/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4056 - val_loss: 1.3022 - val_accuracy: 0.4179

Epoch 01157: val_loss did not improve from 1.29965
Epoch 1158/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4030 - val_loss: 1.3024 - val_accuracy: 0.4163

Epoch 01158: val_loss did not improve from 1.29965
Epoch 1159/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4055 - val_loss: 1.2996 - val_accuracy: 0.4203

Epoch 01159: val_loss improved from 1.29965 to 1.29962, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1160/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4030 - val_loss: 1.3033 - val_accuracy: 0.4179

Epoch 01160: val_loss did not improve from 1.29962
Epoch 1161/10000
12/12 - 0s - loss: 1.2982 - accuracy: 0.4034 - val_loss: 1.3028 - val_accuracy: 0.4226

Epoch 01161: val_loss did not improve from 1.29962
Epoch 1162/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4047 - val_loss: 1.2994 - val_accuracy: 0.4211

Epoch 01162: val_loss improved from 1.29962 to 1.29942, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1163/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4026 - val_loss: 1.3004 - val_accuracy: 0.4187

Epoch 01163: val_loss did not improve from 1.29942
Epoch 1164/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4039 - val_loss: 1.3017 - val_accuracy: 0.4258

Epoch 01164: val_loss did not improve from 1.29942
Epoch 1165/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4024 - val_loss: 1.3011 - val_accuracy: 0.4203

Epoch 01165: val_loss did not improve from 1.29942
Epoch 1166/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4052 - val_loss: 1.3005 - val_accuracy: 0.4266

Epoch 01166: val_loss did not improve from 1.29942
Epoch 1167/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4061 - val_loss: 1.2998 - val_accuracy: 0.4242

Epoch 01167: val_loss did not improve from 1.29942
Epoch 1168/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4071 - val_loss: 1.3015 - val_accuracy: 0.4258

Epoch 01168: val_loss did not improve from 1.29942
Epoch 1169/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4078 - val_loss: 1.3016 - val_accuracy: 0.4187

Epoch 01169: val_loss did not improve from 1.29942
Epoch 1170/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4064 - val_loss: 1.3007 - val_accuracy: 0.4219

Epoch 01170: val_loss did not improve from 1.29942
Epoch 1171/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4058 - val_loss: 1.2986 - val_accuracy: 0.4226

Epoch 01171: val_loss improved from 1.29942 to 1.29855, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1172/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4056 - val_loss: 1.2992 - val_accuracy: 0.4250

Epoch 01172: val_loss did not improve from 1.29855
Epoch 1173/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4043 - val_loss: 1.3002 - val_accuracy: 0.4226

Epoch 01173: val_loss did not improve from 1.29855
Epoch 1174/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4040 - val_loss: 1.2994 - val_accuracy: 0.4195

Epoch 01174: val_loss did not improve from 1.29855
Epoch 1175/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4042 - val_loss: 1.3012 - val_accuracy: 0.4290

Epoch 01175: val_loss did not improve from 1.29855
Epoch 1176/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4037 - val_loss: 1.3005 - val_accuracy: 0.4226

Epoch 01176: val_loss did not improve from 1.29855
Epoch 1177/10000
12/12 - 0s - loss: 1.2963 - accuracy: 0.4067 - val_loss: 1.2998 - val_accuracy: 0.4258

Epoch 01177: val_loss did not improve from 1.29855
Epoch 1178/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4040 - val_loss: 1.3006 - val_accuracy: 0.4163

Epoch 01178: val_loss did not improve from 1.29855
Epoch 1179/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4047 - val_loss: 1.3007 - val_accuracy: 0.4250

Epoch 01179: val_loss did not improve from 1.29855
Epoch 1180/10000
12/12 - 0s - loss: 1.3013 - accuracy: 0.4061 - val_loss: 1.3154 - val_accuracy: 0.4003

Epoch 01180: val_loss did not improve from 1.29855
Epoch 1181/10000
12/12 - 0s - loss: 1.3012 - accuracy: 0.4054 - val_loss: 1.2993 - val_accuracy: 0.4274

Epoch 01181: val_loss did not improve from 1.29855
Epoch 1182/10000
12/12 - 0s - loss: 1.3017 - accuracy: 0.4040 - val_loss: 1.3046 - val_accuracy: 0.4203

Epoch 01182: val_loss did not improve from 1.29855
Epoch 1183/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4023 - val_loss: 1.3012 - val_accuracy: 0.4195

Epoch 01183: val_loss did not improve from 1.29855
Epoch 1184/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4036 - val_loss: 1.3026 - val_accuracy: 0.4187

Epoch 01184: val_loss did not improve from 1.29855
Epoch 1185/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4068 - val_loss: 1.2999 - val_accuracy: 0.4242

Epoch 01185: val_loss did not improve from 1.29855
Epoch 1186/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4067 - val_loss: 1.2997 - val_accuracy: 0.4234

Epoch 01186: val_loss did not improve from 1.29855
Epoch 1187/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4066 - val_loss: 1.3009 - val_accuracy: 0.4211

Epoch 01187: val_loss did not improve from 1.29855
Epoch 1188/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4064 - val_loss: 1.3059 - val_accuracy: 0.4171

Epoch 01188: val_loss did not improve from 1.29855
Epoch 1189/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4062 - val_loss: 1.2992 - val_accuracy: 0.4258

Epoch 01189: val_loss did not improve from 1.29855
Epoch 1190/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4001 - val_loss: 1.3002 - val_accuracy: 0.4226

Epoch 01190: val_loss did not improve from 1.29855
Epoch 1191/10000
12/12 - 0s - loss: 1.2966 - accuracy: 0.4040 - val_loss: 1.2998 - val_accuracy: 0.4234

Epoch 01191: val_loss did not improve from 1.29855
Epoch 1192/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4072 - val_loss: 1.3008 - val_accuracy: 0.4195

Epoch 01192: val_loss did not improve from 1.29855
Epoch 1193/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4047 - val_loss: 1.3004 - val_accuracy: 0.4195

Epoch 01193: val_loss did not improve from 1.29855
Epoch 1194/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4068 - val_loss: 1.3017 - val_accuracy: 0.4187

Epoch 01194: val_loss did not improve from 1.29855
Epoch 1195/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4054 - val_loss: 1.3006 - val_accuracy: 0.4226

Epoch 01195: val_loss did not improve from 1.29855
Epoch 1196/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4031 - val_loss: 1.3008 - val_accuracy: 0.4226

Epoch 01196: val_loss did not improve from 1.29855
Epoch 1197/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4069 - val_loss: 1.2999 - val_accuracy: 0.4195

Epoch 01197: val_loss did not improve from 1.29855
Epoch 1198/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4038 - val_loss: 1.2984 - val_accuracy: 0.4250

Epoch 01198: val_loss improved from 1.29855 to 1.29837, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1199/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4052 - val_loss: 1.2982 - val_accuracy: 0.4274

Epoch 01199: val_loss improved from 1.29837 to 1.29815, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1200/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4078 - val_loss: 1.3010 - val_accuracy: 0.4219

Epoch 01200: val_loss did not improve from 1.29815
Epoch 1201/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4070 - val_loss: 1.3037 - val_accuracy: 0.4211

Epoch 01201: val_loss did not improve from 1.29815
Epoch 1202/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4083 - val_loss: 1.2994 - val_accuracy: 0.4234

Epoch 01202: val_loss did not improve from 1.29815
Epoch 1203/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4018 - val_loss: 1.2996 - val_accuracy: 0.4234

Epoch 01203: val_loss did not improve from 1.29815
Epoch 1204/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4047 - val_loss: 1.3008 - val_accuracy: 0.4234

Epoch 01204: val_loss did not improve from 1.29815
Epoch 1205/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4055 - val_loss: 1.2993 - val_accuracy: 0.4171

Epoch 01205: val_loss did not improve from 1.29815
Epoch 1206/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4044 - val_loss: 1.2984 - val_accuracy: 0.4195

Epoch 01206: val_loss did not improve from 1.29815
Epoch 1207/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4053 - val_loss: 1.2987 - val_accuracy: 0.4282

Epoch 01207: val_loss did not improve from 1.29815
Epoch 1208/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4020 - val_loss: 1.3053 - val_accuracy: 0.4099

Epoch 01208: val_loss did not improve from 1.29815
Epoch 1209/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4054 - val_loss: 1.2992 - val_accuracy: 0.4274

Epoch 01209: val_loss did not improve from 1.29815
Epoch 1210/10000
12/12 - 0s - loss: 1.2949 - accuracy: 0.4046 - val_loss: 1.3019 - val_accuracy: 0.4179

Epoch 01210: val_loss did not improve from 1.29815
Epoch 1211/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4039 - val_loss: 1.3012 - val_accuracy: 0.4211

Epoch 01211: val_loss did not improve from 1.29815
Epoch 1212/10000
12/12 - 0s - loss: 1.2950 - accuracy: 0.4040 - val_loss: 1.3035 - val_accuracy: 0.4258

Epoch 01212: val_loss did not improve from 1.29815
Epoch 1213/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4039 - val_loss: 1.3031 - val_accuracy: 0.4219

Epoch 01213: val_loss did not improve from 1.29815
Epoch 1214/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4077 - val_loss: 1.3039 - val_accuracy: 0.4107

Epoch 01214: val_loss did not improve from 1.29815
Epoch 1215/10000
12/12 - 0s - loss: 1.2958 - accuracy: 0.4035 - val_loss: 1.3004 - val_accuracy: 0.4242

Epoch 01215: val_loss did not improve from 1.29815
Epoch 1216/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4043 - val_loss: 1.2986 - val_accuracy: 0.4242

Epoch 01216: val_loss did not improve from 1.29815
Epoch 1217/10000
12/12 - 0s - loss: 1.2962 - accuracy: 0.4056 - val_loss: 1.2996 - val_accuracy: 0.4179

Epoch 01217: val_loss did not improve from 1.29815
Epoch 1218/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4050 - val_loss: 1.3013 - val_accuracy: 0.4203

Epoch 01218: val_loss did not improve from 1.29815
Epoch 1219/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4053 - val_loss: 1.2976 - val_accuracy: 0.4203

Epoch 01219: val_loss improved from 1.29815 to 1.29755, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1220/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4082 - val_loss: 1.2988 - val_accuracy: 0.4219

Epoch 01220: val_loss did not improve from 1.29755
Epoch 1221/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4061 - val_loss: 1.3012 - val_accuracy: 0.4187

Epoch 01221: val_loss did not improve from 1.29755
Epoch 1222/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4077 - val_loss: 1.2997 - val_accuracy: 0.4258

Epoch 01222: val_loss did not improve from 1.29755
Epoch 1223/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4058 - val_loss: 1.2985 - val_accuracy: 0.4242

Epoch 01223: val_loss did not improve from 1.29755
Epoch 1224/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4064 - val_loss: 1.2987 - val_accuracy: 0.4306

Epoch 01224: val_loss did not improve from 1.29755
Epoch 1225/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4049 - val_loss: 1.3005 - val_accuracy: 0.4211

Epoch 01225: val_loss did not improve from 1.29755
Epoch 1226/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4055 - val_loss: 1.2990 - val_accuracy: 0.4195

Epoch 01226: val_loss did not improve from 1.29755
Epoch 1227/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4026 - val_loss: 1.2989 - val_accuracy: 0.4195

Epoch 01227: val_loss did not improve from 1.29755
Epoch 1228/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4054 - val_loss: 1.3002 - val_accuracy: 0.4163

Epoch 01228: val_loss did not improve from 1.29755
Epoch 1229/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4072 - val_loss: 1.3027 - val_accuracy: 0.4187

Epoch 01229: val_loss did not improve from 1.29755
Epoch 1230/10000
12/12 - 0s - loss: 1.3025 - accuracy: 0.4016 - val_loss: 1.3024 - val_accuracy: 0.4298

Epoch 01230: val_loss did not improve from 1.29755
Epoch 1231/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4048 - val_loss: 1.3001 - val_accuracy: 0.4211

Epoch 01231: val_loss did not improve from 1.29755
Epoch 1232/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4053 - val_loss: 1.2978 - val_accuracy: 0.4250

Epoch 01232: val_loss did not improve from 1.29755
Epoch 1233/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4047 - val_loss: 1.3023 - val_accuracy: 0.4195

Epoch 01233: val_loss did not improve from 1.29755
Epoch 1234/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4047 - val_loss: 1.2993 - val_accuracy: 0.4234

Epoch 01234: val_loss did not improve from 1.29755
Epoch 1235/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4057 - val_loss: 1.2992 - val_accuracy: 0.4203

Epoch 01235: val_loss did not improve from 1.29755
Epoch 1236/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4069 - val_loss: 1.2993 - val_accuracy: 0.4211

Epoch 01236: val_loss did not improve from 1.29755
Epoch 1237/10000
12/12 - 0s - loss: 1.2940 - accuracy: 0.4037 - val_loss: 1.3005 - val_accuracy: 0.4219

Epoch 01237: val_loss did not improve from 1.29755
Epoch 1238/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4057 - val_loss: 1.3007 - val_accuracy: 0.4258

Epoch 01238: val_loss did not improve from 1.29755
Epoch 1239/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4070 - val_loss: 1.2988 - val_accuracy: 0.4203

Epoch 01239: val_loss did not improve from 1.29755
Epoch 1240/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4008 - val_loss: 1.2990 - val_accuracy: 0.4203

Epoch 01240: val_loss did not improve from 1.29755
Epoch 1241/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4022 - val_loss: 1.3002 - val_accuracy: 0.4250

Epoch 01241: val_loss did not improve from 1.29755
Epoch 1242/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4073 - val_loss: 1.3007 - val_accuracy: 0.4195

Epoch 01242: val_loss did not improve from 1.29755
Epoch 1243/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4029 - val_loss: 1.3015 - val_accuracy: 0.4171

Epoch 01243: val_loss did not improve from 1.29755
Epoch 1244/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4073 - val_loss: 1.2995 - val_accuracy: 0.4195

Epoch 01244: val_loss did not improve from 1.29755
Epoch 1245/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4075 - val_loss: 1.2991 - val_accuracy: 0.4226

Epoch 01245: val_loss did not improve from 1.29755
Epoch 1246/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4037 - val_loss: 1.2988 - val_accuracy: 0.4195

Epoch 01246: val_loss did not improve from 1.29755
Epoch 1247/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4067 - val_loss: 1.3008 - val_accuracy: 0.4155

Epoch 01247: val_loss did not improve from 1.29755
Epoch 1248/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4066 - val_loss: 1.2987 - val_accuracy: 0.4203

Epoch 01248: val_loss did not improve from 1.29755
Epoch 1249/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4040 - val_loss: 1.3033 - val_accuracy: 0.4203

Epoch 01249: val_loss did not improve from 1.29755
Epoch 1250/10000
12/12 - 0s - loss: 1.2990 - accuracy: 0.4055 - val_loss: 1.2988 - val_accuracy: 0.4179

Epoch 01250: val_loss did not improve from 1.29755
Epoch 1251/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4043 - val_loss: 1.2996 - val_accuracy: 0.4211

Epoch 01251: val_loss did not improve from 1.29755
Epoch 1252/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4039 - val_loss: 1.3001 - val_accuracy: 0.4187

Epoch 01252: val_loss did not improve from 1.29755
Epoch 1253/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4055 - val_loss: 1.3021 - val_accuracy: 0.4211

Epoch 01253: val_loss did not improve from 1.29755
Epoch 1254/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4050 - val_loss: 1.2983 - val_accuracy: 0.4211

Epoch 01254: val_loss did not improve from 1.29755
Epoch 1255/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4064 - val_loss: 1.2977 - val_accuracy: 0.4171

Epoch 01255: val_loss did not improve from 1.29755
Epoch 1256/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4080 - val_loss: 1.2989 - val_accuracy: 0.4179

Epoch 01256: val_loss did not improve from 1.29755
Epoch 1257/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4060 - val_loss: 1.3074 - val_accuracy: 0.4107

Epoch 01257: val_loss did not improve from 1.29755
Epoch 1258/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4048 - val_loss: 1.2989 - val_accuracy: 0.4211

Epoch 01258: val_loss did not improve from 1.29755
Epoch 1259/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4105 - val_loss: 1.3007 - val_accuracy: 0.4226

Epoch 01259: val_loss did not improve from 1.29755
Epoch 1260/10000
12/12 - 0s - loss: 1.2951 - accuracy: 0.4090 - val_loss: 1.2984 - val_accuracy: 0.4219

Epoch 01260: val_loss did not improve from 1.29755
Epoch 1261/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4070 - val_loss: 1.3015 - val_accuracy: 0.4250

Epoch 01261: val_loss did not improve from 1.29755
Epoch 1262/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4107 - val_loss: 1.3011 - val_accuracy: 0.4354

Epoch 01262: val_loss did not improve from 1.29755
Epoch 1263/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4057 - val_loss: 1.3008 - val_accuracy: 0.4274

Epoch 01263: val_loss did not improve from 1.29755
Epoch 1264/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4086 - val_loss: 1.2974 - val_accuracy: 0.4234

Epoch 01264: val_loss improved from 1.29755 to 1.29740, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1265/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4066 - val_loss: 1.2996 - val_accuracy: 0.4179

Epoch 01265: val_loss did not improve from 1.29740
Epoch 1266/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4101 - val_loss: 1.3026 - val_accuracy: 0.4195

Epoch 01266: val_loss did not improve from 1.29740
Epoch 1267/10000
12/12 - 0s - loss: 1.2964 - accuracy: 0.4069 - val_loss: 1.3002 - val_accuracy: 0.4171

Epoch 01267: val_loss did not improve from 1.29740
Epoch 1268/10000
12/12 - 0s - loss: 1.2938 - accuracy: 0.4067 - val_loss: 1.2979 - val_accuracy: 0.4306

Epoch 01268: val_loss did not improve from 1.29740
Epoch 1269/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4112 - val_loss: 1.2982 - val_accuracy: 0.4211

Epoch 01269: val_loss did not improve from 1.29740
Epoch 1270/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4068 - val_loss: 1.2979 - val_accuracy: 0.4266

Epoch 01270: val_loss did not improve from 1.29740
Epoch 1271/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4067 - val_loss: 1.2994 - val_accuracy: 0.4179

Epoch 01271: val_loss did not improve from 1.29740
Epoch 1272/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4083 - val_loss: 1.2983 - val_accuracy: 0.4219

Epoch 01272: val_loss did not improve from 1.29740
Epoch 1273/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4067 - val_loss: 1.2977 - val_accuracy: 0.4187

Epoch 01273: val_loss did not improve from 1.29740
Epoch 1274/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4041 - val_loss: 1.2985 - val_accuracy: 0.4171

Epoch 01274: val_loss did not improve from 1.29740
Epoch 1275/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4071 - val_loss: 1.2974 - val_accuracy: 0.4187

Epoch 01275: val_loss did not improve from 1.29740
Epoch 1276/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4064 - val_loss: 1.2976 - val_accuracy: 0.4250

Epoch 01276: val_loss did not improve from 1.29740
Epoch 1277/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4058 - val_loss: 1.2993 - val_accuracy: 0.4179

Epoch 01277: val_loss did not improve from 1.29740
Epoch 1278/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4025 - val_loss: 1.2997 - val_accuracy: 0.4211

Epoch 01278: val_loss did not improve from 1.29740
Epoch 1279/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4088 - val_loss: 1.2988 - val_accuracy: 0.4203

Epoch 01279: val_loss did not improve from 1.29740
Epoch 1280/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4090 - val_loss: 1.3012 - val_accuracy: 0.4123

Epoch 01280: val_loss did not improve from 1.29740
Epoch 1281/10000
12/12 - 0s - loss: 1.2984 - accuracy: 0.4054 - val_loss: 1.3004 - val_accuracy: 0.4179

Epoch 01281: val_loss did not improve from 1.29740
Epoch 1282/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4098 - val_loss: 1.3012 - val_accuracy: 0.4163

Epoch 01282: val_loss did not improve from 1.29740
Epoch 1283/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4094 - val_loss: 1.3058 - val_accuracy: 0.4187

Epoch 01283: val_loss did not improve from 1.29740
Epoch 1284/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4064 - val_loss: 1.2983 - val_accuracy: 0.4203

Epoch 01284: val_loss did not improve from 1.29740
Epoch 1285/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4070 - val_loss: 1.2979 - val_accuracy: 0.4242

Epoch 01285: val_loss did not improve from 1.29740
Epoch 1286/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4059 - val_loss: 1.2988 - val_accuracy: 0.4266

Epoch 01286: val_loss did not improve from 1.29740
Epoch 1287/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4052 - val_loss: 1.2983 - val_accuracy: 0.4258

Epoch 01287: val_loss did not improve from 1.29740
Epoch 1288/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4084 - val_loss: 1.3015 - val_accuracy: 0.4147

Epoch 01288: val_loss did not improve from 1.29740
Epoch 1289/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4085 - val_loss: 1.2988 - val_accuracy: 0.4234

Epoch 01289: val_loss did not improve from 1.29740
Epoch 1290/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4055 - val_loss: 1.2989 - val_accuracy: 0.4226

Epoch 01290: val_loss did not improve from 1.29740
Epoch 1291/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4088 - val_loss: 1.3037 - val_accuracy: 0.4306

Epoch 01291: val_loss did not improve from 1.29740
Epoch 1292/10000
12/12 - 0s - loss: 1.2975 - accuracy: 0.4056 - val_loss: 1.2989 - val_accuracy: 0.4219

Epoch 01292: val_loss did not improve from 1.29740
Epoch 1293/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4062 - val_loss: 1.3017 - val_accuracy: 0.4242

Epoch 01293: val_loss did not improve from 1.29740
Epoch 1294/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4051 - val_loss: 1.2986 - val_accuracy: 0.4203

Epoch 01294: val_loss did not improve from 1.29740
Epoch 1295/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4082 - val_loss: 1.2979 - val_accuracy: 0.4195

Epoch 01295: val_loss did not improve from 1.29740
Epoch 1296/10000
12/12 - 0s - loss: 1.2946 - accuracy: 0.4023 - val_loss: 1.3002 - val_accuracy: 0.4250

Epoch 01296: val_loss did not improve from 1.29740
Epoch 1297/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4097 - val_loss: 1.2971 - val_accuracy: 0.4226

Epoch 01297: val_loss improved from 1.29740 to 1.29713, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1298/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4087 - val_loss: 1.2978 - val_accuracy: 0.4226

Epoch 01298: val_loss did not improve from 1.29713
Epoch 1299/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4041 - val_loss: 1.3058 - val_accuracy: 0.4163

Epoch 01299: val_loss did not improve from 1.29713
Epoch 1300/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4032 - val_loss: 1.2982 - val_accuracy: 0.4171

Epoch 01300: val_loss did not improve from 1.29713
Epoch 1301/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4113 - val_loss: 1.2992 - val_accuracy: 0.4242

Epoch 01301: val_loss did not improve from 1.29713
Epoch 1302/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4045 - val_loss: 1.2995 - val_accuracy: 0.4195

Epoch 01302: val_loss did not improve from 1.29713
Epoch 1303/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4071 - val_loss: 1.2978 - val_accuracy: 0.4171

Epoch 01303: val_loss did not improve from 1.29713
Epoch 1304/10000
12/12 - 0s - loss: 1.2930 - accuracy: 0.4083 - val_loss: 1.2973 - val_accuracy: 0.4266

Epoch 01304: val_loss did not improve from 1.29713
Epoch 1305/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4061 - val_loss: 1.3001 - val_accuracy: 0.4250

Epoch 01305: val_loss did not improve from 1.29713
Epoch 1306/10000
12/12 - 0s - loss: 1.2970 - accuracy: 0.4078 - val_loss: 1.2999 - val_accuracy: 0.4226

Epoch 01306: val_loss did not improve from 1.29713
Epoch 1307/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4074 - val_loss: 1.2983 - val_accuracy: 0.4234

Epoch 01307: val_loss did not improve from 1.29713
Epoch 1308/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4034 - val_loss: 1.3001 - val_accuracy: 0.4187

Epoch 01308: val_loss did not improve from 1.29713
Epoch 1309/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4057 - val_loss: 1.2989 - val_accuracy: 0.4242

Epoch 01309: val_loss did not improve from 1.29713
Epoch 1310/10000
12/12 - 0s - loss: 1.2934 - accuracy: 0.4058 - val_loss: 1.2983 - val_accuracy: 0.4195

Epoch 01310: val_loss did not improve from 1.29713
Epoch 1311/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4099 - val_loss: 1.2979 - val_accuracy: 0.4211

Epoch 01311: val_loss did not improve from 1.29713
Epoch 1312/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4075 - val_loss: 1.2970 - val_accuracy: 0.4203

Epoch 01312: val_loss improved from 1.29713 to 1.29695, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1313/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4057 - val_loss: 1.3028 - val_accuracy: 0.4155

Epoch 01313: val_loss did not improve from 1.29695
Epoch 1314/10000
12/12 - 0s - loss: 1.2956 - accuracy: 0.4017 - val_loss: 1.2985 - val_accuracy: 0.4187

Epoch 01314: val_loss did not improve from 1.29695
Epoch 1315/10000
12/12 - 0s - loss: 1.2969 - accuracy: 0.4044 - val_loss: 1.3011 - val_accuracy: 0.4179

Epoch 01315: val_loss did not improve from 1.29695
Epoch 1316/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4122 - val_loss: 1.3001 - val_accuracy: 0.4195

Epoch 01316: val_loss did not improve from 1.29695
Epoch 1317/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4108 - val_loss: 1.2990 - val_accuracy: 0.4226

Epoch 01317: val_loss did not improve from 1.29695
Epoch 1318/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4080 - val_loss: 1.2991 - val_accuracy: 0.4195

Epoch 01318: val_loss did not improve from 1.29695
Epoch 1319/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4067 - val_loss: 1.2980 - val_accuracy: 0.4195

Epoch 01319: val_loss did not improve from 1.29695
Epoch 1320/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4068 - val_loss: 1.2992 - val_accuracy: 0.4258

Epoch 01320: val_loss did not improve from 1.29695
Epoch 1321/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4111 - val_loss: 1.2979 - val_accuracy: 0.4242

Epoch 01321: val_loss did not improve from 1.29695
Epoch 1322/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4041 - val_loss: 1.2977 - val_accuracy: 0.4266

Epoch 01322: val_loss did not improve from 1.29695
Epoch 1323/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4082 - val_loss: 1.2963 - val_accuracy: 0.4234

Epoch 01323: val_loss improved from 1.29695 to 1.29626, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1324/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4085 - val_loss: 1.3000 - val_accuracy: 0.4195

Epoch 01324: val_loss did not improve from 1.29626
Epoch 1325/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4044 - val_loss: 1.2970 - val_accuracy: 0.4219

Epoch 01325: val_loss did not improve from 1.29626
Epoch 1326/10000
12/12 - 0s - loss: 1.2937 - accuracy: 0.4080 - val_loss: 1.2973 - val_accuracy: 0.4203

Epoch 01326: val_loss did not improve from 1.29626
Epoch 1327/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4103 - val_loss: 1.2975 - val_accuracy: 0.4290

Epoch 01327: val_loss did not improve from 1.29626
Epoch 1328/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4089 - val_loss: 1.2956 - val_accuracy: 0.4306

Epoch 01328: val_loss improved from 1.29626 to 1.29557, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1329/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4045 - val_loss: 1.2980 - val_accuracy: 0.4155

Epoch 01329: val_loss did not improve from 1.29557
Epoch 1330/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4044 - val_loss: 1.2968 - val_accuracy: 0.4226

Epoch 01330: val_loss did not improve from 1.29557
Epoch 1331/10000
12/12 - 0s - loss: 1.2928 - accuracy: 0.4087 - val_loss: 1.2976 - val_accuracy: 0.4211

Epoch 01331: val_loss did not improve from 1.29557
Epoch 1332/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4058 - val_loss: 1.2967 - val_accuracy: 0.4203

Epoch 01332: val_loss did not improve from 1.29557
Epoch 1333/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4076 - val_loss: 1.2955 - val_accuracy: 0.4250

Epoch 01333: val_loss improved from 1.29557 to 1.29553, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1334/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4083 - val_loss: 1.2969 - val_accuracy: 0.4250

Epoch 01334: val_loss did not improve from 1.29553
Epoch 1335/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4080 - val_loss: 1.2964 - val_accuracy: 0.4195

Epoch 01335: val_loss did not improve from 1.29553
Epoch 1336/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4076 - val_loss: 1.2954 - val_accuracy: 0.4219

Epoch 01336: val_loss improved from 1.29553 to 1.29538, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1337/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4073 - val_loss: 1.2962 - val_accuracy: 0.4234

Epoch 01337: val_loss did not improve from 1.29538
Epoch 1338/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4084 - val_loss: 1.2978 - val_accuracy: 0.4139

Epoch 01338: val_loss did not improve from 1.29538
Epoch 1339/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4070 - val_loss: 1.2957 - val_accuracy: 0.4219

Epoch 01339: val_loss did not improve from 1.29538
Epoch 1340/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4067 - val_loss: 1.2986 - val_accuracy: 0.4226

Epoch 01340: val_loss did not improve from 1.29538
Epoch 1341/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4072 - val_loss: 1.2962 - val_accuracy: 0.4219

Epoch 01341: val_loss did not improve from 1.29538
Epoch 1342/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4076 - val_loss: 1.2972 - val_accuracy: 0.4139

Epoch 01342: val_loss did not improve from 1.29538
Epoch 1343/10000
12/12 - 0s - loss: 1.2913 - accuracy: 0.4096 - val_loss: 1.2984 - val_accuracy: 0.4131

Epoch 01343: val_loss did not improve from 1.29538
Epoch 1344/10000
12/12 - 0s - loss: 1.2957 - accuracy: 0.4078 - val_loss: 1.3039 - val_accuracy: 0.4155

Epoch 01344: val_loss did not improve from 1.29538
Epoch 1345/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4056 - val_loss: 1.2992 - val_accuracy: 0.4211

Epoch 01345: val_loss did not improve from 1.29538
Epoch 1346/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4087 - val_loss: 1.2982 - val_accuracy: 0.4203

Epoch 01346: val_loss did not improve from 1.29538
Epoch 1347/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4063 - val_loss: 1.2970 - val_accuracy: 0.4234

Epoch 01347: val_loss did not improve from 1.29538
Epoch 1348/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4081 - val_loss: 1.2971 - val_accuracy: 0.4211

Epoch 01348: val_loss did not improve from 1.29538
Epoch 1349/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4053 - val_loss: 1.2967 - val_accuracy: 0.4203

Epoch 01349: val_loss did not improve from 1.29538
Epoch 1350/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4072 - val_loss: 1.2959 - val_accuracy: 0.4242

Epoch 01350: val_loss did not improve from 1.29538
Epoch 1351/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4116 - val_loss: 1.2978 - val_accuracy: 0.4242

Epoch 01351: val_loss did not improve from 1.29538
Epoch 1352/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4084 - val_loss: 1.2962 - val_accuracy: 0.4242

Epoch 01352: val_loss did not improve from 1.29538
Epoch 1353/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4097 - val_loss: 1.2946 - val_accuracy: 0.4330

Epoch 01353: val_loss improved from 1.29538 to 1.29457, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1354/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4107 - val_loss: 1.2952 - val_accuracy: 0.4258

Epoch 01354: val_loss did not improve from 1.29457
Epoch 1355/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4133 - val_loss: 1.2961 - val_accuracy: 0.4234

Epoch 01355: val_loss did not improve from 1.29457
Epoch 1356/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4091 - val_loss: 1.2970 - val_accuracy: 0.4234

Epoch 01356: val_loss did not improve from 1.29457
Epoch 1357/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4079 - val_loss: 1.2958 - val_accuracy: 0.4203

Epoch 01357: val_loss did not improve from 1.29457
Epoch 1358/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4097 - val_loss: 1.2959 - val_accuracy: 0.4195

Epoch 01358: val_loss did not improve from 1.29457
Epoch 1359/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4067 - val_loss: 1.2954 - val_accuracy: 0.4242

Epoch 01359: val_loss did not improve from 1.29457
Epoch 1360/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4101 - val_loss: 1.2971 - val_accuracy: 0.4250

Epoch 01360: val_loss did not improve from 1.29457
Epoch 1361/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4112 - val_loss: 1.2992 - val_accuracy: 0.4234

Epoch 01361: val_loss did not improve from 1.29457
Epoch 1362/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4059 - val_loss: 1.2961 - val_accuracy: 0.4266

Epoch 01362: val_loss did not improve from 1.29457
Epoch 1363/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4111 - val_loss: 1.2952 - val_accuracy: 0.4250

Epoch 01363: val_loss did not improve from 1.29457
Epoch 1364/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4117 - val_loss: 1.2981 - val_accuracy: 0.4187

Epoch 01364: val_loss did not improve from 1.29457
Epoch 1365/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4112 - val_loss: 1.2977 - val_accuracy: 0.4179

Epoch 01365: val_loss did not improve from 1.29457
Epoch 1366/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4070 - val_loss: 1.2996 - val_accuracy: 0.4258

Epoch 01366: val_loss did not improve from 1.29457
Epoch 1367/10000
12/12 - 0s - loss: 1.2976 - accuracy: 0.4042 - val_loss: 1.2977 - val_accuracy: 0.4226

Epoch 01367: val_loss did not improve from 1.29457
Epoch 1368/10000
12/12 - 0s - loss: 1.2959 - accuracy: 0.4052 - val_loss: 1.2986 - val_accuracy: 0.4234

Epoch 01368: val_loss did not improve from 1.29457
Epoch 1369/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4075 - val_loss: 1.2980 - val_accuracy: 0.4195

Epoch 01369: val_loss did not improve from 1.29457
Epoch 1370/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4073 - val_loss: 1.2958 - val_accuracy: 0.4234

Epoch 01370: val_loss did not improve from 1.29457
Epoch 1371/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4087 - val_loss: 1.2956 - val_accuracy: 0.4219

Epoch 01371: val_loss did not improve from 1.29457
Epoch 1372/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4113 - val_loss: 1.2970 - val_accuracy: 0.4226

Epoch 01372: val_loss did not improve from 1.29457
Epoch 1373/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4102 - val_loss: 1.2970 - val_accuracy: 0.4219

Epoch 01373: val_loss did not improve from 1.29457
Epoch 1374/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4066 - val_loss: 1.2956 - val_accuracy: 0.4155

Epoch 01374: val_loss did not improve from 1.29457
Epoch 1375/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4077 - val_loss: 1.2960 - val_accuracy: 0.4179

Epoch 01375: val_loss did not improve from 1.29457
Epoch 1376/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4069 - val_loss: 1.2999 - val_accuracy: 0.4203

Epoch 01376: val_loss did not improve from 1.29457
Epoch 1377/10000
12/12 - 0s - loss: 1.2965 - accuracy: 0.4034 - val_loss: 1.2955 - val_accuracy: 0.4258

Epoch 01377: val_loss did not improve from 1.29457
Epoch 1378/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4078 - val_loss: 1.2954 - val_accuracy: 0.4155

Epoch 01378: val_loss did not improve from 1.29457
Epoch 1379/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4086 - val_loss: 1.2985 - val_accuracy: 0.4083

Epoch 01379: val_loss did not improve from 1.29457
Epoch 1380/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4101 - val_loss: 1.2963 - val_accuracy: 0.4195

Epoch 01380: val_loss did not improve from 1.29457
Epoch 1381/10000
12/12 - 0s - loss: 1.2931 - accuracy: 0.4047 - val_loss: 1.2989 - val_accuracy: 0.4195

Epoch 01381: val_loss did not improve from 1.29457
Epoch 1382/10000
12/12 - 0s - loss: 1.2943 - accuracy: 0.4064 - val_loss: 1.2979 - val_accuracy: 0.4203

Epoch 01382: val_loss did not improve from 1.29457
Epoch 1383/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4062 - val_loss: 1.2969 - val_accuracy: 0.4258

Epoch 01383: val_loss did not improve from 1.29457
Epoch 1384/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4072 - val_loss: 1.2990 - val_accuracy: 0.4203

Epoch 01384: val_loss did not improve from 1.29457
Epoch 1385/10000
12/12 - 0s - loss: 1.2926 - accuracy: 0.4147 - val_loss: 1.3030 - val_accuracy: 0.4139

Epoch 01385: val_loss did not improve from 1.29457
Epoch 1386/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4089 - val_loss: 1.3000 - val_accuracy: 0.4139

Epoch 01386: val_loss did not improve from 1.29457
Epoch 1387/10000
12/12 - 0s - loss: 1.2941 - accuracy: 0.4064 - val_loss: 1.2954 - val_accuracy: 0.4242

Epoch 01387: val_loss did not improve from 1.29457
Epoch 1388/10000
12/12 - 0s - loss: 1.2939 - accuracy: 0.4054 - val_loss: 1.3066 - val_accuracy: 0.4195

Epoch 01388: val_loss did not improve from 1.29457
Epoch 1389/10000
12/12 - 0s - loss: 1.2948 - accuracy: 0.4094 - val_loss: 1.2994 - val_accuracy: 0.4187

Epoch 01389: val_loss did not improve from 1.29457
Epoch 1390/10000
12/12 - 0s - loss: 1.3003 - accuracy: 0.4063 - val_loss: 1.2993 - val_accuracy: 0.4203

Epoch 01390: val_loss did not improve from 1.29457
Epoch 1391/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4097 - val_loss: 1.3046 - val_accuracy: 0.4051

Epoch 01391: val_loss did not improve from 1.29457
Epoch 1392/10000
12/12 - 0s - loss: 1.2942 - accuracy: 0.4122 - val_loss: 1.2990 - val_accuracy: 0.4147

Epoch 01392: val_loss did not improve from 1.29457
Epoch 1393/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4095 - val_loss: 1.2975 - val_accuracy: 0.4242

Epoch 01393: val_loss did not improve from 1.29457
Epoch 1394/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4103 - val_loss: 1.2959 - val_accuracy: 0.4211

Epoch 01394: val_loss did not improve from 1.29457
Epoch 1395/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4070 - val_loss: 1.2969 - val_accuracy: 0.4195

Epoch 01395: val_loss did not improve from 1.29457
Epoch 1396/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4062 - val_loss: 1.2986 - val_accuracy: 0.4219

Epoch 01396: val_loss did not improve from 1.29457
Epoch 1397/10000
12/12 - 0s - loss: 1.2935 - accuracy: 0.4098 - val_loss: 1.3069 - val_accuracy: 0.4075

Epoch 01397: val_loss did not improve from 1.29457
Epoch 1398/10000
12/12 - 0s - loss: 1.2955 - accuracy: 0.4131 - val_loss: 1.2974 - val_accuracy: 0.4179

Epoch 01398: val_loss did not improve from 1.29457
Epoch 1399/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4091 - val_loss: 1.2984 - val_accuracy: 0.4155

Epoch 01399: val_loss did not improve from 1.29457
Epoch 1400/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4087 - val_loss: 1.2966 - val_accuracy: 0.4139

Epoch 01400: val_loss did not improve from 1.29457
Epoch 1401/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4094 - val_loss: 1.3019 - val_accuracy: 0.4123

Epoch 01401: val_loss did not improve from 1.29457
Epoch 1402/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4060 - val_loss: 1.2957 - val_accuracy: 0.4266

Epoch 01402: val_loss did not improve from 1.29457
Epoch 1403/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4084 - val_loss: 1.2965 - val_accuracy: 0.4234

Epoch 01403: val_loss did not improve from 1.29457
Epoch 1404/10000
12/12 - 0s - loss: 1.2916 - accuracy: 0.4053 - val_loss: 1.2994 - val_accuracy: 0.4187

Epoch 01404: val_loss did not improve from 1.29457
Epoch 1405/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4066 - val_loss: 1.2973 - val_accuracy: 0.4234

Epoch 01405: val_loss did not improve from 1.29457
Epoch 1406/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4103 - val_loss: 1.2987 - val_accuracy: 0.4219

Epoch 01406: val_loss did not improve from 1.29457
Epoch 1407/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4082 - val_loss: 1.2963 - val_accuracy: 0.4155

Epoch 01407: val_loss did not improve from 1.29457
Epoch 1408/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4098 - val_loss: 1.3005 - val_accuracy: 0.4219

Epoch 01408: val_loss did not improve from 1.29457
Epoch 1409/10000
12/12 - 0s - loss: 1.2923 - accuracy: 0.4095 - val_loss: 1.2958 - val_accuracy: 0.4234

Epoch 01409: val_loss did not improve from 1.29457
Epoch 1410/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4109 - val_loss: 1.2993 - val_accuracy: 0.4258

Epoch 01410: val_loss did not improve from 1.29457
Epoch 1411/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4131 - val_loss: 1.2959 - val_accuracy: 0.4298

Epoch 01411: val_loss did not improve from 1.29457
Epoch 1412/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4101 - val_loss: 1.3062 - val_accuracy: 0.4043

Epoch 01412: val_loss did not improve from 1.29457
Epoch 1413/10000
12/12 - 0s - loss: 1.2994 - accuracy: 0.4055 - val_loss: 1.2961 - val_accuracy: 0.4306

Epoch 01413: val_loss did not improve from 1.29457
Epoch 1414/10000
12/12 - 0s - loss: 1.2953 - accuracy: 0.4078 - val_loss: 1.3014 - val_accuracy: 0.4211

Epoch 01414: val_loss did not improve from 1.29457
Epoch 1415/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4102 - val_loss: 1.2976 - val_accuracy: 0.4187

Epoch 01415: val_loss did not improve from 1.29457
Epoch 1416/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4072 - val_loss: 1.2966 - val_accuracy: 0.4195

Epoch 01416: val_loss did not improve from 1.29457
Epoch 1417/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4096 - val_loss: 1.3022 - val_accuracy: 0.4139

Epoch 01417: val_loss did not improve from 1.29457
Epoch 1418/10000
12/12 - 0s - loss: 1.2908 - accuracy: 0.4088 - val_loss: 1.2963 - val_accuracy: 0.4211

Epoch 01418: val_loss did not improve from 1.29457
Epoch 1419/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4105 - val_loss: 1.2946 - val_accuracy: 0.4282

Epoch 01419: val_loss did not improve from 1.29457
Epoch 1420/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4093 - val_loss: 1.2951 - val_accuracy: 0.4195

Epoch 01420: val_loss did not improve from 1.29457
Epoch 1421/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4156 - val_loss: 1.2954 - val_accuracy: 0.4274

Epoch 01421: val_loss did not improve from 1.29457
Epoch 1422/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4097 - val_loss: 1.2968 - val_accuracy: 0.4171

Epoch 01422: val_loss did not improve from 1.29457
Epoch 1423/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4074 - val_loss: 1.2997 - val_accuracy: 0.4179

Epoch 01423: val_loss did not improve from 1.29457
Epoch 1424/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4097 - val_loss: 1.2960 - val_accuracy: 0.4203

Epoch 01424: val_loss did not improve from 1.29457
Epoch 1425/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4109 - val_loss: 1.2946 - val_accuracy: 0.4234

Epoch 01425: val_loss did not improve from 1.29457
Epoch 1426/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4102 - val_loss: 1.2958 - val_accuracy: 0.4226

Epoch 01426: val_loss did not improve from 1.29457
Epoch 1427/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4106 - val_loss: 1.2945 - val_accuracy: 0.4306

Epoch 01427: val_loss improved from 1.29457 to 1.29452, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1428/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4107 - val_loss: 1.2949 - val_accuracy: 0.4250

Epoch 01428: val_loss did not improve from 1.29452
Epoch 1429/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4107 - val_loss: 1.2971 - val_accuracy: 0.4179

Epoch 01429: val_loss did not improve from 1.29452
Epoch 1430/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4118 - val_loss: 1.2944 - val_accuracy: 0.4179

Epoch 01430: val_loss improved from 1.29452 to 1.29440, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1431/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4099 - val_loss: 1.2963 - val_accuracy: 0.4195

Epoch 01431: val_loss did not improve from 1.29440
Epoch 1432/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4108 - val_loss: 1.2952 - val_accuracy: 0.4282

Epoch 01432: val_loss did not improve from 1.29440
Epoch 1433/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4109 - val_loss: 1.2969 - val_accuracy: 0.4195

Epoch 01433: val_loss did not improve from 1.29440
Epoch 1434/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4089 - val_loss: 1.2954 - val_accuracy: 0.4195

Epoch 01434: val_loss did not improve from 1.29440
Epoch 1435/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4105 - val_loss: 1.2969 - val_accuracy: 0.4242

Epoch 01435: val_loss did not improve from 1.29440
Epoch 1436/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4127 - val_loss: 1.2971 - val_accuracy: 0.4242

Epoch 01436: val_loss did not improve from 1.29440
Epoch 1437/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4084 - val_loss: 1.2953 - val_accuracy: 0.4226

Epoch 01437: val_loss did not improve from 1.29440
Epoch 1438/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4114 - val_loss: 1.2969 - val_accuracy: 0.4163

Epoch 01438: val_loss did not improve from 1.29440
Epoch 1439/10000
12/12 - 0s - loss: 1.2954 - accuracy: 0.4047 - val_loss: 1.2967 - val_accuracy: 0.4242

Epoch 01439: val_loss did not improve from 1.29440
Epoch 1440/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4101 - val_loss: 1.2941 - val_accuracy: 0.4250

Epoch 01440: val_loss improved from 1.29440 to 1.29406, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1441/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4074 - val_loss: 1.2951 - val_accuracy: 0.4203

Epoch 01441: val_loss did not improve from 1.29406
Epoch 1442/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4070 - val_loss: 1.2945 - val_accuracy: 0.4242

Epoch 01442: val_loss did not improve from 1.29406
Epoch 1443/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4142 - val_loss: 1.2945 - val_accuracy: 0.4219

Epoch 01443: val_loss did not improve from 1.29406
Epoch 1444/10000
12/12 - 0s - loss: 1.2907 - accuracy: 0.4103 - val_loss: 1.2988 - val_accuracy: 0.4195

Epoch 01444: val_loss did not improve from 1.29406
Epoch 1445/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4118 - val_loss: 1.2958 - val_accuracy: 0.4211

Epoch 01445: val_loss did not improve from 1.29406
Epoch 1446/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4110 - val_loss: 1.2978 - val_accuracy: 0.4242

Epoch 01446: val_loss did not improve from 1.29406
Epoch 1447/10000
12/12 - 0s - loss: 1.2927 - accuracy: 0.4125 - val_loss: 1.2955 - val_accuracy: 0.4226

Epoch 01447: val_loss did not improve from 1.29406
Epoch 1448/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4130 - val_loss: 1.2963 - val_accuracy: 0.4147

Epoch 01448: val_loss did not improve from 1.29406
Epoch 1449/10000
12/12 - 0s - loss: 1.2890 - accuracy: 0.4120 - val_loss: 1.2983 - val_accuracy: 0.4139

Epoch 01449: val_loss did not improve from 1.29406
Epoch 1450/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4088 - val_loss: 1.2962 - val_accuracy: 0.4203

Epoch 01450: val_loss did not improve from 1.29406
Epoch 1451/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4075 - val_loss: 1.2974 - val_accuracy: 0.4226

Epoch 01451: val_loss did not improve from 1.29406
Epoch 1452/10000
12/12 - 0s - loss: 1.2919 - accuracy: 0.4098 - val_loss: 1.2969 - val_accuracy: 0.4211

Epoch 01452: val_loss did not improve from 1.29406
Epoch 1453/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4102 - val_loss: 1.2958 - val_accuracy: 0.4226

Epoch 01453: val_loss did not improve from 1.29406
Epoch 1454/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4095 - val_loss: 1.2945 - val_accuracy: 0.4234

Epoch 01454: val_loss did not improve from 1.29406
Epoch 1455/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4167 - val_loss: 1.2947 - val_accuracy: 0.4274

Epoch 01455: val_loss did not improve from 1.29406
Epoch 1456/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4110 - val_loss: 1.2973 - val_accuracy: 0.4171

Epoch 01456: val_loss did not improve from 1.29406
Epoch 1457/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4116 - val_loss: 1.2953 - val_accuracy: 0.4219

Epoch 01457: val_loss did not improve from 1.29406
Epoch 1458/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4094 - val_loss: 1.2943 - val_accuracy: 0.4219

Epoch 01458: val_loss did not improve from 1.29406
Epoch 1459/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4101 - val_loss: 1.2962 - val_accuracy: 0.4250

Epoch 01459: val_loss did not improve from 1.29406
Epoch 1460/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4121 - val_loss: 1.2965 - val_accuracy: 0.4258

Epoch 01460: val_loss did not improve from 1.29406
Epoch 1461/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4101 - val_loss: 1.2955 - val_accuracy: 0.4219

Epoch 01461: val_loss did not improve from 1.29406
Epoch 1462/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4064 - val_loss: 1.2941 - val_accuracy: 0.4250

Epoch 01462: val_loss did not improve from 1.29406
Epoch 1463/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4086 - val_loss: 1.2944 - val_accuracy: 0.4179

Epoch 01463: val_loss did not improve from 1.29406
Epoch 1464/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4133 - val_loss: 1.2968 - val_accuracy: 0.4195

Epoch 01464: val_loss did not improve from 1.29406
Epoch 1465/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4094 - val_loss: 1.2955 - val_accuracy: 0.4242

Epoch 01465: val_loss did not improve from 1.29406
Epoch 1466/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4107 - val_loss: 1.2957 - val_accuracy: 0.4211

Epoch 01466: val_loss did not improve from 1.29406
Epoch 1467/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4107 - val_loss: 1.3024 - val_accuracy: 0.4091

Epoch 01467: val_loss did not improve from 1.29406
Epoch 1468/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4097 - val_loss: 1.2977 - val_accuracy: 0.4147

Epoch 01468: val_loss did not improve from 1.29406
Epoch 1469/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4097 - val_loss: 1.2957 - val_accuracy: 0.4203

Epoch 01469: val_loss did not improve from 1.29406
Epoch 1470/10000
12/12 - 0s - loss: 1.2922 - accuracy: 0.4101 - val_loss: 1.2991 - val_accuracy: 0.4171

Epoch 01470: val_loss did not improve from 1.29406
Epoch 1471/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4106 - val_loss: 1.2941 - val_accuracy: 0.4234

Epoch 01471: val_loss did not improve from 1.29406
Epoch 1472/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4141 - val_loss: 1.2949 - val_accuracy: 0.4226

Epoch 01472: val_loss did not improve from 1.29406
Epoch 1473/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4091 - val_loss: 1.2966 - val_accuracy: 0.4203

Epoch 01473: val_loss did not improve from 1.29406
Epoch 1474/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4121 - val_loss: 1.2975 - val_accuracy: 0.4171

Epoch 01474: val_loss did not improve from 1.29406
Epoch 1475/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4100 - val_loss: 1.2952 - val_accuracy: 0.4219

Epoch 01475: val_loss did not improve from 1.29406
Epoch 1476/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4099 - val_loss: 1.2944 - val_accuracy: 0.4250

Epoch 01476: val_loss did not improve from 1.29406
Epoch 1477/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4114 - val_loss: 1.2941 - val_accuracy: 0.4250

Epoch 01477: val_loss did not improve from 1.29406
Epoch 1478/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4125 - val_loss: 1.2953 - val_accuracy: 0.4219

Epoch 01478: val_loss did not improve from 1.29406
Epoch 1479/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4094 - val_loss: 1.2949 - val_accuracy: 0.4179

Epoch 01479: val_loss did not improve from 1.29406
Epoch 1480/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4109 - val_loss: 1.2982 - val_accuracy: 0.4234

Epoch 01480: val_loss did not improve from 1.29406
Epoch 1481/10000
12/12 - 0s - loss: 1.2924 - accuracy: 0.4148 - val_loss: 1.2954 - val_accuracy: 0.4187

Epoch 01481: val_loss did not improve from 1.29406
Epoch 1482/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4125 - val_loss: 1.2944 - val_accuracy: 0.4195

Epoch 01482: val_loss did not improve from 1.29406
Epoch 1483/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4126 - val_loss: 1.2957 - val_accuracy: 0.4242

Epoch 01483: val_loss did not improve from 1.29406
Epoch 1484/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4063 - val_loss: 1.2949 - val_accuracy: 0.4163

Epoch 01484: val_loss did not improve from 1.29406
Epoch 1485/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4108 - val_loss: 1.2952 - val_accuracy: 0.4226

Epoch 01485: val_loss did not improve from 1.29406
Epoch 1486/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4072 - val_loss: 1.2971 - val_accuracy: 0.4195

Epoch 01486: val_loss did not improve from 1.29406
Epoch 1487/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4131 - val_loss: 1.2939 - val_accuracy: 0.4242

Epoch 01487: val_loss improved from 1.29406 to 1.29394, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1488/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4092 - val_loss: 1.2966 - val_accuracy: 0.4139

Epoch 01488: val_loss did not improve from 1.29394
Epoch 1489/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4082 - val_loss: 1.2937 - val_accuracy: 0.4242

Epoch 01489: val_loss improved from 1.29394 to 1.29374, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1490/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4118 - val_loss: 1.2967 - val_accuracy: 0.4219

Epoch 01490: val_loss did not improve from 1.29374
Epoch 1491/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4116 - val_loss: 1.2941 - val_accuracy: 0.4179

Epoch 01491: val_loss did not improve from 1.29374
Epoch 1492/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4139 - val_loss: 1.2961 - val_accuracy: 0.4219

Epoch 01492: val_loss did not improve from 1.29374
Epoch 1493/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4066 - val_loss: 1.2961 - val_accuracy: 0.4179

Epoch 01493: val_loss did not improve from 1.29374
Epoch 1494/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4094 - val_loss: 1.2943 - val_accuracy: 0.4187

Epoch 01494: val_loss did not improve from 1.29374
Epoch 1495/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4114 - val_loss: 1.2952 - val_accuracy: 0.4195

Epoch 01495: val_loss did not improve from 1.29374
Epoch 1496/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4117 - val_loss: 1.2982 - val_accuracy: 0.4211

Epoch 01496: val_loss did not improve from 1.29374
Epoch 1497/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4097 - val_loss: 1.2943 - val_accuracy: 0.4338

Epoch 01497: val_loss did not improve from 1.29374
Epoch 1498/10000
12/12 - 0s - loss: 1.2921 - accuracy: 0.4126 - val_loss: 1.2949 - val_accuracy: 0.4282

Epoch 01498: val_loss did not improve from 1.29374
Epoch 1499/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4126 - val_loss: 1.2975 - val_accuracy: 0.4179

Epoch 01499: val_loss did not improve from 1.29374
Epoch 1500/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4129 - val_loss: 1.2936 - val_accuracy: 0.4242

Epoch 01500: val_loss improved from 1.29374 to 1.29356, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1501/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4070 - val_loss: 1.3003 - val_accuracy: 0.4171

Epoch 01501: val_loss did not improve from 1.29356
Epoch 1502/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4140 - val_loss: 1.2957 - val_accuracy: 0.4187

Epoch 01502: val_loss did not improve from 1.29356
Epoch 1503/10000
12/12 - 0s - loss: 1.2918 - accuracy: 0.4096 - val_loss: 1.2961 - val_accuracy: 0.4195

Epoch 01503: val_loss did not improve from 1.29356
Epoch 1504/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4141 - val_loss: 1.2947 - val_accuracy: 0.4187

Epoch 01504: val_loss did not improve from 1.29356
Epoch 1505/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4129 - val_loss: 1.2949 - val_accuracy: 0.4195

Epoch 01505: val_loss did not improve from 1.29356
Epoch 1506/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4140 - val_loss: 1.2987 - val_accuracy: 0.4250

Epoch 01506: val_loss did not improve from 1.29356
Epoch 1507/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4116 - val_loss: 1.2928 - val_accuracy: 0.4266

Epoch 01507: val_loss improved from 1.29356 to 1.29275, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1508/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4083 - val_loss: 1.2942 - val_accuracy: 0.4179

Epoch 01508: val_loss did not improve from 1.29275
Epoch 1509/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4098 - val_loss: 1.2970 - val_accuracy: 0.4195

Epoch 01509: val_loss did not improve from 1.29275
Epoch 1510/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4101 - val_loss: 1.2957 - val_accuracy: 0.4322

Epoch 01510: val_loss did not improve from 1.29275
Epoch 1511/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4122 - val_loss: 1.2953 - val_accuracy: 0.4250

Epoch 01511: val_loss did not improve from 1.29275
Epoch 1512/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4086 - val_loss: 1.2944 - val_accuracy: 0.4274

Epoch 01512: val_loss did not improve from 1.29275
Epoch 1513/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4136 - val_loss: 1.2977 - val_accuracy: 0.4187

Epoch 01513: val_loss did not improve from 1.29275
Epoch 1514/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4110 - val_loss: 1.2966 - val_accuracy: 0.4139

Epoch 01514: val_loss did not improve from 1.29275
Epoch 1515/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4125 - val_loss: 1.2967 - val_accuracy: 0.4115

Epoch 01515: val_loss did not improve from 1.29275
Epoch 1516/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4097 - val_loss: 1.2969 - val_accuracy: 0.4258

Epoch 01516: val_loss did not improve from 1.29275
Epoch 1517/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4123 - val_loss: 1.2949 - val_accuracy: 0.4234

Epoch 01517: val_loss did not improve from 1.29275
Epoch 1518/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4125 - val_loss: 1.2943 - val_accuracy: 0.4211

Epoch 01518: val_loss did not improve from 1.29275
Epoch 1519/10000
12/12 - 0s - loss: 1.2895 - accuracy: 0.4146 - val_loss: 1.2970 - val_accuracy: 0.4203

Epoch 01519: val_loss did not improve from 1.29275
Epoch 1520/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4139 - val_loss: 1.2919 - val_accuracy: 0.4242

Epoch 01520: val_loss improved from 1.29275 to 1.29186, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1521/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4179 - val_loss: 1.2936 - val_accuracy: 0.4219

Epoch 01521: val_loss did not improve from 1.29186
Epoch 1522/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4132 - val_loss: 1.2975 - val_accuracy: 0.4211

Epoch 01522: val_loss did not improve from 1.29186
Epoch 1523/10000
12/12 - 0s - loss: 1.2910 - accuracy: 0.4144 - val_loss: 1.2974 - val_accuracy: 0.4219

Epoch 01523: val_loss did not improve from 1.29186
Epoch 1524/10000
12/12 - 0s - loss: 1.2912 - accuracy: 0.4117 - val_loss: 1.2950 - val_accuracy: 0.4242

Epoch 01524: val_loss did not improve from 1.29186
Epoch 1525/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4130 - val_loss: 1.2956 - val_accuracy: 0.4147

Epoch 01525: val_loss did not improve from 1.29186
Epoch 1526/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4126 - val_loss: 1.2955 - val_accuracy: 0.4211

Epoch 01526: val_loss did not improve from 1.29186
Epoch 1527/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4101 - val_loss: 1.2962 - val_accuracy: 0.4258

Epoch 01527: val_loss did not improve from 1.29186
Epoch 1528/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4115 - val_loss: 1.2981 - val_accuracy: 0.4139

Epoch 01528: val_loss did not improve from 1.29186
Epoch 1529/10000
12/12 - 0s - loss: 1.2936 - accuracy: 0.4113 - val_loss: 1.2962 - val_accuracy: 0.4203

Epoch 01529: val_loss did not improve from 1.29186
Epoch 1530/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4109 - val_loss: 1.2934 - val_accuracy: 0.4306

Epoch 01530: val_loss did not improve from 1.29186
Epoch 1531/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4088 - val_loss: 1.2947 - val_accuracy: 0.4139

Epoch 01531: val_loss did not improve from 1.29186
Epoch 1532/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4140 - val_loss: 1.2982 - val_accuracy: 0.4187

Epoch 01532: val_loss did not improve from 1.29186
Epoch 1533/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4063 - val_loss: 1.2944 - val_accuracy: 0.4258

Epoch 01533: val_loss did not improve from 1.29186
Epoch 1534/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4129 - val_loss: 1.2965 - val_accuracy: 0.4139

Epoch 01534: val_loss did not improve from 1.29186
Epoch 1535/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4101 - val_loss: 1.2967 - val_accuracy: 0.4179

Epoch 01535: val_loss did not improve from 1.29186
Epoch 1536/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4153 - val_loss: 1.2952 - val_accuracy: 0.4171

Epoch 01536: val_loss did not improve from 1.29186
Epoch 1537/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4125 - val_loss: 1.2929 - val_accuracy: 0.4226

Epoch 01537: val_loss did not improve from 1.29186
Epoch 1538/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4101 - val_loss: 1.2954 - val_accuracy: 0.4250

Epoch 01538: val_loss did not improve from 1.29186
Epoch 1539/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4108 - val_loss: 1.2956 - val_accuracy: 0.4203

Epoch 01539: val_loss did not improve from 1.29186
Epoch 1540/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4149 - val_loss: 1.3005 - val_accuracy: 0.4211

Epoch 01540: val_loss did not improve from 1.29186
Epoch 1541/10000
12/12 - 0s - loss: 1.2929 - accuracy: 0.4076 - val_loss: 1.2956 - val_accuracy: 0.4211

Epoch 01541: val_loss did not improve from 1.29186
Epoch 1542/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4126 - val_loss: 1.2940 - val_accuracy: 0.4338

Epoch 01542: val_loss did not improve from 1.29186
Epoch 1543/10000
12/12 - 0s - loss: 1.2891 - accuracy: 0.4123 - val_loss: 1.2933 - val_accuracy: 0.4234

Epoch 01543: val_loss did not improve from 1.29186
Epoch 1544/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4152 - val_loss: 1.2956 - val_accuracy: 0.4234

Epoch 01544: val_loss did not improve from 1.29186
Epoch 1545/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4155 - val_loss: 1.2946 - val_accuracy: 0.4370

Epoch 01545: val_loss did not improve from 1.29186
Epoch 1546/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4149 - val_loss: 1.2949 - val_accuracy: 0.4298

Epoch 01546: val_loss did not improve from 1.29186
Epoch 1547/10000
12/12 - 0s - loss: 1.2900 - accuracy: 0.4115 - val_loss: 1.2948 - val_accuracy: 0.4258

Epoch 01547: val_loss did not improve from 1.29186
Epoch 1548/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4160 - val_loss: 1.2934 - val_accuracy: 0.4203

Epoch 01548: val_loss did not improve from 1.29186
Epoch 1549/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4096 - val_loss: 1.2942 - val_accuracy: 0.4322

Epoch 01549: val_loss did not improve from 1.29186
Epoch 1550/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4117 - val_loss: 1.2942 - val_accuracy: 0.4282

Epoch 01550: val_loss did not improve from 1.29186
Epoch 1551/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4141 - val_loss: 1.2935 - val_accuracy: 0.4330

Epoch 01551: val_loss did not improve from 1.29186
Epoch 1552/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4125 - val_loss: 1.2947 - val_accuracy: 0.4155

Epoch 01552: val_loss did not improve from 1.29186
Epoch 1553/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4138 - val_loss: 1.2936 - val_accuracy: 0.4266

Epoch 01553: val_loss did not improve from 1.29186
Epoch 1554/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4134 - val_loss: 1.2939 - val_accuracy: 0.4211

Epoch 01554: val_loss did not improve from 1.29186
Epoch 1555/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4099 - val_loss: 1.2980 - val_accuracy: 0.4179

Epoch 01555: val_loss did not improve from 1.29186
Epoch 1556/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4134 - val_loss: 1.2928 - val_accuracy: 0.4266

Epoch 01556: val_loss did not improve from 1.29186
Epoch 1557/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4074 - val_loss: 1.2939 - val_accuracy: 0.4250

Epoch 01557: val_loss did not improve from 1.29186
Epoch 1558/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4108 - val_loss: 1.2937 - val_accuracy: 0.4234

Epoch 01558: val_loss did not improve from 1.29186
Epoch 1559/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4147 - val_loss: 1.2929 - val_accuracy: 0.4242

Epoch 01559: val_loss did not improve from 1.29186
Epoch 1560/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4119 - val_loss: 1.2986 - val_accuracy: 0.4234

Epoch 01560: val_loss did not improve from 1.29186
Epoch 1561/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4143 - val_loss: 1.2930 - val_accuracy: 0.4155

Epoch 01561: val_loss did not improve from 1.29186
Epoch 1562/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4156 - val_loss: 1.2946 - val_accuracy: 0.4211

Epoch 01562: val_loss did not improve from 1.29186
Epoch 1563/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4140 - val_loss: 1.2952 - val_accuracy: 0.4203

Epoch 01563: val_loss did not improve from 1.29186
Epoch 1564/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4120 - val_loss: 1.2942 - val_accuracy: 0.4314

Epoch 01564: val_loss did not improve from 1.29186
Epoch 1565/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4119 - val_loss: 1.2949 - val_accuracy: 0.4258

Epoch 01565: val_loss did not improve from 1.29186
Epoch 1566/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4083 - val_loss: 1.2949 - val_accuracy: 0.4274

Epoch 01566: val_loss did not improve from 1.29186
Epoch 1567/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4139 - val_loss: 1.2933 - val_accuracy: 0.4282

Epoch 01567: val_loss did not improve from 1.29186
Epoch 1568/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4142 - val_loss: 1.2962 - val_accuracy: 0.4266

Epoch 01568: val_loss did not improve from 1.29186
Epoch 1569/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4119 - val_loss: 1.2945 - val_accuracy: 0.4330

Epoch 01569: val_loss did not improve from 1.29186
Epoch 1570/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4094 - val_loss: 1.2962 - val_accuracy: 0.4187

Epoch 01570: val_loss did not improve from 1.29186
Epoch 1571/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4117 - val_loss: 1.2940 - val_accuracy: 0.4171

Epoch 01571: val_loss did not improve from 1.29186
Epoch 1572/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4101 - val_loss: 1.2942 - val_accuracy: 0.4282

Epoch 01572: val_loss did not improve from 1.29186
Epoch 1573/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4152 - val_loss: 1.2928 - val_accuracy: 0.4258

Epoch 01573: val_loss did not improve from 1.29186
Epoch 1574/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4180 - val_loss: 1.2966 - val_accuracy: 0.4234

Epoch 01574: val_loss did not improve from 1.29186
Epoch 1575/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4117 - val_loss: 1.2932 - val_accuracy: 0.4211

Epoch 01575: val_loss did not improve from 1.29186
Epoch 1576/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4109 - val_loss: 1.2936 - val_accuracy: 0.4203

Epoch 01576: val_loss did not improve from 1.29186
Epoch 1577/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4124 - val_loss: 1.2930 - val_accuracy: 0.4266

Epoch 01577: val_loss did not improve from 1.29186
Epoch 1578/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4148 - val_loss: 1.2932 - val_accuracy: 0.4266

Epoch 01578: val_loss did not improve from 1.29186
Epoch 1579/10000
12/12 - 0s - loss: 1.2896 - accuracy: 0.4139 - val_loss: 1.2938 - val_accuracy: 0.4187

Epoch 01579: val_loss did not improve from 1.29186
Epoch 1580/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4117 - val_loss: 1.2934 - val_accuracy: 0.4266

Epoch 01580: val_loss did not improve from 1.29186
Epoch 1581/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4096 - val_loss: 1.2934 - val_accuracy: 0.4266

Epoch 01581: val_loss did not improve from 1.29186
Epoch 1582/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4109 - val_loss: 1.2919 - val_accuracy: 0.4163

Epoch 01582: val_loss did not improve from 1.29186
Epoch 1583/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4138 - val_loss: 1.2925 - val_accuracy: 0.4234

Epoch 01583: val_loss did not improve from 1.29186
Epoch 1584/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4165 - val_loss: 1.2990 - val_accuracy: 0.4242

Epoch 01584: val_loss did not improve from 1.29186
Epoch 1585/10000
12/12 - 0s - loss: 1.2967 - accuracy: 0.4134 - val_loss: 1.2979 - val_accuracy: 0.4163

Epoch 01585: val_loss did not improve from 1.29186
Epoch 1586/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4071 - val_loss: 1.2953 - val_accuracy: 0.4226

Epoch 01586: val_loss did not improve from 1.29186
Epoch 1587/10000
12/12 - 0s - loss: 1.2883 - accuracy: 0.4108 - val_loss: 1.2927 - val_accuracy: 0.4330

Epoch 01587: val_loss did not improve from 1.29186
Epoch 1588/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4160 - val_loss: 1.2928 - val_accuracy: 0.4234

Epoch 01588: val_loss did not improve from 1.29186
Epoch 1589/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4102 - val_loss: 1.2952 - val_accuracy: 0.4203

Epoch 01589: val_loss did not improve from 1.29186
Epoch 1590/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4112 - val_loss: 1.2939 - val_accuracy: 0.4242

Epoch 01590: val_loss did not improve from 1.29186
Epoch 1591/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4060 - val_loss: 1.2921 - val_accuracy: 0.4338

Epoch 01591: val_loss did not improve from 1.29186
Epoch 1592/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4133 - val_loss: 1.2919 - val_accuracy: 0.4219

Epoch 01592: val_loss did not improve from 1.29186
Epoch 1593/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4125 - val_loss: 1.2907 - val_accuracy: 0.4274

Epoch 01593: val_loss improved from 1.29186 to 1.29075, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1594/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4152 - val_loss: 1.2923 - val_accuracy: 0.4226

Epoch 01594: val_loss did not improve from 1.29075
Epoch 1595/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4081 - val_loss: 1.2944 - val_accuracy: 0.4211

Epoch 01595: val_loss did not improve from 1.29075
Epoch 1596/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4104 - val_loss: 1.2971 - val_accuracy: 0.4179

Epoch 01596: val_loss did not improve from 1.29075
Epoch 1597/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4131 - val_loss: 1.2956 - val_accuracy: 0.4242

Epoch 01597: val_loss did not improve from 1.29075
Epoch 1598/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4147 - val_loss: 1.2916 - val_accuracy: 0.4195

Epoch 01598: val_loss did not improve from 1.29075
Epoch 1599/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4156 - val_loss: 1.2912 - val_accuracy: 0.4242

Epoch 01599: val_loss did not improve from 1.29075
Epoch 1600/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4158 - val_loss: 1.2931 - val_accuracy: 0.4226

Epoch 01600: val_loss did not improve from 1.29075
Epoch 1601/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4122 - val_loss: 1.2943 - val_accuracy: 0.4179

Epoch 01601: val_loss did not improve from 1.29075
Epoch 1602/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4163 - val_loss: 1.2984 - val_accuracy: 0.4171

Epoch 01602: val_loss did not improve from 1.29075
Epoch 1603/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4118 - val_loss: 1.2922 - val_accuracy: 0.4314

Epoch 01603: val_loss did not improve from 1.29075
Epoch 1604/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4109 - val_loss: 1.2946 - val_accuracy: 0.4282

Epoch 01604: val_loss did not improve from 1.29075
Epoch 1605/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4149 - val_loss: 1.2926 - val_accuracy: 0.4282

Epoch 01605: val_loss did not improve from 1.29075
Epoch 1606/10000
12/12 - 0s - loss: 1.2894 - accuracy: 0.4079 - val_loss: 1.2949 - val_accuracy: 0.4250

Epoch 01606: val_loss did not improve from 1.29075
Epoch 1607/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4146 - val_loss: 1.3110 - val_accuracy: 0.4250

Epoch 01607: val_loss did not improve from 1.29075
Epoch 1608/10000
12/12 - 0s - loss: 1.3006 - accuracy: 0.4055 - val_loss: 1.2944 - val_accuracy: 0.4282

Epoch 01608: val_loss did not improve from 1.29075
Epoch 1609/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4156 - val_loss: 1.3028 - val_accuracy: 0.4091

Epoch 01609: val_loss did not improve from 1.29075
Epoch 1610/10000
12/12 - 0s - loss: 1.2920 - accuracy: 0.4105 - val_loss: 1.2923 - val_accuracy: 0.4266

Epoch 01610: val_loss did not improve from 1.29075
Epoch 1611/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4124 - val_loss: 1.2987 - val_accuracy: 0.4242

Epoch 01611: val_loss did not improve from 1.29075
Epoch 1612/10000
12/12 - 0s - loss: 1.2947 - accuracy: 0.4118 - val_loss: 1.2923 - val_accuracy: 0.4226

Epoch 01612: val_loss did not improve from 1.29075
Epoch 1613/10000
12/12 - 0s - loss: 1.2909 - accuracy: 0.4134 - val_loss: 1.2957 - val_accuracy: 0.4123

Epoch 01613: val_loss did not improve from 1.29075
Epoch 1614/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4114 - val_loss: 1.2944 - val_accuracy: 0.4203

Epoch 01614: val_loss did not improve from 1.29075
Epoch 1615/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4106 - val_loss: 1.2932 - val_accuracy: 0.4250

Epoch 01615: val_loss did not improve from 1.29075
Epoch 1616/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4125 - val_loss: 1.2928 - val_accuracy: 0.4266

Epoch 01616: val_loss did not improve from 1.29075
Epoch 1617/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4148 - val_loss: 1.2919 - val_accuracy: 0.4282

Epoch 01617: val_loss did not improve from 1.29075
Epoch 1618/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4162 - val_loss: 1.2938 - val_accuracy: 0.4298

Epoch 01618: val_loss did not improve from 1.29075
Epoch 1619/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4153 - val_loss: 1.2925 - val_accuracy: 0.4282

Epoch 01619: val_loss did not improve from 1.29075
Epoch 1620/10000
12/12 - 0s - loss: 1.2906 - accuracy: 0.4076 - val_loss: 1.2952 - val_accuracy: 0.4234

Epoch 01620: val_loss did not improve from 1.29075
Epoch 1621/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4139 - val_loss: 1.2954 - val_accuracy: 0.4187

Epoch 01621: val_loss did not improve from 1.29075
Epoch 1622/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4151 - val_loss: 1.2942 - val_accuracy: 0.4219

Epoch 01622: val_loss did not improve from 1.29075
Epoch 1623/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4073 - val_loss: 1.2939 - val_accuracy: 0.4234

Epoch 01623: val_loss did not improve from 1.29075
Epoch 1624/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4125 - val_loss: 1.2926 - val_accuracy: 0.4211

Epoch 01624: val_loss did not improve from 1.29075
Epoch 1625/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4164 - val_loss: 1.2954 - val_accuracy: 0.4266

Epoch 01625: val_loss did not improve from 1.29075
Epoch 1626/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4147 - val_loss: 1.2915 - val_accuracy: 0.4258

Epoch 01626: val_loss did not improve from 1.29075
Epoch 1627/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4142 - val_loss: 1.2913 - val_accuracy: 0.4195

Epoch 01627: val_loss did not improve from 1.29075
Epoch 1628/10000
12/12 - 0s - loss: 1.2866 - accuracy: 0.4194 - val_loss: 1.2922 - val_accuracy: 0.4203

Epoch 01628: val_loss did not improve from 1.29075
Epoch 1629/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4134 - val_loss: 1.2917 - val_accuracy: 0.4258

Epoch 01629: val_loss did not improve from 1.29075
Epoch 1630/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4120 - val_loss: 1.2925 - val_accuracy: 0.4306

Epoch 01630: val_loss did not improve from 1.29075
Epoch 1631/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4122 - val_loss: 1.2921 - val_accuracy: 0.4290

Epoch 01631: val_loss did not improve from 1.29075
Epoch 1632/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4140 - val_loss: 1.2905 - val_accuracy: 0.4266

Epoch 01632: val_loss improved from 1.29075 to 1.29050, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1633/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4134 - val_loss: 1.2923 - val_accuracy: 0.4219

Epoch 01633: val_loss did not improve from 1.29050
Epoch 1634/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4132 - val_loss: 1.2923 - val_accuracy: 0.4211

Epoch 01634: val_loss did not improve from 1.29050
Epoch 1635/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4120 - val_loss: 1.2915 - val_accuracy: 0.4203

Epoch 01635: val_loss did not improve from 1.29050
Epoch 1636/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4138 - val_loss: 1.2915 - val_accuracy: 0.4242

Epoch 01636: val_loss did not improve from 1.29050
Epoch 1637/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4154 - val_loss: 1.2917 - val_accuracy: 0.4234

Epoch 01637: val_loss did not improve from 1.29050
Epoch 1638/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4138 - val_loss: 1.2922 - val_accuracy: 0.4266

Epoch 01638: val_loss did not improve from 1.29050
Epoch 1639/10000
12/12 - 0s - loss: 1.2884 - accuracy: 0.4161 - val_loss: 1.2917 - val_accuracy: 0.4274

Epoch 01639: val_loss did not improve from 1.29050
Epoch 1640/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4124 - val_loss: 1.2946 - val_accuracy: 0.4211

Epoch 01640: val_loss did not improve from 1.29050
Epoch 1641/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4106 - val_loss: 1.2911 - val_accuracy: 0.4203

Epoch 01641: val_loss did not improve from 1.29050
Epoch 1642/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4167 - val_loss: 1.2925 - val_accuracy: 0.4219

Epoch 01642: val_loss did not improve from 1.29050
Epoch 1643/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4131 - val_loss: 1.2935 - val_accuracy: 0.4163

Epoch 01643: val_loss did not improve from 1.29050
Epoch 1644/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4120 - val_loss: 1.2922 - val_accuracy: 0.4163

Epoch 01644: val_loss did not improve from 1.29050
Epoch 1645/10000
12/12 - 0s - loss: 1.2889 - accuracy: 0.4127 - val_loss: 1.2924 - val_accuracy: 0.4211

Epoch 01645: val_loss did not improve from 1.29050
Epoch 1646/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4152 - val_loss: 1.2942 - val_accuracy: 0.4219

Epoch 01646: val_loss did not improve from 1.29050
Epoch 1647/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4140 - val_loss: 1.2925 - val_accuracy: 0.4242

Epoch 01647: val_loss did not improve from 1.29050
Epoch 1648/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4107 - val_loss: 1.2940 - val_accuracy: 0.4274

Epoch 01648: val_loss did not improve from 1.29050
Epoch 1649/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4157 - val_loss: 1.2914 - val_accuracy: 0.4282

Epoch 01649: val_loss did not improve from 1.29050
Epoch 1650/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4112 - val_loss: 1.2922 - val_accuracy: 0.4266

Epoch 01650: val_loss did not improve from 1.29050
Epoch 1651/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4141 - val_loss: 1.2913 - val_accuracy: 0.4274

Epoch 01651: val_loss did not improve from 1.29050
Epoch 1652/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4113 - val_loss: 1.2921 - val_accuracy: 0.4219

Epoch 01652: val_loss did not improve from 1.29050
Epoch 1653/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4140 - val_loss: 1.2905 - val_accuracy: 0.4274

Epoch 01653: val_loss improved from 1.29050 to 1.29050, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1654/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4121 - val_loss: 1.2937 - val_accuracy: 0.4219

Epoch 01654: val_loss did not improve from 1.29050
Epoch 1655/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4146 - val_loss: 1.2913 - val_accuracy: 0.4211

Epoch 01655: val_loss did not improve from 1.29050
Epoch 1656/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4148 - val_loss: 1.2906 - val_accuracy: 0.4274

Epoch 01656: val_loss did not improve from 1.29050
Epoch 1657/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4115 - val_loss: 1.2916 - val_accuracy: 0.4298

Epoch 01657: val_loss did not improve from 1.29050
Epoch 1658/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4129 - val_loss: 1.2916 - val_accuracy: 0.4219

Epoch 01658: val_loss did not improve from 1.29050
Epoch 1659/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4128 - val_loss: 1.2915 - val_accuracy: 0.4274

Epoch 01659: val_loss did not improve from 1.29050
Epoch 1660/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4134 - val_loss: 1.2916 - val_accuracy: 0.4211

Epoch 01660: val_loss did not improve from 1.29050
Epoch 1661/10000
12/12 - 0s - loss: 1.2873 - accuracy: 0.4145 - val_loss: 1.2935 - val_accuracy: 0.4219

Epoch 01661: val_loss did not improve from 1.29050
Epoch 1662/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4159 - val_loss: 1.2948 - val_accuracy: 0.4187

Epoch 01662: val_loss did not improve from 1.29050
Epoch 1663/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4156 - val_loss: 1.2910 - val_accuracy: 0.4171

Epoch 01663: val_loss did not improve from 1.29050
Epoch 1664/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4157 - val_loss: 1.2924 - val_accuracy: 0.4258

Epoch 01664: val_loss did not improve from 1.29050
Epoch 1665/10000
12/12 - 0s - loss: 1.2888 - accuracy: 0.4107 - val_loss: 1.2941 - val_accuracy: 0.4258

Epoch 01665: val_loss did not improve from 1.29050
Epoch 1666/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4112 - val_loss: 1.2990 - val_accuracy: 0.4282

Epoch 01666: val_loss did not improve from 1.29050
Epoch 1667/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4131 - val_loss: 1.2967 - val_accuracy: 0.4242

Epoch 01667: val_loss did not improve from 1.29050
Epoch 1668/10000
12/12 - 0s - loss: 1.2887 - accuracy: 0.4139 - val_loss: 1.2935 - val_accuracy: 0.4258

Epoch 01668: val_loss did not improve from 1.29050
Epoch 1669/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4126 - val_loss: 1.2945 - val_accuracy: 0.4203

Epoch 01669: val_loss did not improve from 1.29050
Epoch 1670/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4145 - val_loss: 1.2924 - val_accuracy: 0.4171

Epoch 01670: val_loss did not improve from 1.29050
Epoch 1671/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4144 - val_loss: 1.2905 - val_accuracy: 0.4290

Epoch 01671: val_loss improved from 1.29050 to 1.29045, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1672/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4164 - val_loss: 1.2914 - val_accuracy: 0.4187

Epoch 01672: val_loss did not improve from 1.29045
Epoch 1673/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4158 - val_loss: 1.2940 - val_accuracy: 0.4139

Epoch 01673: val_loss did not improve from 1.29045
Epoch 1674/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4125 - val_loss: 1.2898 - val_accuracy: 0.4242

Epoch 01674: val_loss improved from 1.29045 to 1.28978, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1675/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4151 - val_loss: 1.2901 - val_accuracy: 0.4242

Epoch 01675: val_loss did not improve from 1.28978
Epoch 1676/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4152 - val_loss: 1.2926 - val_accuracy: 0.4203

Epoch 01676: val_loss did not improve from 1.28978
Epoch 1677/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4139 - val_loss: 1.2924 - val_accuracy: 0.4187

Epoch 01677: val_loss did not improve from 1.28978
Epoch 1678/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4150 - val_loss: 1.2903 - val_accuracy: 0.4234

Epoch 01678: val_loss did not improve from 1.28978
Epoch 1679/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4081 - val_loss: 1.2945 - val_accuracy: 0.4179

Epoch 01679: val_loss did not improve from 1.28978
Epoch 1680/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4148 - val_loss: 1.2905 - val_accuracy: 0.4187

Epoch 01680: val_loss did not improve from 1.28978
Epoch 1681/10000
12/12 - 0s - loss: 1.2867 - accuracy: 0.4132 - val_loss: 1.2936 - val_accuracy: 0.4226

Epoch 01681: val_loss did not improve from 1.28978
Epoch 1682/10000
12/12 - 0s - loss: 1.2877 - accuracy: 0.4150 - val_loss: 1.2913 - val_accuracy: 0.4203

Epoch 01682: val_loss did not improve from 1.28978
Epoch 1683/10000
12/12 - 0s - loss: 1.2978 - accuracy: 0.4129 - val_loss: 1.3032 - val_accuracy: 0.4051

Epoch 01683: val_loss did not improve from 1.28978
Epoch 1684/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4109 - val_loss: 1.3018 - val_accuracy: 0.4139

Epoch 01684: val_loss did not improve from 1.28978
Epoch 1685/10000
12/12 - 0s - loss: 1.2933 - accuracy: 0.4127 - val_loss: 1.2948 - val_accuracy: 0.4250

Epoch 01685: val_loss did not improve from 1.28978
Epoch 1686/10000
12/12 - 0s - loss: 1.2899 - accuracy: 0.4130 - val_loss: 1.2992 - val_accuracy: 0.4314

Epoch 01686: val_loss did not improve from 1.28978
Epoch 1687/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4150 - val_loss: 1.2914 - val_accuracy: 0.4290

Epoch 01687: val_loss did not improve from 1.28978
Epoch 1688/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4159 - val_loss: 1.2923 - val_accuracy: 0.4274

Epoch 01688: val_loss did not improve from 1.28978
Epoch 1689/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4159 - val_loss: 1.2927 - val_accuracy: 0.4282

Epoch 01689: val_loss did not improve from 1.28978
Epoch 1690/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4140 - val_loss: 1.2940 - val_accuracy: 0.4242

Epoch 01690: val_loss did not improve from 1.28978
Epoch 1691/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4119 - val_loss: 1.2922 - val_accuracy: 0.4258

Epoch 01691: val_loss did not improve from 1.28978
Epoch 1692/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4155 - val_loss: 1.2909 - val_accuracy: 0.4226

Epoch 01692: val_loss did not improve from 1.28978
Epoch 1693/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4114 - val_loss: 1.2927 - val_accuracy: 0.4322

Epoch 01693: val_loss did not improve from 1.28978
Epoch 1694/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4163 - val_loss: 1.2907 - val_accuracy: 0.4330

Epoch 01694: val_loss did not improve from 1.28978
Epoch 1695/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4120 - val_loss: 1.2921 - val_accuracy: 0.4266

Epoch 01695: val_loss did not improve from 1.28978
Epoch 1696/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4174 - val_loss: 1.2912 - val_accuracy: 0.4266

Epoch 01696: val_loss did not improve from 1.28978
Epoch 1697/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4135 - val_loss: 1.2930 - val_accuracy: 0.4322

Epoch 01697: val_loss did not improve from 1.28978
Epoch 1698/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4152 - val_loss: 1.2907 - val_accuracy: 0.4274

Epoch 01698: val_loss did not improve from 1.28978
Epoch 1699/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4158 - val_loss: 1.2907 - val_accuracy: 0.4219

Epoch 01699: val_loss did not improve from 1.28978
Epoch 1700/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4152 - val_loss: 1.2916 - val_accuracy: 0.4219

Epoch 01700: val_loss did not improve from 1.28978
Epoch 1701/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4141 - val_loss: 1.2928 - val_accuracy: 0.4219

Epoch 01701: val_loss did not improve from 1.28978
Epoch 1702/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4144 - val_loss: 1.2941 - val_accuracy: 0.4226

Epoch 01702: val_loss did not improve from 1.28978
Epoch 1703/10000
12/12 - 0s - loss: 1.2868 - accuracy: 0.4118 - val_loss: 1.2931 - val_accuracy: 0.4211

Epoch 01703: val_loss did not improve from 1.28978
Epoch 1704/10000
12/12 - 0s - loss: 1.2886 - accuracy: 0.4130 - val_loss: 1.2931 - val_accuracy: 0.4274

Epoch 01704: val_loss did not improve from 1.28978
Epoch 1705/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4125 - val_loss: 1.2924 - val_accuracy: 0.4211

Epoch 01705: val_loss did not improve from 1.28978
Epoch 1706/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4172 - val_loss: 1.2914 - val_accuracy: 0.4219

Epoch 01706: val_loss did not improve from 1.28978
Epoch 1707/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4117 - val_loss: 1.2916 - val_accuracy: 0.4171

Epoch 01707: val_loss did not improve from 1.28978
Epoch 1708/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4156 - val_loss: 1.2909 - val_accuracy: 0.4219

Epoch 01708: val_loss did not improve from 1.28978
Epoch 1709/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4177 - val_loss: 1.2905 - val_accuracy: 0.4226

Epoch 01709: val_loss did not improve from 1.28978
Epoch 1710/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4162 - val_loss: 1.2916 - val_accuracy: 0.4234

Epoch 01710: val_loss did not improve from 1.28978
Epoch 1711/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4145 - val_loss: 1.2964 - val_accuracy: 0.4195

Epoch 01711: val_loss did not improve from 1.28978
Epoch 1712/10000
12/12 - 0s - loss: 1.2911 - accuracy: 0.4088 - val_loss: 1.2923 - val_accuracy: 0.4211

Epoch 01712: val_loss did not improve from 1.28978
Epoch 1713/10000
12/12 - 0s - loss: 1.2905 - accuracy: 0.4167 - val_loss: 1.2919 - val_accuracy: 0.4386

Epoch 01713: val_loss did not improve from 1.28978
Epoch 1714/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4118 - val_loss: 1.2934 - val_accuracy: 0.4250

Epoch 01714: val_loss did not improve from 1.28978
Epoch 1715/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4100 - val_loss: 1.2936 - val_accuracy: 0.4171

Epoch 01715: val_loss did not improve from 1.28978
Epoch 1716/10000
12/12 - 0s - loss: 1.2901 - accuracy: 0.4128 - val_loss: 1.2950 - val_accuracy: 0.4203

Epoch 01716: val_loss did not improve from 1.28978
Epoch 1717/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4121 - val_loss: 1.2927 - val_accuracy: 0.4234

Epoch 01717: val_loss did not improve from 1.28978
Epoch 1718/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4158 - val_loss: 1.2939 - val_accuracy: 0.4282

Epoch 01718: val_loss did not improve from 1.28978
Epoch 1719/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4156 - val_loss: 1.2961 - val_accuracy: 0.4131

Epoch 01719: val_loss did not improve from 1.28978
Epoch 1720/10000
12/12 - 0s - loss: 1.2885 - accuracy: 0.4124 - val_loss: 1.2928 - val_accuracy: 0.4250

Epoch 01720: val_loss did not improve from 1.28978
Epoch 1721/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4129 - val_loss: 1.2919 - val_accuracy: 0.4242

Epoch 01721: val_loss did not improve from 1.28978
Epoch 1722/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4144 - val_loss: 1.2901 - val_accuracy: 0.4282

Epoch 01722: val_loss did not improve from 1.28978
Epoch 1723/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4172 - val_loss: 1.2905 - val_accuracy: 0.4242

Epoch 01723: val_loss did not improve from 1.28978
Epoch 1724/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4151 - val_loss: 1.2932 - val_accuracy: 0.4195

Epoch 01724: val_loss did not improve from 1.28978
Epoch 1725/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4131 - val_loss: 1.2914 - val_accuracy: 0.4211

Epoch 01725: val_loss did not improve from 1.28978
Epoch 1726/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4153 - val_loss: 1.2904 - val_accuracy: 0.4219

Epoch 01726: val_loss did not improve from 1.28978
Epoch 1727/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4165 - val_loss: 1.2898 - val_accuracy: 0.4282

Epoch 01727: val_loss improved from 1.28978 to 1.28978, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1728/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4159 - val_loss: 1.2965 - val_accuracy: 0.4306

Epoch 01728: val_loss did not improve from 1.28978
Epoch 1729/10000
12/12 - 0s - loss: 1.2945 - accuracy: 0.4100 - val_loss: 1.3040 - val_accuracy: 0.4075

Epoch 01729: val_loss did not improve from 1.28978
Epoch 1730/10000
12/12 - 0s - loss: 1.2914 - accuracy: 0.4110 - val_loss: 1.2918 - val_accuracy: 0.4258

Epoch 01730: val_loss did not improve from 1.28978
Epoch 1731/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4059 - val_loss: 1.2915 - val_accuracy: 0.4219

Epoch 01731: val_loss did not improve from 1.28978
Epoch 1732/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4166 - val_loss: 1.2919 - val_accuracy: 0.4195

Epoch 01732: val_loss did not improve from 1.28978
Epoch 1733/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4149 - val_loss: 1.2916 - val_accuracy: 0.4314

Epoch 01733: val_loss did not improve from 1.28978
Epoch 1734/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4160 - val_loss: 1.2918 - val_accuracy: 0.4258

Epoch 01734: val_loss did not improve from 1.28978
Epoch 1735/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4119 - val_loss: 1.2973 - val_accuracy: 0.4298

Epoch 01735: val_loss did not improve from 1.28978
Epoch 1736/10000
12/12 - 0s - loss: 1.2917 - accuracy: 0.4137 - val_loss: 1.2895 - val_accuracy: 0.4258

Epoch 01736: val_loss improved from 1.28978 to 1.28949, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1737/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4159 - val_loss: 1.2913 - val_accuracy: 0.4211

Epoch 01737: val_loss did not improve from 1.28949
Epoch 1738/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4168 - val_loss: 1.2930 - val_accuracy: 0.4242

Epoch 01738: val_loss did not improve from 1.28949
Epoch 1739/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4129 - val_loss: 1.2946 - val_accuracy: 0.4147

Epoch 01739: val_loss did not improve from 1.28949
Epoch 1740/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4158 - val_loss: 1.2913 - val_accuracy: 0.4282

Epoch 01740: val_loss did not improve from 1.28949
Epoch 1741/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4123 - val_loss: 1.2928 - val_accuracy: 0.4226

Epoch 01741: val_loss did not improve from 1.28949
Epoch 1742/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4178 - val_loss: 1.2925 - val_accuracy: 0.4258

Epoch 01742: val_loss did not improve from 1.28949
Epoch 1743/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4145 - val_loss: 1.2927 - val_accuracy: 0.4163

Epoch 01743: val_loss did not improve from 1.28949
Epoch 1744/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4133 - val_loss: 1.2917 - val_accuracy: 0.4346

Epoch 01744: val_loss did not improve from 1.28949
Epoch 1745/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4109 - val_loss: 1.2912 - val_accuracy: 0.4250

Epoch 01745: val_loss did not improve from 1.28949
Epoch 1746/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4169 - val_loss: 1.2918 - val_accuracy: 0.4226

Epoch 01746: val_loss did not improve from 1.28949
Epoch 1747/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4162 - val_loss: 1.2944 - val_accuracy: 0.4226

Epoch 01747: val_loss did not improve from 1.28949
Epoch 1748/10000
12/12 - 0s - loss: 1.2871 - accuracy: 0.4163 - val_loss: 1.2905 - val_accuracy: 0.4234

Epoch 01748: val_loss did not improve from 1.28949
Epoch 1749/10000
12/12 - 0s - loss: 1.2863 - accuracy: 0.4117 - val_loss: 1.2920 - val_accuracy: 0.4211

Epoch 01749: val_loss did not improve from 1.28949
Epoch 1750/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4150 - val_loss: 1.2897 - val_accuracy: 0.4250

Epoch 01750: val_loss did not improve from 1.28949
Epoch 1751/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4128 - val_loss: 1.2914 - val_accuracy: 0.4163

Epoch 01751: val_loss did not improve from 1.28949
Epoch 1752/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4123 - val_loss: 1.2896 - val_accuracy: 0.4306

Epoch 01752: val_loss did not improve from 1.28949
Epoch 1753/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4155 - val_loss: 1.2943 - val_accuracy: 0.4131

Epoch 01753: val_loss did not improve from 1.28949
Epoch 1754/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4180 - val_loss: 1.2949 - val_accuracy: 0.4258

Epoch 01754: val_loss did not improve from 1.28949
Epoch 1755/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4156 - val_loss: 1.2910 - val_accuracy: 0.4203

Epoch 01755: val_loss did not improve from 1.28949
Epoch 1756/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4158 - val_loss: 1.2915 - val_accuracy: 0.4195

Epoch 01756: val_loss did not improve from 1.28949
Epoch 1757/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4133 - val_loss: 1.2904 - val_accuracy: 0.4242

Epoch 01757: val_loss did not improve from 1.28949
Epoch 1758/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4182 - val_loss: 1.2915 - val_accuracy: 0.4203

Epoch 01758: val_loss did not improve from 1.28949
Epoch 1759/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4111 - val_loss: 1.2928 - val_accuracy: 0.4250

Epoch 01759: val_loss did not improve from 1.28949
Epoch 1760/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4134 - val_loss: 1.2903 - val_accuracy: 0.4306

Epoch 01760: val_loss did not improve from 1.28949
Epoch 1761/10000
12/12 - 0s - loss: 1.2864 - accuracy: 0.4140 - val_loss: 1.2967 - val_accuracy: 0.4155

Epoch 01761: val_loss did not improve from 1.28949
Epoch 1762/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4132 - val_loss: 1.2908 - val_accuracy: 0.4274

Epoch 01762: val_loss did not improve from 1.28949
Epoch 1763/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4164 - val_loss: 1.2899 - val_accuracy: 0.4226

Epoch 01763: val_loss did not improve from 1.28949
Epoch 1764/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4153 - val_loss: 1.2911 - val_accuracy: 0.4211

Epoch 01764: val_loss did not improve from 1.28949
Epoch 1765/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4161 - val_loss: 1.2905 - val_accuracy: 0.4290

Epoch 01765: val_loss did not improve from 1.28949
Epoch 1766/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4189 - val_loss: 1.2954 - val_accuracy: 0.4139

Epoch 01766: val_loss did not improve from 1.28949
Epoch 1767/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4132 - val_loss: 1.2933 - val_accuracy: 0.4195

Epoch 01767: val_loss did not improve from 1.28949
Epoch 1768/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4170 - val_loss: 1.2906 - val_accuracy: 0.4211

Epoch 01768: val_loss did not improve from 1.28949
Epoch 1769/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4186 - val_loss: 1.2905 - val_accuracy: 0.4203

Epoch 01769: val_loss did not improve from 1.28949
Epoch 1770/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4168 - val_loss: 1.2911 - val_accuracy: 0.4226

Epoch 01770: val_loss did not improve from 1.28949
Epoch 1771/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4157 - val_loss: 1.2904 - val_accuracy: 0.4298

Epoch 01771: val_loss did not improve from 1.28949
Epoch 1772/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4171 - val_loss: 1.2910 - val_accuracy: 0.4203

Epoch 01772: val_loss did not improve from 1.28949
Epoch 1773/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4132 - val_loss: 1.2928 - val_accuracy: 0.4187

Epoch 01773: val_loss did not improve from 1.28949
Epoch 1774/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4107 - val_loss: 1.2920 - val_accuracy: 0.4234

Epoch 01774: val_loss did not improve from 1.28949
Epoch 1775/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4175 - val_loss: 1.2891 - val_accuracy: 0.4290

Epoch 01775: val_loss improved from 1.28949 to 1.28908, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1776/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4179 - val_loss: 1.2905 - val_accuracy: 0.4258

Epoch 01776: val_loss did not improve from 1.28908
Epoch 1777/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4121 - val_loss: 1.2916 - val_accuracy: 0.4234

Epoch 01777: val_loss did not improve from 1.28908
Epoch 1778/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4157 - val_loss: 1.2930 - val_accuracy: 0.4258

Epoch 01778: val_loss did not improve from 1.28908
Epoch 1779/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4119 - val_loss: 1.2933 - val_accuracy: 0.4163

Epoch 01779: val_loss did not improve from 1.28908
Epoch 1780/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4151 - val_loss: 1.2915 - val_accuracy: 0.4211

Epoch 01780: val_loss did not improve from 1.28908
Epoch 1781/10000
12/12 - 0s - loss: 1.2893 - accuracy: 0.4105 - val_loss: 1.2928 - val_accuracy: 0.4266

Epoch 01781: val_loss did not improve from 1.28908
Epoch 1782/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4119 - val_loss: 1.2916 - val_accuracy: 0.4171

Epoch 01782: val_loss did not improve from 1.28908
Epoch 1783/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4120 - val_loss: 1.2921 - val_accuracy: 0.4171

Epoch 01783: val_loss did not improve from 1.28908
Epoch 1784/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4151 - val_loss: 1.2920 - val_accuracy: 0.4250

Epoch 01784: val_loss did not improve from 1.28908
Epoch 1785/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4156 - val_loss: 1.2905 - val_accuracy: 0.4219

Epoch 01785: val_loss did not improve from 1.28908
Epoch 1786/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4125 - val_loss: 1.3096 - val_accuracy: 0.4226

Epoch 01786: val_loss did not improve from 1.28908
Epoch 1787/10000
12/12 - 0s - loss: 1.2960 - accuracy: 0.4084 - val_loss: 1.2893 - val_accuracy: 0.4346

Epoch 01787: val_loss did not improve from 1.28908
Epoch 1788/10000
12/12 - 0s - loss: 1.2998 - accuracy: 0.4101 - val_loss: 1.3049 - val_accuracy: 0.4099

Epoch 01788: val_loss did not improve from 1.28908
Epoch 1789/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4133 - val_loss: 1.2913 - val_accuracy: 0.4179

Epoch 01789: val_loss did not improve from 1.28908
Epoch 1790/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4159 - val_loss: 1.2914 - val_accuracy: 0.4266

Epoch 01790: val_loss did not improve from 1.28908
Epoch 1791/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4172 - val_loss: 1.2905 - val_accuracy: 0.4155

Epoch 01791: val_loss did not improve from 1.28908
Epoch 1792/10000
12/12 - 0s - loss: 1.2876 - accuracy: 0.4148 - val_loss: 1.2912 - val_accuracy: 0.4187

Epoch 01792: val_loss did not improve from 1.28908
Epoch 1793/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4167 - val_loss: 1.2917 - val_accuracy: 0.4226

Epoch 01793: val_loss did not improve from 1.28908
Epoch 1794/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4156 - val_loss: 1.2923 - val_accuracy: 0.4226

Epoch 01794: val_loss did not improve from 1.28908
Epoch 1795/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4168 - val_loss: 1.2899 - val_accuracy: 0.4282

Epoch 01795: val_loss did not improve from 1.28908
Epoch 1796/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4152 - val_loss: 1.2903 - val_accuracy: 0.4258

Epoch 01796: val_loss did not improve from 1.28908
Epoch 1797/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4124 - val_loss: 1.2910 - val_accuracy: 0.4195

Epoch 01797: val_loss did not improve from 1.28908
Epoch 1798/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4179 - val_loss: 1.2901 - val_accuracy: 0.4282

Epoch 01798: val_loss did not improve from 1.28908
Epoch 1799/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4169 - val_loss: 1.2897 - val_accuracy: 0.4234

Epoch 01799: val_loss did not improve from 1.28908
Epoch 1800/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4140 - val_loss: 1.2909 - val_accuracy: 0.4187

Epoch 01800: val_loss did not improve from 1.28908
Epoch 1801/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4172 - val_loss: 1.2904 - val_accuracy: 0.4226

Epoch 01801: val_loss did not improve from 1.28908
Epoch 1802/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4193 - val_loss: 1.2908 - val_accuracy: 0.4195

Epoch 01802: val_loss did not improve from 1.28908
Epoch 1803/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4178 - val_loss: 1.2911 - val_accuracy: 0.4171

Epoch 01803: val_loss did not improve from 1.28908
Epoch 1804/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4143 - val_loss: 1.2902 - val_accuracy: 0.4306

Epoch 01804: val_loss did not improve from 1.28908
Epoch 1805/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4149 - val_loss: 1.2961 - val_accuracy: 0.4234

Epoch 01805: val_loss did not improve from 1.28908
Epoch 1806/10000
12/12 - 0s - loss: 1.2925 - accuracy: 0.4144 - val_loss: 1.2928 - val_accuracy: 0.4147

Epoch 01806: val_loss did not improve from 1.28908
Epoch 1807/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4129 - val_loss: 1.2936 - val_accuracy: 0.4107

Epoch 01807: val_loss did not improve from 1.28908
Epoch 1808/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4170 - val_loss: 1.2965 - val_accuracy: 0.4187

Epoch 01808: val_loss did not improve from 1.28908
Epoch 1809/10000
12/12 - 0s - loss: 1.2915 - accuracy: 0.4142 - val_loss: 1.2907 - val_accuracy: 0.4266

Epoch 01809: val_loss did not improve from 1.28908
Epoch 1810/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4167 - val_loss: 1.2913 - val_accuracy: 0.4147

Epoch 01810: val_loss did not improve from 1.28908
Epoch 1811/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4132 - val_loss: 1.2904 - val_accuracy: 0.4250

Epoch 01811: val_loss did not improve from 1.28908
Epoch 1812/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4156 - val_loss: 1.2899 - val_accuracy: 0.4226

Epoch 01812: val_loss did not improve from 1.28908
Epoch 1813/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4147 - val_loss: 1.2974 - val_accuracy: 0.4107

Epoch 01813: val_loss did not improve from 1.28908
Epoch 1814/10000
12/12 - 0s - loss: 1.2902 - accuracy: 0.4086 - val_loss: 1.2890 - val_accuracy: 0.4258

Epoch 01814: val_loss improved from 1.28908 to 1.28903, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1815/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4152 - val_loss: 1.2923 - val_accuracy: 0.4282

Epoch 01815: val_loss did not improve from 1.28903
Epoch 1816/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4145 - val_loss: 1.2902 - val_accuracy: 0.4226

Epoch 01816: val_loss did not improve from 1.28903
Epoch 1817/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4155 - val_loss: 1.2908 - val_accuracy: 0.4203

Epoch 01817: val_loss did not improve from 1.28903
Epoch 1818/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4151 - val_loss: 1.2919 - val_accuracy: 0.4242

Epoch 01818: val_loss did not improve from 1.28903
Epoch 1819/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4119 - val_loss: 1.2913 - val_accuracy: 0.4250

Epoch 01819: val_loss did not improve from 1.28903
Epoch 1820/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4157 - val_loss: 1.2910 - val_accuracy: 0.4250

Epoch 01820: val_loss did not improve from 1.28903
Epoch 1821/10000
12/12 - 0s - loss: 1.2879 - accuracy: 0.4117 - val_loss: 1.2976 - val_accuracy: 0.4115

Epoch 01821: val_loss did not improve from 1.28903
Epoch 1822/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4151 - val_loss: 1.2908 - val_accuracy: 0.4242

Epoch 01822: val_loss did not improve from 1.28903
Epoch 1823/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4156 - val_loss: 1.2898 - val_accuracy: 0.4226

Epoch 01823: val_loss did not improve from 1.28903
Epoch 1824/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4139 - val_loss: 1.2903 - val_accuracy: 0.4211

Epoch 01824: val_loss did not improve from 1.28903
Epoch 1825/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4167 - val_loss: 1.2925 - val_accuracy: 0.4163

Epoch 01825: val_loss did not improve from 1.28903
Epoch 1826/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4173 - val_loss: 1.2905 - val_accuracy: 0.4234

Epoch 01826: val_loss did not improve from 1.28903
Epoch 1827/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4117 - val_loss: 1.2912 - val_accuracy: 0.4203

Epoch 01827: val_loss did not improve from 1.28903
Epoch 1828/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4168 - val_loss: 1.2897 - val_accuracy: 0.4211

Epoch 01828: val_loss did not improve from 1.28903
Epoch 1829/10000
12/12 - 0s - loss: 1.2849 - accuracy: 0.4168 - val_loss: 1.2909 - val_accuracy: 0.4123

Epoch 01829: val_loss did not improve from 1.28903
Epoch 1830/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4194 - val_loss: 1.2887 - val_accuracy: 0.4258

Epoch 01830: val_loss improved from 1.28903 to 1.28870, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1831/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4166 - val_loss: 1.2892 - val_accuracy: 0.4219

Epoch 01831: val_loss did not improve from 1.28870
Epoch 1832/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4172 - val_loss: 1.2881 - val_accuracy: 0.4314

Epoch 01832: val_loss improved from 1.28870 to 1.28809, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1833/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4152 - val_loss: 1.2892 - val_accuracy: 0.4187

Epoch 01833: val_loss did not improve from 1.28809
Epoch 1834/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4145 - val_loss: 1.2897 - val_accuracy: 0.4298

Epoch 01834: val_loss did not improve from 1.28809
Epoch 1835/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4159 - val_loss: 1.2885 - val_accuracy: 0.4258

Epoch 01835: val_loss did not improve from 1.28809
Epoch 1836/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4139 - val_loss: 1.2936 - val_accuracy: 0.4234

Epoch 01836: val_loss did not improve from 1.28809
Epoch 1837/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4151 - val_loss: 1.2889 - val_accuracy: 0.4226

Epoch 01837: val_loss did not improve from 1.28809
Epoch 1838/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4180 - val_loss: 1.2879 - val_accuracy: 0.4234

Epoch 01838: val_loss improved from 1.28809 to 1.28791, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1839/10000
12/12 - 0s - loss: 1.2882 - accuracy: 0.4078 - val_loss: 1.2908 - val_accuracy: 0.4258

Epoch 01839: val_loss did not improve from 1.28791
Epoch 1840/10000
12/12 - 0s - loss: 1.2853 - accuracy: 0.4149 - val_loss: 1.2909 - val_accuracy: 0.4242

Epoch 01840: val_loss did not improve from 1.28791
Epoch 1841/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4168 - val_loss: 1.2897 - val_accuracy: 0.4330

Epoch 01841: val_loss did not improve from 1.28791
Epoch 1842/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4141 - val_loss: 1.2918 - val_accuracy: 0.4203

Epoch 01842: val_loss did not improve from 1.28791
Epoch 1843/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4178 - val_loss: 1.2943 - val_accuracy: 0.4155

Epoch 01843: val_loss did not improve from 1.28791
Epoch 1844/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4149 - val_loss: 1.2882 - val_accuracy: 0.4282

Epoch 01844: val_loss did not improve from 1.28791
Epoch 1845/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4138 - val_loss: 1.2922 - val_accuracy: 0.4234

Epoch 01845: val_loss did not improve from 1.28791
Epoch 1846/10000
12/12 - 0s - loss: 1.2861 - accuracy: 0.4182 - val_loss: 1.2886 - val_accuracy: 0.4195

Epoch 01846: val_loss did not improve from 1.28791
Epoch 1847/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4160 - val_loss: 1.2909 - val_accuracy: 0.4155

Epoch 01847: val_loss did not improve from 1.28791
Epoch 1848/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4179 - val_loss: 1.2877 - val_accuracy: 0.4266

Epoch 01848: val_loss improved from 1.28791 to 1.28768, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1849/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4163 - val_loss: 1.2904 - val_accuracy: 0.4219

Epoch 01849: val_loss did not improve from 1.28768
Epoch 1850/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4145 - val_loss: 1.2906 - val_accuracy: 0.4139

Epoch 01850: val_loss did not improve from 1.28768
Epoch 1851/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4157 - val_loss: 1.2895 - val_accuracy: 0.4211

Epoch 01851: val_loss did not improve from 1.28768
Epoch 1852/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4157 - val_loss: 1.2904 - val_accuracy: 0.4131

Epoch 01852: val_loss did not improve from 1.28768
Epoch 1853/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4153 - val_loss: 1.2941 - val_accuracy: 0.4043

Epoch 01853: val_loss did not improve from 1.28768
Epoch 1854/10000
12/12 - 0s - loss: 1.2878 - accuracy: 0.4166 - val_loss: 1.2903 - val_accuracy: 0.4290

Epoch 01854: val_loss did not improve from 1.28768
Epoch 1855/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4143 - val_loss: 1.2892 - val_accuracy: 0.4234

Epoch 01855: val_loss did not improve from 1.28768
Epoch 1856/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4158 - val_loss: 1.2934 - val_accuracy: 0.4139

Epoch 01856: val_loss did not improve from 1.28768
Epoch 1857/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4145 - val_loss: 1.2870 - val_accuracy: 0.4234

Epoch 01857: val_loss improved from 1.28768 to 1.28696, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1858/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4171 - val_loss: 1.2882 - val_accuracy: 0.4171

Epoch 01858: val_loss did not improve from 1.28696
Epoch 1859/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4179 - val_loss: 1.2908 - val_accuracy: 0.4195

Epoch 01859: val_loss did not improve from 1.28696
Epoch 1860/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4150 - val_loss: 1.2891 - val_accuracy: 0.4211

Epoch 01860: val_loss did not improve from 1.28696
Epoch 1861/10000
12/12 - 0s - loss: 1.2869 - accuracy: 0.4119 - val_loss: 1.2889 - val_accuracy: 0.4163

Epoch 01861: val_loss did not improve from 1.28696
Epoch 1862/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4177 - val_loss: 1.2871 - val_accuracy: 0.4274

Epoch 01862: val_loss did not improve from 1.28696
Epoch 1863/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4154 - val_loss: 1.2900 - val_accuracy: 0.4091

Epoch 01863: val_loss did not improve from 1.28696
Epoch 1864/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4130 - val_loss: 1.2890 - val_accuracy: 0.4242

Epoch 01864: val_loss did not improve from 1.28696
Epoch 1865/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4166 - val_loss: 1.2880 - val_accuracy: 0.4250

Epoch 01865: val_loss did not improve from 1.28696
Epoch 1866/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4179 - val_loss: 1.2911 - val_accuracy: 0.4195

Epoch 01866: val_loss did not improve from 1.28696
Epoch 1867/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4166 - val_loss: 1.2879 - val_accuracy: 0.4250

Epoch 01867: val_loss did not improve from 1.28696
Epoch 1868/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4116 - val_loss: 1.2903 - val_accuracy: 0.4242

Epoch 01868: val_loss did not improve from 1.28696
Epoch 1869/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4151 - val_loss: 1.2917 - val_accuracy: 0.4306

Epoch 01869: val_loss did not improve from 1.28696
Epoch 1870/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4173 - val_loss: 1.2879 - val_accuracy: 0.4298

Epoch 01870: val_loss did not improve from 1.28696
Epoch 1871/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4202 - val_loss: 1.2938 - val_accuracy: 0.4163

Epoch 01871: val_loss did not improve from 1.28696
Epoch 1872/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4129 - val_loss: 1.2891 - val_accuracy: 0.4163

Epoch 01872: val_loss did not improve from 1.28696
Epoch 1873/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4152 - val_loss: 1.2880 - val_accuracy: 0.4306

Epoch 01873: val_loss did not improve from 1.28696
Epoch 1874/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4169 - val_loss: 1.2889 - val_accuracy: 0.4195

Epoch 01874: val_loss did not improve from 1.28696
Epoch 1875/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4161 - val_loss: 1.2885 - val_accuracy: 0.4290

Epoch 01875: val_loss did not improve from 1.28696
Epoch 1876/10000
12/12 - 0s - loss: 1.2881 - accuracy: 0.4169 - val_loss: 1.2897 - val_accuracy: 0.4131

Epoch 01876: val_loss did not improve from 1.28696
Epoch 1877/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4162 - val_loss: 1.2999 - val_accuracy: 0.4123

Epoch 01877: val_loss did not improve from 1.28696
Epoch 1878/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4127 - val_loss: 1.2919 - val_accuracy: 0.4250

Epoch 01878: val_loss did not improve from 1.28696
Epoch 1879/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4157 - val_loss: 1.2926 - val_accuracy: 0.4203

Epoch 01879: val_loss did not improve from 1.28696
Epoch 1880/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4153 - val_loss: 1.2887 - val_accuracy: 0.4195

Epoch 01880: val_loss did not improve from 1.28696
Epoch 1881/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4206 - val_loss: 1.2894 - val_accuracy: 0.4274

Epoch 01881: val_loss did not improve from 1.28696
Epoch 1882/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4193 - val_loss: 1.2898 - val_accuracy: 0.4163

Epoch 01882: val_loss did not improve from 1.28696
Epoch 1883/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4181 - val_loss: 1.2894 - val_accuracy: 0.4187

Epoch 01883: val_loss did not improve from 1.28696
Epoch 1884/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4172 - val_loss: 1.2885 - val_accuracy: 0.4226

Epoch 01884: val_loss did not improve from 1.28696
Epoch 1885/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4157 - val_loss: 1.2895 - val_accuracy: 0.4282

Epoch 01885: val_loss did not improve from 1.28696
Epoch 1886/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4148 - val_loss: 1.2896 - val_accuracy: 0.4219

Epoch 01886: val_loss did not improve from 1.28696
Epoch 1887/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4168 - val_loss: 1.2885 - val_accuracy: 0.4203

Epoch 01887: val_loss did not improve from 1.28696
Epoch 1888/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4193 - val_loss: 1.2954 - val_accuracy: 0.4139

Epoch 01888: val_loss did not improve from 1.28696
Epoch 1889/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4163 - val_loss: 1.2922 - val_accuracy: 0.4163

Epoch 01889: val_loss did not improve from 1.28696
Epoch 1890/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4124 - val_loss: 1.2900 - val_accuracy: 0.4147

Epoch 01890: val_loss did not improve from 1.28696
Epoch 1891/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4165 - val_loss: 1.2897 - val_accuracy: 0.4306

Epoch 01891: val_loss did not improve from 1.28696
Epoch 1892/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4135 - val_loss: 1.2900 - val_accuracy: 0.4163

Epoch 01892: val_loss did not improve from 1.28696
Epoch 1893/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4166 - val_loss: 1.2890 - val_accuracy: 0.4234

Epoch 01893: val_loss did not improve from 1.28696
Epoch 1894/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4134 - val_loss: 1.2906 - val_accuracy: 0.4195

Epoch 01894: val_loss did not improve from 1.28696
Epoch 1895/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4177 - val_loss: 1.2885 - val_accuracy: 0.4242

Epoch 01895: val_loss did not improve from 1.28696
Epoch 1896/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4162 - val_loss: 1.2913 - val_accuracy: 0.4115

Epoch 01896: val_loss did not improve from 1.28696
Epoch 1897/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4132 - val_loss: 1.2916 - val_accuracy: 0.4203

Epoch 01897: val_loss did not improve from 1.28696
Epoch 1898/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4123 - val_loss: 1.2877 - val_accuracy: 0.4266

Epoch 01898: val_loss did not improve from 1.28696
Epoch 1899/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4150 - val_loss: 1.2885 - val_accuracy: 0.4179

Epoch 01899: val_loss did not improve from 1.28696
Epoch 1900/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4180 - val_loss: 1.2870 - val_accuracy: 0.4250

Epoch 01900: val_loss did not improve from 1.28696
Epoch 1901/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4144 - val_loss: 1.2885 - val_accuracy: 0.4234

Epoch 01901: val_loss did not improve from 1.28696
Epoch 1902/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4120 - val_loss: 1.2893 - val_accuracy: 0.4266

Epoch 01902: val_loss did not improve from 1.28696
Epoch 1903/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4177 - val_loss: 1.2883 - val_accuracy: 0.4258

Epoch 01903: val_loss did not improve from 1.28696
Epoch 1904/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4129 - val_loss: 1.2877 - val_accuracy: 0.4187

Epoch 01904: val_loss did not improve from 1.28696
Epoch 1905/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4156 - val_loss: 1.2895 - val_accuracy: 0.4226

Epoch 01905: val_loss did not improve from 1.28696
Epoch 1906/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4137 - val_loss: 1.2891 - val_accuracy: 0.4211

Epoch 01906: val_loss did not improve from 1.28696
Epoch 1907/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4160 - val_loss: 1.2899 - val_accuracy: 0.4211

Epoch 01907: val_loss did not improve from 1.28696
Epoch 1908/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4101 - val_loss: 1.2878 - val_accuracy: 0.4242

Epoch 01908: val_loss did not improve from 1.28696
Epoch 1909/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4155 - val_loss: 1.2876 - val_accuracy: 0.4195

Epoch 01909: val_loss did not improve from 1.28696
Epoch 1910/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4144 - val_loss: 1.2888 - val_accuracy: 0.4195

Epoch 01910: val_loss did not improve from 1.28696
Epoch 1911/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4180 - val_loss: 1.2879 - val_accuracy: 0.4250

Epoch 01911: val_loss did not improve from 1.28696
Epoch 1912/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4151 - val_loss: 1.2877 - val_accuracy: 0.4274

Epoch 01912: val_loss did not improve from 1.28696
Epoch 1913/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4156 - val_loss: 1.2871 - val_accuracy: 0.4274

Epoch 01913: val_loss did not improve from 1.28696
Epoch 1914/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4140 - val_loss: 1.2887 - val_accuracy: 0.4195

Epoch 01914: val_loss did not improve from 1.28696
Epoch 1915/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4187 - val_loss: 1.2896 - val_accuracy: 0.4163

Epoch 01915: val_loss did not improve from 1.28696
Epoch 1916/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4164 - val_loss: 1.2883 - val_accuracy: 0.4115

Epoch 01916: val_loss did not improve from 1.28696
Epoch 1917/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4179 - val_loss: 1.2913 - val_accuracy: 0.4234

Epoch 01917: val_loss did not improve from 1.28696
Epoch 1918/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4160 - val_loss: 1.2884 - val_accuracy: 0.4242

Epoch 01918: val_loss did not improve from 1.28696
Epoch 1919/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4140 - val_loss: 1.2916 - val_accuracy: 0.4155

Epoch 01919: val_loss did not improve from 1.28696
Epoch 1920/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4168 - val_loss: 1.2974 - val_accuracy: 0.4059

Epoch 01920: val_loss did not improve from 1.28696
Epoch 1921/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4176 - val_loss: 1.2900 - val_accuracy: 0.4203

Epoch 01921: val_loss did not improve from 1.28696
Epoch 1922/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4128 - val_loss: 1.2879 - val_accuracy: 0.4266

Epoch 01922: val_loss did not improve from 1.28696
Epoch 1923/10000
12/12 - 0s - loss: 1.2835 - accuracy: 0.4166 - val_loss: 1.2878 - val_accuracy: 0.4290

Epoch 01923: val_loss did not improve from 1.28696
Epoch 1924/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4154 - val_loss: 1.2897 - val_accuracy: 0.4274

Epoch 01924: val_loss did not improve from 1.28696
Epoch 1925/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4163 - val_loss: 1.2869 - val_accuracy: 0.4258

Epoch 01925: val_loss improved from 1.28696 to 1.28691, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1926/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4151 - val_loss: 1.2884 - val_accuracy: 0.4211

Epoch 01926: val_loss did not improve from 1.28691
Epoch 1927/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4153 - val_loss: 1.2883 - val_accuracy: 0.4266

Epoch 01927: val_loss did not improve from 1.28691
Epoch 1928/10000
12/12 - 0s - loss: 1.2838 - accuracy: 0.4137 - val_loss: 1.2893 - val_accuracy: 0.4179

Epoch 01928: val_loss did not improve from 1.28691
Epoch 1929/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4094 - val_loss: 1.2894 - val_accuracy: 0.4123

Epoch 01929: val_loss did not improve from 1.28691
Epoch 1930/10000
12/12 - 0s - loss: 1.2859 - accuracy: 0.4156 - val_loss: 1.2870 - val_accuracy: 0.4258

Epoch 01930: val_loss did not improve from 1.28691
Epoch 1931/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4148 - val_loss: 1.2900 - val_accuracy: 0.4258

Epoch 01931: val_loss did not improve from 1.28691
Epoch 1932/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4237 - val_loss: 1.2891 - val_accuracy: 0.4242

Epoch 01932: val_loss did not improve from 1.28691
Epoch 1933/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4200 - val_loss: 1.2874 - val_accuracy: 0.4234

Epoch 01933: val_loss did not improve from 1.28691
Epoch 1934/10000
12/12 - 0s - loss: 1.2847 - accuracy: 0.4149 - val_loss: 1.2912 - val_accuracy: 0.4203

Epoch 01934: val_loss did not improve from 1.28691
Epoch 1935/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4163 - val_loss: 1.2886 - val_accuracy: 0.4242

Epoch 01935: val_loss did not improve from 1.28691
Epoch 1936/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4129 - val_loss: 1.2887 - val_accuracy: 0.4274

Epoch 01936: val_loss did not improve from 1.28691
Epoch 1937/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4140 - val_loss: 1.2871 - val_accuracy: 0.4171

Epoch 01937: val_loss did not improve from 1.28691
Epoch 1938/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4163 - val_loss: 1.2872 - val_accuracy: 0.4211

Epoch 01938: val_loss did not improve from 1.28691
Epoch 1939/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4149 - val_loss: 1.2873 - val_accuracy: 0.4226

Epoch 01939: val_loss did not improve from 1.28691
Epoch 1940/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4128 - val_loss: 1.2894 - val_accuracy: 0.4195

Epoch 01940: val_loss did not improve from 1.28691
Epoch 1941/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4124 - val_loss: 1.2870 - val_accuracy: 0.4258

Epoch 01941: val_loss did not improve from 1.28691
Epoch 1942/10000
12/12 - 0s - loss: 1.2880 - accuracy: 0.4161 - val_loss: 1.2881 - val_accuracy: 0.4234

Epoch 01942: val_loss did not improve from 1.28691
Epoch 1943/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4176 - val_loss: 1.2887 - val_accuracy: 0.4234

Epoch 01943: val_loss did not improve from 1.28691
Epoch 1944/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4157 - val_loss: 1.2862 - val_accuracy: 0.4378

Epoch 01944: val_loss improved from 1.28691 to 1.28623, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1945/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4161 - val_loss: 1.2869 - val_accuracy: 0.4314

Epoch 01945: val_loss did not improve from 1.28623
Epoch 1946/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4163 - val_loss: 1.2871 - val_accuracy: 0.4195

Epoch 01946: val_loss did not improve from 1.28623
Epoch 1947/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4134 - val_loss: 1.2857 - val_accuracy: 0.4187

Epoch 01947: val_loss improved from 1.28623 to 1.28566, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1948/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4167 - val_loss: 1.2863 - val_accuracy: 0.4211

Epoch 01948: val_loss did not improve from 1.28566
Epoch 1949/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4117 - val_loss: 1.2866 - val_accuracy: 0.4290

Epoch 01949: val_loss did not improve from 1.28566
Epoch 1950/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4155 - val_loss: 1.2851 - val_accuracy: 0.4274

Epoch 01950: val_loss improved from 1.28566 to 1.28510, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1951/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4173 - val_loss: 1.2903 - val_accuracy: 0.4258

Epoch 01951: val_loss did not improve from 1.28510
Epoch 1952/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4165 - val_loss: 1.2874 - val_accuracy: 0.4226

Epoch 01952: val_loss did not improve from 1.28510
Epoch 1953/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4156 - val_loss: 1.2981 - val_accuracy: 0.4258

Epoch 01953: val_loss did not improve from 1.28510
Epoch 1954/10000
12/12 - 0s - loss: 1.2858 - accuracy: 0.4148 - val_loss: 1.2867 - val_accuracy: 0.4282

Epoch 01954: val_loss did not improve from 1.28510
Epoch 1955/10000
12/12 - 0s - loss: 1.2865 - accuracy: 0.4141 - val_loss: 1.2866 - val_accuracy: 0.4298

Epoch 01955: val_loss did not improve from 1.28510
Epoch 1956/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4161 - val_loss: 1.2855 - val_accuracy: 0.4219

Epoch 01956: val_loss did not improve from 1.28510
Epoch 1957/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4136 - val_loss: 1.2870 - val_accuracy: 0.4250

Epoch 01957: val_loss did not improve from 1.28510
Epoch 1958/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4162 - val_loss: 1.2871 - val_accuracy: 0.4179

Epoch 01958: val_loss did not improve from 1.28510
Epoch 1959/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4206 - val_loss: 1.2854 - val_accuracy: 0.4219

Epoch 01959: val_loss did not improve from 1.28510
Epoch 1960/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4165 - val_loss: 1.2870 - val_accuracy: 0.4187

Epoch 01960: val_loss did not improve from 1.28510
Epoch 1961/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4161 - val_loss: 1.2860 - val_accuracy: 0.4258

Epoch 01961: val_loss did not improve from 1.28510
Epoch 1962/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4184 - val_loss: 1.2871 - val_accuracy: 0.4219

Epoch 01962: val_loss did not improve from 1.28510
Epoch 1963/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4164 - val_loss: 1.2863 - val_accuracy: 0.4219

Epoch 01963: val_loss did not improve from 1.28510
Epoch 1964/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4193 - val_loss: 1.2871 - val_accuracy: 0.4187

Epoch 01964: val_loss did not improve from 1.28510
Epoch 1965/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4154 - val_loss: 1.2881 - val_accuracy: 0.4258

Epoch 01965: val_loss did not improve from 1.28510
Epoch 1966/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4126 - val_loss: 1.2868 - val_accuracy: 0.4195

Epoch 01966: val_loss did not improve from 1.28510
Epoch 1967/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4180 - val_loss: 1.2854 - val_accuracy: 0.4203

Epoch 01967: val_loss did not improve from 1.28510
Epoch 1968/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4172 - val_loss: 1.2913 - val_accuracy: 0.4163

Epoch 01968: val_loss did not improve from 1.28510
Epoch 1969/10000
12/12 - 0s - loss: 1.2842 - accuracy: 0.4125 - val_loss: 1.2876 - val_accuracy: 0.4298

Epoch 01969: val_loss did not improve from 1.28510
Epoch 1970/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4172 - val_loss: 1.2895 - val_accuracy: 0.4163

Epoch 01970: val_loss did not improve from 1.28510
Epoch 1971/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4167 - val_loss: 1.2897 - val_accuracy: 0.4298

Epoch 01971: val_loss did not improve from 1.28510
Epoch 1972/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4173 - val_loss: 1.2881 - val_accuracy: 0.4242

Epoch 01972: val_loss did not improve from 1.28510
Epoch 1973/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4151 - val_loss: 1.2884 - val_accuracy: 0.4226

Epoch 01973: val_loss did not improve from 1.28510
Epoch 1974/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4159 - val_loss: 1.2918 - val_accuracy: 0.4282

Epoch 01974: val_loss did not improve from 1.28510
Epoch 1975/10000
12/12 - 0s - loss: 1.2860 - accuracy: 0.4148 - val_loss: 1.2868 - val_accuracy: 0.4266

Epoch 01975: val_loss did not improve from 1.28510
Epoch 1976/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4158 - val_loss: 1.2872 - val_accuracy: 0.4187

Epoch 01976: val_loss did not improve from 1.28510
Epoch 1977/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4182 - val_loss: 1.2871 - val_accuracy: 0.4258

Epoch 01977: val_loss did not improve from 1.28510
Epoch 1978/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4167 - val_loss: 1.2921 - val_accuracy: 0.4266

Epoch 01978: val_loss did not improve from 1.28510
Epoch 1979/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4141 - val_loss: 1.2910 - val_accuracy: 0.4179

Epoch 01979: val_loss did not improve from 1.28510
Epoch 1980/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4148 - val_loss: 1.2873 - val_accuracy: 0.4187

Epoch 01980: val_loss did not improve from 1.28510
Epoch 1981/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4150 - val_loss: 1.2868 - val_accuracy: 0.4250

Epoch 01981: val_loss did not improve from 1.28510
Epoch 1982/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4201 - val_loss: 1.2926 - val_accuracy: 0.4163

Epoch 01982: val_loss did not improve from 1.28510
Epoch 1983/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4147 - val_loss: 1.2878 - val_accuracy: 0.4211

Epoch 01983: val_loss did not improve from 1.28510
Epoch 1984/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4168 - val_loss: 1.2867 - val_accuracy: 0.4306

Epoch 01984: val_loss did not improve from 1.28510
Epoch 1985/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4187 - val_loss: 1.2875 - val_accuracy: 0.4290

Epoch 01985: val_loss did not improve from 1.28510
Epoch 1986/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4180 - val_loss: 1.2859 - val_accuracy: 0.4266

Epoch 01986: val_loss did not improve from 1.28510
Epoch 1987/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4180 - val_loss: 1.2860 - val_accuracy: 0.4234

Epoch 01987: val_loss did not improve from 1.28510
Epoch 1988/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4174 - val_loss: 1.2859 - val_accuracy: 0.4322

Epoch 01988: val_loss did not improve from 1.28510
Epoch 1989/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4154 - val_loss: 1.2868 - val_accuracy: 0.4139

Epoch 01989: val_loss did not improve from 1.28510
Epoch 1990/10000
12/12 - 0s - loss: 1.2820 - accuracy: 0.4160 - val_loss: 1.2905 - val_accuracy: 0.4250

Epoch 01990: val_loss did not improve from 1.28510
Epoch 1991/10000
12/12 - 0s - loss: 1.2857 - accuracy: 0.4156 - val_loss: 1.2862 - val_accuracy: 0.4258

Epoch 01991: val_loss did not improve from 1.28510
Epoch 1992/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4162 - val_loss: 1.2896 - val_accuracy: 0.4187

Epoch 01992: val_loss did not improve from 1.28510
Epoch 1993/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4140 - val_loss: 1.2869 - val_accuracy: 0.4195

Epoch 01993: val_loss did not improve from 1.28510
Epoch 1994/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4195 - val_loss: 1.2872 - val_accuracy: 0.4306

Epoch 01994: val_loss did not improve from 1.28510
Epoch 1995/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4189 - val_loss: 1.2863 - val_accuracy: 0.4242

Epoch 01995: val_loss did not improve from 1.28510
Epoch 1996/10000
12/12 - 0s - loss: 1.2823 - accuracy: 0.4163 - val_loss: 1.2846 - val_accuracy: 0.4258

Epoch 01996: val_loss improved from 1.28510 to 1.28463, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 1997/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4158 - val_loss: 1.2876 - val_accuracy: 0.4179

Epoch 01997: val_loss did not improve from 1.28463
Epoch 1998/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4167 - val_loss: 1.2868 - val_accuracy: 0.4187

Epoch 01998: val_loss did not improve from 1.28463
Epoch 1999/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4174 - val_loss: 1.2855 - val_accuracy: 0.4306

Epoch 01999: val_loss did not improve from 1.28463
Epoch 2000/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4156 - val_loss: 1.2897 - val_accuracy: 0.4242

Epoch 02000: val_loss did not improve from 1.28463
Epoch 2001/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4154 - val_loss: 1.2850 - val_accuracy: 0.4298

Epoch 02001: val_loss did not improve from 1.28463
Epoch 2002/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4171 - val_loss: 1.2943 - val_accuracy: 0.4155

Epoch 02002: val_loss did not improve from 1.28463
Epoch 2003/10000
12/12 - 0s - loss: 1.2862 - accuracy: 0.4163 - val_loss: 1.2868 - val_accuracy: 0.4314

Epoch 02003: val_loss did not improve from 1.28463
Epoch 2004/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4127 - val_loss: 1.2871 - val_accuracy: 0.4187

Epoch 02004: val_loss did not improve from 1.28463
Epoch 2005/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4189 - val_loss: 1.2860 - val_accuracy: 0.4258

Epoch 02005: val_loss did not improve from 1.28463
Epoch 2006/10000
12/12 - 0s - loss: 1.2845 - accuracy: 0.4163 - val_loss: 1.2840 - val_accuracy: 0.4306

Epoch 02006: val_loss improved from 1.28463 to 1.28397, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2007/10000
12/12 - 0s - loss: 1.2870 - accuracy: 0.4134 - val_loss: 1.2915 - val_accuracy: 0.4242

Epoch 02007: val_loss did not improve from 1.28397
Epoch 2008/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4168 - val_loss: 1.2855 - val_accuracy: 0.4282

Epoch 02008: val_loss did not improve from 1.28397
Epoch 2009/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4167 - val_loss: 1.2867 - val_accuracy: 0.4250

Epoch 02009: val_loss did not improve from 1.28397
Epoch 2010/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4159 - val_loss: 1.2856 - val_accuracy: 0.4242

Epoch 02010: val_loss did not improve from 1.28397
Epoch 2011/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4172 - val_loss: 1.2842 - val_accuracy: 0.4203

Epoch 02011: val_loss did not improve from 1.28397
Epoch 2012/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4173 - val_loss: 1.2833 - val_accuracy: 0.4258

Epoch 02012: val_loss improved from 1.28397 to 1.28334, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2013/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4179 - val_loss: 1.2846 - val_accuracy: 0.4226

Epoch 02013: val_loss did not improve from 1.28334
Epoch 2014/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4187 - val_loss: 1.2842 - val_accuracy: 0.4219

Epoch 02014: val_loss did not improve from 1.28334
Epoch 2015/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4167 - val_loss: 1.2845 - val_accuracy: 0.4282

Epoch 02015: val_loss did not improve from 1.28334
Epoch 2016/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4192 - val_loss: 1.2852 - val_accuracy: 0.4234

Epoch 02016: val_loss did not improve from 1.28334
Epoch 2017/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4190 - val_loss: 1.2850 - val_accuracy: 0.4250

Epoch 02017: val_loss did not improve from 1.28334
Epoch 2018/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4188 - val_loss: 1.2850 - val_accuracy: 0.4219

Epoch 02018: val_loss did not improve from 1.28334
Epoch 2019/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4152 - val_loss: 1.2904 - val_accuracy: 0.4298

Epoch 02019: val_loss did not improve from 1.28334
Epoch 2020/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4134 - val_loss: 1.2919 - val_accuracy: 0.4266

Epoch 02020: val_loss did not improve from 1.28334
Epoch 2021/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4156 - val_loss: 1.2834 - val_accuracy: 0.4306

Epoch 02021: val_loss did not improve from 1.28334
Epoch 2022/10000
12/12 - 0s - loss: 1.2851 - accuracy: 0.4181 - val_loss: 1.2910 - val_accuracy: 0.4147

Epoch 02022: val_loss did not improve from 1.28334
Epoch 2023/10000
12/12 - 0s - loss: 1.2828 - accuracy: 0.4139 - val_loss: 1.2843 - val_accuracy: 0.4274

Epoch 02023: val_loss did not improve from 1.28334
Epoch 2024/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4181 - val_loss: 1.2840 - val_accuracy: 0.4234

Epoch 02024: val_loss did not improve from 1.28334
Epoch 2025/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4175 - val_loss: 1.2889 - val_accuracy: 0.4306

Epoch 02025: val_loss did not improve from 1.28334
Epoch 2026/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4176 - val_loss: 1.2854 - val_accuracy: 0.4219

Epoch 02026: val_loss did not improve from 1.28334
Epoch 2027/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4154 - val_loss: 1.2851 - val_accuracy: 0.4195

Epoch 02027: val_loss did not improve from 1.28334
Epoch 2028/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4175 - val_loss: 1.2870 - val_accuracy: 0.4274

Epoch 02028: val_loss did not improve from 1.28334
Epoch 2029/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4183 - val_loss: 1.2836 - val_accuracy: 0.4306

Epoch 02029: val_loss did not improve from 1.28334
Epoch 2030/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4171 - val_loss: 1.2843 - val_accuracy: 0.4274

Epoch 02030: val_loss did not improve from 1.28334
Epoch 2031/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4154 - val_loss: 1.2854 - val_accuracy: 0.4250

Epoch 02031: val_loss did not improve from 1.28334
Epoch 2032/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4183 - val_loss: 1.2848 - val_accuracy: 0.4234

Epoch 02032: val_loss did not improve from 1.28334
Epoch 2033/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4156 - val_loss: 1.2879 - val_accuracy: 0.4179

Epoch 02033: val_loss did not improve from 1.28334
Epoch 2034/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4156 - val_loss: 1.2858 - val_accuracy: 0.4306

Epoch 02034: val_loss did not improve from 1.28334
Epoch 2035/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4157 - val_loss: 1.2903 - val_accuracy: 0.4203

Epoch 02035: val_loss did not improve from 1.28334
Epoch 2036/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4171 - val_loss: 1.2845 - val_accuracy: 0.4258

Epoch 02036: val_loss did not improve from 1.28334
Epoch 2037/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4141 - val_loss: 1.2852 - val_accuracy: 0.4290

Epoch 02037: val_loss did not improve from 1.28334
Epoch 2038/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4186 - val_loss: 1.2843 - val_accuracy: 0.4234

Epoch 02038: val_loss did not improve from 1.28334
Epoch 2039/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4211 - val_loss: 1.2837 - val_accuracy: 0.4226

Epoch 02039: val_loss did not improve from 1.28334
Epoch 2040/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4214 - val_loss: 1.2848 - val_accuracy: 0.4226

Epoch 02040: val_loss did not improve from 1.28334
Epoch 2041/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4179 - val_loss: 1.2837 - val_accuracy: 0.4242

Epoch 02041: val_loss did not improve from 1.28334
Epoch 2042/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4182 - val_loss: 1.2833 - val_accuracy: 0.4242

Epoch 02042: val_loss improved from 1.28334 to 1.28327, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2043/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4176 - val_loss: 1.2850 - val_accuracy: 0.4338

Epoch 02043: val_loss did not improve from 1.28327
Epoch 2044/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4140 - val_loss: 1.2840 - val_accuracy: 0.4306

Epoch 02044: val_loss did not improve from 1.28327
Epoch 2045/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4156 - val_loss: 1.2860 - val_accuracy: 0.4187

Epoch 02045: val_loss did not improve from 1.28327
Epoch 2046/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4164 - val_loss: 1.2880 - val_accuracy: 0.4187

Epoch 02046: val_loss did not improve from 1.28327
Epoch 2047/10000
12/12 - 0s - loss: 1.2822 - accuracy: 0.4162 - val_loss: 1.2848 - val_accuracy: 0.4258

Epoch 02047: val_loss did not improve from 1.28327
Epoch 2048/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4148 - val_loss: 1.2842 - val_accuracy: 0.4234

Epoch 02048: val_loss did not improve from 1.28327
Epoch 2049/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4185 - val_loss: 1.2879 - val_accuracy: 0.4139

Epoch 02049: val_loss did not improve from 1.28327
Epoch 2050/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4177 - val_loss: 1.2834 - val_accuracy: 0.4314

Epoch 02050: val_loss did not improve from 1.28327
Epoch 2051/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4179 - val_loss: 1.2840 - val_accuracy: 0.4258

Epoch 02051: val_loss did not improve from 1.28327
Epoch 2052/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4182 - val_loss: 1.2849 - val_accuracy: 0.4298

Epoch 02052: val_loss did not improve from 1.28327
Epoch 2053/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4168 - val_loss: 1.2903 - val_accuracy: 0.4290

Epoch 02053: val_loss did not improve from 1.28327
Epoch 2054/10000
12/12 - 0s - loss: 1.2904 - accuracy: 0.4142 - val_loss: 1.2859 - val_accuracy: 0.4234

Epoch 02054: val_loss did not improve from 1.28327
Epoch 2055/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4195 - val_loss: 1.2815 - val_accuracy: 0.4354

Epoch 02055: val_loss improved from 1.28327 to 1.28148, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2056/10000
12/12 - 0s - loss: 1.2817 - accuracy: 0.4165 - val_loss: 1.2869 - val_accuracy: 0.4242

Epoch 02056: val_loss did not improve from 1.28148
Epoch 2057/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4194 - val_loss: 1.2850 - val_accuracy: 0.4258

Epoch 02057: val_loss did not improve from 1.28148
Epoch 2058/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4171 - val_loss: 1.2853 - val_accuracy: 0.4322

Epoch 02058: val_loss did not improve from 1.28148
Epoch 2059/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4163 - val_loss: 1.2843 - val_accuracy: 0.4187

Epoch 02059: val_loss did not improve from 1.28148
Epoch 2060/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4182 - val_loss: 1.2844 - val_accuracy: 0.4171

Epoch 02060: val_loss did not improve from 1.28148
Epoch 2061/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4174 - val_loss: 1.2835 - val_accuracy: 0.4274

Epoch 02061: val_loss did not improve from 1.28148
Epoch 2062/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4194 - val_loss: 1.2860 - val_accuracy: 0.4330

Epoch 02062: val_loss did not improve from 1.28148
Epoch 2063/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4185 - val_loss: 1.2839 - val_accuracy: 0.4187

Epoch 02063: val_loss did not improve from 1.28148
Epoch 2064/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4172 - val_loss: 1.2828 - val_accuracy: 0.4187

Epoch 02064: val_loss did not improve from 1.28148
Epoch 2065/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4183 - val_loss: 1.2858 - val_accuracy: 0.4242

Epoch 02065: val_loss did not improve from 1.28148
Epoch 2066/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4174 - val_loss: 1.2872 - val_accuracy: 0.4242

Epoch 02066: val_loss did not improve from 1.28148
Epoch 2067/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4184 - val_loss: 1.2840 - val_accuracy: 0.4330

Epoch 02067: val_loss did not improve from 1.28148
Epoch 2068/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4168 - val_loss: 1.2854 - val_accuracy: 0.4258

Epoch 02068: val_loss did not improve from 1.28148
Epoch 2069/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4164 - val_loss: 1.2887 - val_accuracy: 0.4163

Epoch 02069: val_loss did not improve from 1.28148
Epoch 2070/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4156 - val_loss: 1.2865 - val_accuracy: 0.4211

Epoch 02070: val_loss did not improve from 1.28148
Epoch 2071/10000
12/12 - 0s - loss: 1.2903 - accuracy: 0.4129 - val_loss: 1.2849 - val_accuracy: 0.4266

Epoch 02071: val_loss did not improve from 1.28148
Epoch 2072/10000
12/12 - 0s - loss: 1.2824 - accuracy: 0.4174 - val_loss: 1.2963 - val_accuracy: 0.4187

Epoch 02072: val_loss did not improve from 1.28148
Epoch 2073/10000
12/12 - 0s - loss: 1.2892 - accuracy: 0.4135 - val_loss: 1.2816 - val_accuracy: 0.4266

Epoch 02073: val_loss did not improve from 1.28148
Epoch 2074/10000
12/12 - 0s - loss: 1.2856 - accuracy: 0.4152 - val_loss: 1.2854 - val_accuracy: 0.4211

Epoch 02074: val_loss did not improve from 1.28148
Epoch 2075/10000
12/12 - 0s - loss: 1.2819 - accuracy: 0.4194 - val_loss: 1.2894 - val_accuracy: 0.4171

Epoch 02075: val_loss did not improve from 1.28148
Epoch 2076/10000
12/12 - 0s - loss: 1.2830 - accuracy: 0.4185 - val_loss: 1.2825 - val_accuracy: 0.4306

Epoch 02076: val_loss did not improve from 1.28148
Epoch 2077/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4156 - val_loss: 1.2829 - val_accuracy: 0.4362

Epoch 02077: val_loss did not improve from 1.28148
Epoch 2078/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4182 - val_loss: 1.2829 - val_accuracy: 0.4290

Epoch 02078: val_loss did not improve from 1.28148
Epoch 2079/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4162 - val_loss: 1.2834 - val_accuracy: 0.4274

Epoch 02079: val_loss did not improve from 1.28148
Epoch 2080/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4192 - val_loss: 1.2859 - val_accuracy: 0.4290

Epoch 02080: val_loss did not improve from 1.28148
Epoch 2081/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4150 - val_loss: 1.2839 - val_accuracy: 0.4226

Epoch 02081: val_loss did not improve from 1.28148
Epoch 2082/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4173 - val_loss: 1.2821 - val_accuracy: 0.4195

Epoch 02082: val_loss did not improve from 1.28148
Epoch 2083/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4171 - val_loss: 1.2840 - val_accuracy: 0.4234

Epoch 02083: val_loss did not improve from 1.28148
Epoch 2084/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4207 - val_loss: 1.2851 - val_accuracy: 0.4250

Epoch 02084: val_loss did not improve from 1.28148
Epoch 2085/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4156 - val_loss: 1.2854 - val_accuracy: 0.4250

Epoch 02085: val_loss did not improve from 1.28148
Epoch 2086/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4148 - val_loss: 1.2854 - val_accuracy: 0.4234

Epoch 02086: val_loss did not improve from 1.28148
Epoch 2087/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4179 - val_loss: 1.2860 - val_accuracy: 0.4115

Epoch 02087: val_loss did not improve from 1.28148
Epoch 2088/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4194 - val_loss: 1.2841 - val_accuracy: 0.4195

Epoch 02088: val_loss did not improve from 1.28148
Epoch 2089/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4186 - val_loss: 1.2854 - val_accuracy: 0.4219

Epoch 02089: val_loss did not improve from 1.28148
Epoch 2090/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4177 - val_loss: 1.2842 - val_accuracy: 0.4250

Epoch 02090: val_loss did not improve from 1.28148
Epoch 2091/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4171 - val_loss: 1.2843 - val_accuracy: 0.4274

Epoch 02091: val_loss did not improve from 1.28148
Epoch 2092/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4121 - val_loss: 1.2846 - val_accuracy: 0.4282

Epoch 02092: val_loss did not improve from 1.28148
Epoch 2093/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4173 - val_loss: 1.2835 - val_accuracy: 0.4274

Epoch 02093: val_loss did not improve from 1.28148
Epoch 2094/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4168 - val_loss: 1.2854 - val_accuracy: 0.4219

Epoch 02094: val_loss did not improve from 1.28148
Epoch 2095/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4187 - val_loss: 1.2838 - val_accuracy: 0.4250

Epoch 02095: val_loss did not improve from 1.28148
Epoch 2096/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4202 - val_loss: 1.2833 - val_accuracy: 0.4219

Epoch 02096: val_loss did not improve from 1.28148
Epoch 2097/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4153 - val_loss: 1.2841 - val_accuracy: 0.4219

Epoch 02097: val_loss did not improve from 1.28148
Epoch 2098/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4178 - val_loss: 1.2836 - val_accuracy: 0.4282

Epoch 02098: val_loss did not improve from 1.28148
Epoch 2099/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4187 - val_loss: 1.2854 - val_accuracy: 0.4147

Epoch 02099: val_loss did not improve from 1.28148
Epoch 2100/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4158 - val_loss: 1.2823 - val_accuracy: 0.4282

Epoch 02100: val_loss did not improve from 1.28148
Epoch 2101/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4202 - val_loss: 1.2837 - val_accuracy: 0.4282

Epoch 02101: val_loss did not improve from 1.28148
Epoch 2102/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4186 - val_loss: 1.2863 - val_accuracy: 0.4171

Epoch 02102: val_loss did not improve from 1.28148
Epoch 2103/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4175 - val_loss: 1.2856 - val_accuracy: 0.4211

Epoch 02103: val_loss did not improve from 1.28148
Epoch 2104/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4163 - val_loss: 1.2849 - val_accuracy: 0.4211

Epoch 02104: val_loss did not improve from 1.28148
Epoch 2105/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4195 - val_loss: 1.2845 - val_accuracy: 0.4330

Epoch 02105: val_loss did not improve from 1.28148
Epoch 2106/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4144 - val_loss: 1.2859 - val_accuracy: 0.4234

Epoch 02106: val_loss did not improve from 1.28148
Epoch 2107/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4166 - val_loss: 1.2901 - val_accuracy: 0.4163

Epoch 02107: val_loss did not improve from 1.28148
Epoch 2108/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4205 - val_loss: 1.2833 - val_accuracy: 0.4211

Epoch 02108: val_loss did not improve from 1.28148
Epoch 2109/10000
12/12 - 0s - loss: 1.2836 - accuracy: 0.4215 - val_loss: 1.2842 - val_accuracy: 0.4234

Epoch 02109: val_loss did not improve from 1.28148
Epoch 2110/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4158 - val_loss: 1.2835 - val_accuracy: 0.4226

Epoch 02110: val_loss did not improve from 1.28148
Epoch 2111/10000
12/12 - 0s - loss: 1.2809 - accuracy: 0.4211 - val_loss: 1.2840 - val_accuracy: 0.4147

Epoch 02111: val_loss did not improve from 1.28148
Epoch 2112/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4192 - val_loss: 1.2868 - val_accuracy: 0.4187

Epoch 02112: val_loss did not improve from 1.28148
Epoch 2113/10000
12/12 - 0s - loss: 1.2844 - accuracy: 0.4128 - val_loss: 1.2830 - val_accuracy: 0.4250

Epoch 02113: val_loss did not improve from 1.28148
Epoch 2114/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4141 - val_loss: 1.2905 - val_accuracy: 0.4274

Epoch 02114: val_loss did not improve from 1.28148
Epoch 2115/10000
12/12 - 0s - loss: 1.2810 - accuracy: 0.4178 - val_loss: 1.2855 - val_accuracy: 0.4203

Epoch 02115: val_loss did not improve from 1.28148
Epoch 2116/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4171 - val_loss: 1.2836 - val_accuracy: 0.4266

Epoch 02116: val_loss did not improve from 1.28148
Epoch 2117/10000
12/12 - 0s - loss: 1.2898 - accuracy: 0.4140 - val_loss: 1.2903 - val_accuracy: 0.4171

Epoch 02117: val_loss did not improve from 1.28148
Epoch 2118/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4171 - val_loss: 1.2897 - val_accuracy: 0.4211

Epoch 02118: val_loss did not improve from 1.28148
Epoch 2119/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4181 - val_loss: 1.2842 - val_accuracy: 0.4147

Epoch 02119: val_loss did not improve from 1.28148
Epoch 2120/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4162 - val_loss: 1.2832 - val_accuracy: 0.4314

Epoch 02120: val_loss did not improve from 1.28148
Epoch 2121/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4194 - val_loss: 1.2831 - val_accuracy: 0.4226

Epoch 02121: val_loss did not improve from 1.28148
Epoch 2122/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4190 - val_loss: 1.2832 - val_accuracy: 0.4211

Epoch 02122: val_loss did not improve from 1.28148
Epoch 2123/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4180 - val_loss: 1.2845 - val_accuracy: 0.4242

Epoch 02123: val_loss did not improve from 1.28148
Epoch 2124/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4166 - val_loss: 1.2841 - val_accuracy: 0.4306

Epoch 02124: val_loss did not improve from 1.28148
Epoch 2125/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4213 - val_loss: 1.2828 - val_accuracy: 0.4298

Epoch 02125: val_loss did not improve from 1.28148
Epoch 2126/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4179 - val_loss: 1.2825 - val_accuracy: 0.4242

Epoch 02126: val_loss did not improve from 1.28148
Epoch 2127/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4223 - val_loss: 1.2830 - val_accuracy: 0.4219

Epoch 02127: val_loss did not improve from 1.28148
Epoch 2128/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4176 - val_loss: 1.2846 - val_accuracy: 0.4298

Epoch 02128: val_loss did not improve from 1.28148
Epoch 2129/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4176 - val_loss: 1.2867 - val_accuracy: 0.4234

Epoch 02129: val_loss did not improve from 1.28148
Epoch 2130/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4158 - val_loss: 1.2855 - val_accuracy: 0.4195

Epoch 02130: val_loss did not improve from 1.28148
Epoch 2131/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4179 - val_loss: 1.2919 - val_accuracy: 0.4346

Epoch 02131: val_loss did not improve from 1.28148
Epoch 2132/10000
12/12 - 0s - loss: 1.2831 - accuracy: 0.4162 - val_loss: 1.2880 - val_accuracy: 0.4195

Epoch 02132: val_loss did not improve from 1.28148
Epoch 2133/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4155 - val_loss: 1.2835 - val_accuracy: 0.4155

Epoch 02133: val_loss did not improve from 1.28148
Epoch 2134/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4194 - val_loss: 1.2835 - val_accuracy: 0.4211

Epoch 02134: val_loss did not improve from 1.28148
Epoch 2135/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4206 - val_loss: 1.2851 - val_accuracy: 0.4195

Epoch 02135: val_loss did not improve from 1.28148
Epoch 2136/10000
12/12 - 0s - loss: 1.2821 - accuracy: 0.4187 - val_loss: 1.2842 - val_accuracy: 0.4163

Epoch 02136: val_loss did not improve from 1.28148
Epoch 2137/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4208 - val_loss: 1.2845 - val_accuracy: 0.4250

Epoch 02137: val_loss did not improve from 1.28148
Epoch 2138/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4175 - val_loss: 1.2850 - val_accuracy: 0.4234

Epoch 02138: val_loss did not improve from 1.28148
Epoch 2139/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4152 - val_loss: 1.2830 - val_accuracy: 0.4242

Epoch 02139: val_loss did not improve from 1.28148
Epoch 2140/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4145 - val_loss: 1.2833 - val_accuracy: 0.4242

Epoch 02140: val_loss did not improve from 1.28148
Epoch 2141/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4153 - val_loss: 1.2833 - val_accuracy: 0.4203

Epoch 02141: val_loss did not improve from 1.28148
Epoch 2142/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4204 - val_loss: 1.2845 - val_accuracy: 0.4242

Epoch 02142: val_loss did not improve from 1.28148
Epoch 2143/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4191 - val_loss: 1.2838 - val_accuracy: 0.4195

Epoch 02143: val_loss did not improve from 1.28148
Epoch 2144/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4185 - val_loss: 1.2851 - val_accuracy: 0.4250

Epoch 02144: val_loss did not improve from 1.28148
Epoch 2145/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4189 - val_loss: 1.2844 - val_accuracy: 0.4298

Epoch 02145: val_loss did not improve from 1.28148
Epoch 2146/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4181 - val_loss: 1.2848 - val_accuracy: 0.4187

Epoch 02146: val_loss did not improve from 1.28148
Epoch 2147/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4213 - val_loss: 1.2812 - val_accuracy: 0.4266

Epoch 02147: val_loss improved from 1.28148 to 1.28117, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2148/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4194 - val_loss: 1.2830 - val_accuracy: 0.4298

Epoch 02148: val_loss did not improve from 1.28117
Epoch 2149/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4182 - val_loss: 1.2842 - val_accuracy: 0.4219

Epoch 02149: val_loss did not improve from 1.28117
Epoch 2150/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4185 - val_loss: 1.2892 - val_accuracy: 0.4155

Epoch 02150: val_loss did not improve from 1.28117
Epoch 2151/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4175 - val_loss: 1.2860 - val_accuracy: 0.4242

Epoch 02151: val_loss did not improve from 1.28117
Epoch 2152/10000
12/12 - 0s - loss: 1.2855 - accuracy: 0.4189 - val_loss: 1.2829 - val_accuracy: 0.4234

Epoch 02152: val_loss did not improve from 1.28117
Epoch 2153/10000
12/12 - 0s - loss: 1.2850 - accuracy: 0.4177 - val_loss: 1.2900 - val_accuracy: 0.4226

Epoch 02153: val_loss did not improve from 1.28117
Epoch 2154/10000
12/12 - 0s - loss: 1.2795 - accuracy: 0.4192 - val_loss: 1.2897 - val_accuracy: 0.4330

Epoch 02154: val_loss did not improve from 1.28117
Epoch 2155/10000
12/12 - 0s - loss: 1.2944 - accuracy: 0.4157 - val_loss: 1.2954 - val_accuracy: 0.4163

Epoch 02155: val_loss did not improve from 1.28117
Epoch 2156/10000
12/12 - 0s - loss: 1.2832 - accuracy: 0.4139 - val_loss: 1.2829 - val_accuracy: 0.4195

Epoch 02156: val_loss did not improve from 1.28117
Epoch 2157/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4192 - val_loss: 1.2850 - val_accuracy: 0.4187

Epoch 02157: val_loss did not improve from 1.28117
Epoch 2158/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4195 - val_loss: 1.2870 - val_accuracy: 0.4306

Epoch 02158: val_loss did not improve from 1.28117
Epoch 2159/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4173 - val_loss: 1.2873 - val_accuracy: 0.4203

Epoch 02159: val_loss did not improve from 1.28117
Epoch 2160/10000
12/12 - 0s - loss: 1.2827 - accuracy: 0.4166 - val_loss: 1.2836 - val_accuracy: 0.4234

Epoch 02160: val_loss did not improve from 1.28117
Epoch 2161/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4179 - val_loss: 1.2876 - val_accuracy: 0.4386

Epoch 02161: val_loss did not improve from 1.28117
Epoch 2162/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4187 - val_loss: 1.2845 - val_accuracy: 0.4219

Epoch 02162: val_loss did not improve from 1.28117
Epoch 2163/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4193 - val_loss: 1.2838 - val_accuracy: 0.4250

Epoch 02163: val_loss did not improve from 1.28117
Epoch 2164/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4195 - val_loss: 1.2828 - val_accuracy: 0.4266

Epoch 02164: val_loss did not improve from 1.28117
Epoch 2165/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4216 - val_loss: 1.2848 - val_accuracy: 0.4155

Epoch 02165: val_loss did not improve from 1.28117
Epoch 2166/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4191 - val_loss: 1.2841 - val_accuracy: 0.4250

Epoch 02166: val_loss did not improve from 1.28117
Epoch 2167/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4199 - val_loss: 1.2846 - val_accuracy: 0.4219

Epoch 02167: val_loss did not improve from 1.28117
Epoch 2168/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4201 - val_loss: 1.2831 - val_accuracy: 0.4226

Epoch 02168: val_loss did not improve from 1.28117
Epoch 2169/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4202 - val_loss: 1.2834 - val_accuracy: 0.4250

Epoch 02169: val_loss did not improve from 1.28117
Epoch 2170/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4178 - val_loss: 1.2837 - val_accuracy: 0.4211

Epoch 02170: val_loss did not improve from 1.28117
Epoch 2171/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4186 - val_loss: 1.2835 - val_accuracy: 0.4314

Epoch 02171: val_loss did not improve from 1.28117
Epoch 2172/10000
12/12 - 0s - loss: 1.2807 - accuracy: 0.4139 - val_loss: 1.2868 - val_accuracy: 0.4211

Epoch 02172: val_loss did not improve from 1.28117
Epoch 2173/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4184 - val_loss: 1.2827 - val_accuracy: 0.4242

Epoch 02173: val_loss did not improve from 1.28117
Epoch 2174/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4187 - val_loss: 1.2831 - val_accuracy: 0.4242

Epoch 02174: val_loss did not improve from 1.28117
Epoch 2175/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4185 - val_loss: 1.2824 - val_accuracy: 0.4298

Epoch 02175: val_loss did not improve from 1.28117
Epoch 2176/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4184 - val_loss: 1.2830 - val_accuracy: 0.4195

Epoch 02176: val_loss did not improve from 1.28117
Epoch 2177/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4201 - val_loss: 1.2833 - val_accuracy: 0.4266

Epoch 02177: val_loss did not improve from 1.28117
Epoch 2178/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4210 - val_loss: 1.2838 - val_accuracy: 0.4314

Epoch 02178: val_loss did not improve from 1.28117
Epoch 2179/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4173 - val_loss: 1.2820 - val_accuracy: 0.4322

Epoch 02179: val_loss did not improve from 1.28117
Epoch 2180/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4160 - val_loss: 1.2842 - val_accuracy: 0.4314

Epoch 02180: val_loss did not improve from 1.28117
Epoch 2181/10000
12/12 - 0s - loss: 1.2783 - accuracy: 0.4187 - val_loss: 1.2837 - val_accuracy: 0.4258

Epoch 02181: val_loss did not improve from 1.28117
Epoch 2182/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4185 - val_loss: 1.2907 - val_accuracy: 0.4187

Epoch 02182: val_loss did not improve from 1.28117
Epoch 2183/10000
12/12 - 0s - loss: 1.2815 - accuracy: 0.4189 - val_loss: 1.2819 - val_accuracy: 0.4314

Epoch 02183: val_loss did not improve from 1.28117
Epoch 2184/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4210 - val_loss: 1.2832 - val_accuracy: 0.4234

Epoch 02184: val_loss did not improve from 1.28117
Epoch 2185/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4239 - val_loss: 1.2830 - val_accuracy: 0.4242

Epoch 02185: val_loss did not improve from 1.28117
Epoch 2186/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4208 - val_loss: 1.2828 - val_accuracy: 0.4234

Epoch 02186: val_loss did not improve from 1.28117
Epoch 2187/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4195 - val_loss: 1.2850 - val_accuracy: 0.4155

Epoch 02187: val_loss did not improve from 1.28117
Epoch 2188/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4171 - val_loss: 1.2814 - val_accuracy: 0.4306

Epoch 02188: val_loss did not improve from 1.28117
Epoch 2189/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4182 - val_loss: 1.2834 - val_accuracy: 0.4187

Epoch 02189: val_loss did not improve from 1.28117
Epoch 2190/10000
12/12 - 0s - loss: 1.2812 - accuracy: 0.4175 - val_loss: 1.2816 - val_accuracy: 0.4266

Epoch 02190: val_loss did not improve from 1.28117
Epoch 2191/10000
12/12 - 0s - loss: 1.2840 - accuracy: 0.4132 - val_loss: 1.2886 - val_accuracy: 0.4171

Epoch 02191: val_loss did not improve from 1.28117
Epoch 2192/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4182 - val_loss: 1.2817 - val_accuracy: 0.4290

Epoch 02192: val_loss did not improve from 1.28117
Epoch 2193/10000
12/12 - 0s - loss: 1.2804 - accuracy: 0.4181 - val_loss: 1.2870 - val_accuracy: 0.4195

Epoch 02193: val_loss did not improve from 1.28117
Epoch 2194/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4218 - val_loss: 1.2820 - val_accuracy: 0.4250

Epoch 02194: val_loss did not improve from 1.28117
Epoch 2195/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4218 - val_loss: 1.2830 - val_accuracy: 0.4234

Epoch 02195: val_loss did not improve from 1.28117
Epoch 2196/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4228 - val_loss: 1.2827 - val_accuracy: 0.4266

Epoch 02196: val_loss did not improve from 1.28117
Epoch 2197/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4186 - val_loss: 1.2835 - val_accuracy: 0.4290

Epoch 02197: val_loss did not improve from 1.28117
Epoch 2198/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4220 - val_loss: 1.2861 - val_accuracy: 0.4139

Epoch 02198: val_loss did not improve from 1.28117
Epoch 2199/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4170 - val_loss: 1.2844 - val_accuracy: 0.4219

Epoch 02199: val_loss did not improve from 1.28117
Epoch 2200/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4197 - val_loss: 1.2820 - val_accuracy: 0.4234

Epoch 02200: val_loss did not improve from 1.28117
Epoch 2201/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4192 - val_loss: 1.2853 - val_accuracy: 0.4219

Epoch 02201: val_loss did not improve from 1.28117
Epoch 2202/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4241 - val_loss: 1.2875 - val_accuracy: 0.4211

Epoch 02202: val_loss did not improve from 1.28117
Epoch 2203/10000
12/12 - 0s - loss: 1.2814 - accuracy: 0.4197 - val_loss: 1.2838 - val_accuracy: 0.4242

Epoch 02203: val_loss did not improve from 1.28117
Epoch 2204/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4225 - val_loss: 1.2816 - val_accuracy: 0.4242

Epoch 02204: val_loss did not improve from 1.28117
Epoch 2205/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4205 - val_loss: 1.2820 - val_accuracy: 0.4306

Epoch 02205: val_loss did not improve from 1.28117
Epoch 2206/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4225 - val_loss: 1.2817 - val_accuracy: 0.4290

Epoch 02206: val_loss did not improve from 1.28117
Epoch 2207/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4235 - val_loss: 1.2826 - val_accuracy: 0.4171

Epoch 02207: val_loss did not improve from 1.28117
Epoch 2208/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4151 - val_loss: 1.2857 - val_accuracy: 0.4203

Epoch 02208: val_loss did not improve from 1.28117
Epoch 2209/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4190 - val_loss: 1.2824 - val_accuracy: 0.4258

Epoch 02209: val_loss did not improve from 1.28117
Epoch 2210/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4223 - val_loss: 1.2830 - val_accuracy: 0.4211

Epoch 02210: val_loss did not improve from 1.28117
Epoch 2211/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4222 - val_loss: 1.2810 - val_accuracy: 0.4282

Epoch 02211: val_loss improved from 1.28117 to 1.28105, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2212/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4210 - val_loss: 1.2823 - val_accuracy: 0.4330

Epoch 02212: val_loss did not improve from 1.28105
Epoch 2213/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4199 - val_loss: 1.2837 - val_accuracy: 0.4362

Epoch 02213: val_loss did not improve from 1.28105
Epoch 2214/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4205 - val_loss: 1.2859 - val_accuracy: 0.4234

Epoch 02214: val_loss did not improve from 1.28105
Epoch 2215/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4210 - val_loss: 1.2818 - val_accuracy: 0.4290

Epoch 02215: val_loss did not improve from 1.28105
Epoch 2216/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4215 - val_loss: 1.2818 - val_accuracy: 0.4242

Epoch 02216: val_loss did not improve from 1.28105
Epoch 2217/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4205 - val_loss: 1.2823 - val_accuracy: 0.4250

Epoch 02217: val_loss did not improve from 1.28105
Epoch 2218/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4167 - val_loss: 1.2837 - val_accuracy: 0.4290

Epoch 02218: val_loss did not improve from 1.28105
Epoch 2219/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4187 - val_loss: 1.2817 - val_accuracy: 0.4242

Epoch 02219: val_loss did not improve from 1.28105
Epoch 2220/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4182 - val_loss: 1.2849 - val_accuracy: 0.4195

Epoch 02220: val_loss did not improve from 1.28105
Epoch 2221/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4199 - val_loss: 1.2814 - val_accuracy: 0.4219

Epoch 02221: val_loss did not improve from 1.28105
Epoch 2222/10000
12/12 - 0s - loss: 1.2793 - accuracy: 0.4207 - val_loss: 1.2810 - val_accuracy: 0.4274

Epoch 02222: val_loss improved from 1.28105 to 1.28098, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2223/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4187 - val_loss: 1.2852 - val_accuracy: 0.4314

Epoch 02223: val_loss did not improve from 1.28098
Epoch 2224/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4210 - val_loss: 1.2826 - val_accuracy: 0.4203

Epoch 02224: val_loss did not improve from 1.28098
Epoch 2225/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4180 - val_loss: 1.2863 - val_accuracy: 0.4211

Epoch 02225: val_loss did not improve from 1.28098
Epoch 2226/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4182 - val_loss: 1.2836 - val_accuracy: 0.4203

Epoch 02226: val_loss did not improve from 1.28098
Epoch 2227/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4205 - val_loss: 1.2839 - val_accuracy: 0.4171

Epoch 02227: val_loss did not improve from 1.28098
Epoch 2228/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4132 - val_loss: 1.2881 - val_accuracy: 0.4266

Epoch 02228: val_loss did not improve from 1.28098
Epoch 2229/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4182 - val_loss: 1.2836 - val_accuracy: 0.4266

Epoch 02229: val_loss did not improve from 1.28098
Epoch 2230/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4169 - val_loss: 1.2828 - val_accuracy: 0.4266

Epoch 02230: val_loss did not improve from 1.28098
Epoch 2231/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4198 - val_loss: 1.2877 - val_accuracy: 0.4203

Epoch 02231: val_loss did not improve from 1.28098
Epoch 2232/10000
12/12 - 0s - loss: 1.2897 - accuracy: 0.4168 - val_loss: 1.2829 - val_accuracy: 0.4242

Epoch 02232: val_loss did not improve from 1.28098
Epoch 2233/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4191 - val_loss: 1.2889 - val_accuracy: 0.4274

Epoch 02233: val_loss did not improve from 1.28098
Epoch 2234/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4134 - val_loss: 1.2830 - val_accuracy: 0.4234

Epoch 02234: val_loss did not improve from 1.28098
Epoch 2235/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4174 - val_loss: 1.2800 - val_accuracy: 0.4346

Epoch 02235: val_loss improved from 1.28098 to 1.28004, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2236/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4180 - val_loss: 1.2841 - val_accuracy: 0.4226

Epoch 02236: val_loss did not improve from 1.28004
Epoch 2237/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4195 - val_loss: 1.2807 - val_accuracy: 0.4306

Epoch 02237: val_loss did not improve from 1.28004
Epoch 2238/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4190 - val_loss: 1.2844 - val_accuracy: 0.4211

Epoch 02238: val_loss did not improve from 1.28004
Epoch 2239/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4175 - val_loss: 1.2900 - val_accuracy: 0.4266

Epoch 02239: val_loss did not improve from 1.28004
Epoch 2240/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4195 - val_loss: 1.2898 - val_accuracy: 0.4171

Epoch 02240: val_loss did not improve from 1.28004
Epoch 2241/10000
12/12 - 0s - loss: 1.2848 - accuracy: 0.4128 - val_loss: 1.2864 - val_accuracy: 0.4242

Epoch 02241: val_loss did not improve from 1.28004
Epoch 2242/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4183 - val_loss: 1.2844 - val_accuracy: 0.4282

Epoch 02242: val_loss did not improve from 1.28004
Epoch 2243/10000
12/12 - 0s - loss: 1.2802 - accuracy: 0.4150 - val_loss: 1.2913 - val_accuracy: 0.4250

Epoch 02243: val_loss did not improve from 1.28004
Epoch 2244/10000
12/12 - 0s - loss: 1.2818 - accuracy: 0.4153 - val_loss: 1.2834 - val_accuracy: 0.4219

Epoch 02244: val_loss did not improve from 1.28004
Epoch 2245/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4182 - val_loss: 1.2810 - val_accuracy: 0.4290

Epoch 02245: val_loss did not improve from 1.28004
Epoch 2246/10000
12/12 - 0s - loss: 1.2837 - accuracy: 0.4156 - val_loss: 1.2872 - val_accuracy: 0.4107

Epoch 02246: val_loss did not improve from 1.28004
Epoch 2247/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4212 - val_loss: 1.2826 - val_accuracy: 0.4155

Epoch 02247: val_loss did not improve from 1.28004
Epoch 2248/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4179 - val_loss: 1.2806 - val_accuracy: 0.4179

Epoch 02248: val_loss did not improve from 1.28004
Epoch 2249/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4195 - val_loss: 1.2813 - val_accuracy: 0.4258

Epoch 02249: val_loss did not improve from 1.28004
Epoch 2250/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4185 - val_loss: 1.2866 - val_accuracy: 0.4219

Epoch 02250: val_loss did not improve from 1.28004
Epoch 2251/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4138 - val_loss: 1.2808 - val_accuracy: 0.4330

Epoch 02251: val_loss did not improve from 1.28004
Epoch 2252/10000
12/12 - 0s - loss: 1.2794 - accuracy: 0.4184 - val_loss: 1.2928 - val_accuracy: 0.4234

Epoch 02252: val_loss did not improve from 1.28004
Epoch 2253/10000
12/12 - 0s - loss: 1.2852 - accuracy: 0.4134 - val_loss: 1.2823 - val_accuracy: 0.4203

Epoch 02253: val_loss did not improve from 1.28004
Epoch 2254/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4194 - val_loss: 1.2814 - val_accuracy: 0.4306

Epoch 02254: val_loss did not improve from 1.28004
Epoch 2255/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4187 - val_loss: 1.2819 - val_accuracy: 0.4330

Epoch 02255: val_loss did not improve from 1.28004
Epoch 2256/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4187 - val_loss: 1.2829 - val_accuracy: 0.4219

Epoch 02256: val_loss did not improve from 1.28004
Epoch 2257/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4179 - val_loss: 1.2820 - val_accuracy: 0.4274

Epoch 02257: val_loss did not improve from 1.28004
Epoch 2258/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4195 - val_loss: 1.2872 - val_accuracy: 0.4250

Epoch 02258: val_loss did not improve from 1.28004
Epoch 2259/10000
12/12 - 0s - loss: 1.2829 - accuracy: 0.4187 - val_loss: 1.2800 - val_accuracy: 0.4250

Epoch 02259: val_loss improved from 1.28004 to 1.28002, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2260/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4179 - val_loss: 1.2839 - val_accuracy: 0.4298

Epoch 02260: val_loss did not improve from 1.28002
Epoch 2261/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4215 - val_loss: 1.2858 - val_accuracy: 0.4131

Epoch 02261: val_loss did not improve from 1.28002
Epoch 2262/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4186 - val_loss: 1.2813 - val_accuracy: 0.4266

Epoch 02262: val_loss did not improve from 1.28002
Epoch 2263/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4200 - val_loss: 1.2808 - val_accuracy: 0.4282

Epoch 02263: val_loss did not improve from 1.28002
Epoch 2264/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4196 - val_loss: 1.2811 - val_accuracy: 0.4171

Epoch 02264: val_loss did not improve from 1.28002
Epoch 2265/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4206 - val_loss: 1.2816 - val_accuracy: 0.4226

Epoch 02265: val_loss did not improve from 1.28002
Epoch 2266/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4194 - val_loss: 1.2852 - val_accuracy: 0.4226

Epoch 02266: val_loss did not improve from 1.28002
Epoch 2267/10000
12/12 - 0s - loss: 1.2798 - accuracy: 0.4163 - val_loss: 1.2834 - val_accuracy: 0.4155

Epoch 02267: val_loss did not improve from 1.28002
Epoch 2268/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4216 - val_loss: 1.2816 - val_accuracy: 0.4274

Epoch 02268: val_loss did not improve from 1.28002
Epoch 2269/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4190 - val_loss: 1.2881 - val_accuracy: 0.4139

Epoch 02269: val_loss did not improve from 1.28002
Epoch 2270/10000
12/12 - 0s - loss: 1.2841 - accuracy: 0.4147 - val_loss: 1.2938 - val_accuracy: 0.4250

Epoch 02270: val_loss did not improve from 1.28002
Epoch 2271/10000
12/12 - 0s - loss: 1.2833 - accuracy: 0.4171 - val_loss: 1.2814 - val_accuracy: 0.4306

Epoch 02271: val_loss did not improve from 1.28002
Epoch 2272/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4194 - val_loss: 1.2859 - val_accuracy: 0.4163

Epoch 02272: val_loss did not improve from 1.28002
Epoch 2273/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4215 - val_loss: 1.2822 - val_accuracy: 0.4219

Epoch 02273: val_loss did not improve from 1.28002
Epoch 2274/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4208 - val_loss: 1.2812 - val_accuracy: 0.4314

Epoch 02274: val_loss did not improve from 1.28002
Epoch 2275/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4201 - val_loss: 1.2823 - val_accuracy: 0.4242

Epoch 02275: val_loss did not improve from 1.28002
Epoch 2276/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4147 - val_loss: 1.2838 - val_accuracy: 0.4354

Epoch 02276: val_loss did not improve from 1.28002
Epoch 2277/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4198 - val_loss: 1.2830 - val_accuracy: 0.4242

Epoch 02277: val_loss did not improve from 1.28002
Epoch 2278/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4181 - val_loss: 1.2835 - val_accuracy: 0.4274

Epoch 02278: val_loss did not improve from 1.28002
Epoch 2279/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4177 - val_loss: 1.2817 - val_accuracy: 0.4250

Epoch 02279: val_loss did not improve from 1.28002
Epoch 2280/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4209 - val_loss: 1.2864 - val_accuracy: 0.4179

Epoch 02280: val_loss did not improve from 1.28002
Epoch 2281/10000
12/12 - 0s - loss: 1.2839 - accuracy: 0.4188 - val_loss: 1.2857 - val_accuracy: 0.4306

Epoch 02281: val_loss did not improve from 1.28002
Epoch 2282/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4202 - val_loss: 1.2815 - val_accuracy: 0.4298

Epoch 02282: val_loss did not improve from 1.28002
Epoch 2283/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4225 - val_loss: 1.2844 - val_accuracy: 0.4203

Epoch 02283: val_loss did not improve from 1.28002
Epoch 2284/10000
12/12 - 0s - loss: 1.2770 - accuracy: 0.4215 - val_loss: 1.2837 - val_accuracy: 0.4258

Epoch 02284: val_loss did not improve from 1.28002
Epoch 2285/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4194 - val_loss: 1.2821 - val_accuracy: 0.4171

Epoch 02285: val_loss did not improve from 1.28002
Epoch 2286/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4202 - val_loss: 1.2850 - val_accuracy: 0.4219

Epoch 02286: val_loss did not improve from 1.28002
Epoch 2287/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4187 - val_loss: 1.2820 - val_accuracy: 0.4370

Epoch 02287: val_loss did not improve from 1.28002
Epoch 2288/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4232 - val_loss: 1.2831 - val_accuracy: 0.4338

Epoch 02288: val_loss did not improve from 1.28002
Epoch 2289/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4218 - val_loss: 1.2833 - val_accuracy: 0.4274

Epoch 02289: val_loss did not improve from 1.28002
Epoch 2290/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4208 - val_loss: 1.2827 - val_accuracy: 0.4226

Epoch 02290: val_loss did not improve from 1.28002
Epoch 2291/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4184 - val_loss: 1.2838 - val_accuracy: 0.4234

Epoch 02291: val_loss did not improve from 1.28002
Epoch 2292/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4200 - val_loss: 1.2829 - val_accuracy: 0.4211

Epoch 02292: val_loss did not improve from 1.28002
Epoch 2293/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4210 - val_loss: 1.2832 - val_accuracy: 0.4242

Epoch 02293: val_loss did not improve from 1.28002
Epoch 2294/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4189 - val_loss: 1.2815 - val_accuracy: 0.4234

Epoch 02294: val_loss did not improve from 1.28002
Epoch 2295/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4215 - val_loss: 1.2818 - val_accuracy: 0.4298

Epoch 02295: val_loss did not improve from 1.28002
Epoch 2296/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4175 - val_loss: 1.2812 - val_accuracy: 0.4187

Epoch 02296: val_loss did not improve from 1.28002
Epoch 2297/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4210 - val_loss: 1.2820 - val_accuracy: 0.4155

Epoch 02297: val_loss did not improve from 1.28002
Epoch 2298/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4194 - val_loss: 1.2819 - val_accuracy: 0.4234

Epoch 02298: val_loss did not improve from 1.28002
Epoch 2299/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4247 - val_loss: 1.2823 - val_accuracy: 0.4234

Epoch 02299: val_loss did not improve from 1.28002
Epoch 2300/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4211 - val_loss: 1.2840 - val_accuracy: 0.4266

Epoch 02300: val_loss did not improve from 1.28002
Epoch 2301/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4180 - val_loss: 1.2828 - val_accuracy: 0.4219

Epoch 02301: val_loss did not improve from 1.28002
Epoch 2302/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4183 - val_loss: 1.2812 - val_accuracy: 0.4234

Epoch 02302: val_loss did not improve from 1.28002
Epoch 2303/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4199 - val_loss: 1.2825 - val_accuracy: 0.4234

Epoch 02303: val_loss did not improve from 1.28002
Epoch 2304/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4208 - val_loss: 1.2821 - val_accuracy: 0.4274

Epoch 02304: val_loss did not improve from 1.28002
Epoch 2305/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4202 - val_loss: 1.2827 - val_accuracy: 0.4258

Epoch 02305: val_loss did not improve from 1.28002
Epoch 2306/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4196 - val_loss: 1.2841 - val_accuracy: 0.4139

Epoch 02306: val_loss did not improve from 1.28002
Epoch 2307/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4151 - val_loss: 1.2826 - val_accuracy: 0.4250

Epoch 02307: val_loss did not improve from 1.28002
Epoch 2308/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4184 - val_loss: 1.2816 - val_accuracy: 0.4250

Epoch 02308: val_loss did not improve from 1.28002
Epoch 2309/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4168 - val_loss: 1.2888 - val_accuracy: 0.4147

Epoch 02309: val_loss did not improve from 1.28002
Epoch 2310/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4151 - val_loss: 1.2821 - val_accuracy: 0.4226

Epoch 02310: val_loss did not improve from 1.28002
Epoch 2311/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4207 - val_loss: 1.2843 - val_accuracy: 0.4282

Epoch 02311: val_loss did not improve from 1.28002
Epoch 2312/10000
12/12 - 0s - loss: 1.2813 - accuracy: 0.4201 - val_loss: 1.2857 - val_accuracy: 0.4203

Epoch 02312: val_loss did not improve from 1.28002
Epoch 2313/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4202 - val_loss: 1.2830 - val_accuracy: 0.4195

Epoch 02313: val_loss did not improve from 1.28002
Epoch 2314/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4194 - val_loss: 1.2826 - val_accuracy: 0.4163

Epoch 02314: val_loss did not improve from 1.28002
Epoch 2315/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4184 - val_loss: 1.2817 - val_accuracy: 0.4219

Epoch 02315: val_loss did not improve from 1.28002
Epoch 2316/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4179 - val_loss: 1.2827 - val_accuracy: 0.4306

Epoch 02316: val_loss did not improve from 1.28002
Epoch 2317/10000
12/12 - 0s - loss: 1.2776 - accuracy: 0.4181 - val_loss: 1.2858 - val_accuracy: 0.4258

Epoch 02317: val_loss did not improve from 1.28002
Epoch 2318/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4194 - val_loss: 1.2828 - val_accuracy: 0.4266

Epoch 02318: val_loss did not improve from 1.28002
Epoch 2319/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4209 - val_loss: 1.2830 - val_accuracy: 0.4266

Epoch 02319: val_loss did not improve from 1.28002
Epoch 2320/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4207 - val_loss: 1.2841 - val_accuracy: 0.4234

Epoch 02320: val_loss did not improve from 1.28002
Epoch 2321/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4213 - val_loss: 1.2862 - val_accuracy: 0.4179

Epoch 02321: val_loss did not improve from 1.28002
Epoch 2322/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4178 - val_loss: 1.2824 - val_accuracy: 0.4187

Epoch 02322: val_loss did not improve from 1.28002
Epoch 2323/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4223 - val_loss: 1.2816 - val_accuracy: 0.4171

Epoch 02323: val_loss did not improve from 1.28002
Epoch 2324/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4209 - val_loss: 1.2817 - val_accuracy: 0.4282

Epoch 02324: val_loss did not improve from 1.28002
Epoch 2325/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4167 - val_loss: 1.2815 - val_accuracy: 0.4314

Epoch 02325: val_loss did not improve from 1.28002
Epoch 2326/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4197 - val_loss: 1.2808 - val_accuracy: 0.4226

Epoch 02326: val_loss did not improve from 1.28002
Epoch 2327/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4178 - val_loss: 1.2816 - val_accuracy: 0.4258

Epoch 02327: val_loss did not improve from 1.28002
Epoch 2328/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4204 - val_loss: 1.2875 - val_accuracy: 0.4282

Epoch 02328: val_loss did not improve from 1.28002
Epoch 2329/10000
12/12 - 0s - loss: 1.2875 - accuracy: 0.4160 - val_loss: 1.2860 - val_accuracy: 0.4203

Epoch 02329: val_loss did not improve from 1.28002
Epoch 2330/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4205 - val_loss: 1.2876 - val_accuracy: 0.4226

Epoch 02330: val_loss did not improve from 1.28002
Epoch 2331/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4209 - val_loss: 1.2834 - val_accuracy: 0.4258

Epoch 02331: val_loss did not improve from 1.28002
Epoch 2332/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4184 - val_loss: 1.2857 - val_accuracy: 0.4115

Epoch 02332: val_loss did not improve from 1.28002
Epoch 2333/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4186 - val_loss: 1.2822 - val_accuracy: 0.4290

Epoch 02333: val_loss did not improve from 1.28002
Epoch 2334/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4219 - val_loss: 1.2837 - val_accuracy: 0.4219

Epoch 02334: val_loss did not improve from 1.28002
Epoch 2335/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4199 - val_loss: 1.2813 - val_accuracy: 0.4250

Epoch 02335: val_loss did not improve from 1.28002
Epoch 2336/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4210 - val_loss: 1.2806 - val_accuracy: 0.4266

Epoch 02336: val_loss did not improve from 1.28002
Epoch 2337/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4209 - val_loss: 1.2851 - val_accuracy: 0.4203

Epoch 02337: val_loss did not improve from 1.28002
Epoch 2338/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4190 - val_loss: 1.2866 - val_accuracy: 0.4179

Epoch 02338: val_loss did not improve from 1.28002
Epoch 2339/10000
12/12 - 0s - loss: 1.2872 - accuracy: 0.4153 - val_loss: 1.2829 - val_accuracy: 0.4258

Epoch 02339: val_loss did not improve from 1.28002
Epoch 2340/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4185 - val_loss: 1.2826 - val_accuracy: 0.4298

Epoch 02340: val_loss did not improve from 1.28002
Epoch 2341/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4205 - val_loss: 1.2811 - val_accuracy: 0.4298

Epoch 02341: val_loss did not improve from 1.28002
Epoch 2342/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4227 - val_loss: 1.2810 - val_accuracy: 0.4242

Epoch 02342: val_loss did not improve from 1.28002
Epoch 2343/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4212 - val_loss: 1.2834 - val_accuracy: 0.4059

Epoch 02343: val_loss did not improve from 1.28002
Epoch 2344/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4173 - val_loss: 1.2823 - val_accuracy: 0.4211

Epoch 02344: val_loss did not improve from 1.28002
Epoch 2345/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4194 - val_loss: 1.2825 - val_accuracy: 0.4242

Epoch 02345: val_loss did not improve from 1.28002
Epoch 2346/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4180 - val_loss: 1.2816 - val_accuracy: 0.4250

Epoch 02346: val_loss did not improve from 1.28002
Epoch 2347/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4213 - val_loss: 1.2802 - val_accuracy: 0.4282

Epoch 02347: val_loss did not improve from 1.28002
Epoch 2348/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4222 - val_loss: 1.2835 - val_accuracy: 0.4203

Epoch 02348: val_loss did not improve from 1.28002
Epoch 2349/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4198 - val_loss: 1.2815 - val_accuracy: 0.4314

Epoch 02349: val_loss did not improve from 1.28002
Epoch 2350/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4199 - val_loss: 1.2820 - val_accuracy: 0.4234

Epoch 02350: val_loss did not improve from 1.28002
Epoch 2351/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4213 - val_loss: 1.2810 - val_accuracy: 0.4290

Epoch 02351: val_loss did not improve from 1.28002
Epoch 2352/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4214 - val_loss: 1.2834 - val_accuracy: 0.4219

Epoch 02352: val_loss did not improve from 1.28002
Epoch 2353/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4204 - val_loss: 1.2830 - val_accuracy: 0.4314

Epoch 02353: val_loss did not improve from 1.28002
Epoch 2354/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4226 - val_loss: 1.2821 - val_accuracy: 0.4258

Epoch 02354: val_loss did not improve from 1.28002
Epoch 2355/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4196 - val_loss: 1.2817 - val_accuracy: 0.4290

Epoch 02355: val_loss did not improve from 1.28002
Epoch 2356/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4239 - val_loss: 1.2810 - val_accuracy: 0.4250

Epoch 02356: val_loss did not improve from 1.28002
Epoch 2357/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4200 - val_loss: 1.2815 - val_accuracy: 0.4266

Epoch 02357: val_loss did not improve from 1.28002
Epoch 2358/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4195 - val_loss: 1.2830 - val_accuracy: 0.4163

Epoch 02358: val_loss did not improve from 1.28002
Epoch 2359/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4215 - val_loss: 1.2817 - val_accuracy: 0.4274

Epoch 02359: val_loss did not improve from 1.28002
Epoch 2360/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4217 - val_loss: 1.2836 - val_accuracy: 0.4306

Epoch 02360: val_loss did not improve from 1.28002
Epoch 2361/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4205 - val_loss: 1.2818 - val_accuracy: 0.4250

Epoch 02361: val_loss did not improve from 1.28002
Epoch 2362/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4191 - val_loss: 1.2823 - val_accuracy: 0.4203

Epoch 02362: val_loss did not improve from 1.28002
Epoch 2363/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4206 - val_loss: 1.2825 - val_accuracy: 0.4258

Epoch 02363: val_loss did not improve from 1.28002
Epoch 2364/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4196 - val_loss: 1.2828 - val_accuracy: 0.4282

Epoch 02364: val_loss did not improve from 1.28002
Epoch 2365/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4220 - val_loss: 1.2804 - val_accuracy: 0.4322

Epoch 02365: val_loss did not improve from 1.28002
Epoch 2366/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4194 - val_loss: 1.2824 - val_accuracy: 0.4187

Epoch 02366: val_loss did not improve from 1.28002
Epoch 2367/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4166 - val_loss: 1.2849 - val_accuracy: 0.4123

Epoch 02367: val_loss did not improve from 1.28002
Epoch 2368/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4174 - val_loss: 1.2820 - val_accuracy: 0.4234

Epoch 02368: val_loss did not improve from 1.28002
Epoch 2369/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4234 - val_loss: 1.2808 - val_accuracy: 0.4211

Epoch 02369: val_loss did not improve from 1.28002
Epoch 2370/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4195 - val_loss: 1.2813 - val_accuracy: 0.4314

Epoch 02370: val_loss did not improve from 1.28002
Epoch 2371/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4174 - val_loss: 1.2851 - val_accuracy: 0.4219

Epoch 02371: val_loss did not improve from 1.28002
Epoch 2372/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4202 - val_loss: 1.2813 - val_accuracy: 0.4274

Epoch 02372: val_loss did not improve from 1.28002
Epoch 2373/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4159 - val_loss: 1.2811 - val_accuracy: 0.4322

Epoch 02373: val_loss did not improve from 1.28002
Epoch 2374/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4196 - val_loss: 1.2813 - val_accuracy: 0.4211

Epoch 02374: val_loss did not improve from 1.28002
Epoch 2375/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4202 - val_loss: 1.2821 - val_accuracy: 0.4195

Epoch 02375: val_loss did not improve from 1.28002
Epoch 2376/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4187 - val_loss: 1.2818 - val_accuracy: 0.4242

Epoch 02376: val_loss did not improve from 1.28002
Epoch 2377/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4224 - val_loss: 1.2828 - val_accuracy: 0.4234

Epoch 02377: val_loss did not improve from 1.28002
Epoch 2378/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4194 - val_loss: 1.2821 - val_accuracy: 0.4163

Epoch 02378: val_loss did not improve from 1.28002
Epoch 2379/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4197 - val_loss: 1.2904 - val_accuracy: 0.4163

Epoch 02379: val_loss did not improve from 1.28002
Epoch 2380/10000
12/12 - 0s - loss: 1.2834 - accuracy: 0.4180 - val_loss: 1.2815 - val_accuracy: 0.4258

Epoch 02380: val_loss did not improve from 1.28002
Epoch 2381/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4207 - val_loss: 1.2816 - val_accuracy: 0.4274

Epoch 02381: val_loss did not improve from 1.28002
Epoch 2382/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4157 - val_loss: 1.2824 - val_accuracy: 0.4306

Epoch 02382: val_loss did not improve from 1.28002
Epoch 2383/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4199 - val_loss: 1.2845 - val_accuracy: 0.4250

Epoch 02383: val_loss did not improve from 1.28002
Epoch 2384/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4201 - val_loss: 1.2864 - val_accuracy: 0.4147

Epoch 02384: val_loss did not improve from 1.28002
Epoch 2385/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4200 - val_loss: 1.2810 - val_accuracy: 0.4219

Epoch 02385: val_loss did not improve from 1.28002
Epoch 2386/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4204 - val_loss: 1.2810 - val_accuracy: 0.4242

Epoch 02386: val_loss did not improve from 1.28002
Epoch 2387/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4183 - val_loss: 1.2797 - val_accuracy: 0.4226

Epoch 02387: val_loss improved from 1.28002 to 1.27968, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2388/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4197 - val_loss: 1.2810 - val_accuracy: 0.4234

Epoch 02388: val_loss did not improve from 1.27968
Epoch 2389/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4214 - val_loss: 1.2807 - val_accuracy: 0.4266

Epoch 02389: val_loss did not improve from 1.27968
Epoch 2390/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4209 - val_loss: 1.2800 - val_accuracy: 0.4258

Epoch 02390: val_loss did not improve from 1.27968
Epoch 2391/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4210 - val_loss: 1.2820 - val_accuracy: 0.4226

Epoch 02391: val_loss did not improve from 1.27968
Epoch 2392/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4214 - val_loss: 1.2839 - val_accuracy: 0.4226

Epoch 02392: val_loss did not improve from 1.27968
Epoch 2393/10000
12/12 - 0s - loss: 1.2789 - accuracy: 0.4181 - val_loss: 1.2824 - val_accuracy: 0.4298

Epoch 02393: val_loss did not improve from 1.27968
Epoch 2394/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4202 - val_loss: 1.2798 - val_accuracy: 0.4330

Epoch 02394: val_loss did not improve from 1.27968
Epoch 2395/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4233 - val_loss: 1.2842 - val_accuracy: 0.4250

Epoch 02395: val_loss did not improve from 1.27968
Epoch 2396/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4196 - val_loss: 1.2804 - val_accuracy: 0.4211

Epoch 02396: val_loss did not improve from 1.27968
Epoch 2397/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4218 - val_loss: 1.2813 - val_accuracy: 0.4195

Epoch 02397: val_loss did not improve from 1.27968
Epoch 2398/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4193 - val_loss: 1.2825 - val_accuracy: 0.4187

Epoch 02398: val_loss did not improve from 1.27968
Epoch 2399/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4228 - val_loss: 1.2807 - val_accuracy: 0.4250

Epoch 02399: val_loss did not improve from 1.27968
Epoch 2400/10000
12/12 - 0s - loss: 1.2806 - accuracy: 0.4180 - val_loss: 1.2833 - val_accuracy: 0.4163

Epoch 02400: val_loss did not improve from 1.27968
Epoch 2401/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4199 - val_loss: 1.2832 - val_accuracy: 0.4250

Epoch 02401: val_loss did not improve from 1.27968
Epoch 2402/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4211 - val_loss: 1.2826 - val_accuracy: 0.4187

Epoch 02402: val_loss did not improve from 1.27968
Epoch 2403/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4224 - val_loss: 1.2826 - val_accuracy: 0.4346

Epoch 02403: val_loss did not improve from 1.27968
Epoch 2404/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4230 - val_loss: 1.2821 - val_accuracy: 0.4290

Epoch 02404: val_loss did not improve from 1.27968
Epoch 2405/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4247 - val_loss: 1.2829 - val_accuracy: 0.4274

Epoch 02405: val_loss did not improve from 1.27968
Epoch 2406/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4202 - val_loss: 1.2817 - val_accuracy: 0.4258

Epoch 02406: val_loss did not improve from 1.27968
Epoch 2407/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4214 - val_loss: 1.2811 - val_accuracy: 0.4234

Epoch 02407: val_loss did not improve from 1.27968
Epoch 2408/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4213 - val_loss: 1.3071 - val_accuracy: 0.4211

Epoch 02408: val_loss did not improve from 1.27968
Epoch 2409/10000
12/12 - 0s - loss: 1.3016 - accuracy: 0.4086 - val_loss: 1.2815 - val_accuracy: 0.4282

Epoch 02409: val_loss did not improve from 1.27968
Epoch 2410/10000
12/12 - 0s - loss: 1.2843 - accuracy: 0.4181 - val_loss: 1.2920 - val_accuracy: 0.4147

Epoch 02410: val_loss did not improve from 1.27968
Epoch 2411/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4203 - val_loss: 1.2862 - val_accuracy: 0.4179

Epoch 02411: val_loss did not improve from 1.27968
Epoch 2412/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4171 - val_loss: 1.2825 - val_accuracy: 0.4179

Epoch 02412: val_loss did not improve from 1.27968
Epoch 2413/10000
12/12 - 0s - loss: 1.2874 - accuracy: 0.4151 - val_loss: 1.2828 - val_accuracy: 0.4314

Epoch 02413: val_loss did not improve from 1.27968
Epoch 2414/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4194 - val_loss: 1.2835 - val_accuracy: 0.4306

Epoch 02414: val_loss did not improve from 1.27968
Epoch 2415/10000
12/12 - 0s - loss: 1.2787 - accuracy: 0.4193 - val_loss: 1.2848 - val_accuracy: 0.4147

Epoch 02415: val_loss did not improve from 1.27968
Epoch 2416/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4189 - val_loss: 1.2828 - val_accuracy: 0.4306

Epoch 02416: val_loss did not improve from 1.27968
Epoch 2417/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4206 - val_loss: 1.2895 - val_accuracy: 0.4234

Epoch 02417: val_loss did not improve from 1.27968
Epoch 2418/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4226 - val_loss: 1.2906 - val_accuracy: 0.4195

Epoch 02418: val_loss did not improve from 1.27968
Epoch 2419/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4191 - val_loss: 1.2807 - val_accuracy: 0.4274

Epoch 02419: val_loss did not improve from 1.27968
Epoch 2420/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4192 - val_loss: 1.2803 - val_accuracy: 0.4258

Epoch 02420: val_loss did not improve from 1.27968
Epoch 2421/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4216 - val_loss: 1.2801 - val_accuracy: 0.4266

Epoch 02421: val_loss did not improve from 1.27968
Epoch 2422/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4173 - val_loss: 1.2810 - val_accuracy: 0.4203

Epoch 02422: val_loss did not improve from 1.27968
Epoch 2423/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4212 - val_loss: 1.2810 - val_accuracy: 0.4163

Epoch 02423: val_loss did not improve from 1.27968
Epoch 2424/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4225 - val_loss: 1.2819 - val_accuracy: 0.4274

Epoch 02424: val_loss did not improve from 1.27968
Epoch 2425/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4194 - val_loss: 1.2814 - val_accuracy: 0.4219

Epoch 02425: val_loss did not improve from 1.27968
Epoch 2426/10000
12/12 - 0s - loss: 1.2811 - accuracy: 0.4213 - val_loss: 1.2845 - val_accuracy: 0.4203

Epoch 02426: val_loss did not improve from 1.27968
Epoch 2427/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4230 - val_loss: 1.2828 - val_accuracy: 0.4171

Epoch 02427: val_loss did not improve from 1.27968
Epoch 2428/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4211 - val_loss: 1.2808 - val_accuracy: 0.4234

Epoch 02428: val_loss did not improve from 1.27968
Epoch 2429/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4217 - val_loss: 1.2814 - val_accuracy: 0.4195

Epoch 02429: val_loss did not improve from 1.27968
Epoch 2430/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4212 - val_loss: 1.2833 - val_accuracy: 0.4195

Epoch 02430: val_loss did not improve from 1.27968
Epoch 2431/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4223 - val_loss: 1.2815 - val_accuracy: 0.4266

Epoch 02431: val_loss did not improve from 1.27968
Epoch 2432/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4188 - val_loss: 1.2832 - val_accuracy: 0.4290

Epoch 02432: val_loss did not improve from 1.27968
Epoch 2433/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4202 - val_loss: 1.2792 - val_accuracy: 0.4179

Epoch 02433: val_loss improved from 1.27968 to 1.27919, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2434/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4196 - val_loss: 1.2825 - val_accuracy: 0.4226

Epoch 02434: val_loss did not improve from 1.27919
Epoch 2435/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4232 - val_loss: 1.2832 - val_accuracy: 0.4171

Epoch 02435: val_loss did not improve from 1.27919
Epoch 2436/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4239 - val_loss: 1.2830 - val_accuracy: 0.4139

Epoch 02436: val_loss did not improve from 1.27919
Epoch 2437/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4202 - val_loss: 1.2872 - val_accuracy: 0.4099

Epoch 02437: val_loss did not improve from 1.27919
Epoch 2438/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4218 - val_loss: 1.2823 - val_accuracy: 0.4179

Epoch 02438: val_loss did not improve from 1.27919
Epoch 2439/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4192 - val_loss: 1.2827 - val_accuracy: 0.4203

Epoch 02439: val_loss did not improve from 1.27919
Epoch 2440/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4226 - val_loss: 1.2826 - val_accuracy: 0.4147

Epoch 02440: val_loss did not improve from 1.27919
Epoch 2441/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4213 - val_loss: 1.2815 - val_accuracy: 0.4234

Epoch 02441: val_loss did not improve from 1.27919
Epoch 2442/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4214 - val_loss: 1.2820 - val_accuracy: 0.4274

Epoch 02442: val_loss did not improve from 1.27919
Epoch 2443/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4213 - val_loss: 1.2866 - val_accuracy: 0.4290

Epoch 02443: val_loss did not improve from 1.27919
Epoch 2444/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4181 - val_loss: 1.2807 - val_accuracy: 0.4282

Epoch 02444: val_loss did not improve from 1.27919
Epoch 2445/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4227 - val_loss: 1.2802 - val_accuracy: 0.4258

Epoch 02445: val_loss did not improve from 1.27919
Epoch 2446/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4205 - val_loss: 1.2800 - val_accuracy: 0.4187

Epoch 02446: val_loss did not improve from 1.27919
Epoch 2447/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4258 - val_loss: 1.2807 - val_accuracy: 0.4234

Epoch 02447: val_loss did not improve from 1.27919
Epoch 2448/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4259 - val_loss: 1.2877 - val_accuracy: 0.4131

Epoch 02448: val_loss did not improve from 1.27919
Epoch 2449/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4194 - val_loss: 1.2812 - val_accuracy: 0.4290

Epoch 02449: val_loss did not improve from 1.27919
Epoch 2450/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4225 - val_loss: 1.2800 - val_accuracy: 0.4234

Epoch 02450: val_loss did not improve from 1.27919
Epoch 2451/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4216 - val_loss: 1.2828 - val_accuracy: 0.4163

Epoch 02451: val_loss did not improve from 1.27919
Epoch 2452/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4206 - val_loss: 1.2837 - val_accuracy: 0.4330

Epoch 02452: val_loss did not improve from 1.27919
Epoch 2453/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4195 - val_loss: 1.2819 - val_accuracy: 0.4195

Epoch 02453: val_loss did not improve from 1.27919
Epoch 2454/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4194 - val_loss: 1.2847 - val_accuracy: 0.4179

Epoch 02454: val_loss did not improve from 1.27919
Epoch 2455/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4196 - val_loss: 1.2811 - val_accuracy: 0.4330

Epoch 02455: val_loss did not improve from 1.27919
Epoch 2456/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4206 - val_loss: 1.2876 - val_accuracy: 0.4171

Epoch 02456: val_loss did not improve from 1.27919
Epoch 2457/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4193 - val_loss: 1.2824 - val_accuracy: 0.4147

Epoch 02457: val_loss did not improve from 1.27919
Epoch 2458/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4242 - val_loss: 1.2805 - val_accuracy: 0.4195

Epoch 02458: val_loss did not improve from 1.27919
Epoch 2459/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4212 - val_loss: 1.2833 - val_accuracy: 0.4266

Epoch 02459: val_loss did not improve from 1.27919
Epoch 2460/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4195 - val_loss: 1.2815 - val_accuracy: 0.4306

Epoch 02460: val_loss did not improve from 1.27919
Epoch 2461/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4214 - val_loss: 1.2823 - val_accuracy: 0.4234

Epoch 02461: val_loss did not improve from 1.27919
Epoch 2462/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4226 - val_loss: 1.2829 - val_accuracy: 0.4250

Epoch 02462: val_loss did not improve from 1.27919
Epoch 2463/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4232 - val_loss: 1.2798 - val_accuracy: 0.4219

Epoch 02463: val_loss did not improve from 1.27919
Epoch 2464/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4210 - val_loss: 1.2808 - val_accuracy: 0.4203

Epoch 02464: val_loss did not improve from 1.27919
Epoch 2465/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4187 - val_loss: 1.2808 - val_accuracy: 0.4266

Epoch 02465: val_loss did not improve from 1.27919
Epoch 2466/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4196 - val_loss: 1.2822 - val_accuracy: 0.4234

Epoch 02466: val_loss did not improve from 1.27919
Epoch 2467/10000
12/12 - 0s - loss: 1.2763 - accuracy: 0.4207 - val_loss: 1.2839 - val_accuracy: 0.4163

Epoch 02467: val_loss did not improve from 1.27919
Epoch 2468/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4215 - val_loss: 1.2820 - val_accuracy: 0.4187

Epoch 02468: val_loss did not improve from 1.27919
Epoch 2469/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4220 - val_loss: 1.2817 - val_accuracy: 0.4195

Epoch 02469: val_loss did not improve from 1.27919
Epoch 2470/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4203 - val_loss: 1.2802 - val_accuracy: 0.4211

Epoch 02470: val_loss did not improve from 1.27919
Epoch 2471/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4241 - val_loss: 1.2817 - val_accuracy: 0.4282

Epoch 02471: val_loss did not improve from 1.27919
Epoch 2472/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4223 - val_loss: 1.2827 - val_accuracy: 0.4155

Epoch 02472: val_loss did not improve from 1.27919
Epoch 2473/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4216 - val_loss: 1.2797 - val_accuracy: 0.4290

Epoch 02473: val_loss did not improve from 1.27919
Epoch 2474/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4202 - val_loss: 1.2785 - val_accuracy: 0.4234

Epoch 02474: val_loss improved from 1.27919 to 1.27853, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2475/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4261 - val_loss: 1.2808 - val_accuracy: 0.4179

Epoch 02475: val_loss did not improve from 1.27853
Epoch 2476/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4179 - val_loss: 1.2793 - val_accuracy: 0.4258

Epoch 02476: val_loss did not improve from 1.27853
Epoch 2477/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4238 - val_loss: 1.2789 - val_accuracy: 0.4298

Epoch 02477: val_loss did not improve from 1.27853
Epoch 2478/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4218 - val_loss: 1.2815 - val_accuracy: 0.4306

Epoch 02478: val_loss did not improve from 1.27853
Epoch 2479/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4198 - val_loss: 1.2896 - val_accuracy: 0.4179

Epoch 02479: val_loss did not improve from 1.27853
Epoch 2480/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4196 - val_loss: 1.2803 - val_accuracy: 0.4226

Epoch 02480: val_loss did not improve from 1.27853
Epoch 2481/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4214 - val_loss: 1.2796 - val_accuracy: 0.4250

Epoch 02481: val_loss did not improve from 1.27853
Epoch 2482/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4223 - val_loss: 1.2790 - val_accuracy: 0.4274

Epoch 02482: val_loss did not improve from 1.27853
Epoch 2483/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4236 - val_loss: 1.2792 - val_accuracy: 0.4211

Epoch 02483: val_loss did not improve from 1.27853
Epoch 2484/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4234 - val_loss: 1.2795 - val_accuracy: 0.4282

Epoch 02484: val_loss did not improve from 1.27853
Epoch 2485/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4249 - val_loss: 1.2827 - val_accuracy: 0.4203

Epoch 02485: val_loss did not improve from 1.27853
Epoch 2486/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4202 - val_loss: 1.2798 - val_accuracy: 0.4179

Epoch 02486: val_loss did not improve from 1.27853
Epoch 2487/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4216 - val_loss: 1.2794 - val_accuracy: 0.4234

Epoch 02487: val_loss did not improve from 1.27853
Epoch 2488/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4218 - val_loss: 1.2805 - val_accuracy: 0.4290

Epoch 02488: val_loss did not improve from 1.27853
Epoch 2489/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4222 - val_loss: 1.2814 - val_accuracy: 0.4195

Epoch 02489: val_loss did not improve from 1.27853
Epoch 2490/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4254 - val_loss: 1.2796 - val_accuracy: 0.4211

Epoch 02490: val_loss did not improve from 1.27853
Epoch 2491/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4220 - val_loss: 1.2820 - val_accuracy: 0.4274

Epoch 02491: val_loss did not improve from 1.27853
Epoch 2492/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4194 - val_loss: 1.2817 - val_accuracy: 0.4203

Epoch 02492: val_loss did not improve from 1.27853
Epoch 2493/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4257 - val_loss: 1.2821 - val_accuracy: 0.4242

Epoch 02493: val_loss did not improve from 1.27853
Epoch 2494/10000
12/12 - 0s - loss: 1.2800 - accuracy: 0.4196 - val_loss: 1.2886 - val_accuracy: 0.4211

Epoch 02494: val_loss did not improve from 1.27853
Epoch 2495/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4252 - val_loss: 1.2805 - val_accuracy: 0.4226

Epoch 02495: val_loss did not improve from 1.27853
Epoch 2496/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4198 - val_loss: 1.2828 - val_accuracy: 0.4234

Epoch 02496: val_loss did not improve from 1.27853
Epoch 2497/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4256 - val_loss: 1.2792 - val_accuracy: 0.4330

Epoch 02497: val_loss did not improve from 1.27853
Epoch 2498/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4231 - val_loss: 1.2787 - val_accuracy: 0.4282

Epoch 02498: val_loss did not improve from 1.27853
Epoch 2499/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4202 - val_loss: 1.2801 - val_accuracy: 0.4195

Epoch 02499: val_loss did not improve from 1.27853
Epoch 2500/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4193 - val_loss: 1.2805 - val_accuracy: 0.4219

Epoch 02500: val_loss did not improve from 1.27853
Epoch 2501/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4227 - val_loss: 1.2854 - val_accuracy: 0.4139

Epoch 02501: val_loss did not improve from 1.27853
Epoch 2502/10000
12/12 - 0s - loss: 1.2778 - accuracy: 0.4197 - val_loss: 1.2814 - val_accuracy: 0.4171

Epoch 02502: val_loss did not improve from 1.27853
Epoch 2503/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4210 - val_loss: 1.2801 - val_accuracy: 0.4211

Epoch 02503: val_loss did not improve from 1.27853
Epoch 2504/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4218 - val_loss: 1.2809 - val_accuracy: 0.4250

Epoch 02504: val_loss did not improve from 1.27853
Epoch 2505/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4194 - val_loss: 1.2813 - val_accuracy: 0.4211

Epoch 02505: val_loss did not improve from 1.27853
Epoch 2506/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4196 - val_loss: 1.2793 - val_accuracy: 0.4306

Epoch 02506: val_loss did not improve from 1.27853
Epoch 2507/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4209 - val_loss: 1.2817 - val_accuracy: 0.4258

Epoch 02507: val_loss did not improve from 1.27853
Epoch 2508/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4225 - val_loss: 1.2811 - val_accuracy: 0.4163

Epoch 02508: val_loss did not improve from 1.27853
Epoch 2509/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4214 - val_loss: 1.2819 - val_accuracy: 0.4203

Epoch 02509: val_loss did not improve from 1.27853
Epoch 2510/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4222 - val_loss: 1.2802 - val_accuracy: 0.4219

Epoch 02510: val_loss did not improve from 1.27853
Epoch 2511/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4221 - val_loss: 1.2803 - val_accuracy: 0.4242

Epoch 02511: val_loss did not improve from 1.27853
Epoch 2512/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4252 - val_loss: 1.2781 - val_accuracy: 0.4234

Epoch 02512: val_loss improved from 1.27853 to 1.27808, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2513/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4225 - val_loss: 1.2802 - val_accuracy: 0.4195

Epoch 02513: val_loss did not improve from 1.27808
Epoch 2514/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4202 - val_loss: 1.2796 - val_accuracy: 0.4195

Epoch 02514: val_loss did not improve from 1.27808
Epoch 2515/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4202 - val_loss: 1.2787 - val_accuracy: 0.4179

Epoch 02515: val_loss did not improve from 1.27808
Epoch 2516/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4214 - val_loss: 1.2806 - val_accuracy: 0.4282

Epoch 02516: val_loss did not improve from 1.27808
Epoch 2517/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4220 - val_loss: 1.2811 - val_accuracy: 0.4179

Epoch 02517: val_loss did not improve from 1.27808
Epoch 2518/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4214 - val_loss: 1.2789 - val_accuracy: 0.4250

Epoch 02518: val_loss did not improve from 1.27808
Epoch 2519/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4239 - val_loss: 1.2819 - val_accuracy: 0.4242

Epoch 02519: val_loss did not improve from 1.27808
Epoch 2520/10000
12/12 - 0s - loss: 1.2799 - accuracy: 0.4227 - val_loss: 1.2785 - val_accuracy: 0.4266

Epoch 02520: val_loss did not improve from 1.27808
Epoch 2521/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4198 - val_loss: 1.2788 - val_accuracy: 0.4274

Epoch 02521: val_loss did not improve from 1.27808
Epoch 2522/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4202 - val_loss: 1.2819 - val_accuracy: 0.4282

Epoch 02522: val_loss did not improve from 1.27808
Epoch 2523/10000
12/12 - 0s - loss: 1.2785 - accuracy: 0.4204 - val_loss: 1.2813 - val_accuracy: 0.4306

Epoch 02523: val_loss did not improve from 1.27808
Epoch 2524/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4215 - val_loss: 1.2816 - val_accuracy: 0.4306

Epoch 02524: val_loss did not improve from 1.27808
Epoch 2525/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4215 - val_loss: 1.2844 - val_accuracy: 0.4107

Epoch 02525: val_loss did not improve from 1.27808
Epoch 2526/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4204 - val_loss: 1.2849 - val_accuracy: 0.4234

Epoch 02526: val_loss did not improve from 1.27808
Epoch 2527/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4181 - val_loss: 1.2809 - val_accuracy: 0.4211

Epoch 02527: val_loss did not improve from 1.27808
Epoch 2528/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4191 - val_loss: 1.2827 - val_accuracy: 0.4075

Epoch 02528: val_loss did not improve from 1.27808
Epoch 2529/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4232 - val_loss: 1.2816 - val_accuracy: 0.4211

Epoch 02529: val_loss did not improve from 1.27808
Epoch 2530/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4256 - val_loss: 1.2814 - val_accuracy: 0.4330

Epoch 02530: val_loss did not improve from 1.27808
Epoch 2531/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4223 - val_loss: 1.2818 - val_accuracy: 0.4147

Epoch 02531: val_loss did not improve from 1.27808
Epoch 2532/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4221 - val_loss: 1.2786 - val_accuracy: 0.4274

Epoch 02532: val_loss did not improve from 1.27808
Epoch 2533/10000
12/12 - 0s - loss: 1.2792 - accuracy: 0.4214 - val_loss: 1.2801 - val_accuracy: 0.4386

Epoch 02533: val_loss did not improve from 1.27808
Epoch 2534/10000
12/12 - 0s - loss: 1.2825 - accuracy: 0.4193 - val_loss: 1.2834 - val_accuracy: 0.4290

Epoch 02534: val_loss did not improve from 1.27808
Epoch 2535/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4247 - val_loss: 1.2816 - val_accuracy: 0.4219

Epoch 02535: val_loss did not improve from 1.27808
Epoch 2536/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4232 - val_loss: 1.2797 - val_accuracy: 0.4219

Epoch 02536: val_loss did not improve from 1.27808
Epoch 2537/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4205 - val_loss: 1.2783 - val_accuracy: 0.4211

Epoch 02537: val_loss did not improve from 1.27808
Epoch 2538/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4205 - val_loss: 1.2807 - val_accuracy: 0.4234

Epoch 02538: val_loss did not improve from 1.27808
Epoch 2539/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4209 - val_loss: 1.2804 - val_accuracy: 0.4195

Epoch 02539: val_loss did not improve from 1.27808
Epoch 2540/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4252 - val_loss: 1.2845 - val_accuracy: 0.4179

Epoch 02540: val_loss did not improve from 1.27808
Epoch 2541/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4202 - val_loss: 1.2797 - val_accuracy: 0.4234

Epoch 02541: val_loss did not improve from 1.27808
Epoch 2542/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4226 - val_loss: 1.2807 - val_accuracy: 0.4171

Epoch 02542: val_loss did not improve from 1.27808
Epoch 2543/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4233 - val_loss: 1.2805 - val_accuracy: 0.4258

Epoch 02543: val_loss did not improve from 1.27808
Epoch 2544/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4223 - val_loss: 1.2822 - val_accuracy: 0.4226

Epoch 02544: val_loss did not improve from 1.27808
Epoch 2545/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4239 - val_loss: 1.2786 - val_accuracy: 0.4219

Epoch 02545: val_loss did not improve from 1.27808
Epoch 2546/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4206 - val_loss: 1.2817 - val_accuracy: 0.4274

Epoch 02546: val_loss did not improve from 1.27808
Epoch 2547/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4196 - val_loss: 1.2820 - val_accuracy: 0.4211

Epoch 02547: val_loss did not improve from 1.27808
Epoch 2548/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4227 - val_loss: 1.2840 - val_accuracy: 0.4155

Epoch 02548: val_loss did not improve from 1.27808
Epoch 2549/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4218 - val_loss: 1.2946 - val_accuracy: 0.4123

Epoch 02549: val_loss did not improve from 1.27808
Epoch 2550/10000
12/12 - 0s - loss: 1.2803 - accuracy: 0.4154 - val_loss: 1.2825 - val_accuracy: 0.4195

Epoch 02550: val_loss did not improve from 1.27808
Epoch 2551/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4175 - val_loss: 1.2831 - val_accuracy: 0.4266

Epoch 02551: val_loss did not improve from 1.27808
Epoch 2552/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4219 - val_loss: 1.2803 - val_accuracy: 0.4139

Epoch 02552: val_loss did not improve from 1.27808
Epoch 2553/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4234 - val_loss: 1.2807 - val_accuracy: 0.4187

Epoch 02553: val_loss did not improve from 1.27808
Epoch 2554/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4193 - val_loss: 1.2800 - val_accuracy: 0.4171

Epoch 02554: val_loss did not improve from 1.27808
Epoch 2555/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4233 - val_loss: 1.2821 - val_accuracy: 0.4266

Epoch 02555: val_loss did not improve from 1.27808
Epoch 2556/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4232 - val_loss: 1.2838 - val_accuracy: 0.4163

Epoch 02556: val_loss did not improve from 1.27808
Epoch 2557/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4198 - val_loss: 1.2802 - val_accuracy: 0.4282

Epoch 02557: val_loss did not improve from 1.27808
Epoch 2558/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4194 - val_loss: 1.2809 - val_accuracy: 0.4219

Epoch 02558: val_loss did not improve from 1.27808
Epoch 2559/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4189 - val_loss: 1.2816 - val_accuracy: 0.4211

Epoch 02559: val_loss did not improve from 1.27808
Epoch 2560/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4236 - val_loss: 1.2806 - val_accuracy: 0.4219

Epoch 02560: val_loss did not improve from 1.27808
Epoch 2561/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4221 - val_loss: 1.2802 - val_accuracy: 0.4219

Epoch 02561: val_loss did not improve from 1.27808
Epoch 2562/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4203 - val_loss: 1.2818 - val_accuracy: 0.4211

Epoch 02562: val_loss did not improve from 1.27808
Epoch 2563/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4226 - val_loss: 1.2801 - val_accuracy: 0.4226

Epoch 02563: val_loss did not improve from 1.27808
Epoch 2564/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4218 - val_loss: 1.2921 - val_accuracy: 0.4179

Epoch 02564: val_loss did not improve from 1.27808
Epoch 2565/10000
12/12 - 0s - loss: 1.2932 - accuracy: 0.4134 - val_loss: 1.2835 - val_accuracy: 0.4250

Epoch 02565: val_loss did not improve from 1.27808
Epoch 2566/10000
12/12 - 0s - loss: 1.2757 - accuracy: 0.4213 - val_loss: 1.2857 - val_accuracy: 0.4234

Epoch 02566: val_loss did not improve from 1.27808
Epoch 2567/10000
12/12 - 0s - loss: 1.2779 - accuracy: 0.4170 - val_loss: 1.2831 - val_accuracy: 0.4187

Epoch 02567: val_loss did not improve from 1.27808
Epoch 2568/10000
12/12 - 0s - loss: 1.2826 - accuracy: 0.4157 - val_loss: 1.2820 - val_accuracy: 0.4203

Epoch 02568: val_loss did not improve from 1.27808
Epoch 2569/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4214 - val_loss: 1.2812 - val_accuracy: 0.4155

Epoch 02569: val_loss did not improve from 1.27808
Epoch 2570/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4198 - val_loss: 1.2811 - val_accuracy: 0.4163

Epoch 02570: val_loss did not improve from 1.27808
Epoch 2571/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4245 - val_loss: 1.2796 - val_accuracy: 0.4298

Epoch 02571: val_loss did not improve from 1.27808
Epoch 2572/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4194 - val_loss: 1.2797 - val_accuracy: 0.4195

Epoch 02572: val_loss did not improve from 1.27808
Epoch 2573/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4243 - val_loss: 1.2812 - val_accuracy: 0.4163

Epoch 02573: val_loss did not improve from 1.27808
Epoch 2574/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4252 - val_loss: 1.2790 - val_accuracy: 0.4219

Epoch 02574: val_loss did not improve from 1.27808
Epoch 2575/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4194 - val_loss: 1.2849 - val_accuracy: 0.4211

Epoch 02575: val_loss did not improve from 1.27808
Epoch 2576/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4219 - val_loss: 1.2816 - val_accuracy: 0.4195

Epoch 02576: val_loss did not improve from 1.27808
Epoch 2577/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4221 - val_loss: 1.2798 - val_accuracy: 0.4195

Epoch 02577: val_loss did not improve from 1.27808
Epoch 2578/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4224 - val_loss: 1.2816 - val_accuracy: 0.4226

Epoch 02578: val_loss did not improve from 1.27808
Epoch 2579/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4223 - val_loss: 1.2809 - val_accuracy: 0.4131

Epoch 02579: val_loss did not improve from 1.27808
Epoch 2580/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4217 - val_loss: 1.2801 - val_accuracy: 0.4195

Epoch 02580: val_loss did not improve from 1.27808
Epoch 2581/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4180 - val_loss: 1.2877 - val_accuracy: 0.4203

Epoch 02581: val_loss did not improve from 1.27808
Epoch 2582/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4210 - val_loss: 1.2804 - val_accuracy: 0.4195

Epoch 02582: val_loss did not improve from 1.27808
Epoch 2583/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4233 - val_loss: 1.2810 - val_accuracy: 0.4258

Epoch 02583: val_loss did not improve from 1.27808
Epoch 2584/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4215 - val_loss: 1.2807 - val_accuracy: 0.4322

Epoch 02584: val_loss did not improve from 1.27808
Epoch 2585/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4253 - val_loss: 1.2795 - val_accuracy: 0.4242

Epoch 02585: val_loss did not improve from 1.27808
Epoch 2586/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4247 - val_loss: 1.2819 - val_accuracy: 0.4211

Epoch 02586: val_loss did not improve from 1.27808
Epoch 2587/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4260 - val_loss: 1.2810 - val_accuracy: 0.4258

Epoch 02587: val_loss did not improve from 1.27808
Epoch 2588/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4249 - val_loss: 1.2804 - val_accuracy: 0.4195

Epoch 02588: val_loss did not improve from 1.27808
Epoch 2589/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4193 - val_loss: 1.2798 - val_accuracy: 0.4250

Epoch 02589: val_loss did not improve from 1.27808
Epoch 2590/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4212 - val_loss: 1.2795 - val_accuracy: 0.4211

Epoch 02590: val_loss did not improve from 1.27808
Epoch 2591/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4241 - val_loss: 1.2811 - val_accuracy: 0.4298

Epoch 02591: val_loss did not improve from 1.27808
Epoch 2592/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4239 - val_loss: 1.2800 - val_accuracy: 0.4187

Epoch 02592: val_loss did not improve from 1.27808
Epoch 2593/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4202 - val_loss: 1.2790 - val_accuracy: 0.4226

Epoch 02593: val_loss did not improve from 1.27808
Epoch 2594/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4227 - val_loss: 1.2812 - val_accuracy: 0.4187

Epoch 02594: val_loss did not improve from 1.27808
Epoch 2595/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4187 - val_loss: 1.2804 - val_accuracy: 0.4242

Epoch 02595: val_loss did not improve from 1.27808
Epoch 2596/10000
12/12 - 0s - loss: 1.2765 - accuracy: 0.4224 - val_loss: 1.2815 - val_accuracy: 0.4179

Epoch 02596: val_loss did not improve from 1.27808
Epoch 2597/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4189 - val_loss: 1.2854 - val_accuracy: 0.4179

Epoch 02597: val_loss did not improve from 1.27808
Epoch 2598/10000
12/12 - 0s - loss: 1.2791 - accuracy: 0.4215 - val_loss: 1.2816 - val_accuracy: 0.4242

Epoch 02598: val_loss did not improve from 1.27808
Epoch 2599/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4202 - val_loss: 1.2801 - val_accuracy: 0.4330

Epoch 02599: val_loss did not improve from 1.27808
Epoch 2600/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4211 - val_loss: 1.2803 - val_accuracy: 0.4258

Epoch 02600: val_loss did not improve from 1.27808
Epoch 2601/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4219 - val_loss: 1.2807 - val_accuracy: 0.4234

Epoch 02601: val_loss did not improve from 1.27808
Epoch 2602/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4187 - val_loss: 1.2815 - val_accuracy: 0.4187

Epoch 02602: val_loss did not improve from 1.27808
Epoch 2603/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4207 - val_loss: 1.2792 - val_accuracy: 0.4203

Epoch 02603: val_loss did not improve from 1.27808
Epoch 2604/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4210 - val_loss: 1.2788 - val_accuracy: 0.4234

Epoch 02604: val_loss did not improve from 1.27808
Epoch 2605/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4199 - val_loss: 1.2846 - val_accuracy: 0.4131

Epoch 02605: val_loss did not improve from 1.27808
Epoch 2606/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4183 - val_loss: 1.2821 - val_accuracy: 0.4139

Epoch 02606: val_loss did not improve from 1.27808
Epoch 2607/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4208 - val_loss: 1.2843 - val_accuracy: 0.4250

Epoch 02607: val_loss did not improve from 1.27808
Epoch 2608/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4193 - val_loss: 1.2792 - val_accuracy: 0.4250

Epoch 02608: val_loss did not improve from 1.27808
Epoch 2609/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4207 - val_loss: 1.2803 - val_accuracy: 0.4163

Epoch 02609: val_loss did not improve from 1.27808
Epoch 2610/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4210 - val_loss: 1.2803 - val_accuracy: 0.4314

Epoch 02610: val_loss did not improve from 1.27808
Epoch 2611/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4220 - val_loss: 1.2805 - val_accuracy: 0.4234

Epoch 02611: val_loss did not improve from 1.27808
Epoch 2612/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4237 - val_loss: 1.2800 - val_accuracy: 0.4211

Epoch 02612: val_loss did not improve from 1.27808
Epoch 2613/10000
12/12 - 0s - loss: 1.2796 - accuracy: 0.4220 - val_loss: 1.2816 - val_accuracy: 0.4242

Epoch 02613: val_loss did not improve from 1.27808
Epoch 2614/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4211 - val_loss: 1.2789 - val_accuracy: 0.4211

Epoch 02614: val_loss did not improve from 1.27808
Epoch 2615/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4218 - val_loss: 1.2824 - val_accuracy: 0.4354

Epoch 02615: val_loss did not improve from 1.27808
Epoch 2616/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4241 - val_loss: 1.2818 - val_accuracy: 0.4258

Epoch 02616: val_loss did not improve from 1.27808
Epoch 2617/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4223 - val_loss: 1.2848 - val_accuracy: 0.4203

Epoch 02617: val_loss did not improve from 1.27808
Epoch 2618/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4262 - val_loss: 1.2790 - val_accuracy: 0.4195

Epoch 02618: val_loss did not improve from 1.27808
Epoch 2619/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4189 - val_loss: 1.2823 - val_accuracy: 0.4147

Epoch 02619: val_loss did not improve from 1.27808
Epoch 2620/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4225 - val_loss: 1.2795 - val_accuracy: 0.4203

Epoch 02620: val_loss did not improve from 1.27808
Epoch 2621/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4236 - val_loss: 1.2808 - val_accuracy: 0.4258

Epoch 02621: val_loss did not improve from 1.27808
Epoch 2622/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4210 - val_loss: 1.2806 - val_accuracy: 0.4131

Epoch 02622: val_loss did not improve from 1.27808
Epoch 2623/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4221 - val_loss: 1.2815 - val_accuracy: 0.4123

Epoch 02623: val_loss did not improve from 1.27808
Epoch 2624/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4201 - val_loss: 1.2839 - val_accuracy: 0.4187

Epoch 02624: val_loss did not improve from 1.27808
Epoch 2625/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4217 - val_loss: 1.2785 - val_accuracy: 0.4226

Epoch 02625: val_loss did not improve from 1.27808
Epoch 2626/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4231 - val_loss: 1.2795 - val_accuracy: 0.4219

Epoch 02626: val_loss did not improve from 1.27808
Epoch 2627/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4232 - val_loss: 1.2806 - val_accuracy: 0.4147

Epoch 02627: val_loss did not improve from 1.27808
Epoch 2628/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4227 - val_loss: 1.2803 - val_accuracy: 0.4211

Epoch 02628: val_loss did not improve from 1.27808
Epoch 2629/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4199 - val_loss: 1.2803 - val_accuracy: 0.4211

Epoch 02629: val_loss did not improve from 1.27808
Epoch 2630/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4194 - val_loss: 1.2806 - val_accuracy: 0.4250

Epoch 02630: val_loss did not improve from 1.27808
Epoch 2631/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4223 - val_loss: 1.2780 - val_accuracy: 0.4211

Epoch 02631: val_loss improved from 1.27808 to 1.27800, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2632/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4241 - val_loss: 1.2815 - val_accuracy: 0.4226

Epoch 02632: val_loss did not improve from 1.27800
Epoch 2633/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4220 - val_loss: 1.2824 - val_accuracy: 0.4211

Epoch 02633: val_loss did not improve from 1.27800
Epoch 2634/10000
12/12 - 0s - loss: 1.2784 - accuracy: 0.4179 - val_loss: 1.2833 - val_accuracy: 0.4195

Epoch 02634: val_loss did not improve from 1.27800
Epoch 2635/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4238 - val_loss: 1.2808 - val_accuracy: 0.4250

Epoch 02635: val_loss did not improve from 1.27800
Epoch 2636/10000
12/12 - 0s - loss: 1.2761 - accuracy: 0.4193 - val_loss: 1.2815 - val_accuracy: 0.4171

Epoch 02636: val_loss did not improve from 1.27800
Epoch 2637/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4223 - val_loss: 1.2808 - val_accuracy: 0.4187

Epoch 02637: val_loss did not improve from 1.27800
Epoch 2638/10000
12/12 - 0s - loss: 1.2764 - accuracy: 0.4206 - val_loss: 1.2802 - val_accuracy: 0.4330

Epoch 02638: val_loss did not improve from 1.27800
Epoch 2639/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4264 - val_loss: 1.2802 - val_accuracy: 0.4211

Epoch 02639: val_loss did not improve from 1.27800
Epoch 2640/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4241 - val_loss: 1.2857 - val_accuracy: 0.4219

Epoch 02640: val_loss did not improve from 1.27800
Epoch 2641/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4198 - val_loss: 1.2805 - val_accuracy: 0.4163

Epoch 02641: val_loss did not improve from 1.27800
Epoch 2642/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4212 - val_loss: 1.2793 - val_accuracy: 0.4163

Epoch 02642: val_loss did not improve from 1.27800
Epoch 2643/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4247 - val_loss: 1.2820 - val_accuracy: 0.4242

Epoch 02643: val_loss did not improve from 1.27800
Epoch 2644/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4231 - val_loss: 1.2784 - val_accuracy: 0.4195

Epoch 02644: val_loss did not improve from 1.27800
Epoch 2645/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4254 - val_loss: 1.2784 - val_accuracy: 0.4211

Epoch 02645: val_loss did not improve from 1.27800
Epoch 2646/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4210 - val_loss: 1.2792 - val_accuracy: 0.4155

Epoch 02646: val_loss did not improve from 1.27800
Epoch 2647/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4195 - val_loss: 1.2787 - val_accuracy: 0.4226

Epoch 02647: val_loss did not improve from 1.27800
Epoch 2648/10000
12/12 - 0s - loss: 1.2781 - accuracy: 0.4214 - val_loss: 1.2820 - val_accuracy: 0.4187

Epoch 02648: val_loss did not improve from 1.27800
Epoch 2649/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4235 - val_loss: 1.2798 - val_accuracy: 0.4242

Epoch 02649: val_loss did not improve from 1.27800
Epoch 2650/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4219 - val_loss: 1.2850 - val_accuracy: 0.4282

Epoch 02650: val_loss did not improve from 1.27800
Epoch 2651/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4209 - val_loss: 1.2787 - val_accuracy: 0.4171

Epoch 02651: val_loss did not improve from 1.27800
Epoch 2652/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4226 - val_loss: 1.2802 - val_accuracy: 0.4171

Epoch 02652: val_loss did not improve from 1.27800
Epoch 2653/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4247 - val_loss: 1.2801 - val_accuracy: 0.4234

Epoch 02653: val_loss did not improve from 1.27800
Epoch 2654/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4244 - val_loss: 1.2779 - val_accuracy: 0.4234

Epoch 02654: val_loss improved from 1.27800 to 1.27793, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2655/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4234 - val_loss: 1.2783 - val_accuracy: 0.4226

Epoch 02655: val_loss did not improve from 1.27793
Epoch 2656/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4212 - val_loss: 1.2785 - val_accuracy: 0.4187

Epoch 02656: val_loss did not improve from 1.27793
Epoch 2657/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4235 - val_loss: 1.2793 - val_accuracy: 0.4266

Epoch 02657: val_loss did not improve from 1.27793
Epoch 2658/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4210 - val_loss: 1.2773 - val_accuracy: 0.4211

Epoch 02658: val_loss improved from 1.27793 to 1.27726, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2659/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4219 - val_loss: 1.2773 - val_accuracy: 0.4226

Epoch 02659: val_loss did not improve from 1.27726
Epoch 2660/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4248 - val_loss: 1.2787 - val_accuracy: 0.4226

Epoch 02660: val_loss did not improve from 1.27726
Epoch 2661/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4226 - val_loss: 1.2772 - val_accuracy: 0.4226

Epoch 02661: val_loss improved from 1.27726 to 1.27719, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2662/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4214 - val_loss: 1.2866 - val_accuracy: 0.4155

Epoch 02662: val_loss did not improve from 1.27719
Epoch 2663/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4260 - val_loss: 1.2793 - val_accuracy: 0.4274

Epoch 02663: val_loss did not improve from 1.27719
Epoch 2664/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4231 - val_loss: 1.2795 - val_accuracy: 0.4187

Epoch 02664: val_loss did not improve from 1.27719
Epoch 2665/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4214 - val_loss: 1.2793 - val_accuracy: 0.4258

Epoch 02665: val_loss did not improve from 1.27719
Epoch 2666/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4235 - val_loss: 1.2796 - val_accuracy: 0.4258

Epoch 02666: val_loss did not improve from 1.27719
Epoch 2667/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4225 - val_loss: 1.2814 - val_accuracy: 0.4234

Epoch 02667: val_loss did not improve from 1.27719
Epoch 2668/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4250 - val_loss: 1.2783 - val_accuracy: 0.4234

Epoch 02668: val_loss did not improve from 1.27719
Epoch 2669/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4211 - val_loss: 1.2801 - val_accuracy: 0.4211

Epoch 02669: val_loss did not improve from 1.27719
Epoch 2670/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4188 - val_loss: 1.2798 - val_accuracy: 0.4187

Epoch 02670: val_loss did not improve from 1.27719
Epoch 2671/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4228 - val_loss: 1.2819 - val_accuracy: 0.4139

Epoch 02671: val_loss did not improve from 1.27719
Epoch 2672/10000
12/12 - 0s - loss: 1.2754 - accuracy: 0.4205 - val_loss: 1.2808 - val_accuracy: 0.4250

Epoch 02672: val_loss did not improve from 1.27719
Epoch 2673/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4226 - val_loss: 1.2814 - val_accuracy: 0.4219

Epoch 02673: val_loss did not improve from 1.27719
Epoch 2674/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4214 - val_loss: 1.2803 - val_accuracy: 0.4219

Epoch 02674: val_loss did not improve from 1.27719
Epoch 2675/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4238 - val_loss: 1.2778 - val_accuracy: 0.4219

Epoch 02675: val_loss did not improve from 1.27719
Epoch 2676/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4229 - val_loss: 1.2812 - val_accuracy: 0.4258

Epoch 02676: val_loss did not improve from 1.27719
Epoch 2677/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4226 - val_loss: 1.2856 - val_accuracy: 0.4171

Epoch 02677: val_loss did not improve from 1.27719
Epoch 2678/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4233 - val_loss: 1.2791 - val_accuracy: 0.4195

Epoch 02678: val_loss did not improve from 1.27719
Epoch 2679/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4253 - val_loss: 1.2807 - val_accuracy: 0.4314

Epoch 02679: val_loss did not improve from 1.27719
Epoch 2680/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4214 - val_loss: 1.2811 - val_accuracy: 0.4163

Epoch 02680: val_loss did not improve from 1.27719
Epoch 2681/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4237 - val_loss: 1.2819 - val_accuracy: 0.4211

Epoch 02681: val_loss did not improve from 1.27719
Epoch 2682/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4224 - val_loss: 1.2809 - val_accuracy: 0.4219

Epoch 02682: val_loss did not improve from 1.27719
Epoch 2683/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4220 - val_loss: 1.2834 - val_accuracy: 0.4258

Epoch 02683: val_loss did not improve from 1.27719
Epoch 2684/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4213 - val_loss: 1.2791 - val_accuracy: 0.4219

Epoch 02684: val_loss did not improve from 1.27719
Epoch 2685/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4233 - val_loss: 1.2798 - val_accuracy: 0.4171

Epoch 02685: val_loss did not improve from 1.27719
Epoch 2686/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4251 - val_loss: 1.2776 - val_accuracy: 0.4338

Epoch 02686: val_loss did not improve from 1.27719
Epoch 2687/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4219 - val_loss: 1.2791 - val_accuracy: 0.4139

Epoch 02687: val_loss did not improve from 1.27719
Epoch 2688/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4231 - val_loss: 1.2795 - val_accuracy: 0.4234

Epoch 02688: val_loss did not improve from 1.27719
Epoch 2689/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4227 - val_loss: 1.2791 - val_accuracy: 0.4195

Epoch 02689: val_loss did not improve from 1.27719
Epoch 2690/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4233 - val_loss: 1.2788 - val_accuracy: 0.4290

Epoch 02690: val_loss did not improve from 1.27719
Epoch 2691/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4216 - val_loss: 1.2783 - val_accuracy: 0.4219

Epoch 02691: val_loss did not improve from 1.27719
Epoch 2692/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4229 - val_loss: 1.2801 - val_accuracy: 0.4211

Epoch 02692: val_loss did not improve from 1.27719
Epoch 2693/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4233 - val_loss: 1.2800 - val_accuracy: 0.4226

Epoch 02693: val_loss did not improve from 1.27719
Epoch 2694/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4230 - val_loss: 1.2838 - val_accuracy: 0.4171

Epoch 02694: val_loss did not improve from 1.27719
Epoch 2695/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4134 - val_loss: 1.2785 - val_accuracy: 0.4171

Epoch 02695: val_loss did not improve from 1.27719
Epoch 2696/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4225 - val_loss: 1.2784 - val_accuracy: 0.4242

Epoch 02696: val_loss did not improve from 1.27719
Epoch 2697/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4211 - val_loss: 1.2805 - val_accuracy: 0.4314

Epoch 02697: val_loss did not improve from 1.27719
Epoch 2698/10000
12/12 - 0s - loss: 1.2775 - accuracy: 0.4224 - val_loss: 1.2791 - val_accuracy: 0.4354

Epoch 02698: val_loss did not improve from 1.27719
Epoch 2699/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4223 - val_loss: 1.2821 - val_accuracy: 0.4226

Epoch 02699: val_loss did not improve from 1.27719
Epoch 2700/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4241 - val_loss: 1.2806 - val_accuracy: 0.4219

Epoch 02700: val_loss did not improve from 1.27719
Epoch 2701/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4260 - val_loss: 1.2799 - val_accuracy: 0.4242

Epoch 02701: val_loss did not improve from 1.27719
Epoch 2702/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4217 - val_loss: 1.2799 - val_accuracy: 0.4226

Epoch 02702: val_loss did not improve from 1.27719
Epoch 2703/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4242 - val_loss: 1.2866 - val_accuracy: 0.4242

Epoch 02703: val_loss did not improve from 1.27719
Epoch 2704/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4257 - val_loss: 1.2804 - val_accuracy: 0.4179

Epoch 02704: val_loss did not improve from 1.27719
Epoch 2705/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4194 - val_loss: 1.2799 - val_accuracy: 0.4179

Epoch 02705: val_loss did not improve from 1.27719
Epoch 2706/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4227 - val_loss: 1.2798 - val_accuracy: 0.4211

Epoch 02706: val_loss did not improve from 1.27719
Epoch 2707/10000
12/12 - 0s - loss: 1.2750 - accuracy: 0.4181 - val_loss: 1.2811 - val_accuracy: 0.4250

Epoch 02707: val_loss did not improve from 1.27719
Epoch 2708/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4218 - val_loss: 1.2781 - val_accuracy: 0.4195

Epoch 02708: val_loss did not improve from 1.27719
Epoch 2709/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4221 - val_loss: 1.2797 - val_accuracy: 0.4187

Epoch 02709: val_loss did not improve from 1.27719
Epoch 2710/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4262 - val_loss: 1.2891 - val_accuracy: 0.4179

Epoch 02710: val_loss did not improve from 1.27719
Epoch 2711/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4207 - val_loss: 1.2798 - val_accuracy: 0.4211

Epoch 02711: val_loss did not improve from 1.27719
Epoch 2712/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4202 - val_loss: 1.2802 - val_accuracy: 0.4179

Epoch 02712: val_loss did not improve from 1.27719
Epoch 2713/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4236 - val_loss: 1.2799 - val_accuracy: 0.4171

Epoch 02713: val_loss did not improve from 1.27719
Epoch 2714/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4236 - val_loss: 1.2806 - val_accuracy: 0.4187

Epoch 02714: val_loss did not improve from 1.27719
Epoch 2715/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4214 - val_loss: 1.2858 - val_accuracy: 0.4131

Epoch 02715: val_loss did not improve from 1.27719
Epoch 2716/10000
12/12 - 0s - loss: 1.2805 - accuracy: 0.4194 - val_loss: 1.2801 - val_accuracy: 0.4219

Epoch 02716: val_loss did not improve from 1.27719
Epoch 2717/10000
12/12 - 0s - loss: 1.2773 - accuracy: 0.4194 - val_loss: 1.2837 - val_accuracy: 0.4242

Epoch 02717: val_loss did not improve from 1.27719
Epoch 2718/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4209 - val_loss: 1.2817 - val_accuracy: 0.4258

Epoch 02718: val_loss did not improve from 1.27719
Epoch 2719/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4198 - val_loss: 1.2813 - val_accuracy: 0.4219

Epoch 02719: val_loss did not improve from 1.27719
Epoch 2720/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4267 - val_loss: 1.2827 - val_accuracy: 0.4242

Epoch 02720: val_loss did not improve from 1.27719
Epoch 2721/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4231 - val_loss: 1.2796 - val_accuracy: 0.4211

Epoch 02721: val_loss did not improve from 1.27719
Epoch 2722/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4238 - val_loss: 1.2852 - val_accuracy: 0.4338

Epoch 02722: val_loss did not improve from 1.27719
Epoch 2723/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4201 - val_loss: 1.2793 - val_accuracy: 0.4234

Epoch 02723: val_loss did not improve from 1.27719
Epoch 2724/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4215 - val_loss: 1.2817 - val_accuracy: 0.4258

Epoch 02724: val_loss did not improve from 1.27719
Epoch 2725/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4225 - val_loss: 1.2809 - val_accuracy: 0.4139

Epoch 02725: val_loss did not improve from 1.27719
Epoch 2726/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4247 - val_loss: 1.2810 - val_accuracy: 0.4211

Epoch 02726: val_loss did not improve from 1.27719
Epoch 2727/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4225 - val_loss: 1.2805 - val_accuracy: 0.4242

Epoch 02727: val_loss did not improve from 1.27719
Epoch 2728/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4225 - val_loss: 1.2813 - val_accuracy: 0.4163

Epoch 02728: val_loss did not improve from 1.27719
Epoch 2729/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4214 - val_loss: 1.2801 - val_accuracy: 0.4179

Epoch 02729: val_loss did not improve from 1.27719
Epoch 2730/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4249 - val_loss: 1.2785 - val_accuracy: 0.4234

Epoch 02730: val_loss did not improve from 1.27719
Epoch 2731/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4229 - val_loss: 1.2779 - val_accuracy: 0.4242

Epoch 02731: val_loss did not improve from 1.27719
Epoch 2732/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4230 - val_loss: 1.2794 - val_accuracy: 0.4226

Epoch 02732: val_loss did not improve from 1.27719
Epoch 2733/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4236 - val_loss: 1.2790 - val_accuracy: 0.4266

Epoch 02733: val_loss did not improve from 1.27719
Epoch 2734/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4234 - val_loss: 1.2805 - val_accuracy: 0.4226

Epoch 02734: val_loss did not improve from 1.27719
Epoch 2735/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4255 - val_loss: 1.2781 - val_accuracy: 0.4234

Epoch 02735: val_loss did not improve from 1.27719
Epoch 2736/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4264 - val_loss: 1.2844 - val_accuracy: 0.4242

Epoch 02736: val_loss did not improve from 1.27719
Epoch 2737/10000
12/12 - 0s - loss: 1.2788 - accuracy: 0.4162 - val_loss: 1.2800 - val_accuracy: 0.4171

Epoch 02737: val_loss did not improve from 1.27719
Epoch 2738/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4201 - val_loss: 1.2794 - val_accuracy: 0.4171

Epoch 02738: val_loss did not improve from 1.27719
Epoch 2739/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4221 - val_loss: 1.2800 - val_accuracy: 0.4219

Epoch 02739: val_loss did not improve from 1.27719
Epoch 2740/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4182 - val_loss: 1.2787 - val_accuracy: 0.4203

Epoch 02740: val_loss did not improve from 1.27719
Epoch 2741/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4247 - val_loss: 1.2807 - val_accuracy: 0.4203

Epoch 02741: val_loss did not improve from 1.27719
Epoch 2742/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4214 - val_loss: 1.2773 - val_accuracy: 0.4226

Epoch 02742: val_loss did not improve from 1.27719
Epoch 2743/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4217 - val_loss: 1.2781 - val_accuracy: 0.4187

Epoch 02743: val_loss did not improve from 1.27719
Epoch 2744/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4222 - val_loss: 1.2797 - val_accuracy: 0.4282

Epoch 02744: val_loss did not improve from 1.27719
Epoch 2745/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4222 - val_loss: 1.2792 - val_accuracy: 0.4203

Epoch 02745: val_loss did not improve from 1.27719
Epoch 2746/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4217 - val_loss: 1.2805 - val_accuracy: 0.4203

Epoch 02746: val_loss did not improve from 1.27719
Epoch 2747/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4228 - val_loss: 1.2798 - val_accuracy: 0.4226

Epoch 02747: val_loss did not improve from 1.27719
Epoch 2748/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4220 - val_loss: 1.2791 - val_accuracy: 0.4211

Epoch 02748: val_loss did not improve from 1.27719
Epoch 2749/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4249 - val_loss: 1.2787 - val_accuracy: 0.4195

Epoch 02749: val_loss did not improve from 1.27719
Epoch 2750/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4222 - val_loss: 1.2785 - val_accuracy: 0.4234

Epoch 02750: val_loss did not improve from 1.27719
Epoch 2751/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4260 - val_loss: 1.2784 - val_accuracy: 0.4187

Epoch 02751: val_loss did not improve from 1.27719
Epoch 2752/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4227 - val_loss: 1.2826 - val_accuracy: 0.4187

Epoch 02752: val_loss did not improve from 1.27719
Epoch 2753/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4247 - val_loss: 1.2778 - val_accuracy: 0.4274

Epoch 02753: val_loss did not improve from 1.27719
Epoch 2754/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4228 - val_loss: 1.2780 - val_accuracy: 0.4258

Epoch 02754: val_loss did not improve from 1.27719
Epoch 2755/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4210 - val_loss: 1.2788 - val_accuracy: 0.4203

Epoch 02755: val_loss did not improve from 1.27719
Epoch 2756/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4211 - val_loss: 1.2806 - val_accuracy: 0.4147

Epoch 02756: val_loss did not improve from 1.27719
Epoch 2757/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4240 - val_loss: 1.2819 - val_accuracy: 0.4187

Epoch 02757: val_loss did not improve from 1.27719
Epoch 2758/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4222 - val_loss: 1.2774 - val_accuracy: 0.4242

Epoch 02758: val_loss did not improve from 1.27719
Epoch 2759/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4211 - val_loss: 1.2778 - val_accuracy: 0.4219

Epoch 02759: val_loss did not improve from 1.27719
Epoch 2760/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4210 - val_loss: 1.2806 - val_accuracy: 0.4195

Epoch 02760: val_loss did not improve from 1.27719
Epoch 2761/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4236 - val_loss: 1.2781 - val_accuracy: 0.4250

Epoch 02761: val_loss did not improve from 1.27719
Epoch 2762/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4237 - val_loss: 1.2852 - val_accuracy: 0.4211

Epoch 02762: val_loss did not improve from 1.27719
Epoch 2763/10000
12/12 - 0s - loss: 1.2777 - accuracy: 0.4215 - val_loss: 1.2774 - val_accuracy: 0.4187

Epoch 02763: val_loss did not improve from 1.27719
Epoch 2764/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4169 - val_loss: 1.2792 - val_accuracy: 0.4258

Epoch 02764: val_loss did not improve from 1.27719
Epoch 2765/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4132 - val_loss: 1.2780 - val_accuracy: 0.4203

Epoch 02765: val_loss did not improve from 1.27719
Epoch 2766/10000
12/12 - 0s - loss: 1.2767 - accuracy: 0.4199 - val_loss: 1.2791 - val_accuracy: 0.4155

Epoch 02766: val_loss did not improve from 1.27719
Epoch 2767/10000
12/12 - 0s - loss: 1.2780 - accuracy: 0.4232 - val_loss: 1.2774 - val_accuracy: 0.4219

Epoch 02767: val_loss did not improve from 1.27719
Epoch 2768/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4225 - val_loss: 1.2862 - val_accuracy: 0.4179

Epoch 02768: val_loss did not improve from 1.27719
Epoch 2769/10000
12/12 - 0s - loss: 1.2752 - accuracy: 0.4164 - val_loss: 1.2781 - val_accuracy: 0.4266

Epoch 02769: val_loss did not improve from 1.27719
Epoch 2770/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4214 - val_loss: 1.2791 - val_accuracy: 0.4147

Epoch 02770: val_loss did not improve from 1.27719
Epoch 2771/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4248 - val_loss: 1.2787 - val_accuracy: 0.4219

Epoch 02771: val_loss did not improve from 1.27719
Epoch 2772/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4240 - val_loss: 1.2782 - val_accuracy: 0.4282

Epoch 02772: val_loss did not improve from 1.27719
Epoch 2773/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4198 - val_loss: 1.2808 - val_accuracy: 0.4242

Epoch 02773: val_loss did not improve from 1.27719
Epoch 2774/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4190 - val_loss: 1.2790 - val_accuracy: 0.4163

Epoch 02774: val_loss did not improve from 1.27719
Epoch 2775/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4234 - val_loss: 1.2788 - val_accuracy: 0.4266

Epoch 02775: val_loss did not improve from 1.27719
Epoch 2776/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4267 - val_loss: 1.2780 - val_accuracy: 0.4171

Epoch 02776: val_loss did not improve from 1.27719
Epoch 2777/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4250 - val_loss: 1.2763 - val_accuracy: 0.4155

Epoch 02777: val_loss improved from 1.27719 to 1.27632, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2778/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4210 - val_loss: 1.2768 - val_accuracy: 0.4250

Epoch 02778: val_loss did not improve from 1.27632
Epoch 2779/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4218 - val_loss: 1.2793 - val_accuracy: 0.4258

Epoch 02779: val_loss did not improve from 1.27632
Epoch 2780/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4239 - val_loss: 1.2786 - val_accuracy: 0.4203

Epoch 02780: val_loss did not improve from 1.27632
Epoch 2781/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4287 - val_loss: 1.2853 - val_accuracy: 0.4163

Epoch 02781: val_loss did not improve from 1.27632
Epoch 2782/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4218 - val_loss: 1.2803 - val_accuracy: 0.4115

Epoch 02782: val_loss did not improve from 1.27632
Epoch 2783/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4267 - val_loss: 1.2796 - val_accuracy: 0.4179

Epoch 02783: val_loss did not improve from 1.27632
Epoch 2784/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4266 - val_loss: 1.2806 - val_accuracy: 0.4234

Epoch 02784: val_loss did not improve from 1.27632
Epoch 2785/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4277 - val_loss: 1.2774 - val_accuracy: 0.4266

Epoch 02785: val_loss did not improve from 1.27632
Epoch 2786/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4233 - val_loss: 1.2789 - val_accuracy: 0.4203

Epoch 02786: val_loss did not improve from 1.27632
Epoch 2787/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4247 - val_loss: 1.2779 - val_accuracy: 0.4219

Epoch 02787: val_loss did not improve from 1.27632
Epoch 2788/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4261 - val_loss: 1.2788 - val_accuracy: 0.4203

Epoch 02788: val_loss did not improve from 1.27632
Epoch 2789/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4254 - val_loss: 1.2800 - val_accuracy: 0.4163

Epoch 02789: val_loss did not improve from 1.27632
Epoch 2790/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4241 - val_loss: 1.2792 - val_accuracy: 0.4139

Epoch 02790: val_loss did not improve from 1.27632
Epoch 2791/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4241 - val_loss: 1.2798 - val_accuracy: 0.4234

Epoch 02791: val_loss did not improve from 1.27632
Epoch 2792/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4210 - val_loss: 1.2797 - val_accuracy: 0.4211

Epoch 02792: val_loss did not improve from 1.27632
Epoch 2793/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4223 - val_loss: 1.2792 - val_accuracy: 0.4274

Epoch 02793: val_loss did not improve from 1.27632
Epoch 2794/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4230 - val_loss: 1.2820 - val_accuracy: 0.4147

Epoch 02794: val_loss did not improve from 1.27632
Epoch 2795/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4199 - val_loss: 1.2798 - val_accuracy: 0.4171

Epoch 02795: val_loss did not improve from 1.27632
Epoch 2796/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4241 - val_loss: 1.2781 - val_accuracy: 0.4171

Epoch 02796: val_loss did not improve from 1.27632
Epoch 2797/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4230 - val_loss: 1.2798 - val_accuracy: 0.4131

Epoch 02797: val_loss did not improve from 1.27632
Epoch 2798/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4236 - val_loss: 1.2815 - val_accuracy: 0.4226

Epoch 02798: val_loss did not improve from 1.27632
Epoch 2799/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4231 - val_loss: 1.2776 - val_accuracy: 0.4234

Epoch 02799: val_loss did not improve from 1.27632
Epoch 2800/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4249 - val_loss: 1.2793 - val_accuracy: 0.4322

Epoch 02800: val_loss did not improve from 1.27632
Epoch 2801/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4228 - val_loss: 1.2799 - val_accuracy: 0.4298

Epoch 02801: val_loss did not improve from 1.27632
Epoch 2802/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4228 - val_loss: 1.2823 - val_accuracy: 0.4211

Epoch 02802: val_loss did not improve from 1.27632
Epoch 2803/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4245 - val_loss: 1.2825 - val_accuracy: 0.4195

Epoch 02803: val_loss did not improve from 1.27632
Epoch 2804/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4210 - val_loss: 1.2779 - val_accuracy: 0.4219

Epoch 02804: val_loss did not improve from 1.27632
Epoch 2805/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4233 - val_loss: 1.2790 - val_accuracy: 0.4099

Epoch 02805: val_loss did not improve from 1.27632
Epoch 2806/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4222 - val_loss: 1.2777 - val_accuracy: 0.4258

Epoch 02806: val_loss did not improve from 1.27632
Epoch 2807/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4240 - val_loss: 1.2769 - val_accuracy: 0.4187

Epoch 02807: val_loss did not improve from 1.27632
Epoch 2808/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4239 - val_loss: 1.2775 - val_accuracy: 0.4226

Epoch 02808: val_loss did not improve from 1.27632
Epoch 2809/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4220 - val_loss: 1.2837 - val_accuracy: 0.4155

Epoch 02809: val_loss did not improve from 1.27632
Epoch 2810/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4237 - val_loss: 1.2788 - val_accuracy: 0.4226

Epoch 02810: val_loss did not improve from 1.27632
Epoch 2811/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4218 - val_loss: 1.2783 - val_accuracy: 0.4250

Epoch 02811: val_loss did not improve from 1.27632
Epoch 2812/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4255 - val_loss: 1.2783 - val_accuracy: 0.4203

Epoch 02812: val_loss did not improve from 1.27632
Epoch 2813/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4246 - val_loss: 1.2803 - val_accuracy: 0.4250

Epoch 02813: val_loss did not improve from 1.27632
Epoch 2814/10000
12/12 - 0s - loss: 1.2768 - accuracy: 0.4207 - val_loss: 1.2773 - val_accuracy: 0.4282

Epoch 02814: val_loss did not improve from 1.27632
Epoch 2815/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4211 - val_loss: 1.2785 - val_accuracy: 0.4163

Epoch 02815: val_loss did not improve from 1.27632
Epoch 2816/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4241 - val_loss: 1.2788 - val_accuracy: 0.4250

Epoch 02816: val_loss did not improve from 1.27632
Epoch 2817/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4211 - val_loss: 1.2810 - val_accuracy: 0.4234

Epoch 02817: val_loss did not improve from 1.27632
Epoch 2818/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4229 - val_loss: 1.2760 - val_accuracy: 0.4171

Epoch 02818: val_loss improved from 1.27632 to 1.27604, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2819/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4247 - val_loss: 1.2782 - val_accuracy: 0.4266

Epoch 02819: val_loss did not improve from 1.27604
Epoch 2820/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4222 - val_loss: 1.2838 - val_accuracy: 0.4179

Epoch 02820: val_loss did not improve from 1.27604
Epoch 2821/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4213 - val_loss: 1.2776 - val_accuracy: 0.4219

Epoch 02821: val_loss did not improve from 1.27604
Epoch 2822/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4243 - val_loss: 1.2834 - val_accuracy: 0.4195

Epoch 02822: val_loss did not improve from 1.27604
Epoch 2823/10000
12/12 - 0s - loss: 1.2760 - accuracy: 0.4184 - val_loss: 1.2779 - val_accuracy: 0.4378

Epoch 02823: val_loss did not improve from 1.27604
Epoch 2824/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4227 - val_loss: 1.2846 - val_accuracy: 0.4195

Epoch 02824: val_loss did not improve from 1.27604
Epoch 2825/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4234 - val_loss: 1.2778 - val_accuracy: 0.4219

Epoch 02825: val_loss did not improve from 1.27604
Epoch 2826/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4247 - val_loss: 1.2791 - val_accuracy: 0.4179

Epoch 02826: val_loss did not improve from 1.27604
Epoch 2827/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4233 - val_loss: 1.2838 - val_accuracy: 0.4195

Epoch 02827: val_loss did not improve from 1.27604
Epoch 2828/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4240 - val_loss: 1.2775 - val_accuracy: 0.4203

Epoch 02828: val_loss did not improve from 1.27604
Epoch 2829/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4242 - val_loss: 1.2828 - val_accuracy: 0.4219

Epoch 02829: val_loss did not improve from 1.27604
Epoch 2830/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4228 - val_loss: 1.2789 - val_accuracy: 0.4187

Epoch 02830: val_loss did not improve from 1.27604
Epoch 2831/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4202 - val_loss: 1.2858 - val_accuracy: 0.4266

Epoch 02831: val_loss did not improve from 1.27604
Epoch 2832/10000
12/12 - 0s - loss: 1.2797 - accuracy: 0.4167 - val_loss: 1.2785 - val_accuracy: 0.4147

Epoch 02832: val_loss did not improve from 1.27604
Epoch 2833/10000
12/12 - 0s - loss: 1.2745 - accuracy: 0.4187 - val_loss: 1.2844 - val_accuracy: 0.4187

Epoch 02833: val_loss did not improve from 1.27604
Epoch 2834/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4168 - val_loss: 1.2801 - val_accuracy: 0.4322

Epoch 02834: val_loss did not improve from 1.27604
Epoch 2835/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4217 - val_loss: 1.2791 - val_accuracy: 0.4258

Epoch 02835: val_loss did not improve from 1.27604
Epoch 2836/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4291 - val_loss: 1.2783 - val_accuracy: 0.4306

Epoch 02836: val_loss did not improve from 1.27604
Epoch 2837/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4222 - val_loss: 1.2779 - val_accuracy: 0.4234

Epoch 02837: val_loss did not improve from 1.27604
Epoch 2838/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4240 - val_loss: 1.2818 - val_accuracy: 0.4195

Epoch 02838: val_loss did not improve from 1.27604
Epoch 2839/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4245 - val_loss: 1.2775 - val_accuracy: 0.4242

Epoch 02839: val_loss did not improve from 1.27604
Epoch 2840/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4262 - val_loss: 1.2822 - val_accuracy: 0.4131

Epoch 02840: val_loss did not improve from 1.27604
Epoch 2841/10000
12/12 - 0s - loss: 1.2737 - accuracy: 0.4209 - val_loss: 1.2786 - val_accuracy: 0.4203

Epoch 02841: val_loss did not improve from 1.27604
Epoch 2842/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4210 - val_loss: 1.2763 - val_accuracy: 0.4234

Epoch 02842: val_loss did not improve from 1.27604
Epoch 2843/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4231 - val_loss: 1.2776 - val_accuracy: 0.4155

Epoch 02843: val_loss did not improve from 1.27604
Epoch 2844/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4212 - val_loss: 1.2772 - val_accuracy: 0.4211

Epoch 02844: val_loss did not improve from 1.27604
Epoch 2845/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4226 - val_loss: 1.2782 - val_accuracy: 0.4219

Epoch 02845: val_loss did not improve from 1.27604
Epoch 2846/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4242 - val_loss: 1.2791 - val_accuracy: 0.4219

Epoch 02846: val_loss did not improve from 1.27604
Epoch 2847/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4240 - val_loss: 1.2796 - val_accuracy: 0.4234

Epoch 02847: val_loss did not improve from 1.27604
Epoch 2848/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4191 - val_loss: 1.2817 - val_accuracy: 0.4219

Epoch 02848: val_loss did not improve from 1.27604
Epoch 2849/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4241 - val_loss: 1.2782 - val_accuracy: 0.4274

Epoch 02849: val_loss did not improve from 1.27604
Epoch 2850/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4230 - val_loss: 1.2765 - val_accuracy: 0.4234

Epoch 02850: val_loss did not improve from 1.27604
Epoch 2851/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4227 - val_loss: 1.2793 - val_accuracy: 0.4211

Epoch 02851: val_loss did not improve from 1.27604
Epoch 2852/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4257 - val_loss: 1.2805 - val_accuracy: 0.4242

Epoch 02852: val_loss did not improve from 1.27604
Epoch 2853/10000
12/12 - 0s - loss: 1.2801 - accuracy: 0.4165 - val_loss: 1.2815 - val_accuracy: 0.4211

Epoch 02853: val_loss did not improve from 1.27604
Epoch 2854/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4249 - val_loss: 1.2815 - val_accuracy: 0.4234

Epoch 02854: val_loss did not improve from 1.27604
Epoch 2855/10000
12/12 - 0s - loss: 1.2733 - accuracy: 0.4216 - val_loss: 1.2815 - val_accuracy: 0.4322

Epoch 02855: val_loss did not improve from 1.27604
Epoch 2856/10000
12/12 - 0s - loss: 1.2854 - accuracy: 0.4160 - val_loss: 1.2814 - val_accuracy: 0.4322

Epoch 02856: val_loss did not improve from 1.27604
Epoch 2857/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4206 - val_loss: 1.2773 - val_accuracy: 0.4226

Epoch 02857: val_loss did not improve from 1.27604
Epoch 2858/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4254 - val_loss: 1.2774 - val_accuracy: 0.4179

Epoch 02858: val_loss did not improve from 1.27604
Epoch 2859/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4254 - val_loss: 1.2782 - val_accuracy: 0.4282

Epoch 02859: val_loss did not improve from 1.27604
Epoch 2860/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4249 - val_loss: 1.2775 - val_accuracy: 0.4226

Epoch 02860: val_loss did not improve from 1.27604
Epoch 2861/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4216 - val_loss: 1.2796 - val_accuracy: 0.4314

Epoch 02861: val_loss did not improve from 1.27604
Epoch 2862/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4234 - val_loss: 1.2804 - val_accuracy: 0.4266

Epoch 02862: val_loss did not improve from 1.27604
Epoch 2863/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4185 - val_loss: 1.2801 - val_accuracy: 0.4330

Epoch 02863: val_loss did not improve from 1.27604
Epoch 2864/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4225 - val_loss: 1.2892 - val_accuracy: 0.4234

Epoch 02864: val_loss did not improve from 1.27604
Epoch 2865/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4233 - val_loss: 1.2798 - val_accuracy: 0.4226

Epoch 02865: val_loss did not improve from 1.27604
Epoch 2866/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4206 - val_loss: 1.2774 - val_accuracy: 0.4219

Epoch 02866: val_loss did not improve from 1.27604
Epoch 2867/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4234 - val_loss: 1.2771 - val_accuracy: 0.4258

Epoch 02867: val_loss did not improve from 1.27604
Epoch 2868/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4233 - val_loss: 1.2779 - val_accuracy: 0.4242

Epoch 02868: val_loss did not improve from 1.27604
Epoch 2869/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4244 - val_loss: 1.2777 - val_accuracy: 0.4203

Epoch 02869: val_loss did not improve from 1.27604
Epoch 2870/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4216 - val_loss: 1.2799 - val_accuracy: 0.4195

Epoch 02870: val_loss did not improve from 1.27604
Epoch 2871/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4209 - val_loss: 1.2795 - val_accuracy: 0.4250

Epoch 02871: val_loss did not improve from 1.27604
Epoch 2872/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4244 - val_loss: 1.2800 - val_accuracy: 0.4266

Epoch 02872: val_loss did not improve from 1.27604
Epoch 2873/10000
12/12 - 0s - loss: 1.2748 - accuracy: 0.4224 - val_loss: 1.2827 - val_accuracy: 0.4306

Epoch 02873: val_loss did not improve from 1.27604
Epoch 2874/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4211 - val_loss: 1.2844 - val_accuracy: 0.4242

Epoch 02874: val_loss did not improve from 1.27604
Epoch 2875/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4230 - val_loss: 1.2789 - val_accuracy: 0.4195

Epoch 02875: val_loss did not improve from 1.27604
Epoch 2876/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4265 - val_loss: 1.2844 - val_accuracy: 0.4226

Epoch 02876: val_loss did not improve from 1.27604
Epoch 2877/10000
12/12 - 0s - loss: 1.2749 - accuracy: 0.4217 - val_loss: 1.2793 - val_accuracy: 0.4155

Epoch 02877: val_loss did not improve from 1.27604
Epoch 2878/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4242 - val_loss: 1.2802 - val_accuracy: 0.4234

Epoch 02878: val_loss did not improve from 1.27604
Epoch 2879/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4263 - val_loss: 1.2811 - val_accuracy: 0.4155

Epoch 02879: val_loss did not improve from 1.27604
Epoch 2880/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4248 - val_loss: 1.2810 - val_accuracy: 0.4203

Epoch 02880: val_loss did not improve from 1.27604
Epoch 2881/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4258 - val_loss: 1.2839 - val_accuracy: 0.4203

Epoch 02881: val_loss did not improve from 1.27604
Epoch 2882/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4197 - val_loss: 1.2796 - val_accuracy: 0.4226

Epoch 02882: val_loss did not improve from 1.27604
Epoch 2883/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4272 - val_loss: 1.2839 - val_accuracy: 0.4219

Epoch 02883: val_loss did not improve from 1.27604
Epoch 2884/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4239 - val_loss: 1.2789 - val_accuracy: 0.4155

Epoch 02884: val_loss did not improve from 1.27604
Epoch 2885/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4249 - val_loss: 1.2800 - val_accuracy: 0.4234

Epoch 02885: val_loss did not improve from 1.27604
Epoch 2886/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4205 - val_loss: 1.2808 - val_accuracy: 0.4290

Epoch 02886: val_loss did not improve from 1.27604
Epoch 2887/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4179 - val_loss: 1.2796 - val_accuracy: 0.4211

Epoch 02887: val_loss did not improve from 1.27604
Epoch 2888/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4231 - val_loss: 1.2777 - val_accuracy: 0.4179

Epoch 02888: val_loss did not improve from 1.27604
Epoch 2889/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4262 - val_loss: 1.2771 - val_accuracy: 0.4147

Epoch 02889: val_loss did not improve from 1.27604
Epoch 2890/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4246 - val_loss: 1.2777 - val_accuracy: 0.4155

Epoch 02890: val_loss did not improve from 1.27604
Epoch 2891/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4223 - val_loss: 1.2796 - val_accuracy: 0.4163

Epoch 02891: val_loss did not improve from 1.27604
Epoch 2892/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4263 - val_loss: 1.2826 - val_accuracy: 0.4322

Epoch 02892: val_loss did not improve from 1.27604
Epoch 2893/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4294 - val_loss: 1.2775 - val_accuracy: 0.4250

Epoch 02893: val_loss did not improve from 1.27604
Epoch 2894/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4245 - val_loss: 1.2794 - val_accuracy: 0.4282

Epoch 02894: val_loss did not improve from 1.27604
Epoch 2895/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4252 - val_loss: 1.2778 - val_accuracy: 0.4195

Epoch 02895: val_loss did not improve from 1.27604
Epoch 2896/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4250 - val_loss: 1.2796 - val_accuracy: 0.4242

Epoch 02896: val_loss did not improve from 1.27604
Epoch 2897/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4234 - val_loss: 1.2832 - val_accuracy: 0.4298

Epoch 02897: val_loss did not improve from 1.27604
Epoch 2898/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4251 - val_loss: 1.2836 - val_accuracy: 0.4219

Epoch 02898: val_loss did not improve from 1.27604
Epoch 2899/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4256 - val_loss: 1.2785 - val_accuracy: 0.4298

Epoch 02899: val_loss did not improve from 1.27604
Epoch 2900/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4240 - val_loss: 1.2841 - val_accuracy: 0.4242

Epoch 02900: val_loss did not improve from 1.27604
Epoch 2901/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4252 - val_loss: 1.2785 - val_accuracy: 0.4226

Epoch 02901: val_loss did not improve from 1.27604
Epoch 2902/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4235 - val_loss: 1.2798 - val_accuracy: 0.4234

Epoch 02902: val_loss did not improve from 1.27604
Epoch 2903/10000
12/12 - 0s - loss: 1.2734 - accuracy: 0.4252 - val_loss: 1.2832 - val_accuracy: 0.4171

Epoch 02903: val_loss did not improve from 1.27604
Epoch 2904/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4230 - val_loss: 1.2819 - val_accuracy: 0.4242

Epoch 02904: val_loss did not improve from 1.27604
Epoch 2905/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4211 - val_loss: 1.2795 - val_accuracy: 0.4250

Epoch 02905: val_loss did not improve from 1.27604
Epoch 2906/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4239 - val_loss: 1.2789 - val_accuracy: 0.4203

Epoch 02906: val_loss did not improve from 1.27604
Epoch 2907/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4233 - val_loss: 1.2775 - val_accuracy: 0.4147

Epoch 02907: val_loss did not improve from 1.27604
Epoch 2908/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4249 - val_loss: 1.2784 - val_accuracy: 0.4203

Epoch 02908: val_loss did not improve from 1.27604
Epoch 2909/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4281 - val_loss: 1.2770 - val_accuracy: 0.4219

Epoch 02909: val_loss did not improve from 1.27604
Epoch 2910/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4221 - val_loss: 1.2789 - val_accuracy: 0.4306

Epoch 02910: val_loss did not improve from 1.27604
Epoch 2911/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4230 - val_loss: 1.2769 - val_accuracy: 0.4226

Epoch 02911: val_loss did not improve from 1.27604
Epoch 2912/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4229 - val_loss: 1.2802 - val_accuracy: 0.4195

Epoch 02912: val_loss did not improve from 1.27604
Epoch 2913/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4263 - val_loss: 1.2771 - val_accuracy: 0.4306

Epoch 02913: val_loss did not improve from 1.27604
Epoch 2914/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4228 - val_loss: 1.2774 - val_accuracy: 0.4195

Epoch 02914: val_loss did not improve from 1.27604
Epoch 2915/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4247 - val_loss: 1.2814 - val_accuracy: 0.4171

Epoch 02915: val_loss did not improve from 1.27604
Epoch 2916/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4262 - val_loss: 1.2782 - val_accuracy: 0.4203

Epoch 02916: val_loss did not improve from 1.27604
Epoch 2917/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4233 - val_loss: 1.2785 - val_accuracy: 0.4266

Epoch 02917: val_loss did not improve from 1.27604
Epoch 2918/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4255 - val_loss: 1.2771 - val_accuracy: 0.4242

Epoch 02918: val_loss did not improve from 1.27604
Epoch 2919/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4259 - val_loss: 1.2792 - val_accuracy: 0.4187

Epoch 02919: val_loss did not improve from 1.27604
Epoch 2920/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4253 - val_loss: 1.2794 - val_accuracy: 0.4131

Epoch 02920: val_loss did not improve from 1.27604
Epoch 2921/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4257 - val_loss: 1.2784 - val_accuracy: 0.4234

Epoch 02921: val_loss did not improve from 1.27604
Epoch 2922/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4278 - val_loss: 1.2770 - val_accuracy: 0.4338

Epoch 02922: val_loss did not improve from 1.27604
Epoch 2923/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4181 - val_loss: 1.2783 - val_accuracy: 0.4123

Epoch 02923: val_loss did not improve from 1.27604
Epoch 2924/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4208 - val_loss: 1.2799 - val_accuracy: 0.4242

Epoch 02924: val_loss did not improve from 1.27604
Epoch 2925/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4222 - val_loss: 1.2782 - val_accuracy: 0.4290

Epoch 02925: val_loss did not improve from 1.27604
Epoch 2926/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4228 - val_loss: 1.2783 - val_accuracy: 0.4250

Epoch 02926: val_loss did not improve from 1.27604
Epoch 2927/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4236 - val_loss: 1.2774 - val_accuracy: 0.4234

Epoch 02927: val_loss did not improve from 1.27604
Epoch 2928/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4230 - val_loss: 1.2804 - val_accuracy: 0.4195

Epoch 02928: val_loss did not improve from 1.27604
Epoch 2929/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4205 - val_loss: 1.2768 - val_accuracy: 0.4147

Epoch 02929: val_loss did not improve from 1.27604
Epoch 2930/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4241 - val_loss: 1.2780 - val_accuracy: 0.4250

Epoch 02930: val_loss did not improve from 1.27604
Epoch 2931/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4209 - val_loss: 1.2804 - val_accuracy: 0.4226

Epoch 02931: val_loss did not improve from 1.27604
Epoch 2932/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4266 - val_loss: 1.2788 - val_accuracy: 0.4266

Epoch 02932: val_loss did not improve from 1.27604
Epoch 2933/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4234 - val_loss: 1.2793 - val_accuracy: 0.4234

Epoch 02933: val_loss did not improve from 1.27604
Epoch 2934/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4215 - val_loss: 1.2790 - val_accuracy: 0.4242

Epoch 02934: val_loss did not improve from 1.27604
Epoch 2935/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4217 - val_loss: 1.2770 - val_accuracy: 0.4171

Epoch 02935: val_loss did not improve from 1.27604
Epoch 2936/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4226 - val_loss: 1.2763 - val_accuracy: 0.4203

Epoch 02936: val_loss did not improve from 1.27604
Epoch 2937/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4255 - val_loss: 1.2772 - val_accuracy: 0.4282

Epoch 02937: val_loss did not improve from 1.27604
Epoch 2938/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4214 - val_loss: 1.2823 - val_accuracy: 0.4226

Epoch 02938: val_loss did not improve from 1.27604
Epoch 2939/10000
12/12 - 0s - loss: 1.2741 - accuracy: 0.4243 - val_loss: 1.2774 - val_accuracy: 0.4203

Epoch 02939: val_loss did not improve from 1.27604
Epoch 2940/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4256 - val_loss: 1.2764 - val_accuracy: 0.4258

Epoch 02940: val_loss did not improve from 1.27604
Epoch 2941/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4219 - val_loss: 1.2770 - val_accuracy: 0.4163

Epoch 02941: val_loss did not improve from 1.27604
Epoch 2942/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4218 - val_loss: 1.2758 - val_accuracy: 0.4242

Epoch 02942: val_loss improved from 1.27604 to 1.27577, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2943/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4243 - val_loss: 1.2766 - val_accuracy: 0.4187

Epoch 02943: val_loss did not improve from 1.27577
Epoch 2944/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4228 - val_loss: 1.2764 - val_accuracy: 0.4171

Epoch 02944: val_loss did not improve from 1.27577
Epoch 2945/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4227 - val_loss: 1.2770 - val_accuracy: 0.4250

Epoch 02945: val_loss did not improve from 1.27577
Epoch 2946/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4256 - val_loss: 1.2758 - val_accuracy: 0.4226

Epoch 02946: val_loss did not improve from 1.27577
Epoch 2947/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4256 - val_loss: 1.2775 - val_accuracy: 0.4226

Epoch 02947: val_loss did not improve from 1.27577
Epoch 2948/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4241 - val_loss: 1.2796 - val_accuracy: 0.4219

Epoch 02948: val_loss did not improve from 1.27577
Epoch 2949/10000
12/12 - 0s - loss: 1.2719 - accuracy: 0.4218 - val_loss: 1.2762 - val_accuracy: 0.4171

Epoch 02949: val_loss did not improve from 1.27577
Epoch 2950/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4235 - val_loss: 1.2774 - val_accuracy: 0.4195

Epoch 02950: val_loss did not improve from 1.27577
Epoch 2951/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4254 - val_loss: 1.2761 - val_accuracy: 0.4226

Epoch 02951: val_loss did not improve from 1.27577
Epoch 2952/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4241 - val_loss: 1.2776 - val_accuracy: 0.4211

Epoch 02952: val_loss did not improve from 1.27577
Epoch 2953/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4251 - val_loss: 1.2796 - val_accuracy: 0.4226

Epoch 02953: val_loss did not improve from 1.27577
Epoch 2954/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4224 - val_loss: 1.2791 - val_accuracy: 0.4266

Epoch 02954: val_loss did not improve from 1.27577
Epoch 2955/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4218 - val_loss: 1.2776 - val_accuracy: 0.4131

Epoch 02955: val_loss did not improve from 1.27577
Epoch 2956/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4222 - val_loss: 1.2773 - val_accuracy: 0.4242

Epoch 02956: val_loss did not improve from 1.27577
Epoch 2957/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4224 - val_loss: 1.2782 - val_accuracy: 0.4163

Epoch 02957: val_loss did not improve from 1.27577
Epoch 2958/10000
12/12 - 0s - loss: 1.2766 - accuracy: 0.4186 - val_loss: 1.2769 - val_accuracy: 0.4195

Epoch 02958: val_loss did not improve from 1.27577
Epoch 2959/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4230 - val_loss: 1.2751 - val_accuracy: 0.4203

Epoch 02959: val_loss improved from 1.27577 to 1.27512, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2960/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4220 - val_loss: 1.2786 - val_accuracy: 0.4179

Epoch 02960: val_loss did not improve from 1.27512
Epoch 2961/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4202 - val_loss: 1.2768 - val_accuracy: 0.4274

Epoch 02961: val_loss did not improve from 1.27512
Epoch 2962/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4256 - val_loss: 1.2793 - val_accuracy: 0.4290

Epoch 02962: val_loss did not improve from 1.27512
Epoch 2963/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4255 - val_loss: 1.2760 - val_accuracy: 0.4139

Epoch 02963: val_loss did not improve from 1.27512
Epoch 2964/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4249 - val_loss: 1.2777 - val_accuracy: 0.4314

Epoch 02964: val_loss did not improve from 1.27512
Epoch 2965/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4244 - val_loss: 1.2759 - val_accuracy: 0.4203

Epoch 02965: val_loss did not improve from 1.27512
Epoch 2966/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4241 - val_loss: 1.2765 - val_accuracy: 0.4155

Epoch 02966: val_loss did not improve from 1.27512
Epoch 2967/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4213 - val_loss: 1.2771 - val_accuracy: 0.4147

Epoch 02967: val_loss did not improve from 1.27512
Epoch 2968/10000
12/12 - 0s - loss: 1.2736 - accuracy: 0.4236 - val_loss: 1.2792 - val_accuracy: 0.4306

Epoch 02968: val_loss did not improve from 1.27512
Epoch 2969/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4244 - val_loss: 1.2774 - val_accuracy: 0.4234

Epoch 02969: val_loss did not improve from 1.27512
Epoch 2970/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4253 - val_loss: 1.2749 - val_accuracy: 0.4195

Epoch 02970: val_loss improved from 1.27512 to 1.27494, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 2971/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4228 - val_loss: 1.2776 - val_accuracy: 0.4203

Epoch 02971: val_loss did not improve from 1.27494
Epoch 2972/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4246 - val_loss: 1.2787 - val_accuracy: 0.4290

Epoch 02972: val_loss did not improve from 1.27494
Epoch 2973/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4251 - val_loss: 1.2811 - val_accuracy: 0.4155

Epoch 02973: val_loss did not improve from 1.27494
Epoch 2974/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4218 - val_loss: 1.2785 - val_accuracy: 0.4219

Epoch 02974: val_loss did not improve from 1.27494
Epoch 2975/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4261 - val_loss: 1.2780 - val_accuracy: 0.4211

Epoch 02975: val_loss did not improve from 1.27494
Epoch 2976/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4256 - val_loss: 1.2768 - val_accuracy: 0.4226

Epoch 02976: val_loss did not improve from 1.27494
Epoch 2977/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4259 - val_loss: 1.2797 - val_accuracy: 0.4211

Epoch 02977: val_loss did not improve from 1.27494
Epoch 2978/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4248 - val_loss: 1.2787 - val_accuracy: 0.4234

Epoch 02978: val_loss did not improve from 1.27494
Epoch 2979/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4275 - val_loss: 1.2781 - val_accuracy: 0.4274

Epoch 02979: val_loss did not improve from 1.27494
Epoch 2980/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4233 - val_loss: 1.2795 - val_accuracy: 0.4250

Epoch 02980: val_loss did not improve from 1.27494
Epoch 2981/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4237 - val_loss: 1.2767 - val_accuracy: 0.4155

Epoch 02981: val_loss did not improve from 1.27494
Epoch 2982/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4244 - val_loss: 1.2824 - val_accuracy: 0.4226

Epoch 02982: val_loss did not improve from 1.27494
Epoch 2983/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4202 - val_loss: 1.2780 - val_accuracy: 0.4258

Epoch 02983: val_loss did not improve from 1.27494
Epoch 2984/10000
12/12 - 0s - loss: 1.2728 - accuracy: 0.4277 - val_loss: 1.2770 - val_accuracy: 0.4258

Epoch 02984: val_loss did not improve from 1.27494
Epoch 2985/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4240 - val_loss: 1.2824 - val_accuracy: 0.4179

Epoch 02985: val_loss did not improve from 1.27494
Epoch 2986/10000
12/12 - 0s - loss: 1.2762 - accuracy: 0.4194 - val_loss: 1.2782 - val_accuracy: 0.4179

Epoch 02986: val_loss did not improve from 1.27494
Epoch 2987/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4202 - val_loss: 1.2775 - val_accuracy: 0.4234

Epoch 02987: val_loss did not improve from 1.27494
Epoch 2988/10000
12/12 - 0s - loss: 1.2739 - accuracy: 0.4203 - val_loss: 1.2791 - val_accuracy: 0.4226

Epoch 02988: val_loss did not improve from 1.27494
Epoch 2989/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4259 - val_loss: 1.2818 - val_accuracy: 0.4155

Epoch 02989: val_loss did not improve from 1.27494
Epoch 2990/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4258 - val_loss: 1.2807 - val_accuracy: 0.4258

Epoch 02990: val_loss did not improve from 1.27494
Epoch 2991/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4216 - val_loss: 1.2789 - val_accuracy: 0.4242

Epoch 02991: val_loss did not improve from 1.27494
Epoch 2992/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4240 - val_loss: 1.2814 - val_accuracy: 0.4195

Epoch 02992: val_loss did not improve from 1.27494
Epoch 2993/10000
12/12 - 0s - loss: 1.2769 - accuracy: 0.4206 - val_loss: 1.2762 - val_accuracy: 0.4171

Epoch 02993: val_loss did not improve from 1.27494
Epoch 2994/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4242 - val_loss: 1.2778 - val_accuracy: 0.4234

Epoch 02994: val_loss did not improve from 1.27494
Epoch 2995/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4228 - val_loss: 1.2767 - val_accuracy: 0.4290

Epoch 02995: val_loss did not improve from 1.27494
Epoch 2996/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4219 - val_loss: 1.2766 - val_accuracy: 0.4234

Epoch 02996: val_loss did not improve from 1.27494
Epoch 2997/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4230 - val_loss: 1.2757 - val_accuracy: 0.4242

Epoch 02997: val_loss did not improve from 1.27494
Epoch 2998/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4254 - val_loss: 1.2762 - val_accuracy: 0.4179

Epoch 02998: val_loss did not improve from 1.27494
Epoch 2999/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4216 - val_loss: 1.2814 - val_accuracy: 0.4195

Epoch 02999: val_loss did not improve from 1.27494
Epoch 3000/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4218 - val_loss: 1.2803 - val_accuracy: 0.4330

Epoch 03000: val_loss did not improve from 1.27494
Epoch 3001/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4229 - val_loss: 1.2759 - val_accuracy: 0.4250

Epoch 03001: val_loss did not improve from 1.27494
Epoch 3002/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4257 - val_loss: 1.2758 - val_accuracy: 0.4234

Epoch 03002: val_loss did not improve from 1.27494
Epoch 3003/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4243 - val_loss: 1.2776 - val_accuracy: 0.4219

Epoch 03003: val_loss did not improve from 1.27494
Epoch 3004/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4267 - val_loss: 1.2769 - val_accuracy: 0.4219

Epoch 03004: val_loss did not improve from 1.27494
Epoch 3005/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4253 - val_loss: 1.2760 - val_accuracy: 0.4171

Epoch 03005: val_loss did not improve from 1.27494
Epoch 3006/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4240 - val_loss: 1.2831 - val_accuracy: 0.4211

Epoch 03006: val_loss did not improve from 1.27494
Epoch 3007/10000
12/12 - 0s - loss: 1.2758 - accuracy: 0.4198 - val_loss: 1.2765 - val_accuracy: 0.4274

Epoch 03007: val_loss did not improve from 1.27494
Epoch 3008/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4224 - val_loss: 1.2784 - val_accuracy: 0.4179

Epoch 03008: val_loss did not improve from 1.27494
Epoch 3009/10000
12/12 - 0s - loss: 1.2724 - accuracy: 0.4215 - val_loss: 1.2793 - val_accuracy: 0.4266

Epoch 03009: val_loss did not improve from 1.27494
Epoch 3010/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4250 - val_loss: 1.2759 - val_accuracy: 0.4123

Epoch 03010: val_loss did not improve from 1.27494
Epoch 3011/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4220 - val_loss: 1.2777 - val_accuracy: 0.4242

Epoch 03011: val_loss did not improve from 1.27494
Epoch 3012/10000
12/12 - 0s - loss: 1.2771 - accuracy: 0.4219 - val_loss: 1.2805 - val_accuracy: 0.4187

Epoch 03012: val_loss did not improve from 1.27494
Epoch 3013/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4245 - val_loss: 1.2771 - val_accuracy: 0.4250

Epoch 03013: val_loss did not improve from 1.27494
Epoch 3014/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4264 - val_loss: 1.2767 - val_accuracy: 0.4274

Epoch 03014: val_loss did not improve from 1.27494
Epoch 3015/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4240 - val_loss: 1.2759 - val_accuracy: 0.4211

Epoch 03015: val_loss did not improve from 1.27494
Epoch 3016/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4237 - val_loss: 1.2794 - val_accuracy: 0.4147

Epoch 03016: val_loss did not improve from 1.27494
Epoch 3017/10000
12/12 - 0s - loss: 1.2774 - accuracy: 0.4184 - val_loss: 1.2873 - val_accuracy: 0.4274

Epoch 03017: val_loss did not improve from 1.27494
Epoch 3018/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4228 - val_loss: 1.2742 - val_accuracy: 0.4179

Epoch 03018: val_loss improved from 1.27494 to 1.27418, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3019/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4251 - val_loss: 1.2766 - val_accuracy: 0.4171

Epoch 03019: val_loss did not improve from 1.27418
Epoch 3020/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4210 - val_loss: 1.2784 - val_accuracy: 0.4226

Epoch 03020: val_loss did not improve from 1.27418
Epoch 3021/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4245 - val_loss: 1.2757 - val_accuracy: 0.4306

Epoch 03021: val_loss did not improve from 1.27418
Epoch 3022/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4257 - val_loss: 1.2783 - val_accuracy: 0.4139

Epoch 03022: val_loss did not improve from 1.27418
Epoch 3023/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4242 - val_loss: 1.2752 - val_accuracy: 0.4234

Epoch 03023: val_loss did not improve from 1.27418
Epoch 3024/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4243 - val_loss: 1.2774 - val_accuracy: 0.4163

Epoch 03024: val_loss did not improve from 1.27418
Epoch 3025/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4228 - val_loss: 1.2747 - val_accuracy: 0.4179

Epoch 03025: val_loss did not improve from 1.27418
Epoch 3026/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4225 - val_loss: 1.2751 - val_accuracy: 0.4266

Epoch 03026: val_loss did not improve from 1.27418
Epoch 3027/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4256 - val_loss: 1.2756 - val_accuracy: 0.4219

Epoch 03027: val_loss did not improve from 1.27418
Epoch 3028/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4256 - val_loss: 1.2768 - val_accuracy: 0.4163

Epoch 03028: val_loss did not improve from 1.27418
Epoch 3029/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4256 - val_loss: 1.2782 - val_accuracy: 0.4242

Epoch 03029: val_loss did not improve from 1.27418
Epoch 3030/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4227 - val_loss: 1.2845 - val_accuracy: 0.4266

Epoch 03030: val_loss did not improve from 1.27418
Epoch 3031/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4240 - val_loss: 1.2777 - val_accuracy: 0.4226

Epoch 03031: val_loss did not improve from 1.27418
Epoch 3032/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4256 - val_loss: 1.2836 - val_accuracy: 0.4179

Epoch 03032: val_loss did not improve from 1.27418
Epoch 3033/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4180 - val_loss: 1.2755 - val_accuracy: 0.4211

Epoch 03033: val_loss did not improve from 1.27418
Epoch 3034/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4255 - val_loss: 1.2766 - val_accuracy: 0.4203

Epoch 03034: val_loss did not improve from 1.27418
Epoch 3035/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4263 - val_loss: 1.2754 - val_accuracy: 0.4242

Epoch 03035: val_loss did not improve from 1.27418
Epoch 3036/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4272 - val_loss: 1.2756 - val_accuracy: 0.4266

Epoch 03036: val_loss did not improve from 1.27418
Epoch 3037/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4262 - val_loss: 1.2752 - val_accuracy: 0.4330

Epoch 03037: val_loss did not improve from 1.27418
Epoch 3038/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4254 - val_loss: 1.2790 - val_accuracy: 0.4203

Epoch 03038: val_loss did not improve from 1.27418
Epoch 3039/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4261 - val_loss: 1.2751 - val_accuracy: 0.4266

Epoch 03039: val_loss did not improve from 1.27418
Epoch 3040/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4262 - val_loss: 1.2774 - val_accuracy: 0.4234

Epoch 03040: val_loss did not improve from 1.27418
Epoch 3041/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4240 - val_loss: 1.2767 - val_accuracy: 0.4211

Epoch 03041: val_loss did not improve from 1.27418
Epoch 3042/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4243 - val_loss: 1.2762 - val_accuracy: 0.4282

Epoch 03042: val_loss did not improve from 1.27418
Epoch 3043/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4267 - val_loss: 1.2768 - val_accuracy: 0.4179

Epoch 03043: val_loss did not improve from 1.27418
Epoch 3044/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4225 - val_loss: 1.2786 - val_accuracy: 0.4211

Epoch 03044: val_loss did not improve from 1.27418
Epoch 3045/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4233 - val_loss: 1.2763 - val_accuracy: 0.4234

Epoch 03045: val_loss did not improve from 1.27418
Epoch 3046/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4256 - val_loss: 1.2776 - val_accuracy: 0.4330

Epoch 03046: val_loss did not improve from 1.27418
Epoch 3047/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4258 - val_loss: 1.2760 - val_accuracy: 0.4226

Epoch 03047: val_loss did not improve from 1.27418
Epoch 3048/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4233 - val_loss: 1.2744 - val_accuracy: 0.4250

Epoch 03048: val_loss did not improve from 1.27418
Epoch 3049/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4260 - val_loss: 1.2762 - val_accuracy: 0.4258

Epoch 03049: val_loss did not improve from 1.27418
Epoch 3050/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4265 - val_loss: 1.2771 - val_accuracy: 0.4274

Epoch 03050: val_loss did not improve from 1.27418
Epoch 3051/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4227 - val_loss: 1.2757 - val_accuracy: 0.4234

Epoch 03051: val_loss did not improve from 1.27418
Epoch 3052/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4235 - val_loss: 1.2758 - val_accuracy: 0.4171

Epoch 03052: val_loss did not improve from 1.27418
Epoch 3053/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4228 - val_loss: 1.2765 - val_accuracy: 0.4250

Epoch 03053: val_loss did not improve from 1.27418
Epoch 3054/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4229 - val_loss: 1.2764 - val_accuracy: 0.4195

Epoch 03054: val_loss did not improve from 1.27418
Epoch 3055/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4286 - val_loss: 1.2738 - val_accuracy: 0.4274

Epoch 03055: val_loss improved from 1.27418 to 1.27376, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3056/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4282 - val_loss: 1.2745 - val_accuracy: 0.4250

Epoch 03056: val_loss did not improve from 1.27376
Epoch 3057/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4217 - val_loss: 1.2773 - val_accuracy: 0.4226

Epoch 03057: val_loss did not improve from 1.27376
Epoch 3058/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4257 - val_loss: 1.2742 - val_accuracy: 0.4242

Epoch 03058: val_loss did not improve from 1.27376
Epoch 3059/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4259 - val_loss: 1.2755 - val_accuracy: 0.4219

Epoch 03059: val_loss did not improve from 1.27376
Epoch 3060/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4219 - val_loss: 1.2738 - val_accuracy: 0.4250

Epoch 03060: val_loss did not improve from 1.27376
Epoch 3061/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4237 - val_loss: 1.2783 - val_accuracy: 0.4203

Epoch 03061: val_loss did not improve from 1.27376
Epoch 3062/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4256 - val_loss: 1.2748 - val_accuracy: 0.4250

Epoch 03062: val_loss did not improve from 1.27376
Epoch 3063/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4235 - val_loss: 1.2744 - val_accuracy: 0.4203

Epoch 03063: val_loss did not improve from 1.27376
Epoch 3064/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4223 - val_loss: 1.2750 - val_accuracy: 0.4211

Epoch 03064: val_loss did not improve from 1.27376
Epoch 3065/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4276 - val_loss: 1.2773 - val_accuracy: 0.4338

Epoch 03065: val_loss did not improve from 1.27376
Epoch 3066/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4232 - val_loss: 1.2809 - val_accuracy: 0.4250

Epoch 03066: val_loss did not improve from 1.27376
Epoch 3067/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4247 - val_loss: 1.2760 - val_accuracy: 0.4282

Epoch 03067: val_loss did not improve from 1.27376
Epoch 3068/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4256 - val_loss: 1.2809 - val_accuracy: 0.4250

Epoch 03068: val_loss did not improve from 1.27376
Epoch 3069/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4268 - val_loss: 1.2759 - val_accuracy: 0.4250

Epoch 03069: val_loss did not improve from 1.27376
Epoch 3070/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4249 - val_loss: 1.2763 - val_accuracy: 0.4314

Epoch 03070: val_loss did not improve from 1.27376
Epoch 3071/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4227 - val_loss: 1.2852 - val_accuracy: 0.4171

Epoch 03071: val_loss did not improve from 1.27376
Epoch 3072/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4216 - val_loss: 1.2795 - val_accuracy: 0.4242

Epoch 03072: val_loss did not improve from 1.27376
Epoch 3073/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4219 - val_loss: 1.2764 - val_accuracy: 0.4258

Epoch 03073: val_loss did not improve from 1.27376
Epoch 3074/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4249 - val_loss: 1.2739 - val_accuracy: 0.4250

Epoch 03074: val_loss did not improve from 1.27376
Epoch 3075/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4264 - val_loss: 1.2775 - val_accuracy: 0.4298

Epoch 03075: val_loss did not improve from 1.27376
Epoch 3076/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4218 - val_loss: 1.2764 - val_accuracy: 0.4298

Epoch 03076: val_loss did not improve from 1.27376
Epoch 3077/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4221 - val_loss: 1.2777 - val_accuracy: 0.4147

Epoch 03077: val_loss did not improve from 1.27376
Epoch 3078/10000
12/12 - 0s - loss: 1.2735 - accuracy: 0.4165 - val_loss: 1.2741 - val_accuracy: 0.4234

Epoch 03078: val_loss did not improve from 1.27376
Epoch 3079/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4249 - val_loss: 1.2771 - val_accuracy: 0.4258

Epoch 03079: val_loss did not improve from 1.27376
Epoch 3080/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4234 - val_loss: 1.2765 - val_accuracy: 0.4211

Epoch 03080: val_loss did not improve from 1.27376
Epoch 3081/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4249 - val_loss: 1.2790 - val_accuracy: 0.4234

Epoch 03081: val_loss did not improve from 1.27376
Epoch 3082/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4253 - val_loss: 1.2755 - val_accuracy: 0.4226

Epoch 03082: val_loss did not improve from 1.27376
Epoch 3083/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4247 - val_loss: 1.2746 - val_accuracy: 0.4226

Epoch 03083: val_loss did not improve from 1.27376
Epoch 3084/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4257 - val_loss: 1.2735 - val_accuracy: 0.4187

Epoch 03084: val_loss improved from 1.27376 to 1.27353, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3085/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4257 - val_loss: 1.2841 - val_accuracy: 0.4115

Epoch 03085: val_loss did not improve from 1.27353
Epoch 3086/10000
12/12 - 0s - loss: 1.2772 - accuracy: 0.4172 - val_loss: 1.2746 - val_accuracy: 0.4282

Epoch 03086: val_loss did not improve from 1.27353
Epoch 3087/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4273 - val_loss: 1.2753 - val_accuracy: 0.4195

Epoch 03087: val_loss did not improve from 1.27353
Epoch 3088/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4270 - val_loss: 1.2802 - val_accuracy: 0.4219

Epoch 03088: val_loss did not improve from 1.27353
Epoch 3089/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4232 - val_loss: 1.2796 - val_accuracy: 0.4091

Epoch 03089: val_loss did not improve from 1.27353
Epoch 3090/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4221 - val_loss: 1.2749 - val_accuracy: 0.4219

Epoch 03090: val_loss did not improve from 1.27353
Epoch 3091/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4238 - val_loss: 1.2759 - val_accuracy: 0.4226

Epoch 03091: val_loss did not improve from 1.27353
Epoch 3092/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4197 - val_loss: 1.2748 - val_accuracy: 0.4282

Epoch 03092: val_loss did not improve from 1.27353
Epoch 3093/10000
12/12 - 0s - loss: 1.2715 - accuracy: 0.4202 - val_loss: 1.2808 - val_accuracy: 0.4306

Epoch 03093: val_loss did not improve from 1.27353
Epoch 3094/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4226 - val_loss: 1.2754 - val_accuracy: 0.4322

Epoch 03094: val_loss did not improve from 1.27353
Epoch 3095/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4209 - val_loss: 1.2766 - val_accuracy: 0.4242

Epoch 03095: val_loss did not improve from 1.27353
Epoch 3096/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4250 - val_loss: 1.2758 - val_accuracy: 0.4250

Epoch 03096: val_loss did not improve from 1.27353
Epoch 3097/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4233 - val_loss: 1.2759 - val_accuracy: 0.4163

Epoch 03097: val_loss did not improve from 1.27353
Epoch 3098/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4252 - val_loss: 1.2752 - val_accuracy: 0.4274

Epoch 03098: val_loss did not improve from 1.27353
Epoch 3099/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4250 - val_loss: 1.2749 - val_accuracy: 0.4211

Epoch 03099: val_loss did not improve from 1.27353
Epoch 3100/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4294 - val_loss: 1.2743 - val_accuracy: 0.4266

Epoch 03100: val_loss did not improve from 1.27353
Epoch 3101/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4233 - val_loss: 1.2751 - val_accuracy: 0.4250

Epoch 03101: val_loss did not improve from 1.27353
Epoch 3102/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4258 - val_loss: 1.2747 - val_accuracy: 0.4219

Epoch 03102: val_loss did not improve from 1.27353
Epoch 3103/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4249 - val_loss: 1.2758 - val_accuracy: 0.4258

Epoch 03103: val_loss did not improve from 1.27353
Epoch 3104/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4225 - val_loss: 1.2741 - val_accuracy: 0.4171

Epoch 03104: val_loss did not improve from 1.27353
Epoch 3105/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4242 - val_loss: 1.2807 - val_accuracy: 0.4219

Epoch 03105: val_loss did not improve from 1.27353
Epoch 3106/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4232 - val_loss: 1.2757 - val_accuracy: 0.4219

Epoch 03106: val_loss did not improve from 1.27353
Epoch 3107/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4254 - val_loss: 1.2803 - val_accuracy: 0.4242

Epoch 03107: val_loss did not improve from 1.27353
Epoch 3108/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4177 - val_loss: 1.2751 - val_accuracy: 0.4187

Epoch 03108: val_loss did not improve from 1.27353
Epoch 3109/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4245 - val_loss: 1.2751 - val_accuracy: 0.4226

Epoch 03109: val_loss did not improve from 1.27353
Epoch 3110/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4228 - val_loss: 1.2754 - val_accuracy: 0.4179

Epoch 03110: val_loss did not improve from 1.27353
Epoch 3111/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4225 - val_loss: 1.2818 - val_accuracy: 0.4266

Epoch 03111: val_loss did not improve from 1.27353
Epoch 3112/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4249 - val_loss: 1.2751 - val_accuracy: 0.4195

Epoch 03112: val_loss did not improve from 1.27353
Epoch 3113/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4257 - val_loss: 1.2756 - val_accuracy: 0.4274

Epoch 03113: val_loss did not improve from 1.27353
Epoch 3114/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4197 - val_loss: 1.2745 - val_accuracy: 0.4203

Epoch 03114: val_loss did not improve from 1.27353
Epoch 3115/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4268 - val_loss: 1.2786 - val_accuracy: 0.4203

Epoch 03115: val_loss did not improve from 1.27353
Epoch 3116/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4258 - val_loss: 1.2735 - val_accuracy: 0.4187

Epoch 03116: val_loss improved from 1.27353 to 1.27353, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3117/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4263 - val_loss: 1.2728 - val_accuracy: 0.4242

Epoch 03117: val_loss improved from 1.27353 to 1.27283, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3118/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4220 - val_loss: 1.2753 - val_accuracy: 0.4226

Epoch 03118: val_loss did not improve from 1.27283
Epoch 3119/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4222 - val_loss: 1.2847 - val_accuracy: 0.4250

Epoch 03119: val_loss did not improve from 1.27283
Epoch 3120/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4233 - val_loss: 1.2760 - val_accuracy: 0.4250

Epoch 03120: val_loss did not improve from 1.27283
Epoch 3121/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4224 - val_loss: 1.2742 - val_accuracy: 0.4211

Epoch 03121: val_loss did not improve from 1.27283
Epoch 3122/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4235 - val_loss: 1.2758 - val_accuracy: 0.4266

Epoch 03122: val_loss did not improve from 1.27283
Epoch 3123/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4212 - val_loss: 1.2764 - val_accuracy: 0.4242

Epoch 03123: val_loss did not improve from 1.27283
Epoch 3124/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4218 - val_loss: 1.2776 - val_accuracy: 0.4147

Epoch 03124: val_loss did not improve from 1.27283
Epoch 3125/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4241 - val_loss: 1.2747 - val_accuracy: 0.4211

Epoch 03125: val_loss did not improve from 1.27283
Epoch 3126/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4271 - val_loss: 1.2753 - val_accuracy: 0.4219

Epoch 03126: val_loss did not improve from 1.27283
Epoch 3127/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4209 - val_loss: 1.2749 - val_accuracy: 0.4290

Epoch 03127: val_loss did not improve from 1.27283
Epoch 3128/10000
12/12 - 0s - loss: 1.2727 - accuracy: 0.4239 - val_loss: 1.2840 - val_accuracy: 0.4258

Epoch 03128: val_loss did not improve from 1.27283
Epoch 3129/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4194 - val_loss: 1.2754 - val_accuracy: 0.4242

Epoch 03129: val_loss did not improve from 1.27283
Epoch 3130/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4217 - val_loss: 1.2757 - val_accuracy: 0.4250

Epoch 03130: val_loss did not improve from 1.27283
Epoch 3131/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4204 - val_loss: 1.2741 - val_accuracy: 0.4298

Epoch 03131: val_loss did not improve from 1.27283
Epoch 3132/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4219 - val_loss: 1.2760 - val_accuracy: 0.4266

Epoch 03132: val_loss did not improve from 1.27283
Epoch 3133/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4242 - val_loss: 1.2758 - val_accuracy: 0.4250

Epoch 03133: val_loss did not improve from 1.27283
Epoch 3134/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4262 - val_loss: 1.2807 - val_accuracy: 0.4219

Epoch 03134: val_loss did not improve from 1.27283
Epoch 3135/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4208 - val_loss: 1.2744 - val_accuracy: 0.4187

Epoch 03135: val_loss did not improve from 1.27283
Epoch 3136/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4220 - val_loss: 1.2731 - val_accuracy: 0.4139

Epoch 03136: val_loss did not improve from 1.27283
Epoch 3137/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4194 - val_loss: 1.2766 - val_accuracy: 0.4250

Epoch 03137: val_loss did not improve from 1.27283
Epoch 3138/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4256 - val_loss: 1.2749 - val_accuracy: 0.4163

Epoch 03138: val_loss did not improve from 1.27283
Epoch 3139/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4228 - val_loss: 1.2739 - val_accuracy: 0.4306

Epoch 03139: val_loss did not improve from 1.27283
Epoch 3140/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4256 - val_loss: 1.2738 - val_accuracy: 0.4139

Epoch 03140: val_loss did not improve from 1.27283
Epoch 3141/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4228 - val_loss: 1.2733 - val_accuracy: 0.4171

Epoch 03141: val_loss did not improve from 1.27283
Epoch 3142/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4277 - val_loss: 1.2739 - val_accuracy: 0.4187

Epoch 03142: val_loss did not improve from 1.27283
Epoch 3143/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4235 - val_loss: 1.2750 - val_accuracy: 0.4211

Epoch 03143: val_loss did not improve from 1.27283
Epoch 3144/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4224 - val_loss: 1.2769 - val_accuracy: 0.4203

Epoch 03144: val_loss did not improve from 1.27283
Epoch 3145/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4241 - val_loss: 1.2737 - val_accuracy: 0.4107

Epoch 03145: val_loss did not improve from 1.27283
Epoch 3146/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4264 - val_loss: 1.2745 - val_accuracy: 0.4179

Epoch 03146: val_loss did not improve from 1.27283
Epoch 3147/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4237 - val_loss: 1.2763 - val_accuracy: 0.4171

Epoch 03147: val_loss did not improve from 1.27283
Epoch 3148/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4211 - val_loss: 1.2750 - val_accuracy: 0.4290

Epoch 03148: val_loss did not improve from 1.27283
Epoch 3149/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4249 - val_loss: 1.2753 - val_accuracy: 0.4234

Epoch 03149: val_loss did not improve from 1.27283
Epoch 3150/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4238 - val_loss: 1.2780 - val_accuracy: 0.4234

Epoch 03150: val_loss did not improve from 1.27283
Epoch 3151/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4218 - val_loss: 1.2756 - val_accuracy: 0.4306

Epoch 03151: val_loss did not improve from 1.27283
Epoch 3152/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4226 - val_loss: 1.2724 - val_accuracy: 0.4163

Epoch 03152: val_loss improved from 1.27283 to 1.27242, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3153/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4267 - val_loss: 1.2733 - val_accuracy: 0.4203

Epoch 03153: val_loss did not improve from 1.27242
Epoch 3154/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4233 - val_loss: 1.2747 - val_accuracy: 0.4219

Epoch 03154: val_loss did not improve from 1.27242
Epoch 3155/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4233 - val_loss: 1.2767 - val_accuracy: 0.4250

Epoch 03155: val_loss did not improve from 1.27242
Epoch 3156/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4260 - val_loss: 1.2758 - val_accuracy: 0.4242

Epoch 03156: val_loss did not improve from 1.27242
Epoch 3157/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4250 - val_loss: 1.2751 - val_accuracy: 0.4250

Epoch 03157: val_loss did not improve from 1.27242
Epoch 3158/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4222 - val_loss: 1.2753 - val_accuracy: 0.4226

Epoch 03158: val_loss did not improve from 1.27242
Epoch 3159/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4279 - val_loss: 1.2755 - val_accuracy: 0.4195

Epoch 03159: val_loss did not improve from 1.27242
Epoch 3160/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4245 - val_loss: 1.2763 - val_accuracy: 0.4203

Epoch 03160: val_loss did not improve from 1.27242
Epoch 3161/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4241 - val_loss: 1.2850 - val_accuracy: 0.4274

Epoch 03161: val_loss did not improve from 1.27242
Epoch 3162/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4243 - val_loss: 1.2825 - val_accuracy: 0.4179

Epoch 03162: val_loss did not improve from 1.27242
Epoch 3163/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4239 - val_loss: 1.2734 - val_accuracy: 0.4258

Epoch 03163: val_loss did not improve from 1.27242
Epoch 3164/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4261 - val_loss: 1.2733 - val_accuracy: 0.4274

Epoch 03164: val_loss did not improve from 1.27242
Epoch 3165/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4253 - val_loss: 1.2779 - val_accuracy: 0.4187

Epoch 03165: val_loss did not improve from 1.27242
Epoch 3166/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4231 - val_loss: 1.2736 - val_accuracy: 0.4203

Epoch 03166: val_loss did not improve from 1.27242
Epoch 3167/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4274 - val_loss: 1.2751 - val_accuracy: 0.4250

Epoch 03167: val_loss did not improve from 1.27242
Epoch 3168/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4298 - val_loss: 1.2776 - val_accuracy: 0.4274

Epoch 03168: val_loss did not improve from 1.27242
Epoch 3169/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4272 - val_loss: 1.2739 - val_accuracy: 0.4250

Epoch 03169: val_loss did not improve from 1.27242
Epoch 3170/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4210 - val_loss: 1.2800 - val_accuracy: 0.4258

Epoch 03170: val_loss did not improve from 1.27242
Epoch 3171/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4256 - val_loss: 1.2741 - val_accuracy: 0.4226

Epoch 03171: val_loss did not improve from 1.27242
Epoch 3172/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4254 - val_loss: 1.2744 - val_accuracy: 0.4187

Epoch 03172: val_loss did not improve from 1.27242
Epoch 3173/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4213 - val_loss: 1.2763 - val_accuracy: 0.4250

Epoch 03173: val_loss did not improve from 1.27242
Epoch 3174/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4248 - val_loss: 1.2743 - val_accuracy: 0.4219

Epoch 03174: val_loss did not improve from 1.27242
Epoch 3175/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4254 - val_loss: 1.2757 - val_accuracy: 0.4211

Epoch 03175: val_loss did not improve from 1.27242
Epoch 3176/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4201 - val_loss: 1.2749 - val_accuracy: 0.4258

Epoch 03176: val_loss did not improve from 1.27242
Epoch 3177/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4245 - val_loss: 1.2748 - val_accuracy: 0.4298

Epoch 03177: val_loss did not improve from 1.27242
Epoch 3178/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4240 - val_loss: 1.2730 - val_accuracy: 0.4203

Epoch 03178: val_loss did not improve from 1.27242
Epoch 3179/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4226 - val_loss: 1.2739 - val_accuracy: 0.4203

Epoch 03179: val_loss did not improve from 1.27242
Epoch 3180/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4241 - val_loss: 1.2734 - val_accuracy: 0.4226

Epoch 03180: val_loss did not improve from 1.27242
Epoch 3181/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4241 - val_loss: 1.2801 - val_accuracy: 0.4219

Epoch 03181: val_loss did not improve from 1.27242
Epoch 3182/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4228 - val_loss: 1.2735 - val_accuracy: 0.4179

Epoch 03182: val_loss did not improve from 1.27242
Epoch 3183/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4238 - val_loss: 1.2751 - val_accuracy: 0.4219

Epoch 03183: val_loss did not improve from 1.27242
Epoch 3184/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4269 - val_loss: 1.2775 - val_accuracy: 0.4234

Epoch 03184: val_loss did not improve from 1.27242
Epoch 3185/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4259 - val_loss: 1.2754 - val_accuracy: 0.4274

Epoch 03185: val_loss did not improve from 1.27242
Epoch 3186/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4239 - val_loss: 1.2765 - val_accuracy: 0.4234

Epoch 03186: val_loss did not improve from 1.27242
Epoch 3187/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4220 - val_loss: 1.2767 - val_accuracy: 0.4274

Epoch 03187: val_loss did not improve from 1.27242
Epoch 3188/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4244 - val_loss: 1.2763 - val_accuracy: 0.4219

Epoch 03188: val_loss did not improve from 1.27242
Epoch 3189/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4218 - val_loss: 1.2743 - val_accuracy: 0.4250

Epoch 03189: val_loss did not improve from 1.27242
Epoch 3190/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4252 - val_loss: 1.2761 - val_accuracy: 0.4242

Epoch 03190: val_loss did not improve from 1.27242
Epoch 3191/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4209 - val_loss: 1.2766 - val_accuracy: 0.4290

Epoch 03191: val_loss did not improve from 1.27242
Epoch 3192/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4227 - val_loss: 1.2724 - val_accuracy: 0.4242

Epoch 03192: val_loss improved from 1.27242 to 1.27236, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3193/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4246 - val_loss: 1.2755 - val_accuracy: 0.4250

Epoch 03193: val_loss did not improve from 1.27236
Epoch 3194/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4267 - val_loss: 1.2730 - val_accuracy: 0.4219

Epoch 03194: val_loss did not improve from 1.27236
Epoch 3195/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4241 - val_loss: 1.2729 - val_accuracy: 0.4258

Epoch 03195: val_loss did not improve from 1.27236
Epoch 3196/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4228 - val_loss: 1.2748 - val_accuracy: 0.4179

Epoch 03196: val_loss did not improve from 1.27236
Epoch 3197/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4257 - val_loss: 1.2729 - val_accuracy: 0.4195

Epoch 03197: val_loss did not improve from 1.27236
Epoch 3198/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4226 - val_loss: 1.2766 - val_accuracy: 0.4147

Epoch 03198: val_loss did not improve from 1.27236
Epoch 3199/10000
12/12 - 0s - loss: 1.2700 - accuracy: 0.4240 - val_loss: 1.2744 - val_accuracy: 0.4179

Epoch 03199: val_loss did not improve from 1.27236
Epoch 3200/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4233 - val_loss: 1.2756 - val_accuracy: 0.4258

Epoch 03200: val_loss did not improve from 1.27236
Epoch 3201/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4260 - val_loss: 1.2761 - val_accuracy: 0.4258

Epoch 03201: val_loss did not improve from 1.27236
Epoch 3202/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4264 - val_loss: 1.2731 - val_accuracy: 0.4226

Epoch 03202: val_loss did not improve from 1.27236
Epoch 3203/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4215 - val_loss: 1.2736 - val_accuracy: 0.4274

Epoch 03203: val_loss did not improve from 1.27236
Epoch 3204/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4258 - val_loss: 1.2735 - val_accuracy: 0.4147

Epoch 03204: val_loss did not improve from 1.27236
Epoch 3205/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4270 - val_loss: 1.2740 - val_accuracy: 0.4258

Epoch 03205: val_loss did not improve from 1.27236
Epoch 3206/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4293 - val_loss: 1.2724 - val_accuracy: 0.4274

Epoch 03206: val_loss did not improve from 1.27236
Epoch 3207/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4219 - val_loss: 1.2734 - val_accuracy: 0.4203

Epoch 03207: val_loss did not improve from 1.27236
Epoch 3208/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4249 - val_loss: 1.2790 - val_accuracy: 0.4226

Epoch 03208: val_loss did not improve from 1.27236
Epoch 3209/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4245 - val_loss: 1.2733 - val_accuracy: 0.4203

Epoch 03209: val_loss did not improve from 1.27236
Epoch 3210/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4218 - val_loss: 1.2790 - val_accuracy: 0.4234

Epoch 03210: val_loss did not improve from 1.27236
Epoch 3211/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4238 - val_loss: 1.2799 - val_accuracy: 0.4242

Epoch 03211: val_loss did not improve from 1.27236
Epoch 3212/10000
12/12 - 0s - loss: 1.2759 - accuracy: 0.4192 - val_loss: 1.2737 - val_accuracy: 0.4211

Epoch 03212: val_loss did not improve from 1.27236
Epoch 3213/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4225 - val_loss: 1.2749 - val_accuracy: 0.4282

Epoch 03213: val_loss did not improve from 1.27236
Epoch 3214/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4217 - val_loss: 1.2724 - val_accuracy: 0.4242

Epoch 03214: val_loss did not improve from 1.27236
Epoch 3215/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4210 - val_loss: 1.2768 - val_accuracy: 0.4211

Epoch 03215: val_loss did not improve from 1.27236
Epoch 3216/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4222 - val_loss: 1.2761 - val_accuracy: 0.4282

Epoch 03216: val_loss did not improve from 1.27236
Epoch 3217/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4290 - val_loss: 1.2751 - val_accuracy: 0.4258

Epoch 03217: val_loss did not improve from 1.27236
Epoch 3218/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4232 - val_loss: 1.2736 - val_accuracy: 0.4163

Epoch 03218: val_loss did not improve from 1.27236
Epoch 3219/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4256 - val_loss: 1.2770 - val_accuracy: 0.4274

Epoch 03219: val_loss did not improve from 1.27236
Epoch 3220/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4233 - val_loss: 1.2762 - val_accuracy: 0.4290

Epoch 03220: val_loss did not improve from 1.27236
Epoch 3221/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4221 - val_loss: 1.2760 - val_accuracy: 0.4211

Epoch 03221: val_loss did not improve from 1.27236
Epoch 3222/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4231 - val_loss: 1.2752 - val_accuracy: 0.4163

Epoch 03222: val_loss did not improve from 1.27236
Epoch 3223/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4238 - val_loss: 1.2754 - val_accuracy: 0.4171

Epoch 03223: val_loss did not improve from 1.27236
Epoch 3224/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4195 - val_loss: 1.2778 - val_accuracy: 0.4187

Epoch 03224: val_loss did not improve from 1.27236
Epoch 3225/10000
12/12 - 0s - loss: 1.2744 - accuracy: 0.4214 - val_loss: 1.2752 - val_accuracy: 0.4219

Epoch 03225: val_loss did not improve from 1.27236
Epoch 3226/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4230 - val_loss: 1.2757 - val_accuracy: 0.4250

Epoch 03226: val_loss did not improve from 1.27236
Epoch 3227/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4230 - val_loss: 1.2709 - val_accuracy: 0.4234

Epoch 03227: val_loss improved from 1.27236 to 1.27091, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3228/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4241 - val_loss: 1.2798 - val_accuracy: 0.4322

Epoch 03228: val_loss did not improve from 1.27091
Epoch 3229/10000
12/12 - 0s - loss: 1.2742 - accuracy: 0.4218 - val_loss: 1.2737 - val_accuracy: 0.4258

Epoch 03229: val_loss did not improve from 1.27091
Epoch 3230/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4244 - val_loss: 1.2720 - val_accuracy: 0.4139

Epoch 03230: val_loss did not improve from 1.27091
Epoch 3231/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4271 - val_loss: 1.2740 - val_accuracy: 0.4322

Epoch 03231: val_loss did not improve from 1.27091
Epoch 3232/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4278 - val_loss: 1.2731 - val_accuracy: 0.4234

Epoch 03232: val_loss did not improve from 1.27091
Epoch 3233/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4272 - val_loss: 1.2737 - val_accuracy: 0.4274

Epoch 03233: val_loss did not improve from 1.27091
Epoch 3234/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4246 - val_loss: 1.2778 - val_accuracy: 0.4163

Epoch 03234: val_loss did not improve from 1.27091
Epoch 3235/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4249 - val_loss: 1.2822 - val_accuracy: 0.4219

Epoch 03235: val_loss did not improve from 1.27091
Epoch 3236/10000
12/12 - 0s - loss: 1.2723 - accuracy: 0.4193 - val_loss: 1.2776 - val_accuracy: 0.4226

Epoch 03236: val_loss did not improve from 1.27091
Epoch 3237/10000
12/12 - 0s - loss: 1.2721 - accuracy: 0.4230 - val_loss: 1.2744 - val_accuracy: 0.4155

Epoch 03237: val_loss did not improve from 1.27091
Epoch 3238/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4280 - val_loss: 1.2780 - val_accuracy: 0.4139

Epoch 03238: val_loss did not improve from 1.27091
Epoch 3239/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4241 - val_loss: 1.2733 - val_accuracy: 0.4330

Epoch 03239: val_loss did not improve from 1.27091
Epoch 3240/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4239 - val_loss: 1.2739 - val_accuracy: 0.4187

Epoch 03240: val_loss did not improve from 1.27091
Epoch 3241/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4240 - val_loss: 1.2735 - val_accuracy: 0.4234

Epoch 03241: val_loss did not improve from 1.27091
Epoch 3242/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4296 - val_loss: 1.2748 - val_accuracy: 0.4282

Epoch 03242: val_loss did not improve from 1.27091
Epoch 3243/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4249 - val_loss: 1.2807 - val_accuracy: 0.4203

Epoch 03243: val_loss did not improve from 1.27091
Epoch 3244/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4246 - val_loss: 1.2728 - val_accuracy: 0.4250

Epoch 03244: val_loss did not improve from 1.27091
Epoch 3245/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4254 - val_loss: 1.2738 - val_accuracy: 0.4179

Epoch 03245: val_loss did not improve from 1.27091
Epoch 3246/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4241 - val_loss: 1.2751 - val_accuracy: 0.4155

Epoch 03246: val_loss did not improve from 1.27091
Epoch 3247/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4258 - val_loss: 1.2788 - val_accuracy: 0.4203

Epoch 03247: val_loss did not improve from 1.27091
Epoch 3248/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4236 - val_loss: 1.2725 - val_accuracy: 0.4219

Epoch 03248: val_loss did not improve from 1.27091
Epoch 3249/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4263 - val_loss: 1.2742 - val_accuracy: 0.4258

Epoch 03249: val_loss did not improve from 1.27091
Epoch 3250/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4241 - val_loss: 1.2755 - val_accuracy: 0.4242

Epoch 03250: val_loss did not improve from 1.27091
Epoch 3251/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4234 - val_loss: 1.2781 - val_accuracy: 0.4171

Epoch 03251: val_loss did not improve from 1.27091
Epoch 3252/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4253 - val_loss: 1.2742 - val_accuracy: 0.4266

Epoch 03252: val_loss did not improve from 1.27091
Epoch 3253/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4266 - val_loss: 1.2760 - val_accuracy: 0.4242

Epoch 03253: val_loss did not improve from 1.27091
Epoch 3254/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4239 - val_loss: 1.2810 - val_accuracy: 0.4234

Epoch 03254: val_loss did not improve from 1.27091
Epoch 3255/10000
12/12 - 0s - loss: 1.2692 - accuracy: 0.4265 - val_loss: 1.2844 - val_accuracy: 0.4242

Epoch 03255: val_loss did not improve from 1.27091
Epoch 3256/10000
12/12 - 0s - loss: 1.2782 - accuracy: 0.4211 - val_loss: 1.2766 - val_accuracy: 0.4171

Epoch 03256: val_loss did not improve from 1.27091
Epoch 3257/10000
12/12 - 0s - loss: 1.2816 - accuracy: 0.4172 - val_loss: 1.2819 - val_accuracy: 0.4298

Epoch 03257: val_loss did not improve from 1.27091
Epoch 3258/10000
12/12 - 0s - loss: 1.2738 - accuracy: 0.4248 - val_loss: 1.2731 - val_accuracy: 0.4179

Epoch 03258: val_loss did not improve from 1.27091
Epoch 3259/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4253 - val_loss: 1.2746 - val_accuracy: 0.4219

Epoch 03259: val_loss did not improve from 1.27091
Epoch 3260/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4234 - val_loss: 1.2768 - val_accuracy: 0.4226

Epoch 03260: val_loss did not improve from 1.27091
Epoch 3261/10000
12/12 - 0s - loss: 1.2740 - accuracy: 0.4212 - val_loss: 1.2750 - val_accuracy: 0.4163

Epoch 03261: val_loss did not improve from 1.27091
Epoch 3262/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4226 - val_loss: 1.2719 - val_accuracy: 0.4250

Epoch 03262: val_loss did not improve from 1.27091
Epoch 3263/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4258 - val_loss: 1.2723 - val_accuracy: 0.4195

Epoch 03263: val_loss did not improve from 1.27091
Epoch 3264/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4249 - val_loss: 1.2752 - val_accuracy: 0.4298

Epoch 03264: val_loss did not improve from 1.27091
Epoch 3265/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4272 - val_loss: 1.2732 - val_accuracy: 0.4195

Epoch 03265: val_loss did not improve from 1.27091
Epoch 3266/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4222 - val_loss: 1.2745 - val_accuracy: 0.4266

Epoch 03266: val_loss did not improve from 1.27091
Epoch 3267/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4271 - val_loss: 1.2722 - val_accuracy: 0.4242

Epoch 03267: val_loss did not improve from 1.27091
Epoch 3268/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4271 - val_loss: 1.2740 - val_accuracy: 0.4195

Epoch 03268: val_loss did not improve from 1.27091
Epoch 3269/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4263 - val_loss: 1.2736 - val_accuracy: 0.4274

Epoch 03269: val_loss did not improve from 1.27091
Epoch 3270/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4276 - val_loss: 1.2753 - val_accuracy: 0.4282

Epoch 03270: val_loss did not improve from 1.27091
Epoch 3271/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4237 - val_loss: 1.2753 - val_accuracy: 0.4171

Epoch 03271: val_loss did not improve from 1.27091
Epoch 3272/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4250 - val_loss: 1.2774 - val_accuracy: 0.4219

Epoch 03272: val_loss did not improve from 1.27091
Epoch 3273/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4265 - val_loss: 1.2762 - val_accuracy: 0.4203

Epoch 03273: val_loss did not improve from 1.27091
Epoch 3274/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4220 - val_loss: 1.2818 - val_accuracy: 0.4226

Epoch 03274: val_loss did not improve from 1.27091
Epoch 3275/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4215 - val_loss: 1.2766 - val_accuracy: 0.4282

Epoch 03275: val_loss did not improve from 1.27091
Epoch 3276/10000
12/12 - 0s - loss: 1.2730 - accuracy: 0.4249 - val_loss: 1.2755 - val_accuracy: 0.4274

Epoch 03276: val_loss did not improve from 1.27091
Epoch 3277/10000
12/12 - 0s - loss: 1.2846 - accuracy: 0.4152 - val_loss: 1.2824 - val_accuracy: 0.4250

Epoch 03277: val_loss did not improve from 1.27091
Epoch 3278/10000
12/12 - 0s - loss: 1.2790 - accuracy: 0.4208 - val_loss: 1.2815 - val_accuracy: 0.4250

Epoch 03278: val_loss did not improve from 1.27091
Epoch 3279/10000
12/12 - 0s - loss: 1.2756 - accuracy: 0.4181 - val_loss: 1.2772 - val_accuracy: 0.4250

Epoch 03279: val_loss did not improve from 1.27091
Epoch 3280/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4221 - val_loss: 1.2756 - val_accuracy: 0.4322

Epoch 03280: val_loss did not improve from 1.27091
Epoch 3281/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4237 - val_loss: 1.2717 - val_accuracy: 0.4226

Epoch 03281: val_loss did not improve from 1.27091
Epoch 3282/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4272 - val_loss: 1.2785 - val_accuracy: 0.4242

Epoch 03282: val_loss did not improve from 1.27091
Epoch 3283/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4256 - val_loss: 1.2725 - val_accuracy: 0.4163

Epoch 03283: val_loss did not improve from 1.27091
Epoch 3284/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4278 - val_loss: 1.2727 - val_accuracy: 0.4274

Epoch 03284: val_loss did not improve from 1.27091
Epoch 3285/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4277 - val_loss: 1.2746 - val_accuracy: 0.4211

Epoch 03285: val_loss did not improve from 1.27091
Epoch 3286/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4242 - val_loss: 1.2868 - val_accuracy: 0.4250

Epoch 03286: val_loss did not improve from 1.27091
Epoch 3287/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4247 - val_loss: 1.2719 - val_accuracy: 0.4274

Epoch 03287: val_loss did not improve from 1.27091
Epoch 3288/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4225 - val_loss: 1.2797 - val_accuracy: 0.4234

Epoch 03288: val_loss did not improve from 1.27091
Epoch 3289/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4227 - val_loss: 1.2745 - val_accuracy: 0.4187

Epoch 03289: val_loss did not improve from 1.27091
Epoch 3290/10000
12/12 - 0s - loss: 1.2701 - accuracy: 0.4218 - val_loss: 1.2755 - val_accuracy: 0.4179

Epoch 03290: val_loss did not improve from 1.27091
Epoch 3291/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4264 - val_loss: 1.2726 - val_accuracy: 0.4219

Epoch 03291: val_loss did not improve from 1.27091
Epoch 3292/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4216 - val_loss: 1.2792 - val_accuracy: 0.4155

Epoch 03292: val_loss did not improve from 1.27091
Epoch 3293/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4268 - val_loss: 1.2790 - val_accuracy: 0.4187

Epoch 03293: val_loss did not improve from 1.27091
Epoch 3294/10000
12/12 - 0s - loss: 1.2755 - accuracy: 0.4205 - val_loss: 1.2749 - val_accuracy: 0.4179

Epoch 03294: val_loss did not improve from 1.27091
Epoch 3295/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4236 - val_loss: 1.2722 - val_accuracy: 0.4314

Epoch 03295: val_loss did not improve from 1.27091
Epoch 3296/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4200 - val_loss: 1.2733 - val_accuracy: 0.4203

Epoch 03296: val_loss did not improve from 1.27091
Epoch 3297/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4282 - val_loss: 1.2724 - val_accuracy: 0.4274

Epoch 03297: val_loss did not improve from 1.27091
Epoch 3298/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4276 - val_loss: 1.2731 - val_accuracy: 0.4274

Epoch 03298: val_loss did not improve from 1.27091
Epoch 3299/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4250 - val_loss: 1.2753 - val_accuracy: 0.4211

Epoch 03299: val_loss did not improve from 1.27091
Epoch 3300/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4246 - val_loss: 1.2726 - val_accuracy: 0.4234

Epoch 03300: val_loss did not improve from 1.27091
Epoch 3301/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4271 - val_loss: 1.2722 - val_accuracy: 0.4234

Epoch 03301: val_loss did not improve from 1.27091
Epoch 3302/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4245 - val_loss: 1.2753 - val_accuracy: 0.4211

Epoch 03302: val_loss did not improve from 1.27091
Epoch 3303/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4273 - val_loss: 1.2744 - val_accuracy: 0.4306

Epoch 03303: val_loss did not improve from 1.27091
Epoch 3304/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4256 - val_loss: 1.2733 - val_accuracy: 0.4147

Epoch 03304: val_loss did not improve from 1.27091
Epoch 3305/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4225 - val_loss: 1.2766 - val_accuracy: 0.4234

Epoch 03305: val_loss did not improve from 1.27091
Epoch 3306/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4255 - val_loss: 1.2731 - val_accuracy: 0.4274

Epoch 03306: val_loss did not improve from 1.27091
Epoch 3307/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4275 - val_loss: 1.2744 - val_accuracy: 0.4234

Epoch 03307: val_loss did not improve from 1.27091
Epoch 3308/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4263 - val_loss: 1.2732 - val_accuracy: 0.4298

Epoch 03308: val_loss did not improve from 1.27091
Epoch 3309/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4217 - val_loss: 1.2835 - val_accuracy: 0.4131

Epoch 03309: val_loss did not improve from 1.27091
Epoch 3310/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4208 - val_loss: 1.2828 - val_accuracy: 0.4211

Epoch 03310: val_loss did not improve from 1.27091
Epoch 3311/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4223 - val_loss: 1.2721 - val_accuracy: 0.4250

Epoch 03311: val_loss did not improve from 1.27091
Epoch 3312/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4202 - val_loss: 1.2730 - val_accuracy: 0.4187

Epoch 03312: val_loss did not improve from 1.27091
Epoch 3313/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4249 - val_loss: 1.2712 - val_accuracy: 0.4338

Epoch 03313: val_loss did not improve from 1.27091
Epoch 3314/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4282 - val_loss: 1.2717 - val_accuracy: 0.4306

Epoch 03314: val_loss did not improve from 1.27091
Epoch 3315/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4230 - val_loss: 1.2796 - val_accuracy: 0.4258

Epoch 03315: val_loss did not improve from 1.27091
Epoch 3316/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4251 - val_loss: 1.2741 - val_accuracy: 0.4250

Epoch 03316: val_loss did not improve from 1.27091
Epoch 3317/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4264 - val_loss: 1.2738 - val_accuracy: 0.4171

Epoch 03317: val_loss did not improve from 1.27091
Epoch 3318/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4258 - val_loss: 1.2737 - val_accuracy: 0.4250

Epoch 03318: val_loss did not improve from 1.27091
Epoch 3319/10000
12/12 - 0s - loss: 1.2743 - accuracy: 0.4202 - val_loss: 1.2725 - val_accuracy: 0.4171

Epoch 03319: val_loss did not improve from 1.27091
Epoch 3320/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4228 - val_loss: 1.2740 - val_accuracy: 0.4226

Epoch 03320: val_loss did not improve from 1.27091
Epoch 3321/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4259 - val_loss: 1.2732 - val_accuracy: 0.4282

Epoch 03321: val_loss did not improve from 1.27091
Epoch 3322/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4267 - val_loss: 1.2709 - val_accuracy: 0.4242

Epoch 03322: val_loss did not improve from 1.27091
Epoch 3323/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4224 - val_loss: 1.2718 - val_accuracy: 0.4219

Epoch 03323: val_loss did not improve from 1.27091
Epoch 3324/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4249 - val_loss: 1.2818 - val_accuracy: 0.4234

Epoch 03324: val_loss did not improve from 1.27091
Epoch 3325/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4264 - val_loss: 1.2753 - val_accuracy: 0.4242

Epoch 03325: val_loss did not improve from 1.27091
Epoch 3326/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4234 - val_loss: 1.2717 - val_accuracy: 0.4226

Epoch 03326: val_loss did not improve from 1.27091
Epoch 3327/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4273 - val_loss: 1.2733 - val_accuracy: 0.4226

Epoch 03327: val_loss did not improve from 1.27091
Epoch 3328/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4257 - val_loss: 1.2718 - val_accuracy: 0.4242

Epoch 03328: val_loss did not improve from 1.27091
Epoch 3329/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4218 - val_loss: 1.2756 - val_accuracy: 0.4131

Epoch 03329: val_loss did not improve from 1.27091
Epoch 3330/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4235 - val_loss: 1.2717 - val_accuracy: 0.4195

Epoch 03330: val_loss did not improve from 1.27091
Epoch 3331/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4264 - val_loss: 1.2720 - val_accuracy: 0.4219

Epoch 03331: val_loss did not improve from 1.27091
Epoch 3332/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4295 - val_loss: 1.2731 - val_accuracy: 0.4203

Epoch 03332: val_loss did not improve from 1.27091
Epoch 3333/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4267 - val_loss: 1.2820 - val_accuracy: 0.4139

Epoch 03333: val_loss did not improve from 1.27091
Epoch 3334/10000
12/12 - 0s - loss: 1.2808 - accuracy: 0.4142 - val_loss: 1.2730 - val_accuracy: 0.4195

Epoch 03334: val_loss did not improve from 1.27091
Epoch 3335/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4200 - val_loss: 1.2746 - val_accuracy: 0.4171

Epoch 03335: val_loss did not improve from 1.27091
Epoch 3336/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4265 - val_loss: 1.2743 - val_accuracy: 0.4203

Epoch 03336: val_loss did not improve from 1.27091
Epoch 3337/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4232 - val_loss: 1.2748 - val_accuracy: 0.4155

Epoch 03337: val_loss did not improve from 1.27091
Epoch 3338/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4267 - val_loss: 1.2735 - val_accuracy: 0.4298

Epoch 03338: val_loss did not improve from 1.27091
Epoch 3339/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4262 - val_loss: 1.2724 - val_accuracy: 0.4250

Epoch 03339: val_loss did not improve from 1.27091
Epoch 3340/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4261 - val_loss: 1.2734 - val_accuracy: 0.4187

Epoch 03340: val_loss did not improve from 1.27091
Epoch 3341/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4270 - val_loss: 1.2710 - val_accuracy: 0.4219

Epoch 03341: val_loss did not improve from 1.27091
Epoch 3342/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4270 - val_loss: 1.2761 - val_accuracy: 0.4219

Epoch 03342: val_loss did not improve from 1.27091
Epoch 3343/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4251 - val_loss: 1.2724 - val_accuracy: 0.4195

Epoch 03343: val_loss did not improve from 1.27091
Epoch 3344/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4261 - val_loss: 1.2721 - val_accuracy: 0.4234

Epoch 03344: val_loss did not improve from 1.27091
Epoch 3345/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4231 - val_loss: 1.2756 - val_accuracy: 0.4179

Epoch 03345: val_loss did not improve from 1.27091
Epoch 3346/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4256 - val_loss: 1.2711 - val_accuracy: 0.4226

Epoch 03346: val_loss did not improve from 1.27091
Epoch 3347/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4234 - val_loss: 1.2749 - val_accuracy: 0.4219

Epoch 03347: val_loss did not improve from 1.27091
Epoch 3348/10000
12/12 - 0s - loss: 1.2679 - accuracy: 0.4251 - val_loss: 1.2779 - val_accuracy: 0.4234

Epoch 03348: val_loss did not improve from 1.27091
Epoch 3349/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4225 - val_loss: 1.2715 - val_accuracy: 0.4290

Epoch 03349: val_loss did not improve from 1.27091
Epoch 3350/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4267 - val_loss: 1.2734 - val_accuracy: 0.4195

Epoch 03350: val_loss did not improve from 1.27091
Epoch 3351/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4247 - val_loss: 1.2734 - val_accuracy: 0.4258

Epoch 03351: val_loss did not improve from 1.27091
Epoch 3352/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4256 - val_loss: 1.2742 - val_accuracy: 0.4234

Epoch 03352: val_loss did not improve from 1.27091
Epoch 3353/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4261 - val_loss: 1.2749 - val_accuracy: 0.4211

Epoch 03353: val_loss did not improve from 1.27091
Epoch 3354/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4285 - val_loss: 1.2741 - val_accuracy: 0.4282

Epoch 03354: val_loss did not improve from 1.27091
Epoch 3355/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4273 - val_loss: 1.2759 - val_accuracy: 0.4147

Epoch 03355: val_loss did not improve from 1.27091
Epoch 3356/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4211 - val_loss: 1.2788 - val_accuracy: 0.4234

Epoch 03356: val_loss did not improve from 1.27091
Epoch 3357/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4241 - val_loss: 1.2753 - val_accuracy: 0.4250

Epoch 03357: val_loss did not improve from 1.27091
Epoch 3358/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4252 - val_loss: 1.2738 - val_accuracy: 0.4242

Epoch 03358: val_loss did not improve from 1.27091
Epoch 3359/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4261 - val_loss: 1.2763 - val_accuracy: 0.4179

Epoch 03359: val_loss did not improve from 1.27091
Epoch 3360/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4262 - val_loss: 1.2704 - val_accuracy: 0.4282

Epoch 03360: val_loss improved from 1.27091 to 1.27044, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3361/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4255 - val_loss: 1.2716 - val_accuracy: 0.4195

Epoch 03361: val_loss did not improve from 1.27044
Epoch 3362/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4268 - val_loss: 1.2771 - val_accuracy: 0.4203

Epoch 03362: val_loss did not improve from 1.27044
Epoch 3363/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4276 - val_loss: 1.2702 - val_accuracy: 0.4282

Epoch 03363: val_loss improved from 1.27044 to 1.27022, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3364/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4286 - val_loss: 1.2724 - val_accuracy: 0.4179

Epoch 03364: val_loss did not improve from 1.27022
Epoch 3365/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4249 - val_loss: 1.2721 - val_accuracy: 0.4195

Epoch 03365: val_loss did not improve from 1.27022
Epoch 3366/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4254 - val_loss: 1.2764 - val_accuracy: 0.4211

Epoch 03366: val_loss did not improve from 1.27022
Epoch 3367/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4276 - val_loss: 1.2742 - val_accuracy: 0.4179

Epoch 03367: val_loss did not improve from 1.27022
Epoch 3368/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4262 - val_loss: 1.2738 - val_accuracy: 0.4203

Epoch 03368: val_loss did not improve from 1.27022
Epoch 3369/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4194 - val_loss: 1.2815 - val_accuracy: 0.4219

Epoch 03369: val_loss did not improve from 1.27022
Epoch 3370/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4249 - val_loss: 1.2700 - val_accuracy: 0.4226

Epoch 03370: val_loss improved from 1.27022 to 1.27004, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3371/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4249 - val_loss: 1.2762 - val_accuracy: 0.4322

Epoch 03371: val_loss did not improve from 1.27004
Epoch 3372/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4273 - val_loss: 1.2730 - val_accuracy: 0.4274

Epoch 03372: val_loss did not improve from 1.27004
Epoch 3373/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4255 - val_loss: 1.2743 - val_accuracy: 0.4250

Epoch 03373: val_loss did not improve from 1.27004
Epoch 3374/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4245 - val_loss: 1.2718 - val_accuracy: 0.4083

Epoch 03374: val_loss did not improve from 1.27004
Epoch 3375/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4238 - val_loss: 1.2752 - val_accuracy: 0.4139

Epoch 03375: val_loss did not improve from 1.27004
Epoch 3376/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4228 - val_loss: 1.2787 - val_accuracy: 0.4354

Epoch 03376: val_loss did not improve from 1.27004
Epoch 3377/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4225 - val_loss: 1.2729 - val_accuracy: 0.4219

Epoch 03377: val_loss did not improve from 1.27004
Epoch 3378/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4262 - val_loss: 1.2714 - val_accuracy: 0.4195

Epoch 03378: val_loss did not improve from 1.27004
Epoch 3379/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4285 - val_loss: 1.2792 - val_accuracy: 0.4306

Epoch 03379: val_loss did not improve from 1.27004
Epoch 3380/10000
12/12 - 0s - loss: 1.2731 - accuracy: 0.4187 - val_loss: 1.2718 - val_accuracy: 0.4242

Epoch 03380: val_loss did not improve from 1.27004
Epoch 3381/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4282 - val_loss: 1.2727 - val_accuracy: 0.4179

Epoch 03381: val_loss did not improve from 1.27004
Epoch 3382/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4286 - val_loss: 1.2718 - val_accuracy: 0.4131

Epoch 03382: val_loss did not improve from 1.27004
Epoch 3383/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4256 - val_loss: 1.2764 - val_accuracy: 0.4354

Epoch 03383: val_loss did not improve from 1.27004
Epoch 3384/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4269 - val_loss: 1.2718 - val_accuracy: 0.4282

Epoch 03384: val_loss did not improve from 1.27004
Epoch 3385/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4248 - val_loss: 1.2748 - val_accuracy: 0.4330

Epoch 03385: val_loss did not improve from 1.27004
Epoch 3386/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4241 - val_loss: 1.2712 - val_accuracy: 0.4187

Epoch 03386: val_loss did not improve from 1.27004
Epoch 3387/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4247 - val_loss: 1.2717 - val_accuracy: 0.4242

Epoch 03387: val_loss did not improve from 1.27004
Epoch 3388/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4250 - val_loss: 1.2716 - val_accuracy: 0.4203

Epoch 03388: val_loss did not improve from 1.27004
Epoch 3389/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4261 - val_loss: 1.2721 - val_accuracy: 0.4219

Epoch 03389: val_loss did not improve from 1.27004
Epoch 3390/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4264 - val_loss: 1.2738 - val_accuracy: 0.4282

Epoch 03390: val_loss did not improve from 1.27004
Epoch 3391/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4272 - val_loss: 1.2771 - val_accuracy: 0.4282

Epoch 03391: val_loss did not improve from 1.27004
Epoch 3392/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4249 - val_loss: 1.2728 - val_accuracy: 0.4226

Epoch 03392: val_loss did not improve from 1.27004
Epoch 3393/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4239 - val_loss: 1.2742 - val_accuracy: 0.4203

Epoch 03393: val_loss did not improve from 1.27004
Epoch 3394/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4251 - val_loss: 1.2703 - val_accuracy: 0.4219

Epoch 03394: val_loss did not improve from 1.27004
Epoch 3395/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4244 - val_loss: 1.2724 - val_accuracy: 0.4155

Epoch 03395: val_loss did not improve from 1.27004
Epoch 3396/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4265 - val_loss: 1.2707 - val_accuracy: 0.4195

Epoch 03396: val_loss did not improve from 1.27004
Epoch 3397/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4268 - val_loss: 1.2712 - val_accuracy: 0.4282

Epoch 03397: val_loss did not improve from 1.27004
Epoch 3398/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4221 - val_loss: 1.2790 - val_accuracy: 0.4195

Epoch 03398: val_loss did not improve from 1.27004
Epoch 3399/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4240 - val_loss: 1.2719 - val_accuracy: 0.4266

Epoch 03399: val_loss did not improve from 1.27004
Epoch 3400/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4256 - val_loss: 1.2732 - val_accuracy: 0.4187

Epoch 03400: val_loss did not improve from 1.27004
Epoch 3401/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4244 - val_loss: 1.2731 - val_accuracy: 0.4258

Epoch 03401: val_loss did not improve from 1.27004
Epoch 3402/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4256 - val_loss: 1.2699 - val_accuracy: 0.4219

Epoch 03402: val_loss improved from 1.27004 to 1.26994, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3403/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4275 - val_loss: 1.2707 - val_accuracy: 0.4258

Epoch 03403: val_loss did not improve from 1.26994
Epoch 3404/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4230 - val_loss: 1.2711 - val_accuracy: 0.4211

Epoch 03404: val_loss did not improve from 1.26994
Epoch 3405/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4268 - val_loss: 1.2716 - val_accuracy: 0.4298

Epoch 03405: val_loss did not improve from 1.26994
Epoch 3406/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4257 - val_loss: 1.2707 - val_accuracy: 0.4242

Epoch 03406: val_loss did not improve from 1.26994
Epoch 3407/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4225 - val_loss: 1.2703 - val_accuracy: 0.4115

Epoch 03407: val_loss did not improve from 1.26994
Epoch 3408/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4216 - val_loss: 1.2741 - val_accuracy: 0.4147

Epoch 03408: val_loss did not improve from 1.26994
Epoch 3409/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4242 - val_loss: 1.2730 - val_accuracy: 0.4226

Epoch 03409: val_loss did not improve from 1.26994
Epoch 3410/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4278 - val_loss: 1.2708 - val_accuracy: 0.4211

Epoch 03410: val_loss did not improve from 1.26994
Epoch 3411/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4226 - val_loss: 1.2742 - val_accuracy: 0.4171

Epoch 03411: val_loss did not improve from 1.26994
Epoch 3412/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4239 - val_loss: 1.2711 - val_accuracy: 0.4195

Epoch 03412: val_loss did not improve from 1.26994
Epoch 3413/10000
12/12 - 0s - loss: 1.2753 - accuracy: 0.4212 - val_loss: 1.2782 - val_accuracy: 0.4274

Epoch 03413: val_loss did not improve from 1.26994
Epoch 3414/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4238 - val_loss: 1.2766 - val_accuracy: 0.4195

Epoch 03414: val_loss did not improve from 1.26994
Epoch 3415/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4237 - val_loss: 1.2706 - val_accuracy: 0.4242

Epoch 03415: val_loss did not improve from 1.26994
Epoch 3416/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4243 - val_loss: 1.2829 - val_accuracy: 0.4258

Epoch 03416: val_loss did not improve from 1.26994
Epoch 3417/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4256 - val_loss: 1.2726 - val_accuracy: 0.4234

Epoch 03417: val_loss did not improve from 1.26994
Epoch 3418/10000
12/12 - 0s - loss: 1.2698 - accuracy: 0.4235 - val_loss: 1.2756 - val_accuracy: 0.4266

Epoch 03418: val_loss did not improve from 1.26994
Epoch 3419/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4200 - val_loss: 1.2732 - val_accuracy: 0.4242

Epoch 03419: val_loss did not improve from 1.26994
Epoch 3420/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4270 - val_loss: 1.2702 - val_accuracy: 0.4242

Epoch 03420: val_loss did not improve from 1.26994
Epoch 3421/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4246 - val_loss: 1.2789 - val_accuracy: 0.4362

Epoch 03421: val_loss did not improve from 1.26994
Epoch 3422/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4243 - val_loss: 1.2721 - val_accuracy: 0.4155

Epoch 03422: val_loss did not improve from 1.26994
Epoch 3423/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4258 - val_loss: 1.2708 - val_accuracy: 0.4226

Epoch 03423: val_loss did not improve from 1.26994
Epoch 3424/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4266 - val_loss: 1.2798 - val_accuracy: 0.4163

Epoch 03424: val_loss did not improve from 1.26994
Epoch 3425/10000
12/12 - 0s - loss: 1.2714 - accuracy: 0.4223 - val_loss: 1.2704 - val_accuracy: 0.4187

Epoch 03425: val_loss did not improve from 1.26994
Epoch 3426/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4232 - val_loss: 1.2738 - val_accuracy: 0.4274

Epoch 03426: val_loss did not improve from 1.26994
Epoch 3427/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4280 - val_loss: 1.2822 - val_accuracy: 0.4187

Epoch 03427: val_loss did not improve from 1.26994
Epoch 3428/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4267 - val_loss: 1.2732 - val_accuracy: 0.4203

Epoch 03428: val_loss did not improve from 1.26994
Epoch 3429/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4238 - val_loss: 1.2749 - val_accuracy: 0.4266

Epoch 03429: val_loss did not improve from 1.26994
Epoch 3430/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4241 - val_loss: 1.2771 - val_accuracy: 0.4179

Epoch 03430: val_loss did not improve from 1.26994
Epoch 3431/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4216 - val_loss: 1.2781 - val_accuracy: 0.4274

Epoch 03431: val_loss did not improve from 1.26994
Epoch 3432/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4223 - val_loss: 1.2706 - val_accuracy: 0.4274

Epoch 03432: val_loss did not improve from 1.26994
Epoch 3433/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4249 - val_loss: 1.2748 - val_accuracy: 0.4258

Epoch 03433: val_loss did not improve from 1.26994
Epoch 3434/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4256 - val_loss: 1.2703 - val_accuracy: 0.4282

Epoch 03434: val_loss did not improve from 1.26994
Epoch 3435/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4245 - val_loss: 1.2714 - val_accuracy: 0.4242

Epoch 03435: val_loss did not improve from 1.26994
Epoch 3436/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4248 - val_loss: 1.2763 - val_accuracy: 0.4266

Epoch 03436: val_loss did not improve from 1.26994
Epoch 3437/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4264 - val_loss: 1.2742 - val_accuracy: 0.4250

Epoch 03437: val_loss did not improve from 1.26994
Epoch 3438/10000
12/12 - 0s - loss: 1.2699 - accuracy: 0.4262 - val_loss: 1.2789 - val_accuracy: 0.4203

Epoch 03438: val_loss did not improve from 1.26994
Epoch 3439/10000
12/12 - 0s - loss: 1.2695 - accuracy: 0.4196 - val_loss: 1.2753 - val_accuracy: 0.4234

Epoch 03439: val_loss did not improve from 1.26994
Epoch 3440/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4255 - val_loss: 1.2756 - val_accuracy: 0.4242

Epoch 03440: val_loss did not improve from 1.26994
Epoch 3441/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4234 - val_loss: 1.2732 - val_accuracy: 0.4242

Epoch 03441: val_loss did not improve from 1.26994
Epoch 3442/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4264 - val_loss: 1.2740 - val_accuracy: 0.4282

Epoch 03442: val_loss did not improve from 1.26994
Epoch 3443/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4259 - val_loss: 1.2714 - val_accuracy: 0.4242

Epoch 03443: val_loss did not improve from 1.26994
Epoch 3444/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4245 - val_loss: 1.2733 - val_accuracy: 0.4242

Epoch 03444: val_loss did not improve from 1.26994
Epoch 3445/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4238 - val_loss: 1.2742 - val_accuracy: 0.4195

Epoch 03445: val_loss did not improve from 1.26994
Epoch 3446/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4267 - val_loss: 1.2740 - val_accuracy: 0.4266

Epoch 03446: val_loss did not improve from 1.26994
Epoch 3447/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4286 - val_loss: 1.2719 - val_accuracy: 0.4211

Epoch 03447: val_loss did not improve from 1.26994
Epoch 3448/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4222 - val_loss: 1.2733 - val_accuracy: 0.4179

Epoch 03448: val_loss did not improve from 1.26994
Epoch 3449/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4263 - val_loss: 1.2714 - val_accuracy: 0.4242

Epoch 03449: val_loss did not improve from 1.26994
Epoch 3450/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4287 - val_loss: 1.2705 - val_accuracy: 0.4203

Epoch 03450: val_loss did not improve from 1.26994
Epoch 3451/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4257 - val_loss: 1.2728 - val_accuracy: 0.4171

Epoch 03451: val_loss did not improve from 1.26994
Epoch 3452/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4293 - val_loss: 1.2705 - val_accuracy: 0.4282

Epoch 03452: val_loss did not improve from 1.26994
Epoch 3453/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4268 - val_loss: 1.2748 - val_accuracy: 0.4250

Epoch 03453: val_loss did not improve from 1.26994
Epoch 3454/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4267 - val_loss: 1.2736 - val_accuracy: 0.4250

Epoch 03454: val_loss did not improve from 1.26994
Epoch 3455/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4249 - val_loss: 1.2735 - val_accuracy: 0.4147

Epoch 03455: val_loss did not improve from 1.26994
Epoch 3456/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4225 - val_loss: 1.2719 - val_accuracy: 0.4219

Epoch 03456: val_loss did not improve from 1.26994
Epoch 3457/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4250 - val_loss: 1.2749 - val_accuracy: 0.4298

Epoch 03457: val_loss did not improve from 1.26994
Epoch 3458/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4277 - val_loss: 1.2719 - val_accuracy: 0.4242

Epoch 03458: val_loss did not improve from 1.26994
Epoch 3459/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4271 - val_loss: 1.2777 - val_accuracy: 0.4258

Epoch 03459: val_loss did not improve from 1.26994
Epoch 3460/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4240 - val_loss: 1.2711 - val_accuracy: 0.4234

Epoch 03460: val_loss did not improve from 1.26994
Epoch 3461/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4286 - val_loss: 1.2709 - val_accuracy: 0.4282

Epoch 03461: val_loss did not improve from 1.26994
Epoch 3462/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4272 - val_loss: 1.2698 - val_accuracy: 0.4266

Epoch 03462: val_loss improved from 1.26994 to 1.26983, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3463/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4275 - val_loss: 1.2751 - val_accuracy: 0.4258

Epoch 03463: val_loss did not improve from 1.26983
Epoch 3464/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4274 - val_loss: 1.2713 - val_accuracy: 0.4266

Epoch 03464: val_loss did not improve from 1.26983
Epoch 3465/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4242 - val_loss: 1.2692 - val_accuracy: 0.4179

Epoch 03465: val_loss improved from 1.26983 to 1.26917, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3466/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4262 - val_loss: 1.2708 - val_accuracy: 0.4234

Epoch 03466: val_loss did not improve from 1.26917
Epoch 3467/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4246 - val_loss: 1.2742 - val_accuracy: 0.4266

Epoch 03467: val_loss did not improve from 1.26917
Epoch 3468/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4233 - val_loss: 1.2755 - val_accuracy: 0.4234

Epoch 03468: val_loss did not improve from 1.26917
Epoch 3469/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4290 - val_loss: 1.2701 - val_accuracy: 0.4211

Epoch 03469: val_loss did not improve from 1.26917
Epoch 3470/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4237 - val_loss: 1.2740 - val_accuracy: 0.4139

Epoch 03470: val_loss did not improve from 1.26917
Epoch 3471/10000
12/12 - 0s - loss: 1.2703 - accuracy: 0.4209 - val_loss: 1.2688 - val_accuracy: 0.4290

Epoch 03471: val_loss improved from 1.26917 to 1.26882, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3472/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4229 - val_loss: 1.2704 - val_accuracy: 0.4219

Epoch 03472: val_loss did not improve from 1.26882
Epoch 3473/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4245 - val_loss: 1.2720 - val_accuracy: 0.4250

Epoch 03473: val_loss did not improve from 1.26882
Epoch 3474/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4278 - val_loss: 1.2713 - val_accuracy: 0.4306

Epoch 03474: val_loss did not improve from 1.26882
Epoch 3475/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4246 - val_loss: 1.2714 - val_accuracy: 0.4298

Epoch 03475: val_loss did not improve from 1.26882
Epoch 3476/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4258 - val_loss: 1.2695 - val_accuracy: 0.4226

Epoch 03476: val_loss did not improve from 1.26882
Epoch 3477/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4285 - val_loss: 1.2723 - val_accuracy: 0.4346

Epoch 03477: val_loss did not improve from 1.26882
Epoch 3478/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4272 - val_loss: 1.2740 - val_accuracy: 0.4250

Epoch 03478: val_loss did not improve from 1.26882
Epoch 3479/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4260 - val_loss: 1.2723 - val_accuracy: 0.4234

Epoch 03479: val_loss did not improve from 1.26882
Epoch 3480/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4234 - val_loss: 1.2712 - val_accuracy: 0.4330

Epoch 03480: val_loss did not improve from 1.26882
Epoch 3481/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4281 - val_loss: 1.2711 - val_accuracy: 0.4242

Epoch 03481: val_loss did not improve from 1.26882
Epoch 3482/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4256 - val_loss: 1.2699 - val_accuracy: 0.4242

Epoch 03482: val_loss did not improve from 1.26882
Epoch 3483/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4242 - val_loss: 1.2717 - val_accuracy: 0.4226

Epoch 03483: val_loss did not improve from 1.26882
Epoch 3484/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4270 - val_loss: 1.2684 - val_accuracy: 0.4258

Epoch 03484: val_loss improved from 1.26882 to 1.26843, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3485/10000
12/12 - 0s - loss: 1.2685 - accuracy: 0.4249 - val_loss: 1.2703 - val_accuracy: 0.4258

Epoch 03485: val_loss did not improve from 1.26843
Epoch 3486/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4268 - val_loss: 1.2719 - val_accuracy: 0.4242

Epoch 03486: val_loss did not improve from 1.26843
Epoch 3487/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4251 - val_loss: 1.2728 - val_accuracy: 0.4187

Epoch 03487: val_loss did not improve from 1.26843
Epoch 3488/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4256 - val_loss: 1.2698 - val_accuracy: 0.4179

Epoch 03488: val_loss did not improve from 1.26843
Epoch 3489/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4249 - val_loss: 1.2700 - val_accuracy: 0.4242

Epoch 03489: val_loss did not improve from 1.26843
Epoch 3490/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4272 - val_loss: 1.2714 - val_accuracy: 0.4155

Epoch 03490: val_loss did not improve from 1.26843
Epoch 3491/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4264 - val_loss: 1.2739 - val_accuracy: 0.4306

Epoch 03491: val_loss did not improve from 1.26843
Epoch 3492/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4260 - val_loss: 1.2703 - val_accuracy: 0.4226

Epoch 03492: val_loss did not improve from 1.26843
Epoch 3493/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4280 - val_loss: 1.2696 - val_accuracy: 0.4226

Epoch 03493: val_loss did not improve from 1.26843
Epoch 3494/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4259 - val_loss: 1.2720 - val_accuracy: 0.4139

Epoch 03494: val_loss did not improve from 1.26843
Epoch 3495/10000
12/12 - 0s - loss: 1.2712 - accuracy: 0.4280 - val_loss: 1.2828 - val_accuracy: 0.4242

Epoch 03495: val_loss did not improve from 1.26843
Epoch 3496/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4249 - val_loss: 1.2711 - val_accuracy: 0.4234

Epoch 03496: val_loss did not improve from 1.26843
Epoch 3497/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4262 - val_loss: 1.2712 - val_accuracy: 0.4290

Epoch 03497: val_loss did not improve from 1.26843
Epoch 3498/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4259 - val_loss: 1.2717 - val_accuracy: 0.4155

Epoch 03498: val_loss did not improve from 1.26843
Epoch 3499/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4251 - val_loss: 1.2723 - val_accuracy: 0.4282

Epoch 03499: val_loss did not improve from 1.26843
Epoch 3500/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4288 - val_loss: 1.2714 - val_accuracy: 0.4195

Epoch 03500: val_loss did not improve from 1.26843
Epoch 3501/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4208 - val_loss: 1.2733 - val_accuracy: 0.4226

Epoch 03501: val_loss did not improve from 1.26843
Epoch 3502/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4282 - val_loss: 1.2704 - val_accuracy: 0.4226

Epoch 03502: val_loss did not improve from 1.26843
Epoch 3503/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4249 - val_loss: 1.2708 - val_accuracy: 0.4250

Epoch 03503: val_loss did not improve from 1.26843
Epoch 3504/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4260 - val_loss: 1.2719 - val_accuracy: 0.4171

Epoch 03504: val_loss did not improve from 1.26843
Epoch 3505/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4265 - val_loss: 1.2703 - val_accuracy: 0.4306

Epoch 03505: val_loss did not improve from 1.26843
Epoch 3506/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4281 - val_loss: 1.2755 - val_accuracy: 0.4234

Epoch 03506: val_loss did not improve from 1.26843
Epoch 3507/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4249 - val_loss: 1.2706 - val_accuracy: 0.4274

Epoch 03507: val_loss did not improve from 1.26843
Epoch 3508/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4273 - val_loss: 1.2713 - val_accuracy: 0.4187

Epoch 03508: val_loss did not improve from 1.26843
Epoch 3509/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4248 - val_loss: 1.2719 - val_accuracy: 0.4226

Epoch 03509: val_loss did not improve from 1.26843
Epoch 3510/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4240 - val_loss: 1.2899 - val_accuracy: 0.4203

Epoch 03510: val_loss did not improve from 1.26843
Epoch 3511/10000
12/12 - 0s - loss: 1.2702 - accuracy: 0.4203 - val_loss: 1.2704 - val_accuracy: 0.4282

Epoch 03511: val_loss did not improve from 1.26843
Epoch 3512/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4232 - val_loss: 1.2711 - val_accuracy: 0.4258

Epoch 03512: val_loss did not improve from 1.26843
Epoch 3513/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4283 - val_loss: 1.2748 - val_accuracy: 0.4242

Epoch 03513: val_loss did not improve from 1.26843
Epoch 3514/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4269 - val_loss: 1.2708 - val_accuracy: 0.4282

Epoch 03514: val_loss did not improve from 1.26843
Epoch 3515/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4282 - val_loss: 1.2707 - val_accuracy: 0.4242

Epoch 03515: val_loss did not improve from 1.26843
Epoch 3516/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4278 - val_loss: 1.2782 - val_accuracy: 0.4306

Epoch 03516: val_loss did not improve from 1.26843
Epoch 3517/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4264 - val_loss: 1.2696 - val_accuracy: 0.4219

Epoch 03517: val_loss did not improve from 1.26843
Epoch 3518/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4278 - val_loss: 1.2706 - val_accuracy: 0.4226

Epoch 03518: val_loss did not improve from 1.26843
Epoch 3519/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4273 - val_loss: 1.2711 - val_accuracy: 0.4211

Epoch 03519: val_loss did not improve from 1.26843
Epoch 3520/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4247 - val_loss: 1.2710 - val_accuracy: 0.4322

Epoch 03520: val_loss did not improve from 1.26843
Epoch 3521/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4286 - val_loss: 1.2714 - val_accuracy: 0.4179

Epoch 03521: val_loss did not improve from 1.26843
Epoch 3522/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4230 - val_loss: 1.2713 - val_accuracy: 0.4179

Epoch 03522: val_loss did not improve from 1.26843
Epoch 3523/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4259 - val_loss: 1.2710 - val_accuracy: 0.4266

Epoch 03523: val_loss did not improve from 1.26843
Epoch 3524/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4260 - val_loss: 1.2710 - val_accuracy: 0.4226

Epoch 03524: val_loss did not improve from 1.26843
Epoch 3525/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4275 - val_loss: 1.2732 - val_accuracy: 0.4203

Epoch 03525: val_loss did not improve from 1.26843
Epoch 3526/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4261 - val_loss: 1.2774 - val_accuracy: 0.4242

Epoch 03526: val_loss did not improve from 1.26843
Epoch 3527/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4253 - val_loss: 1.2714 - val_accuracy: 0.4187

Epoch 03527: val_loss did not improve from 1.26843
Epoch 3528/10000
12/12 - 0s - loss: 1.2696 - accuracy: 0.4209 - val_loss: 1.2721 - val_accuracy: 0.4187

Epoch 03528: val_loss did not improve from 1.26843
Epoch 3529/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4264 - val_loss: 1.2701 - val_accuracy: 0.4171

Epoch 03529: val_loss did not improve from 1.26843
Epoch 3530/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4272 - val_loss: 1.2713 - val_accuracy: 0.4226

Epoch 03530: val_loss did not improve from 1.26843
Epoch 3531/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4298 - val_loss: 1.2710 - val_accuracy: 0.4298

Epoch 03531: val_loss did not improve from 1.26843
Epoch 3532/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4251 - val_loss: 1.2712 - val_accuracy: 0.4163

Epoch 03532: val_loss did not improve from 1.26843
Epoch 3533/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4281 - val_loss: 1.2696 - val_accuracy: 0.4179

Epoch 03533: val_loss did not improve from 1.26843
Epoch 3534/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4276 - val_loss: 1.2698 - val_accuracy: 0.4187

Epoch 03534: val_loss did not improve from 1.26843
Epoch 3535/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4288 - val_loss: 1.2739 - val_accuracy: 0.4226

Epoch 03535: val_loss did not improve from 1.26843
Epoch 3536/10000
12/12 - 0s - loss: 1.2726 - accuracy: 0.4176 - val_loss: 1.2740 - val_accuracy: 0.4266

Epoch 03536: val_loss did not improve from 1.26843
Epoch 3537/10000
12/12 - 0s - loss: 1.2720 - accuracy: 0.4262 - val_loss: 1.2820 - val_accuracy: 0.4322

Epoch 03537: val_loss did not improve from 1.26843
Epoch 3538/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4273 - val_loss: 1.2801 - val_accuracy: 0.4290

Epoch 03538: val_loss did not improve from 1.26843
Epoch 3539/10000
12/12 - 0s - loss: 1.2709 - accuracy: 0.4225 - val_loss: 1.2698 - val_accuracy: 0.4219

Epoch 03539: val_loss did not improve from 1.26843
Epoch 3540/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4302 - val_loss: 1.2755 - val_accuracy: 0.4219

Epoch 03540: val_loss did not improve from 1.26843
Epoch 3541/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4281 - val_loss: 1.2716 - val_accuracy: 0.4290

Epoch 03541: val_loss did not improve from 1.26843
Epoch 3542/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4300 - val_loss: 1.2714 - val_accuracy: 0.4219

Epoch 03542: val_loss did not improve from 1.26843
Epoch 3543/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4276 - val_loss: 1.2732 - val_accuracy: 0.4274

Epoch 03543: val_loss did not improve from 1.26843
Epoch 3544/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4277 - val_loss: 1.2717 - val_accuracy: 0.4123

Epoch 03544: val_loss did not improve from 1.26843
Epoch 3545/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4246 - val_loss: 1.2734 - val_accuracy: 0.4234

Epoch 03545: val_loss did not improve from 1.26843
Epoch 3546/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4263 - val_loss: 1.2749 - val_accuracy: 0.4330

Epoch 03546: val_loss did not improve from 1.26843
Epoch 3547/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4277 - val_loss: 1.2700 - val_accuracy: 0.4187

Epoch 03547: val_loss did not improve from 1.26843
Epoch 3548/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4275 - val_loss: 1.2702 - val_accuracy: 0.4242

Epoch 03548: val_loss did not improve from 1.26843
Epoch 3549/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4283 - val_loss: 1.2709 - val_accuracy: 0.4306

Epoch 03549: val_loss did not improve from 1.26843
Epoch 3550/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4292 - val_loss: 1.2720 - val_accuracy: 0.4226

Epoch 03550: val_loss did not improve from 1.26843
Epoch 3551/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4291 - val_loss: 1.2732 - val_accuracy: 0.4274

Epoch 03551: val_loss did not improve from 1.26843
Epoch 3552/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4272 - val_loss: 1.2707 - val_accuracy: 0.4187

Epoch 03552: val_loss did not improve from 1.26843
Epoch 3553/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4264 - val_loss: 1.2694 - val_accuracy: 0.4219

Epoch 03553: val_loss did not improve from 1.26843
Epoch 3554/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4274 - val_loss: 1.2704 - val_accuracy: 0.4282

Epoch 03554: val_loss did not improve from 1.26843
Epoch 3555/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4271 - val_loss: 1.2703 - val_accuracy: 0.4330

Epoch 03555: val_loss did not improve from 1.26843
Epoch 3556/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4243 - val_loss: 1.2703 - val_accuracy: 0.4274

Epoch 03556: val_loss did not improve from 1.26843
Epoch 3557/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4245 - val_loss: 1.2694 - val_accuracy: 0.4211

Epoch 03557: val_loss did not improve from 1.26843
Epoch 3558/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4269 - val_loss: 1.2731 - val_accuracy: 0.4187

Epoch 03558: val_loss did not improve from 1.26843
Epoch 3559/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4253 - val_loss: 1.2725 - val_accuracy: 0.4250

Epoch 03559: val_loss did not improve from 1.26843
Epoch 3560/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4271 - val_loss: 1.2698 - val_accuracy: 0.4155

Epoch 03560: val_loss did not improve from 1.26843
Epoch 3561/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4312 - val_loss: 1.2716 - val_accuracy: 0.4274

Epoch 03561: val_loss did not improve from 1.26843
Epoch 3562/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4276 - val_loss: 1.2725 - val_accuracy: 0.4266

Epoch 03562: val_loss did not improve from 1.26843
Epoch 3563/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4245 - val_loss: 1.2694 - val_accuracy: 0.4250

Epoch 03563: val_loss did not improve from 1.26843
Epoch 3564/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4270 - val_loss: 1.2699 - val_accuracy: 0.4226

Epoch 03564: val_loss did not improve from 1.26843
Epoch 3565/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4297 - val_loss: 1.2697 - val_accuracy: 0.4226

Epoch 03565: val_loss did not improve from 1.26843
Epoch 3566/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4281 - val_loss: 1.2770 - val_accuracy: 0.4362

Epoch 03566: val_loss did not improve from 1.26843
Epoch 3567/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4267 - val_loss: 1.2717 - val_accuracy: 0.4274

Epoch 03567: val_loss did not improve from 1.26843
Epoch 3568/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4233 - val_loss: 1.2766 - val_accuracy: 0.4250

Epoch 03568: val_loss did not improve from 1.26843
Epoch 3569/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4297 - val_loss: 1.2698 - val_accuracy: 0.4163

Epoch 03569: val_loss did not improve from 1.26843
Epoch 3570/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4256 - val_loss: 1.2705 - val_accuracy: 0.4187

Epoch 03570: val_loss did not improve from 1.26843
Epoch 3571/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4264 - val_loss: 1.2774 - val_accuracy: 0.4314

Epoch 03571: val_loss did not improve from 1.26843
Epoch 3572/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4271 - val_loss: 1.2711 - val_accuracy: 0.4250

Epoch 03572: val_loss did not improve from 1.26843
Epoch 3573/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4256 - val_loss: 1.2728 - val_accuracy: 0.4250

Epoch 03573: val_loss did not improve from 1.26843
Epoch 3574/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4280 - val_loss: 1.2720 - val_accuracy: 0.4250

Epoch 03574: val_loss did not improve from 1.26843
Epoch 3575/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4289 - val_loss: 1.2684 - val_accuracy: 0.4211

Epoch 03575: val_loss did not improve from 1.26843
Epoch 3576/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4264 - val_loss: 1.2705 - val_accuracy: 0.4219

Epoch 03576: val_loss did not improve from 1.26843
Epoch 3577/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4276 - val_loss: 1.2714 - val_accuracy: 0.4195

Epoch 03577: val_loss did not improve from 1.26843
Epoch 3578/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4260 - val_loss: 1.2689 - val_accuracy: 0.4179

Epoch 03578: val_loss did not improve from 1.26843
Epoch 3579/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4273 - val_loss: 1.2719 - val_accuracy: 0.4282

Epoch 03579: val_loss did not improve from 1.26843
Epoch 3580/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4290 - val_loss: 1.2729 - val_accuracy: 0.4226

Epoch 03580: val_loss did not improve from 1.26843
Epoch 3581/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4254 - val_loss: 1.2711 - val_accuracy: 0.4195

Epoch 03581: val_loss did not improve from 1.26843
Epoch 3582/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4246 - val_loss: 1.2707 - val_accuracy: 0.4282

Epoch 03582: val_loss did not improve from 1.26843
Epoch 3583/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4260 - val_loss: 1.2735 - val_accuracy: 0.4330

Epoch 03583: val_loss did not improve from 1.26843
Epoch 3584/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4241 - val_loss: 1.2729 - val_accuracy: 0.4298

Epoch 03584: val_loss did not improve from 1.26843
Epoch 3585/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4262 - val_loss: 1.2741 - val_accuracy: 0.4211

Epoch 03585: val_loss did not improve from 1.26843
Epoch 3586/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4295 - val_loss: 1.2702 - val_accuracy: 0.4266

Epoch 03586: val_loss did not improve from 1.26843
Epoch 3587/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4295 - val_loss: 1.2726 - val_accuracy: 0.4226

Epoch 03587: val_loss did not improve from 1.26843
Epoch 3588/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4260 - val_loss: 1.2731 - val_accuracy: 0.4219

Epoch 03588: val_loss did not improve from 1.26843
Epoch 3589/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4257 - val_loss: 1.2701 - val_accuracy: 0.4203

Epoch 03589: val_loss did not improve from 1.26843
Epoch 3590/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4241 - val_loss: 1.2753 - val_accuracy: 0.4330

Epoch 03590: val_loss did not improve from 1.26843
Epoch 3591/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4276 - val_loss: 1.2697 - val_accuracy: 0.4226

Epoch 03591: val_loss did not improve from 1.26843
Epoch 3592/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4272 - val_loss: 1.2796 - val_accuracy: 0.4226

Epoch 03592: val_loss did not improve from 1.26843
Epoch 3593/10000
12/12 - 0s - loss: 1.2725 - accuracy: 0.4231 - val_loss: 1.2693 - val_accuracy: 0.4234

Epoch 03593: val_loss did not improve from 1.26843
Epoch 3594/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4285 - val_loss: 1.2685 - val_accuracy: 0.4242

Epoch 03594: val_loss did not improve from 1.26843
Epoch 3595/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4258 - val_loss: 1.2715 - val_accuracy: 0.4131

Epoch 03595: val_loss did not improve from 1.26843
Epoch 3596/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4259 - val_loss: 1.2753 - val_accuracy: 0.4298

Epoch 03596: val_loss did not improve from 1.26843
Epoch 3597/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4278 - val_loss: 1.2699 - val_accuracy: 0.4298

Epoch 03597: val_loss did not improve from 1.26843
Epoch 3598/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4248 - val_loss: 1.2737 - val_accuracy: 0.4258

Epoch 03598: val_loss did not improve from 1.26843
Epoch 3599/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4272 - val_loss: 1.2707 - val_accuracy: 0.4219

Epoch 03599: val_loss did not improve from 1.26843
Epoch 3600/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4248 - val_loss: 1.2753 - val_accuracy: 0.4266

Epoch 03600: val_loss did not improve from 1.26843
Epoch 3601/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4277 - val_loss: 1.2716 - val_accuracy: 0.4282

Epoch 03601: val_loss did not improve from 1.26843
Epoch 3602/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4278 - val_loss: 1.2727 - val_accuracy: 0.4266

Epoch 03602: val_loss did not improve from 1.26843
Epoch 3603/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4296 - val_loss: 1.2704 - val_accuracy: 0.4266

Epoch 03603: val_loss did not improve from 1.26843
Epoch 3604/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4303 - val_loss: 1.2852 - val_accuracy: 0.4234

Epoch 03604: val_loss did not improve from 1.26843
Epoch 3605/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4195 - val_loss: 1.2713 - val_accuracy: 0.4195

Epoch 03605: val_loss did not improve from 1.26843
Epoch 3606/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4278 - val_loss: 1.2702 - val_accuracy: 0.4219

Epoch 03606: val_loss did not improve from 1.26843
Epoch 3607/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4271 - val_loss: 1.2687 - val_accuracy: 0.4179

Epoch 03607: val_loss did not improve from 1.26843
Epoch 3608/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4327 - val_loss: 1.2687 - val_accuracy: 0.4290

Epoch 03608: val_loss did not improve from 1.26843
Epoch 3609/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4253 - val_loss: 1.2756 - val_accuracy: 0.4155

Epoch 03609: val_loss did not improve from 1.26843
Epoch 3610/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4232 - val_loss: 1.2730 - val_accuracy: 0.4131

Epoch 03610: val_loss did not improve from 1.26843
Epoch 3611/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4245 - val_loss: 1.2689 - val_accuracy: 0.4226

Epoch 03611: val_loss did not improve from 1.26843
Epoch 3612/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4292 - val_loss: 1.2699 - val_accuracy: 0.4282

Epoch 03612: val_loss did not improve from 1.26843
Epoch 3613/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4252 - val_loss: 1.2724 - val_accuracy: 0.4250

Epoch 03613: val_loss did not improve from 1.26843
Epoch 3614/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4293 - val_loss: 1.2684 - val_accuracy: 0.4258

Epoch 03614: val_loss improved from 1.26843 to 1.26839, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3615/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4275 - val_loss: 1.2697 - val_accuracy: 0.4195

Epoch 03615: val_loss did not improve from 1.26839
Epoch 3616/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4309 - val_loss: 1.2689 - val_accuracy: 0.4266

Epoch 03616: val_loss did not improve from 1.26839
Epoch 3617/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4282 - val_loss: 1.2701 - val_accuracy: 0.4250

Epoch 03617: val_loss did not improve from 1.26839
Epoch 3618/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4305 - val_loss: 1.2732 - val_accuracy: 0.4250

Epoch 03618: val_loss did not improve from 1.26839
Epoch 3619/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4291 - val_loss: 1.2694 - val_accuracy: 0.4242

Epoch 03619: val_loss did not improve from 1.26839
Epoch 3620/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4287 - val_loss: 1.2720 - val_accuracy: 0.4250

Epoch 03620: val_loss did not improve from 1.26839
Epoch 3621/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4266 - val_loss: 1.2743 - val_accuracy: 0.4290

Epoch 03621: val_loss did not improve from 1.26839
Epoch 3622/10000
12/12 - 0s - loss: 1.2718 - accuracy: 0.4203 - val_loss: 1.2709 - val_accuracy: 0.4139

Epoch 03622: val_loss did not improve from 1.26839
Epoch 3623/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4243 - val_loss: 1.2719 - val_accuracy: 0.4242

Epoch 03623: val_loss did not improve from 1.26839
Epoch 3624/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4270 - val_loss: 1.2740 - val_accuracy: 0.4274

Epoch 03624: val_loss did not improve from 1.26839
Epoch 3625/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4281 - val_loss: 1.2717 - val_accuracy: 0.4298

Epoch 03625: val_loss did not improve from 1.26839
Epoch 3626/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4249 - val_loss: 1.2766 - val_accuracy: 0.4131

Epoch 03626: val_loss did not improve from 1.26839
Epoch 3627/10000
12/12 - 0s - loss: 1.2689 - accuracy: 0.4233 - val_loss: 1.2692 - val_accuracy: 0.4234

Epoch 03627: val_loss did not improve from 1.26839
Epoch 3628/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4296 - val_loss: 1.2694 - val_accuracy: 0.4322

Epoch 03628: val_loss did not improve from 1.26839
Epoch 3629/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4300 - val_loss: 1.2731 - val_accuracy: 0.4163

Epoch 03629: val_loss did not improve from 1.26839
Epoch 3630/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4317 - val_loss: 1.2711 - val_accuracy: 0.4203

Epoch 03630: val_loss did not improve from 1.26839
Epoch 3631/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4286 - val_loss: 1.2713 - val_accuracy: 0.4179

Epoch 03631: val_loss did not improve from 1.26839
Epoch 3632/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4271 - val_loss: 1.2683 - val_accuracy: 0.4211

Epoch 03632: val_loss improved from 1.26839 to 1.26826, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3633/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4246 - val_loss: 1.2685 - val_accuracy: 0.4211

Epoch 03633: val_loss did not improve from 1.26826
Epoch 3634/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4279 - val_loss: 1.2711 - val_accuracy: 0.4274

Epoch 03634: val_loss did not improve from 1.26826
Epoch 3635/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4274 - val_loss: 1.2737 - val_accuracy: 0.4187

Epoch 03635: val_loss did not improve from 1.26826
Epoch 3636/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4277 - val_loss: 1.2691 - val_accuracy: 0.4290

Epoch 03636: val_loss did not improve from 1.26826
Epoch 3637/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4274 - val_loss: 1.2691 - val_accuracy: 0.4219

Epoch 03637: val_loss did not improve from 1.26826
Epoch 3638/10000
12/12 - 0s - loss: 1.2746 - accuracy: 0.4241 - val_loss: 1.2700 - val_accuracy: 0.4266

Epoch 03638: val_loss did not improve from 1.26826
Epoch 3639/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4275 - val_loss: 1.2708 - val_accuracy: 0.4179

Epoch 03639: val_loss did not improve from 1.26826
Epoch 3640/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4229 - val_loss: 1.2687 - val_accuracy: 0.4219

Epoch 03640: val_loss did not improve from 1.26826
Epoch 3641/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4298 - val_loss: 1.2698 - val_accuracy: 0.4211

Epoch 03641: val_loss did not improve from 1.26826
Epoch 3642/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4266 - val_loss: 1.2709 - val_accuracy: 0.4298

Epoch 03642: val_loss did not improve from 1.26826
Epoch 3643/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4252 - val_loss: 1.2692 - val_accuracy: 0.4322

Epoch 03643: val_loss did not improve from 1.26826
Epoch 3644/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4280 - val_loss: 1.2685 - val_accuracy: 0.4250

Epoch 03644: val_loss did not improve from 1.26826
Epoch 3645/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4268 - val_loss: 1.2706 - val_accuracy: 0.4171

Epoch 03645: val_loss did not improve from 1.26826
Epoch 3646/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4253 - val_loss: 1.2691 - val_accuracy: 0.4266

Epoch 03646: val_loss did not improve from 1.26826
Epoch 3647/10000
12/12 - 0s - loss: 1.2708 - accuracy: 0.4233 - val_loss: 1.2875 - val_accuracy: 0.4171

Epoch 03647: val_loss did not improve from 1.26826
Epoch 3648/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4287 - val_loss: 1.2763 - val_accuracy: 0.4250

Epoch 03648: val_loss did not improve from 1.26826
Epoch 3649/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4303 - val_loss: 1.2701 - val_accuracy: 0.4266

Epoch 03649: val_loss did not improve from 1.26826
Epoch 3650/10000
12/12 - 0s - loss: 1.2716 - accuracy: 0.4232 - val_loss: 1.2719 - val_accuracy: 0.4266

Epoch 03650: val_loss did not improve from 1.26826
Epoch 3651/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4275 - val_loss: 1.2785 - val_accuracy: 0.4203

Epoch 03651: val_loss did not improve from 1.26826
Epoch 3652/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4231 - val_loss: 1.2724 - val_accuracy: 0.4219

Epoch 03652: val_loss did not improve from 1.26826
Epoch 3653/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4256 - val_loss: 1.2711 - val_accuracy: 0.4226

Epoch 03653: val_loss did not improve from 1.26826
Epoch 3654/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4274 - val_loss: 1.2726 - val_accuracy: 0.4203

Epoch 03654: val_loss did not improve from 1.26826
Epoch 3655/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4265 - val_loss: 1.2700 - val_accuracy: 0.4234

Epoch 03655: val_loss did not improve from 1.26826
Epoch 3656/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4293 - val_loss: 1.2699 - val_accuracy: 0.4203

Epoch 03656: val_loss did not improve from 1.26826
Epoch 3657/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4253 - val_loss: 1.2717 - val_accuracy: 0.4234

Epoch 03657: val_loss did not improve from 1.26826
Epoch 3658/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4247 - val_loss: 1.2703 - val_accuracy: 0.4211

Epoch 03658: val_loss did not improve from 1.26826
Epoch 3659/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4286 - val_loss: 1.2681 - val_accuracy: 0.4242

Epoch 03659: val_loss improved from 1.26826 to 1.26810, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3660/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4268 - val_loss: 1.2753 - val_accuracy: 0.4155

Epoch 03660: val_loss did not improve from 1.26810
Epoch 3661/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4264 - val_loss: 1.2691 - val_accuracy: 0.4203

Epoch 03661: val_loss did not improve from 1.26810
Epoch 3662/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4265 - val_loss: 1.2690 - val_accuracy: 0.4290

Epoch 03662: val_loss did not improve from 1.26810
Epoch 3663/10000
12/12 - 0s - loss: 1.2676 - accuracy: 0.4222 - val_loss: 1.2721 - val_accuracy: 0.4242

Epoch 03663: val_loss did not improve from 1.26810
Epoch 3664/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4275 - val_loss: 1.2697 - val_accuracy: 0.4266

Epoch 03664: val_loss did not improve from 1.26810
Epoch 3665/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4272 - val_loss: 1.2700 - val_accuracy: 0.4298

Epoch 03665: val_loss did not improve from 1.26810
Epoch 3666/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4243 - val_loss: 1.2695 - val_accuracy: 0.4250

Epoch 03666: val_loss did not improve from 1.26810
Epoch 3667/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4249 - val_loss: 1.2729 - val_accuracy: 0.4179

Epoch 03667: val_loss did not improve from 1.26810
Epoch 3668/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4216 - val_loss: 1.2742 - val_accuracy: 0.4234

Epoch 03668: val_loss did not improve from 1.26810
Epoch 3669/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4256 - val_loss: 1.2712 - val_accuracy: 0.4290

Epoch 03669: val_loss did not improve from 1.26810
Epoch 3670/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4264 - val_loss: 1.2713 - val_accuracy: 0.4330

Epoch 03670: val_loss did not improve from 1.26810
Epoch 3671/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4287 - val_loss: 1.2717 - val_accuracy: 0.4219

Epoch 03671: val_loss did not improve from 1.26810
Epoch 3672/10000
12/12 - 0s - loss: 1.2672 - accuracy: 0.4250 - val_loss: 1.2741 - val_accuracy: 0.4234

Epoch 03672: val_loss did not improve from 1.26810
Epoch 3673/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4254 - val_loss: 1.2753 - val_accuracy: 0.4187

Epoch 03673: val_loss did not improve from 1.26810
Epoch 3674/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4243 - val_loss: 1.2720 - val_accuracy: 0.4274

Epoch 03674: val_loss did not improve from 1.26810
Epoch 3675/10000
12/12 - 0s - loss: 1.2688 - accuracy: 0.4194 - val_loss: 1.2712 - val_accuracy: 0.4282

Epoch 03675: val_loss did not improve from 1.26810
Epoch 3676/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4289 - val_loss: 1.2686 - val_accuracy: 0.4171

Epoch 03676: val_loss did not improve from 1.26810
Epoch 3677/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4291 - val_loss: 1.2702 - val_accuracy: 0.4298

Epoch 03677: val_loss did not improve from 1.26810
Epoch 3678/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4273 - val_loss: 1.2710 - val_accuracy: 0.4171

Epoch 03678: val_loss did not improve from 1.26810
Epoch 3679/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4244 - val_loss: 1.2700 - val_accuracy: 0.4226

Epoch 03679: val_loss did not improve from 1.26810
Epoch 3680/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4275 - val_loss: 1.2702 - val_accuracy: 0.4282

Epoch 03680: val_loss did not improve from 1.26810
Epoch 3681/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4280 - val_loss: 1.2697 - val_accuracy: 0.4258

Epoch 03681: val_loss did not improve from 1.26810
Epoch 3682/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4260 - val_loss: 1.2721 - val_accuracy: 0.4250

Epoch 03682: val_loss did not improve from 1.26810
Epoch 3683/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4278 - val_loss: 1.2697 - val_accuracy: 0.4282

Epoch 03683: val_loss did not improve from 1.26810
Epoch 3684/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4287 - val_loss: 1.2689 - val_accuracy: 0.4298

Epoch 03684: val_loss did not improve from 1.26810
Epoch 3685/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4279 - val_loss: 1.2704 - val_accuracy: 0.4258

Epoch 03685: val_loss did not improve from 1.26810
Epoch 3686/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4295 - val_loss: 1.2704 - val_accuracy: 0.4242

Epoch 03686: val_loss did not improve from 1.26810
Epoch 3687/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4264 - val_loss: 1.2693 - val_accuracy: 0.4242

Epoch 03687: val_loss did not improve from 1.26810
Epoch 3688/10000
12/12 - 0s - loss: 1.2722 - accuracy: 0.4247 - val_loss: 1.2762 - val_accuracy: 0.4354

Epoch 03688: val_loss did not improve from 1.26810
Epoch 3689/10000
12/12 - 0s - loss: 1.2682 - accuracy: 0.4254 - val_loss: 1.2931 - val_accuracy: 0.4226

Epoch 03689: val_loss did not improve from 1.26810
Epoch 3690/10000
12/12 - 0s - loss: 1.2751 - accuracy: 0.4225 - val_loss: 1.2682 - val_accuracy: 0.4266

Epoch 03690: val_loss did not improve from 1.26810
Epoch 3691/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4271 - val_loss: 1.2748 - val_accuracy: 0.4306

Epoch 03691: val_loss did not improve from 1.26810
Epoch 3692/10000
12/12 - 0s - loss: 1.2665 - accuracy: 0.4264 - val_loss: 1.2703 - val_accuracy: 0.4282

Epoch 03692: val_loss did not improve from 1.26810
Epoch 3693/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4291 - val_loss: 1.2686 - val_accuracy: 0.4298

Epoch 03693: val_loss did not improve from 1.26810
Epoch 3694/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4265 - val_loss: 1.2698 - val_accuracy: 0.4211

Epoch 03694: val_loss did not improve from 1.26810
Epoch 3695/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4307 - val_loss: 1.2714 - val_accuracy: 0.4203

Epoch 03695: val_loss did not improve from 1.26810
Epoch 3696/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4226 - val_loss: 1.2689 - val_accuracy: 0.4171

Epoch 03696: val_loss did not improve from 1.26810
Epoch 3697/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4259 - val_loss: 1.2695 - val_accuracy: 0.4266

Epoch 03697: val_loss did not improve from 1.26810
Epoch 3698/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4269 - val_loss: 1.2727 - val_accuracy: 0.4290

Epoch 03698: val_loss did not improve from 1.26810
Epoch 3699/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4271 - val_loss: 1.2711 - val_accuracy: 0.4282

Epoch 03699: val_loss did not improve from 1.26810
Epoch 3700/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4264 - val_loss: 1.2684 - val_accuracy: 0.4195

Epoch 03700: val_loss did not improve from 1.26810
Epoch 3701/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4264 - val_loss: 1.2686 - val_accuracy: 0.4219

Epoch 03701: val_loss did not improve from 1.26810
Epoch 3702/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4303 - val_loss: 1.2747 - val_accuracy: 0.4242

Epoch 03702: val_loss did not improve from 1.26810
Epoch 3703/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4275 - val_loss: 1.2708 - val_accuracy: 0.4258

Epoch 03703: val_loss did not improve from 1.26810
Epoch 3704/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4307 - val_loss: 1.2697 - val_accuracy: 0.4290

Epoch 03704: val_loss did not improve from 1.26810
Epoch 3705/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4299 - val_loss: 1.2701 - val_accuracy: 0.4250

Epoch 03705: val_loss did not improve from 1.26810
Epoch 3706/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4284 - val_loss: 1.2686 - val_accuracy: 0.4266

Epoch 03706: val_loss did not improve from 1.26810
Epoch 3707/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4295 - val_loss: 1.2687 - val_accuracy: 0.4219

Epoch 03707: val_loss did not improve from 1.26810
Epoch 3708/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4277 - val_loss: 1.2712 - val_accuracy: 0.4306

Epoch 03708: val_loss did not improve from 1.26810
Epoch 3709/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4290 - val_loss: 1.2685 - val_accuracy: 0.4282

Epoch 03709: val_loss did not improve from 1.26810
Epoch 3710/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4303 - val_loss: 1.2698 - val_accuracy: 0.4147

Epoch 03710: val_loss did not improve from 1.26810
Epoch 3711/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4291 - val_loss: 1.2690 - val_accuracy: 0.4187

Epoch 03711: val_loss did not improve from 1.26810
Epoch 3712/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4283 - val_loss: 1.2712 - val_accuracy: 0.4226

Epoch 03712: val_loss did not improve from 1.26810
Epoch 3713/10000
12/12 - 0s - loss: 1.2656 - accuracy: 0.4249 - val_loss: 1.2680 - val_accuracy: 0.4226

Epoch 03713: val_loss improved from 1.26810 to 1.26804, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3714/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4264 - val_loss: 1.2699 - val_accuracy: 0.4226

Epoch 03714: val_loss did not improve from 1.26804
Epoch 3715/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4254 - val_loss: 1.2764 - val_accuracy: 0.4219

Epoch 03715: val_loss did not improve from 1.26804
Epoch 3716/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4283 - val_loss: 1.2702 - val_accuracy: 0.4266

Epoch 03716: val_loss did not improve from 1.26804
Epoch 3717/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4287 - val_loss: 1.2688 - val_accuracy: 0.4258

Epoch 03717: val_loss did not improve from 1.26804
Epoch 3718/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4286 - val_loss: 1.2677 - val_accuracy: 0.4242

Epoch 03718: val_loss improved from 1.26804 to 1.26772, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3719/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4251 - val_loss: 1.2705 - val_accuracy: 0.4322

Epoch 03719: val_loss did not improve from 1.26772
Epoch 3720/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4304 - val_loss: 1.2773 - val_accuracy: 0.4242

Epoch 03720: val_loss did not improve from 1.26772
Epoch 3721/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4279 - val_loss: 1.2705 - val_accuracy: 0.4139

Epoch 03721: val_loss did not improve from 1.26772
Epoch 3722/10000
12/12 - 0s - loss: 1.2687 - accuracy: 0.4254 - val_loss: 1.2707 - val_accuracy: 0.4242

Epoch 03722: val_loss did not improve from 1.26772
Epoch 3723/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4283 - val_loss: 1.2718 - val_accuracy: 0.4219

Epoch 03723: val_loss did not improve from 1.26772
Epoch 3724/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4300 - val_loss: 1.2688 - val_accuracy: 0.4314

Epoch 03724: val_loss did not improve from 1.26772
Epoch 3725/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4261 - val_loss: 1.2668 - val_accuracy: 0.4258

Epoch 03725: val_loss improved from 1.26772 to 1.26677, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3726/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4300 - val_loss: 1.2674 - val_accuracy: 0.4258

Epoch 03726: val_loss did not improve from 1.26677
Epoch 3727/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4291 - val_loss: 1.2692 - val_accuracy: 0.4234

Epoch 03727: val_loss did not improve from 1.26677
Epoch 3728/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4295 - val_loss: 1.2715 - val_accuracy: 0.4298

Epoch 03728: val_loss did not improve from 1.26677
Epoch 3729/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4322 - val_loss: 1.2690 - val_accuracy: 0.4234

Epoch 03729: val_loss did not improve from 1.26677
Epoch 3730/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4289 - val_loss: 1.2715 - val_accuracy: 0.4226

Epoch 03730: val_loss did not improve from 1.26677
Epoch 3731/10000
12/12 - 0s - loss: 1.2674 - accuracy: 0.4274 - val_loss: 1.2708 - val_accuracy: 0.4274

Epoch 03731: val_loss did not improve from 1.26677
Epoch 3732/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4230 - val_loss: 1.2711 - val_accuracy: 0.4226

Epoch 03732: val_loss did not improve from 1.26677
Epoch 3733/10000
12/12 - 0s - loss: 1.2704 - accuracy: 0.4252 - val_loss: 1.2721 - val_accuracy: 0.4219

Epoch 03733: val_loss did not improve from 1.26677
Epoch 3734/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4223 - val_loss: 1.2696 - val_accuracy: 0.4250

Epoch 03734: val_loss did not improve from 1.26677
Epoch 3735/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4270 - val_loss: 1.2740 - val_accuracy: 0.4266

Epoch 03735: val_loss did not improve from 1.26677
Epoch 3736/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4315 - val_loss: 1.2699 - val_accuracy: 0.4266

Epoch 03736: val_loss did not improve from 1.26677
Epoch 3737/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4327 - val_loss: 1.2704 - val_accuracy: 0.4250

Epoch 03737: val_loss did not improve from 1.26677
Epoch 3738/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4285 - val_loss: 1.2725 - val_accuracy: 0.4258

Epoch 03738: val_loss did not improve from 1.26677
Epoch 3739/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4258 - val_loss: 1.2673 - val_accuracy: 0.4226

Epoch 03739: val_loss did not improve from 1.26677
Epoch 3740/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4234 - val_loss: 1.2667 - val_accuracy: 0.4147

Epoch 03740: val_loss improved from 1.26677 to 1.26669, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3741/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4286 - val_loss: 1.2694 - val_accuracy: 0.4290

Epoch 03741: val_loss did not improve from 1.26669
Epoch 3742/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4291 - val_loss: 1.2706 - val_accuracy: 0.4226

Epoch 03742: val_loss did not improve from 1.26669
Epoch 3743/10000
12/12 - 0s - loss: 1.2694 - accuracy: 0.4262 - val_loss: 1.2723 - val_accuracy: 0.4290

Epoch 03743: val_loss did not improve from 1.26669
Epoch 3744/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4243 - val_loss: 1.2704 - val_accuracy: 0.4219

Epoch 03744: val_loss did not improve from 1.26669
Epoch 3745/10000
12/12 - 0s - loss: 1.2707 - accuracy: 0.4202 - val_loss: 1.2736 - val_accuracy: 0.4266

Epoch 03745: val_loss did not improve from 1.26669
Epoch 3746/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4313 - val_loss: 1.2689 - val_accuracy: 0.4171

Epoch 03746: val_loss did not improve from 1.26669
Epoch 3747/10000
12/12 - 0s - loss: 1.2678 - accuracy: 0.4224 - val_loss: 1.2676 - val_accuracy: 0.4282

Epoch 03747: val_loss did not improve from 1.26669
Epoch 3748/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4306 - val_loss: 1.2652 - val_accuracy: 0.4266

Epoch 03748: val_loss improved from 1.26669 to 1.26516, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3749/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4277 - val_loss: 1.2664 - val_accuracy: 0.4242

Epoch 03749: val_loss did not improve from 1.26516
Epoch 3750/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4295 - val_loss: 1.2678 - val_accuracy: 0.4203

Epoch 03750: val_loss did not improve from 1.26516
Epoch 3751/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4303 - val_loss: 1.2761 - val_accuracy: 0.4258

Epoch 03751: val_loss did not improve from 1.26516
Epoch 3752/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4285 - val_loss: 1.2706 - val_accuracy: 0.4155

Epoch 03752: val_loss did not improve from 1.26516
Epoch 3753/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4295 - val_loss: 1.2704 - val_accuracy: 0.4219

Epoch 03753: val_loss did not improve from 1.26516
Epoch 3754/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4314 - val_loss: 1.2749 - val_accuracy: 0.4290

Epoch 03754: val_loss did not improve from 1.26516
Epoch 3755/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4311 - val_loss: 1.2700 - val_accuracy: 0.4171

Epoch 03755: val_loss did not improve from 1.26516
Epoch 3756/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4290 - val_loss: 1.2696 - val_accuracy: 0.4258

Epoch 03756: val_loss did not improve from 1.26516
Epoch 3757/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4309 - val_loss: 1.2712 - val_accuracy: 0.4234

Epoch 03757: val_loss did not improve from 1.26516
Epoch 3758/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4290 - val_loss: 1.2704 - val_accuracy: 0.4203

Epoch 03758: val_loss did not improve from 1.26516
Epoch 3759/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4283 - val_loss: 1.2710 - val_accuracy: 0.4282

Epoch 03759: val_loss did not improve from 1.26516
Epoch 3760/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4298 - val_loss: 1.2695 - val_accuracy: 0.4250

Epoch 03760: val_loss did not improve from 1.26516
Epoch 3761/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4261 - val_loss: 1.2701 - val_accuracy: 0.4290

Epoch 03761: val_loss did not improve from 1.26516
Epoch 3762/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4279 - val_loss: 1.2726 - val_accuracy: 0.4306

Epoch 03762: val_loss did not improve from 1.26516
Epoch 3763/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4313 - val_loss: 1.2695 - val_accuracy: 0.4226

Epoch 03763: val_loss did not improve from 1.26516
Epoch 3764/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4290 - val_loss: 1.2695 - val_accuracy: 0.4234

Epoch 03764: val_loss did not improve from 1.26516
Epoch 3765/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4292 - val_loss: 1.2728 - val_accuracy: 0.4250

Epoch 03765: val_loss did not improve from 1.26516
Epoch 3766/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4290 - val_loss: 1.2682 - val_accuracy: 0.4203

Epoch 03766: val_loss did not improve from 1.26516
Epoch 3767/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4258 - val_loss: 1.2692 - val_accuracy: 0.4226

Epoch 03767: val_loss did not improve from 1.26516
Epoch 3768/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4335 - val_loss: 1.2682 - val_accuracy: 0.4211

Epoch 03768: val_loss did not improve from 1.26516
Epoch 3769/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4309 - val_loss: 1.2702 - val_accuracy: 0.4171

Epoch 03769: val_loss did not improve from 1.26516
Epoch 3770/10000
12/12 - 0s - loss: 1.2706 - accuracy: 0.4254 - val_loss: 1.2701 - val_accuracy: 0.4290

Epoch 03770: val_loss did not improve from 1.26516
Epoch 3771/10000
12/12 - 0s - loss: 1.2683 - accuracy: 0.4248 - val_loss: 1.2826 - val_accuracy: 0.4219

Epoch 03771: val_loss did not improve from 1.26516
Epoch 3772/10000
12/12 - 0s - loss: 1.2732 - accuracy: 0.4234 - val_loss: 1.2693 - val_accuracy: 0.4258

Epoch 03772: val_loss did not improve from 1.26516
Epoch 3773/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4274 - val_loss: 1.2749 - val_accuracy: 0.4250

Epoch 03773: val_loss did not improve from 1.26516
Epoch 3774/10000
12/12 - 0s - loss: 1.2660 - accuracy: 0.4268 - val_loss: 1.2676 - val_accuracy: 0.4314

Epoch 03774: val_loss did not improve from 1.26516
Epoch 3775/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4239 - val_loss: 1.2717 - val_accuracy: 0.4115

Epoch 03775: val_loss did not improve from 1.26516
Epoch 3776/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4274 - val_loss: 1.2708 - val_accuracy: 0.4314

Epoch 03776: val_loss did not improve from 1.26516
Epoch 3777/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4297 - val_loss: 1.2702 - val_accuracy: 0.4234

Epoch 03777: val_loss did not improve from 1.26516
Epoch 3778/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4290 - val_loss: 1.2711 - val_accuracy: 0.4250

Epoch 03778: val_loss did not improve from 1.26516
Epoch 3779/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4282 - val_loss: 1.2715 - val_accuracy: 0.4179

Epoch 03779: val_loss did not improve from 1.26516
Epoch 3780/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4249 - val_loss: 1.2728 - val_accuracy: 0.4075

Epoch 03780: val_loss did not improve from 1.26516
Epoch 3781/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4270 - val_loss: 1.2724 - val_accuracy: 0.4211

Epoch 03781: val_loss did not improve from 1.26516
Epoch 3782/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4296 - val_loss: 1.2694 - val_accuracy: 0.4266

Epoch 03782: val_loss did not improve from 1.26516
Epoch 3783/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4294 - val_loss: 1.2724 - val_accuracy: 0.4258

Epoch 03783: val_loss did not improve from 1.26516
Epoch 3784/10000
12/12 - 0s - loss: 1.2697 - accuracy: 0.4243 - val_loss: 1.2703 - val_accuracy: 0.4226

Epoch 03784: val_loss did not improve from 1.26516
Epoch 3785/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4281 - val_loss: 1.2682 - val_accuracy: 0.4219

Epoch 03785: val_loss did not improve from 1.26516
Epoch 3786/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4268 - val_loss: 1.2727 - val_accuracy: 0.4330

Epoch 03786: val_loss did not improve from 1.26516
Epoch 3787/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4257 - val_loss: 1.2691 - val_accuracy: 0.4155

Epoch 03787: val_loss did not improve from 1.26516
Epoch 3788/10000
12/12 - 0s - loss: 1.2664 - accuracy: 0.4258 - val_loss: 1.2678 - val_accuracy: 0.4258

Epoch 03788: val_loss did not improve from 1.26516
Epoch 3789/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4292 - val_loss: 1.2700 - val_accuracy: 0.4266

Epoch 03789: val_loss did not improve from 1.26516
Epoch 3790/10000
12/12 - 0s - loss: 1.2711 - accuracy: 0.4225 - val_loss: 1.2747 - val_accuracy: 0.4211

Epoch 03790: val_loss did not improve from 1.26516
Epoch 3791/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4270 - val_loss: 1.2689 - val_accuracy: 0.4290

Epoch 03791: val_loss did not improve from 1.26516
Epoch 3792/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4285 - val_loss: 1.2709 - val_accuracy: 0.4274

Epoch 03792: val_loss did not improve from 1.26516
Epoch 3793/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4266 - val_loss: 1.2677 - val_accuracy: 0.4290

Epoch 03793: val_loss did not improve from 1.26516
Epoch 3794/10000
12/12 - 0s - loss: 1.2705 - accuracy: 0.4255 - val_loss: 1.2693 - val_accuracy: 0.4306

Epoch 03794: val_loss did not improve from 1.26516
Epoch 3795/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4284 - val_loss: 1.2763 - val_accuracy: 0.4386

Epoch 03795: val_loss did not improve from 1.26516
Epoch 3796/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4315 - val_loss: 1.2703 - val_accuracy: 0.4195

Epoch 03796: val_loss did not improve from 1.26516
Epoch 3797/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4280 - val_loss: 1.2700 - val_accuracy: 0.4314

Epoch 03797: val_loss did not improve from 1.26516
Epoch 3798/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4246 - val_loss: 1.2671 - val_accuracy: 0.4274

Epoch 03798: val_loss did not improve from 1.26516
Epoch 3799/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4303 - val_loss: 1.2694 - val_accuracy: 0.4234

Epoch 03799: val_loss did not improve from 1.26516
Epoch 3800/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4294 - val_loss: 1.2691 - val_accuracy: 0.4290

Epoch 03800: val_loss did not improve from 1.26516
Epoch 3801/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4287 - val_loss: 1.2717 - val_accuracy: 0.4226

Epoch 03801: val_loss did not improve from 1.26516
Epoch 3802/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4270 - val_loss: 1.2728 - val_accuracy: 0.4290

Epoch 03802: val_loss did not improve from 1.26516
Epoch 3803/10000
12/12 - 0s - loss: 1.2662 - accuracy: 0.4248 - val_loss: 1.2723 - val_accuracy: 0.4282

Epoch 03803: val_loss did not improve from 1.26516
Epoch 3804/10000
12/12 - 0s - loss: 1.2661 - accuracy: 0.4274 - val_loss: 1.2696 - val_accuracy: 0.4211

Epoch 03804: val_loss did not improve from 1.26516
Epoch 3805/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4285 - val_loss: 1.2685 - val_accuracy: 0.4314

Epoch 03805: val_loss did not improve from 1.26516
Epoch 3806/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4258 - val_loss: 1.2731 - val_accuracy: 0.4195

Epoch 03806: val_loss did not improve from 1.26516
Epoch 3807/10000
12/12 - 0s - loss: 1.2691 - accuracy: 0.4264 - val_loss: 1.2763 - val_accuracy: 0.4386

Epoch 03807: val_loss did not improve from 1.26516
Epoch 3808/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4288 - val_loss: 1.2712 - val_accuracy: 0.4242

Epoch 03808: val_loss did not improve from 1.26516
Epoch 3809/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4316 - val_loss: 1.2682 - val_accuracy: 0.4211

Epoch 03809: val_loss did not improve from 1.26516
Epoch 3810/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4303 - val_loss: 1.2672 - val_accuracy: 0.4282

Epoch 03810: val_loss did not improve from 1.26516
Epoch 3811/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4330 - val_loss: 1.2671 - val_accuracy: 0.4242

Epoch 03811: val_loss did not improve from 1.26516
Epoch 3812/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4316 - val_loss: 1.2669 - val_accuracy: 0.4195

Epoch 03812: val_loss did not improve from 1.26516
Epoch 3813/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4294 - val_loss: 1.2745 - val_accuracy: 0.4203

Epoch 03813: val_loss did not improve from 1.26516
Epoch 3814/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4257 - val_loss: 1.2687 - val_accuracy: 0.4362

Epoch 03814: val_loss did not improve from 1.26516
Epoch 3815/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4280 - val_loss: 1.2674 - val_accuracy: 0.4234

Epoch 03815: val_loss did not improve from 1.26516
Epoch 3816/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4298 - val_loss: 1.2700 - val_accuracy: 0.4195

Epoch 03816: val_loss did not improve from 1.26516
Epoch 3817/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4303 - val_loss: 1.2704 - val_accuracy: 0.4274

Epoch 03817: val_loss did not improve from 1.26516
Epoch 3818/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4267 - val_loss: 1.2803 - val_accuracy: 0.4203

Epoch 03818: val_loss did not improve from 1.26516
Epoch 3819/10000
12/12 - 0s - loss: 1.2680 - accuracy: 0.4196 - val_loss: 1.2673 - val_accuracy: 0.4187

Epoch 03819: val_loss did not improve from 1.26516
Epoch 3820/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4279 - val_loss: 1.2712 - val_accuracy: 0.4298

Epoch 03820: val_loss did not improve from 1.26516
Epoch 3821/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4277 - val_loss: 1.2699 - val_accuracy: 0.4282

Epoch 03821: val_loss did not improve from 1.26516
Epoch 3822/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4298 - val_loss: 1.2698 - val_accuracy: 0.4195

Epoch 03822: val_loss did not improve from 1.26516
Epoch 3823/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4291 - val_loss: 1.2682 - val_accuracy: 0.4234

Epoch 03823: val_loss did not improve from 1.26516
Epoch 3824/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4291 - val_loss: 1.2681 - val_accuracy: 0.4258

Epoch 03824: val_loss did not improve from 1.26516
Epoch 3825/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4292 - val_loss: 1.2682 - val_accuracy: 0.4290

Epoch 03825: val_loss did not improve from 1.26516
Epoch 3826/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4250 - val_loss: 1.2669 - val_accuracy: 0.4258

Epoch 03826: val_loss did not improve from 1.26516
Epoch 3827/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4291 - val_loss: 1.2673 - val_accuracy: 0.4298

Epoch 03827: val_loss did not improve from 1.26516
Epoch 3828/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4289 - val_loss: 1.2680 - val_accuracy: 0.4322

Epoch 03828: val_loss did not improve from 1.26516
Epoch 3829/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4259 - val_loss: 1.2720 - val_accuracy: 0.4250

Epoch 03829: val_loss did not improve from 1.26516
Epoch 3830/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4305 - val_loss: 1.2686 - val_accuracy: 0.4211

Epoch 03830: val_loss did not improve from 1.26516
Epoch 3831/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4298 - val_loss: 1.2670 - val_accuracy: 0.4179

Epoch 03831: val_loss did not improve from 1.26516
Epoch 3832/10000
12/12 - 0s - loss: 1.2658 - accuracy: 0.4272 - val_loss: 1.2714 - val_accuracy: 0.4330

Epoch 03832: val_loss did not improve from 1.26516
Epoch 3833/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4295 - val_loss: 1.2697 - val_accuracy: 0.4234

Epoch 03833: val_loss did not improve from 1.26516
Epoch 3834/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4298 - val_loss: 1.2688 - val_accuracy: 0.4362

Epoch 03834: val_loss did not improve from 1.26516
Epoch 3835/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4326 - val_loss: 1.2668 - val_accuracy: 0.4274

Epoch 03835: val_loss did not improve from 1.26516
Epoch 3836/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4280 - val_loss: 1.2685 - val_accuracy: 0.4298

Epoch 03836: val_loss did not improve from 1.26516
Epoch 3837/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4326 - val_loss: 1.2667 - val_accuracy: 0.4330

Epoch 03837: val_loss did not improve from 1.26516
Epoch 3838/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4289 - val_loss: 1.2693 - val_accuracy: 0.4290

Epoch 03838: val_loss did not improve from 1.26516
Epoch 3839/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4285 - val_loss: 1.2686 - val_accuracy: 0.4250

Epoch 03839: val_loss did not improve from 1.26516
Epoch 3840/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4283 - val_loss: 1.2696 - val_accuracy: 0.4179

Epoch 03840: val_loss did not improve from 1.26516
Epoch 3841/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4279 - val_loss: 1.2672 - val_accuracy: 0.4250

Epoch 03841: val_loss did not improve from 1.26516
Epoch 3842/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4295 - val_loss: 1.2655 - val_accuracy: 0.4250

Epoch 03842: val_loss did not improve from 1.26516
Epoch 3843/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4286 - val_loss: 1.2685 - val_accuracy: 0.4258

Epoch 03843: val_loss did not improve from 1.26516
Epoch 3844/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4298 - val_loss: 1.2714 - val_accuracy: 0.4242

Epoch 03844: val_loss did not improve from 1.26516
Epoch 3845/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4252 - val_loss: 1.2675 - val_accuracy: 0.4250

Epoch 03845: val_loss did not improve from 1.26516
Epoch 3846/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4272 - val_loss: 1.2708 - val_accuracy: 0.4282

Epoch 03846: val_loss did not improve from 1.26516
Epoch 3847/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4293 - val_loss: 1.2681 - val_accuracy: 0.4171

Epoch 03847: val_loss did not improve from 1.26516
Epoch 3848/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4282 - val_loss: 1.2666 - val_accuracy: 0.4274

Epoch 03848: val_loss did not improve from 1.26516
Epoch 3849/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4283 - val_loss: 1.2726 - val_accuracy: 0.4187

Epoch 03849: val_loss did not improve from 1.26516
Epoch 3850/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4318 - val_loss: 1.2684 - val_accuracy: 0.4258

Epoch 03850: val_loss did not improve from 1.26516
Epoch 3851/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4273 - val_loss: 1.2675 - val_accuracy: 0.4163

Epoch 03851: val_loss did not improve from 1.26516
Epoch 3852/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4329 - val_loss: 1.2673 - val_accuracy: 0.4187

Epoch 03852: val_loss did not improve from 1.26516
Epoch 3853/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4264 - val_loss: 1.2686 - val_accuracy: 0.4258

Epoch 03853: val_loss did not improve from 1.26516
Epoch 3854/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4294 - val_loss: 1.2687 - val_accuracy: 0.4266

Epoch 03854: val_loss did not improve from 1.26516
Epoch 3855/10000
12/12 - 0s - loss: 1.2635 - accuracy: 0.4280 - val_loss: 1.2684 - val_accuracy: 0.4250

Epoch 03855: val_loss did not improve from 1.26516
Epoch 3856/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4271 - val_loss: 1.2677 - val_accuracy: 0.4266

Epoch 03856: val_loss did not improve from 1.26516
Epoch 3857/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4304 - val_loss: 1.2740 - val_accuracy: 0.4163

Epoch 03857: val_loss did not improve from 1.26516
Epoch 3858/10000
12/12 - 0s - loss: 1.2651 - accuracy: 0.4283 - val_loss: 1.2704 - val_accuracy: 0.4282

Epoch 03858: val_loss did not improve from 1.26516
Epoch 3859/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4333 - val_loss: 1.2706 - val_accuracy: 0.4266

Epoch 03859: val_loss did not improve from 1.26516
Epoch 3860/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4285 - val_loss: 1.2676 - val_accuracy: 0.4219

Epoch 03860: val_loss did not improve from 1.26516
Epoch 3861/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4287 - val_loss: 1.2687 - val_accuracy: 0.4226

Epoch 03861: val_loss did not improve from 1.26516
Epoch 3862/10000
12/12 - 0s - loss: 1.2640 - accuracy: 0.4296 - val_loss: 1.2704 - val_accuracy: 0.4306

Epoch 03862: val_loss did not improve from 1.26516
Epoch 3863/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4282 - val_loss: 1.2665 - val_accuracy: 0.4258

Epoch 03863: val_loss did not improve from 1.26516
Epoch 3864/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4312 - val_loss: 1.2672 - val_accuracy: 0.4354

Epoch 03864: val_loss did not improve from 1.26516
Epoch 3865/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4277 - val_loss: 1.2695 - val_accuracy: 0.4242

Epoch 03865: val_loss did not improve from 1.26516
Epoch 3866/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4284 - val_loss: 1.2681 - val_accuracy: 0.4266

Epoch 03866: val_loss did not improve from 1.26516
Epoch 3867/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4328 - val_loss: 1.2681 - val_accuracy: 0.4274

Epoch 03867: val_loss did not improve from 1.26516
Epoch 3868/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4332 - val_loss: 1.2702 - val_accuracy: 0.4171

Epoch 03868: val_loss did not improve from 1.26516
Epoch 3869/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4310 - val_loss: 1.2657 - val_accuracy: 0.4314

Epoch 03869: val_loss did not improve from 1.26516
Epoch 3870/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4295 - val_loss: 1.2676 - val_accuracy: 0.4242

Epoch 03870: val_loss did not improve from 1.26516
Epoch 3871/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4320 - val_loss: 1.2709 - val_accuracy: 0.4274

Epoch 03871: val_loss did not improve from 1.26516
Epoch 3872/10000
12/12 - 0s - loss: 1.2686 - accuracy: 0.4270 - val_loss: 1.2707 - val_accuracy: 0.4163

Epoch 03872: val_loss did not improve from 1.26516
Epoch 3873/10000
12/12 - 0s - loss: 1.2625 - accuracy: 0.4283 - val_loss: 1.2682 - val_accuracy: 0.4226

Epoch 03873: val_loss did not improve from 1.26516
Epoch 3874/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4273 - val_loss: 1.2691 - val_accuracy: 0.4234

Epoch 03874: val_loss did not improve from 1.26516
Epoch 3875/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4311 - val_loss: 1.2681 - val_accuracy: 0.4187

Epoch 03875: val_loss did not improve from 1.26516
Epoch 3876/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4296 - val_loss: 1.2720 - val_accuracy: 0.4274

Epoch 03876: val_loss did not improve from 1.26516
Epoch 3877/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4292 - val_loss: 1.2678 - val_accuracy: 0.4258

Epoch 03877: val_loss did not improve from 1.26516
Epoch 3878/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4315 - val_loss: 1.2732 - val_accuracy: 0.4274

Epoch 03878: val_loss did not improve from 1.26516
Epoch 3879/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4343 - val_loss: 1.2746 - val_accuracy: 0.4219

Epoch 03879: val_loss did not improve from 1.26516
Epoch 3880/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4299 - val_loss: 1.2675 - val_accuracy: 0.4179

Epoch 03880: val_loss did not improve from 1.26516
Epoch 3881/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4326 - val_loss: 1.2711 - val_accuracy: 0.4155

Epoch 03881: val_loss did not improve from 1.26516
Epoch 3882/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4317 - val_loss: 1.2682 - val_accuracy: 0.4211

Epoch 03882: val_loss did not improve from 1.26516
Epoch 3883/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4302 - val_loss: 1.2684 - val_accuracy: 0.4258

Epoch 03883: val_loss did not improve from 1.26516
Epoch 3884/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4291 - val_loss: 1.2688 - val_accuracy: 0.4242

Epoch 03884: val_loss did not improve from 1.26516
Epoch 3885/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4300 - val_loss: 1.2745 - val_accuracy: 0.4234

Epoch 03885: val_loss did not improve from 1.26516
Epoch 3886/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4247 - val_loss: 1.2685 - val_accuracy: 0.4171

Epoch 03886: val_loss did not improve from 1.26516
Epoch 3887/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4247 - val_loss: 1.2702 - val_accuracy: 0.4219

Epoch 03887: val_loss did not improve from 1.26516
Epoch 3888/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4269 - val_loss: 1.2680 - val_accuracy: 0.4346

Epoch 03888: val_loss did not improve from 1.26516
Epoch 3889/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4301 - val_loss: 1.2691 - val_accuracy: 0.4195

Epoch 03889: val_loss did not improve from 1.26516
Epoch 3890/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4311 - val_loss: 1.2708 - val_accuracy: 0.4250

Epoch 03890: val_loss did not improve from 1.26516
Epoch 3891/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4300 - val_loss: 1.2703 - val_accuracy: 0.4290

Epoch 03891: val_loss did not improve from 1.26516
Epoch 3892/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4266 - val_loss: 1.2756 - val_accuracy: 0.4195

Epoch 03892: val_loss did not improve from 1.26516
Epoch 3893/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4247 - val_loss: 1.2690 - val_accuracy: 0.4187

Epoch 03893: val_loss did not improve from 1.26516
Epoch 3894/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4328 - val_loss: 1.2713 - val_accuracy: 0.4195

Epoch 03894: val_loss did not improve from 1.26516
Epoch 3895/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4260 - val_loss: 1.2680 - val_accuracy: 0.4234

Epoch 03895: val_loss did not improve from 1.26516
Epoch 3896/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4294 - val_loss: 1.2675 - val_accuracy: 0.4338

Epoch 03896: val_loss did not improve from 1.26516
Epoch 3897/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4316 - val_loss: 1.2691 - val_accuracy: 0.4234

Epoch 03897: val_loss did not improve from 1.26516
Epoch 3898/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4256 - val_loss: 1.2700 - val_accuracy: 0.4242

Epoch 03898: val_loss did not improve from 1.26516
Epoch 3899/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4271 - val_loss: 1.2689 - val_accuracy: 0.4203

Epoch 03899: val_loss did not improve from 1.26516
Epoch 3900/10000
12/12 - 0s - loss: 1.2671 - accuracy: 0.4269 - val_loss: 1.2757 - val_accuracy: 0.4338

Epoch 03900: val_loss did not improve from 1.26516
Epoch 3901/10000
12/12 - 0s - loss: 1.2693 - accuracy: 0.4288 - val_loss: 1.2727 - val_accuracy: 0.4147

Epoch 03901: val_loss did not improve from 1.26516
Epoch 3902/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4246 - val_loss: 1.2732 - val_accuracy: 0.4187

Epoch 03902: val_loss did not improve from 1.26516
Epoch 3903/10000
12/12 - 0s - loss: 1.2713 - accuracy: 0.4235 - val_loss: 1.2760 - val_accuracy: 0.4250

Epoch 03903: val_loss did not improve from 1.26516
Epoch 3904/10000
12/12 - 0s - loss: 1.2677 - accuracy: 0.4254 - val_loss: 1.2732 - val_accuracy: 0.4234

Epoch 03904: val_loss did not improve from 1.26516
Epoch 3905/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4279 - val_loss: 1.2705 - val_accuracy: 0.4258

Epoch 03905: val_loss did not improve from 1.26516
Epoch 3906/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4305 - val_loss: 1.2686 - val_accuracy: 0.4322

Epoch 03906: val_loss did not improve from 1.26516
Epoch 3907/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4271 - val_loss: 1.2725 - val_accuracy: 0.4338

Epoch 03907: val_loss did not improve from 1.26516
Epoch 3908/10000
12/12 - 0s - loss: 1.2673 - accuracy: 0.4268 - val_loss: 1.2679 - val_accuracy: 0.4290

Epoch 03908: val_loss did not improve from 1.26516
Epoch 3909/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4295 - val_loss: 1.2682 - val_accuracy: 0.4250

Epoch 03909: val_loss did not improve from 1.26516
Epoch 3910/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4289 - val_loss: 1.2658 - val_accuracy: 0.4226

Epoch 03910: val_loss did not improve from 1.26516
Epoch 3911/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4299 - val_loss: 1.2682 - val_accuracy: 0.4274

Epoch 03911: val_loss did not improve from 1.26516
Epoch 3912/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4279 - val_loss: 1.2743 - val_accuracy: 0.4195

Epoch 03912: val_loss did not improve from 1.26516
Epoch 3913/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4284 - val_loss: 1.2696 - val_accuracy: 0.4258

Epoch 03913: val_loss did not improve from 1.26516
Epoch 3914/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4328 - val_loss: 1.2687 - val_accuracy: 0.4211

Epoch 03914: val_loss did not improve from 1.26516
Epoch 3915/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4262 - val_loss: 1.2744 - val_accuracy: 0.4234

Epoch 03915: val_loss did not improve from 1.26516
Epoch 3916/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4271 - val_loss: 1.2690 - val_accuracy: 0.4163

Epoch 03916: val_loss did not improve from 1.26516
Epoch 3917/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4311 - val_loss: 1.2688 - val_accuracy: 0.4290

Epoch 03917: val_loss did not improve from 1.26516
Epoch 3918/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4288 - val_loss: 1.2676 - val_accuracy: 0.4242

Epoch 03918: val_loss did not improve from 1.26516
Epoch 3919/10000
12/12 - 0s - loss: 1.2653 - accuracy: 0.4286 - val_loss: 1.2712 - val_accuracy: 0.4187

Epoch 03919: val_loss did not improve from 1.26516
Epoch 3920/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4261 - val_loss: 1.2719 - val_accuracy: 0.4338

Epoch 03920: val_loss did not improve from 1.26516
Epoch 3921/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4295 - val_loss: 1.2678 - val_accuracy: 0.4226

Epoch 03921: val_loss did not improve from 1.26516
Epoch 3922/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4311 - val_loss: 1.2673 - val_accuracy: 0.4290

Epoch 03922: val_loss did not improve from 1.26516
Epoch 3923/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4323 - val_loss: 1.2698 - val_accuracy: 0.4171

Epoch 03923: val_loss did not improve from 1.26516
Epoch 3924/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4266 - val_loss: 1.2693 - val_accuracy: 0.4314

Epoch 03924: val_loss did not improve from 1.26516
Epoch 3925/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4295 - val_loss: 1.2694 - val_accuracy: 0.4274

Epoch 03925: val_loss did not improve from 1.26516
Epoch 3926/10000
12/12 - 0s - loss: 1.2642 - accuracy: 0.4278 - val_loss: 1.2692 - val_accuracy: 0.4274

Epoch 03926: val_loss did not improve from 1.26516
Epoch 3927/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4279 - val_loss: 1.2695 - val_accuracy: 0.4219

Epoch 03927: val_loss did not improve from 1.26516
Epoch 3928/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4299 - val_loss: 1.2663 - val_accuracy: 0.4234

Epoch 03928: val_loss did not improve from 1.26516
Epoch 3929/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4306 - val_loss: 1.2706 - val_accuracy: 0.4163

Epoch 03929: val_loss did not improve from 1.26516
Epoch 3930/10000
12/12 - 0s - loss: 1.2670 - accuracy: 0.4233 - val_loss: 1.2696 - val_accuracy: 0.4226

Epoch 03930: val_loss did not improve from 1.26516
Epoch 3931/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4279 - val_loss: 1.2691 - val_accuracy: 0.4266

Epoch 03931: val_loss did not improve from 1.26516
Epoch 3932/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4332 - val_loss: 1.2681 - val_accuracy: 0.4147

Epoch 03932: val_loss did not improve from 1.26516
Epoch 3933/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4275 - val_loss: 1.2675 - val_accuracy: 0.4211

Epoch 03933: val_loss did not improve from 1.26516
Epoch 3934/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4343 - val_loss: 1.2699 - val_accuracy: 0.4274

Epoch 03934: val_loss did not improve from 1.26516
Epoch 3935/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4313 - val_loss: 1.2675 - val_accuracy: 0.4219

Epoch 03935: val_loss did not improve from 1.26516
Epoch 3936/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4273 - val_loss: 1.2661 - val_accuracy: 0.4226

Epoch 03936: val_loss did not improve from 1.26516
Epoch 3937/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4279 - val_loss: 1.2669 - val_accuracy: 0.4107

Epoch 03937: val_loss did not improve from 1.26516
Epoch 3938/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4264 - val_loss: 1.2655 - val_accuracy: 0.4211

Epoch 03938: val_loss did not improve from 1.26516
Epoch 3939/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4295 - val_loss: 1.2672 - val_accuracy: 0.4171

Epoch 03939: val_loss did not improve from 1.26516
Epoch 3940/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4292 - val_loss: 1.2659 - val_accuracy: 0.4258

Epoch 03940: val_loss did not improve from 1.26516
Epoch 3941/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4303 - val_loss: 1.2680 - val_accuracy: 0.4226

Epoch 03941: val_loss did not improve from 1.26516
Epoch 3942/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4280 - val_loss: 1.2677 - val_accuracy: 0.4274

Epoch 03942: val_loss did not improve from 1.26516
Epoch 3943/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4316 - val_loss: 1.2649 - val_accuracy: 0.4226

Epoch 03943: val_loss improved from 1.26516 to 1.26494, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3944/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4351 - val_loss: 1.2638 - val_accuracy: 0.4211

Epoch 03944: val_loss improved from 1.26494 to 1.26377, saving model to ./results/NN_thk_class/aggr_theta/ckpt_10
Epoch 3945/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4287 - val_loss: 1.2671 - val_accuracy: 0.4219

Epoch 03945: val_loss did not improve from 1.26377
Epoch 3946/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4265 - val_loss: 1.2665 - val_accuracy: 0.4179

Epoch 03946: val_loss did not improve from 1.26377
Epoch 3947/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4302 - val_loss: 1.2683 - val_accuracy: 0.4258

Epoch 03947: val_loss did not improve from 1.26377
Epoch 3948/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4325 - val_loss: 1.2697 - val_accuracy: 0.4266

Epoch 03948: val_loss did not improve from 1.26377
Epoch 3949/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4276 - val_loss: 1.2711 - val_accuracy: 0.4282

Epoch 03949: val_loss did not improve from 1.26377
Epoch 3950/10000
12/12 - 0s - loss: 1.2659 - accuracy: 0.4269 - val_loss: 1.2703 - val_accuracy: 0.4266

Epoch 03950: val_loss did not improve from 1.26377
Epoch 3951/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4277 - val_loss: 1.2690 - val_accuracy: 0.4171

Epoch 03951: val_loss did not improve from 1.26377
Epoch 3952/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4270 - val_loss: 1.2681 - val_accuracy: 0.4274

Epoch 03952: val_loss did not improve from 1.26377
Epoch 3953/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4296 - val_loss: 1.2669 - val_accuracy: 0.4282

Epoch 03953: val_loss did not improve from 1.26377
Epoch 3954/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4305 - val_loss: 1.2669 - val_accuracy: 0.4211

Epoch 03954: val_loss did not improve from 1.26377
Epoch 3955/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4300 - val_loss: 1.2712 - val_accuracy: 0.4219

Epoch 03955: val_loss did not improve from 1.26377
Epoch 3956/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4268 - val_loss: 1.2689 - val_accuracy: 0.4250

Epoch 03956: val_loss did not improve from 1.26377
Epoch 3957/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4285 - val_loss: 1.2667 - val_accuracy: 0.4274

Epoch 03957: val_loss did not improve from 1.26377
Epoch 3958/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4282 - val_loss: 1.2853 - val_accuracy: 0.4163

Epoch 03958: val_loss did not improve from 1.26377
Epoch 3959/10000
12/12 - 0s - loss: 1.2747 - accuracy: 0.4261 - val_loss: 1.2680 - val_accuracy: 0.4282

Epoch 03959: val_loss did not improve from 1.26377
Epoch 3960/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4274 - val_loss: 1.2689 - val_accuracy: 0.4290

Epoch 03960: val_loss did not improve from 1.26377
Epoch 3961/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4330 - val_loss: 1.2683 - val_accuracy: 0.4226

Epoch 03961: val_loss did not improve from 1.26377
Epoch 3962/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4303 - val_loss: 1.2692 - val_accuracy: 0.4274

Epoch 03962: val_loss did not improve from 1.26377
Epoch 3963/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4270 - val_loss: 1.2720 - val_accuracy: 0.4219

Epoch 03963: val_loss did not improve from 1.26377
Epoch 3964/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4294 - val_loss: 1.2678 - val_accuracy: 0.4242

Epoch 03964: val_loss did not improve from 1.26377
Epoch 3965/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4294 - val_loss: 1.2676 - val_accuracy: 0.4219

Epoch 03965: val_loss did not improve from 1.26377
Epoch 3966/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4336 - val_loss: 1.2692 - val_accuracy: 0.4226

Epoch 03966: val_loss did not improve from 1.26377
Epoch 3967/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4326 - val_loss: 1.2675 - val_accuracy: 0.4131

Epoch 03967: val_loss did not improve from 1.26377
Epoch 3968/10000
12/12 - 0s - loss: 1.2632 - accuracy: 0.4304 - val_loss: 1.2729 - val_accuracy: 0.4314

Epoch 03968: val_loss did not improve from 1.26377
Epoch 3969/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4266 - val_loss: 1.2677 - val_accuracy: 0.4258

Epoch 03969: val_loss did not improve from 1.26377
Epoch 3970/10000
12/12 - 0s - loss: 1.2654 - accuracy: 0.4272 - val_loss: 1.2688 - val_accuracy: 0.4242

Epoch 03970: val_loss did not improve from 1.26377
Epoch 3971/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4298 - val_loss: 1.2682 - val_accuracy: 0.4290

Epoch 03971: val_loss did not improve from 1.26377
Epoch 3972/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4299 - val_loss: 1.2695 - val_accuracy: 0.4195

Epoch 03972: val_loss did not improve from 1.26377
Epoch 3973/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4291 - val_loss: 1.2698 - val_accuracy: 0.4258

Epoch 03973: val_loss did not improve from 1.26377
Epoch 3974/10000
12/12 - 0s - loss: 1.2649 - accuracy: 0.4259 - val_loss: 1.2675 - val_accuracy: 0.4250

Epoch 03974: val_loss did not improve from 1.26377
Epoch 3975/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4254 - val_loss: 1.2755 - val_accuracy: 0.4330

Epoch 03975: val_loss did not improve from 1.26377
Epoch 3976/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4255 - val_loss: 1.2690 - val_accuracy: 0.4298

Epoch 03976: val_loss did not improve from 1.26377
Epoch 3977/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4282 - val_loss: 1.2673 - val_accuracy: 0.4155

Epoch 03977: val_loss did not improve from 1.26377
Epoch 3978/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4304 - val_loss: 1.2666 - val_accuracy: 0.4290

Epoch 03978: val_loss did not improve from 1.26377
Epoch 3979/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4294 - val_loss: 1.2674 - val_accuracy: 0.4290

Epoch 03979: val_loss did not improve from 1.26377
Epoch 3980/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4308 - val_loss: 1.2680 - val_accuracy: 0.4250

Epoch 03980: val_loss did not improve from 1.26377
Epoch 3981/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4333 - val_loss: 1.2663 - val_accuracy: 0.4250

Epoch 03981: val_loss did not improve from 1.26377
Epoch 3982/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4326 - val_loss: 1.2662 - val_accuracy: 0.4147

Epoch 03982: val_loss did not improve from 1.26377
Epoch 3983/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4291 - val_loss: 1.2702 - val_accuracy: 0.4195

Epoch 03983: val_loss did not improve from 1.26377
Epoch 3984/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4287 - val_loss: 1.2712 - val_accuracy: 0.4139

Epoch 03984: val_loss did not improve from 1.26377
Epoch 3985/10000
12/12 - 0s - loss: 1.2644 - accuracy: 0.4262 - val_loss: 1.2666 - val_accuracy: 0.4195

Epoch 03985: val_loss did not improve from 1.26377
Epoch 3986/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4262 - val_loss: 1.2673 - val_accuracy: 0.4147

Epoch 03986: val_loss did not improve from 1.26377
Epoch 3987/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4298 - val_loss: 1.2649 - val_accuracy: 0.4195

Epoch 03987: val_loss did not improve from 1.26377
Epoch 3988/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4310 - val_loss: 1.2675 - val_accuracy: 0.4274

Epoch 03988: val_loss did not improve from 1.26377
Epoch 3989/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4282 - val_loss: 1.2693 - val_accuracy: 0.4219

Epoch 03989: val_loss did not improve from 1.26377
Epoch 3990/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4263 - val_loss: 1.2718 - val_accuracy: 0.4282

Epoch 03990: val_loss did not improve from 1.26377
Epoch 3991/10000
12/12 - 0s - loss: 1.2650 - accuracy: 0.4266 - val_loss: 1.2681 - val_accuracy: 0.4195

Epoch 03991: val_loss did not improve from 1.26377
Epoch 3992/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4256 - val_loss: 1.2703 - val_accuracy: 0.4266

Epoch 03992: val_loss did not improve from 1.26377
Epoch 3993/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4254 - val_loss: 1.2704 - val_accuracy: 0.4250

Epoch 03993: val_loss did not improve from 1.26377
Epoch 3994/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4282 - val_loss: 1.2768 - val_accuracy: 0.4314

Epoch 03994: val_loss did not improve from 1.26377
Epoch 3995/10000
12/12 - 0s - loss: 1.2675 - accuracy: 0.4230 - val_loss: 1.2676 - val_accuracy: 0.4211

Epoch 03995: val_loss did not improve from 1.26377
Epoch 3996/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4256 - val_loss: 1.2674 - val_accuracy: 0.4187

Epoch 03996: val_loss did not improve from 1.26377
Epoch 3997/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4325 - val_loss: 1.2678 - val_accuracy: 0.4219

Epoch 03997: val_loss did not improve from 1.26377
Epoch 3998/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4292 - val_loss: 1.2686 - val_accuracy: 0.4266

Epoch 03998: val_loss did not improve from 1.26377
Epoch 3999/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4295 - val_loss: 1.2675 - val_accuracy: 0.4163

Epoch 03999: val_loss did not improve from 1.26377
Epoch 4000/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4287 - val_loss: 1.2668 - val_accuracy: 0.4362

Epoch 04000: val_loss did not improve from 1.26377
Epoch 4001/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4294 - val_loss: 1.2682 - val_accuracy: 0.4282

Epoch 04001: val_loss did not improve from 1.26377
Epoch 4002/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4323 - val_loss: 1.2678 - val_accuracy: 0.4298

Epoch 04002: val_loss did not improve from 1.26377
Epoch 4003/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4299 - val_loss: 1.2701 - val_accuracy: 0.4290

Epoch 04003: val_loss did not improve from 1.26377
Epoch 4004/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4311 - val_loss: 1.2690 - val_accuracy: 0.4258

Epoch 04004: val_loss did not improve from 1.26377
Epoch 4005/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4266 - val_loss: 1.2687 - val_accuracy: 0.4163

Epoch 04005: val_loss did not improve from 1.26377
Epoch 4006/10000
12/12 - 0s - loss: 1.2621 - accuracy: 0.4313 - val_loss: 1.2679 - val_accuracy: 0.4274

Epoch 04006: val_loss did not improve from 1.26377
Epoch 4007/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4331 - val_loss: 1.2693 - val_accuracy: 0.4298

Epoch 04007: val_loss did not improve from 1.26377
Epoch 4008/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4272 - val_loss: 1.2702 - val_accuracy: 0.4226

Epoch 04008: val_loss did not improve from 1.26377
Epoch 4009/10000
12/12 - 0s - loss: 1.2607 - accuracy: 0.4302 - val_loss: 1.2679 - val_accuracy: 0.4338

Epoch 04009: val_loss did not improve from 1.26377
Epoch 4010/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4280 - val_loss: 1.2695 - val_accuracy: 0.4274

Epoch 04010: val_loss did not improve from 1.26377
Epoch 4011/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4306 - val_loss: 1.2666 - val_accuracy: 0.4290

Epoch 04011: val_loss did not improve from 1.26377
Epoch 4012/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4288 - val_loss: 1.2721 - val_accuracy: 0.4346

Epoch 04012: val_loss did not improve from 1.26377
Epoch 4013/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4264 - val_loss: 1.2669 - val_accuracy: 0.4242

Epoch 04013: val_loss did not improve from 1.26377
Epoch 4014/10000
12/12 - 0s - loss: 1.2628 - accuracy: 0.4316 - val_loss: 1.2696 - val_accuracy: 0.4226

Epoch 04014: val_loss did not improve from 1.26377
Epoch 4015/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4311 - val_loss: 1.2684 - val_accuracy: 0.4226

Epoch 04015: val_loss did not improve from 1.26377
Epoch 4016/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4298 - val_loss: 1.2679 - val_accuracy: 0.4203

Epoch 04016: val_loss did not improve from 1.26377
Epoch 4017/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4235 - val_loss: 1.2681 - val_accuracy: 0.4362

Epoch 04017: val_loss did not improve from 1.26377
Epoch 4018/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4272 - val_loss: 1.2684 - val_accuracy: 0.4203

Epoch 04018: val_loss did not improve from 1.26377
Epoch 4019/10000
12/12 - 0s - loss: 1.2631 - accuracy: 0.4257 - val_loss: 1.2756 - val_accuracy: 0.4226

Epoch 04019: val_loss did not improve from 1.26377
Epoch 4020/10000
12/12 - 0s - loss: 1.2630 - accuracy: 0.4304 - val_loss: 1.2688 - val_accuracy: 0.4187

Epoch 04020: val_loss did not improve from 1.26377
Epoch 4021/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4287 - val_loss: 1.2691 - val_accuracy: 0.4171

Epoch 04021: val_loss did not improve from 1.26377
Epoch 4022/10000
12/12 - 0s - loss: 1.2606 - accuracy: 0.4340 - val_loss: 1.2659 - val_accuracy: 0.4266

Epoch 04022: val_loss did not improve from 1.26377
Epoch 4023/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4284 - val_loss: 1.2690 - val_accuracy: 0.4195

Epoch 04023: val_loss did not improve from 1.26377
Epoch 4024/10000
12/12 - 0s - loss: 1.2610 - accuracy: 0.4285 - val_loss: 1.2662 - val_accuracy: 0.4330

Epoch 04024: val_loss did not improve from 1.26377
Epoch 4025/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4329 - val_loss: 1.2705 - val_accuracy: 0.4226

Epoch 04025: val_loss did not improve from 1.26377
Epoch 4026/10000
12/12 - 0s - loss: 1.2684 - accuracy: 0.4226 - val_loss: 1.2702 - val_accuracy: 0.4234

Epoch 04026: val_loss did not improve from 1.26377
Epoch 4027/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4278 - val_loss: 1.2683 - val_accuracy: 0.4163

Epoch 04027: val_loss did not improve from 1.26377
Epoch 4028/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4322 - val_loss: 1.2666 - val_accuracy: 0.4203

Epoch 04028: val_loss did not improve from 1.26377
Epoch 4029/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4279 - val_loss: 1.2678 - val_accuracy: 0.4250

Epoch 04029: val_loss did not improve from 1.26377
Epoch 4030/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4290 - val_loss: 1.2692 - val_accuracy: 0.4234

Epoch 04030: val_loss did not improve from 1.26377
Epoch 4031/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4306 - val_loss: 1.2678 - val_accuracy: 0.4179

Epoch 04031: val_loss did not improve from 1.26377
Epoch 4032/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4269 - val_loss: 1.2711 - val_accuracy: 0.4250

Epoch 04032: val_loss did not improve from 1.26377
Epoch 4033/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4259 - val_loss: 1.2688 - val_accuracy: 0.4298

Epoch 04033: val_loss did not improve from 1.26377
Epoch 4034/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4302 - val_loss: 1.2681 - val_accuracy: 0.4258

Epoch 04034: val_loss did not improve from 1.26377
Epoch 4035/10000
12/12 - 0s - loss: 1.2634 - accuracy: 0.4312 - val_loss: 1.2662 - val_accuracy: 0.4250

Epoch 04035: val_loss did not improve from 1.26377
Epoch 4036/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4318 - val_loss: 1.2661 - val_accuracy: 0.4274

Epoch 04036: val_loss did not improve from 1.26377
Epoch 4037/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4296 - val_loss: 1.2703 - val_accuracy: 0.4298

Epoch 04037: val_loss did not improve from 1.26377
Epoch 4038/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4286 - val_loss: 1.2677 - val_accuracy: 0.4203

Epoch 04038: val_loss did not improve from 1.26377
Epoch 4039/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4268 - val_loss: 1.2708 - val_accuracy: 0.4322

Epoch 04039: val_loss did not improve from 1.26377
Epoch 4040/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4294 - val_loss: 1.2664 - val_accuracy: 0.4203

Epoch 04040: val_loss did not improve from 1.26377
Epoch 4041/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4293 - val_loss: 1.2693 - val_accuracy: 0.4131

Epoch 04041: val_loss did not improve from 1.26377
Epoch 4042/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4323 - val_loss: 1.2687 - val_accuracy: 0.4250

Epoch 04042: val_loss did not improve from 1.26377
Epoch 4043/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4318 - val_loss: 1.2691 - val_accuracy: 0.4242

Epoch 04043: val_loss did not improve from 1.26377
Epoch 4044/10000
12/12 - 0s - loss: 1.2619 - accuracy: 0.4306 - val_loss: 1.2687 - val_accuracy: 0.4274

Epoch 04044: val_loss did not improve from 1.26377
Epoch 4045/10000
12/12 - 0s - loss: 1.2668 - accuracy: 0.4260 - val_loss: 1.2651 - val_accuracy: 0.4250

Epoch 04045: val_loss did not improve from 1.26377
Epoch 4046/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4278 - val_loss: 1.2722 - val_accuracy: 0.4226

Epoch 04046: val_loss did not improve from 1.26377
Epoch 4047/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4324 - val_loss: 1.2677 - val_accuracy: 0.4226

Epoch 04047: val_loss did not improve from 1.26377
Epoch 4048/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4311 - val_loss: 1.2687 - val_accuracy: 0.4258

Epoch 04048: val_loss did not improve from 1.26377
Epoch 4049/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4304 - val_loss: 1.2664 - val_accuracy: 0.4250

Epoch 04049: val_loss did not improve from 1.26377
Epoch 4050/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4292 - val_loss: 1.2682 - val_accuracy: 0.4179

Epoch 04050: val_loss did not improve from 1.26377
Epoch 4051/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4315 - val_loss: 1.2729 - val_accuracy: 0.4219

Epoch 04051: val_loss did not improve from 1.26377
Epoch 4052/10000
12/12 - 0s - loss: 1.2681 - accuracy: 0.4233 - val_loss: 1.2689 - val_accuracy: 0.4226

Epoch 04052: val_loss did not improve from 1.26377
Epoch 4053/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4316 - val_loss: 1.2683 - val_accuracy: 0.4274

Epoch 04053: val_loss did not improve from 1.26377
Epoch 4054/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4285 - val_loss: 1.2675 - val_accuracy: 0.4242

Epoch 04054: val_loss did not improve from 1.26377
Epoch 4055/10000
12/12 - 0s - loss: 1.2592 - accuracy: 0.4294 - val_loss: 1.2698 - val_accuracy: 0.4234

Epoch 04055: val_loss did not improve from 1.26377
Epoch 4056/10000
12/12 - 0s - loss: 1.2603 - accuracy: 0.4280 - val_loss: 1.2680 - val_accuracy: 0.4250

Epoch 04056: val_loss did not improve from 1.26377
Epoch 4057/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4319 - val_loss: 1.2781 - val_accuracy: 0.4242

Epoch 04057: val_loss did not improve from 1.26377
Epoch 4058/10000
12/12 - 0s - loss: 1.2710 - accuracy: 0.4261 - val_loss: 1.2673 - val_accuracy: 0.4274

Epoch 04058: val_loss did not improve from 1.26377
Epoch 4059/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4299 - val_loss: 1.2670 - val_accuracy: 0.4234

Epoch 04059: val_loss did not improve from 1.26377
Epoch 4060/10000
12/12 - 0s - loss: 1.2598 - accuracy: 0.4317 - val_loss: 1.2685 - val_accuracy: 0.4242

Epoch 04060: val_loss did not improve from 1.26377
Epoch 4061/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4272 - val_loss: 1.2690 - val_accuracy: 0.4242

Epoch 04061: val_loss did not improve from 1.26377
Epoch 4062/10000
12/12 - 0s - loss: 1.2643 - accuracy: 0.4326 - val_loss: 1.2665 - val_accuracy: 0.4274

Epoch 04062: val_loss did not improve from 1.26377
Epoch 4063/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4309 - val_loss: 1.2709 - val_accuracy: 0.4234

Epoch 04063: val_loss did not improve from 1.26377
Epoch 4064/10000
12/12 - 0s - loss: 1.2667 - accuracy: 0.4278 - val_loss: 1.2670 - val_accuracy: 0.4274

Epoch 04064: val_loss did not improve from 1.26377
Epoch 4065/10000
12/12 - 0s - loss: 1.2652 - accuracy: 0.4285 - val_loss: 1.2683 - val_accuracy: 0.4219

Epoch 04065: val_loss did not improve from 1.26377
Epoch 4066/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4322 - val_loss: 1.2662 - val_accuracy: 0.4171

Epoch 04066: val_loss did not improve from 1.26377
Epoch 4067/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4295 - val_loss: 1.2776 - val_accuracy: 0.4282

Epoch 04067: val_loss did not improve from 1.26377
Epoch 4068/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4314 - val_loss: 1.2674 - val_accuracy: 0.4298

Epoch 04068: val_loss did not improve from 1.26377
Epoch 4069/10000
12/12 - 0s - loss: 1.2666 - accuracy: 0.4272 - val_loss: 1.2690 - val_accuracy: 0.4203

Epoch 04069: val_loss did not improve from 1.26377
Epoch 4070/10000
12/12 - 0s - loss: 1.2657 - accuracy: 0.4299 - val_loss: 1.2726 - val_accuracy: 0.4171

Epoch 04070: val_loss did not improve from 1.26377
Epoch 4071/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4275 - val_loss: 1.2684 - val_accuracy: 0.4123

Epoch 04071: val_loss did not improve from 1.26377
Epoch 4072/10000
12/12 - 0s - loss: 1.2613 - accuracy: 0.4318 - val_loss: 1.2671 - val_accuracy: 0.4242

Epoch 04072: val_loss did not improve from 1.26377
Epoch 4073/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4298 - val_loss: 1.2702 - val_accuracy: 0.4099

Epoch 04073: val_loss did not improve from 1.26377
Epoch 4074/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4310 - val_loss: 1.2689 - val_accuracy: 0.4226

Epoch 04074: val_loss did not improve from 1.26377
Epoch 4075/10000
12/12 - 0s - loss: 1.2596 - accuracy: 0.4313 - val_loss: 1.2695 - val_accuracy: 0.4282

Epoch 04075: val_loss did not improve from 1.26377
Epoch 4076/10000
12/12 - 0s - loss: 1.2605 - accuracy: 0.4321 - val_loss: 1.2673 - val_accuracy: 0.4195

Epoch 04076: val_loss did not improve from 1.26377
Epoch 4077/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4306 - val_loss: 1.2672 - val_accuracy: 0.4250

Epoch 04077: val_loss did not improve from 1.26377
Epoch 4078/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4275 - val_loss: 1.2696 - val_accuracy: 0.4266

Epoch 04078: val_loss did not improve from 1.26377
Epoch 4079/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4305 - val_loss: 1.2661 - val_accuracy: 0.4290

Epoch 04079: val_loss did not improve from 1.26377
Epoch 4080/10000
12/12 - 0s - loss: 1.2627 - accuracy: 0.4303 - val_loss: 1.2667 - val_accuracy: 0.4226

Epoch 04080: val_loss did not improve from 1.26377
Epoch 4081/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4306 - val_loss: 1.2689 - val_accuracy: 0.4242

Epoch 04081: val_loss did not improve from 1.26377
Epoch 4082/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4303 - val_loss: 1.2666 - val_accuracy: 0.4298

Epoch 04082: val_loss did not improve from 1.26377
Epoch 4083/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4307 - val_loss: 1.2657 - val_accuracy: 0.4211

Epoch 04083: val_loss did not improve from 1.26377
Epoch 4084/10000
12/12 - 0s - loss: 1.2588 - accuracy: 0.4292 - val_loss: 1.2682 - val_accuracy: 0.4282

Epoch 04084: val_loss did not improve from 1.26377
Epoch 4085/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4291 - val_loss: 1.2654 - val_accuracy: 0.4274

Epoch 04085: val_loss did not improve from 1.26377
Epoch 4086/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4274 - val_loss: 1.2854 - val_accuracy: 0.4250

Epoch 04086: val_loss did not improve from 1.26377
Epoch 4087/10000
12/12 - 0s - loss: 1.2729 - accuracy: 0.4223 - val_loss: 1.2661 - val_accuracy: 0.4226

Epoch 04087: val_loss did not improve from 1.26377
Epoch 4088/10000
12/12 - 0s - loss: 1.2647 - accuracy: 0.4248 - val_loss: 1.2715 - val_accuracy: 0.4203

Epoch 04088: val_loss did not improve from 1.26377
Epoch 4089/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4303 - val_loss: 1.2672 - val_accuracy: 0.4274

Epoch 04089: val_loss did not improve from 1.26377
Epoch 4090/10000
12/12 - 0s - loss: 1.2669 - accuracy: 0.4297 - val_loss: 1.2688 - val_accuracy: 0.4274

Epoch 04090: val_loss did not improve from 1.26377
Epoch 4091/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4302 - val_loss: 1.2804 - val_accuracy: 0.4314

Epoch 04091: val_loss did not improve from 1.26377
Epoch 4092/10000
12/12 - 0s - loss: 1.2645 - accuracy: 0.4317 - val_loss: 1.2688 - val_accuracy: 0.4179

Epoch 04092: val_loss did not improve from 1.26377
Epoch 4093/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4274 - val_loss: 1.2699 - val_accuracy: 0.4242

Epoch 04093: val_loss did not improve from 1.26377
Epoch 4094/10000
12/12 - 0s - loss: 1.2717 - accuracy: 0.4215 - val_loss: 1.2700 - val_accuracy: 0.4226

Epoch 04094: val_loss did not improve from 1.26377
Epoch 4095/10000
12/12 - 0s - loss: 1.2648 - accuracy: 0.4276 - val_loss: 1.2713 - val_accuracy: 0.4187

Epoch 04095: val_loss did not improve from 1.26377
Epoch 4096/10000
12/12 - 0s - loss: 1.2690 - accuracy: 0.4271 - val_loss: 1.2697 - val_accuracy: 0.4290

Epoch 04096: val_loss did not improve from 1.26377
Epoch 4097/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4297 - val_loss: 1.2674 - val_accuracy: 0.4258

Epoch 04097: val_loss did not improve from 1.26377
Epoch 4098/10000
12/12 - 0s - loss: 1.2609 - accuracy: 0.4311 - val_loss: 1.2728 - val_accuracy: 0.4266

Epoch 04098: val_loss did not improve from 1.26377
Epoch 4099/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4295 - val_loss: 1.2717 - val_accuracy: 0.4179

Epoch 04099: val_loss did not improve from 1.26377
Epoch 4100/10000
12/12 - 0s - loss: 1.2636 - accuracy: 0.4284 - val_loss: 1.2661 - val_accuracy: 0.4171

Epoch 04100: val_loss did not improve from 1.26377
Epoch 4101/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4295 - val_loss: 1.2673 - val_accuracy: 0.4314

Epoch 04101: val_loss did not improve from 1.26377
Epoch 4102/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4288 - val_loss: 1.2690 - val_accuracy: 0.4203

Epoch 04102: val_loss did not improve from 1.26377
Epoch 4103/10000
12/12 - 0s - loss: 1.2618 - accuracy: 0.4319 - val_loss: 1.2702 - val_accuracy: 0.4314

Epoch 04103: val_loss did not improve from 1.26377
Epoch 4104/10000
12/12 - 0s - loss: 1.2624 - accuracy: 0.4280 - val_loss: 1.2698 - val_accuracy: 0.4187

Epoch 04104: val_loss did not improve from 1.26377
Epoch 4105/10000
12/12 - 0s - loss: 1.2633 - accuracy: 0.4272 - val_loss: 1.2656 - val_accuracy: 0.4195

Epoch 04105: val_loss did not improve from 1.26377
Epoch 4106/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4348 - val_loss: 1.2658 - val_accuracy: 0.4346

Epoch 04106: val_loss did not improve from 1.26377
Epoch 4107/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4299 - val_loss: 1.2693 - val_accuracy: 0.4179

Epoch 04107: val_loss did not improve from 1.26377
Epoch 4108/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4295 - val_loss: 1.2682 - val_accuracy: 0.4266

Epoch 04108: val_loss did not improve from 1.26377
Epoch 4109/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4321 - val_loss: 1.2667 - val_accuracy: 0.4242

Epoch 04109: val_loss did not improve from 1.26377
Epoch 4110/10000
12/12 - 0s - loss: 1.2608 - accuracy: 0.4350 - val_loss: 1.2653 - val_accuracy: 0.4290

Epoch 04110: val_loss did not improve from 1.26377
Epoch 4111/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4315 - val_loss: 1.2731 - val_accuracy: 0.4298

Epoch 04111: val_loss did not improve from 1.26377
Epoch 4112/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4371 - val_loss: 1.2671 - val_accuracy: 0.4266

Epoch 04112: val_loss did not improve from 1.26377
Epoch 4113/10000
12/12 - 0s - loss: 1.2626 - accuracy: 0.4297 - val_loss: 1.2667 - val_accuracy: 0.4187

Epoch 04113: val_loss did not improve from 1.26377
Epoch 4114/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4292 - val_loss: 1.2669 - val_accuracy: 0.4226

Epoch 04114: val_loss did not improve from 1.26377
Epoch 4115/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4336 - val_loss: 1.2689 - val_accuracy: 0.4290

Epoch 04115: val_loss did not improve from 1.26377
Epoch 4116/10000
12/12 - 0s - loss: 1.2612 - accuracy: 0.4305 - val_loss: 1.2690 - val_accuracy: 0.4226

Epoch 04116: val_loss did not improve from 1.26377
Epoch 4117/10000
12/12 - 0s - loss: 1.2602 - accuracy: 0.4281 - val_loss: 1.2694 - val_accuracy: 0.4258

Epoch 04117: val_loss did not improve from 1.26377
Epoch 4118/10000
12/12 - 0s - loss: 1.2655 - accuracy: 0.4306 - val_loss: 1.2749 - val_accuracy: 0.4187

Epoch 04118: val_loss did not improve from 1.26377
Epoch 4119/10000
12/12 - 0s - loss: 1.2638 - accuracy: 0.4303 - val_loss: 1.2670 - val_accuracy: 0.4219

Epoch 04119: val_loss did not improve from 1.26377
Epoch 4120/10000
12/12 - 0s - loss: 1.2629 - accuracy: 0.4336 - val_loss: 1.2688 - val_accuracy: 0.4242

Epoch 04120: val_loss did not improve from 1.26377
Epoch 4121/10000
12/12 - 0s - loss: 1.2637 - accuracy: 0.4256 - val_loss: 1.2680 - val_accuracy: 0.4131

Epoch 04121: val_loss did not improve from 1.26377
Epoch 4122/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4255 - val_loss: 1.2680 - val_accuracy: 0.4219

Epoch 04122: val_loss did not improve from 1.26377
Epoch 4123/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4304 - val_loss: 1.2681 - val_accuracy: 0.4219

Epoch 04123: val_loss did not improve from 1.26377
Epoch 4124/10000
12/12 - 0s - loss: 1.2614 - accuracy: 0.4280 - val_loss: 1.2710 - val_accuracy: 0.4290

Epoch 04124: val_loss did not improve from 1.26377
Epoch 4125/10000
12/12 - 0s - loss: 1.2646 - accuracy: 0.4280 - val_loss: 1.2681 - val_accuracy: 0.4322

Epoch 04125: val_loss did not improve from 1.26377
Epoch 4126/10000
12/12 - 0s - loss: 1.2622 - accuracy: 0.4299 - val_loss: 1.2696 - val_accuracy: 0.4242

Epoch 04126: val_loss did not improve from 1.26377
Epoch 4127/10000
12/12 - 0s - loss: 1.2639 - accuracy: 0.4279 - val_loss: 1.2657 - val_accuracy: 0.4234

Epoch 04127: val_loss did not improve from 1.26377
Epoch 4128/10000
12/12 - 0s - loss: 1.2617 - accuracy: 0.4304 - val_loss: 1.2703 - val_accuracy: 0.4179

Epoch 04128: val_loss did not improve from 1.26377
Epoch 4129/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4328 - val_loss: 1.2678 - val_accuracy: 0.4226

Epoch 04129: val_loss did not improve from 1.26377
Epoch 4130/10000
12/12 - 0s - loss: 1.2594 - accuracy: 0.4299 - val_loss: 1.2668 - val_accuracy: 0.4171

Epoch 04130: val_loss did not improve from 1.26377
Epoch 4131/10000
12/12 - 0s - loss: 1.2595 - accuracy: 0.4295 - val_loss: 1.2690 - val_accuracy: 0.4155

Epoch 04131: val_loss did not improve from 1.26377
Epoch 4132/10000
12/12 - 0s - loss: 1.2600 - accuracy: 0.4312 - val_loss: 1.2672 - val_accuracy: 0.4219

Epoch 04132: val_loss did not improve from 1.26377
Epoch 4133/10000
12/12 - 0s - loss: 1.2597 - accuracy: 0.4319 - val_loss: 1.2670 - val_accuracy: 0.4195

Epoch 04133: val_loss did not improve from 1.26377
Epoch 4134/10000
12/12 - 0s - loss: 1.2601 - accuracy: 0.4318 - val_loss: 1.2660 - val_accuracy: 0.4226

Epoch 04134: val_loss did not improve from 1.26377
Epoch 4135/10000
12/12 - 0s - loss: 1.2590 - accuracy: 0.4326 - val_loss: 1.2671 - val_accuracy: 0.4155

Epoch 04135: val_loss did not improve from 1.26377
Epoch 4136/10000
12/12 - 0s - loss: 1.2616 - accuracy: 0.4286 - val_loss: 1.2662 - val_accuracy: 0.4258

Epoch 04136: val_loss did not improve from 1.26377
Epoch 4137/10000
12/12 - 0s - loss: 1.2663 - accuracy: 0.4311 - val_loss: 1.2691 - val_accuracy: 0.4187

Epoch 04137: val_loss did not improve from 1.26377
Epoch 4138/10000
12/12 - 0s - loss: 1.2623 - accuracy: 0.4289 - val_loss: 1.2651 - val_accuracy: 0.4290

Epoch 04138: val_loss did not improve from 1.26377
Epoch 4139/10000
12/12 - 0s - loss: 1.2641 - accuracy: 0.4341 - val_loss: 1.2724 - val_accuracy: 0.4274

Epoch 04139: val_loss did not improve from 1.26377
Epoch 4140/10000
12/12 - 0s - loss: 1.2615 - accuracy: 0.4326 - val_loss: 1.2688 - val_accuracy: 0.4242

Epoch 04140: val_loss did not improve from 1.26377
Epoch 4141/10000
12/12 - 0s - loss: 1.2604 - accuracy: 0.4318 - val_loss: 1.2670 - val_accuracy: 0.4203

Epoch 04141: val_loss did not improve from 1.26377
Epoch 4142/10000
12/12 - 0s - loss: 1.2589 - accuracy: 0.4318 - val_loss: 1.2681 - val_accuracy: 0.4203

Epoch 04142: val_loss did not improve from 1.26377
Epoch 4143/10000
12/12 - 0s - loss: 1.2611 - accuracy: 0.4295 - val_loss: 1.2664 - val_accuracy: 0.4187

Epoch 04143: val_loss did not improve from 1.26377
Epoch 4144/10000
12/12 - 0s - loss: 1.2620 - accuracy: 0.4295 - val_loss: 1.2668 - val_accuracy: 0.4234

Epoch 04144: val_loss did not improve from 1.26377
Epoch 04144: early stopping
