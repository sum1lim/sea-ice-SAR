Before undersampling: [(1, 2490), (2, 2438), (3, 5585)]
After undersampling: [(1, 2438), (2, 2438), (3, 2438)]
      mask  HH_0_0_x  HV_0_0_x  IA_0_0_x  HH_0_0_y  HV_0_0_y  IA_0_0_y         0         1         2    3         4    5         6         7         8         9        10   11        12   13        14        15
0        1  0.168627  0.070588  0.136885  0.188956  0.060264  0.136885  1.013115  0.160969  0.714933  0.0  0.959666  0.0  0.555706  0.607727  0.762693  0.257122  0.876032  0.0  0.673396  0.0  0.628327  0.495509
1        1  0.227451  0.105882  0.161740  0.202801  0.099880  0.161740  0.901091  0.117570  0.605982  0.0  0.875730  0.0  0.440391  0.595507  0.640773  0.152041  0.764271  0.0  0.641344  0.0  0.532715  0.525719
2        1  0.196078  0.074510  0.141540  0.223850  0.084754  0.141540  0.965628  0.164831  0.657878  0.0  0.915082  0.0  0.501081  0.583421  0.705437  0.208877  0.821245  0.0  0.664958  0.0  0.591832  0.514078
3        1  0.250980  0.070588  0.133505  0.235454  0.080672  0.133505  0.846937  0.244100  0.569521  0.0  0.800621  0.0  0.560033  0.289272  0.659756  0.286762  0.712270  0.0  0.553711  0.0  0.611404  0.236452
4        1  0.196078  0.070588  0.090944  0.215446  0.060264  0.090944  1.162442  0.276055  0.810996  0.0  1.084886  0.0  0.691957  0.630770  0.900510  0.370442  0.987719  0.0  0.769157  0.0  0.769581  0.516443
...    ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...       ...  ...       ...       ...       ...       ...       ...  ...       ...  ...       ...       ...
7309     3  0.537255  0.168627  0.134279  0.431453  0.161585  0.134279  0.777940  0.266452  0.498572  0.0  0.689310  0.0  0.506344  0.300244  0.641586  0.358685  0.606142  0.0  0.475495  0.0  0.538743  0.246268
7310     3  0.207843  0.054902  0.137705  0.272189  0.074030  0.137705  1.018972  0.212891  0.682999  0.0  0.940175  0.0  0.542466  0.543760  0.750062  0.235987  0.855921  0.0  0.690303  0.0  0.639362  0.491030
7311     3  0.333333  0.152941  0.138706  0.424330  0.162545  0.138706  0.922463  0.222746  0.619279  0.0  0.839944  0.0  0.539506  0.388152  0.693302  0.238758  0.777104  0.0  0.604032  0.0  0.617724  0.352435
7312     3  0.317647  0.098039  0.079011  0.324210  0.092037  0.079011  1.122456  0.346872  0.759321  0.0  0.996147  0.0  0.696744  0.476149  0.876679  0.376376  0.934077  0.0  0.725277  0.0  0.783004  0.431742
7313     3  0.317647  0.098039  0.134529  0.340856  0.097719  0.134529  0.911192  0.235641  0.578130  0.0  0.851375  0.0  0.504249  0.480897  0.683174  0.268706  0.727277  0.0  0.635871  0.0  0.587831  0.448341

[7314 rows x 23 columns]
Size of dataset: (7314, 23)
Classes: [1. 2. 3.]
*************************** Fold #: 1 ***************************
8/8 - 0s - 77ms/epoch - 10ms/step
Test accuracy: 0.6968826907301067
              precision    recall  f1-score   support

           0       0.71      0.74      0.73      2438
           1       0.64      0.68      0.66      2438
           2       0.75      0.67      0.71      2438

    accuracy                           0.70      7314
   macro avg       0.70      0.70      0.70      7314
weighted avg       0.70      0.70      0.70      7314

[[1. 2. 3.]]
[[74.2 16.2  9.7]
 [19.1 68.  12.9]
 [11.  22.1 66.9]]
*************************** Fold #: 2 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.7722176647525294
              precision    recall  f1-score   support

           0       0.74      0.77      0.76      2438
           1       0.76      0.80      0.78      2438
           2       0.82      0.74      0.78      2438

    accuracy                           0.77      7314
   macro avg       0.77      0.77      0.77      7314
weighted avg       0.77      0.77      0.77      7314

[[1. 2. 3.]]
[[77.4 11.2 11.4]
 [15.5 79.9  4.7]
 [11.6 13.9 74.4]]
*************************** Fold #: 3 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.7698933552091879
              precision    recall  f1-score   support

           0       0.74      0.76      0.75      2438
           1       0.80      0.75      0.77      2438
           2       0.78      0.80      0.79      2438

    accuracy                           0.77      7314
   macro avg       0.77      0.77      0.77      7314
weighted avg       0.77      0.77      0.77      7314

[[1. 2. 3.]]
[[76.2 10.  13.8]
 [15.9 75.   9.1]
 [11.5  8.7 79.7]]
*************************** Fold #: 4 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.7834290401968826
              precision    recall  f1-score   support

           0       0.74      0.80      0.77      2438
           1       0.82      0.76      0.79      2438
           2       0.79      0.80      0.79      2438

    accuracy                           0.78      7314
   macro avg       0.79      0.78      0.78      7314
weighted avg       0.79      0.78      0.78      7314

[[1. 2. 3.]]
[[79.6  8.9 11.5]
 [14.9 75.8  9.3]
 [12.5  7.9 79.6]]
*************************** Fold #: 5 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.6881323489198797
              precision    recall  f1-score   support

           0       0.69      0.76      0.72      2438
           1       0.70      0.55      0.61      2438
           2       0.68      0.76      0.72      2438

    accuracy                           0.69      7314
   macro avg       0.69      0.69      0.68      7314
weighted avg       0.69      0.69      0.68      7314

[[1. 2. 3.]]
[[75.6 11.1 13.2]
 [23.1 54.8 22.1]
 [11.1 12.9 76. ]]
*************************** Fold #: 6 ***************************
8/8 - 0s - 49ms/epoch - 6ms/step
Test accuracy: 0.7280557834290402
              precision    recall  f1-score   support

           0       0.73      0.76      0.75      2438
           1       0.69      0.76      0.72      2438
           2       0.77      0.67      0.72      2438

    accuracy                           0.73      7314
   macro avg       0.73      0.73      0.73      7314
weighted avg       0.73      0.73      0.73      7314

[[1. 2. 3.]]
[[75.8 13.  11.2]
 [16.  75.6  8.3]
 [11.6 21.5 66.9]]
*************************** Fold #: 7 ***************************
8/8 - 0s - 48ms/epoch - 6ms/step
Test accuracy: 0.7238173366147115
              precision    recall  f1-score   support

           0       0.71      0.75      0.73      2438
           1       0.66      0.75      0.71      2438
           2       0.82      0.66      0.73      2438

    accuracy                           0.72      7314
   macro avg       0.73      0.72      0.72      7314
weighted avg       0.73      0.72      0.72      7314

[[1. 2. 3.]]
[[75.5 17.1  7.4]
 [17.8 75.3  7. ]
 [12.6 21.  66.4]]
*************************** Fold #: 8 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.6652994257588187
              precision    recall  f1-score   support

           0       0.71      0.77      0.74      2438
           1       0.61      0.56      0.58      2438
           2       0.67      0.67      0.67      2438

    accuracy                           0.67      7314
   macro avg       0.66      0.67      0.66      7314
weighted avg       0.66      0.67      0.66      7314

[[1. 2. 3.]]
[[76.8 14.2  9. ]
 [20.1 55.6 24.2]
 [10.7 22.1 67.2]]
*************************** Fold #: 9 ***************************
8/8 - 0s - 49ms/epoch - 6ms/step
Test accuracy: 0.653677878042111
              precision    recall  f1-score   support

           0       0.72      0.74      0.73      2438
           1       0.63      0.45      0.52      2438
           2       0.61      0.77      0.68      2438

    accuracy                           0.65      7314
   macro avg       0.65      0.65      0.65      7314
weighted avg       0.65      0.65      0.65      7314

[[1. 2. 3.]]
[[74.4 13.4 12.2]
 [18.5 44.7 36.7]
 [10.5 12.6 77. ]]
*************************** Fold #: 10 ***************************
8/8 - 0s - 49ms/epoch - 6ms/step
Test accuracy: 0.6710418375717802
              precision    recall  f1-score   support

           0       0.71      0.77      0.74      2438
           1       0.62      0.59      0.60      2438
           2       0.68      0.65      0.67      2438

    accuracy                           0.67      7314
   macro avg       0.67      0.67      0.67      7314
weighted avg       0.67      0.67      0.67      7314

[[1. 2. 3.]]
[[77.2 14.9  8. ]
 [18.7 58.9 22.4]
 [13.4 21.4 65.2]]

Maximum accuracy: 0.7834290401968826

Average accuracy: 0.7152447361225047
Standard Deviation (accuracy): 0.04764481134333662
