Before undersampling: [(1, 2259), (2, 2395), (3, 5457)]
After undersampling: [(1, 2259), (2, 2259), (3, 2259)]
      mask  HH_0_0_x  HV_0_0_x  IA_0_0_x  HH_0_0_y  HV_0_0_y  IA_0_0_y    0         1         2         3         4         5         6         7    8         9        10        11        12        13        14        15
0        1  0.203922  0.109804  0.143143  0.194398  0.084514  0.143143  0.0  5.069291  2.812374  2.087871  2.508142  2.793135  2.177850  1.403742  0.0  5.033875  2.661724  1.589883  2.320903  2.842110  2.128695  1.384525
1        1  0.129412  0.082353  0.143131  0.193197  0.080752  0.143131  0.0  5.059154  2.544869  2.136570  2.489097  2.614758  2.209349  1.595846  0.0  5.043000  2.925472  1.491903  2.110747  2.964361  2.018728  1.085016
2        1  0.145098  0.090196  0.143120  0.201921  0.079072  0.143120  0.0  5.155295  2.831163  1.963682  2.213491  2.970191  2.246831  1.535742  0.0  5.026694  2.715747  1.903546  2.485172  2.769120  2.054157  1.169069
3        1  0.172549  0.050980  0.140716  0.148699  0.060504  0.140716  0.0  5.413149  2.806651  1.971777  2.498190  2.860096  2.191307  1.614491  0.0  5.303193  2.905775  1.675801  2.458358  3.078350  2.230098  1.359512
4        1  0.180392  0.050980  0.140705  0.135894  0.056343  0.140705  0.0  5.488761  2.982492  1.963243  2.332481  3.079403  2.274747  1.468309  0.0  5.355285  2.945332  1.839186  2.549531  3.072583  2.226768  1.391278
...    ...       ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ...       ...
6772     3  0.313725  0.070588  0.142846  0.249060  0.085394  0.142846  0.0  4.985814  2.554134  1.749708  2.326301  2.562561  1.964329  1.473960  0.0  4.776536  2.756993  1.704468  2.219548  2.822294  2.147882  1.053414
6773     3  0.345098  0.117647  0.134234  0.367747  0.110604  0.134234  0.0  4.591496  2.424206  1.936903  2.321160  2.334105  1.913395  1.077777  0.0  4.603917  2.580734  1.631827  1.939081  2.661275  2.060168  1.486257
6774     3  0.203922  0.078431  0.135019  0.304762  0.096519  0.135019  0.0  4.748074  2.730672  1.827408  2.043180  2.692698  2.005674  1.124082  0.0  4.571293  2.584487  1.379766  2.149269  2.709855  1.990362  1.132495
6775     3  0.266667  0.070588  0.142379  0.259224  0.090516  0.142379  0.0  4.775140  2.534457  1.854397  2.162387  2.629312  2.078862  1.364953  0.0  4.634089  2.601206  1.714942  2.183343  2.543034  1.945724  0.912486
6776     3  0.380392  0.184314  0.134985  0.394958  0.146859  0.134985  0.0  5.227432  3.048430  1.519724  2.111603  2.942285  1.940137  1.247749  0.0  4.960047  2.658108  1.860400  2.384400  2.748001  2.280414  1.304178

[6777 rows x 23 columns]
Size of dataset: (6777, 23)
Classes: [1. 2. 3.]
*************************** Fold #: 1 ***************************
7/7 - 0s - 76ms/epoch - 11ms/step
Test accuracy: 0.536963258078796
              precision    recall  f1-score   support

           0       0.65      0.79      0.71      2259
           1       0.13      0.02      0.04      2259
           2       0.50      0.80      0.61      2259

    accuracy                           0.54      6777
   macro avg       0.43      0.54      0.46      6777
weighted avg       0.43      0.54      0.46      6777

[[1. 2. 3.]]
[[78.6  8.6 12.8]
 [29.3  2.4 68.3]
 [12.5  7.5 80. ]]
*************************** Fold #: 2 ***************************
7/7 - 0s - 51ms/epoch - 7ms/step
Test accuracy: 0.6241699867197875
              precision    recall  f1-score   support

           0       0.73      0.77      0.75      2259
           1       0.59      0.35      0.44      2259
           2       0.55      0.76      0.64      2259

    accuracy                           0.62      6777
   macro avg       0.63      0.62      0.61      6777
weighted avg       0.63      0.62      0.61      6777

[[1. 2. 3.]]
[[76.7 13.8  9.5]
 [13.5 35.  51.5]
 [14.2 10.2 75.6]]
*************************** Fold #: 3 ***************************
7/7 - 0s - 49ms/epoch - 7ms/step
Test accuracy: 0.6328759037922385
              precision    recall  f1-score   support

           0       0.75      0.75      0.75      2259
           1       0.60      0.38      0.47      2259
           2       0.56      0.77      0.65      2259

    accuracy                           0.63      6777
   macro avg       0.64      0.63      0.62      6777
weighted avg       0.64      0.63      0.62      6777

[[1. 2. 3.]]
[[74.5 14.5 11. ]
 [13.2 38.  48.7]
 [12.  10.7 77.3]]
*************************** Fold #: 4 ***************************
7/7 - 0s - 49ms/epoch - 7ms/step
Test accuracy: 0.6620923712557178
              precision    recall  f1-score   support

           0       0.81      0.72      0.76      2259
           1       0.65      0.49      0.56      2259
           2       0.57      0.78      0.66      2259

    accuracy                           0.66      6777
   macro avg       0.68      0.66      0.66      6777
weighted avg       0.68      0.66      0.66      6777

[[1. 2. 3.]]
[[72.2 17.4 10.4]
 [ 3.6 48.8 47.6]
 [13.7  8.6 77.6]]
*************************** Fold #: 5 ***************************
7/7 - 0s - 50ms/epoch - 7ms/step
Test accuracy: 0.5577689243027888
              precision    recall  f1-score   support

           0       0.65      0.79      0.71      2259
           1       0.35      0.09      0.15      2259
           2       0.52      0.79      0.63      2259

    accuracy                           0.56      6777
   macro avg       0.51      0.56      0.50      6777
weighted avg       0.51      0.56      0.50      6777

[[1. 2. 3.]]
[[79.2  9.4 11.4]
 [29.1  9.2 61.7]
 [13.3  7.7 79. ]]
*************************** Fold #: 6 ***************************
7/7 - 0s - 49ms/epoch - 7ms/step
Test accuracy: 0.6908661649697506
              precision    recall  f1-score   support

           0       0.76      0.72      0.74      2259
           1       0.71      0.55      0.62      2259
           2       0.63      0.80      0.70      2259

    accuracy                           0.69      6777
   macro avg       0.70      0.69      0.69      6777
weighted avg       0.70      0.69      0.69      6777

[[1. 2. 3.]]
[[71.9 14.2 13.9]
 [11.3 55.1 33.6]
 [11.5  8.2 80.3]]
*************************** Fold #: 7 ***************************
7/7 - 0s - 48ms/epoch - 7ms/step
Test accuracy: 0.7003098716246127
              precision    recall  f1-score   support

           0       0.76      0.76      0.76      2259
           1       0.72      0.56      0.63      2259
           2       0.64      0.78      0.70      2259

    accuracy                           0.70      6777
   macro avg       0.71      0.70      0.70      6777
weighted avg       0.71      0.70      0.70      6777

[[1. 2. 3.]]
[[75.7 12.6 11.6]
 [11.4 56.3 32.3]
 [12.9  9.  78.1]]
*************************** Fold #: 8 ***************************
7/7 - 0s - 49ms/epoch - 7ms/step
Test accuracy: 0.6997196399586838
              precision    recall  f1-score   support

           0       0.82      0.70      0.75      2259
           1       0.70      0.62      0.66      2259
           2       0.62      0.78      0.69      2259

    accuracy                           0.70      6777
   macro avg       0.71      0.70      0.70      6777
weighted avg       0.71      0.70      0.70      6777

[[1. 2. 3.]]
[[69.9 17.4 12.7]
 [ 3.1 62.3 34.7]
 [12.7  9.6 77.7]]
*************************** Fold #: 9 ***************************
7/7 - 0s - 48ms/epoch - 7ms/step
Test accuracy: 0.7433967832374206
              precision    recall  f1-score   support

           0       0.82      0.70      0.76      2259
           1       0.76      0.73      0.74      2259
           2       0.67      0.80      0.73      2259

    accuracy                           0.74      6777
   macro avg       0.75      0.74      0.74      6777
weighted avg       0.75      0.74      0.74      6777

[[1. 2. 3.]]
[[70.4 14.1 15.5]
 [ 4.1 73.1 22.8]
 [11.2  9.3 79.5]]
*************************** Fold #: 10 ***************************
7/7 - 0s - 48ms/epoch - 7ms/step
Test accuracy: 0.705917072450937
              precision    recall  f1-score   support

           0       0.81      0.74      0.77      2259
           1       0.73      0.59      0.65      2259
           2       0.62      0.80      0.70      2259

    accuracy                           0.71      6777
   macro avg       0.72      0.71      0.71      6777
weighted avg       0.72      0.71      0.71      6777

[[1. 2. 3.]]
[[73.5 13.9 12.5]
 [ 4.5 58.7 36.8]
 [12.6  7.8 79.6]]

Maximum accuracy: 0.7433967832374206

Average accuracy: 0.6554079976390733
Standard Deviation (accuracy): 0.06718209830484788
