Before undersampling: [(1, 2259), (2, 2395), (3, 5457)]
After undersampling: [(1, 2259), (2, 2259), (3, 2259)]
      mask  HH_0_0_x  HV_0_0_x  IA_0_0_x  HH_0_0_y  HV_0_0_y  IA_0_0_y         0    1         2         3         4    5         6         7         8    9        10        11        12   13        14        15
0        1  0.203922  0.109804  0.143143  0.194398  0.084514  0.143143  1.901462  0.0  3.241011  1.764227  1.563381  0.0  3.215747  0.385739  1.535898  0.0  3.735208  2.144640  1.472826  0.0  2.468049  0.825479
1        1  0.129412  0.082353  0.143131  0.193197  0.080752  0.143131  1.696345  0.0  3.686492  2.205699  1.285908  0.0  2.331687  0.525611  1.626778  0.0  3.347485  1.667664  1.689008  0.0  3.012212  0.885982
2        1  0.145098  0.090196  0.143120  0.201921  0.079072  0.143120  1.661516  0.0  3.586307  1.936208  1.220274  0.0  2.635402  0.896429  1.704687  0.0  3.204724  1.725183  1.707576  0.0  2.770490  0.141773
3        1  0.172549  0.050980  0.140716  0.148699  0.060504  0.140716  1.390548  0.0  3.383763  1.953542  1.484204  0.0  2.297174  0.534774  1.519867  0.0  3.140671  1.783848  1.506669  0.0  2.662942  0.840357
4        1  0.180392  0.050980  0.140705  0.135894  0.056343  0.140705  1.437158  0.0  3.288158  1.722406  1.307603  0.0  2.754967  0.872971  1.608347  0.0  3.252567  1.799813  1.671812  0.0  2.478476  0.653155
...    ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...       ...  ...       ...       ...       ...  ...       ...       ...       ...  ...       ...       ...
6772     3  0.345098  0.094118  0.135941  0.351020  0.116527  0.135941  1.297145  0.0  3.509983  2.082369  1.228686  0.0  2.429742  0.825546  1.419656  0.0  3.369256  2.086959  1.601160  0.0  2.406263  1.003874
6773     3  0.164706  0.035294  0.079558  0.176070  0.043057  0.079558  1.601101  0.0  3.434321  1.755677  1.478667  0.0  2.285533  0.407719  1.597494  0.0  3.310731  1.840561  1.464097  0.0  2.702827  1.051143
6774     3  0.419608  0.203922  0.166214  0.426170  0.207043  0.166214  1.581605  0.0  3.300250  1.764244  1.094862  0.0  2.711635  0.808023  1.478256  0.0  3.200248  1.819621  1.245957  0.0  2.809633  0.896160
6775     3  0.415686  0.086275  0.133676  0.334614  0.122049  0.133676  1.609350  0.0  3.318498  1.581141  1.349573  0.0  2.722978  0.806696  1.250838  0.0  3.455639  2.207263  1.505096  0.0  1.990319  0.464528
6776     3  0.270588  0.090196  0.095278  0.333653  0.091717  0.095278  1.816135  0.0  3.827580  2.066214  1.231488  0.0  2.917428  0.600383  1.662243  0.0  3.577708  1.896769  2.011218  0.0  3.007109  0.434095

[6777 rows x 23 columns]
Size of dataset: (6777, 23)
Classes: [1. 2. 3.]
*************************** Fold #: 1 ***************************
7/7 - 0s - 78ms/epoch - 11ms/step
Test accuracy: 0.5627858934631843
              precision    recall  f1-score   support

           0       0.63      0.79      0.70      2259
           1       0.42      0.13      0.19      2259
           2       0.54      0.78      0.63      2259

    accuracy                           0.56      6777
   macro avg       0.53      0.56      0.51      6777
weighted avg       0.53      0.56      0.51      6777

[[1. 2. 3.]]
[[78.5  9.3 12.2]
 [32.1 12.5 55.3]
 [14.3  7.9 77.8]]
*************************** Fold #: 2 ***************************
7/7 - 0s - 52ms/epoch - 7ms/step
Test accuracy: 0.5422753430721559
              precision    recall  f1-score   support

           0       0.65      0.78      0.71      2259
           1       0.27      0.08      0.12      2259
           2       0.51      0.77      0.62      2259

    accuracy                           0.54      6777
   macro avg       0.48      0.54      0.48      6777
weighted avg       0.48      0.54      0.48      6777

[[1. 2. 3.]]
[[77.7 11.3 11. ]
 [29.8  8.1 62.1]
 [12.6 10.5 76.9]]
*************************** Fold #: 3 ***************************
7/7 - 0s - 51ms/epoch - 7ms/step
Test accuracy: 0.6886527962225173
              precision    recall  f1-score   support

           0       0.76      0.76      0.76      2259
           1       0.71      0.55      0.62      2259
           2       0.62      0.75      0.68      2259

    accuracy                           0.69      6777
   macro avg       0.70      0.69      0.69      6777
weighted avg       0.70      0.69      0.69      6777

[[1. 2. 3.]]
[[76.2 12.9 10.9]
 [ 9.2 54.9 35.9]
 [14.7  9.8 75.5]]
*************************** Fold #: 4 ***************************
7/7 - 0s - 51ms/epoch - 7ms/step
Test accuracy: 0.5632285672126309
              precision    recall  f1-score   support

           0       0.68      0.73      0.71      2259
           1       0.41      0.17      0.25      2259
           2       0.52      0.78      0.63      2259

    accuracy                           0.56      6777
   macro avg       0.54      0.56      0.53      6777
weighted avg       0.54      0.56      0.53      6777

[[1. 2. 3.]]
[[73.1 14.1 12.8]
 [23.2 17.4 59.4]
 [11.  10.6 78.4]]
*************************** Fold #: 5 ***************************
7/7 - 0s - 51ms/epoch - 7ms/step
Test accuracy: 0.5781319167773351
              precision    recall  f1-score   support

           0       0.71      0.77      0.74      2259
           1       0.45      0.23      0.31      2259
           2       0.53      0.74      0.61      2259

    accuracy                           0.58      6777
   macro avg       0.56      0.58      0.55      6777
weighted avg       0.56      0.58      0.55      6777

[[1. 2. 3.]]
[[76.7 13.6  9.7]
 [20.1 23.2 56.7]
 [11.6 14.8 73.5]]
*************************** Fold #: 6 ***************************
7/7 - 0s - 50ms/epoch - 7ms/step
Test accuracy: 0.6012985096650435
              precision    recall  f1-score   support

           0       0.71      0.76      0.73      2259
           1       0.54      0.27      0.36      2259
           2       0.54      0.77      0.64      2259

    accuracy                           0.60      6777
   macro avg       0.60      0.60      0.58      6777
weighted avg       0.60      0.60      0.58      6777

[[1. 2. 3.]]
[[76.  12.3 11.7]
 [19.3 27.1 53.6]
 [12.3 10.4 77.3]]
*************************** Fold #: 7 ***************************
7/7 - 0s - 51ms/epoch - 7ms/step
Test accuracy: 0.55319462889184
              precision    recall  f1-score   support

           0       0.64      0.76      0.70      2259
           1       0.34      0.10      0.15      2259
           2       0.52      0.80      0.63      2259

    accuracy                           0.55      6777
   macro avg       0.50      0.55      0.49      6777
weighted avg       0.50      0.55      0.49      6777

[[1. 2. 3.]]
[[75.9 10.  14.1]
 [31.2  9.8 59.1]
 [11.1  8.7 80.3]]
*************************** Fold #: 8 ***************************
7/7 - 0s - 50ms/epoch - 7ms/step
Test accuracy: 0.5443411539029069
              precision    recall  f1-score   support

           0       0.67      0.73      0.70      2259
           1       0.33      0.13      0.19      2259
           2       0.51      0.77      0.62      2259

    accuracy                           0.54      6777
   macro avg       0.50      0.54      0.50      6777
weighted avg       0.50      0.54      0.50      6777

[[1. 2. 3.]]
[[72.8 14.6 12.6]
 [26.3 13.2 60.5]
 [10.3 12.4 77.2]]
*************************** Fold #: 9 ***************************
7/7 - 0s - 50ms/epoch - 7ms/step
Test accuracy: 0.6879150066401063
              precision    recall  f1-score   support

           0       0.76      0.78      0.77      2259
           1       0.73      0.51      0.60      2259
           2       0.61      0.77      0.68      2259

    accuracy                           0.69      6777
   macro avg       0.70      0.69      0.68      6777
weighted avg       0.70      0.69      0.68      6777

[[1. 2. 3.]]
[[78.   9.7 12.4]
 [11.  51.4 37.6]
 [13.4  9.6 77. ]]
*************************** Fold #: 10 ***************************
7/7 - 0s - 50ms/epoch - 7ms/step
Test accuracy: 0.5585067138851999
              precision    recall  f1-score   support

           0       0.67      0.74      0.70      2259
           1       0.39      0.13      0.19      2259
           2       0.52      0.81      0.63      2259

    accuracy                           0.56      6777
   macro avg       0.53      0.56      0.51      6777
weighted avg       0.53      0.56      0.51      6777

[[1. 2. 3.]]
[[73.6 11.  15.4]
 [26.5 12.7 60.8]
 [10.2  8.5 81.3]]

Maximum accuracy: 0.6886527962225173

Average accuracy: 0.588033052973292
Standard Deviation (accuracy): 0.0554934374182392
