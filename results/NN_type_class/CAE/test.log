Before undersampling: [(1, 2490), (2, 2438), (3, 5585)]
After undersampling: [(1, 2438), (2, 2438), (3, 2438)]
      mask  HH_0_0_x  HV_0_0_x  IA_0_0_x  HH_0_0_y  HV_0_0_y  IA_0_0_y         0         1         2    3         4         5         6         7         8         9        10   11        12        13        14        15
0        1  0.235294  0.066667  0.161478  0.165826  0.090916  0.161478  0.300503  0.226659  0.595614  0.0  0.221666  0.086815  0.497707  0.150873  0.237230  0.220220  0.572508  0.0  0.169875  0.070699  0.480416  0.152632
1        1  0.247059  0.090196  0.161921  0.175670  0.091477  0.161921  0.309109  0.226429  0.603964  0.0  0.225494  0.102487  0.510385  0.143203  0.244369  0.213274  0.580002  0.0  0.176003  0.075461  0.497633  0.147959
2        1  0.164706  0.070588  0.137329  0.191837  0.069148  0.137329  0.543333  0.396514  0.824775  0.0  0.332312  0.085728  0.655191  0.230458  0.446286  0.385101  0.810903  0.0  0.309393  0.060747  0.639552  0.251813
3        1  0.215686  0.086275  0.131347  0.193677  0.083713  0.131347  0.378578  0.295166  0.749096  0.0  0.336174  0.109306  0.650927  0.194129  0.315174  0.301982  0.730392  0.0  0.272555  0.125148  0.626815  0.206452
4        1  0.227451  0.062745  0.137944  0.202961  0.069948  0.137944  0.406091  0.332787  0.739866  0.0  0.328683  0.092741  0.627607  0.218326  0.319462  0.315595  0.728150  0.0  0.300526  0.080797  0.603123  0.230002
...    ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...
7309     3  0.254902  0.145098  0.141081  0.324930  0.113005  0.141081  0.508945  0.434984  0.772252  0.0  0.424460  0.083745  0.668212  0.192932  0.425739  0.433054  0.765611  0.0  0.406943  0.083373  0.647931  0.221117
7310     3  0.423529  0.113725  0.137659  0.429212  0.117807  0.137659  0.702971  0.541432  0.903575  0.0  0.396417  0.108539  0.739752  0.220355  0.571106  0.495440  0.910525  0.0  0.467834  0.081239  0.713941  0.246033
7311     3  0.321569  0.062745  0.134871  0.312605  0.090036  0.134871  0.550676  0.401271  0.853694  0.0  0.466746  0.109389  0.770276  0.195047  0.523823  0.448648  0.856816  0.0  0.435212  0.220103  0.725650  0.233354
7312     3  0.329412  0.141176  0.119129  0.380312  0.130692  0.119129  0.680789  0.535509  0.953772  0.0  0.541916  0.172484  0.835898  0.217116  0.582078  0.525334  0.951627  0.0  0.545748  0.178747  0.809837  0.253116
7313     3  0.274510  0.113725  0.139776  0.443457  0.133413  0.139776  0.599323  0.489874  0.861750  0.0  0.626448  0.172629  0.832462  0.190884  0.541505  0.515624  0.856621  0.0  0.606037  0.229803  0.797276  0.224407

[7314 rows x 23 columns]
Size of dataset: (7314, 23)
Classes: [1. 2. 3.]
*************************** Fold #: 1 ***************************
8/8 - 0s - 78ms/epoch - 10ms/step
Test accuracy: 0.670494941208641
              precision    recall  f1-score   support

           0       0.71      0.73      0.72      2438
           1       0.64      0.53      0.58      2438
           2       0.66      0.76      0.70      2438

    accuracy                           0.67      7314
   macro avg       0.67      0.67      0.67      7314
weighted avg       0.67      0.67      0.67      7314

[[1. 2. 3.]]
[[72.5 16.6 10.9]
 [18.7 52.9 28.4]
 [11.1 13.2 75.8]]
*************************** Fold #: 2 ***************************
8/8 - 0s - 51ms/epoch - 6ms/step
Test accuracy: 0.5823079026524474
              precision    recall  f1-score   support

           0       0.64      0.82      0.72      2438
           1       0.47      0.15      0.22      2438
           2       0.56      0.78      0.65      2438

    accuracy                           0.58      7314
   macro avg       0.55      0.58      0.53      7314
weighted avg       0.55      0.58      0.53      7314

[[1. 2. 3.]]
[[82.   8.4  9.6]
 [32.8 14.6 52.6]
 [13.5  8.3 78.1]]
*************************** Fold #: 3 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.667760459392945
              precision    recall  f1-score   support

           0       0.73      0.75      0.74      2438
           1       0.67      0.46      0.55      2438
           2       0.61      0.79      0.69      2438

    accuracy                           0.67      7314
   macro avg       0.67      0.67      0.66      7314
weighted avg       0.67      0.67      0.66      7314

[[1. 2. 3.]]
[[75.1 13.9 11. ]
 [15.2 46.1 38.7]
 [12.3  8.5 79.1]]
*************************** Fold #: 4 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.7491112934098988
              precision    recall  f1-score   support

           0       0.75      0.74      0.75      2438
           1       0.77      0.71      0.74      2438
           2       0.73      0.79      0.76      2438

    accuracy                           0.75      7314
   macro avg       0.75      0.75      0.75      7314
weighted avg       0.75      0.75      0.75      7314

[[1. 2. 3.]]
[[74.4 11.6 14.1]
 [13.3 71.2 15.5]
 [11.4  9.4 79.2]]
*************************** Fold #: 5 ***************************
8/8 - 0s - 51ms/epoch - 6ms/step
Test accuracy: 0.7172545802570413
              precision    recall  f1-score   support

           0       0.71      0.77      0.74      2438
           1       0.72      0.66      0.69      2438
           2       0.73      0.72      0.72      2438

    accuracy                           0.72      7314
   macro avg       0.72      0.72      0.72      7314
weighted avg       0.72      0.72      0.72      7314

[[1. 2. 3.]]
[[77.4 13.6  9.1]
 [16.2 65.5 18.3]
 [15.5 12.1 72.3]]
*************************** Fold #: 6 ***************************
8/8 - 0s - 51ms/epoch - 6ms/step
Test accuracy: 0.6719989062072738
              precision    recall  f1-score   support

           0       0.71      0.76      0.73      2438
           1       0.66      0.51      0.58      2438
           2       0.65      0.74      0.69      2438

    accuracy                           0.67      7314
   macro avg       0.67      0.67      0.67      7314
weighted avg       0.67      0.67      0.67      7314

[[1. 2. 3.]]
[[76.3 13.8  9.9]
 [18.5 51.  30.5]
 [13.1 12.6 74.3]]
*************************** Fold #: 7 ***************************
8/8 - 0s - 53ms/epoch - 7ms/step
Test accuracy: 0.7126059611703582
              precision    recall  f1-score   support

           0       0.74      0.77      0.75      2438
           1       0.71      0.58      0.64      2438
           2       0.69      0.79      0.74      2438

    accuracy                           0.71      7314
   macro avg       0.71      0.71      0.71      7314
weighted avg       0.71      0.71      0.71      7314

[[1. 2. 3.]]
[[76.7 14.1  9.1]
 [15.5 58.1 26.4]
 [11.4  9.6 78.9]]
*************************** Fold #: 8 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.5844954881050041
              precision    recall  f1-score   support

           0       0.67      0.75      0.71      2438
           1       0.52      0.20      0.29      2438
           2       0.54      0.80      0.65      2438

    accuracy                           0.58      7314
   macro avg       0.57      0.58      0.55      7314
weighted avg       0.57      0.58      0.55      7314

[[1. 2. 3.]]
[[74.9 10.5 14.6]
 [25.9 20.1 54. ]
 [11.3  8.3 80.4]]
*************************** Fold #: 9 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.6576428766748701
              precision    recall  f1-score   support

           0       0.72      0.72      0.72      2438
           1       0.60      0.54      0.57      2438
           2       0.65      0.71      0.68      2438

    accuracy                           0.66      7314
   macro avg       0.66      0.66      0.66      7314
weighted avg       0.66      0.66      0.66      7314

[[1. 2. 3.]]
[[72.4 18.4  9.2]
 [16.9 54.3 28.8]
 [11.4 17.9 70.7]]
*************************** Fold #: 10 ***************************
8/8 - 0s - 50ms/epoch - 6ms/step
Test accuracy: 0.6871752802843861
              precision    recall  f1-score   support

           0       0.75      0.72      0.74      2438
           1       0.65      0.58      0.61      2438
           2       0.66      0.77      0.71      2438

    accuracy                           0.69      7314
   macro avg       0.69      0.69      0.69      7314
weighted avg       0.69      0.69      0.69      7314

[[1. 2. 3.]]
[[71.6 18.5  9.9]
 [12.4 57.7 29.9]
 [10.8 12.3 76.8]]

Maximum accuracy: 0.7491112934098988

Average accuracy: 0.6700847689362865
Standard Deviation (accuracy): 0.053504577733613605
