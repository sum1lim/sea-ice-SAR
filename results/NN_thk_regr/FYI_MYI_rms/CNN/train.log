[0.772456 0.95876  1.14052  1.32228  1.50404  1.6858   1.86756  2.04932
 2.23108  2.41284  2.5946   2.77636  2.95812  3.13988  3.32164  3.5034
 3.68516  3.86692  4.04868  4.23044  4.4122   4.59396  4.77572  4.95748
 5.13924  5.321   ]
Before undersampling: [(0, 11), (1, 42), (2, 118), (3, 381), (4, 1164), (5, 3274), (6, 3623), (7, 2488), (8, 2344), (9, 2104), (10, 1890), (11, 1864), (12, 1630), (13, 1353), (14, 1175), (15, 902), (16, 775), (17, 649), (18, 517), (19, 434), (20, 356), (21, 317), (22, 293), (23, 225), (24, 200)]
After undersampling: [(0, 11), (1, 21), (2, 34), (3, 48), (4, 130), (5, 418), (6, 751), (7, 616), (8, 236), (9, 159), (10, 181), (11, 267), (12, 120), (13, 71), (14, 101), (15, 125), (16, 98), (17, 21), (18, 72), (19, 11), (20, 10), (21, 23), (22, 32), (23, 9), (24, 25)]
      label  HH_0_0_x  HV_0_0_x  IA_0_0_x       FYI      DFYI       MYI         rms  HH_0_0_y  HV_0_0_y  IA_0_0_y                                                CNN
0     0.858  0.184314  0.054902  0.108219  0.677054  0.244229  0.078717  114.079010  0.202881  0.062025  0.108219  [[[[0.2274509803921568], [0.1081809698366651],...
1     0.922  0.219608  0.043137  0.095634  0.054778  0.917930  0.027292  159.825714  0.221769  0.050900  0.095634  [[[[0.1215686274509803], [0.0955935010723039],...
2     0.934  0.192157  0.031373  0.097116  0.587126  0.332548  0.080326  114.531723  0.164306  0.049300  0.097116  [[[[0.1215686274509803], [0.0971558065975413],...
3     0.895  0.188235  0.035294  0.097129  0.495887  0.419141  0.084972  119.685417  0.168868  0.048820  0.097129  [[[[0.188235294117647], [0.0971691505581724], ...
4     0.944  0.325490  0.066667  0.096222  0.002803  0.962774  0.034423  209.269592  0.278271  0.079072  0.096222  [[[[0.2745098039215686], [0.0962616415584788],...
...     ...       ...       ...       ...       ...       ...       ...         ...       ...       ...       ...                                                ...
3585  5.199  0.274510  0.090196  0.093369  0.006926  0.799138  0.193936  225.319885  0.286995  0.094358  0.093369  [[[[0.3294117647058823], [0.0934089436250574],...
3586  5.147  0.243137  0.086275  0.093302  0.066355  0.873926  0.059719  181.825287  0.231132  0.073709  0.093302  [[[[0.2196078431372549], [0.0933420966653263],...
3587  5.249  0.250980  0.172549  0.091978  0.005948  0.481678  0.512374  240.823654  0.317727  0.129092  0.091978  [[[[0.2156862745098039], [0.092018538830327], ...
3588  5.209  0.250980  0.078431  0.091818  0.013138  0.592323  0.394538  219.790482  0.285554  0.097319  0.091818  [[[[0.3254901960784314], [0.0918581046310125],...
3589  5.160  0.274510  0.176471  0.091560  0.005682  0.644607  0.349711  259.152679  0.299000  0.138295  0.091560  [[[[0.3294117647058823], [0.091601936489928], ...

[3590 rows x 12 columns]
Size of dataset: (3590, 11)
*************************** Fold #: 1 ***************************
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 conv (InputLayer)              [(None, 7, 7, 3, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 zero_padding3d (ZeroPadding3D)  (None, 8, 8, 4, 1)  0           ['conv[0][0]']                   
                                                                                                  
 conv3d (Conv3D)                (None, 8, 8, 4, 8)   224         ['zero_padding3d[0][0]']         
                                                                                                  
 max_pooling3d (MaxPooling3D)   (None, 4, 4, 2, 8)   0           ['conv3d[0][0]']                 
                                                                                                  
 conv3d_1 (Conv3D)              (None, 4, 4, 2, 4)   868         ['max_pooling3d[0][0]']          
                                                                                                  
 max_pooling3d_1 (MaxPooling3D)  (None, 2, 2, 1, 4)  0           ['conv3d_1[0][0]']               
                                                                                                  
 cat (InputLayer)               [(None, 10)]         0           []                               
                                                                                                  
 flatten (Flatten)              (None, 16)           0           ['max_pooling3d_1[0][0]']        
                                                                                                  
 concatenate (Concatenate)      (None, 26)           0           ['cat[0][0]',                    
                                                                  'flatten[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 52)           1404        ['concatenate[0][0]']            
                                                                                                  
 dense_1 (Dense)                (None, 52)           2756        ['dense[0][0]']                  
                                                                                                  
 dense_2 (Dense)                (None, 52)           2756        ['dense_1[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 52)           2756        ['dense_2[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 52)           2756        ['dense_3[0][0]']                
                                                                                                  
 dense_5 (Dense)                (None, 1)            53          ['dense_4[0][0]']                
                                                                                                  
==================================================================================================
Total params: 13,573
Trainable params: 13,573
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/10000

Epoch 1: val_loss improved from inf to 6.27471, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 2s - loss: 6.5296 - mse: 6.5296 - mae: 2.4339 - val_loss: 6.2747 - val_mse: 6.2747 - val_mae: 2.3936 - 2s/epoch - 442ms/step
Epoch 2/10000

Epoch 2: val_loss improved from 6.27471 to 6.11107, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 6.4104 - mse: 6.4104 - mae: 2.4100 - val_loss: 6.1111 - val_mse: 6.1111 - val_mae: 2.3605 - 1s/epoch - 299ms/step
Epoch 3/10000

Epoch 3: val_loss improved from 6.11107 to 5.79100, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 6.2072 - mse: 6.2072 - mae: 2.3689 - val_loss: 5.7910 - val_mse: 5.7910 - val_mae: 2.2946 - 1s/epoch - 299ms/step
Epoch 4/10000

Epoch 4: val_loss improved from 5.79100 to 5.16142, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 5.8071 - mse: 5.8071 - mae: 2.2860 - val_loss: 5.1614 - val_mse: 5.1614 - val_mae: 2.1592 - 1s/epoch - 339ms/step
Epoch 5/10000

Epoch 5: val_loss improved from 5.16142 to 3.98485, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 5.0262 - mse: 5.0262 - mae: 2.1142 - val_loss: 3.9849 - val_mse: 3.9849 - val_mae: 1.8792 - 1s/epoch - 336ms/step
Epoch 6/10000

Epoch 6: val_loss improved from 3.98485 to 2.10790, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 3.6286 - mse: 3.6286 - mae: 1.7626 - val_loss: 2.1079 - val_mse: 2.1079 - val_mae: 1.3120 - 1s/epoch - 338ms/step
Epoch 7/10000

Epoch 7: val_loss improved from 2.10790 to 0.51900, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 1.6396 - mse: 1.6396 - mae: 1.0787 - val_loss: 0.5190 - val_mse: 0.5190 - val_mae: 0.5517 - 1s/epoch - 319ms/step
Epoch 8/10000

Epoch 8: val_loss did not improve from 0.51900
4/4 - 0s - loss: 0.8613 - mse: 0.8613 - mae: 0.7179 - val_loss: 1.2390 - val_mse: 1.2390 - val_mae: 0.8915 - 467ms/epoch - 117ms/step
Epoch 9/10000

Epoch 9: val_loss did not improve from 0.51900
4/4 - 0s - loss: 1.2400 - mse: 1.2400 - mae: 0.8898 - val_loss: 0.5539 - val_mse: 0.5539 - val_mae: 0.5840 - 465ms/epoch - 116ms/step
Epoch 10/10000

Epoch 10: val_loss did not improve from 0.51900
4/4 - 0s - loss: 0.6607 - mse: 0.6607 - mae: 0.6155 - val_loss: 0.6408 - val_mse: 0.6408 - val_mae: 0.6142 - 467ms/epoch - 117ms/step
Epoch 11/10000

Epoch 11: val_loss did not improve from 0.51900
4/4 - 0s - loss: 0.7753 - mse: 0.7753 - mae: 0.6647 - val_loss: 0.7233 - val_mse: 0.7233 - val_mae: 0.6618 - 463ms/epoch - 116ms/step
Epoch 12/10000

Epoch 12: val_loss did not improve from 0.51900
4/4 - 0s - loss: 0.7766 - mse: 0.7766 - mae: 0.6658 - val_loss: 0.5683 - val_mse: 0.5683 - val_mae: 0.5717 - 466ms/epoch - 116ms/step
Epoch 13/10000

Epoch 13: val_loss improved from 0.51900 to 0.51084, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6413 - mse: 0.6413 - mae: 0.5921 - val_loss: 0.5108 - val_mse: 0.5108 - val_mae: 0.5558 - 1s/epoch - 336ms/step
Epoch 14/10000

Epoch 14: val_loss did not improve from 0.51084
4/4 - 0s - loss: 0.6453 - mse: 0.6453 - mae: 0.6123 - val_loss: 0.5419 - val_mse: 0.5419 - val_mae: 0.5770 - 467ms/epoch - 117ms/step
Epoch 15/10000

Epoch 15: val_loss improved from 0.51084 to 0.50478, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6576 - mse: 0.6576 - mae: 0.6207 - val_loss: 0.5048 - val_mse: 0.5048 - val_mae: 0.5509 - 1s/epoch - 344ms/step
Epoch 16/10000

Epoch 16: val_loss did not improve from 0.50478
4/4 - 1s - loss: 0.6170 - mse: 0.6170 - mae: 0.5872 - val_loss: 0.5207 - val_mse: 0.5207 - val_mae: 0.5489 - 507ms/epoch - 127ms/step
Epoch 17/10000

Epoch 17: val_loss did not improve from 0.50478
4/4 - 0s - loss: 0.6282 - mse: 0.6282 - mae: 0.5852 - val_loss: 0.5259 - val_mse: 0.5259 - val_mae: 0.5507 - 484ms/epoch - 121ms/step
Epoch 18/10000

Epoch 18: val_loss improved from 0.50478 to 0.50445, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6236 - mse: 0.6236 - mae: 0.5837 - val_loss: 0.5045 - val_mse: 0.5045 - val_mae: 0.5436 - 1s/epoch - 336ms/step
Epoch 19/10000

Epoch 19: val_loss improved from 0.50445 to 0.50064, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6123 - mse: 0.6123 - mae: 0.5834 - val_loss: 0.5006 - val_mse: 0.5006 - val_mae: 0.5475 - 1s/epoch - 340ms/step
Epoch 20/10000

Epoch 20: val_loss improved from 0.50064 to 0.49915, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6149 - mse: 0.6149 - mae: 0.5892 - val_loss: 0.4991 - val_mse: 0.4991 - val_mae: 0.5453 - 1s/epoch - 324ms/step
Epoch 21/10000

Epoch 21: val_loss did not improve from 0.49915
4/4 - 0s - loss: 0.6105 - mse: 0.6105 - mae: 0.5836 - val_loss: 0.5019 - val_mse: 0.5019 - val_mae: 0.5420 - 476ms/epoch - 119ms/step
Epoch 22/10000

Epoch 22: val_loss did not improve from 0.49915
4/4 - 0s - loss: 0.6102 - mse: 0.6102 - mae: 0.5799 - val_loss: 0.5022 - val_mse: 0.5022 - val_mae: 0.5415 - 474ms/epoch - 119ms/step
Epoch 23/10000

Epoch 23: val_loss improved from 0.49915 to 0.49775, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6087 - mse: 0.6087 - mae: 0.5792 - val_loss: 0.4977 - val_mse: 0.4977 - val_mae: 0.5413 - 1s/epoch - 337ms/step
Epoch 24/10000

Epoch 24: val_loss improved from 0.49775 to 0.49596, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6078 - mse: 0.6078 - mae: 0.5818 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5424 - 1s/epoch - 336ms/step
Epoch 25/10000

Epoch 25: val_loss did not improve from 0.49596
4/4 - 0s - loss: 0.6069 - mse: 0.6069 - mae: 0.5816 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5401 - 492ms/epoch - 123ms/step
Epoch 26/10000

Epoch 26: val_loss did not improve from 0.49596
4/4 - 0s - loss: 0.6061 - mse: 0.6061 - mae: 0.5783 - val_loss: 0.4987 - val_mse: 0.4987 - val_mae: 0.5393 - 462ms/epoch - 116ms/step
Epoch 27/10000

Epoch 27: val_loss did not improve from 0.49596
4/4 - 0s - loss: 0.6056 - mse: 0.6056 - mae: 0.5771 - val_loss: 0.4963 - val_mse: 0.4963 - val_mae: 0.5387 - 466ms/epoch - 117ms/step
Epoch 28/10000

Epoch 28: val_loss improved from 0.49596 to 0.49516, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6043 - mse: 0.6043 - mae: 0.5766 - val_loss: 0.4952 - val_mse: 0.4952 - val_mae: 0.5381 - 1s/epoch - 339ms/step
Epoch 29/10000

Epoch 29: val_loss improved from 0.49516 to 0.49199, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6027 - mse: 0.6027 - mae: 0.5769 - val_loss: 0.4920 - val_mse: 0.4920 - val_mae: 0.5390 - 1s/epoch - 321ms/step
Epoch 30/10000

Epoch 30: val_loss improved from 0.49199 to 0.49111, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6030 - mse: 0.6030 - mae: 0.5794 - val_loss: 0.4911 - val_mse: 0.4911 - val_mae: 0.5399 - 1s/epoch - 343ms/step
Epoch 31/10000

Epoch 31: val_loss improved from 0.49111 to 0.49050, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.6024 - mse: 0.6024 - mae: 0.5794 - val_loss: 0.4905 - val_mse: 0.4905 - val_mae: 0.5373 - 1s/epoch - 322ms/step
Epoch 32/10000

Epoch 32: val_loss did not improve from 0.49050
4/4 - 0s - loss: 0.5994 - mse: 0.5994 - mae: 0.5752 - val_loss: 0.4931 - val_mse: 0.4931 - val_mae: 0.5357 - 475ms/epoch - 119ms/step
Epoch 33/10000

Epoch 33: val_loss did not improve from 0.49050
4/4 - 0s - loss: 0.6001 - mse: 0.6001 - mae: 0.5730 - val_loss: 0.4920 - val_mse: 0.4920 - val_mae: 0.5351 - 467ms/epoch - 117ms/step
Epoch 34/10000

Epoch 34: val_loss improved from 0.49050 to 0.48781, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5985 - mse: 0.5985 - mae: 0.5734 - val_loss: 0.4878 - val_mse: 0.4878 - val_mae: 0.5354 - 1s/epoch - 335ms/step
Epoch 35/10000

Epoch 35: val_loss improved from 0.48781 to 0.48705, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5970 - mse: 0.5970 - mae: 0.5742 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5346 - 1s/epoch - 340ms/step
Epoch 36/10000

Epoch 36: val_loss improved from 0.48705 to 0.48619, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5961 - mse: 0.5961 - mae: 0.5730 - val_loss: 0.4862 - val_mse: 0.4862 - val_mae: 0.5339 - 1s/epoch - 321ms/step
Epoch 37/10000

Epoch 37: val_loss improved from 0.48619 to 0.48474, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5953 - mse: 0.5953 - mae: 0.5736 - val_loss: 0.4847 - val_mse: 0.4847 - val_mae: 0.5343 - 1s/epoch - 335ms/step
Epoch 38/10000

Epoch 38: val_loss did not improve from 0.48474
4/4 - 0s - loss: 0.5942 - mse: 0.5942 - mae: 0.5726 - val_loss: 0.4857 - val_mse: 0.4857 - val_mae: 0.5320 - 471ms/epoch - 118ms/step
Epoch 39/10000

Epoch 39: val_loss did not improve from 0.48474
4/4 - 0s - loss: 0.5929 - mse: 0.5929 - mae: 0.5695 - val_loss: 0.4858 - val_mse: 0.4858 - val_mae: 0.5312 - 466ms/epoch - 116ms/step
Epoch 40/10000

Epoch 40: val_loss improved from 0.48474 to 0.48220, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5919 - mse: 0.5919 - mae: 0.5687 - val_loss: 0.4822 - val_mse: 0.4822 - val_mae: 0.5314 - 1s/epoch - 339ms/step
Epoch 41/10000

Epoch 41: val_loss improved from 0.48220 to 0.48116, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5910 - mse: 0.5910 - mae: 0.5713 - val_loss: 0.4812 - val_mse: 0.4812 - val_mae: 0.5337 - 1s/epoch - 321ms/step
Epoch 42/10000

Epoch 42: val_loss improved from 0.48116 to 0.47993, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5918 - mse: 0.5918 - mae: 0.5730 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.5304 - 1s/epoch - 334ms/step
Epoch 43/10000

Epoch 43: val_loss did not improve from 0.47993
4/4 - 0s - loss: 0.5889 - mse: 0.5889 - mae: 0.5681 - val_loss: 0.4818 - val_mse: 0.4818 - val_mae: 0.5283 - 471ms/epoch - 118ms/step
Epoch 44/10000

Epoch 44: val_loss improved from 0.47993 to 0.47956, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5877 - mse: 0.5877 - mae: 0.5654 - val_loss: 0.4796 - val_mse: 0.4796 - val_mae: 0.5277 - 1s/epoch - 348ms/step
Epoch 45/10000

Epoch 45: val_loss improved from 0.47956 to 0.47686, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5860 - mse: 0.5860 - mae: 0.5658 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.5282 - 1s/epoch - 320ms/step
Epoch 46/10000

Epoch 46: val_loss improved from 0.47686 to 0.47584, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5852 - mse: 0.5852 - mae: 0.5669 - val_loss: 0.4758 - val_mse: 0.4758 - val_mae: 0.5274 - 1s/epoch - 354ms/step
Epoch 47/10000

Epoch 47: val_loss improved from 0.47584 to 0.47534, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5838 - mse: 0.5838 - mae: 0.5653 - val_loss: 0.4753 - val_mse: 0.4753 - val_mae: 0.5259 - 1s/epoch - 337ms/step
Epoch 48/10000

Epoch 48: val_loss improved from 0.47534 to 0.47466, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5824 - mse: 0.5824 - mae: 0.5636 - val_loss: 0.4747 - val_mse: 0.4747 - val_mae: 0.5249 - 1s/epoch - 340ms/step
Epoch 49/10000

Epoch 49: val_loss improved from 0.47466 to 0.47322, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5812 - mse: 0.5812 - mae: 0.5626 - val_loss: 0.4732 - val_mse: 0.4732 - val_mae: 0.5243 - 1s/epoch - 321ms/step
Epoch 50/10000

Epoch 50: val_loss improved from 0.47322 to 0.47219, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5799 - mse: 0.5799 - mae: 0.5622 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.5234 - 1s/epoch - 343ms/step
Epoch 51/10000

Epoch 51: val_loss did not improve from 0.47219
4/4 - 0s - loss: 0.5792 - mse: 0.5792 - mae: 0.5605 - val_loss: 0.4727 - val_mse: 0.4727 - val_mae: 0.5221 - 475ms/epoch - 119ms/step
Epoch 52/10000

Epoch 52: val_loss improved from 0.47219 to 0.46923, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5782 - mse: 0.5782 - mae: 0.5600 - val_loss: 0.4692 - val_mse: 0.4692 - val_mae: 0.5225 - 1s/epoch - 324ms/step
Epoch 53/10000

Epoch 53: val_loss improved from 0.46923 to 0.46863, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5763 - mse: 0.5763 - mae: 0.5600 - val_loss: 0.4686 - val_mse: 0.4686 - val_mae: 0.5211 - 1s/epoch - 334ms/step
Epoch 54/10000

Epoch 54: val_loss improved from 0.46863 to 0.46716, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5748 - mse: 0.5748 - mae: 0.5586 - val_loss: 0.4672 - val_mse: 0.4672 - val_mae: 0.5205 - 1s/epoch - 339ms/step
Epoch 55/10000

Epoch 55: val_loss improved from 0.46716 to 0.46553, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5737 - mse: 0.5737 - mae: 0.5584 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.5205 - 1s/epoch - 321ms/step
Epoch 56/10000

Epoch 56: val_loss improved from 0.46553 to 0.46445, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5725 - mse: 0.5725 - mae: 0.5582 - val_loss: 0.4644 - val_mse: 0.4644 - val_mae: 0.5193 - 1s/epoch - 334ms/step
Epoch 57/10000

Epoch 57: val_loss improved from 0.46445 to 0.46317, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5709 - mse: 0.5709 - mae: 0.5570 - val_loss: 0.4632 - val_mse: 0.4632 - val_mae: 0.5185 - 1s/epoch - 341ms/step
Epoch 58/10000

Epoch 58: val_loss improved from 0.46317 to 0.46269, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5695 - mse: 0.5695 - mae: 0.5561 - val_loss: 0.4627 - val_mse: 0.4627 - val_mae: 0.5167 - 1s/epoch - 317ms/step
Epoch 59/10000

Epoch 59: val_loss did not improve from 0.46269
4/4 - 0s - loss: 0.5678 - mse: 0.5678 - mae: 0.5531 - val_loss: 0.4632 - val_mse: 0.4632 - val_mae: 0.5150 - 468ms/epoch - 117ms/step
Epoch 60/10000

Epoch 60: val_loss improved from 0.46269 to 0.45990, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5669 - mse: 0.5669 - mae: 0.5516 - val_loss: 0.4599 - val_mse: 0.4599 - val_mae: 0.5152 - 1s/epoch - 334ms/step
Epoch 61/10000

Epoch 61: val_loss improved from 0.45990 to 0.45803, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5651 - mse: 0.5651 - mae: 0.5526 - val_loss: 0.4580 - val_mse: 0.4580 - val_mae: 0.5154 - 1s/epoch - 339ms/step
Epoch 62/10000

Epoch 62: val_loss improved from 0.45803 to 0.45728, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5641 - mse: 0.5641 - mae: 0.5530 - val_loss: 0.4573 - val_mse: 0.4573 - val_mae: 0.5134 - 1s/epoch - 320ms/step
Epoch 63/10000

Epoch 63: val_loss did not improve from 0.45728
4/4 - 0s - loss: 0.5629 - mse: 0.5629 - mae: 0.5490 - val_loss: 0.4590 - val_mse: 0.4590 - val_mae: 0.5111 - 471ms/epoch - 118ms/step
Epoch 64/10000

Epoch 64: val_loss improved from 0.45728 to 0.45434, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5618 - mse: 0.5618 - mae: 0.5480 - val_loss: 0.4543 - val_mse: 0.4543 - val_mae: 0.5123 - 1s/epoch - 335ms/step
Epoch 65/10000

Epoch 65: val_loss improved from 0.45434 to 0.45301, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5597 - mse: 0.5597 - mae: 0.5499 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.5115 - 1s/epoch - 339ms/step
Epoch 66/10000

Epoch 66: val_loss did not improve from 0.45301
4/4 - 0s - loss: 0.5579 - mse: 0.5579 - mae: 0.5479 - val_loss: 0.4531 - val_mse: 0.4531 - val_mae: 0.5089 - 468ms/epoch - 117ms/step
Epoch 67/10000

Epoch 67: val_loss improved from 0.45301 to 0.45238, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5565 - mse: 0.5565 - mae: 0.5447 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.5077 - 1s/epoch - 320ms/step
Epoch 68/10000

Epoch 68: val_loss improved from 0.45238 to 0.44955, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5551 - mse: 0.5551 - mae: 0.5436 - val_loss: 0.4495 - val_mse: 0.4495 - val_mae: 0.5076 - 1s/epoch - 336ms/step
Epoch 69/10000

Epoch 69: val_loss improved from 0.44955 to 0.44773, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5533 - mse: 0.5533 - mae: 0.5447 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.5074 - 1s/epoch - 341ms/step
Epoch 70/10000

Epoch 70: val_loss did not improve from 0.44773
4/4 - 0s - loss: 0.5516 - mse: 0.5516 - mae: 0.5435 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.5049 - 465ms/epoch - 116ms/step
Epoch 71/10000

Epoch 71: val_loss improved from 0.44773 to 0.44745, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5513 - mse: 0.5513 - mae: 0.5399 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.5036 - 1s/epoch - 320ms/step
Epoch 72/10000

Epoch 72: val_loss improved from 0.44745 to 0.44355, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
4/4 - 1s - loss: 0.5488 - mse: 0.5488 - mae: 0.5397 - val_loss: 0.4436 - val_mse: 0.4436 - val_mae: 0.5053 - 1s/epoch - 334ms/step
Epoch 73/10000

Epoch 73: val_loss improved from 0.44355 to 0.44298, saving model to ./results/NN_thk_regr/FYI_MYI_rms//CNN/ckpt_1
