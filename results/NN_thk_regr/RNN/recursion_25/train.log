[0.772476 0.95796  1.13892  1.31988  1.50084  1.6818   1.86276  2.04372
 2.22468  2.40564  2.5866   2.76756  2.94852  3.12948  3.31044  3.4914
 3.67236  3.85332  4.03428  4.21524  4.3962   4.57716  4.75812  4.93908
 5.12004  5.301   ]
Before undersampling: [(0, 11), (1, 39), (2, 115), (3, 362), (4, 1078), (5, 3055), (6, 3442), (7, 2347), (8, 2192), (9, 2045), (10, 1798), (11, 1759), (12, 1575), (13, 1285), (14, 1141), (15, 851), (16, 754), (17, 607), (18, 484), (19, 419), (20, 334), (21, 313), (22, 265), (23, 211), (24, 176)]
After undersampling: [(0, 11), (1, 8), (2, 26), (3, 49), (4, 183), (5, 1032), (6, 332), (7, 128), (8, 204), (9, 237), (10, 177), (11, 143), (12, 362), (13, 70), (14, 90), (15, 80), (16, 63), (17, 44), (18, 68), (19, 40), (20, 30), (21, 34), (22, 42), (23, 22), (24, 26)]
      label  HH_0_0_x  HV_0_0_x  IA_0_0_x       FYI      DFYI       MYI     thk_0     rms_0     thk_1     rms_1     thk_2     rms_2     thk_3     rms_3  ...         2         3    4    5         6         7    8    9        10        11   12   13        14        15                                                CNN
0     0.858  0.184314  0.054902  0.108219  0.677054  0.244229  0.078717  1.139022  4.619061  1.121850  4.587435  1.163103  4.630546  1.142668  4.608280  ...  1.794105  1.232723  0.0  0.0  1.676458  0.457529  0.0  0.0  2.629072  1.680807  0.0  0.0  2.071088  0.997636  [[[[0.2274509803921568], [0.1081809698366651],...
1     0.922  0.219608  0.043137  0.095634  0.054778  0.917930  0.027292  1.255907  4.934867  1.190188  4.955407  1.254201  4.917210  1.214210  4.943307  ...  1.858653  0.958789  0.0  0.0  1.482595  0.882993  0.0  0.0  1.813574  1.036300  0.0  0.0  1.021202  0.304315  [[[[0.1215686274509803], [0.0955935010723039],...
2     0.934  0.192157  0.031373  0.097116  0.587126  0.332548  0.080326  1.116638  4.507772  1.127930  4.540287  1.129141  4.575030  1.129684  4.550352  ...  2.465073  1.454735  0.0  0.0  1.664574  0.567139  0.0  0.0  1.608063  1.070126  0.0  0.0  1.394648  0.755752  [[[[0.1215686274509803], [0.0971558065975413],...
3     0.895  0.188235  0.035294  0.097129  0.495887  0.419141  0.084972  1.118644  4.592724  1.095643  4.587478  1.145017  4.605608  1.145263  4.589715  ...  1.455201  0.920117  0.0  0.0  1.215891  0.197614  0.0  0.0  2.230993  1.186736  0.0  0.0  1.461483  0.813507  [[[[0.188235294117647], [0.0971691505581724], ...
4     0.944  0.325490  0.066667  0.096222  0.002803  0.962774  0.034423  1.262448  5.170933  1.227499  5.174989  1.274633  5.133248  1.257773  5.172892  ...  2.084994  0.914255  0.0  0.0  1.564887  0.758167  0.0  0.0  1.739678  1.101263  0.0  0.0  1.458454  0.544326  [[[[0.2745098039215686], [0.0962616415584788],...
...     ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...  ...  ...       ...       ...  ...  ...       ...       ...  ...  ...       ...       ...                                                ...
3496  5.247  0.333333  0.101961  0.144103  0.237813  0.133494  0.628693  1.234870  4.873087  1.230179  4.881016  1.332511  4.876536  1.288875  4.899395  ...  1.932301  1.139117  0.0  0.0  1.494050  0.286946  0.0  0.0  1.879899  1.215439  0.0  0.0  1.438250  0.679756  [[[[0.188235294117647], [0.1441346411611519], ...
3497  5.126  0.376471  0.152941  0.134660  0.056583  0.046755  0.896662  1.346896  4.775708  1.296040  4.812373  1.365768  4.798210  1.370311  4.806980  ...  2.158879  0.998291  0.0  0.0  1.665850  0.302233  0.0  0.0  1.332346  0.696291  0.0  0.0  1.556165  0.846926  [[[[0.4117647058823529], [0.1346939086914062],...
3498  5.175  0.407843  0.133333  0.134660  0.055732  0.047280  0.896988  1.352152  4.753513  1.311627  4.783792  1.387699  4.749600  1.397979  4.795096  ...  1.670015  0.545604  0.0  0.0  1.675143  0.354022  0.0  0.0  1.697468  0.919105  0.0  0.0  1.299724  1.074453  [[[[0.4549019607843137], [0.1346939086914062],...
3499  5.170  0.258824  0.035294  0.090093  0.691879  0.287280  0.020842  1.227172  4.477526  1.144009  4.482209  1.168136  4.481647  1.206624  4.487376  ...  1.807213  0.897108  0.0  0.0  1.759332  0.053094  0.0  0.0  2.362018  1.301118  0.0  0.0  0.989112  0.826534  [[[[0.1803921568627451], [0.0901344000124463],...
3500  5.216  0.235294  0.082353  0.091293  0.560729  0.400106  0.039165  1.212427  4.694746  1.163682  4.689672  1.193163  4.745670  1.191880  4.691133  ...  1.626172  1.132155  0.0  0.0  1.092578  0.535208  0.0  0.0  2.121283  0.759186  0.0  0.0  1.667662  0.302372  [[[[0.1254901960784313], [0.0913350946762982],...

[3501 rows x 37 columns]
Size of dataset: (3501, 36)
*************************** Fold #: 1 ***************************
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 conv (InputLayer)              [(None, 7, 7, 3, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 zero_padding3d (ZeroPadding3D)  (None, 8, 8, 4, 1)  0           ['conv[0][0]']                   
                                                                                                  
 conv3d (Conv3D)                (None, 8, 8, 4, 8)   224         ['zero_padding3d[0][0]']         
                                                                                                  
 max_pooling3d (MaxPooling3D)   (None, 4, 4, 2, 8)   0           ['conv3d[0][0]']                 
                                                                                                  
 conv3d_1 (Conv3D)              (None, 4, 4, 2, 4)   868         ['max_pooling3d[0][0]']          
                                                                                                  
 max_pooling3d_1 (MaxPooling3D)  (None, 2, 2, 1, 4)  0           ['conv3d_1[0][0]']               
                                                                                                  
 cat (InputLayer)               [(None, 35)]         0           []                               
                                                                                                  
 flatten (Flatten)              (None, 16)           0           ['max_pooling3d_1[0][0]']        
                                                                                                  
 concatenate (Concatenate)      (None, 51)           0           ['cat[0][0]',                    
                                                                  'flatten[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 102)          5304        ['concatenate[0][0]']            
                                                                                                  
 dense_1 (Dense)                (None, 102)          10506       ['dense[0][0]']                  
                                                                                                  
 dense_2 (Dense)                (None, 102)          10506       ['dense_1[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 102)          10506       ['dense_2[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 102)          10506       ['dense_3[0][0]']                
                                                                                                  
 dense_5 (Dense)                (None, 1)            103         ['dense_4[0][0]']                
                                                                                                  
==================================================================================================
Total params: 48,523
Trainable params: 48,523
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/10000

Epoch 1: val_loss improved from inf to 1.48604, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 2s - loss: 1.5159 - mse: 1.5159 - mae: 1.2094 - val_loss: 1.4860 - val_mse: 1.4860 - val_mae: 1.1973 - 2s/epoch - 800ms/step
Epoch 2/10000

Epoch 2: val_loss improved from 1.48604 to 1.40227, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 1.4520 - mse: 1.4520 - mae: 1.1829 - val_loss: 1.4023 - val_mse: 1.4023 - val_mae: 1.1620 - 1s/epoch - 531ms/step
Epoch 3/10000

Epoch 3: val_loss improved from 1.40227 to 1.26944, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 1.3593 - mse: 1.3593 - mae: 1.1433 - val_loss: 1.2694 - val_mse: 1.2694 - val_mae: 1.1037 - 1s/epoch - 531ms/step
Epoch 4/10000

Epoch 4: val_loss improved from 1.26944 to 1.06770, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 1.2146 - mse: 1.2146 - mae: 1.0781 - val_loss: 1.0677 - val_mse: 1.0677 - val_mae: 1.0088 - 1s/epoch - 588ms/step
Epoch 5/10000

Epoch 5: val_loss improved from 1.06770 to 0.77684, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.9962 - mse: 0.9962 - mae: 0.9721 - val_loss: 0.7768 - val_mse: 0.7768 - val_mae: 0.8537 - 1s/epoch - 614ms/step
Epoch 6/10000

Epoch 6: val_loss improved from 0.77684 to 0.40444, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.6893 - mse: 0.6893 - mae: 0.7984 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.5992 - 1s/epoch - 576ms/step
Epoch 7/10000

Epoch 7: val_loss improved from 0.40444 to 0.07666, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.3181 - mse: 0.3181 - mae: 0.5148 - val_loss: 0.0767 - val_mse: 0.0767 - val_mae: 0.2046 - 1s/epoch - 606ms/step
Epoch 8/10000

Epoch 8: val_loss did not improve from 0.07666
2/2 - 0s - loss: 0.0644 - mse: 0.0644 - mae: 0.1984 - val_loss: 0.1787 - val_mse: 0.1787 - val_mae: 0.3843 - 330ms/epoch - 165ms/step
Epoch 9/10000

Epoch 9: val_loss did not improve from 0.07666
2/2 - 0s - loss: 0.2406 - mse: 0.2406 - mae: 0.4493 - val_loss: 0.2894 - val_mse: 0.2894 - val_mae: 0.5020 - 328ms/epoch - 164ms/step
Epoch 10/10000

Epoch 10: val_loss did not improve from 0.07666
2/2 - 0s - loss: 0.2640 - mse: 0.2640 - mae: 0.4742 - val_loss: 0.1041 - val_mse: 0.1041 - val_mae: 0.2844 - 327ms/epoch - 164ms/step
Epoch 11/10000

Epoch 11: val_loss improved from 0.07666 to 0.04224, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0877 - mse: 0.0877 - mae: 0.2541 - val_loss: 0.0422 - val_mse: 0.0422 - val_mae: 0.1616 - 1s/epoch - 615ms/step
Epoch 12/10000

Epoch 12: val_loss did not improve from 0.04224
2/2 - 0s - loss: 0.0494 - mse: 0.0494 - mae: 0.1706 - val_loss: 0.0915 - val_mse: 0.0915 - val_mae: 0.2308 - 326ms/epoch - 163ms/step
Epoch 13/10000

Epoch 13: val_loss did not improve from 0.04224
2/2 - 0s - loss: 0.0984 - mse: 0.0984 - mae: 0.2470 - val_loss: 0.1364 - val_mse: 0.1364 - val_mae: 0.3079 - 331ms/epoch - 165ms/step
Epoch 14/10000

Epoch 14: val_loss did not improve from 0.04224
2/2 - 0s - loss: 0.1326 - mse: 0.1326 - mae: 0.3048 - val_loss: 0.1357 - val_mse: 0.1357 - val_mae: 0.3068 - 330ms/epoch - 165ms/step
Epoch 15/10000

Epoch 15: val_loss did not improve from 0.04224
2/2 - 0s - loss: 0.1237 - mse: 0.1237 - mae: 0.2903 - val_loss: 0.0989 - val_mse: 0.0989 - val_mae: 0.2440 - 330ms/epoch - 165ms/step
Epoch 16/10000

Epoch 16: val_loss did not improve from 0.04224
2/2 - 0s - loss: 0.0851 - mse: 0.0851 - mae: 0.2234 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1711 - 332ms/epoch - 166ms/step
Epoch 17/10000

Epoch 17: val_loss improved from 0.04224 to 0.04135, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0493 - mse: 0.0493 - mae: 0.1660 - val_loss: 0.0414 - val_mse: 0.0414 - val_mae: 0.1690 - 1s/epoch - 578ms/step
Epoch 18/10000

Epoch 18: val_loss did not improve from 0.04135
2/2 - 0s - loss: 0.0461 - mse: 0.0461 - mae: 0.1786 - val_loss: 0.0594 - val_mse: 0.0594 - val_mae: 0.2097 - 335ms/epoch - 167ms/step
Epoch 19/10000

Epoch 19: val_loss did not improve from 0.04135
2/2 - 0s - loss: 0.0668 - mse: 0.0668 - mae: 0.2186 - val_loss: 0.0689 - val_mse: 0.0689 - val_mae: 0.2271 - 332ms/epoch - 166ms/step
Epoch 20/10000

Epoch 20: val_loss did not improve from 0.04135
2/2 - 0s - loss: 0.0710 - mse: 0.0710 - mae: 0.2262 - val_loss: 0.0534 - val_mse: 0.0534 - val_mae: 0.1980 - 332ms/epoch - 166ms/step
Epoch 21/10000

Epoch 21: val_loss improved from 0.04135 to 0.04101, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0528 - mse: 0.0528 - mae: 0.1934 - val_loss: 0.0410 - val_mse: 0.0410 - val_mae: 0.1676 - 1s/epoch - 607ms/step
Epoch 22/10000

Epoch 22: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0416 - mse: 0.0416 - mae: 0.1656 - val_loss: 0.0456 - val_mse: 0.0456 - val_mae: 0.1603 - 346ms/epoch - 173ms/step
Epoch 23/10000

Epoch 23: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0465 - mse: 0.0465 - mae: 0.1604 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1690 - 326ms/epoch - 163ms/step
Epoch 24/10000

Epoch 24: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0529 - mse: 0.0529 - mae: 0.1682 - val_loss: 0.0548 - val_mse: 0.0548 - val_mae: 0.1698 - 327ms/epoch - 163ms/step
Epoch 25/10000

Epoch 25: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0516 - mse: 0.0516 - mae: 0.1665 - val_loss: 0.0476 - val_mse: 0.0476 - val_mae: 0.1614 - 327ms/epoch - 163ms/step
Epoch 26/10000

Epoch 26: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0450 - mse: 0.0450 - mae: 0.1595 - val_loss: 0.0413 - val_mse: 0.0413 - val_mae: 0.1608 - 331ms/epoch - 166ms/step
Epoch 27/10000

Epoch 27: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0414 - mse: 0.0414 - mae: 0.1637 - val_loss: 0.0413 - val_mse: 0.0413 - val_mae: 0.1693 - 333ms/epoch - 167ms/step
Epoch 28/10000

Epoch 28: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0434 - mse: 0.0434 - mae: 0.1736 - val_loss: 0.0436 - val_mse: 0.0436 - val_mae: 0.1762 - 331ms/epoch - 166ms/step
Epoch 29/10000

Epoch 29: val_loss did not improve from 0.04101
2/2 - 0s - loss: 0.0455 - mse: 0.0455 - mae: 0.1788 - val_loss: 0.0427 - val_mse: 0.0427 - val_mae: 0.1736 - 325ms/epoch - 163ms/step
Epoch 30/10000

Epoch 30: val_loss improved from 0.04101 to 0.04053, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0436 - mse: 0.0436 - mae: 0.1744 - val_loss: 0.0405 - val_mse: 0.0405 - val_mae: 0.1658 - 1s/epoch - 614ms/step
Epoch 31/10000

Epoch 31: val_loss did not improve from 0.04053
2/2 - 0s - loss: 0.0412 - mse: 0.0412 - mae: 0.1661 - val_loss: 0.0410 - val_mse: 0.0410 - val_mae: 0.1601 - 329ms/epoch - 165ms/step
Epoch 32/10000

Epoch 32: val_loss did not improve from 0.04053
2/2 - 0s - loss: 0.0413 - mse: 0.0413 - mae: 0.1601 - val_loss: 0.0429 - val_mse: 0.0429 - val_mae: 0.1587 - 327ms/epoch - 163ms/step
Epoch 33/10000

Epoch 33: val_loss did not improve from 0.04053
2/2 - 0s - loss: 0.0423 - mse: 0.0423 - mae: 0.1577 - val_loss: 0.0431 - val_mse: 0.0431 - val_mae: 0.1585 - 329ms/epoch - 164ms/step
Epoch 34/10000

Epoch 34: val_loss did not improve from 0.04053
2/2 - 0s - loss: 0.0421 - mse: 0.0421 - mae: 0.1578 - val_loss: 0.0415 - val_mse: 0.0415 - val_mae: 0.1589 - 325ms/epoch - 163ms/step
Epoch 35/10000

Epoch 35: val_loss improved from 0.04053 to 0.04029, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0409 - mse: 0.0409 - mae: 0.1591 - val_loss: 0.0403 - val_mse: 0.0403 - val_mae: 0.1612 - 1s/epoch - 575ms/step
Epoch 36/10000

Epoch 36: val_loss improved from 0.04029 to 0.04017, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0404 - mse: 0.0404 - mae: 0.1627 - val_loss: 0.0402 - val_mse: 0.0402 - val_mae: 0.1642 - 1s/epoch - 608ms/step
Epoch 37/10000

Epoch 37: val_loss did not improve from 0.04017
2/2 - 0s - loss: 0.0408 - mse: 0.0408 - mae: 0.1660 - val_loss: 0.0403 - val_mse: 0.0403 - val_mae: 0.1653 - 330ms/epoch - 165ms/step
Epoch 38/10000

Epoch 38: val_loss improved from 0.04017 to 0.04008, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0410 - mse: 0.0410 - mae: 0.1667 - val_loss: 0.0401 - val_mse: 0.0401 - val_mae: 0.1638 - 1s/epoch - 612ms/step
Epoch 39/10000

Epoch 39: val_loss improved from 0.04008 to 0.04000, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0406 - mse: 0.0406 - mae: 0.1646 - val_loss: 0.0400 - val_mse: 0.0400 - val_mae: 0.1614 - 1s/epoch - 576ms/step
Epoch 40/10000

Epoch 40: val_loss did not improve from 0.04000
2/2 - 0s - loss: 0.0402 - mse: 0.0402 - mae: 0.1616 - val_loss: 0.0403 - val_mse: 0.0403 - val_mae: 0.1595 - 331ms/epoch - 165ms/step
Epoch 41/10000

Epoch 41: val_loss did not improve from 0.04000
2/2 - 0s - loss: 0.0402 - mse: 0.0402 - mae: 0.1594 - val_loss: 0.0406 - val_mse: 0.0406 - val_mae: 0.1586 - 330ms/epoch - 165ms/step
Epoch 42/10000

Epoch 42: val_loss did not improve from 0.04000
2/2 - 0s - loss: 0.0402 - mse: 0.0402 - mae: 0.1585 - val_loss: 0.0404 - val_mse: 0.0404 - val_mae: 0.1587 - 334ms/epoch - 167ms/step
Epoch 43/10000

Epoch 43: val_loss did not improve from 0.04000
2/2 - 0s - loss: 0.0401 - mse: 0.0401 - mae: 0.1587 - val_loss: 0.0401 - val_mse: 0.0401 - val_mae: 0.1593 - 332ms/epoch - 166ms/step
Epoch 44/10000

Epoch 44: val_loss improved from 0.04000 to 0.03981, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0399 - mse: 0.0399 - mae: 0.1597 - val_loss: 0.0398 - val_mse: 0.0398 - val_mae: 0.1603 - 1s/epoch - 601ms/step
Epoch 45/10000

Epoch 45: val_loss improved from 0.03981 to 0.03970, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0398 - mse: 0.0398 - mae: 0.1610 - val_loss: 0.0397 - val_mse: 0.0397 - val_mae: 0.1610 - 1s/epoch - 604ms/step
Epoch 46/10000

Epoch 46: val_loss improved from 0.03970 to 0.03966, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0399 - mse: 0.0399 - mae: 0.1618 - val_loss: 0.0397 - val_mse: 0.0397 - val_mae: 0.1610 - 1s/epoch - 610ms/step
Epoch 47/10000

Epoch 47: val_loss did not improve from 0.03966
2/2 - 0s - loss: 0.0398 - mse: 0.0398 - mae: 0.1614 - val_loss: 0.0397 - val_mse: 0.0397 - val_mae: 0.1600 - 331ms/epoch - 166ms/step
Epoch 48/10000

Epoch 48: val_loss did not improve from 0.03966
2/2 - 0s - loss: 0.0397 - mse: 0.0397 - mae: 0.1601 - val_loss: 0.0398 - val_mse: 0.0398 - val_mae: 0.1589 - 327ms/epoch - 163ms/step
Epoch 49/10000

Epoch 49: val_loss did not improve from 0.03966
2/2 - 0s - loss: 0.0396 - mse: 0.0396 - mae: 0.1587 - val_loss: 0.0399 - val_mse: 0.0399 - val_mae: 0.1583 - 328ms/epoch - 164ms/step
Epoch 50/10000

Epoch 50: val_loss did not improve from 0.03966
2/2 - 0s - loss: 0.0396 - mse: 0.0396 - mae: 0.1581 - val_loss: 0.0398 - val_mse: 0.0398 - val_mae: 0.1582 - 329ms/epoch - 165ms/step
Epoch 51/10000

Epoch 51: val_loss improved from 0.03966 to 0.03965, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0395 - mse: 0.0395 - mae: 0.1582 - val_loss: 0.0396 - val_mse: 0.0396 - val_mae: 0.1584 - 1s/epoch - 574ms/step
Epoch 52/10000

Epoch 52: val_loss improved from 0.03965 to 0.03952, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0394 - mse: 0.0394 - mae: 0.1586 - val_loss: 0.0395 - val_mse: 0.0395 - val_mae: 0.1587 - 1s/epoch - 605ms/step
Epoch 53/10000

Epoch 53: val_loss improved from 0.03952 to 0.03946, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0393 - mse: 0.0393 - mae: 0.1589 - val_loss: 0.0395 - val_mse: 0.0395 - val_mae: 0.1587 - 1s/epoch - 607ms/step
Epoch 54/10000

Epoch 54: val_loss improved from 0.03946 to 0.03945, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0393 - mse: 0.0393 - mae: 0.1587 - val_loss: 0.0395 - val_mse: 0.0395 - val_mae: 0.1584 - 1s/epoch - 614ms/step
Epoch 55/10000

Epoch 55: val_loss did not improve from 0.03945
2/2 - 0s - loss: 0.0392 - mse: 0.0392 - mae: 0.1582 - val_loss: 0.0395 - val_mse: 0.0395 - val_mae: 0.1580 - 331ms/epoch - 166ms/step
Epoch 56/10000

Epoch 56: val_loss improved from 0.03945 to 0.03944, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0392 - mse: 0.0392 - mae: 0.1576 - val_loss: 0.0394 - val_mse: 0.0394 - val_mae: 0.1578 - 1s/epoch - 576ms/step
Epoch 57/10000

Epoch 57: val_loss improved from 0.03944 to 0.03936, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0391 - mse: 0.0391 - mae: 0.1575 - val_loss: 0.0394 - val_mse: 0.0394 - val_mae: 0.1578 - 1s/epoch - 609ms/step
Epoch 58/10000

Epoch 58: val_loss improved from 0.03936 to 0.03929, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0390 - mse: 0.0390 - mae: 0.1575 - val_loss: 0.0393 - val_mse: 0.0393 - val_mae: 0.1578 - 1s/epoch - 611ms/step
Epoch 59/10000

Epoch 59: val_loss improved from 0.03929 to 0.03921, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0390 - mse: 0.0390 - mae: 0.1577 - val_loss: 0.0392 - val_mse: 0.0392 - val_mae: 0.1580 - 1s/epoch - 578ms/step
Epoch 60/10000

Epoch 60: val_loss improved from 0.03921 to 0.03920, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0389 - mse: 0.0389 - mae: 0.1577 - val_loss: 0.0392 - val_mse: 0.0392 - val_mae: 0.1576 - 1s/epoch - 610ms/step
Epoch 61/10000

Epoch 61: val_loss did not improve from 0.03920
2/2 - 0s - loss: 0.0389 - mse: 0.0389 - mae: 0.1572 - val_loss: 0.0392 - val_mse: 0.0392 - val_mae: 0.1572 - 330ms/epoch - 165ms/step
Epoch 62/10000

Epoch 62: val_loss did not improve from 0.03920
2/2 - 0s - loss: 0.0388 - mse: 0.0388 - mae: 0.1566 - val_loss: 0.0392 - val_mse: 0.0392 - val_mae: 0.1568 - 330ms/epoch - 165ms/step
Epoch 63/10000

Epoch 63: val_loss did not improve from 0.03920
2/2 - 0s - loss: 0.0388 - mse: 0.0388 - mae: 0.1561 - val_loss: 0.0392 - val_mse: 0.0392 - val_mae: 0.1566 - 332ms/epoch - 166ms/step
Epoch 64/10000

Epoch 64: val_loss improved from 0.03920 to 0.03913, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0387 - mse: 0.0387 - mae: 0.1560 - val_loss: 0.0391 - val_mse: 0.0391 - val_mae: 0.1567 - 1s/epoch - 612ms/step
Epoch 65/10000

Epoch 65: val_loss improved from 0.03913 to 0.03905, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0387 - mse: 0.0387 - mae: 0.1561 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1568 - 1s/epoch - 578ms/step
Epoch 66/10000

Epoch 66: val_loss improved from 0.03905 to 0.03898, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0386 - mse: 0.0386 - mae: 0.1564 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1569 - 1s/epoch - 608ms/step
Epoch 67/10000

Epoch 67: val_loss did not improve from 0.03898
2/2 - 0s - loss: 0.0386 - mse: 0.0386 - mae: 0.1564 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1566 - 332ms/epoch - 166ms/step
Epoch 68/10000

Epoch 68: val_loss did not improve from 0.03898
2/2 - 0s - loss: 0.0385 - mse: 0.0385 - mae: 0.1558 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1562 - 325ms/epoch - 163ms/step
Epoch 69/10000

Epoch 69: val_loss did not improve from 0.03898
2/2 - 0s - loss: 0.0385 - mse: 0.0385 - mae: 0.1553 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1559 - 327ms/epoch - 164ms/step
Epoch 70/10000

Epoch 70: val_loss improved from 0.03898 to 0.03896, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0384 - mse: 0.0384 - mae: 0.1550 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1558 - 1s/epoch - 610ms/step
Epoch 71/10000

Epoch 71: val_loss improved from 0.03896 to 0.03890, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0384 - mse: 0.0384 - mae: 0.1549 - val_loss: 0.0389 - val_mse: 0.0389 - val_mae: 0.1558 - 1s/epoch - 577ms/step
Epoch 72/10000

Epoch 72: val_loss improved from 0.03890 to 0.03884, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0383 - mse: 0.0383 - mae: 0.1552 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1559 - 1s/epoch - 602ms/step
Epoch 73/10000

Epoch 73: val_loss did not improve from 0.03884
2/2 - 0s - loss: 0.0383 - mse: 0.0383 - mae: 0.1550 - val_loss: 0.0389 - val_mse: 0.0389 - val_mae: 0.1555 - 333ms/epoch - 167ms/step
Epoch 74/10000

Epoch 74: val_loss did not improve from 0.03884
2/2 - 0s - loss: 0.0382 - mse: 0.0382 - mae: 0.1543 - val_loss: 0.0389 - val_mse: 0.0389 - val_mae: 0.1550 - 329ms/epoch - 164ms/step
Epoch 75/10000

Epoch 75: val_loss did not improve from 0.03884
2/2 - 0s - loss: 0.0382 - mse: 0.0382 - mae: 0.1538 - val_loss: 0.0389 - val_mse: 0.0389 - val_mae: 0.1550 - 335ms/epoch - 167ms/step
Epoch 76/10000

Epoch 76: val_loss improved from 0.03884 to 0.03879, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0381 - mse: 0.0381 - mae: 0.1538 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1551 - 1s/epoch - 602ms/step
Epoch 77/10000

Epoch 77: val_loss improved from 0.03879 to 0.03870, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0381 - mse: 0.0381 - mae: 0.1541 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1553 - 1s/epoch - 611ms/step
Epoch 78/10000

Epoch 78: val_loss improved from 0.03870 to 0.03867, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0381 - mse: 0.0381 - mae: 0.1544 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1553 - 1s/epoch - 574ms/step
Epoch 79/10000

Epoch 79: val_loss did not improve from 0.03867
2/2 - 0s - loss: 0.0380 - mse: 0.0380 - mae: 0.1542 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1548 - 332ms/epoch - 166ms/step
Epoch 80/10000

Epoch 80: val_loss did not improve from 0.03867
2/2 - 0s - loss: 0.0379 - mse: 0.0379 - mae: 0.1534 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1544 - 332ms/epoch - 166ms/step
Epoch 81/10000

Epoch 81: val_loss did not improve from 0.03867
2/2 - 0s - loss: 0.0379 - mse: 0.0379 - mae: 0.1528 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1542 - 337ms/epoch - 168ms/step
Epoch 82/10000

Epoch 82: val_loss did not improve from 0.03867
2/2 - 0s - loss: 0.0379 - mse: 0.0379 - mae: 0.1524 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1541 - 328ms/epoch - 164ms/step
Epoch 83/10000

Epoch 83: val_loss improved from 0.03867 to 0.03860, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0378 - mse: 0.0378 - mae: 0.1526 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1545 - 1s/epoch - 602ms/step
Epoch 84/10000

Epoch 84: val_loss improved from 0.03860 to 0.03853, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0378 - mse: 0.0378 - mae: 0.1531 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1546 - 1s/epoch - 606ms/step
Epoch 85/10000

Epoch 85: val_loss improved from 0.03853 to 0.03850, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0378 - mse: 0.0378 - mae: 0.1536 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1546 - 1s/epoch - 611ms/step
Epoch 86/10000

Epoch 86: val_loss did not improve from 0.03850
2/2 - 0s - loss: 0.0377 - mse: 0.0377 - mae: 0.1534 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1540 - 336ms/epoch - 168ms/step
Epoch 87/10000

Epoch 87: val_loss did not improve from 0.03850
2/2 - 0s - loss: 0.0377 - mse: 0.0377 - mae: 0.1522 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1534 - 329ms/epoch - 165ms/step
Epoch 88/10000

Epoch 88: val_loss did not improve from 0.03850
2/2 - 0s - loss: 0.0377 - mse: 0.0377 - mae: 0.1512 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1531 - 326ms/epoch - 163ms/step
Epoch 89/10000

Epoch 89: val_loss did not improve from 0.03850
2/2 - 0s - loss: 0.0377 - mse: 0.0377 - mae: 0.1509 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1533 - 327ms/epoch - 163ms/step
Epoch 90/10000

Epoch 90: val_loss improved from 0.03850 to 0.03849, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0376 - mse: 0.0376 - mae: 0.1514 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1536 - 1s/epoch - 575ms/step
Epoch 91/10000

Epoch 91: val_loss improved from 0.03849 to 0.03843, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0375 - mse: 0.0375 - mae: 0.1520 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1538 - 1s/epoch - 607ms/step
Epoch 92/10000

Epoch 92: val_loss improved from 0.03843 to 0.03842, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0375 - mse: 0.0375 - mae: 0.1523 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1537 - 1s/epoch - 615ms/step
Epoch 93/10000

Epoch 93: val_loss did not improve from 0.03842
2/2 - 0s - loss: 0.0375 - mse: 0.0375 - mae: 0.1519 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1532 - 334ms/epoch - 167ms/step
Epoch 94/10000

Epoch 94: val_loss did not improve from 0.03842
2/2 - 0s - loss: 0.0374 - mse: 0.0374 - mae: 0.1512 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1528 - 330ms/epoch - 165ms/step
Epoch 95/10000

Epoch 95: val_loss did not improve from 0.03842
2/2 - 0s - loss: 0.0374 - mse: 0.0374 - mae: 0.1505 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1526 - 333ms/epoch - 166ms/step
Epoch 96/10000

Epoch 96: val_loss did not improve from 0.03842
2/2 - 0s - loss: 0.0374 - mse: 0.0374 - mae: 0.1501 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1526 - 329ms/epoch - 165ms/step
Epoch 97/10000

Epoch 97: val_loss improved from 0.03842 to 0.03842, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0374 - mse: 0.0374 - mae: 0.1504 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1529 - 1s/epoch - 577ms/step
Epoch 98/10000

Epoch 98: val_loss improved from 0.03842 to 0.03837, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0373 - mse: 0.0373 - mae: 0.1509 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1530 - 1s/epoch - 610ms/step
Epoch 99/10000

Epoch 99: val_loss improved from 0.03837 to 0.03836, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0373 - mse: 0.0373 - mae: 0.1511 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1529 - 1s/epoch - 615ms/step
Epoch 100/10000

Epoch 100: val_loss did not improve from 0.03836
2/2 - 0s - loss: 0.0373 - mse: 0.0373 - mae: 0.1508 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1525 - 334ms/epoch - 167ms/step
Epoch 101/10000

Epoch 101: val_loss did not improve from 0.03836
2/2 - 0s - loss: 0.0373 - mse: 0.0373 - mae: 0.1500 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1521 - 333ms/epoch - 166ms/step
Epoch 102/10000

Epoch 102: val_loss did not improve from 0.03836
2/2 - 0s - loss: 0.0372 - mse: 0.0372 - mae: 0.1496 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1522 - 330ms/epoch - 165ms/step
Epoch 103/10000

Epoch 103: val_loss did not improve from 0.03836
2/2 - 0s - loss: 0.0372 - mse: 0.0372 - mae: 0.1499 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1524 - 333ms/epoch - 167ms/step
Epoch 104/10000

Epoch 104: val_loss improved from 0.03836 to 0.03835, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0372 - mse: 0.0372 - mae: 0.1502 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1523 - 1s/epoch - 576ms/step
Epoch 105/10000

Epoch 105: val_loss did not improve from 0.03835
2/2 - 0s - loss: 0.0371 - mse: 0.0371 - mae: 0.1500 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1521 - 340ms/epoch - 170ms/step
Epoch 106/10000

Epoch 106: val_loss did not improve from 0.03835
2/2 - 0s - loss: 0.0371 - mse: 0.0371 - mae: 0.1496 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1519 - 326ms/epoch - 163ms/step
Epoch 107/10000

Epoch 107: val_loss did not improve from 0.03835
2/2 - 0s - loss: 0.0371 - mse: 0.0371 - mae: 0.1491 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1517 - 328ms/epoch - 164ms/step
Epoch 108/10000

Epoch 108: val_loss did not improve from 0.03835
2/2 - 0s - loss: 0.0371 - mse: 0.0371 - mae: 0.1488 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1517 - 327ms/epoch - 164ms/step
Epoch 109/10000

Epoch 109: val_loss did not improve from 0.03835
2/2 - 0s - loss: 0.0370 - mse: 0.0370 - mae: 0.1490 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1518 - 333ms/epoch - 167ms/step
Epoch 110/10000

Epoch 110: val_loss improved from 0.03835 to 0.03834, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0370 - mse: 0.0370 - mae: 0.1492 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1519 - 1s/epoch - 613ms/step
Epoch 111/10000

Epoch 111: val_loss improved from 0.03834 to 0.03834, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0370 - mse: 0.0370 - mae: 0.1493 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1518 - 1s/epoch - 577ms/step
Epoch 112/10000

Epoch 112: val_loss did not improve from 0.03834
2/2 - 0s - loss: 0.0370 - mse: 0.0370 - mae: 0.1491 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1516 - 339ms/epoch - 169ms/step
Epoch 113/10000

Epoch 113: val_loss did not improve from 0.03834
2/2 - 0s - loss: 0.0370 - mse: 0.0370 - mae: 0.1488 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1515 - 334ms/epoch - 167ms/step
Epoch 114/10000

Epoch 114: val_loss did not improve from 0.03834
2/2 - 0s - loss: 0.0370 - mse: 0.0370 - mae: 0.1484 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1513 - 328ms/epoch - 164ms/step
Epoch 115/10000

Epoch 115: val_loss did not improve from 0.03834
2/2 - 0s - loss: 0.0369 - mse: 0.0369 - mae: 0.1482 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1513 - 334ms/epoch - 167ms/step
Epoch 116/10000

Epoch 116: val_loss did not improve from 0.03834
2/2 - 0s - loss: 0.0369 - mse: 0.0369 - mae: 0.1483 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1513 - 333ms/epoch - 167ms/step
Epoch 117/10000

Epoch 117: val_loss improved from 0.03834 to 0.03833, saving model to ./results/NN_thk_regr/RNN/recursion_25/ckpt_1
2/2 - 1s - loss: 0.0369 - mse: 0.0369 - mae: 0.1484 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1514 - 1s/epoch - 604ms/step
Epoch 118/10000

Epoch 118: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0369 - mse: 0.0369 - mae: 0.1485 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1513 - 334ms/epoch - 167ms/step
Epoch 119/10000

Epoch 119: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0369 - mse: 0.0369 - mae: 0.1484 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1512 - 326ms/epoch - 163ms/step
Epoch 120/10000

Epoch 120: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0368 - mse: 0.0368 - mae: 0.1480 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1510 - 327ms/epoch - 164ms/step
Epoch 121/10000

Epoch 121: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0368 - mse: 0.0368 - mae: 0.1479 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1510 - 329ms/epoch - 165ms/step
Epoch 122/10000

Epoch 122: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0368 - mse: 0.0368 - mae: 0.1478 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1510 - 331ms/epoch - 165ms/step
Epoch 123/10000

Epoch 123: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0368 - mse: 0.0368 - mae: 0.1477 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1509 - 326ms/epoch - 163ms/step
Epoch 124/10000

Epoch 124: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0368 - mse: 0.0368 - mae: 0.1476 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1509 - 338ms/epoch - 169ms/step
Epoch 125/10000

Epoch 125: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0368 - mse: 0.0368 - mae: 0.1477 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1510 - 329ms/epoch - 165ms/step
Epoch 126/10000

Epoch 126: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0368 - mse: 0.0368 - mae: 0.1479 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1510 - 335ms/epoch - 168ms/step
Epoch 127/10000

Epoch 127: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1477 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1508 - 331ms/epoch - 165ms/step
Epoch 128/10000

Epoch 128: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1473 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1506 - 333ms/epoch - 167ms/step
Epoch 129/10000

Epoch 129: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1472 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1507 - 331ms/epoch - 165ms/step
Epoch 130/10000

Epoch 130: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1473 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1507 - 330ms/epoch - 165ms/step
Epoch 131/10000

Epoch 131: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1473 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1507 - 333ms/epoch - 167ms/step
Epoch 132/10000

Epoch 132: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1473 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1506 - 328ms/epoch - 164ms/step
Epoch 133/10000

Epoch 133: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1471 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1505 - 333ms/epoch - 167ms/step
Epoch 134/10000

Epoch 134: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1469 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1504 - 332ms/epoch - 166ms/step
Epoch 135/10000

Epoch 135: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0367 - mse: 0.0367 - mae: 0.1468 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1505 - 332ms/epoch - 166ms/step
Epoch 136/10000

Epoch 136: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1469 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1505 - 335ms/epoch - 167ms/step
Epoch 137/10000

Epoch 137: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1469 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1504 - 329ms/epoch - 165ms/step
Epoch 138/10000

Epoch 138: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1466 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1503 - 331ms/epoch - 165ms/step
Epoch 139/10000

Epoch 139: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1464 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1503 - 326ms/epoch - 163ms/step
Epoch 140/10000

Epoch 140: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1466 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1504 - 329ms/epoch - 164ms/step
Epoch 141/10000

Epoch 141: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1469 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1504 - 332ms/epoch - 166ms/step
Epoch 142/10000

Epoch 142: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1468 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1503 - 332ms/epoch - 166ms/step
Epoch 143/10000

Epoch 143: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1464 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1502 - 336ms/epoch - 168ms/step
Epoch 144/10000

Epoch 144: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1461 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1502 - 336ms/epoch - 168ms/step
Epoch 145/10000

Epoch 145: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1464 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1503 - 334ms/epoch - 167ms/step
Epoch 146/10000

Epoch 146: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1468 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1503 - 334ms/epoch - 167ms/step
Epoch 147/10000

Epoch 147: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1465 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1501 - 329ms/epoch - 164ms/step
Epoch 148/10000

Epoch 148: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1460 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1500 - 334ms/epoch - 167ms/step
Epoch 149/10000

Epoch 149: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1459 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1501 - 335ms/epoch - 167ms/step
Epoch 150/10000

Epoch 150: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1461 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1502 - 333ms/epoch - 167ms/step
Epoch 151/10000

Epoch 151: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1463 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1502 - 331ms/epoch - 165ms/step
Epoch 152/10000

Epoch 152: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1464 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1502 - 328ms/epoch - 164ms/step
Epoch 153/10000

Epoch 153: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1463 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1500 - 333ms/epoch - 167ms/step
Epoch 154/10000

Epoch 154: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1459 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1499 - 335ms/epoch - 167ms/step
Epoch 155/10000

Epoch 155: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1455 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1499 - 327ms/epoch - 164ms/step
Epoch 156/10000

Epoch 156: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1455 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1500 - 335ms/epoch - 167ms/step
Epoch 157/10000

Epoch 157: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1461 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1502 - 333ms/epoch - 166ms/step
Epoch 158/10000

Epoch 158: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1466 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1501 - 329ms/epoch - 164ms/step
Epoch 159/10000

Epoch 159: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1461 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1499 - 333ms/epoch - 166ms/step
Epoch 160/10000

Epoch 160: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1454 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1499 - 325ms/epoch - 163ms/step
Epoch 161/10000

Epoch 161: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0366 - mse: 0.0366 - mae: 0.1454 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1499 - 331ms/epoch - 166ms/step
Epoch 162/10000

Epoch 162: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1458 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1500 - 329ms/epoch - 165ms/step
Epoch 163/10000

Epoch 163: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1459 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1499 - 328ms/epoch - 164ms/step
Epoch 164/10000

Epoch 164: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1458 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1498 - 333ms/epoch - 166ms/step
Epoch 165/10000

Epoch 165: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1454 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1498 - 329ms/epoch - 165ms/step
Epoch 166/10000

Epoch 166: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1452 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1499 - 334ms/epoch - 167ms/step
Epoch 167/10000

Epoch 167: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1457 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1501 - 331ms/epoch - 165ms/step
Epoch 168/10000

Epoch 168: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0365 - mse: 0.0365 - mae: 0.1461 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1500 - 331ms/epoch - 166ms/step
Epoch 169/10000

Epoch 169: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1459 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1498 - 335ms/epoch - 167ms/step
Epoch 170/10000

Epoch 170: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1454 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1498 - 329ms/epoch - 165ms/step
Epoch 171/10000

Epoch 171: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1451 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1498 - 332ms/epoch - 166ms/step
Epoch 172/10000

Epoch 172: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1454 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1499 - 333ms/epoch - 166ms/step
Epoch 173/10000

Epoch 173: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1455 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 329ms/epoch - 165ms/step
Epoch 174/10000

Epoch 174: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1456 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1499 - 333ms/epoch - 167ms/step
Epoch 175/10000

Epoch 175: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1456 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 332ms/epoch - 166ms/step
Epoch 176/10000

Epoch 176: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1454 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1497 - 330ms/epoch - 165ms/step
Epoch 177/10000

Epoch 177: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1453 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1497 - 331ms/epoch - 165ms/step
Epoch 178/10000

Epoch 178: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1451 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1497 - 330ms/epoch - 165ms/step
Epoch 179/10000

Epoch 179: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1449 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1497 - 329ms/epoch - 164ms/step
Epoch 180/10000

Epoch 180: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1451 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 331ms/epoch - 166ms/step
Epoch 181/10000

Epoch 181: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1457 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1499 - 329ms/epoch - 165ms/step
Epoch 182/10000

Epoch 182: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1457 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 332ms/epoch - 166ms/step
Epoch 183/10000

Epoch 183: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1452 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1497 - 330ms/epoch - 165ms/step
Epoch 184/10000

Epoch 184: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1449 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1497 - 333ms/epoch - 167ms/step
Epoch 185/10000

Epoch 185: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1453 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1499 - 332ms/epoch - 166ms/step
Epoch 186/10000

Epoch 186: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1457 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 330ms/epoch - 165ms/step
Epoch 187/10000

Epoch 187: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1452 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1496 - 334ms/epoch - 167ms/step
Epoch 188/10000

Epoch 188: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1448 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1496 - 332ms/epoch - 166ms/step
Epoch 189/10000

Epoch 189: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1448 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1497 - 327ms/epoch - 163ms/step
Epoch 190/10000

Epoch 190: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1451 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 336ms/epoch - 168ms/step
Epoch 191/10000

Epoch 191: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0364 - mse: 0.0364 - mae: 0.1454 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 332ms/epoch - 166ms/step
Epoch 192/10000

Epoch 192: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1454 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1497 - 328ms/epoch - 164ms/step
Epoch 193/10000

Epoch 193: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1450 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1496 - 328ms/epoch - 164ms/step
Epoch 194/10000

Epoch 194: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1447 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1496 - 332ms/epoch - 166ms/step
Epoch 195/10000

Epoch 195: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1447 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 331ms/epoch - 166ms/step
Epoch 196/10000

Epoch 196: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1452 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1499 - 329ms/epoch - 164ms/step
Epoch 197/10000

Epoch 197: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1455 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1497 - 335ms/epoch - 168ms/step
Epoch 198/10000

Epoch 198: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1451 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 339ms/epoch - 170ms/step
Epoch 199/10000

Epoch 199: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1447 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 332ms/epoch - 166ms/step
Epoch 200/10000

Epoch 200: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1448 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1497 - 334ms/epoch - 167ms/step
Epoch 201/10000

Epoch 201: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1451 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1497 - 329ms/epoch - 165ms/step
Epoch 202/10000

Epoch 202: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1450 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 333ms/epoch - 167ms/step
Epoch 203/10000

Epoch 203: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1447 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 334ms/epoch - 167ms/step
Epoch 204/10000

Epoch 204: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1446 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 329ms/epoch - 165ms/step
Epoch 205/10000

Epoch 205: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1447 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1497 - 334ms/epoch - 167ms/step
Epoch 206/10000

Epoch 206: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1452 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1498 - 328ms/epoch - 164ms/step
Epoch 207/10000

Epoch 207: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1451 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 334ms/epoch - 167ms/step
Epoch 208/10000

Epoch 208: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1447 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1496 - 332ms/epoch - 166ms/step
Epoch 209/10000

Epoch 209: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1448 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 330ms/epoch - 165ms/step
Epoch 210/10000

Epoch 210: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1448 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 333ms/epoch - 167ms/step
Epoch 211/10000

Epoch 211: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1446 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 328ms/epoch - 164ms/step
Epoch 212/10000

Epoch 212: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1446 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 333ms/epoch - 167ms/step
Epoch 213/10000

Epoch 213: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1449 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1497 - 328ms/epoch - 164ms/step
Epoch 214/10000

Epoch 214: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1451 - val_loss: 0.0385 - val_mse: 0.0385 - val_mae: 0.1496 - 334ms/epoch - 167ms/step
Epoch 215/10000

Epoch 215: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1447 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1495 - 335ms/epoch - 168ms/step
Epoch 216/10000

Epoch 216: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1444 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1495 - 334ms/epoch - 167ms/step
Epoch 217/10000

Epoch 217: val_loss did not improve from 0.03833
2/2 - 0s - loss: 0.0363 - mse: 0.0363 - mae: 0.1444 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1496 - 330ms/epoch - 165ms/step
Epoch 217: early stopping
