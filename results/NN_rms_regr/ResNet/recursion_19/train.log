[ 13.14519438  30.04553007  46.53366244  63.02179482  79.5099272
  95.99805957 112.48619195 128.97432432 145.4624567  161.95058908
 178.43872145 194.92685383 211.41498621 227.90311858 244.39125096
 260.87938334 277.36751571 293.85564809 310.34378047 326.83191284
 343.32004522 359.80817759 376.29630997 392.78444235 409.27257472
 425.7607071 ]
Before undersampling: [(0, 375), (1, 834), (2, 3661), (3, 4955), (4, 3156), (5, 2425), (6, 2195), (7, 1862), (8, 1648), (9, 1497), (10, 1418), (11, 1313), (12, 1182), (13, 1082), (14, 902), (15, 843), (16, 708), (17, 675), (18, 486), (19, 429), (20, 347), (21, 282), (22, 251), (23, 195), (24, 209)]
After undersampling: [(0, 158), (1, 391), (2, 2657), (3, 3144), (4, 2235), (5, 1749), (6, 1542), (7, 1259), (8, 1264), (9, 1025), (10, 959), (11, 894), (12, 835), (13, 782), (14, 662), (15, 596), (16, 466), (17, 477), (18, 314), (19, 308), (20, 230), (21, 180), (22, 169), (23, 195), (24, 165)]
            label  HH_0_0_x  HV_0_0_x  IA_0_0_x       FYI      DFYI       MYI     rms_0     thk_1     rms_1     thk_2     rms_2     thk_3     rms_3  ...    3         4    5         6         7         8         9        10   11        12   13        14        15                                                CNN
0       16.899340  0.188235  0.039216  0.089391  0.922564  0.071318  0.006118  4.417264  1.133321  4.365023  1.075755  4.348442  1.131209  4.302939  ...  0.0  1.137160  0.0  0.684263  0.703874  0.913822  0.297111  1.068257  0.0  0.835725  0.0  0.796567  0.623173  [[[[0.1411764705882353], [0.089433266134823], ...
1       19.605537  0.160784  0.050980  0.090285  0.678047  0.299178  0.022775  4.529253  1.127222  4.475911  1.094633  4.462218  1.123002  4.442899  ...  0.0  1.105097  0.0  0.686322  0.638387  0.907717  0.301203  1.044980  0.0  0.817731  0.0  0.798199  0.576430  [[[[0.2117647058823529], [0.0903268926283892],...
2       24.847515  0.368627  0.074510  0.111768  0.193828  0.142546  0.663627  4.764492  1.218180  4.901533  1.228689  4.888983  1.243341  4.818077  ...  0.0  0.845783  0.0  0.589817  0.366105  0.733218  0.310030  0.784128  0.0  0.617140  0.0  0.665264  0.342800  [[[[0.5254901960784314], [0.1117299173392501],...
3       25.121198  0.121569  0.074510  0.150416  0.459552  0.105872  0.434576  4.905298  1.280073  4.885018  1.213287  4.873958  1.241845  4.880463  ...  0.0  0.716333  0.0  0.424477  0.365133  0.577178  0.389077  0.499268  0.0  0.579164  0.0  0.507912  0.394418  [[[[0.5568627450980392], [0.1504481596105239],...
4       14.315963  0.125490  0.054902  0.114732  0.983127  0.006677  0.010196  4.375247  1.120706  4.369860  1.083821  4.339561  1.104304  4.300324  ...  0.0  1.088001  0.0  0.626989  0.676717  0.827304  0.226456  1.009606  0.0  0.798301  0.0  0.738400  0.599015  [[[[0.1333333333333333], [0.1146937426398782],...
...           ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...  ...       ...  ...       ...       ...       ...       ...       ...  ...       ...  ...       ...       ...                                                ...
22651  417.027580  0.505882  0.090196  0.152162  0.185910  0.031902  0.782188  4.486675  1.202497  4.531466  1.252972  4.593008  1.239219  4.510143  ...  0.0  0.839703  0.0  0.468273  0.499118  0.650608  0.278814  0.681403  0.0  0.621146  0.0  0.548368  0.455899  [[[[0.4196078431372549], [0.15219440834195], [...
22652  417.866263  0.392157  0.125490  0.152184  0.189279  0.051355  0.759366  4.590506  1.242536  4.658542  1.255140  4.682031  1.275536  4.639037  ...  0.0  0.753041  0.0  0.432618  0.424933  0.606180  0.279904  0.615722  0.0  0.551801  0.0  0.504145  0.391604  [[[[0.3490196078431372], [0.1522158155254289],...
22653  421.196328  0.631373  0.466667  0.154089  0.004261  0.000064  0.995674  1.187829  0.197352  0.941815  0.203265  0.245285  0.157730  0.213412  ...  0.0  0.644292  0.0  0.466233  0.184014  0.544459  0.317551  0.496343  0.0  0.488684  0.0  0.521621  0.200857  [[[[0.596078431372549], [0.1541208603802849], ...
22654  416.289186  0.517647  0.160784  0.153404  0.011037  0.000341  0.988622  1.187829  0.197352  0.941815  0.203265  0.245285  0.157730  0.213412  ...  0.0  0.792541  0.0  0.518223  0.461039  0.679398  0.335284  0.699151  0.0  0.512142  0.0  0.532694  0.315921  [[[[0.4078431372549019], [0.1534358903473499],...
22655  423.194662  0.341176  0.274510  0.153307  0.003870  0.000024  0.996105  1.187829  0.197352  0.941815  0.203265  0.245285  0.157730  0.213412  ...  0.0  0.712026  0.0  0.452670  0.356484  0.560431  0.500874  0.445316  0.0  0.508642  0.0  0.462847  0.257479  [[[[0.5686274509803921], [0.1533395804610907],...

[22656 rows x 128 columns]
Size of dataset: (22656, 127)
*************************** Fold #: 1 ***************************
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 conv (InputLayer)              [(None, 7, 7, 3, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 zero_padding3d (ZeroPadding3D)  (None, 8, 8, 4, 1)  0           ['conv[0][0]']                   
                                                                                                  
 conv3d (Conv3D)                (None, 8, 8, 4, 8)   224         ['zero_padding3d[0][0]']         
                                                                                                  
 max_pooling3d (MaxPooling3D)   (None, 4, 4, 2, 8)   0           ['conv3d[0][0]']                 
                                                                                                  
 conv3d_1 (Conv3D)              (None, 4, 4, 2, 4)   868         ['max_pooling3d[0][0]']          
                                                                                                  
 max_pooling3d_1 (MaxPooling3D)  (None, 2, 2, 1, 4)  0           ['conv3d_1[0][0]']               
                                                                                                  
 cat (InputLayer)               [(None, 126)]        0           []                               
                                                                                                  
 flatten (Flatten)              (None, 16)           0           ['max_pooling3d_1[0][0]']        
                                                                                                  
 concatenate (Concatenate)      (None, 142)          0           ['cat[0][0]',                    
                                                                  'flatten[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 200)          28600       ['concatenate[0][0]']            
                                                                                                  
 dense_1 (Dense)                (None, 200)          40200       ['dense[0][0]']                  
                                                                                                  
 dense_2 (Dense)                (None, 200)          40200       ['dense_1[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 200)          40200       ['dense_2[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 200)          40200       ['dense_3[0][0]']                
                                                                                                  
 dense_5 (Dense)                (None, 1)            201         ['dense_4[0][0]']                
                                                                                                  
==================================================================================================
Total params: 190,693
Trainable params: 190,693
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/10000

Epoch 1: val_loss improved from inf to 1.76124, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 10.0792 - mse: 10.0792 - mae: 2.7396 - val_loss: 1.7612 - val_mse: 1.7612 - val_mae: 1.0823 - 3s/epoch - 274ms/step
Epoch 2/10000

Epoch 2: val_loss improved from 1.76124 to 0.79721, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 1.7113 - mse: 1.7113 - mae: 1.0251 - val_loss: 0.7972 - val_mse: 0.7972 - val_mae: 0.5457 - 3s/epoch - 229ms/step
Epoch 3/10000

Epoch 3: val_loss improved from 0.79721 to 0.76911, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.9513 - mse: 0.9513 - mae: 0.6367 - val_loss: 0.7691 - val_mse: 0.7691 - val_mae: 0.5615 - 3s/epoch - 230ms/step
Epoch 4/10000

Epoch 4: val_loss improved from 0.76911 to 0.61155, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.7492 - mse: 0.7492 - mae: 0.5554 - val_loss: 0.6116 - val_mse: 0.6116 - val_mae: 0.5197 - 3s/epoch - 229ms/step
Epoch 5/10000

Epoch 5: val_loss improved from 0.61155 to 0.33760, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.5267 - mse: 0.5267 - mae: 0.5117 - val_loss: 0.3376 - val_mse: 0.3376 - val_mae: 0.4612 - 3s/epoch - 229ms/step
Epoch 6/10000

Epoch 6: val_loss improved from 0.33760 to 0.32542, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.3146 - mse: 0.3146 - mae: 0.4546 - val_loss: 0.3254 - val_mse: 0.3254 - val_mae: 0.4570 - 3s/epoch - 229ms/step
Epoch 7/10000

Epoch 7: val_loss improved from 0.32542 to 0.28682, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.3053 - mse: 0.3053 - mae: 0.4490 - val_loss: 0.2868 - val_mse: 0.2868 - val_mae: 0.4369 - 3s/epoch - 242ms/step
Epoch 8/10000

Epoch 8: val_loss improved from 0.28682 to 0.28070, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2969 - mse: 0.2969 - mae: 0.4450 - val_loss: 0.2807 - val_mse: 0.2807 - val_mae: 0.4339 - 3s/epoch - 242ms/step
Epoch 9/10000

Epoch 9: val_loss did not improve from 0.28070
12/12 - 2s - loss: 0.2878 - mse: 0.2878 - mae: 0.4387 - val_loss: 0.2811 - val_mse: 0.2811 - val_mae: 0.4340 - 2s/epoch - 168ms/step
Epoch 10/10000

Epoch 10: val_loss improved from 0.28070 to 0.27899, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2869 - mse: 0.2869 - mae: 0.4379 - val_loss: 0.2790 - val_mse: 0.2790 - val_mae: 0.4320 - 3s/epoch - 236ms/step
Epoch 11/10000

Epoch 11: val_loss did not improve from 0.27899
12/12 - 2s - loss: 0.2860 - mse: 0.2860 - mae: 0.4371 - val_loss: 0.2826 - val_mse: 0.2826 - val_mae: 0.4336 - 2s/epoch - 167ms/step
Epoch 12/10000

Epoch 12: val_loss improved from 0.27899 to 0.27843, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2916 - mse: 0.2916 - mae: 0.4409 - val_loss: 0.2784 - val_mse: 0.2784 - val_mae: 0.4318 - 3s/epoch - 241ms/step
Epoch 13/10000

Epoch 13: val_loss improved from 0.27843 to 0.27824, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2894 - mse: 0.2894 - mae: 0.4383 - val_loss: 0.2782 - val_mse: 0.2782 - val_mae: 0.4315 - 3s/epoch - 242ms/step
Epoch 14/10000

Epoch 14: val_loss did not improve from 0.27824
12/12 - 2s - loss: 0.2849 - mse: 0.2849 - mae: 0.4360 - val_loss: 0.2865 - val_mse: 0.2865 - val_mae: 0.4352 - 2s/epoch - 167ms/step
Epoch 15/10000

Epoch 15: val_loss improved from 0.27824 to 0.27719, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2888 - mse: 0.2888 - mae: 0.4384 - val_loss: 0.2772 - val_mse: 0.2772 - val_mae: 0.4305 - 3s/epoch - 245ms/step
Epoch 16/10000

Epoch 16: val_loss did not improve from 0.27719
12/12 - 2s - loss: 0.2866 - mse: 0.2866 - mae: 0.4364 - val_loss: 0.2970 - val_mse: 0.2970 - val_mae: 0.4447 - 2s/epoch - 168ms/step
Epoch 17/10000

Epoch 17: val_loss improved from 0.27719 to 0.27588, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2908 - mse: 0.2908 - mae: 0.4396 - val_loss: 0.2759 - val_mse: 0.2759 - val_mae: 0.4286 - 3s/epoch - 236ms/step
Epoch 18/10000

Epoch 18: val_loss improved from 0.27588 to 0.27563, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2844 - mse: 0.2844 - mae: 0.4351 - val_loss: 0.2756 - val_mse: 0.2756 - val_mae: 0.4284 - 3s/epoch - 243ms/step
Epoch 19/10000

Epoch 19: val_loss did not improve from 0.27563
12/12 - 2s - loss: 0.2833 - mse: 0.2833 - mae: 0.4337 - val_loss: 0.2826 - val_mse: 0.2826 - val_mae: 0.4319 - 2s/epoch - 168ms/step
Epoch 20/10000

Epoch 20: val_loss improved from 0.27563 to 0.27528, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2864 - mse: 0.2864 - mae: 0.4361 - val_loss: 0.2753 - val_mse: 0.2753 - val_mae: 0.4277 - 3s/epoch - 249ms/step
Epoch 21/10000

Epoch 21: val_loss did not improve from 0.27528
12/12 - 2s - loss: 0.2856 - mse: 0.2856 - mae: 0.4353 - val_loss: 0.2768 - val_mse: 0.2768 - val_mae: 0.4295 - 2s/epoch - 168ms/step
Epoch 22/10000

Epoch 22: val_loss did not improve from 0.27528
12/12 - 2s - loss: 0.2838 - mse: 0.2838 - mae: 0.4337 - val_loss: 0.2776 - val_mse: 0.2776 - val_mae: 0.4287 - 2s/epoch - 169ms/step
Epoch 23/10000

Epoch 23: val_loss improved from 0.27528 to 0.27500, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2854 - mse: 0.2854 - mae: 0.4347 - val_loss: 0.2750 - val_mse: 0.2750 - val_mae: 0.4278 - 3s/epoch - 240ms/step
Epoch 24/10000

Epoch 24: val_loss did not improve from 0.27500
12/12 - 2s - loss: 0.2822 - mse: 0.2822 - mae: 0.4326 - val_loss: 0.2959 - val_mse: 0.2959 - val_mae: 0.4428 - 2s/epoch - 173ms/step
Epoch 25/10000

Epoch 25: val_loss did not improve from 0.27500
12/12 - 2s - loss: 0.2891 - mse: 0.2891 - mae: 0.4378 - val_loss: 0.2805 - val_mse: 0.2805 - val_mae: 0.4319 - 2s/epoch - 168ms/step
Epoch 26/10000

Epoch 26: val_loss did not improve from 0.27500
12/12 - 2s - loss: 0.2874 - mse: 0.2874 - mae: 0.4363 - val_loss: 0.2775 - val_mse: 0.2775 - val_mae: 0.4281 - 2s/epoch - 175ms/step
Epoch 27/10000

Epoch 27: val_loss did not improve from 0.27500
12/12 - 2s - loss: 0.2833 - mse: 0.2833 - mae: 0.4336 - val_loss: 0.2756 - val_mse: 0.2756 - val_mae: 0.4270 - 2s/epoch - 168ms/step
Epoch 28/10000

Epoch 28: val_loss improved from 0.27500 to 0.27478, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2830 - mse: 0.2830 - mae: 0.4326 - val_loss: 0.2748 - val_mse: 0.2748 - val_mae: 0.4272 - 3s/epoch - 249ms/step
Epoch 29/10000

Epoch 29: val_loss did not improve from 0.27478
12/12 - 2s - loss: 0.2809 - mse: 0.2809 - mae: 0.4313 - val_loss: 0.2981 - val_mse: 0.2981 - val_mae: 0.4438 - 2s/epoch - 169ms/step
Epoch 30/10000

Epoch 30: val_loss did not improve from 0.27478
12/12 - 2s - loss: 0.2917 - mse: 0.2917 - mae: 0.4380 - val_loss: 0.2761 - val_mse: 0.2761 - val_mae: 0.4282 - 2s/epoch - 167ms/step
Epoch 31/10000

Epoch 31: val_loss improved from 0.27478 to 0.27445, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2883 - mse: 0.2883 - mae: 0.4372 - val_loss: 0.2744 - val_mse: 0.2744 - val_mae: 0.4268 - 3s/epoch - 241ms/step
Epoch 32/10000

Epoch 32: val_loss did not improve from 0.27445
12/12 - 2s - loss: 0.2856 - mse: 0.2856 - mae: 0.4347 - val_loss: 0.2763 - val_mse: 0.2763 - val_mae: 0.4269 - 2s/epoch - 171ms/step
Epoch 33/10000

Epoch 33: val_loss did not improve from 0.27445
12/12 - 2s - loss: 0.2826 - mse: 0.2826 - mae: 0.4323 - val_loss: 0.2771 - val_mse: 0.2771 - val_mae: 0.4274 - 2s/epoch - 168ms/step
Epoch 34/10000

Epoch 34: val_loss did not improve from 0.27445
12/12 - 2s - loss: 0.2848 - mse: 0.2848 - mae: 0.4336 - val_loss: 0.2794 - val_mse: 0.2794 - val_mae: 0.4303 - 2s/epoch - 168ms/step
Epoch 35/10000

Epoch 35: val_loss did not improve from 0.27445
12/12 - 2s - loss: 0.2823 - mse: 0.2823 - mae: 0.4318 - val_loss: 0.2801 - val_mse: 0.2801 - val_mae: 0.4311 - 2s/epoch - 168ms/step
Epoch 36/10000

Epoch 36: val_loss did not improve from 0.27445
12/12 - 2s - loss: 0.2824 - mse: 0.2824 - mae: 0.4317 - val_loss: 0.2907 - val_mse: 0.2907 - val_mae: 0.4384 - 2s/epoch - 168ms/step
Epoch 37/10000

Epoch 37: val_loss did not improve from 0.27445
12/12 - 2s - loss: 0.2894 - mse: 0.2894 - mae: 0.4366 - val_loss: 0.2918 - val_mse: 0.2918 - val_mae: 0.4390 - 2s/epoch - 168ms/step
Epoch 38/10000

Epoch 38: val_loss did not improve from 0.27445
12/12 - 2s - loss: 0.2899 - mse: 0.2899 - mae: 0.4370 - val_loss: 0.2760 - val_mse: 0.2760 - val_mae: 0.4277 - 2s/epoch - 168ms/step
Epoch 39/10000

Epoch 39: val_loss improved from 0.27445 to 0.27354, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2880 - mse: 0.2880 - mae: 0.4354 - val_loss: 0.2735 - val_mse: 0.2735 - val_mae: 0.4254 - 3s/epoch - 237ms/step
Epoch 40/10000

Epoch 40: val_loss improved from 0.27354 to 0.27317, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2834 - mse: 0.2834 - mae: 0.4327 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4250 - 3s/epoch - 241ms/step
Epoch 41/10000

Epoch 41: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2814 - mse: 0.2814 - mae: 0.4314 - val_loss: 0.2887 - val_mse: 0.2887 - val_mae: 0.4339 - 2s/epoch - 170ms/step
Epoch 42/10000

Epoch 42: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2866 - mse: 0.2866 - mae: 0.4344 - val_loss: 0.2857 - val_mse: 0.2857 - val_mae: 0.4320 - 2s/epoch - 168ms/step
Epoch 43/10000

Epoch 43: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2833 - mse: 0.2833 - mae: 0.4325 - val_loss: 0.2806 - val_mse: 0.2806 - val_mae: 0.4287 - 2s/epoch - 170ms/step
Epoch 44/10000

Epoch 44: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2855 - mse: 0.2855 - mae: 0.4345 - val_loss: 0.2904 - val_mse: 0.2904 - val_mae: 0.4349 - 2s/epoch - 168ms/step
Epoch 45/10000

Epoch 45: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2874 - mse: 0.2874 - mae: 0.4350 - val_loss: 0.2904 - val_mse: 0.2904 - val_mae: 0.4350 - 2s/epoch - 168ms/step
Epoch 46/10000

Epoch 46: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2928 - mse: 0.2928 - mae: 0.4382 - val_loss: 0.3239 - val_mse: 0.3239 - val_mae: 0.4568 - 2s/epoch - 168ms/step
Epoch 47/10000

Epoch 47: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.3104 - mse: 0.3104 - mae: 0.4502 - val_loss: 0.2873 - val_mse: 0.2873 - val_mae: 0.4331 - 2s/epoch - 172ms/step
Epoch 48/10000

Epoch 48: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2918 - mse: 0.2918 - mae: 0.4375 - val_loss: 0.2734 - val_mse: 0.2734 - val_mae: 0.4251 - 2s/epoch - 170ms/step
Epoch 49/10000

Epoch 49: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2834 - mse: 0.2834 - mae: 0.4317 - val_loss: 0.2916 - val_mse: 0.2916 - val_mae: 0.4356 - 2s/epoch - 167ms/step
Epoch 50/10000

Epoch 50: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2896 - mse: 0.2896 - mae: 0.4369 - val_loss: 0.2750 - val_mse: 0.2750 - val_mae: 0.4254 - 2s/epoch - 167ms/step
Epoch 51/10000

Epoch 51: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2816 - mse: 0.2816 - mae: 0.4308 - val_loss: 0.3002 - val_mse: 0.3002 - val_mae: 0.4414 - 2s/epoch - 168ms/step
Epoch 52/10000

Epoch 52: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2976 - mse: 0.2976 - mae: 0.4415 - val_loss: 0.2778 - val_mse: 0.2778 - val_mae: 0.4270 - 2s/epoch - 167ms/step
Epoch 53/10000

Epoch 53: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2825 - mse: 0.2825 - mae: 0.4316 - val_loss: 0.2823 - val_mse: 0.2823 - val_mae: 0.4297 - 2s/epoch - 168ms/step
Epoch 54/10000

Epoch 54: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2895 - mse: 0.2895 - mae: 0.4367 - val_loss: 0.2831 - val_mse: 0.2831 - val_mae: 0.4302 - 2s/epoch - 168ms/step
Epoch 55/10000

Epoch 55: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2822 - mse: 0.2822 - mae: 0.4307 - val_loss: 0.2836 - val_mse: 0.2836 - val_mae: 0.4304 - 2s/epoch - 168ms/step
Epoch 56/10000

Epoch 56: val_loss did not improve from 0.27317
12/12 - 2s - loss: 0.2863 - mse: 0.2863 - mae: 0.4341 - val_loss: 0.2748 - val_mse: 0.2748 - val_mae: 0.4253 - 2s/epoch - 168ms/step
Epoch 57/10000

Epoch 57: val_loss improved from 0.27317 to 0.27291, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2809 - mse: 0.2809 - mae: 0.4301 - val_loss: 0.2729 - val_mse: 0.2729 - val_mae: 0.4245 - 3s/epoch - 241ms/step
Epoch 58/10000

Epoch 58: val_loss did not improve from 0.27291
12/12 - 2s - loss: 0.2799 - mse: 0.2799 - mae: 0.4296 - val_loss: 0.2771 - val_mse: 0.2771 - val_mae: 0.4264 - 2s/epoch - 167ms/step
Epoch 59/10000

Epoch 59: val_loss did not improve from 0.27291
12/12 - 2s - loss: 0.2861 - mse: 0.2861 - mae: 0.4338 - val_loss: 0.2747 - val_mse: 0.2747 - val_mae: 0.4251 - 2s/epoch - 170ms/step
Epoch 60/10000

Epoch 60: val_loss did not improve from 0.27291
12/12 - 2s - loss: 0.2807 - mse: 0.2807 - mae: 0.4302 - val_loss: 0.2774 - val_mse: 0.2774 - val_mae: 0.4269 - 2s/epoch - 167ms/step
Epoch 61/10000

Epoch 61: val_loss did not improve from 0.27291
12/12 - 2s - loss: 0.2829 - mse: 0.2829 - mae: 0.4314 - val_loss: 0.2849 - val_mse: 0.2849 - val_mae: 0.4311 - 2s/epoch - 170ms/step
Epoch 62/10000

Epoch 62: val_loss improved from 0.27291 to 0.27269, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2863 - mse: 0.2863 - mae: 0.4336 - val_loss: 0.2727 - val_mse: 0.2727 - val_mae: 0.4241 - 3s/epoch - 241ms/step
Epoch 63/10000

Epoch 63: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2813 - mse: 0.2813 - mae: 0.4302 - val_loss: 0.2731 - val_mse: 0.2731 - val_mae: 0.4244 - 2s/epoch - 168ms/step
Epoch 64/10000

Epoch 64: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2805 - mse: 0.2805 - mae: 0.4297 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4247 - 2s/epoch - 167ms/step
Epoch 65/10000

Epoch 65: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2799 - mse: 0.2799 - mae: 0.4294 - val_loss: 0.2745 - val_mse: 0.2745 - val_mae: 0.4257 - 2s/epoch - 168ms/step
Epoch 66/10000

Epoch 66: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2797 - mse: 0.2797 - mae: 0.4290 - val_loss: 0.2758 - val_mse: 0.2758 - val_mae: 0.4266 - 2s/epoch - 167ms/step
Epoch 67/10000

Epoch 67: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2803 - mse: 0.2803 - mae: 0.4298 - val_loss: 0.2736 - val_mse: 0.2736 - val_mae: 0.4250 - 2s/epoch - 168ms/step
Epoch 68/10000

Epoch 68: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2793 - mse: 0.2793 - mae: 0.4286 - val_loss: 0.2757 - val_mse: 0.2757 - val_mae: 0.4268 - 2s/epoch - 167ms/step
Epoch 69/10000

Epoch 69: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2813 - mse: 0.2813 - mae: 0.4299 - val_loss: 0.2826 - val_mse: 0.2826 - val_mae: 0.4320 - 2s/epoch - 167ms/step
Epoch 70/10000

Epoch 70: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2854 - mse: 0.2854 - mae: 0.4334 - val_loss: 0.2734 - val_mse: 0.2734 - val_mae: 0.4239 - 2s/epoch - 167ms/step
Epoch 71/10000

Epoch 71: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2795 - mse: 0.2795 - mae: 0.4289 - val_loss: 0.2733 - val_mse: 0.2733 - val_mae: 0.4246 - 2s/epoch - 167ms/step
Epoch 72/10000

Epoch 72: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2804 - mse: 0.2804 - mae: 0.4296 - val_loss: 0.2731 - val_mse: 0.2731 - val_mae: 0.4240 - 2s/epoch - 167ms/step
Epoch 73/10000

Epoch 73: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2793 - mse: 0.2793 - mae: 0.4288 - val_loss: 0.2783 - val_mse: 0.2783 - val_mae: 0.4266 - 2s/epoch - 167ms/step
Epoch 74/10000

Epoch 74: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2811 - mse: 0.2811 - mae: 0.4301 - val_loss: 0.2785 - val_mse: 0.2785 - val_mae: 0.4288 - 2s/epoch - 168ms/step
Epoch 75/10000

Epoch 75: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2859 - mse: 0.2859 - mae: 0.4334 - val_loss: 0.2759 - val_mse: 0.2759 - val_mae: 0.4267 - 2s/epoch - 167ms/step
Epoch 76/10000

Epoch 76: val_loss did not improve from 0.27269
12/12 - 2s - loss: 0.2808 - mse: 0.2808 - mae: 0.4297 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4236 - 2s/epoch - 168ms/step
Epoch 77/10000

Epoch 77: val_loss improved from 0.27269 to 0.27253, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2802 - mse: 0.2802 - mae: 0.4292 - val_loss: 0.2725 - val_mse: 0.2725 - val_mae: 0.4234 - 3s/epoch - 241ms/step
Epoch 78/10000

Epoch 78: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2798 - mse: 0.2798 - mae: 0.4285 - val_loss: 0.2759 - val_mse: 0.2759 - val_mae: 0.4265 - 2s/epoch - 167ms/step
Epoch 79/10000

Epoch 79: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2803 - mse: 0.2803 - mae: 0.4292 - val_loss: 0.2939 - val_mse: 0.2939 - val_mae: 0.4395 - 2s/epoch - 167ms/step
Epoch 80/10000

Epoch 80: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2912 - mse: 0.2912 - mae: 0.4362 - val_loss: 0.2742 - val_mse: 0.2742 - val_mae: 0.4240 - 2s/epoch - 167ms/step
Epoch 81/10000

Epoch 81: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2840 - mse: 0.2840 - mae: 0.4312 - val_loss: 0.2850 - val_mse: 0.2850 - val_mae: 0.4331 - 2s/epoch - 167ms/step
Epoch 82/10000

Epoch 82: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2855 - mse: 0.2855 - mae: 0.4326 - val_loss: 0.2736 - val_mse: 0.2736 - val_mae: 0.4247 - 2s/epoch - 168ms/step
Epoch 83/10000

Epoch 83: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2807 - mse: 0.2807 - mae: 0.4292 - val_loss: 0.2750 - val_mse: 0.2750 - val_mae: 0.4248 - 2s/epoch - 167ms/step
Epoch 84/10000

Epoch 84: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2811 - mse: 0.2811 - mae: 0.4293 - val_loss: 0.2749 - val_mse: 0.2749 - val_mae: 0.4258 - 2s/epoch - 167ms/step
Epoch 85/10000

Epoch 85: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2807 - mse: 0.2807 - mae: 0.4290 - val_loss: 0.2745 - val_mse: 0.2745 - val_mae: 0.4242 - 2s/epoch - 167ms/step
Epoch 86/10000

Epoch 86: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2815 - mse: 0.2815 - mae: 0.4298 - val_loss: 0.2772 - val_mse: 0.2772 - val_mae: 0.4272 - 2s/epoch - 168ms/step
Epoch 87/10000

Epoch 87: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2826 - mse: 0.2826 - mae: 0.4304 - val_loss: 0.2823 - val_mse: 0.2823 - val_mae: 0.4289 - 2s/epoch - 168ms/step
Epoch 88/10000

Epoch 88: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2869 - mse: 0.2869 - mae: 0.4330 - val_loss: 0.2822 - val_mse: 0.2822 - val_mae: 0.4313 - 2s/epoch - 167ms/step
Epoch 89/10000

Epoch 89: val_loss did not improve from 0.27253
12/12 - 2s - loss: 0.2862 - mse: 0.2862 - mae: 0.4334 - val_loss: 0.3015 - val_mse: 0.3015 - val_mae: 0.4445 - 2s/epoch - 167ms/step
Epoch 90/10000

Epoch 90: val_loss improved from 0.27253 to 0.27245, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2843 - mse: 0.2843 - mae: 0.4313 - val_loss: 0.2724 - val_mse: 0.2724 - val_mae: 0.4233 - 3s/epoch - 236ms/step
Epoch 91/10000

Epoch 91: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2796 - mse: 0.2796 - mae: 0.4280 - val_loss: 0.2728 - val_mse: 0.2728 - val_mae: 0.4232 - 2s/epoch - 168ms/step
Epoch 92/10000

Epoch 92: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2792 - mse: 0.2792 - mae: 0.4279 - val_loss: 0.2740 - val_mse: 0.2740 - val_mae: 0.4237 - 2s/epoch - 169ms/step
Epoch 93/10000

Epoch 93: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2825 - mse: 0.2825 - mae: 0.4299 - val_loss: 0.3224 - val_mse: 0.3224 - val_mae: 0.4599 - 2s/epoch - 169ms/step
Epoch 94/10000

Epoch 94: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.3015 - mse: 0.3015 - mae: 0.4430 - val_loss: 0.2737 - val_mse: 0.2737 - val_mae: 0.4236 - 2s/epoch - 167ms/step
Epoch 95/10000

Epoch 95: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2814 - mse: 0.2814 - mae: 0.4291 - val_loss: 0.2977 - val_mse: 0.2977 - val_mae: 0.4392 - 2s/epoch - 167ms/step
Epoch 96/10000

Epoch 96: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2909 - mse: 0.2909 - mae: 0.4369 - val_loss: 0.3216 - val_mse: 0.3216 - val_mae: 0.4589 - 2s/epoch - 167ms/step
Epoch 97/10000

Epoch 97: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.3149 - mse: 0.3149 - mae: 0.4542 - val_loss: 0.2957 - val_mse: 0.2957 - val_mae: 0.4377 - 2s/epoch - 167ms/step
Epoch 98/10000

Epoch 98: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.3029 - mse: 0.3029 - mae: 0.4444 - val_loss: 0.2727 - val_mse: 0.2727 - val_mae: 0.4234 - 2s/epoch - 167ms/step
Epoch 99/10000

Epoch 99: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2893 - mse: 0.2893 - mae: 0.4353 - val_loss: 0.2734 - val_mse: 0.2734 - val_mae: 0.4246 - 2s/epoch - 168ms/step
Epoch 100/10000

Epoch 100: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2850 - mse: 0.2850 - mae: 0.4318 - val_loss: 0.2905 - val_mse: 0.2905 - val_mae: 0.4343 - 2s/epoch - 167ms/step
Epoch 101/10000

Epoch 101: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2839 - mse: 0.2839 - mae: 0.4321 - val_loss: 0.2952 - val_mse: 0.2952 - val_mae: 0.4372 - 2s/epoch - 167ms/step
Epoch 102/10000

Epoch 102: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2884 - mse: 0.2884 - mae: 0.4356 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4239 - 2s/epoch - 168ms/step
Epoch 103/10000

Epoch 103: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2847 - mse: 0.2847 - mae: 0.4319 - val_loss: 0.2780 - val_mse: 0.2780 - val_mae: 0.4280 - 2s/epoch - 167ms/step
Epoch 104/10000

Epoch 104: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2794 - mse: 0.2794 - mae: 0.4279 - val_loss: 0.2769 - val_mse: 0.2769 - val_mae: 0.4272 - 2s/epoch - 167ms/step
Epoch 105/10000

Epoch 105: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2797 - mse: 0.2797 - mae: 0.4284 - val_loss: 0.2825 - val_mse: 0.2825 - val_mae: 0.4288 - 2s/epoch - 167ms/step
Epoch 106/10000

Epoch 106: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2872 - mse: 0.2872 - mae: 0.4332 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4238 - 2s/epoch - 167ms/step
Epoch 107/10000

Epoch 107: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2820 - mse: 0.2820 - mae: 0.4300 - val_loss: 0.2999 - val_mse: 0.2999 - val_mae: 0.4437 - 2s/epoch - 168ms/step
Epoch 108/10000

Epoch 108: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2882 - mse: 0.2882 - mae: 0.4349 - val_loss: 0.2738 - val_mse: 0.2738 - val_mae: 0.4238 - 2s/epoch - 167ms/step
Epoch 109/10000

Epoch 109: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2818 - mse: 0.2818 - mae: 0.4299 - val_loss: 0.2749 - val_mse: 0.2749 - val_mae: 0.4242 - 2s/epoch - 168ms/step
Epoch 110/10000

Epoch 110: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2813 - mse: 0.2813 - mae: 0.4296 - val_loss: 0.2854 - val_mse: 0.2854 - val_mae: 0.4330 - 2s/epoch - 167ms/step
Epoch 111/10000

Epoch 111: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2853 - mse: 0.2853 - mae: 0.4330 - val_loss: 0.2725 - val_mse: 0.2725 - val_mae: 0.4232 - 2s/epoch - 167ms/step
Epoch 112/10000

Epoch 112: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2798 - mse: 0.2798 - mae: 0.4287 - val_loss: 0.2782 - val_mse: 0.2782 - val_mae: 0.4262 - 2s/epoch - 167ms/step
Epoch 113/10000

Epoch 113: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2824 - mse: 0.2824 - mae: 0.4298 - val_loss: 0.2772 - val_mse: 0.2772 - val_mae: 0.4278 - 2s/epoch - 167ms/step
Epoch 114/10000

Epoch 114: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2809 - mse: 0.2809 - mae: 0.4292 - val_loss: 0.2817 - val_mse: 0.2817 - val_mae: 0.4282 - 2s/epoch - 167ms/step
Epoch 115/10000

Epoch 115: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2816 - mse: 0.2816 - mae: 0.4297 - val_loss: 0.2823 - val_mse: 0.2823 - val_mae: 0.4309 - 2s/epoch - 167ms/step
Epoch 116/10000

Epoch 116: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2823 - mse: 0.2823 - mae: 0.4301 - val_loss: 0.2974 - val_mse: 0.2974 - val_mae: 0.4385 - 2s/epoch - 168ms/step
Epoch 117/10000

Epoch 117: val_loss did not improve from 0.27245
12/12 - 2s - loss: 0.2899 - mse: 0.2899 - mae: 0.4346 - val_loss: 0.2779 - val_mse: 0.2779 - val_mae: 0.4277 - 2s/epoch - 167ms/step
Epoch 118/10000

Epoch 118: val_loss improved from 0.27245 to 0.27239, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2809 - mse: 0.2809 - mae: 0.4294 - val_loss: 0.2724 - val_mse: 0.2724 - val_mae: 0.4227 - 3s/epoch - 241ms/step
Epoch 119/10000

Epoch 119: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2794 - mse: 0.2794 - mae: 0.4281 - val_loss: 0.2851 - val_mse: 0.2851 - val_mae: 0.4304 - 2s/epoch - 167ms/step
Epoch 120/10000

Epoch 120: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2868 - mse: 0.2868 - mae: 0.4330 - val_loss: 0.3250 - val_mse: 0.3250 - val_mae: 0.4610 - 2s/epoch - 167ms/step
Epoch 121/10000

Epoch 121: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2964 - mse: 0.2964 - mae: 0.4411 - val_loss: 0.3054 - val_mse: 0.3054 - val_mae: 0.4443 - 2s/epoch - 168ms/step
Epoch 122/10000

Epoch 122: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.3055 - mse: 0.3055 - mae: 0.4458 - val_loss: 0.2725 - val_mse: 0.2725 - val_mae: 0.4230 - 2s/epoch - 167ms/step
Epoch 123/10000

Epoch 123: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2801 - mse: 0.2801 - mae: 0.4290 - val_loss: 0.2928 - val_mse: 0.2928 - val_mae: 0.4382 - 2s/epoch - 166ms/step
Epoch 124/10000

Epoch 124: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2897 - mse: 0.2897 - mae: 0.4352 - val_loss: 0.2849 - val_mse: 0.2849 - val_mae: 0.4303 - 2s/epoch - 167ms/step
Epoch 125/10000

Epoch 125: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2898 - mse: 0.2898 - mae: 0.4356 - val_loss: 0.2845 - val_mse: 0.2845 - val_mae: 0.4323 - 2s/epoch - 167ms/step
Epoch 126/10000

Epoch 126: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2861 - mse: 0.2861 - mae: 0.4335 - val_loss: 0.2766 - val_mse: 0.2766 - val_mae: 0.4268 - 2s/epoch - 166ms/step
Epoch 127/10000

Epoch 127: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2808 - mse: 0.2808 - mae: 0.4293 - val_loss: 0.2875 - val_mse: 0.2875 - val_mae: 0.4320 - 2s/epoch - 167ms/step
Epoch 128/10000

Epoch 128: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2852 - mse: 0.2852 - mae: 0.4312 - val_loss: 0.3158 - val_mse: 0.3158 - val_mae: 0.4550 - 2s/epoch - 168ms/step
Epoch 129/10000

Epoch 129: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2912 - mse: 0.2912 - mae: 0.4364 - val_loss: 0.3079 - val_mse: 0.3079 - val_mae: 0.4455 - 2s/epoch - 168ms/step
Epoch 130/10000

Epoch 130: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2979 - mse: 0.2979 - mae: 0.4398 - val_loss: 0.2761 - val_mse: 0.2761 - val_mae: 0.4264 - 2s/epoch - 168ms/step
Epoch 131/10000

Epoch 131: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2792 - mse: 0.2792 - mae: 0.4279 - val_loss: 0.2955 - val_mse: 0.2955 - val_mae: 0.4405 - 2s/epoch - 168ms/step
Epoch 132/10000

Epoch 132: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2891 - mse: 0.2891 - mae: 0.4345 - val_loss: 0.2754 - val_mse: 0.2754 - val_mae: 0.4243 - 2s/epoch - 168ms/step
Epoch 133/10000

Epoch 133: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2788 - mse: 0.2788 - mae: 0.4273 - val_loss: 0.2817 - val_mse: 0.2817 - val_mae: 0.4306 - 2s/epoch - 167ms/step
Epoch 134/10000

Epoch 134: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2859 - mse: 0.2859 - mae: 0.4330 - val_loss: 0.2978 - val_mse: 0.2978 - val_mae: 0.4388 - 2s/epoch - 167ms/step
Epoch 135/10000

Epoch 135: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2939 - mse: 0.2939 - mae: 0.4378 - val_loss: 0.2954 - val_mse: 0.2954 - val_mae: 0.4399 - 2s/epoch - 168ms/step
Epoch 136/10000

Epoch 136: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2864 - mse: 0.2864 - mae: 0.4332 - val_loss: 0.2814 - val_mse: 0.2814 - val_mae: 0.4284 - 2s/epoch - 167ms/step
Epoch 137/10000

Epoch 137: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2861 - mse: 0.2861 - mae: 0.4326 - val_loss: 0.2737 - val_mse: 0.2737 - val_mae: 0.4246 - 2s/epoch - 167ms/step
Epoch 138/10000

Epoch 138: val_loss did not improve from 0.27239
12/12 - 2s - loss: 0.2812 - mse: 0.2812 - mae: 0.4294 - val_loss: 0.2951 - val_mse: 0.2951 - val_mae: 0.4396 - 2s/epoch - 167ms/step
Epoch 139/10000

Epoch 139: val_loss improved from 0.27239 to 0.27213, saving model to ./results/NN_rms_regr/ResNet/recursion_19/ckpt_1
12/12 - 3s - loss: 0.2854 - mse: 0.2854 - mae: 0.4325 - val_loss: 0.2721 - val_mse: 0.2721 - val_mae: 0.4229 - 3s/epoch - 236ms/step
Epoch 140/10000

Epoch 140: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2791 - mse: 0.2791 - mae: 0.4274 - val_loss: 0.2794 - val_mse: 0.2794 - val_mae: 0.4267 - 2s/epoch - 167ms/step
Epoch 141/10000

Epoch 141: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2811 - mse: 0.2811 - mae: 0.4291 - val_loss: 0.2724 - val_mse: 0.2724 - val_mae: 0.4231 - 2s/epoch - 167ms/step
Epoch 142/10000

Epoch 142: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2816 - mse: 0.2816 - mae: 0.4291 - val_loss: 0.2811 - val_mse: 0.2811 - val_mae: 0.4277 - 2s/epoch - 168ms/step
Epoch 143/10000

Epoch 143: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2873 - mse: 0.2873 - mae: 0.4335 - val_loss: 0.2865 - val_mse: 0.2865 - val_mae: 0.4338 - 2s/epoch - 167ms/step
Epoch 144/10000

Epoch 144: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2871 - mse: 0.2871 - mae: 0.4337 - val_loss: 0.2738 - val_mse: 0.2738 - val_mae: 0.4234 - 2s/epoch - 168ms/step
Epoch 145/10000

Epoch 145: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2849 - mse: 0.2849 - mae: 0.4320 - val_loss: 0.2792 - val_mse: 0.2792 - val_mae: 0.4266 - 2s/epoch - 167ms/step
Epoch 146/10000

Epoch 146: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2847 - mse: 0.2847 - mae: 0.4308 - val_loss: 0.2949 - val_mse: 0.2949 - val_mae: 0.4400 - 2s/epoch - 167ms/step
Epoch 147/10000

Epoch 147: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2843 - mse: 0.2843 - mae: 0.4321 - val_loss: 0.2919 - val_mse: 0.2919 - val_mae: 0.4351 - 2s/epoch - 168ms/step
Epoch 148/10000

Epoch 148: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2928 - mse: 0.2928 - mae: 0.4365 - val_loss: 0.3155 - val_mse: 0.3155 - val_mae: 0.4543 - 2s/epoch - 168ms/step
Epoch 149/10000

Epoch 149: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2980 - mse: 0.2980 - mae: 0.4421 - val_loss: 0.3011 - val_mse: 0.3011 - val_mae: 0.4412 - 2s/epoch - 167ms/step
Epoch 150/10000

Epoch 150: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2925 - mse: 0.2925 - mae: 0.4365 - val_loss: 0.3189 - val_mse: 0.3189 - val_mae: 0.4566 - 2s/epoch - 167ms/step
Epoch 151/10000

Epoch 151: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2955 - mse: 0.2955 - mae: 0.4408 - val_loss: 0.3069 - val_mse: 0.3069 - val_mae: 0.4456 - 2s/epoch - 167ms/step
Epoch 152/10000

Epoch 152: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2897 - mse: 0.2897 - mae: 0.4356 - val_loss: 0.3210 - val_mse: 0.3210 - val_mae: 0.4584 - 2s/epoch - 167ms/step
Epoch 153/10000

Epoch 153: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2898 - mse: 0.2898 - mae: 0.4353 - val_loss: 0.2726 - val_mse: 0.2726 - val_mae: 0.4226 - 2s/epoch - 167ms/step
Epoch 154/10000

Epoch 154: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2790 - mse: 0.2790 - mae: 0.4274 - val_loss: 0.2723 - val_mse: 0.2723 - val_mae: 0.4229 - 2s/epoch - 167ms/step
Epoch 155/10000

Epoch 155: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2795 - mse: 0.2795 - mae: 0.4275 - val_loss: 0.2899 - val_mse: 0.2899 - val_mae: 0.4361 - 2s/epoch - 167ms/step
Epoch 156/10000

Epoch 156: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2926 - mse: 0.2926 - mae: 0.4369 - val_loss: 0.2955 - val_mse: 0.2955 - val_mae: 0.4371 - 2s/epoch - 167ms/step
Epoch 157/10000

Epoch 157: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2914 - mse: 0.2914 - mae: 0.4350 - val_loss: 0.2770 - val_mse: 0.2770 - val_mae: 0.4266 - 2s/epoch - 168ms/step
Epoch 158/10000

Epoch 158: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2799 - mse: 0.2799 - mae: 0.4279 - val_loss: 0.2759 - val_mse: 0.2759 - val_mae: 0.4262 - 2s/epoch - 168ms/step
Epoch 159/10000

Epoch 159: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2796 - mse: 0.2796 - mae: 0.4280 - val_loss: 0.2742 - val_mse: 0.2742 - val_mae: 0.4233 - 2s/epoch - 167ms/step
Epoch 160/10000

Epoch 160: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2812 - mse: 0.2812 - mae: 0.4291 - val_loss: 0.3238 - val_mse: 0.3238 - val_mae: 0.4558 - 2s/epoch - 168ms/step
Epoch 161/10000

Epoch 161: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.3026 - mse: 0.3026 - mae: 0.4422 - val_loss: 0.2745 - val_mse: 0.2745 - val_mae: 0.4248 - 2s/epoch - 168ms/step
Epoch 162/10000

Epoch 162: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2809 - mse: 0.2809 - mae: 0.4290 - val_loss: 0.2725 - val_mse: 0.2725 - val_mae: 0.4225 - 2s/epoch - 168ms/step
Epoch 163/10000

Epoch 163: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2793 - mse: 0.2793 - mae: 0.4279 - val_loss: 0.2725 - val_mse: 0.2725 - val_mae: 0.4231 - 2s/epoch - 168ms/step
Epoch 164/10000

Epoch 164: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2788 - mse: 0.2788 - mae: 0.4276 - val_loss: 0.2860 - val_mse: 0.2860 - val_mae: 0.4316 - 2s/epoch - 167ms/step
Epoch 165/10000

Epoch 165: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2864 - mse: 0.2864 - mae: 0.4332 - val_loss: 0.2863 - val_mse: 0.2863 - val_mae: 0.4312 - 2s/epoch - 168ms/step
Epoch 166/10000

Epoch 166: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2867 - mse: 0.2867 - mae: 0.4318 - val_loss: 0.2855 - val_mse: 0.2855 - val_mae: 0.4327 - 2s/epoch - 168ms/step
Epoch 167/10000

Epoch 167: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2798 - mse: 0.2798 - mae: 0.4281 - val_loss: 0.2876 - val_mse: 0.2876 - val_mae: 0.4317 - 2s/epoch - 167ms/step
Epoch 168/10000

Epoch 168: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2827 - mse: 0.2827 - mae: 0.4298 - val_loss: 0.2802 - val_mse: 0.2802 - val_mae: 0.4274 - 2s/epoch - 167ms/step
Epoch 169/10000

Epoch 169: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2834 - mse: 0.2834 - mae: 0.4299 - val_loss: 0.2969 - val_mse: 0.2969 - val_mae: 0.4407 - 2s/epoch - 168ms/step
Epoch 170/10000

Epoch 170: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2815 - mse: 0.2815 - mae: 0.4292 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4229 - 2s/epoch - 168ms/step
Epoch 171/10000

Epoch 171: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2797 - mse: 0.2797 - mae: 0.4281 - val_loss: 0.2754 - val_mse: 0.2754 - val_mae: 0.4257 - 2s/epoch - 168ms/step
Epoch 172/10000

Epoch 172: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2788 - mse: 0.2788 - mae: 0.4272 - val_loss: 0.2964 - val_mse: 0.2964 - val_mae: 0.4377 - 2s/epoch - 168ms/step
Epoch 173/10000

Epoch 173: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2890 - mse: 0.2890 - mae: 0.4340 - val_loss: 0.3009 - val_mse: 0.3009 - val_mae: 0.4436 - 2s/epoch - 168ms/step
Epoch 174/10000

Epoch 174: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2871 - mse: 0.2871 - mae: 0.4337 - val_loss: 0.2757 - val_mse: 0.2757 - val_mae: 0.4242 - 2s/epoch - 167ms/step
Epoch 175/10000

Epoch 175: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2820 - mse: 0.2820 - mae: 0.4295 - val_loss: 0.2775 - val_mse: 0.2775 - val_mae: 0.4255 - 2s/epoch - 168ms/step
Epoch 176/10000

Epoch 176: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2834 - mse: 0.2834 - mae: 0.4307 - val_loss: 0.2730 - val_mse: 0.2730 - val_mae: 0.4227 - 2s/epoch - 168ms/step
Epoch 177/10000

Epoch 177: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2829 - mse: 0.2829 - mae: 0.4297 - val_loss: 0.2728 - val_mse: 0.2728 - val_mae: 0.4234 - 2s/epoch - 168ms/step
Epoch 178/10000

Epoch 178: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2797 - mse: 0.2797 - mae: 0.4277 - val_loss: 0.2822 - val_mse: 0.2822 - val_mae: 0.4309 - 2s/epoch - 167ms/step
Epoch 179/10000

Epoch 179: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2905 - mse: 0.2905 - mae: 0.4361 - val_loss: 0.2798 - val_mse: 0.2798 - val_mae: 0.4266 - 2s/epoch - 168ms/step
Epoch 180/10000

Epoch 180: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2907 - mse: 0.2907 - mae: 0.4359 - val_loss: 0.2752 - val_mse: 0.2752 - val_mae: 0.4252 - 2s/epoch - 167ms/step
Epoch 181/10000

Epoch 181: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2953 - mse: 0.2953 - mae: 0.4399 - val_loss: 0.3437 - val_mse: 0.3437 - val_mae: 0.4749 - 2s/epoch - 168ms/step
Epoch 182/10000

Epoch 182: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.3034 - mse: 0.3034 - mae: 0.4450 - val_loss: 0.2744 - val_mse: 0.2744 - val_mae: 0.4236 - 2s/epoch - 167ms/step
Epoch 183/10000

Epoch 183: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2884 - mse: 0.2884 - mae: 0.4342 - val_loss: 0.2854 - val_mse: 0.2854 - val_mae: 0.4305 - 2s/epoch - 167ms/step
Epoch 184/10000

Epoch 184: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2961 - mse: 0.2961 - mae: 0.4393 - val_loss: 0.2926 - val_mse: 0.2926 - val_mae: 0.4382 - 2s/epoch - 167ms/step
Epoch 185/10000

Epoch 185: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2885 - mse: 0.2885 - mae: 0.4340 - val_loss: 0.2907 - val_mse: 0.2907 - val_mae: 0.4339 - 2s/epoch - 167ms/step
Epoch 186/10000

Epoch 186: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2866 - mse: 0.2866 - mae: 0.4322 - val_loss: 0.2771 - val_mse: 0.2771 - val_mae: 0.4253 - 2s/epoch - 167ms/step
Epoch 187/10000

Epoch 187: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2923 - mse: 0.2923 - mae: 0.4362 - val_loss: 0.2738 - val_mse: 0.2738 - val_mae: 0.4232 - 2s/epoch - 168ms/step
Epoch 188/10000

Epoch 188: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2797 - mse: 0.2797 - mae: 0.4280 - val_loss: 0.2729 - val_mse: 0.2729 - val_mae: 0.4234 - 2s/epoch - 168ms/step
Epoch 189/10000

Epoch 189: val_loss did not improve from 0.27213
12/12 - 2s - loss: 0.2798 - mse: 0.2798 - mae: 0.4280 - val_loss: 0.2753 - val_mse: 0.2753 - val_mae: 0.4259 - 2s/epoch - 167ms/step
Epoch 189: early stopping
