[ 13.14519438  30.04553007  46.53366244  63.02179482  79.5099272
  95.99805957 112.48619195 128.97432432 145.4624567  161.95058908
 178.43872145 194.92685383 211.41498621 227.90311858 244.39125096
 260.87938334 277.36751571 293.85564809 310.34378047 326.83191284
 343.32004522 359.80817759 376.29630997 392.78444235 409.27257472
 425.7607071 ]
Before undersampling: [(0, 375), (1, 834), (2, 3661), (3, 4955), (4, 3156), (5, 2425), (6, 2195), (7, 1862), (8, 1648), (9, 1497), (10, 1418), (11, 1313), (12, 1182), (13, 1082), (14, 902), (15, 843), (16, 708), (17, 675), (18, 486), (19, 429), (20, 347), (21, 282), (22, 251), (23, 195), (24, 209)]
After undersampling: [(0, 136), (1, 381), (2, 2428), (3, 3472), (4, 2224), (5, 1597), (6, 1535), (7, 1360), (8, 1242), (9, 1037), (10, 1006), (11, 889), (12, 816), (13, 798), (14, 636), (15, 601), (16, 477), (17, 484), (18, 330), (19, 304), (20, 230), (21, 177), (22, 165), (23, 195), (24, 170)]
            label  HH_0_0_x  HV_0_0_x  IA_0_0_x       FYI      DFYI       MYI     rms_0     thk_1     rms_1     thk_2     rms_2     thk_3     rms_3  ...    3         4    5         6         7         8         9        10   11        12        13        14        15                                                CNN
0       23.480099  0.270588  0.062745  0.124033  0.759393  0.207154  0.033453  4.483940  1.163126  4.462497  1.124918  4.433985  1.180931  4.445172  ...  0.0  1.016549  0.0  0.604905  0.586914  0.806035  0.249679  0.939981  0.0  0.731856  0.000000  0.700651  0.510417  [[[[0.2980392156862745], [0.123996846816119], ...
1       27.711013  0.207843  0.047059  0.088232  0.887489  0.103202  0.009309  4.417133  1.090360  4.412498  1.080255  4.377108  1.107154  4.343643  ...  0.0  1.127101  0.0  0.702100  0.651536  0.916946  0.303264  1.066429  0.0  0.821556  0.000000  0.806387  0.566281  [[[[0.1450980392156863], [0.0882743386661305],...
2       23.928360  0.200000  0.078431  0.151209  0.889373  0.040653  0.069975  4.468868  1.195256  4.520699  1.161985  4.504385  1.159886  4.463496  ...  0.0  0.877961  0.0  0.497789  0.485092  0.693991  0.195656  0.803566  0.0  0.645145  0.000000  0.594786  0.448331  [[[[0.2392156862745098], [0.1512409883386948],...
3       25.171084  0.176471  0.050980  0.150448  0.355640  0.122056  0.522304  4.846040  1.266177  4.963545  1.246865  4.935526  1.265141  4.903024  ...  0.0  0.631981  0.0  0.431982  0.208516  0.524496  0.501855  0.358433  0.0  0.459935  0.017637  0.454933  0.169272  [[[[0.6627450980392157], [0.1504803077847349],...
4       29.165086  0.247059  0.043137  0.086361  0.892167  0.099319  0.008513  4.407791  1.100606  4.440977  1.090756  4.399405  1.086580  4.362398  ...  0.0  1.120212  0.0  0.689656  0.673642  0.920408  0.320587  1.050618  0.0  0.819671  0.000000  0.794965  0.590912  [[[[0.2392156862745098], [0.0864032969755285],...
...           ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...  ...       ...  ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...                                                ...
22685  410.150134  0.278431  0.105882  0.080638  0.271956  0.003331  0.724713  4.974597  1.193015  4.883787  1.184847  4.923381  1.187656  4.904520  ...  0.0  1.156851  0.0  0.728820  0.670855  0.950185  0.326065  1.093004  0.0  0.834129  0.000000  0.829957  0.573284  [[[[0.3019607843137254], [0.0806800917083141],...
22686  424.042418  0.282353  0.066667  0.149433  0.555378  0.061723  0.382898  4.731061  1.220450  4.833013  1.211024  4.808225  1.225502  4.756752  ...  0.0  0.945098  0.0  0.528045  0.526673  0.715281  0.199913  0.853262  0.0  0.678457  0.000000  0.622234  0.460721  [[[[0.2], [0.1494652841605392], [0.06666666666...
22687  421.196328  0.631373  0.466667  0.154089  0.004261  0.000064  0.995674  1.187829  0.197352  0.941815  0.203265  0.245285  0.157730  0.213412  ...  0.0  0.644292  0.0  0.466233  0.184014  0.544459  0.317551  0.496343  0.0  0.488684  0.000000  0.521621  0.200857  [[[[0.596078431372549], [0.1541208603802849], ...
22688  416.289186  0.517647  0.160784  0.153404  0.011037  0.000341  0.988622  1.187829  0.197352  0.941815  0.203265  0.245285  0.157730  0.213412  ...  0.0  0.792541  0.0  0.518223  0.461039  0.679398  0.335284  0.699151  0.0  0.512142  0.000000  0.532694  0.315921  [[[[0.4078431372549019], [0.1534358903473499],...
22689  423.194662  0.341176  0.274510  0.153307  0.003870  0.000024  0.996105  1.187829  0.197352  0.941815  0.203265  0.245285  0.157730  0.213412  ...  0.0  0.712026  0.0  0.452670  0.356484  0.560431  0.500874  0.445316  0.0  0.508642  0.000000  0.462847  0.257479  [[[[0.5686274509803921], [0.1533395804610907],...

[22690 rows x 128 columns]
Size of dataset: (22690, 127)
*************************** Fold #: 1 ***************************
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 conv (InputLayer)              [(None, 7, 7, 3, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 zero_padding3d (ZeroPadding3D)  (None, 8, 8, 4, 1)  0           ['conv[0][0]']                   
                                                                                                  
 conv3d (Conv3D)                (None, 8, 8, 4, 8)   224         ['zero_padding3d[0][0]']         
                                                                                                  
 max_pooling3d (MaxPooling3D)   (None, 4, 4, 2, 8)   0           ['conv3d[0][0]']                 
                                                                                                  
 conv3d_1 (Conv3D)              (None, 4, 4, 2, 4)   868         ['max_pooling3d[0][0]']          
                                                                                                  
 max_pooling3d_1 (MaxPooling3D)  (None, 2, 2, 1, 4)  0           ['conv3d_1[0][0]']               
                                                                                                  
 cat (InputLayer)               [(None, 126)]        0           []                               
                                                                                                  
 flatten (Flatten)              (None, 16)           0           ['max_pooling3d_1[0][0]']        
                                                                                                  
 concatenate (Concatenate)      (None, 142)          0           ['cat[0][0]',                    
                                                                  'flatten[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 200)          28600       ['concatenate[0][0]']            
                                                                                                  
 dense_1 (Dense)                (None, 200)          40200       ['dense[0][0]']                  
                                                                                                  
 dense_2 (Dense)                (None, 200)          40200       ['dense_1[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 200)          40200       ['dense_2[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 200)          40200       ['dense_3[0][0]']                
                                                                                                  
 dense_5 (Dense)                (None, 1)            201         ['dense_4[0][0]']                
                                                                                                  
==================================================================================================
Total params: 190,693
Trainable params: 190,693
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/10000

Epoch 1: val_loss improved from inf to 2.20910, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 9.7087 - mse: 9.7087 - mae: 2.6754 - val_loss: 2.2091 - val_mse: 2.2091 - val_mae: 1.2523 - 3s/epoch - 280ms/step
Epoch 2/10000

Epoch 2: val_loss improved from 2.20910 to 0.97944, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 1.8485 - mse: 1.8485 - mae: 1.0576 - val_loss: 0.9794 - val_mse: 0.9794 - val_mae: 0.6052 - 3s/epoch - 229ms/step
Epoch 3/10000

Epoch 3: val_loss improved from 0.97944 to 0.82812, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 1.0462 - mse: 1.0462 - mae: 0.6619 - val_loss: 0.8281 - val_mse: 0.8281 - val_mae: 0.5647 - 3s/epoch - 230ms/step
Epoch 4/10000

Epoch 4: val_loss improved from 0.82812 to 0.56815, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.7607 - mse: 0.7607 - mae: 0.5628 - val_loss: 0.5681 - val_mse: 0.5681 - val_mae: 0.5209 - 3s/epoch - 229ms/step
Epoch 5/10000

Epoch 5: val_loss improved from 0.56815 to 0.28507, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.4272 - mse: 0.4272 - mae: 0.4874 - val_loss: 0.2851 - val_mse: 0.2851 - val_mae: 0.4342 - 3s/epoch - 229ms/step
Epoch 6/10000

Epoch 6: val_loss improved from 0.28507 to 0.27791, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2969 - mse: 0.2969 - mae: 0.4419 - val_loss: 0.2779 - val_mse: 0.2779 - val_mae: 0.4307 - 3s/epoch - 234ms/step
Epoch 7/10000

Epoch 7: val_loss did not improve from 0.27791
12/12 - 2s - loss: 0.2819 - mse: 0.2819 - mae: 0.4307 - val_loss: 0.2782 - val_mse: 0.2782 - val_mae: 0.4296 - 2s/epoch - 169ms/step
Epoch 8/10000

Epoch 8: val_loss did not improve from 0.27791
12/12 - 2s - loss: 0.2777 - mse: 0.2777 - mae: 0.4292 - val_loss: 0.2816 - val_mse: 0.2816 - val_mae: 0.4343 - 2s/epoch - 167ms/step
Epoch 9/10000

Epoch 9: val_loss improved from 0.27791 to 0.27502, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2796 - mse: 0.2796 - mae: 0.4309 - val_loss: 0.2750 - val_mse: 0.2750 - val_mae: 0.4288 - 3s/epoch - 242ms/step
Epoch 10/10000

Epoch 10: val_loss improved from 0.27502 to 0.27281, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2769 - mse: 0.2769 - mae: 0.4277 - val_loss: 0.2728 - val_mse: 0.2728 - val_mae: 0.4260 - 3s/epoch - 244ms/step
Epoch 11/10000

Epoch 11: val_loss improved from 0.27281 to 0.27145, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2742 - mse: 0.2742 - mae: 0.4266 - val_loss: 0.2714 - val_mse: 0.2714 - val_mae: 0.4254 - 3s/epoch - 237ms/step
Epoch 12/10000

Epoch 12: val_loss did not improve from 0.27145
12/12 - 2s - loss: 0.2757 - mse: 0.2757 - mae: 0.4273 - val_loss: 0.2824 - val_mse: 0.2824 - val_mae: 0.4308 - 2s/epoch - 168ms/step
Epoch 13/10000

Epoch 13: val_loss did not improve from 0.27145
12/12 - 2s - loss: 0.2767 - mse: 0.2767 - mae: 0.4279 - val_loss: 0.2721 - val_mse: 0.2721 - val_mae: 0.4247 - 2s/epoch - 167ms/step
Epoch 14/10000

Epoch 14: val_loss improved from 0.27145 to 0.27116, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2780 - mse: 0.2780 - mae: 0.4289 - val_loss: 0.2712 - val_mse: 0.2712 - val_mae: 0.4239 - 3s/epoch - 241ms/step
Epoch 15/10000

Epoch 15: val_loss improved from 0.27116 to 0.26991, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2721 - mse: 0.2721 - mae: 0.4241 - val_loss: 0.2699 - val_mse: 0.2699 - val_mae: 0.4232 - 3s/epoch - 241ms/step
Epoch 16/10000

Epoch 16: val_loss did not improve from 0.26991
12/12 - 2s - loss: 0.2729 - mse: 0.2729 - mae: 0.4238 - val_loss: 0.2719 - val_mse: 0.2719 - val_mae: 0.4239 - 2s/epoch - 168ms/step
Epoch 17/10000

Epoch 17: val_loss did not improve from 0.26991
12/12 - 2s - loss: 0.2725 - mse: 0.2725 - mae: 0.4245 - val_loss: 0.2705 - val_mse: 0.2705 - val_mae: 0.4237 - 2s/epoch - 167ms/step
Epoch 18/10000

Epoch 18: val_loss improved from 0.26991 to 0.26941, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2722 - mse: 0.2722 - mae: 0.4235 - val_loss: 0.2694 - val_mse: 0.2694 - val_mae: 0.4226 - 3s/epoch - 243ms/step
Epoch 19/10000

Epoch 19: val_loss did not improve from 0.26941
12/12 - 2s - loss: 0.2730 - mse: 0.2730 - mae: 0.4245 - val_loss: 0.2697 - val_mse: 0.2697 - val_mae: 0.4222 - 2s/epoch - 168ms/step
Epoch 20/10000

Epoch 20: val_loss did not improve from 0.26941
12/12 - 2s - loss: 0.2725 - mse: 0.2725 - mae: 0.4233 - val_loss: 0.2800 - val_mse: 0.2800 - val_mae: 0.4280 - 2s/epoch - 168ms/step
Epoch 21/10000

Epoch 21: val_loss improved from 0.26941 to 0.26905, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2736 - mse: 0.2736 - mae: 0.4253 - val_loss: 0.2691 - val_mse: 0.2691 - val_mae: 0.4219 - 3s/epoch - 236ms/step
Epoch 22/10000

Epoch 22: val_loss improved from 0.26905 to 0.26883, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2709 - mse: 0.2709 - mae: 0.4224 - val_loss: 0.2688 - val_mse: 0.2688 - val_mae: 0.4218 - 3s/epoch - 242ms/step
Epoch 23/10000

Epoch 23: val_loss did not improve from 0.26883
12/12 - 2s - loss: 0.2728 - mse: 0.2728 - mae: 0.4239 - val_loss: 0.2689 - val_mse: 0.2689 - val_mae: 0.4219 - 2s/epoch - 168ms/step
Epoch 24/10000

Epoch 24: val_loss did not improve from 0.26883
12/12 - 2s - loss: 0.2702 - mse: 0.2702 - mae: 0.4215 - val_loss: 0.2751 - val_mse: 0.2751 - val_mae: 0.4273 - 2s/epoch - 168ms/step
Epoch 25/10000

Epoch 25: val_loss did not improve from 0.26883
12/12 - 2s - loss: 0.2714 - mse: 0.2714 - mae: 0.4223 - val_loss: 0.2699 - val_mse: 0.2699 - val_mae: 0.4218 - 2s/epoch - 168ms/step
Epoch 26/10000

Epoch 26: val_loss did not improve from 0.26883
12/12 - 2s - loss: 0.2702 - mse: 0.2702 - mae: 0.4216 - val_loss: 0.2741 - val_mse: 0.2741 - val_mae: 0.4241 - 2s/epoch - 169ms/step
Epoch 27/10000

Epoch 27: val_loss did not improve from 0.26883
12/12 - 2s - loss: 0.2715 - mse: 0.2715 - mae: 0.4226 - val_loss: 0.2735 - val_mse: 0.2735 - val_mae: 0.4261 - 2s/epoch - 167ms/step
Epoch 28/10000

Epoch 28: val_loss did not improve from 0.26883
12/12 - 2s - loss: 0.2711 - mse: 0.2711 - mae: 0.4225 - val_loss: 0.2712 - val_mse: 0.2712 - val_mae: 0.4241 - 2s/epoch - 168ms/step
Epoch 29/10000

Epoch 29: val_loss improved from 0.26883 to 0.26832, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2728 - mse: 0.2728 - mae: 0.4238 - val_loss: 0.2683 - val_mse: 0.2683 - val_mae: 0.4213 - 3s/epoch - 243ms/step
Epoch 30/10000

Epoch 30: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2712 - mse: 0.2712 - mae: 0.4221 - val_loss: 0.2723 - val_mse: 0.2723 - val_mae: 0.4230 - 2s/epoch - 169ms/step
Epoch 31/10000

Epoch 31: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2713 - mse: 0.2713 - mae: 0.4223 - val_loss: 0.2705 - val_mse: 0.2705 - val_mae: 0.4217 - 2s/epoch - 168ms/step
Epoch 32/10000

Epoch 32: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2693 - mse: 0.2693 - mae: 0.4206 - val_loss: 0.2684 - val_mse: 0.2684 - val_mae: 0.4214 - 2s/epoch - 168ms/step
Epoch 33/10000

Epoch 33: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2697 - mse: 0.2697 - mae: 0.4206 - val_loss: 0.2685 - val_mse: 0.2685 - val_mae: 0.4216 - 2s/epoch - 169ms/step
Epoch 34/10000

Epoch 34: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2692 - mse: 0.2692 - mae: 0.4207 - val_loss: 0.2816 - val_mse: 0.2816 - val_mae: 0.4283 - 2s/epoch - 168ms/step
Epoch 35/10000

Epoch 35: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2730 - mse: 0.2730 - mae: 0.4224 - val_loss: 0.2701 - val_mse: 0.2701 - val_mae: 0.4221 - 2s/epoch - 168ms/step
Epoch 36/10000

Epoch 36: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2695 - mse: 0.2695 - mae: 0.4210 - val_loss: 0.2690 - val_mse: 0.2690 - val_mae: 0.4206 - 2s/epoch - 168ms/step
Epoch 37/10000

Epoch 37: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2713 - mse: 0.2713 - mae: 0.4218 - val_loss: 0.2899 - val_mse: 0.2899 - val_mae: 0.4342 - 2s/epoch - 168ms/step
Epoch 38/10000

Epoch 38: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2779 - mse: 0.2779 - mae: 0.4265 - val_loss: 0.2697 - val_mse: 0.2697 - val_mae: 0.4209 - 2s/epoch - 168ms/step
Epoch 39/10000

Epoch 39: val_loss did not improve from 0.26832
12/12 - 2s - loss: 0.2739 - mse: 0.2739 - mae: 0.4232 - val_loss: 0.2743 - val_mse: 0.2743 - val_mae: 0.4266 - 2s/epoch - 168ms/step
Epoch 40/10000

Epoch 40: val_loss improved from 0.26832 to 0.26784, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2724 - mse: 0.2724 - mae: 0.4227 - val_loss: 0.2678 - val_mse: 0.2678 - val_mae: 0.4203 - 3s/epoch - 237ms/step
Epoch 41/10000

Epoch 41: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2683 - mse: 0.2683 - mae: 0.4193 - val_loss: 0.2706 - val_mse: 0.2706 - val_mae: 0.4234 - 2s/epoch - 168ms/step
Epoch 42/10000

Epoch 42: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2696 - mse: 0.2696 - mae: 0.4204 - val_loss: 0.2690 - val_mse: 0.2690 - val_mae: 0.4219 - 2s/epoch - 167ms/step
Epoch 43/10000

Epoch 43: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2692 - mse: 0.2692 - mae: 0.4201 - val_loss: 0.2685 - val_mse: 0.2685 - val_mae: 0.4213 - 2s/epoch - 168ms/step
Epoch 44/10000

Epoch 44: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2686 - mse: 0.2686 - mae: 0.4194 - val_loss: 0.2727 - val_mse: 0.2727 - val_mae: 0.4229 - 2s/epoch - 169ms/step
Epoch 45/10000

Epoch 45: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2699 - mse: 0.2699 - mae: 0.4205 - val_loss: 0.2722 - val_mse: 0.2722 - val_mae: 0.4224 - 2s/epoch - 166ms/step
Epoch 46/10000

Epoch 46: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2719 - mse: 0.2719 - mae: 0.4218 - val_loss: 0.2718 - val_mse: 0.2718 - val_mae: 0.4223 - 2s/epoch - 167ms/step
Epoch 47/10000

Epoch 47: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2711 - mse: 0.2711 - mae: 0.4215 - val_loss: 0.2685 - val_mse: 0.2685 - val_mae: 0.4202 - 2s/epoch - 167ms/step
Epoch 48/10000

Epoch 48: val_loss did not improve from 0.26784
12/12 - 2s - loss: 0.2696 - mse: 0.2696 - mae: 0.4196 - val_loss: 0.2744 - val_mse: 0.2744 - val_mae: 0.4237 - 2s/epoch - 167ms/step
Epoch 49/10000

Epoch 49: val_loss improved from 0.26784 to 0.26773, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2711 - mse: 0.2711 - mae: 0.4213 - val_loss: 0.2677 - val_mse: 0.2677 - val_mae: 0.4205 - 3s/epoch - 242ms/step
Epoch 50/10000

Epoch 50: val_loss did not improve from 0.26773
12/12 - 2s - loss: 0.2707 - mse: 0.2707 - mae: 0.4209 - val_loss: 0.2778 - val_mse: 0.2778 - val_mae: 0.4288 - 2s/epoch - 167ms/step
Epoch 51/10000

Epoch 51: val_loss did not improve from 0.26773
12/12 - 2s - loss: 0.2704 - mse: 0.2704 - mae: 0.4206 - val_loss: 0.2683 - val_mse: 0.2683 - val_mae: 0.4213 - 2s/epoch - 168ms/step
Epoch 52/10000

Epoch 52: val_loss improved from 0.26773 to 0.26767, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2681 - mse: 0.2681 - mae: 0.4186 - val_loss: 0.2677 - val_mse: 0.2677 - val_mae: 0.4203 - 3s/epoch - 243ms/step
Epoch 53/10000

Epoch 53: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2687 - mse: 0.2687 - mae: 0.4196 - val_loss: 0.2708 - val_mse: 0.2708 - val_mae: 0.4235 - 2s/epoch - 169ms/step
Epoch 54/10000

Epoch 54: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2703 - mse: 0.2703 - mae: 0.4208 - val_loss: 0.2696 - val_mse: 0.2696 - val_mae: 0.4205 - 2s/epoch - 168ms/step
Epoch 55/10000

Epoch 55: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2717 - mse: 0.2717 - mae: 0.4210 - val_loss: 0.2819 - val_mse: 0.2819 - val_mae: 0.4282 - 2s/epoch - 169ms/step
Epoch 56/10000

Epoch 56: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2715 - mse: 0.2715 - mae: 0.4210 - val_loss: 0.2831 - val_mse: 0.2831 - val_mae: 0.4330 - 2s/epoch - 172ms/step
Epoch 57/10000

Epoch 57: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2761 - mse: 0.2761 - mae: 0.4237 - val_loss: 0.2696 - val_mse: 0.2696 - val_mae: 0.4224 - 2s/epoch - 169ms/step
Epoch 58/10000

Epoch 58: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2695 - mse: 0.2695 - mae: 0.4198 - val_loss: 0.2725 - val_mse: 0.2725 - val_mae: 0.4243 - 2s/epoch - 168ms/step
Epoch 59/10000

Epoch 59: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2695 - mse: 0.2695 - mae: 0.4194 - val_loss: 0.2691 - val_mse: 0.2691 - val_mae: 0.4221 - 2s/epoch - 167ms/step
Epoch 60/10000

Epoch 60: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2700 - mse: 0.2700 - mae: 0.4202 - val_loss: 0.2754 - val_mse: 0.2754 - val_mae: 0.4241 - 2s/epoch - 171ms/step
Epoch 61/10000

Epoch 61: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2767 - mse: 0.2767 - mae: 0.4253 - val_loss: 0.2685 - val_mse: 0.2685 - val_mae: 0.4206 - 2s/epoch - 169ms/step
Epoch 62/10000

Epoch 62: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2730 - mse: 0.2730 - mae: 0.4220 - val_loss: 0.2691 - val_mse: 0.2691 - val_mae: 0.4221 - 2s/epoch - 177ms/step
Epoch 63/10000

Epoch 63: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2684 - mse: 0.2684 - mae: 0.4188 - val_loss: 0.2678 - val_mse: 0.2678 - val_mae: 0.4200 - 2s/epoch - 169ms/step
Epoch 64/10000

Epoch 64: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2674 - mse: 0.2674 - mae: 0.4182 - val_loss: 0.2800 - val_mse: 0.2800 - val_mae: 0.4304 - 2s/epoch - 169ms/step
Epoch 65/10000

Epoch 65: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2765 - mse: 0.2765 - mae: 0.4249 - val_loss: 0.2713 - val_mse: 0.2713 - val_mae: 0.4239 - 2s/epoch - 175ms/step
Epoch 66/10000

Epoch 66: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2688 - mse: 0.2688 - mae: 0.4193 - val_loss: 0.2678 - val_mse: 0.2678 - val_mae: 0.4197 - 2s/epoch - 168ms/step
Epoch 67/10000

Epoch 67: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2689 - mse: 0.2689 - mae: 0.4190 - val_loss: 0.2682 - val_mse: 0.2682 - val_mae: 0.4204 - 2s/epoch - 171ms/step
Epoch 68/10000

Epoch 68: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2687 - mse: 0.2687 - mae: 0.4188 - val_loss: 0.2709 - val_mse: 0.2709 - val_mae: 0.4213 - 2s/epoch - 170ms/step
Epoch 69/10000

Epoch 69: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2706 - mse: 0.2706 - mae: 0.4200 - val_loss: 0.2682 - val_mse: 0.2682 - val_mae: 0.4208 - 2s/epoch - 168ms/step
Epoch 70/10000

Epoch 70: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2676 - mse: 0.2676 - mae: 0.4180 - val_loss: 0.2697 - val_mse: 0.2697 - val_mae: 0.4221 - 2s/epoch - 174ms/step
Epoch 71/10000

Epoch 71: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2715 - mse: 0.2715 - mae: 0.4212 - val_loss: 0.2722 - val_mse: 0.2722 - val_mae: 0.4216 - 2s/epoch - 168ms/step
Epoch 72/10000

Epoch 72: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2700 - mse: 0.2700 - mae: 0.4195 - val_loss: 0.2713 - val_mse: 0.2713 - val_mae: 0.4234 - 2s/epoch - 175ms/step
Epoch 73/10000

Epoch 73: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2739 - mse: 0.2739 - mae: 0.4229 - val_loss: 0.2707 - val_mse: 0.2707 - val_mae: 0.4218 - 2s/epoch - 172ms/step
Epoch 74/10000

Epoch 74: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2717 - mse: 0.2717 - mae: 0.4210 - val_loss: 0.2717 - val_mse: 0.2717 - val_mae: 0.4235 - 2s/epoch - 170ms/step
Epoch 75/10000

Epoch 75: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2773 - mse: 0.2773 - mae: 0.4250 - val_loss: 0.2883 - val_mse: 0.2883 - val_mae: 0.4365 - 2s/epoch - 169ms/step
Epoch 76/10000

Epoch 76: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2767 - mse: 0.2767 - mae: 0.4244 - val_loss: 0.2679 - val_mse: 0.2679 - val_mae: 0.4205 - 2s/epoch - 171ms/step
Epoch 77/10000

Epoch 77: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2682 - mse: 0.2682 - mae: 0.4184 - val_loss: 0.2714 - val_mse: 0.2714 - val_mae: 0.4237 - 2s/epoch - 170ms/step
Epoch 78/10000

Epoch 78: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2699 - mse: 0.2699 - mae: 0.4198 - val_loss: 0.2749 - val_mse: 0.2749 - val_mae: 0.4233 - 2s/epoch - 169ms/step
Epoch 79/10000

Epoch 79: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2730 - mse: 0.2730 - mae: 0.4209 - val_loss: 0.2690 - val_mse: 0.2690 - val_mae: 0.4204 - 2s/epoch - 168ms/step
Epoch 80/10000

Epoch 80: val_loss did not improve from 0.26767
12/12 - 2s - loss: 0.2713 - mse: 0.2713 - mae: 0.4207 - val_loss: 0.2882 - val_mse: 0.2882 - val_mae: 0.4361 - 2s/epoch - 168ms/step
Epoch 81/10000

Epoch 81: val_loss improved from 0.26767 to 0.26737, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2741 - mse: 0.2741 - mae: 0.4226 - val_loss: 0.2674 - val_mse: 0.2674 - val_mae: 0.4196 - 3s/epoch - 239ms/step
Epoch 82/10000

Epoch 82: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2681 - mse: 0.2681 - mae: 0.4184 - val_loss: 0.2676 - val_mse: 0.2676 - val_mae: 0.4194 - 2s/epoch - 169ms/step
Epoch 83/10000

Epoch 83: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2706 - mse: 0.2706 - mae: 0.4202 - val_loss: 0.2679 - val_mse: 0.2679 - val_mae: 0.4204 - 2s/epoch - 167ms/step
Epoch 84/10000

Epoch 84: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2733 - mse: 0.2733 - mae: 0.4217 - val_loss: 0.2677 - val_mse: 0.2677 - val_mae: 0.4194 - 2s/epoch - 169ms/step
Epoch 85/10000

Epoch 85: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2720 - mse: 0.2720 - mae: 0.4210 - val_loss: 0.2918 - val_mse: 0.2918 - val_mae: 0.4390 - 2s/epoch - 169ms/step
Epoch 86/10000

Epoch 86: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2774 - mse: 0.2774 - mae: 0.4246 - val_loss: 0.2882 - val_mse: 0.2882 - val_mae: 0.4318 - 2s/epoch - 171ms/step
Epoch 87/10000

Epoch 87: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2742 - mse: 0.2742 - mae: 0.4226 - val_loss: 0.2789 - val_mse: 0.2789 - val_mae: 0.4294 - 2s/epoch - 168ms/step
Epoch 88/10000

Epoch 88: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2751 - mse: 0.2751 - mae: 0.4245 - val_loss: 0.2680 - val_mse: 0.2680 - val_mae: 0.4201 - 2s/epoch - 169ms/step
Epoch 89/10000

Epoch 89: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2679 - mse: 0.2679 - mae: 0.4181 - val_loss: 0.2684 - val_mse: 0.2684 - val_mae: 0.4210 - 2s/epoch - 168ms/step
Epoch 90/10000

Epoch 90: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2696 - mse: 0.2696 - mae: 0.4190 - val_loss: 0.2770 - val_mse: 0.2770 - val_mae: 0.4274 - 2s/epoch - 168ms/step
Epoch 91/10000

Epoch 91: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2710 - mse: 0.2710 - mae: 0.4207 - val_loss: 0.2830 - val_mse: 0.2830 - val_mae: 0.4319 - 2s/epoch - 172ms/step
Epoch 92/10000

Epoch 92: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2750 - mse: 0.2750 - mae: 0.4232 - val_loss: 0.2694 - val_mse: 0.2694 - val_mae: 0.4214 - 2s/epoch - 169ms/step
Epoch 93/10000

Epoch 93: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2740 - mse: 0.2740 - mae: 0.4219 - val_loss: 0.2679 - val_mse: 0.2679 - val_mae: 0.4202 - 2s/epoch - 168ms/step
Epoch 94/10000

Epoch 94: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2686 - mse: 0.2686 - mae: 0.4187 - val_loss: 0.2675 - val_mse: 0.2675 - val_mae: 0.4196 - 2s/epoch - 168ms/step
Epoch 95/10000

Epoch 95: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2676 - mse: 0.2676 - mae: 0.4177 - val_loss: 0.2696 - val_mse: 0.2696 - val_mae: 0.4220 - 2s/epoch - 169ms/step
Epoch 96/10000

Epoch 96: val_loss did not improve from 0.26737
12/12 - 2s - loss: 0.2686 - mse: 0.2686 - mae: 0.4184 - val_loss: 0.2675 - val_mse: 0.2675 - val_mae: 0.4200 - 2s/epoch - 168ms/step
Epoch 97/10000

Epoch 97: val_loss improved from 0.26737 to 0.26729, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2684 - mse: 0.2684 - mae: 0.4179 - val_loss: 0.2673 - val_mse: 0.2673 - val_mae: 0.4195 - 3s/epoch - 242ms/step
Epoch 98/10000

Epoch 98: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2676 - mse: 0.2676 - mae: 0.4178 - val_loss: 0.2673 - val_mse: 0.2673 - val_mae: 0.4194 - 2s/epoch - 168ms/step
Epoch 99/10000

Epoch 99: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2675 - mse: 0.2675 - mae: 0.4178 - val_loss: 0.2690 - val_mse: 0.2690 - val_mae: 0.4215 - 2s/epoch - 168ms/step
Epoch 100/10000

Epoch 100: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2675 - mse: 0.2675 - mae: 0.4175 - val_loss: 0.2799 - val_mse: 0.2799 - val_mae: 0.4264 - 2s/epoch - 168ms/step
Epoch 101/10000

Epoch 101: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2764 - mse: 0.2764 - mae: 0.4234 - val_loss: 0.2880 - val_mse: 0.2880 - val_mae: 0.4363 - 2s/epoch - 168ms/step
Epoch 102/10000

Epoch 102: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2751 - mse: 0.2751 - mae: 0.4232 - val_loss: 0.2855 - val_mse: 0.2855 - val_mae: 0.4299 - 2s/epoch - 168ms/step
Epoch 103/10000

Epoch 103: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2720 - mse: 0.2720 - mae: 0.4204 - val_loss: 0.3736 - val_mse: 0.3736 - val_mae: 0.4958 - 2s/epoch - 168ms/step
Epoch 104/10000

Epoch 104: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.3030 - mse: 0.3030 - mae: 0.4436 - val_loss: 0.2745 - val_mse: 0.2745 - val_mae: 0.4230 - 2s/epoch - 168ms/step
Epoch 105/10000

Epoch 105: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2722 - mse: 0.2722 - mae: 0.4203 - val_loss: 0.2915 - val_mse: 0.2915 - val_mae: 0.4386 - 2s/epoch - 168ms/step
Epoch 106/10000

Epoch 106: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2774 - mse: 0.2774 - mae: 0.4246 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4227 - 2s/epoch - 169ms/step
Epoch 107/10000

Epoch 107: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2713 - mse: 0.2713 - mae: 0.4201 - val_loss: 0.2959 - val_mse: 0.2959 - val_mae: 0.4411 - 2s/epoch - 169ms/step
Epoch 108/10000

Epoch 108: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2731 - mse: 0.2731 - mae: 0.4219 - val_loss: 0.2678 - val_mse: 0.2678 - val_mae: 0.4196 - 2s/epoch - 168ms/step
Epoch 109/10000

Epoch 109: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2672 - mse: 0.2672 - mae: 0.4175 - val_loss: 0.2885 - val_mse: 0.2885 - val_mae: 0.4321 - 2s/epoch - 168ms/step
Epoch 110/10000

Epoch 110: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2756 - mse: 0.2756 - mae: 0.4228 - val_loss: 0.2761 - val_mse: 0.2761 - val_mae: 0.4264 - 2s/epoch - 168ms/step
Epoch 111/10000

Epoch 111: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2707 - mse: 0.2707 - mae: 0.4203 - val_loss: 0.2691 - val_mse: 0.2691 - val_mae: 0.4213 - 2s/epoch - 167ms/step
Epoch 112/10000

Epoch 112: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2717 - mse: 0.2717 - mae: 0.4214 - val_loss: 0.2783 - val_mse: 0.2783 - val_mae: 0.4289 - 2s/epoch - 171ms/step
Epoch 113/10000

Epoch 113: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2734 - mse: 0.2734 - mae: 0.4226 - val_loss: 0.2689 - val_mse: 0.2689 - val_mae: 0.4212 - 2s/epoch - 170ms/step
Epoch 114/10000

Epoch 114: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2760 - mse: 0.2760 - mae: 0.4233 - val_loss: 0.2674 - val_mse: 0.2674 - val_mae: 0.4196 - 2s/epoch - 172ms/step
Epoch 115/10000

Epoch 115: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2673 - mse: 0.2673 - mae: 0.4174 - val_loss: 0.2732 - val_mse: 0.2732 - val_mae: 0.4219 - 2s/epoch - 168ms/step
Epoch 116/10000

Epoch 116: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2683 - mse: 0.2683 - mae: 0.4182 - val_loss: 0.2717 - val_mse: 0.2717 - val_mae: 0.4212 - 2s/epoch - 168ms/step
Epoch 117/10000

Epoch 117: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2705 - mse: 0.2705 - mae: 0.4194 - val_loss: 0.2940 - val_mse: 0.2940 - val_mae: 0.4403 - 2s/epoch - 168ms/step
Epoch 118/10000

Epoch 118: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2788 - mse: 0.2788 - mae: 0.4261 - val_loss: 0.2885 - val_mse: 0.2885 - val_mae: 0.4321 - 2s/epoch - 169ms/step
Epoch 119/10000

Epoch 119: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2724 - mse: 0.2724 - mae: 0.4214 - val_loss: 0.2856 - val_mse: 0.2856 - val_mae: 0.4335 - 2s/epoch - 168ms/step
Epoch 120/10000

Epoch 120: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2703 - mse: 0.2703 - mae: 0.4201 - val_loss: 0.2782 - val_mse: 0.2782 - val_mae: 0.4254 - 2s/epoch - 168ms/step
Epoch 121/10000

Epoch 121: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2728 - mse: 0.2728 - mae: 0.4212 - val_loss: 0.2719 - val_mse: 0.2719 - val_mae: 0.4242 - 2s/epoch - 168ms/step
Epoch 122/10000

Epoch 122: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2721 - mse: 0.2721 - mae: 0.4204 - val_loss: 0.2674 - val_mse: 0.2674 - val_mae: 0.4198 - 2s/epoch - 168ms/step
Epoch 123/10000

Epoch 123: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2687 - mse: 0.2687 - mae: 0.4187 - val_loss: 0.2800 - val_mse: 0.2800 - val_mae: 0.4296 - 2s/epoch - 168ms/step
Epoch 124/10000

Epoch 124: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2719 - mse: 0.2719 - mae: 0.4201 - val_loss: 0.3061 - val_mse: 0.3061 - val_mae: 0.4435 - 2s/epoch - 168ms/step
Epoch 125/10000

Epoch 125: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2826 - mse: 0.2826 - mae: 0.4282 - val_loss: 0.2674 - val_mse: 0.2674 - val_mae: 0.4197 - 2s/epoch - 168ms/step
Epoch 126/10000

Epoch 126: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2683 - mse: 0.2683 - mae: 0.4182 - val_loss: 0.2738 - val_mse: 0.2738 - val_mae: 0.4248 - 2s/epoch - 168ms/step
Epoch 127/10000

Epoch 127: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2740 - mse: 0.2740 - mae: 0.4215 - val_loss: 0.2679 - val_mse: 0.2679 - val_mae: 0.4190 - 2s/epoch - 169ms/step
Epoch 128/10000

Epoch 128: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2696 - mse: 0.2696 - mae: 0.4189 - val_loss: 0.2831 - val_mse: 0.2831 - val_mae: 0.4320 - 2s/epoch - 168ms/step
Epoch 129/10000

Epoch 129: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2757 - mse: 0.2757 - mae: 0.4234 - val_loss: 0.2914 - val_mse: 0.2914 - val_mae: 0.4341 - 2s/epoch - 167ms/step
Epoch 130/10000

Epoch 130: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2762 - mse: 0.2762 - mae: 0.4236 - val_loss: 0.2705 - val_mse: 0.2705 - val_mae: 0.4205 - 2s/epoch - 168ms/step
Epoch 131/10000

Epoch 131: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2713 - mse: 0.2713 - mae: 0.4199 - val_loss: 0.2855 - val_mse: 0.2855 - val_mae: 0.4340 - 2s/epoch - 168ms/step
Epoch 132/10000

Epoch 132: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2729 - mse: 0.2729 - mae: 0.4211 - val_loss: 0.2674 - val_mse: 0.2674 - val_mae: 0.4198 - 2s/epoch - 169ms/step
Epoch 133/10000

Epoch 133: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2733 - mse: 0.2733 - mae: 0.4212 - val_loss: 0.2691 - val_mse: 0.2691 - val_mae: 0.4205 - 2s/epoch - 168ms/step
Epoch 134/10000

Epoch 134: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2736 - mse: 0.2736 - mae: 0.4209 - val_loss: 0.2688 - val_mse: 0.2688 - val_mae: 0.4213 - 2s/epoch - 168ms/step
Epoch 135/10000

Epoch 135: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2691 - mse: 0.2691 - mae: 0.4185 - val_loss: 0.2958 - val_mse: 0.2958 - val_mae: 0.4418 - 2s/epoch - 169ms/step
Epoch 136/10000

Epoch 136: val_loss did not improve from 0.26729
12/12 - 2s - loss: 0.2774 - mse: 0.2774 - mae: 0.4249 - val_loss: 0.2695 - val_mse: 0.2695 - val_mae: 0.4197 - 2s/epoch - 169ms/step
Epoch 137/10000

Epoch 137: val_loss improved from 0.26729 to 0.26716, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2683 - mse: 0.2683 - mae: 0.4182 - val_loss: 0.2672 - val_mse: 0.2672 - val_mae: 0.4193 - 3s/epoch - 242ms/step
Epoch 138/10000

Epoch 138: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2692 - mse: 0.2692 - mae: 0.4188 - val_loss: 0.2719 - val_mse: 0.2719 - val_mae: 0.4212 - 2s/epoch - 169ms/step
Epoch 139/10000

Epoch 139: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2698 - mse: 0.2698 - mae: 0.4189 - val_loss: 0.2683 - val_mse: 0.2683 - val_mae: 0.4204 - 2s/epoch - 168ms/step
Epoch 140/10000

Epoch 140: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2680 - mse: 0.2680 - mae: 0.4175 - val_loss: 0.2761 - val_mse: 0.2761 - val_mae: 0.4241 - 2s/epoch - 168ms/step
Epoch 141/10000

Epoch 141: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2756 - mse: 0.2756 - mae: 0.4234 - val_loss: 0.2692 - val_mse: 0.2692 - val_mae: 0.4202 - 2s/epoch - 168ms/step
Epoch 142/10000

Epoch 142: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2687 - mse: 0.2687 - mae: 0.4177 - val_loss: 0.2701 - val_mse: 0.2701 - val_mae: 0.4218 - 2s/epoch - 168ms/step
Epoch 143/10000

Epoch 143: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2711 - mse: 0.2711 - mae: 0.4202 - val_loss: 0.2775 - val_mse: 0.2775 - val_mae: 0.4250 - 2s/epoch - 169ms/step
Epoch 144/10000

Epoch 144: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2701 - mse: 0.2701 - mae: 0.4195 - val_loss: 0.2696 - val_mse: 0.2696 - val_mae: 0.4219 - 2s/epoch - 168ms/step
Epoch 145/10000

Epoch 145: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2687 - mse: 0.2687 - mae: 0.4182 - val_loss: 0.2902 - val_mse: 0.2902 - val_mae: 0.4332 - 2s/epoch - 168ms/step
Epoch 146/10000

Epoch 146: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2801 - mse: 0.2801 - mae: 0.4254 - val_loss: 0.2889 - val_mse: 0.2889 - val_mae: 0.4322 - 2s/epoch - 169ms/step
Epoch 147/10000

Epoch 147: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2778 - mse: 0.2778 - mae: 0.4243 - val_loss: 0.2676 - val_mse: 0.2676 - val_mae: 0.4201 - 2s/epoch - 169ms/step
Epoch 148/10000

Epoch 148: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2680 - mse: 0.2680 - mae: 0.4177 - val_loss: 0.2994 - val_mse: 0.2994 - val_mae: 0.4390 - 2s/epoch - 176ms/step
Epoch 149/10000

Epoch 149: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2797 - mse: 0.2797 - mae: 0.4257 - val_loss: 0.3120 - val_mse: 0.3120 - val_mae: 0.4538 - 2s/epoch - 167ms/step
Epoch 150/10000

Epoch 150: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2845 - mse: 0.2845 - mae: 0.4308 - val_loss: 0.2952 - val_mse: 0.2952 - val_mae: 0.4363 - 2s/epoch - 172ms/step
Epoch 151/10000

Epoch 151: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2794 - mse: 0.2794 - mae: 0.4271 - val_loss: 0.2709 - val_mse: 0.2709 - val_mae: 0.4207 - 2s/epoch - 169ms/step
Epoch 152/10000

Epoch 152: val_loss did not improve from 0.26716
12/12 - 2s - loss: 0.2744 - mse: 0.2744 - mae: 0.4221 - val_loss: 0.2944 - val_mse: 0.2944 - val_mae: 0.4407 - 2s/epoch - 168ms/step
Epoch 153/10000

Epoch 153: val_loss improved from 0.26716 to 0.26714, saving model to ./results/NN_rms_regr/ResNet/recursion_21/ckpt_1
12/12 - 3s - loss: 0.2798 - mse: 0.2798 - mae: 0.4259 - val_loss: 0.2671 - val_mse: 0.2671 - val_mae: 0.4190 - 3s/epoch - 244ms/step
Epoch 154/10000

Epoch 154: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2705 - mse: 0.2705 - mae: 0.4198 - val_loss: 0.2794 - val_mse: 0.2794 - val_mae: 0.4258 - 2s/epoch - 169ms/step
Epoch 155/10000

Epoch 155: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2734 - mse: 0.2734 - mae: 0.4215 - val_loss: 0.2867 - val_mse: 0.2867 - val_mae: 0.4352 - 2s/epoch - 168ms/step
Epoch 156/10000

Epoch 156: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2730 - mse: 0.2730 - mae: 0.4222 - val_loss: 0.3048 - val_mse: 0.3048 - val_mae: 0.4480 - 2s/epoch - 169ms/step
Epoch 157/10000

Epoch 157: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2799 - mse: 0.2799 - mae: 0.4268 - val_loss: 0.2755 - val_mse: 0.2755 - val_mae: 0.4236 - 2s/epoch - 168ms/step
Epoch 158/10000

Epoch 158: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2718 - mse: 0.2718 - mae: 0.4197 - val_loss: 0.2712 - val_mse: 0.2712 - val_mae: 0.4207 - 2s/epoch - 168ms/step
Epoch 159/10000

Epoch 159: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2704 - mse: 0.2704 - mae: 0.4199 - val_loss: 0.2727 - val_mse: 0.2727 - val_mae: 0.4243 - 2s/epoch - 168ms/step
Epoch 160/10000

Epoch 160: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2713 - mse: 0.2713 - mae: 0.4207 - val_loss: 0.2676 - val_mse: 0.2676 - val_mae: 0.4200 - 2s/epoch - 168ms/step
Epoch 161/10000

Epoch 161: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2739 - mse: 0.2739 - mae: 0.4211 - val_loss: 0.2675 - val_mse: 0.2675 - val_mae: 0.4199 - 2s/epoch - 167ms/step
Epoch 162/10000

Epoch 162: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2685 - mse: 0.2685 - mae: 0.4181 - val_loss: 0.2838 - val_mse: 0.2838 - val_mae: 0.4290 - 2s/epoch - 168ms/step
Epoch 163/10000

Epoch 163: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2726 - mse: 0.2726 - mae: 0.4206 - val_loss: 0.2714 - val_mse: 0.2714 - val_mae: 0.4232 - 2s/epoch - 168ms/step
Epoch 164/10000

Epoch 164: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2679 - mse: 0.2679 - mae: 0.4176 - val_loss: 0.2746 - val_mse: 0.2746 - val_mae: 0.4260 - 2s/epoch - 168ms/step
Epoch 165/10000

Epoch 165: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2697 - mse: 0.2697 - mae: 0.4195 - val_loss: 0.2740 - val_mse: 0.2740 - val_mae: 0.4225 - 2s/epoch - 168ms/step
Epoch 166/10000

Epoch 166: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2716 - mse: 0.2716 - mae: 0.4203 - val_loss: 0.2950 - val_mse: 0.2950 - val_mae: 0.4407 - 2s/epoch - 168ms/step
Epoch 167/10000

Epoch 167: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2751 - mse: 0.2751 - mae: 0.4231 - val_loss: 0.3178 - val_mse: 0.3178 - val_mae: 0.4569 - 2s/epoch - 168ms/step
Epoch 168/10000

Epoch 168: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2890 - mse: 0.2890 - mae: 0.4325 - val_loss: 0.2924 - val_mse: 0.2924 - val_mae: 0.4345 - 2s/epoch - 168ms/step
Epoch 169/10000

Epoch 169: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2845 - mse: 0.2845 - mae: 0.4283 - val_loss: 0.2672 - val_mse: 0.2672 - val_mae: 0.4190 - 2s/epoch - 168ms/step
Epoch 170/10000

Epoch 170: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2797 - mse: 0.2797 - mae: 0.4261 - val_loss: 0.3067 - val_mse: 0.3067 - val_mae: 0.4498 - 2s/epoch - 168ms/step
Epoch 171/10000

Epoch 171: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2828 - mse: 0.2828 - mae: 0.4282 - val_loss: 0.3225 - val_mse: 0.3225 - val_mae: 0.4611 - 2s/epoch - 168ms/step
Epoch 172/10000

Epoch 172: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2928 - mse: 0.2928 - mae: 0.4358 - val_loss: 0.3125 - val_mse: 0.3125 - val_mae: 0.4474 - 2s/epoch - 167ms/step
Epoch 173/10000

Epoch 173: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.3022 - mse: 0.3022 - mae: 0.4421 - val_loss: 0.2833 - val_mse: 0.2833 - val_mae: 0.4290 - 2s/epoch - 167ms/step
Epoch 174/10000

Epoch 174: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2975 - mse: 0.2975 - mae: 0.4382 - val_loss: 0.3014 - val_mse: 0.3014 - val_mae: 0.4462 - 2s/epoch - 168ms/step
Epoch 175/10000

Epoch 175: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2801 - mse: 0.2801 - mae: 0.4270 - val_loss: 0.2694 - val_mse: 0.2694 - val_mae: 0.4201 - 2s/epoch - 169ms/step
Epoch 176/10000

Epoch 176: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2683 - mse: 0.2683 - mae: 0.4179 - val_loss: 0.2756 - val_mse: 0.2756 - val_mae: 0.4261 - 2s/epoch - 169ms/step
Epoch 177/10000

Epoch 177: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2707 - mse: 0.2707 - mae: 0.4197 - val_loss: 0.2740 - val_mse: 0.2740 - val_mae: 0.4234 - 2s/epoch - 168ms/step
Epoch 178/10000

Epoch 178: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2689 - mse: 0.2689 - mae: 0.4184 - val_loss: 0.2683 - val_mse: 0.2683 - val_mae: 0.4200 - 2s/epoch - 169ms/step
Epoch 179/10000

Epoch 179: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2689 - mse: 0.2689 - mae: 0.4183 - val_loss: 0.2688 - val_mse: 0.2688 - val_mae: 0.4210 - 2s/epoch - 168ms/step
Epoch 180/10000

Epoch 180: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2726 - mse: 0.2726 - mae: 0.4211 - val_loss: 0.3077 - val_mse: 0.3077 - val_mae: 0.4443 - 2s/epoch - 168ms/step
Epoch 181/10000

Epoch 181: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2826 - mse: 0.2826 - mae: 0.4280 - val_loss: 0.2722 - val_mse: 0.2722 - val_mae: 0.4235 - 2s/epoch - 169ms/step
Epoch 182/10000

Epoch 182: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2766 - mse: 0.2766 - mae: 0.4240 - val_loss: 0.2820 - val_mse: 0.2820 - val_mae: 0.4309 - 2s/epoch - 168ms/step
Epoch 183/10000

Epoch 183: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2776 - mse: 0.2776 - mae: 0.4248 - val_loss: 0.2736 - val_mse: 0.2736 - val_mae: 0.4254 - 2s/epoch - 169ms/step
Epoch 184/10000

Epoch 184: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2683 - mse: 0.2683 - mae: 0.4180 - val_loss: 0.2678 - val_mse: 0.2678 - val_mae: 0.4194 - 2s/epoch - 168ms/step
Epoch 185/10000

Epoch 185: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2687 - mse: 0.2687 - mae: 0.4184 - val_loss: 0.3026 - val_mse: 0.3026 - val_mae: 0.4418 - 2s/epoch - 167ms/step
Epoch 186/10000

Epoch 186: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2819 - mse: 0.2819 - mae: 0.4268 - val_loss: 0.3205 - val_mse: 0.3205 - val_mae: 0.4591 - 2s/epoch - 168ms/step
Epoch 187/10000

Epoch 187: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2882 - mse: 0.2882 - mae: 0.4335 - val_loss: 0.3048 - val_mse: 0.3048 - val_mae: 0.4424 - 2s/epoch - 168ms/step
Epoch 188/10000

Epoch 188: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2742 - mse: 0.2742 - mae: 0.4208 - val_loss: 0.2746 - val_mse: 0.2746 - val_mae: 0.4259 - 2s/epoch - 169ms/step
Epoch 189/10000

Epoch 189: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2718 - mse: 0.2718 - mae: 0.4203 - val_loss: 0.2695 - val_mse: 0.2695 - val_mae: 0.4204 - 2s/epoch - 168ms/step
Epoch 190/10000

Epoch 190: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2680 - mse: 0.2680 - mae: 0.4174 - val_loss: 0.2684 - val_mse: 0.2684 - val_mae: 0.4193 - 2s/epoch - 168ms/step
Epoch 191/10000

Epoch 191: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2683 - mse: 0.2683 - mae: 0.4173 - val_loss: 0.2726 - val_mse: 0.2726 - val_mae: 0.4238 - 2s/epoch - 167ms/step
Epoch 192/10000

Epoch 192: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2715 - mse: 0.2715 - mae: 0.4200 - val_loss: 0.2700 - val_mse: 0.2700 - val_mae: 0.4204 - 2s/epoch - 168ms/step
Epoch 193/10000

Epoch 193: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2673 - mse: 0.2673 - mae: 0.4170 - val_loss: 0.2892 - val_mse: 0.2892 - val_mae: 0.4367 - 2s/epoch - 168ms/step
Epoch 194/10000

Epoch 194: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2737 - mse: 0.2737 - mae: 0.4222 - val_loss: 0.2729 - val_mse: 0.2729 - val_mae: 0.4219 - 2s/epoch - 168ms/step
Epoch 195/10000

Epoch 195: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2719 - mse: 0.2719 - mae: 0.4202 - val_loss: 0.2676 - val_mse: 0.2676 - val_mae: 0.4198 - 2s/epoch - 168ms/step
Epoch 196/10000

Epoch 196: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2697 - mse: 0.2697 - mae: 0.4186 - val_loss: 0.2772 - val_mse: 0.2772 - val_mae: 0.4242 - 2s/epoch - 168ms/step
Epoch 197/10000

Epoch 197: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2728 - mse: 0.2728 - mae: 0.4212 - val_loss: 0.2674 - val_mse: 0.2674 - val_mae: 0.4196 - 2s/epoch - 168ms/step
Epoch 198/10000

Epoch 198: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2715 - mse: 0.2715 - mae: 0.4204 - val_loss: 0.3204 - val_mse: 0.3204 - val_mae: 0.4593 - 2s/epoch - 168ms/step
Epoch 199/10000

Epoch 199: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2836 - mse: 0.2836 - mae: 0.4288 - val_loss: 0.2695 - val_mse: 0.2695 - val_mae: 0.4197 - 2s/epoch - 169ms/step
Epoch 200/10000

Epoch 200: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2696 - mse: 0.2696 - mae: 0.4189 - val_loss: 0.2686 - val_mse: 0.2686 - val_mae: 0.4192 - 2s/epoch - 169ms/step
Epoch 201/10000

Epoch 201: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2691 - mse: 0.2691 - mae: 0.4185 - val_loss: 0.2722 - val_mse: 0.2722 - val_mae: 0.4237 - 2s/epoch - 167ms/step
Epoch 202/10000

Epoch 202: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2707 - mse: 0.2707 - mae: 0.4192 - val_loss: 0.2700 - val_mse: 0.2700 - val_mae: 0.4212 - 2s/epoch - 168ms/step
Epoch 203/10000

Epoch 203: val_loss did not improve from 0.26714
12/12 - 2s - loss: 0.2693 - mse: 0.2693 - mae: 0.4185 - val_loss: 0.2706 - val_mse: 0.2706 - val_mae: 0.4228 - 2s/epoch - 168ms/step
Epoch 203: early stopping
