#!/usr/bin/env python3
import sys
import os
import shutil
import argparse
from sea_ice_SAR.utils import decompose_filepath
from sea_ice_SAR.ML_tools import (
    config_parser,
    calculate_hidden_layer_size,
    process_data,
    learning_curve,
    tr_val_split,
)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping


def NN(hidden_layer_size, input_layer_size, output_layer_size):
    # Construct Neural Network
    model = Sequential()
    model.add(
        Dense(
            hidden_layer_size,
            input_dim=input_layer_size,
            kernel_initializer="normal",
            activation="relu",
        )
    )
    model.add(Dense(hidden_layer_size, kernel_initializer="normal", activation="relu"))
    model.add(Dense(hidden_layer_size, kernel_initializer="normal", activation="relu"))
    model.add(
        Dense(
            output_layer_size,
            kernel_initializer="normal",
        )
    )

    model.compile(loss="mean_absolute_error", optimizer="adam")
    model.summary()

    return model


def main(args):
    # Parse configuration
    (
        train_data,
        _,
        num_epochs,
        hidden_size,
        verbosity,
        K,
        SMOTE,
    ) = config_parser(args.ml_config)

    # Set up results directory
    config_dir, filename, _ = decompose_filepath(args.ml_config)
    result_dir = os.path.join(
        ".".join(config_dir.split("/")[:-1]), f"results/NN_{filename}"
    )
    try:
        os.mkdir(result_dir)
    except FileExistsError:
        shutil.rmtree(result_dir)
        os.mkdir(result_dir)

    # Verbosity == 1 --> sys.stdout
    # Verbosity == 2 --> .log file
    if verbosity == 2:
        log_file = open(f"{result_dir}/train.log", "w")
        sys.stdout = log_file

    # Modify train dataset
    X_tr, Y_tr = process_data(train_data, args.ml_config, regression=True, SMOTE=SMOTE)

    # Define hidden layer size
    input_layer_size = X_tr.shape[1]
    output_layer_size = 1
    if not hidden_size:
        hidden_size = calculate_hidden_layer_size(
            input_layer_size, output_layer_size, hidden_size
        )

    # K-fold classification
    tr_val_pairs = tr_val_split(K, X_tr, Y_tr)

    for iter, (train, validation) in enumerate(tr_val_pairs):
        print(
            f"*************************** Fold #: {iter+1} ***************************",
            file=sys.stdout,
        )
        checkpoint_path = f"{result_dir}/ckpt_{iter+1}"
        cp_callback = ModelCheckpoint(
            filepath=checkpoint_path, save_best_only=True, verbose=verbosity, mode="min"
        )
        es_callback = EarlyStopping(
            monitor="val_loss", mode="min", verbose=verbosity, patience=50
        )

        model = NN(hidden_size, input_layer_size, output_layer_size)

        # Train the model
        model_summary = model.fit(
            x=X_tr[train],
            y=Y_tr[train],
            epochs=num_epochs,
            batch_size=1024,
            verbose=verbosity,
            validation_data=(X_tr[validation], Y_tr[validation]),
            callbacks=[cp_callback, es_callback],
        )

        # Plot the learning curve
        learning_curve(model_summary.history, result_dir, iter)

        if K == 1:
            break

    # stdout redirection closed
    if verbosity == 2:
        log_file.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--ml-config",
        type=str,
        help="YAML file containing the configuration for machine learning",
    )

    args = parser.parse_args()
    main(args)
