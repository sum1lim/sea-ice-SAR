#!/usr/bin/env python3
import argparse
import sys
import tensorflow as tf
import numpy as np

from statistics import stdev
from sea_ice_SAR.ML_tools import (
    config_parser,
    process_data,
    regression_plots,
)
from sea_ice_SAR.utils import decompose_filepath
from tensorflow.keras.models import load_model
from scipy.stats import pearsonr
from sklearn.metrics import r2_score, mean_squared_error

tf.get_logger().setLevel("ERROR")


def main(args):
    # Parse configuration
    (
        _,
        test_data,
        _,
        _,
        verbosity,
        K,
        _,
        min_num_points,
        masks,
        CNN_layers,
        value_range,
    ) = config_parser(args.ml_config)
    _, cfg_filename, _ = decompose_filepath(args.ml_config)

    log_file = open(f"{args.result_dir}/{cfg_filename}/test.log", "w")
    sys.stdout = log_file

    # Modify test dataset
    X_te, CNN_stacks, Y_te = process_data(
        test_data,
        args.ml_config,
        regression=True,
        masks=masks,
        resampling=True,
        CNN_layers=CNN_layers,
        min_num_points=min_num_points,
    )

    if type(CNN_stacks) == np.ndarray:
        X_te = {"conv": CNN_stacks, "cat": X_te}

    error_li = []
    rmse_li = []
    r2_li = []
    pearsonr_li = []
    for k in range(K):
        print(
            f"*************************** Fold #: {k+1} ***************************",
            file=sys.stdout,
        )
        # Call checkpoint
        checkpoint_path = f"{args.result_dir}/{cfg_filename}/ckpt_{k+1}"
        trained_model = load_model(checkpoint_path)

        # Predict the test dataset
        y_pred = trained_model.predict(X_te, verbose=verbosity).flatten()

        absolute_errors = abs(Y_te - y_pred)
        mean_absolute_error = sum(abs(Y_te - y_pred)) / len(Y_te)
        error_li.append(mean_absolute_error)
        rmse = mean_squared_error(Y_te, y_pred, squared=False)
        rmse_li.append(rmse)
        r2 = r2_score(Y_te, y_pred, multioutput="variance_weighted")
        r2_li.append(r2)
        corr_coefficient = pearsonr(Y_te, y_pred)[0]
        pearsonr_li.append(corr_coefficient)

        print(f"Mean Absolute Error: {mean_absolute_error}", file=sys.stdout)
        print(f"RMSE: {rmse}", file=sys.stdout)
        print(f"R2 Score: {r2}", file=sys.stdout)
        print(f"Pearson's r: {corr_coefficient}", file=sys.stdout)
        regression_plots(
            Y_te, y_pred, absolute_errors, f"{args.result_dir}/{cfg_filename}", k
        )

    print(f"\nMimimum MAE: {min(error_li)}", file=sys.stdout)
    print(f"Average MAE: {sum(error_li)/K}", file=sys.stdout)
    print(f"Standard Deviation (MAE): {stdev(error_li)}", file=sys.stdout)

    print(f"\nMinimum RMSE Score: {min(rmse_li)}", file=sys.stdout)
    print(f"Average RMSE Score: {sum(rmse_li)/K}", file=sys.stdout)
    print(f"Standard Deviation (RMSE): {stdev(rmse_li)}", file=sys.stdout)

    print(f"\nMaximum R2 Score: {max(r2_li)}", file=sys.stdout)
    print(f"Average R2 Score: {sum(r2_li)/K}", file=sys.stdout)
    print(f"Standard Deviation (R2 Score): {stdev(r2_li)}", file=sys.stdout)

    print(f"\nMaximum Pearson's r: {max(pearsonr_li)}", file=sys.stdout)
    print(f"Average Pearson's r: {sum(pearsonr_li)/K}", file=sys.stdout)
    print(f"Standard Deviation (Pearson's r): {stdev(pearsonr_li)}", file=sys.stdout)

    log_file.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--result-dir",
        type=str,
        help="Directory path with train results including checkpoint files",
    )
    parser.add_argument(
        "--ml-config",
        nargs="+",
        type=str,
        help="YAML file containing the configuration for deep learning",
    )

    args = parser.parse_args()
    if type(args.ml_config) == list:
        ml_configs = args.ml_config[:]
        for ml_config in ml_configs:
            args.ml_config = ml_config
            main(args)
    else:
        main(args)
