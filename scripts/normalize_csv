#!/usr/bin/env python3
import argparse
import os
import sys
import pandas as pd
from sea_ice_SAR.utils import decompose_filepath


def normalize(input, std_data):
    tr_df = pd.read_csv(std_data)

    minimums = {
        col: tr_df[col].min()
        for col in tr_df.columns
        if col not in ["label", "src_dir", "row", "col", "num_points", "mask"]
    }
    maximums = {
        col: tr_df[col].max()
        for col in tr_df.columns
        if col not in ["label", "src_dir", "row", "col", "num_points", "mask"]
    }

    df = pd.read_csv(input)

    for col in df.columns:
        if col in ["label", "src_dir", "row", "col", "num_points", "mask"]:
            continue
        df[col] = (df[col] - minimums[col]) / (maximums[col] - minimums[col])

    return df


def main(args):
    if os.path.isfile(args.input) == False or os.path.isfile(args.std_data) == False:
        print("File(s) not existing", file=sys.stderr)
        sys.exit(1)

    decomposed = decompose_filepath(args.input)

    df = normalize(args.input, args.std_data)

    out = decomposed[0] + "/" + decomposed[1] + "_norm.csv"

    df.to_csv(out, index=False)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument("--input", type=str, help="Path of dataset to be normalized")
    parser.add_argument(
        "--std-data", type=str, help="Dataset that provides normalization standard"
    )

    args = parser.parse_args()
    main(args)
