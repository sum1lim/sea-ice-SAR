#!/usr/bin/env python3
import argparse
from math import sqrt, ceil, floor
import sys
import numpy as np

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import (
    Conv2D,
    MaxPooling2D,
    UpSampling2D,
    ZeroPadding2D,
    Cropping2D,
)
from sea_ice_SAR.ML_tools import process_data, learning_curve
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping


def CAE(input_dimension):
    if input_dimension > 16:
        print("Input dimension too big", file=sys.stderr)
    padding_size = (16 - input_dimension) / 2
    input_img = Input(shape=(input_dimension, input_dimension, 1))

    x = ZeroPadding2D(
        (
            (floor(padding_size), ceil(padding_size)),
            (floor(padding_size), ceil(padding_size)),
        )
    )(input_img)
    x = Conv2D(16, (3, 3), activation="relu", padding="same")(x)
    x = MaxPooling2D((2, 2), padding="same")(x)
    x = Conv2D(8, (3, 3), activation="relu", padding="same")(x)
    x = MaxPooling2D((2, 2), padding="same")(x)
    x = Conv2D(8, (3, 3), activation="relu", padding="same")(x)
    encoded = MaxPooling2D((2, 2), padding="same")(x)

    # at this point the representation is (4, 4, 8) i.e. 128-dimensional

    x = Conv2D(8, (3, 3), activation="relu", padding="same")(encoded)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(8, (3, 3), activation="relu", padding="same")(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(16, (3, 3), activation="relu", padding="same")(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(1, (3, 3), activation="sigmoid", padding="same")(x)
    decoded = Cropping2D(
        (
            (floor(padding_size), ceil(padding_size)),
            (floor(padding_size), ceil(padding_size)),
        )
    )(x)

    autoencoder = Model(input_img, decoded)
    autoencoder.compile(optimizer="adam", loss="binary_crossentropy")

    return autoencoder


def main(args):
    X_tr, _ = process_data(f"{args.tr_dir}/{args.filename}.csv")
    X_te, _ = process_data(f"{args.te_dir}/{args.filename}.csv")

    input_dimension = sqrt(X_tr.shape[1])
    if int(input_dimension) != input_dimension:
        print("Window should be square", file=sys.stderr)
        sys.exit(1)
    elif int(input_dimension) != sqrt(X_te.shape[1]):
        print("Different train and test sample dimensions", file=sys.stderr)
        sys.exit(1)
    else:
        input_dimension = int(input_dimension)

    X_tr = np.asarray(
        [
            [
                sample[i * input_dimension : (i + 1) * input_dimension]
                for i in range(input_dimension)
            ]
            for sample in X_tr
        ]
    )
    X_te = np.asarray(
        [
            [
                sample[i * input_dimension : (i + 1) * input_dimension]
                for i in range(input_dimension)
            ]
            for sample in X_te
        ]
    )

    X_tr = np.reshape(X_tr, (len(X_tr), input_dimension, input_dimension, 1))
    X_te = np.reshape(X_te, (len(X_te), input_dimension, input_dimension, 1))

    autoencoder = CAE(input_dimension)
    print(autoencoder.summary())

    checkpoint_path = f"./CAE_models/{args.filename}/ckpt"
    cp_callback = ModelCheckpoint(
        filepath=checkpoint_path, save_best_only=True, mode="min"
    )
    es_callback = EarlyStopping(monitor="val_loss", mode="min", patience=5)

    model_summary = autoencoder.fit(
        X_tr,
        X_tr,
        epochs=10000,
        batch_size=1024,
        shuffle=True,
        validation_data=(X_te, X_te),
        callbacks=[cp_callback, es_callback],
    )

    # Plot the learning curve
    learning_curve(model_summary.history, f"./CAE_models/{args.filename}", 0)

    decoded = autoencoder.predict(X_te), (
        len(autoencoder.predict(X_te)),
        input_dimension,
        input_dimension,
    )
    print(X_te)
    print(decoded)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--tr-dir",
        type=str,
        help="Source directory containing training datasets",
    )
    parser.add_argument(
        "--te-dir",
        type=str,
        help="Source directory containing test datasets",
    )
    parser.add_argument(
        "--filename",
        type=str,
        help="Dataset filename",
    )

    args = parser.parse_args()
    main(args)
