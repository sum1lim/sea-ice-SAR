#!/usr/bin/env python3
import argparse
from math import sqrt, ceil, floor
import sys
import os
import gc
import yaml
import pandas
import numpy as np
import tensorflow as tf

from tensorflow.keras import Input, Model, Sequential, losses
from tensorflow.keras.layers import (
    Conv3D,
    UpSampling3D,
    ZeroPadding3D,
    Cropping3D,
    MaxPooling3D,
    Flatten,
)
from tensorflow.keras.models import load_model
from sea_ice_SAR.ML_tools import process_data
from sea_ice_SAR.utils import decompose_filepath
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

tf.get_logger().setLevel("ERROR")


def CAE(input_dimension, num_layers, padding_2d, padding_height):
    autoencoder = Sequential()
    autoencoder.add(Input(shape=(input_dimension, input_dimension, num_layers, 1)))
    autoencoder.add(
        ZeroPadding3D(
            (
                (floor(padding_2d), ceil(padding_2d)),
                (floor(padding_2d), ceil(padding_2d)),
                (floor(padding_height), ceil(padding_height)),
            )
        )
    )
    autoencoder.add(Conv3D(8, (3, 3, 3), activation="relu", padding="same"))
    autoencoder.add(MaxPooling3D(pool_size=(2, 2, 2), padding="same"))
    autoencoder.add(Conv3D(4, (3, 3, 3), activation="relu", padding="same"))
    autoencoder.add(MaxPooling3D(pool_size=(2, 2, 2), padding="same"))
    autoencoder.add(Conv3D(4, (3, 3, 3), activation="relu", padding="same"))

    # end of encoding
    # start of decoding

    autoencoder.add(Conv3D(4, (3, 3, 3), activation="relu", padding="same"))
    autoencoder.add(UpSampling3D((2, 2, 2)))
    autoencoder.add(Conv3D(4, (3, 3, 3), activation="relu", padding="same"))
    autoencoder.add(UpSampling3D((2, 2, 2)))
    autoencoder.add(Conv3D(8, (3, 3, 3), activation="relu", padding="same"))
    autoencoder.add(
        Conv3D(1, kernel_size=(3, 3, 2), activation="sigmoid", padding="same")
    )
    autoencoder.add(
        Cropping3D(
            (
                (floor(padding_2d), ceil(padding_2d)),
                (floor(padding_2d), ceil(padding_2d)),
                (floor(padding_height), ceil(padding_height)),
            )
        )
    )

    autoencoder.compile(optimizer="adam", loss=losses.MeanSquaredError())
    autoencoder.summary()

    return autoencoder


def CAE_output(encoded_df, input_dir, input_file, output_filename, min_num_points=0):
    original_df = pandas.read_csv(f"{input_dir}/{input_file}.csv", header=0)
    original_df.drop(
        original_df[original_df["num_points"] < min_num_points].index, inplace=True
    )
    original_df.reset_index(drop=True, inplace=True)
    original_df.drop(
        original_df.columns.difference(
            ["label", "src_dir", "row", "col", "num_points", "mask"]
        ),
        1,
        inplace=True,
    )
    output_df = pandas.concat([original_df] + encoded_df, axis=1)
    output_df.to_csv(
        f"{input_dir}/{output_filename}.csv",
        index=False,
    )


def convert_to_vectors(df):
    flatten = Sequential()
    flatten.add(Input(shape=df.shape))
    flatten.add(Flatten())
    flatten.compile()

    return pandas.DataFrame(flatten(df)).astype("float")


def predict(autoencoder, X, dataset_type):
    encoder = Model(autoencoder.layers[0].input, autoencoder.layers[5].output)
    encoder.summary()
    encoded = encoder(X)

    decoded = autoencoder(X)

    print(
        f"Performance on {dataset_type} dataset (mean error): {abs(np.mean(X - decoded))}",
        file=sys.stdout,
    )
    return encoded, decoded


def arrange_2d_arrays(X_tr, X_te):
    input_dimension = sqrt(X_tr.shape[1])
    if int(input_dimension) != input_dimension:
        print("Window should be square", file=sys.stderr)
        sys.exit(1)
    elif int(input_dimension) != sqrt(X_te.shape[1]):
        print("Different train and test sample dimensions", file=sys.stderr)
        sys.exit(1)
    else:
        input_dimension = int(input_dimension)

    X_tr = np.asarray(
        [
            [
                sample[i * input_dimension : (i + 1) * input_dimension]
                for i in range(input_dimension)
            ]
            for sample in X_tr
        ]
    )
    X_te = np.asarray(
        [
            [
                sample[i * input_dimension : (i + 1) * input_dimension]
                for i in range(input_dimension)
            ]
            for sample in X_te
        ]
    )

    X_tr = np.reshape(X_tr, (len(X_tr), input_dimension, input_dimension, 1))
    X_te = np.reshape(X_te, (len(X_te), input_dimension, input_dimension, 1))

    return X_tr, X_te, input_dimension


def main(args):
    stream = open(args.config, "r")
    config_dict = yaml.safe_load(stream)

    _, filename, _ = decompose_filepath(args.config)

    # Verbosity == 1 --> sys.stdout
    # Verbosity == 2 --> .log file
    if config_dict["verbosity"] == 2:
        log_file = open(f"./CAE_models/{filename}/train.log", "w")
        sys.stdout = log_file

    encoded_df_tr = []
    encoded_df_te = []
    for idx, f in enumerate(config_dict["filenames"]):
        X_tr_vector, _ = process_data(
            f"{config_dict['train_dir']}/{f}.csv",
            min_num_points=config_dict["min_num_points"],
        )
        X_te_vector, _ = process_data(
            f"{config_dict['test_dir']}/{f}.csv",
            min_num_points=config_dict["min_num_points"],
        )

        X_tr_2d, X_te_2d, input_dimension = arrange_2d_arrays(X_tr_vector, X_te_vector)
        if idx == 0:
            X_tr = X_tr_2d
            X_te = X_te_2d
        else:
            X_tr = np.concatenate((X_tr, X_tr_2d), axis=-1)
            X_te = np.concatenate((X_te, X_te_2d), axis=-1)

    num_layers = idx + 1
    X_tr = np.reshape(
        X_tr, (len(X_tr), input_dimension, input_dimension, num_layers, 1)
    )
    X_te = np.reshape(
        X_te, (len(X_te), input_dimension, input_dimension, num_layers, 1)
    )

    height = 4
    if input_dimension > 8:
        print("2D dimension too big", file=sys.stderr)
    if num_layers > height:
        height = 8
    if num_layers > 8:
        print("Number of layers too big", file=sys.stderr)

    padding_2d = (8 - input_dimension) / 2
    padding_height = (height - num_layers) / 2

    checkpoint_path = f"./CAE_models/{filename}/ckpt"
    cp_callback = ModelCheckpoint(
        filepath=checkpoint_path,
        save_best_only=True,
        mode="min",
        verbose=config_dict["verbosity"],
    )
    es_callback = EarlyStopping(
        monitor="val_loss", mode="min", patience=50, verbose=config_dict["verbosity"]
    )

    if not os.path.exists(checkpoint_path):
        autoencoder = CAE(input_dimension, num_layers, padding_2d, padding_height)
        autoencoder.compile(optimizer="adam", loss=losses.MeanSquaredError())

        model_summary = autoencoder.fit(
            X_tr,
            X_tr,
            epochs=config_dict["epochs"],
            batch_size=1024,
            shuffle=True,
            validation_data=(X_te, X_te),
            callbacks=[cp_callback, es_callback],
            verbose=config_dict["verbosity"],
        )

    autoencoder = load_model(checkpoint_path)

    encoded_tr, _ = predict(autoencoder, X_tr, "train")
    encoded_te, _ = predict(autoencoder, X_te, "test")

    encoded_df_tr.append(convert_to_vectors(encoded_tr))
    encoded_df_te.append(convert_to_vectors(encoded_te))

    CAE_output(
        encoded_df_tr,
        config_dict["train_dir"],
        config_dict["filenames"][0],
        config_dict["output_filename"],
        config_dict["min_num_points"],
    )
    CAE_output(
        encoded_df_te,
        config_dict["test_dir"],
        config_dict["filenames"][0],
        config_dict["output_filename"],
        config_dict["min_num_points"],
    )

    # stdout redirection closed
    if verbosity == 2:
        log_file.close()

    # garbage collection
    gc.collect()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--config",
        nargs="+",
        type=str,
        help="YAML file containing the configuration for CAE",
    )

    args = parser.parse_args()
    args = parser.parse_args()
    if type(args.config) == list:
        configs = args.config[:]
        for config in configs:
            args.config = config
            main(args)
    else:
        main(args)
