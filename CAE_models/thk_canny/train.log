Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
zero_padding3d (ZeroPadding3 (None, 8, 8, 8, 1)        0         
_________________________________________________________________
conv3d (Conv3D)              (None, 8, 8, 8, 8)        224       
_________________________________________________________________
max_pooling3d (MaxPooling3D) (None, 4, 4, 4, 8)        0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 4, 4, 4, 4)        868       
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 2, 2, 2, 4)        0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 2, 2, 2, 4)        436       
_________________________________________________________________
up_sampling3d (UpSampling3D) (None, 4, 4, 4, 4)        0         
_________________________________________________________________
conv3d_3 (Conv3D)            (None, 4, 4, 4, 4)        436       
_________________________________________________________________
up_sampling3d_1 (UpSampling3 (None, 8, 8, 8, 4)        0         
_________________________________________________________________
conv3d_4 (Conv3D)            (None, 8, 8, 8, 8)        872       
_________________________________________________________________
conv3d_5 (Conv3D)            (None, 8, 8, 8, 1)        217       
_________________________________________________________________
cropping3d (Cropping3D)      (None, 7, 7, 6, 1)        0         
=================================================================
Total params: 3,053
Trainable params: 3,053
Non-trainable params: 0
_________________________________________________________________
Epoch 1/1000
14/14 - 7s - loss: 0.1015 - val_loss: 0.2281

Epoch 00001: val_loss improved from inf to 0.22809, saving model to ./CAE_models/thk_canny/ckpt
Epoch 2/1000
14/14 - 7s - loss: 0.0947 - val_loss: 0.2112

Epoch 00002: val_loss improved from 0.22809 to 0.21122, saving model to ./CAE_models/thk_canny/ckpt
Epoch 3/1000
14/14 - 7s - loss: 0.0929 - val_loss: 0.2136

Epoch 00003: val_loss did not improve from 0.21122
Epoch 4/1000
14/14 - 7s - loss: 0.0914 - val_loss: 0.2157

Epoch 00004: val_loss did not improve from 0.21122
Epoch 5/1000
14/14 - 7s - loss: 0.0892 - val_loss: 0.2233

Epoch 00005: val_loss did not improve from 0.21122
Epoch 6/1000
14/14 - 7s - loss: 0.0858 - val_loss: 0.2196

Epoch 00006: val_loss did not improve from 0.21122
Epoch 7/1000
14/14 - 7s - loss: 0.0831 - val_loss: 0.2092

Epoch 00007: val_loss improved from 0.21122 to 0.20922, saving model to ./CAE_models/thk_canny/ckpt
Epoch 8/1000
14/14 - 7s - loss: 0.0809 - val_loss: 0.1936

Epoch 00008: val_loss improved from 0.20922 to 0.19363, saving model to ./CAE_models/thk_canny/ckpt
Epoch 9/1000
14/14 - 7s - loss: 0.0793 - val_loss: 0.1823

Epoch 00009: val_loss improved from 0.19363 to 0.18234, saving model to ./CAE_models/thk_canny/ckpt
Epoch 10/1000
14/14 - 7s - loss: 0.0779 - val_loss: 0.1697

Epoch 00010: val_loss improved from 0.18234 to 0.16968, saving model to ./CAE_models/thk_canny/ckpt
Epoch 11/1000
14/14 - 7s - loss: 0.0765 - val_loss: 0.1635

Epoch 00011: val_loss improved from 0.16968 to 0.16348, saving model to ./CAE_models/thk_canny/ckpt
Epoch 12/1000
14/14 - 7s - loss: 0.0753 - val_loss: 0.1569

Epoch 00012: val_loss improved from 0.16348 to 0.15686, saving model to ./CAE_models/thk_canny/ckpt
Epoch 13/1000
14/14 - 7s - loss: 0.0738 - val_loss: 0.1404

Epoch 00013: val_loss improved from 0.15686 to 0.14036, saving model to ./CAE_models/thk_canny/ckpt
Epoch 14/1000
14/14 - 7s - loss: 0.0725 - val_loss: 0.1305

Epoch 00014: val_loss improved from 0.14036 to 0.13049, saving model to ./CAE_models/thk_canny/ckpt
Epoch 15/1000
14/14 - 7s - loss: 0.0717 - val_loss: 0.1258

Epoch 00015: val_loss improved from 0.13049 to 0.12579, saving model to ./CAE_models/thk_canny/ckpt
Epoch 16/1000
14/14 - 7s - loss: 0.0711 - val_loss: 0.1198

Epoch 00016: val_loss improved from 0.12579 to 0.11976, saving model to ./CAE_models/thk_canny/ckpt
Epoch 17/1000
14/14 - 7s - loss: 0.0707 - val_loss: 0.1166

Epoch 00017: val_loss improved from 0.11976 to 0.11662, saving model to ./CAE_models/thk_canny/ckpt
Epoch 18/1000
14/14 - 7s - loss: 0.0704 - val_loss: 0.1149

Epoch 00018: val_loss improved from 0.11662 to 0.11487, saving model to ./CAE_models/thk_canny/ckpt
Epoch 19/1000
14/14 - 7s - loss: 0.0702 - val_loss: 0.1135

Epoch 00019: val_loss improved from 0.11487 to 0.11351, saving model to ./CAE_models/thk_canny/ckpt
Epoch 20/1000
14/14 - 7s - loss: 0.0700 - val_loss: 0.1127

Epoch 00020: val_loss improved from 0.11351 to 0.11269, saving model to ./CAE_models/thk_canny/ckpt
Epoch 21/1000
14/14 - 7s - loss: 0.0698 - val_loss: 0.1113

Epoch 00021: val_loss improved from 0.11269 to 0.11128, saving model to ./CAE_models/thk_canny/ckpt
Epoch 22/1000
14/14 - 7s - loss: 0.0696 - val_loss: 0.1099

Epoch 00022: val_loss improved from 0.11128 to 0.10990, saving model to ./CAE_models/thk_canny/ckpt
Epoch 23/1000
14/14 - 7s - loss: 0.0694 - val_loss: 0.1091

Epoch 00023: val_loss improved from 0.10990 to 0.10907, saving model to ./CAE_models/thk_canny/ckpt
Epoch 24/1000
14/14 - 7s - loss: 0.0692 - val_loss: 0.1077

Epoch 00024: val_loss improved from 0.10907 to 0.10774, saving model to ./CAE_models/thk_canny/ckpt
Epoch 25/1000
14/14 - 7s - loss: 0.0689 - val_loss: 0.1057

Epoch 00025: val_loss improved from 0.10774 to 0.10571, saving model to ./CAE_models/thk_canny/ckpt
Epoch 26/1000
14/14 - 7s - loss: 0.0687 - val_loss: 0.1049

Epoch 00026: val_loss improved from 0.10571 to 0.10494, saving model to ./CAE_models/thk_canny/ckpt
Epoch 27/1000
14/14 - 7s - loss: 0.0685 - val_loss: 0.1044

Epoch 00027: val_loss improved from 0.10494 to 0.10442, saving model to ./CAE_models/thk_canny/ckpt
Epoch 28/1000
14/14 - 7s - loss: 0.0683 - val_loss: 0.1034

Epoch 00028: val_loss improved from 0.10442 to 0.10345, saving model to ./CAE_models/thk_canny/ckpt
Epoch 29/1000
14/14 - 7s - loss: 0.0680 - val_loss: 0.1031

Epoch 00029: val_loss improved from 0.10345 to 0.10305, saving model to ./CAE_models/thk_canny/ckpt
Epoch 30/1000
14/14 - 7s - loss: 0.0678 - val_loss: 0.1028

Epoch 00030: val_loss improved from 0.10305 to 0.10275, saving model to ./CAE_models/thk_canny/ckpt
Epoch 31/1000
14/14 - 7s - loss: 0.0676 - val_loss: 0.1013

Epoch 00031: val_loss improved from 0.10275 to 0.10130, saving model to ./CAE_models/thk_canny/ckpt
Epoch 32/1000
14/14 - 7s - loss: 0.0674 - val_loss: 0.1007

Epoch 00032: val_loss improved from 0.10130 to 0.10068, saving model to ./CAE_models/thk_canny/ckpt
Epoch 33/1000
14/14 - 7s - loss: 0.0672 - val_loss: 0.0996

Epoch 00033: val_loss improved from 0.10068 to 0.09960, saving model to ./CAE_models/thk_canny/ckpt
Epoch 34/1000
14/14 - 7s - loss: 0.0670 - val_loss: 0.0984

Epoch 00034: val_loss improved from 0.09960 to 0.09845, saving model to ./CAE_models/thk_canny/ckpt
Epoch 35/1000
14/14 - 7s - loss: 0.0669 - val_loss: 0.0975

Epoch 00035: val_loss improved from 0.09845 to 0.09750, saving model to ./CAE_models/thk_canny/ckpt
Epoch 36/1000
14/14 - 7s - loss: 0.0667 - val_loss: 0.0968

Epoch 00036: val_loss improved from 0.09750 to 0.09677, saving model to ./CAE_models/thk_canny/ckpt
Epoch 37/1000
14/14 - 7s - loss: 0.0665 - val_loss: 0.0959

Epoch 00037: val_loss improved from 0.09677 to 0.09590, saving model to ./CAE_models/thk_canny/ckpt
Epoch 38/1000
14/14 - 7s - loss: 0.0664 - val_loss: 0.0950

Epoch 00038: val_loss improved from 0.09590 to 0.09499, saving model to ./CAE_models/thk_canny/ckpt
Epoch 39/1000
14/14 - 7s - loss: 0.0662 - val_loss: 0.0947

Epoch 00039: val_loss improved from 0.09499 to 0.09468, saving model to ./CAE_models/thk_canny/ckpt
Epoch 40/1000
14/14 - 7s - loss: 0.0661 - val_loss: 0.0939

Epoch 00040: val_loss improved from 0.09468 to 0.09391, saving model to ./CAE_models/thk_canny/ckpt
Epoch 41/1000
14/14 - 7s - loss: 0.0660 - val_loss: 0.0939

Epoch 00041: val_loss did not improve from 0.09391
Epoch 42/1000
14/14 - 7s - loss: 0.0658 - val_loss: 0.0929

Epoch 00042: val_loss improved from 0.09391 to 0.09290, saving model to ./CAE_models/thk_canny/ckpt
Epoch 43/1000
14/14 - 7s - loss: 0.0656 - val_loss: 0.0925

Epoch 00043: val_loss improved from 0.09290 to 0.09255, saving model to ./CAE_models/thk_canny/ckpt
Epoch 44/1000
14/14 - 7s - loss: 0.0655 - val_loss: 0.0919

Epoch 00044: val_loss improved from 0.09255 to 0.09190, saving model to ./CAE_models/thk_canny/ckpt
Epoch 45/1000
14/14 - 7s - loss: 0.0653 - val_loss: 0.0917

Epoch 00045: val_loss improved from 0.09190 to 0.09165, saving model to ./CAE_models/thk_canny/ckpt
Epoch 46/1000
14/14 - 7s - loss: 0.0651 - val_loss: 0.0914

Epoch 00046: val_loss improved from 0.09165 to 0.09137, saving model to ./CAE_models/thk_canny/ckpt
Epoch 47/1000
14/14 - 7s - loss: 0.0649 - val_loss: 0.0908

Epoch 00047: val_loss improved from 0.09137 to 0.09079, saving model to ./CAE_models/thk_canny/ckpt
Epoch 48/1000
14/14 - 7s - loss: 0.0649 - val_loss: 0.0909

Epoch 00048: val_loss did not improve from 0.09079
Epoch 49/1000
14/14 - 7s - loss: 0.0645 - val_loss: 0.0903

Epoch 00049: val_loss improved from 0.09079 to 0.09028, saving model to ./CAE_models/thk_canny/ckpt
Epoch 50/1000
14/14 - 7s - loss: 0.0643 - val_loss: 0.0899

Epoch 00050: val_loss improved from 0.09028 to 0.08994, saving model to ./CAE_models/thk_canny/ckpt
Epoch 51/1000
14/14 - 7s - loss: 0.0642 - val_loss: 0.0900

Epoch 00051: val_loss did not improve from 0.08994
Epoch 52/1000
14/14 - 7s - loss: 0.0640 - val_loss: 0.0895

Epoch 00052: val_loss improved from 0.08994 to 0.08951, saving model to ./CAE_models/thk_canny/ckpt
Epoch 53/1000
14/14 - 7s - loss: 0.0638 - val_loss: 0.0891

Epoch 00053: val_loss improved from 0.08951 to 0.08914, saving model to ./CAE_models/thk_canny/ckpt
Epoch 54/1000
14/14 - 7s - loss: 0.0636 - val_loss: 0.0890

Epoch 00054: val_loss improved from 0.08914 to 0.08896, saving model to ./CAE_models/thk_canny/ckpt
Epoch 55/1000
14/14 - 7s - loss: 0.0635 - val_loss: 0.0889

Epoch 00055: val_loss improved from 0.08896 to 0.08885, saving model to ./CAE_models/thk_canny/ckpt
Epoch 56/1000
14/14 - 7s - loss: 0.0633 - val_loss: 0.0887

Epoch 00056: val_loss improved from 0.08885 to 0.08868, saving model to ./CAE_models/thk_canny/ckpt
Epoch 57/1000
14/14 - 7s - loss: 0.0631 - val_loss: 0.0882

Epoch 00057: val_loss improved from 0.08868 to 0.08817, saving model to ./CAE_models/thk_canny/ckpt
Epoch 58/1000
14/14 - 7s - loss: 0.0630 - val_loss: 0.0879

Epoch 00058: val_loss improved from 0.08817 to 0.08794, saving model to ./CAE_models/thk_canny/ckpt
Epoch 59/1000
14/14 - 7s - loss: 0.0628 - val_loss: 0.0875

Epoch 00059: val_loss improved from 0.08794 to 0.08753, saving model to ./CAE_models/thk_canny/ckpt
Epoch 60/1000
14/14 - 7s - loss: 0.0627 - val_loss: 0.0874

Epoch 00060: val_loss improved from 0.08753 to 0.08741, saving model to ./CAE_models/thk_canny/ckpt
Epoch 61/1000
14/14 - 7s - loss: 0.0626 - val_loss: 0.0873

Epoch 00061: val_loss improved from 0.08741 to 0.08732, saving model to ./CAE_models/thk_canny/ckpt
Epoch 62/1000
14/14 - 7s - loss: 0.0624 - val_loss: 0.0870

Epoch 00062: val_loss improved from 0.08732 to 0.08702, saving model to ./CAE_models/thk_canny/ckpt
Epoch 63/1000
14/14 - 7s - loss: 0.0622 - val_loss: 0.0866

Epoch 00063: val_loss improved from 0.08702 to 0.08661, saving model to ./CAE_models/thk_canny/ckpt
Epoch 64/1000
14/14 - 7s - loss: 0.0620 - val_loss: 0.0861

Epoch 00064: val_loss improved from 0.08661 to 0.08612, saving model to ./CAE_models/thk_canny/ckpt
Epoch 65/1000
14/14 - 7s - loss: 0.0619 - val_loss: 0.0860

Epoch 00065: val_loss improved from 0.08612 to 0.08604, saving model to ./CAE_models/thk_canny/ckpt
Epoch 66/1000
14/14 - 7s - loss: 0.0617 - val_loss: 0.0857

Epoch 00066: val_loss improved from 0.08604 to 0.08569, saving model to ./CAE_models/thk_canny/ckpt
Epoch 67/1000
14/14 - 7s - loss: 0.0616 - val_loss: 0.0855

Epoch 00067: val_loss improved from 0.08569 to 0.08550, saving model to ./CAE_models/thk_canny/ckpt
Epoch 68/1000
14/14 - 7s - loss: 0.0614 - val_loss: 0.0851

Epoch 00068: val_loss improved from 0.08550 to 0.08509, saving model to ./CAE_models/thk_canny/ckpt
Epoch 69/1000
14/14 - 7s - loss: 0.0613 - val_loss: 0.0846

Epoch 00069: val_loss improved from 0.08509 to 0.08459, saving model to ./CAE_models/thk_canny/ckpt
Epoch 70/1000
14/14 - 7s - loss: 0.0611 - val_loss: 0.0842

Epoch 00070: val_loss improved from 0.08459 to 0.08416, saving model to ./CAE_models/thk_canny/ckpt
Epoch 71/1000
14/14 - 7s - loss: 0.0609 - val_loss: 0.0841

Epoch 00071: val_loss improved from 0.08416 to 0.08407, saving model to ./CAE_models/thk_canny/ckpt
Epoch 72/1000
14/14 - 7s - loss: 0.0608 - val_loss: 0.0838

Epoch 00072: val_loss improved from 0.08407 to 0.08381, saving model to ./CAE_models/thk_canny/ckpt
Epoch 73/1000
14/14 - 7s - loss: 0.0607 - val_loss: 0.0841

Epoch 00073: val_loss did not improve from 0.08381
Epoch 74/1000
14/14 - 7s - loss: 0.0605 - val_loss: 0.0837

Epoch 00074: val_loss improved from 0.08381 to 0.08371, saving model to ./CAE_models/thk_canny/ckpt
Epoch 75/1000
14/14 - 7s - loss: 0.0604 - val_loss: 0.0835

Epoch 00075: val_loss improved from 0.08371 to 0.08349, saving model to ./CAE_models/thk_canny/ckpt
Epoch 76/1000
14/14 - 7s - loss: 0.0602 - val_loss: 0.0830

Epoch 00076: val_loss improved from 0.08349 to 0.08304, saving model to ./CAE_models/thk_canny/ckpt
Epoch 77/1000
14/14 - 7s - loss: 0.0601 - val_loss: 0.0831

Epoch 00077: val_loss did not improve from 0.08304
Epoch 78/1000
14/14 - 7s - loss: 0.0599 - val_loss: 0.0826

Epoch 00078: val_loss improved from 0.08304 to 0.08261, saving model to ./CAE_models/thk_canny/ckpt
Epoch 79/1000
14/14 - 7s - loss: 0.0598 - val_loss: 0.0826

Epoch 00079: val_loss improved from 0.08261 to 0.08257, saving model to ./CAE_models/thk_canny/ckpt
Epoch 80/1000
14/14 - 7s - loss: 0.0596 - val_loss: 0.0827

Epoch 00080: val_loss did not improve from 0.08257
Epoch 81/1000
14/14 - 7s - loss: 0.0595 - val_loss: 0.0828

Epoch 00081: val_loss did not improve from 0.08257
Epoch 82/1000
14/14 - 7s - loss: 0.0594 - val_loss: 0.0829

Epoch 00082: val_loss did not improve from 0.08257
Epoch 83/1000
14/14 - 7s - loss: 0.0592 - val_loss: 0.0832

Epoch 00083: val_loss did not improve from 0.08257
Epoch 84/1000
14/14 - 7s - loss: 0.0591 - val_loss: 0.0834

Epoch 00084: val_loss did not improve from 0.08257
Epoch 85/1000
14/14 - 7s - loss: 0.0589 - val_loss: 0.0831

Epoch 00085: val_loss did not improve from 0.08257
Epoch 86/1000
14/14 - 7s - loss: 0.0588 - val_loss: 0.0834

Epoch 00086: val_loss did not improve from 0.08257
Epoch 87/1000
14/14 - 7s - loss: 0.0587 - val_loss: 0.0836

Epoch 00087: val_loss did not improve from 0.08257
Epoch 88/1000
14/14 - 7s - loss: 0.0586 - val_loss: 0.0835

Epoch 00088: val_loss did not improve from 0.08257
Epoch 89/1000
14/14 - 7s - loss: 0.0584 - val_loss: 0.0836

Epoch 00089: val_loss did not improve from 0.08257
Epoch 90/1000
14/14 - 7s - loss: 0.0585 - val_loss: 0.0846

Epoch 00090: val_loss did not improve from 0.08257
Epoch 91/1000
14/14 - 7s - loss: 0.0582 - val_loss: 0.0844

Epoch 00091: val_loss did not improve from 0.08257
Epoch 92/1000
14/14 - 7s - loss: 0.0582 - val_loss: 0.0844

Epoch 00092: val_loss did not improve from 0.08257
Epoch 93/1000
14/14 - 7s - loss: 0.0581 - val_loss: 0.0850

Epoch 00093: val_loss did not improve from 0.08257
Epoch 94/1000
14/14 - 7s - loss: 0.0579 - val_loss: 0.0850

Epoch 00094: val_loss did not improve from 0.08257
Epoch 95/1000
14/14 - 7s - loss: 0.0577 - val_loss: 0.0848

Epoch 00095: val_loss did not improve from 0.08257
Epoch 96/1000
14/14 - 7s - loss: 0.0576 - val_loss: 0.0848

Epoch 00096: val_loss did not improve from 0.08257
Epoch 97/1000
14/14 - 7s - loss: 0.0575 - val_loss: 0.0851

Epoch 00097: val_loss did not improve from 0.08257
Epoch 98/1000
14/14 - 7s - loss: 0.0575 - val_loss: 0.0853

Epoch 00098: val_loss did not improve from 0.08257
Epoch 99/1000
14/14 - 7s - loss: 0.0574 - val_loss: 0.0857

Epoch 00099: val_loss did not improve from 0.08257
Epoch 100/1000
14/14 - 7s - loss: 0.0572 - val_loss: 0.0861

Epoch 00100: val_loss did not improve from 0.08257
Epoch 101/1000
14/14 - 7s - loss: 0.0571 - val_loss: 0.0864

Epoch 00101: val_loss did not improve from 0.08257
Epoch 102/1000
14/14 - 7s - loss: 0.0570 - val_loss: 0.0865

Epoch 00102: val_loss did not improve from 0.08257
Epoch 103/1000
14/14 - 7s - loss: 0.0568 - val_loss: 0.0872

Epoch 00103: val_loss did not improve from 0.08257
Epoch 104/1000
14/14 - 7s - loss: 0.0567 - val_loss: 0.0871

Epoch 00104: val_loss did not improve from 0.08257
Epoch 105/1000
14/14 - 7s - loss: 0.0567 - val_loss: 0.0875

Epoch 00105: val_loss did not improve from 0.08257
Epoch 106/1000
14/14 - 7s - loss: 0.0565 - val_loss: 0.0883

Epoch 00106: val_loss did not improve from 0.08257
Epoch 107/1000
14/14 - 7s - loss: 0.0564 - val_loss: 0.0876

Epoch 00107: val_loss did not improve from 0.08257
Epoch 108/1000
14/14 - 7s - loss: 0.0563 - val_loss: 0.0879

Epoch 00108: val_loss did not improve from 0.08257
Epoch 109/1000
14/14 - 7s - loss: 0.0562 - val_loss: 0.0878

Epoch 00109: val_loss did not improve from 0.08257
Epoch 110/1000
14/14 - 7s - loss: 0.0560 - val_loss: 0.0881

Epoch 00110: val_loss did not improve from 0.08257
Epoch 111/1000
14/14 - 7s - loss: 0.0559 - val_loss: 0.0879

Epoch 00111: val_loss did not improve from 0.08257
Epoch 112/1000
14/14 - 7s - loss: 0.0558 - val_loss: 0.0885

Epoch 00112: val_loss did not improve from 0.08257
Epoch 113/1000
14/14 - 7s - loss: 0.0557 - val_loss: 0.0882

Epoch 00113: val_loss did not improve from 0.08257
Epoch 114/1000
14/14 - 7s - loss: 0.0556 - val_loss: 0.0896

Epoch 00114: val_loss did not improve from 0.08257
Epoch 115/1000
14/14 - 7s - loss: 0.0555 - val_loss: 0.0895

Epoch 00115: val_loss did not improve from 0.08257
Epoch 116/1000
14/14 - 7s - loss: 0.0554 - val_loss: 0.0900

Epoch 00116: val_loss did not improve from 0.08257
Epoch 117/1000
14/14 - 7s - loss: 0.0551 - val_loss: 0.0901

Epoch 00117: val_loss did not improve from 0.08257
Epoch 118/1000
14/14 - 7s - loss: 0.0551 - val_loss: 0.0905

Epoch 00118: val_loss did not improve from 0.08257
Epoch 119/1000
14/14 - 7s - loss: 0.0549 - val_loss: 0.0907

Epoch 00119: val_loss did not improve from 0.08257
Epoch 120/1000
14/14 - 7s - loss: 0.0547 - val_loss: 0.0897

Epoch 00120: val_loss did not improve from 0.08257
Epoch 121/1000
14/14 - 7s - loss: 0.0546 - val_loss: 0.0903

Epoch 00121: val_loss did not improve from 0.08257
Epoch 122/1000
14/14 - 7s - loss: 0.0547 - val_loss: 0.0910

Epoch 00122: val_loss did not improve from 0.08257
Epoch 123/1000
14/14 - 7s - loss: 0.0546 - val_loss: 0.0923

Epoch 00123: val_loss did not improve from 0.08257
Epoch 124/1000
14/14 - 7s - loss: 0.0543 - val_loss: 0.0907

Epoch 00124: val_loss did not improve from 0.08257
Epoch 125/1000
14/14 - 7s - loss: 0.0542 - val_loss: 0.0907

Epoch 00125: val_loss did not improve from 0.08257
Epoch 126/1000
14/14 - 7s - loss: 0.0541 - val_loss: 0.0897

Epoch 00126: val_loss did not improve from 0.08257
Epoch 127/1000
14/14 - 7s - loss: 0.0540 - val_loss: 0.0897

Epoch 00127: val_loss did not improve from 0.08257
Epoch 128/1000
14/14 - 7s - loss: 0.0539 - val_loss: 0.0893

Epoch 00128: val_loss did not improve from 0.08257
Epoch 129/1000
14/14 - 7s - loss: 0.0538 - val_loss: 0.0895

Epoch 00129: val_loss did not improve from 0.08257
Epoch 00129: early stopping
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 7, 7, 6, 1)]      0         
_________________________________________________________________
zero_padding3d (ZeroPadding3 (None, 8, 8, 8, 1)        0         
_________________________________________________________________
conv3d (Conv3D)              (None, 8, 8, 8, 8)        224       
_________________________________________________________________
max_pooling3d (MaxPooling3D) (None, 4, 4, 4, 8)        0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 4, 4, 4, 4)        868       
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 2, 2, 2, 4)        0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 2, 2, 2, 4)        436       
=================================================================
Total params: 1,528
Trainable params: 1,528
Non-trainable params: 0
_________________________________________________________________
Performance on train dataset (mean error): 0.004520051181316376
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 7, 7, 6, 1)]      0         
_________________________________________________________________
zero_padding3d (ZeroPadding3 (None, 8, 8, 8, 1)        0         
_________________________________________________________________
conv3d (Conv3D)              (None, 8, 8, 8, 8)        224       
_________________________________________________________________
max_pooling3d (MaxPooling3D) (None, 4, 4, 4, 8)        0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 4, 4, 4, 4)        868       
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 2, 2, 2, 4)        0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 2, 2, 2, 4)        436       
=================================================================
Total params: 1,528
Trainable params: 1,528
Non-trainable params: 0
_________________________________________________________________
Performance on test dataset (mean error): 0.06423317641019821
